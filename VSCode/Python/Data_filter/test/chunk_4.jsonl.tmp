{"text": "Despite warnings about the viruses and other malware targeted at cell phones, actual outbreaks have been few and far between. News that a Brazilian programmer has posted the source code for the Cabir mobile phone virus is raising concerns that there may soon be a malicious variant in the wild.\nTargeted at Bluetooth phones running the Symbian operating system, Cabir variants can spread to mobile phones which are discoverable. Turning off the discoverable mode renders the phones immune from Cabir and other proof-of-concept worms that have been written to target smartphones. Cabir itself can only run on Symbian OS phones running Nokia's Series 60 interface.\nWith the source code available it is more possible that more malware targeted at cellular users will emerge. There has already been at at least one virus in the wild targeted at Series 60 phones.\n\"Publishing virus source code on the Web is dangerous because it encourages others to create malware,\" said [security firm Sophos senior technology consultant Graham] Cluley in a statement. \"Although viruses for mobile phones have to date been creating more hype than havoc, it's possible that more malicious people will now be investigating ways to infect cellphones. All users should be very careful about what applications they allow to install and run on their mobile device.\"\nGiven that the primary force driving the creation and proliferation of malware is the desire to make a buck, malware writers aren't likely to be falling all over themselves to get cell phone worms and viruses out the door. However, as the platform matures and the devices become more widely used for other applications, they too could become targets. At least once someone figures out a way to make money by doing so.", "label": 1}
{"text": "Get on-the-go access to the latest insights featured on our Trustworthy Computing blogs.\nSeveral days ago, one of our customers submitted a sample (SHA1: fbe71968d4c5399c2906b56d9feadf19a35beb97, detected as TrojanDropper:Win32/Vundo.L). This trojan hijacks the hosts “vk.com” and “vkontakte.ru” (both social networking sites in Russia)and redirects them to 188.8.131.52, but achieves this in an unusual way.\nA common method used to hijack a website and redirect it to a site of the attacker’s choice is to add an entry in the Windows hosts file located in the %SystemRoot%\\system32\\drivers\\etc directory. However, when we open this file on an affected computer, it doesn’t contain any entries related to “vk.com” and “vkontakte.ru”, as you can see in the following example:\nBut when we show hidden files, we can see another “hosts” file. It is hidden, as in the following example:\nThere are two files with exactly the same name, “hosts”, in the etc directory! How can this happen?\nAs we know, it is not possible for a directory to contain two files with the same name. When we copy the file names to notepad, save them as a Unicode text file and open them with a hex editor we see the following (the upper is for the first “hosts” file, the lower is for the second “hosts” file):\nFor Unicode (UTF-16), the 0x006F is the same as 0x6F in ASCII, which is the character “o”. But what’s the 0x043E in Unicode? We can find it in Unicode chart table (Range: 0400-04FF). The following is part of this table.\nWe can see that Unicode 0x043E is a Cyrillic character, and it looks very much like the English character “o”. So the hidden “hosts” file is the real hosts file in fact. When we open this file, we can see that two entries have been added to the end of the file:\nThis is not the first time we’ve seen a hacker using Unicode characters to mislead people. In Aug 2010, a Chinese hacker disclosed a trick with a Unicode control character used to mislead people into running an executable file. Hackers use Unicode control characters 0x202E (RLO) to reverse parts of a special file name, which changes the look of the file name in Windows Explorer.\nFor example, there is a file named as “picgpj.exe”, as the following:\nThe “gpj.exe” part of this name is specially crafted. When inserting an RLO character before “gpj.exe” in this name, the whole name appears as the following:\nHackers also usually use a picture as the file icon. Unwary people treat this file as a picture, and blindly double-click to open it, thus running the executable. Obviously, this type of trick is useless for Unicode aware programs, but it is not easy for the eyes of people to identify the problem.\nCan we believe our eyes? The answer is... not always.", "label": 1}
{"text": "It’s the Beginning of the End of Cash. Sweden is pointing the way to a cash-free economy. There are many things to dislike about analog money. Cash and coins are unwieldy, heavy and dirty. Despite Square and PayPal and other services that would seem to herald the end of cash, bills and coins still represent 7 percent of America’s total economy. In Sweden, which ranked first in this year’s Global Information Technology Report from the World Economic Forum — cash is even scarcer than in the USA. While Sweden was the first European country to introduce bank notes in 1661, it’s now come farther than any other country in the attempt to eradicate them. In most Swedish cities, public buses don’t accept cash; tickets are prepaid or purchased with a cell phone text message. A small but growing number of businesses only take cards, and some bank offices — which make money on electronic transactions — have stopped handling cash altogether. ‘There are towns where it isn’t at all possible anymore to enter a bank and use cash,’ complains Curt Persson, chairman of Sweden’s National Pensioners’ Organization. He says that’s a problem for elderly people in rural areas who don’t have credit cards or don’t know how to use them to withdraw cash.\nEven churches and houses of worship are becoming increasingly friendly to cash-free transactions: At the Carl Gustaf Church in Karlshamn, southern Sweden, Vicar Johan Tyrberg recently installed a card reader to allow worshipers to tithe in digital form.\nIt may be the beginning of the end of cash. Sweden’s innovations suggest a future in which cash is increasingly rare. It’s no surprise that Sweden and other Nordic countries are at the forefront of this development, given their emphasis on technology and innovation.\nCASH, CYBERCASH AND CRIME\nA cash-reduced culture gives rise to new concerns – “cybersecurity” and “privacy”. Oscar Swartz, the founder of Banhof, Sweden’s first Internet provider, puts it like so: “One should be able to send money and donate money to different organizations without being traced every time.” Swedish crime statistics suggest a correlation between cash and crime. The number of bank robberies in Sweden has dropped from 110 in 2008 to 16 in 2011 — “the lowest level,” reporter Malin Rising notes, “since it started keeping records 30 years ago.” The Swedish Bankers’ Association also says that robberies of security transports are down.\nSweden has less of a problem with graft, the AP says, than countries with a stronger cash culture. “If people use more cards, they are less involved in shadow economy activities,” economics professor Friedrich Schneider argued. And others note that a cash-reduced culture will disincentivize pickpocketers and muggers: When a card can simply be cancelled, what’s the point?But what about cybercrime? According to the Swedish National Council for Crime Prevention, the number of computerized fraud cases, including skimming, surged to nearly 20,000 in 2011 from 3,304 in 2000. Sweden was the first European country to introduce bank notes in 1661..but now it’s come farther than most on the path to getting rid of them. ‘I can’t see why we should be printing bank notes at all anymore,’ says Bjoern Ulvaeus, former member of 1970s pop group ABBA and a vocal proponent for a world without cash. The prevalence of electronic transactions — and the digital trail they generate — also helps explain why Sweden has less of a problem with graft than countries with a stronger cash culture, such as Italy or Greece, says economics professor Friedrich Schneider of the Johannes Kepler University in Austria.\nCash and coins leave no automatic record of the financial transactions that are made with them. ‘If people use more cards, they are less involved in shadow economy activities,’ says Schneider, a so called expert on underground economies. Who benefits most in a cashless society? The BANKSTERS, of course. They can rob but they can’t be robbed. In a cashless society, they control all the wealth and YOU ARE PENNILESS. Anything you earn is just digits on a computer screen and digits can be deleted in an instant. Cut up your plastic!", "label": 1}
{"text": "Cybersecurity Experts Begin Investigation on Self-Adapting Computer Network That Defends Itself Against Hackers\nThursday, May 10, 2012 - 09:31 in Mathematics & Economics\nKansas State University cybersecurity experts are researching the feasibility of building a computer network that could protect itself against online attackers by automatically changing its setup and configuration.\n- US must focus on protecting critical computer networks from cyber attack, RAND study findsThu, 8 Oct 2009, 12:17:31 EDT\n- A new way to protect computer networks from Internet wormsWed, 4 Jun 2008, 14:56:38 EDT\n- Today's threat: Computer network terrorismTue, 19 Jan 2010, 10:38:08 EST\n- UMass Amherst computer scientist leads the way to the next revolution in artificial intelligenceMon, 2 Apr 2012, 12:37:06 EDT\n- Millionths of a second can cost millions of dollars: A new way to track network delaysThu, 20 Aug 2009, 14:27:56 EDT", "label": 1}
{"text": "Welcome to my second guide in Seven Forums.\nBefore we begin...\nIn computer networking, we all know the term \"Firewall\". Before we get into \"what is firewall\" question, I'd like to explain about frames and packets. If you read my previous guide about \"Internetwork Troubleshooting Guide\"\n, I talk a lot about packets and frames. For those who read my first guide, this one will shed more light into computer internetworks.\nA fast refresh on internetworking terms.\n- Frames - Works in Layer 2, in this case I'll be using Ethernet (there are several others). It contains information that needs to be sent/returned to a certain MAC address.\n- IP Packets - Works in Layer 3, in this case I'll be using TCP as this is what we primarily use.\n- TCP Packets - Works in Layer 4.\nHere's the visual presentation of what an Ethernet frame looks like:\nNow, before I made this guide, I wrote quite a bit about firewall in this thread\n, this guide will complete that post.\nOk, now let's begin...\nTo secure a computer network, you need to \"limit\" what can flow from one side to the other. Computer network are comprised of 2 general types:\n- \"Switched\" network, most of the time we call \"LAN\".\n- \"Routed\" network, most of the time we call \"the great wide Internet\".\nWhen do you need to use which?\nWhen you want to connect one computer to another computer, you will need a \"Switched\" network. Back in the day, this is done by several devices, Hubs, Switches, Repeaters, Access Points, and several others. A computer network is a network of computers that physically are connected together by means of wired or wireless methods. To make sure this network \"works\", you need to logically set so that these computers are on the same \"Network\" (read my first guide\nabout this topic).\nNow, in a small lab - this setup works. You can have tens or hundreds of computers networked together, BUT once you hit several hundred computers, it start to get overwhelming. From a security standpoint, having hundreds of computers networked together IS NOT SAFE. If a computer got infected by a malware that can scan local network for other hosts, you are screwed since the malware will have access to hundreds of computers DIRECTLY, thus another type of network came along - the \"Routed\" network.\nTo simplify hundreds of computer network, we need to segment the network. Let's say we group those computers by it's physical locations - 15 computers as \"Ground office\", 20 computers as \"2nd floor office\", 3 servers \"Servers\" and so on. Tthat hundreds of computers now look much simpler, instead of hundreds of hosts, we see only several networks. Each network can only communicate with each other, it can't cross over to other networks even if it's on the same switch. This time we need a \"Router\". This is one AWESOME device. It can route/bridge between networks. It can make inter network communication possible. Let's say if the computers on \"Ground floor\" got infected by a nasty worm, most of the time you only need to maintain computers in that network, the worm rarely able to move from network to network.\nNow, since we understand that computer networks need to be segmented - this is what happened globally. In offices, in schools, at homes, everyone is segmenting their networks. Now why did I say that routers are AWESOME devices? Different than switch, routers understand what's passing over it's interfaces. You see the diagram I showed you above, a Switch only understand the first row. A switch only checks what the receiver/sender MAC address and acts accordingly. A router on the other hand understands EVERY ROW on that diagram, several expensive routers can even see and understand the \"Data\" part inside a TCP packet.\nSince a router can see very deep into the frames/packets that's going in and out of it, it can now do some checking of things that's coming and going through it. This is what's called \"Firewall\", it checks things and if those things matched a rule (or some rules) stated in the router's memory, the router will act on those frames/packets accordingly as stated in the rule(s). [Great, I spend too much text just to get to the routing part of computer network... *sigh*]\nNow, there are several types of \"Firewall\" techniques that are common. I say techniques because that's what it is, it's a technique or method to check packets that's coming/going through the router. These are the commonly used techniques:\n- Address Translation\n- Stateful Checking\n- Packet Filtering\n- Application layer probe\nAs we understand now, in a common home network there are 2 distinct networks exist. The first is the \"LAN\" part, your computers, XBOX360, laptops, netbooks, PS3s, and so on. The second is the \"WAN\" part, your ISP's part. To bridge between these distinct networks, we usually use a \"broadband gateway\", or \"broadband router\", or \"internet gateway\"... All of these products are routers in essence, they connect your local network to ISP's public network and securing you in the process.\nHere's an example of a simple home network:\nPC[10.1.1.10]---[10.1.1.1]Router[126.96.36.199]---[188.8.131.52]Yahoo.com 1. Address translation\nAddress translation is the most commonly used technique in consumer grade \"firewall\", it's the easiest to implement, no logging, very safe by default, and moderately fast. What and how does it do to secure our network? There are 2 things it does, first is Network address Translation (NAT) and the second is Port Address Translation (PAT). See my picture above. In an IP packet, there always be a \"Sender IP address\" and \"Receiver IP address\" segment in the packets. IP packets contain TCP packet as it's data. In TCP packet, there are informations about destination's port address, ACK, Checksum, etc.\nIn the home network simple illustration, we have a PC that wants to connect to Yahoo.com through port 80 (common web server listen port is 80), when the PC's browser requests to Yahoo.com, it will send packets to Router[10.1.1.1]. Here's when the magic works. In the router, PC's IP packets will have \"Sender IP address\" segment filled with \"10.1.1.10\" and TCP packet's \"Sender Port number\" with some random port number generated by web browser when it initiates the communication. Now, when that packet arrived, the router will save this \"Sender IP address\" and \"Sender Port number\" to a table in the router's memory, CHANGE THE SENDER IP ADDRESS to \"184.108.40.206\"\nthen send it to Yahoo.com. Once Yahoo received the packet, asking for a webpage, Yahoo will then send it's webpage packets back to your router because the \"Sender IP address\" now is your router. Once the packet arrived at your router, it will then check against it's \"sent packets\" table, OH!! it found an entry, so the arrived packets are then again translated the packet's \"Receiver IP address\" back to \"10.1.1.10\", send the packet to the PC, then flush the table entry. PC receives the packet reads the data and draw the Yahoo page... This is how NAT do it's thing. PAT does the same thing, but it changed the \"Port number\" instead \"IP address\". [quoted from my own post]\nNow how can this simple mechanism protects you? It's easy... Since your router keeps a list of what your computer(s) requests to what/where/when, it also knows what is NOT requested, see the logic? If say some kid from china has your IP and try to send something to your public IP - which then arrived at your router, the packets will be checked against a list of hosts that you previously asked for, and this Chinese IP address is not one of them... So, by default the packets from the Chinese IP gets dropped off just like that, as if nothing happens. See, this is the basic principal of how NAT works. The rogue packets won't even be able to reach your computer, regardless if your computer has firewall or not.\nNow, after everything done, you are safe to browse the net, watch youtube, update your status in facebook, read the news, listen to last.fm, and so on... But then you bumped to an issue. As you understand, NAT will drop everything that's not in it's list as if it's a rogue packet. If you play an online game, and you're hosting a session, your computer will \"listen\" to requests off of the Internet. Now... this is getting frustrating - IF your router doesn't have the list requests and your computer doesn't request anything (it's on \"listening\" mode), you won't be able to create any game session, your friends won't be able to join your game, because every attempt they make will be dropped by your router. HOLY CRAP !!! But wait, there's a way to \"poke a hole\" in NAT, it's called \"Port Forwarding\". In a sense, \"Port Forwarding\" will forward EVERY packets that arrived at the router that has specific port number in them. When you host a game, usually the game will tell you that it will be using one or more ports (say you're playing CoD:MW2, it uses 1500, 3005, 3101, 27000-27050, 28960 ports). So, to make a hole in your NAT or effectively saying to your router that every packets that are arrived at those ports are to be sent (and translated of course) directly to your PC, you need to make a \"Port forwarding rule\". Usually in modern routers it has UPnP, it's the magical protocol that will make a hole in your firewall without you making any changes to it (automatically generates a \"Port forwarding rule\" by it self), sometimes without your consent. In a more conventional router (Cisco business/cloud class routers), usually you need to create your own port forwarding rule, it doesn't have UPnP or UPnP is disabled by default because of security reasons. In some routers it's called \"Virtual server\". Now, if you're a security concise person, you don't want UPnP running... but on the other hand, it will save your time in configuring port forwarding. I personally disable UPnP because of the security reasons. Imagine you got infected by some new undetected malware botnet client, and it uses UPnP to poke a hole in your firewall and contacted it's master server, the whole NAT firewall technique cannot save you, because the request are made from inside, and what's inside poke a hole to your defense so that what's from outside can go in... That is terrible... But, you know... consumers - they want it easy and\nsecure, which is almost impossible... [/quoted from my own post] 2. Stateful Checking\nIn stateful checking, the router will check if it has opened a communication session with the remote host. Using the sample from previous case, the router checks if it already opens a communication session with Yahoo.com, if so, then the packets from Yahoo is then permitted to pass. If let's say someone from china tests your firewall, the packets from china will arrive at your firewall, checked if the router has an open session with the china person, if it doesn't have any sessions, the packets are the dropped. 3. Packet Filtering\nNow, this is the FUN one. This technique requires a quite powerful hardware to achieve high throughput. It basically checks EVERY PACKETS to a set of rules it has. Let's say, I don't want the router to be PING-able from the internet. I put a Packet Filter rule that says, \"if it receive an ICMP 'Echo' packet in the 'Input' stage, drop the packet\". If I don't want any of computers in my LAN to contact Yahoo, I put a packet filter rule that says \"Destination IP address = Yahoo.com, drop the packet\". You can filter almost anything by using Packet Filtering. You can even cripple the network using Packet Filtering... This technique is VERY POWERFUL. 4. Application layer probe\nSeveral expensive routers (and Linux/BSD Firewall distribution) can inspect a packet very deeply. It can understand the data within the packets and then analyze it. This method requires A VERY POWERFUL HARDWARE to be able to reach a high throughput. Here's an example of the rule: I want if any Yahoo Messanger chat text contains the \"F\" word, I need that word to be changed with \"*peep*\" text before it reaches Yahoo's servers, and the router will do just that. This technique is very powerful, but IMHO is very limited in application, since it target certain application. I rarely use this technique in my own router (my Mikrotik router can do ALL techniques I talked about).\nWell, that's all for now, I'll write the *not simplified version* some other time... I hope you enjoyed the read", "label": 1}
{"text": "Cyber Law is the law governing computers and the Internet. In today’s highly digitalized world, almost everyone is affected by cyber law. Let me take a few examples:\nAlmost all transactions in shares are in demat form. Almost all companies extensively depend upon their computer networks and keep their valuable data in electronic Form.\nGovernment forms including income tax returns, company law forms etc are now filled in electronic form. Consumers are increasingly using credit cards for shopping. Most people are using email, cell phones and SMS messages for communication. Even in “non-cyber crime” cases, important evidence is found in computers / cell phones e.g. in cases of divorce, murder, kidnapping, tax evasion, organized crime, terrorist operations, counterfeit currency etc.\nCyber crime cases such as online banking frauds, online share trading fraud, source code theft, credit card fraud, tax evasion, virus attacks, cyber sabotage, phishing attacks, email hijacking, denial of service, hacking, pornography etc are becoming common. Digital signatures and e-contracts are fast replacing conventional methods of transacting business.(1)\nCyberspace refers to the nonphysical environment created by joined computers interoperating on a network. In cyberspace, computer operators interact in ways similar to the real world, except cyberspace interaction does not require physical movement beyond typing. Information can be exchanged in real time or delayed time, and people can shop, share, explore, research, work or play.\nThe Internet forms the largest cyberspace environment, housing many sub-environments within it. These include the World Wide Web (Web), USENET newsgroups and Internet Relay Chat (IRC).(2)\n “What is Cyber Law?” , Available: http://www.asianlaws.org/courses/dcl/what-is-cyber-law.htm. Asian School of cyber law, [Accessed: Aug. 2, 2010]\n “What is Cyber Space?” , Available: http://www.wisegeek.com/what-is-cyberspace.htm. wiseGEEK, [Accessed: Aug. 1, 2010]\nLAW IN CYBER’s VIEW :\nAs an IT student that studied and passed many subjects in computer and Information Technology area and a person who have thought about a new idea for Virtual Court in 21st century – from many years ago until now - and grow it in his mind, want to say here is the right place to say some things new . Maybe this is a very pure idea , but I am sure one day it can be an executive acting. I’ve thought how we can make an internet & virtual courts in 21st century. This means a victim can placed in a part of world, jury group or judges in another part of the world and as a result, all elements of a court be in somewhere but with combining the Law, communication and IT technology we make a virtual courtroom.\nWhen I sat in the Dr.Bahma CYBERLAW class , in one second , I see my dream there. CYBER LAW and CYBER SPACE and the issues that around them are very near and close to my idea. now I try to know a new thing and it is a CYBERSPACE and its relation with CYBERLAW. I hope in future I can take my final project in this area.\nIn this post I want to show in general “what is CYBER LAW?” . Of course, it is not very simple to explain CYBER LAW in a very short post but the reason to say something about it can be a symptom to enter to a wide area called CYBER SPACE and CYBER LAW.\nAccording to my recent knowledge and finding information about CYBER SPACE & CYBER LAW ( in Dr.Bahma’s class and some activities in internet) I can say and conclude that nothing different from real situation and Cyber space . The things that push people to do and show bad behaviour in real Space and Cyber is lack of ETHICS. The main different element in cyber space , that allow guilty to do crimes is invisibility .\nThe new technology in this century is like a coin with two sides. One side of Growing Technology is Helping to the speed of moving and another side is remove calm and privacy from the life of everybody that use this technologies.\nThe things that can control users in this kind of technology , after observing ethics , can be the LAW . I want to talk about this part of story in LAW IN CYBER weblog and analysis why and how the users think can have a right to stalk & Harass& & Threat in this atmosphere. I will gather some cases about this area of CYBER SPACE CRIME and write some things more about them\nIn conclusion and from my view , CYBER SPACE AND CYBER LAW is a very important part of every users that want to access and use internet, intranet, VPN or any usable and common networks in the virtual world. The Law in Cyberspace can guide people to go on the right way of using this technologies. Everyone who connect to the internet should know here is a place that million of million people live in it and this new and cyber life has a role to live and must obey the roles.\nIn further posts, we will talk and discuss more about this issue , together and with peace and in a very free situation.", "label": 1}
{"text": "How? read on.\nA “hidden” encrypted volume provides you with “plausible deniability” should the need ever arise. For example, if your drives were seized, and you were forced under order of court to reveal the password – then your hidden drive would provide an extra layer of security. How? We will first create an outer volume that is encrypted, and hide some fake files on there. Then within that encrypted outer volume, we will create a further encrypted volume. You end up with two password-protected volumes – and you can safely reveal the outer volume password – without revealing a secondary hidden volume. The TrueCrypt page has a more technical explanation of a Hidden Volume that you might want to read.\nYou will need\nSince we’ve covered basic Truecrypt file and folder encryptions before, today I will be using an entire partition. This could be a USB hard drive or a second hard drive in your PC. This drive will be formatted entirely in the process, so make sure there is nothing important on it.\nYou will also need a copy of the latest TrueCrypt for your system, which you can download here. For this guide, I have used the Mac OSX version, but the interface is similar on Windows or Linux.\nCreate a Partition\nBegin by plugging in your drive and creating a partition that we will encrypt. I showed you how to create a partition on Windows last week, but on my OS X installation I simply opened Disk Utility, find the drive in the left side, and click on the Partition tab on the right. I chose 1 partition, gave it a name, and clicked Apply.\nCreate Encrypted Volume\nLaunch TrueCrypt and click on Create Volume. Choose the second option, which says “Create a volume within a partition / drive“.\nNext, choose to create a Hidden TrueCrypt Volume.\nBe careful when you select the device on the next screen. If you gave your partition a helpful name, you should have no problem. Go ahead and select the device.\nNext are the encryption options. The defaults are those deemed secure enough for top secret government documents, so it’s probably good enough for us.\nNext, you will need to choose a password for your outer volume. Remember, this will be a password you rarely ever use, but will be the one you give up if forced to. It is very important that this password be substantially different to the one you will encrypt your hidden drive with.\nThe next screen is a little difficult to explain, but suffice to say the more you move your mouse around, the more secure your drive will be. Just do it for about 30 seconds or so, then click Format.\nFor my 160 GB USB drive, it took about an hour and half just to encrypt the outer volume. This is a one-off thing though, when you actually use the drive you need only enter the password.\nNext, you need to copy some fake files to the encrypted disk. These can be anything, but ideally they should be private looking files, maybe some home movies – something you wouldn’t mind someone seeing if you were forced to reveal passwords. Warning: You shouldn’t write to this outer volume later, or your actual hidden volume may become corrupted. It is a fake storage container only to act as a diversion. Click on the button labelled Open Outer Volume, and start copying files in. Bear in mind that if you have a 1 TB drive and someone investigating finds only 100 MB of “secret” files, it may look a bit suspicious.\nWhen you’re done copying, go back and click next. TrueCrypt will automatically unmount the drive and figure out how much space you have left for your real hidden volume. You can make it as large as you like, but I like to leave a little room on the outer drive in case someone were to accidentally write to it.\nMake the outer volume in the same way, but this time make your password long, and really good. Include capital letters, lowercase letters, numbers and punctuation. A good tactic if you don’t like random passwords is to create a sentence around it like: 20MILLIONsecretF1l3$. When asked if you’ll be storing large files, I suggest you choose ‘yes’ as the world of computing moves rapidly, and even today some movies are over 4 GB in size. Best to future-proof the drive now.\nWait again while the outer volume is encrypted. You can now mount your secure hidden volume via TrueCrypt, as it won’t be mounted by default once the hidden volume is created. Just click Mount All Devices, and type in the correct password. You don’t need to type both your outer volume password and your hidden one – just the hidden one is fine.\nIf you leave your computer on a lot of the time, don’t forget to unmount the drive. After a restart or shutdown the computer, the volume will be automatically dismounted.\nIf you read through this far, then obviously you have something worth hiding, and by utilising a hidden encrypted volume, you give yourself a way out should things go awry. Why bother encrypting a drive if the big-brother police state you are living in has the power to legally demand the decryption keys, or send you to jail? Don’t be a sucker, just give them the wrong keys!\nDownload TrueCrypt and try it out.\nImage credit: ShutterStock\nMore articles about:", "label": 1}
{"text": "POPUREB variants have a bootkit component that infect systems’ master boot record (MBR) by replacing this with its own malicious MBR. Bootkits infect systems’ MBR to execute their malicious routines even before the OS runs. These are known for storing their components outside standard file systems, making them difficult to detect by both the OS and most of the available consumer antivirus software.\nUsers may encounter these malware by visiting malicious sites that host them. These may also be downloaded by other malware onto users’ already-infected systems.\nPOPUREB variants are notable for having several components—an installer, a bootkit loader, a driver, and a payload component.\nWhat are POPUREB’s components and how does each of these function?\nThe main function of the installer component, detected as TROJ_POPUREB.SMA, is to write the malware’s components to the physical disk. It then reads and encrypts the system’s MBR and replaces this with its own malicious MBR. The installed malicious MBR then drops the driver component.\nThe driver component contains POPUREB’s drive access functionality, which means it reads the components written on the disk. It then drops and executes the payload component. The driver is also designed to prevent any write attempts to the components and to the malicious MBR that have been written on the physical disk.\nThe bootkit component, detected as RTKT_POPUREB.A, contains all of the malicious components that the attacker integrated into the malware. It is also responsible for keeping infected systems properly functioning despite the presence of malicious components. To do this, the bootkit loader also installs hooks and handlers.\nOnce executed, the payload component, detected as TROJ_POPUREB.SMB, initiates eight threads, including the creation of registry entries and connection to sites to download configuration files. It also executes POPUREB’s main malicious routines.\nHow does TROJ_POPUREB.SMB affect users?\nTROJ_POPUREB.SMB performs several malicious routines, including accessing malicious sites to send information and to download configuration files and other malware. Once installed, it also connects to a specific server to report that the infection was successful.\nWhat users should take better note of, however, is its capability to hijack browser sessions in order to create malicious HTTP traffic. This traffic may involve other payloads, including downloading other malware and displaying malicious online ads.\nHow do POPUREB variants affect users?\nAs malware with a bootkit component, POPUREB variants hide from users by infecting their systems’ MBR. As such, affected users may not readily notice the infection. Compared with other malware, these are also difficult to remove, as they are deeply rooted into infected systems, specifically in their MBR. The most severe POPUREB infection may even leave affected users no other choice but to reformat their systems. This may lead to the loss of important user data.\nAs previously stated, TROJ_POPUREB.SMB hijacks browser sessions to create HTTP traffic, which results in several problems for users. The said traffic may lead to the download of other malicious files onto already-infected systems, making them vulnerable to more infections. This traffic can also direct users to malicious ads that may serve as vectors of redirection to malicious sites such as phishing sites that steal credit card or other personally identifiable information (PII).\nWhat makes POPUREB variants noteworthy?\nMicrosoft at first thought POPUREB variants were bootkits that were capable of not only overwriting infected systems’ MBR but also of employing a driver component. This driver prevents any possible change on the physical disk where the malicious MBR and the other malicious components are written.\nInitial reports on POPUREB indicated that in order to clean infected systems, users may need to reformat their systems, which can lead to the loss of important information. Microsoft, however, clarified later on that cleanup via the Windows Recovery Console was enough to remove the bootkit from infected systems, thus users need not worry about suffering from data loss.\nUpon further analysis, our engineers also noted that because of its technological ease, POPUREB variants may be easily reused and improved by other cybercriminals. As a result, we may see more POPUREB-related attacks in the future, albeit with certain improvements.\nWhat makes POPUREB’s bootkit component different from those of bootkits like TDL4?\nEven though POPUREB’s bootkit component and TDL4 malware both overwrite infected systems’ MBR with their own malicious versions, they do differ somehow. TDL4 malware overwrite infected systems’ MBR to hide from the OS and from antivirus software. POPUREB variants, meanwhile, mainly use their MBR code to launch their driver component and the other data they write on infected systems’ disk sector. In effect, this makes POPUREB variants easier to detect compared with TDL4 malware. POPUREB variants do not encrypt data and create their own file systems as well. As such, these can be cleaned using the Windows Recovery Console.\nAre Trend Micro customers protected from POPUREB variants?\nPowered by the Trend Micro™ Smart Protection Network™, Trend Micro products protect users from various POPUREB malware. File Reputation Technology detects and blocks the download of related malicious files onto users’ systems. Web Reputation Technology, on the other hand, blocks access to related malicious sites that host various POPUREB variants.\nFor machines that are infected by POPUREB variants, customers are advised to use the Rootkit Buster to effectively detect and remove POPUREB malware on affected computers.\nWhat can users do to prevent POPUREB variants from infecting their systems?\nRefrain from visiting unknown sites such as those that come up as search engine results.\nNever click links embedded in unsolicited spam nor download files attached to email messages from unknown sources.\nStay abreast of the latest news on emerging threats and read up on these to stay protected.\nMake it a habit to always back up sensitive information. This can save you from losing data in case of a bootkit infection.\nMicrosoft also released an advisory on how to effectively remove POPUREB variants from infected systems using the Windows Recovery Console. For more information on how you can do this, read this Microsoft blog post.\nAnalysis done by Patrick Estavillo, Vincent Cabuag, and Kathleen Notario\n\"POPUREB is not a very sophisticated malware. However, its technological ease is something that we should watch, as cybercriminals can easily learn its technology and create improved versions in the future. POPUREB, specifically its bootkit component, may become the next wave in bootkit technology.\" Patrick Estavillo,Threat Analyst", "label": 1}
{"text": "If you are using a GSM phone (AT&T or T-Mobile in the U.S.), you likely have a few more months before it will be easy for practically anyone to spy on your communications.\nSecurity researcher Karsten Nohl is launching an open-source, distributed computing project designed to crack the encryption used on GSM phones and compile it into a code book that can be used to decode conversations and any data that gets sent to and from the phone.\nKarsten Nohl talks about his distributed computing, open-source AE/1 cracking project at the Hacking at Random conference.\n“We’re not creating a vulnerability but publicizing a flaw that’s already being exploited very widely,” he said in a phone interview Monday.\nThis weakness in the encryption used on the phones, A5/1, has been known about for years. There are at least four commercial tools that allow for decrypting GSM communications that range in price from $100,000 to $250,000 depending on how fast you want the software to work, said Nohl, who previously has publicized weaknesses with wireless smart card chips used in transit systems.\nIt will take 80 high-performance computers about three months to do a brute force attack on A5/1 and create a large look-up table that will serve as the code book, said Nohl, who announced the project at the Hacking at Random conference in the Netherlands 10 days ago.\nUsing the code book, anyone could get the encryption key for any GSM call, SMS message, or other communication encrypted with A5/1 and listen to the call or read the data in the clear. If 160 people donate their computing resources to the project, it should only take one and a half months to complete, he said.\nParticipants download the software and three months later they share the files created with others, via BitTorrent, for instance, Nohl said. “We have no connection to them,” he added.\nOnce the look-up table is created it would be available for anyone to use.\nSource: CNET News", "label": 1}
{"text": "The Federal Trade Commission today issued proposed revisions to the Children’s Online Privacy Protection Rule, in an effort to ensure that privacy regulations keep pace with the changing online world.\nUnder the proposal, the rules would now specifically apply to mobile phones and the definition of “personal information” would expand to include data derived from tracking cookies and geolocation. That would force sites to secure parental consent before using very common online tools to gather information about children under 13.\n“We believe (the rules) will help address a number of concerns raised\nby consumer groups, privacy experts, and child advocates, while at the same time, balancing children’s ability to be active participants in digital culture with the need to protect them from unfair data collection and marketing practices,” said Kathryn Montgomery, professor of communication at American University, in a statement issued by the Center for Digital Democracy in Washington, D.C.\nBut critics say the rules would also create some sizable technical hurdles as well as legal uncertainties.\n“It is unclear how an expanded COPPA regulatory regime would work without requiring mandatory online age verification of all Internet users, which would raise serious constitutional issues,” wrote Adam Thierer, a senior research fellow at the Mercatus Center, a free market think tank.\nIt would, for one thing, seem to require sites to know when a 12-year old sat down at a desktop computer regularly used by their mother, father or older sibling.\nWeb browser cookies are data files that store information to help sites identify a particular computer, which is used as a sort of best guess for identifying an actual person in the hopes of targeting advertising to online behavior.\nMeanwhile, geolocation data tracks the physical location of a person from information collected on mobile devices, through check-in apps like Foursquare, or map or navigation applications.\nThere are concerns that inserting an age verification process could make these sorts of tools more cumbersome, or undermine advances.\nJim Steyer, CEO of Common Sense Media, said the industry is crying wolf, as it always does when staring at new privacy rules. These are all solvable technical issues for the deep-pocketed tech sector, he said.\n“The big players are coining money on this, it’s a boom time in the Valley, so to suggest that they don’t have the resources from a technical standpoint is a joke,” he said.\n“You’re talking about companies with $100 billion valuations,” he said. “They have a lot of money and brilliant engineers and we continually tout the innovation of Silicon Valley. So our point is: figure it out, kids matter.”\nThe FTC is seeking public comment on the proposed amendments.\n“In this era of rapid technological change, kids are often tech savvy but judgment poor,” FTC Chairman Jon Leibowitz said in a prepared statement. “We want to ensure that the COPPA Rule is effective in helping parents protect their children online, without unnecessarily burdening online businesses.”\nRead on for the FTC’s summary of its proposals:\nThe COPPA Rule requires covered operators to obtain parental consent before collecting personal information from children. The FTC proposes updating the definition of “personal information” to include geolocation information and certain types of persistent identifiers used for functions other than the website’s internal operations, such as tracking cookies used for behavioral advertising. In addition, the Commission proposes modifying the definition of “collection” so operators may allow children to participate in interactive communities, without parental consent, so long as the operators take reasonable measures to delete all or virtually all children’s personal information before it is made public.\nParental Consent Mechanisms:\nThe FTC also proposes adding new methods to obtain verifiable parental consent, including electronic scans of signed parental consent forms, video-conferencing, and use of government-issued identification checked against a database, provided that the parent’s ID is deleted promptly after verification is done. These supplement the nonexclusive list of methods already set forth in the Rule.\nThe FTC proposes eliminating the less-reliable method of parental consent, known as “e-mail plus,” which is available to operators that collect personal information only for internal use. This method currently allows operators to obtain consent through an email to the parent, coupled with another step, such as sending a delayed email confirmation to the parent after receiving consent.\nTo encourage the development of new consent methods, the Commission proposes establishing a voluntary 180-day notice and comment process whereby parties may seek Commission approval of a particular consent mechanism. In addition, the Commission proposes permitting operators participating in a Commission approved safe-harbor program to use a method permitted by that program.\nConfidentiality and Security Requirements:\nTo better protect children’s personal information, the Commission proposes strengthening the Rule’s current confidentiality and security requirements. Specifically, the Commission proposes adding a requirement that operators ensure that any service providers or third-parties to whom they disclose a child’s personal information have in place reasonable procedures to protect it, that operators retain the information for only as long as is reasonably necessary, and that they properly delete that information by taking reasonable measures to protect against unauthorized access to, or use in connection with, its disposal.\nFinally, the FTC proposes to strengthen its oversight of self-regulatory “safe harbor programs” by requiring them to audit their members at least annually and report periodically to the Commission the results of those audits.", "label": 1}
{"text": "If you use free Wi-Fi in coffee shops or internet cafes to check your email, do some research or update your Facebook page, there are a couple of security issues you need to be aware of.\nFree Wi-Fi hotspots are vulnerable to so-called ‘channelling’ attackers - hackers who establish unauthorised access points alongside legitimate Wi-Fi services to steal user names and passwords. To protect yourself when using public Wi-Fi take the following steps:\n- Disable your wireless card if you’re not planning to connect to prevent intruders and preserve battery life.\n- Before connecting, check for a sign that the network name you’re planning to use has Secure Server Identification (SSID).\n- Be wary of sharing information in public locations. Hackers can use your webmail log-ins and passwords to access more sensitive information if you have the same password or a variation for all your online activities.\n- Disable shared folders to prevent the installation of spyware from a malicious network.\nWhen using internet cafes, choose one that looks professional. It can be hard to tell, but there are some good signs you can look for once you’re inside:\n- Users are forbidden from accessing the control panel settings or installing programs.\n- The computer requires a log-in to start the session.\n- The taskbar is uncluttered and free of strange applications. Unusual toolbars within browser windows are a tell-tale sign of a spyware riddled PC.\nUnfamiliar public computers may not be secured by antivirus, antispyware, or a firewall. You may ask the shop assistant a few questions about the security of their PCs, but always be suspicious and, as a rule of thumb, only access services you really must use. Assume the worst, as the machine you’re using is likely to be infected with malicious spyware and may be monitoring your browsing.\nIf you have to access confidential websites like internet banking services, double check that the website hasn’t been redirected by making sure you are using a secure ‘https’ connection. You can use these alternative ways of entering usernames and passwords to outwit keyloggers:\n- Windows has as ‘On Screen Keyboard’ built in to type passwords instead of using the keyboard. It is found though the menu at Start > Run > osk.exe\n- Use a word processor to type out the alphabet, then copy and paste the letters into the password field individually.\nMake sure you don’t tick the 'save password' or 'remember me' functions when using public computers. When you finish your session, clear your browsing history by selecting 'Delete Browsing History' from the browser menu. If you’ve divulged confidential information to a public computer, change your password at your next login to stay on the safe side.Bottom of Form", "label": 1}
{"text": "Securing Your Mobile Device\nThese are great suggestions from the website of the Austrailian Government Initiative. These fit globlally! - Take time to read more. http://www.staysmartonline.gov.au/home_internet_users/Secure_your_mobile_phone_and_devices\nRemember it's not 'just a phone'\n- Treat your smart phone like your wallet – keep it safe and on your person at all times.\n- Remember your smart phone is a computer – all the same security rules apply. This includes checking the authenticity of websites, not clicking on links from people you do not know, and watching out for phishing scams (by email, text or even voicemail) asking for personal information.\nSecure your phone\n- Turn on the security features of your phone. All phones have security settings, so familiarise yourself with them and turn them on.\n- Many mobile phones allow users to set a password or Personal Identification Number (PIN) that must be entered to use the phone. Passwords and PINs make it more difficult for thieves to steal your personal information if your phone is lost or stolen.\n- Put a PIN on your SIM card and password on your phone so that thieves cannot steal your phone credit or run up your phone bill.\n- Consider installing security software from a reputable provider. Anti-virus, anti-theft, anti-malware and firewall software is available for some mobile phone operating systems. Check with your phone manufacturer for recommendations.\n- Check for updates to your phones operating system regularly. Install them as soon as they are available – these updates often contain changes that will make your phone more secure.\n- Bluetooth lets you wirelessly connect to devices and transfer information over short distances. For Bluetooth to work, devices need to see each other and then connect. It is best to leave your phone in undiscoverable mode (hidden) so that it is only visible when you specifically need other people or devices to see it. This means that hackers cannot easily see your phone and they cannot easily connect to it unless they already have your Bluetooth address. When connecting using Bluetooth, do so in private, uncrowded areas only.\n- Be smart with Wi-Fi. When connecting to the internet using Wi-Fi, try to use an encrypted network that requires a password and which you are sure is operated by a reputable provider. Read our tips for using public wireless networks.\n- Change your settings so that your phone asks permission to join a new wireless network.\nRoom 121 Dougherty Science Center\nemail: email@example.com | phone: 865-471-3506", "label": 1}
{"text": "Emerging platforms may improve collaborations between physicians, pharmacists, genetic researchers, and computer scientists working on clinical trials. [© Kirill_M - Fotolia.com]\nThe cost of DNA sequencing has plummeted in the last decade since the human genome was published. Expenses are dropping by about 50% every five months. Last August the National Human Genome Research Institute (NHGRI) reported that researchers had received more than $24 million in grants to develop sequencing technologies that are expected to rapidly sequence a person’s genome for $1,000 or less.\nBut none of that sequence data helps anyone if it is inaccessible, uninterpretable, or isn’t linked to a functionality. As genomics starts to inform proteomics and personalized medicine, it’s going to take massive amounts of computer power for storage capacity, data management, and analysis. The amount of data generated could reach the petabyte range; A petabyte is a unit of information equal to 1,000 terabytes, or 1 billion megabytes.\nThe petabyte crisis and the need to use all that data to discover novel therapeutics provide ready-made forcing functions to move companies into the cloud. Firms are leveraging cloud-based resources to bolster storage and analysis of the huge amounts of data generated from research and clinical development involving next-generation sequencing.\nKey questions being asked by professionals are whether there will be sufficient storage capacity for all that information in healthcare systems, will the information be routinely searchable as new and potentially relevant discoveries are made, and will it be possible to routinely share structured genomic data across healthcare systems. Another big question is will it be possible to make the best clinical decisions for a patient in the context of all that data.\nCloud computing companies have recognized the opportunity to answer these questions and are putting down big stakes. On October 12, Google Ventures co-led a $15 million round of financing for sequencing informatics specialist DNAnexus. Using Google Cloud Storage, the company expects to provide a long-term solution for researchers who require access to the vast repository of DNA sequencing data contained in the public Sequence Read Archive (SRA) database.\nThe SRA database was scheduled for shutdown by the NIH along with several other bioinformatics databases. As a part of its initiative with Google, DNAnexus will provide a freely accessible web-based search interface to simplify searching and accessing these datasets as well as improve their usability for life science research. Through this interface, researchers can also download sequence read files including all sequences from the 1,000 Genomes Project.\nUsers of the DNAnexus SRA website can also import SRA datasets into the commercial DNAnexus platform to access additional functionality such as mapping, RNA-seq, ChIP-seq, variant analysis, and data visualization, as well as tools for integrating SRA data with their own sequence data.\n“The DNAnexus SRA website is an example of a ‘big data’ initiative that benefits from rethinking the interface in a 100% web-enabled world,” said Eric Morse, head of business development, Google Cloud Storage. “By combining Google’s massively scalable data storage infrastructure with DNAnexus’ expertise in web-based interfaces, genomics data analysis, and visualization, researchers can quickly access the world’s genomic information from any web browser.”\nOn November 10, Dell moved clinical practice in oncology closer to the cloud. It committed cloud computing technology, funding, and employee engagement to support pediatric cancer research programs. It is expected to speed computational processes, manage and store the resulting data, and provide a forum for analytics and collaboration.\nThe company’s foray into biomedical research will focus on a personalized medicine clinical trial being conducted by the Neuroblastoma and Medulloblastoma Translational Research Consortium (NMTRC) and supported by The Translational Genomics Research Institute (TGen).\nTGen will use its genomic technology within Dell’s donated cloud to help NMTRC identify a greater depth of personalized treatment strategies for children with stage IV neuroblastoma who are enrolled in the NMRTC trial. The study is being conducted in at least 10 children’s cancer centers in the U.S.\nCenters will send tumor samples to TGen, and “T-Gen will run the gene sequencing on the individual patient tumor samples sent by the participating institutions,” James Coffin, Ph.D., vp and GM of Dell Healthcare and Life Sciences, explained to GEN.\nThe information will then be sent to the cloud for matching with drug(s) that have the highest success in treating the cancer and are impacting the most appropriate pathways. “In pediatric care in particular, you want to make sure you are using the most efficacious, least toxic drug,” said Dr. Coffin. “The way to do that is to match the tumor through a complete genomic tumor analysis from an individual patient, and then we know what pathways can be blocked by which drugs.”\nUp until now, the trial was primarily supported by parents and foundations. Dr. Coffin said that the first trial will enroll 13 pediatric patients with stage IV neuroblastoma, but with DELL’s support, the program’s participation is expected to grow to hundreds of patients over the next three years.\nThis will generate more than 200 billion measurements per patient that must be analyzed, shared, and stored, DELL predicted. Data computation and analysis of this information would have required weeks to months to process and thus would have limited the depth and number of pediatric cancer patients who could be included in the clinical trial. But DELL expects that the time needed for such large-scale studies will be reduced to just days through the use of DELL’s cloud.\nChanging Healthcare Paradigm\nFeasibility for this approach has been established by the trial’s lead investigator Giselle Scholler, M.D., pediatric oncologist at the Van Andel Research Institute (VARI). Dr. Scholler’s team evaluated the use of predictive modeling based on genome-wide mRNA expression profiles from neuroblastoma tumor biopsies to make real-time treatment decisions.\nUpon execution of five analytical methodologies, an OncInsights™ report was generated. These analytics included biomarker expression, drug target expression, network target activity, drug response signature, and drug sensitivity signature. The interactive report allows the physician and reviewing tumor board to quickly navigate the underlying knowledge and evidence at multiple levels.\nWhile the total drug pool available to this study currently comprises 182 FDA approved compounds, only those with established pediatric dosing were used. The pilot study results showed that all reports could be generated, a tumor board held, and an individualized treatment plan agreed to and approved by a medical monitor in ≤12 days.\nDELL has high hopes that its involvement in the large-scale trial and its cloud offering will provide the needed computing power to help increase TGen’s gene sequencing and analysis capacity by 1,200 percent.\nSuch platforms have the ability to improve collaborations between the team of physicians for a patient, pharmacists, genetic researchers, and computer scientists working on the trial. Academic scientists, clinicians, and computer companies are responding to the potential of the cloud by ramping up their partnerships to store, analyze, integrate, and share data. For healthcare the cloud is a key enabler of the information exchange that will allow the leap from episodic care to complete wellness management.", "label": 1}
{"text": "Trojan.Ramgad.A is a computer threat that has been on the loose since the beginning of 2012. There is nothing exception abotu Trojan.Ramgad.A since it is very similar to other Trojans when it comes to its tactics, but by no means does it mean it can be ignored. Trojan.Ramgad.A is quick to destroy the computer system by modifying memory, adding values to the registry and silently working in the background.\nAfter the installation which obviously occurs without the user's permission, Trojan.Ramgad.A injects a key into the registry and then loads automatically together with the OS. Afterwards it connects to a remote server using an HTTP protocol and communicates with the hacker that is responsible for infecting your system. Needless to say, that this communication that takes places without your knowledge or consent breaches your privacy. What is more, based on Trojan.Ramgad.A's components, this Trojan is a 100% backdoor, so being infected with it means that sooner or later you will your system crawling with all types and sorts of malware.\nIf you want to avoid that you need to remove Trojan.Ramgad.A immediately. Even though this Trojan does not manifest itself in any flamboyant way, you can still notice quite a few changes about the system that might pinpoint the infection. For example, slow operating speed and slow Internet connection are the first signs that something is wrong. Also, you might want to check for calc.exe, readerSTD.exe and svclock.exe in Windows Task Manager's process list. These process files are directly associated with Trojan.Ramgad.A and if you see them running, then the infection is definitely in.\nThese are also the files that you need to delete if you are going to terminate Trojan.Ramgad.A on your own. If not, then leave it for a powerful antimalware application to erase Trojan.Ramgad.A for you in no time. Choosing automatic malware removal will also mean that you are protecting your system against other threats at the same time.\n- Connects to the internet without permission\n- Installs itself without permissions\n- Slow Computer\n- Slow internet connection\n- System crashes", "label": 1}
{"text": "Answer Line: Why do I get so much spam?\nSpam! Spam! Spam! Spam! Spam! Carol asked why there's so much of it.\nWhy are there so many unwanted, tricky, manipulative, annoying, dangerous, and often illegal email messages going around? Because unscrupulous people can make a tidy profit mailing Spam. In 2010, Gmail spam expert Brad Taylor told Wired that “It costs $3,000 to rent a botnet and send out 100 million messages. It takes only 30 Viagra orders to pay for that.”\nBotnets--illegal networks of infected computers controlled by people other than their legitimate owners--make an important part of the spam equation. Not only do they send out a great deal of spam, but their owners use spam to infect more computers, and thus grow their botnets.\nThese spammers can get your email address from all sorts of sources. They can search infected PCs for anything that looks like an address. They can read them off of incoming and outgoing email. Hackers can break into e-tailers' databases and steal addresses (and worse).\nPosting your email address on a Web site, as I do for this blog, is asking for trouble. I get far more spam addressed to firstname.lastname@example.org than my other five email addresses put together. Luckily, mail to that address goes through two different spam filters before I get it.\nSo what can you do about it?\nBe careful about sharing your email address. If you're uncomfortable with giving a site your address, either don't give it, and create a temporary, disposable one for that purpose.\nFilter your email. Virtually all email clients--whether local or in the cloud--have spam filters these days. Use yours, and check it daily for false positives.\nBe skeptical. Just because a message appears to come from a friend doesn't mean it has. If there's something odd about the message--if it doesn't read like something they would have written, or seems overly eager to have you click a link--don't trust it.", "label": 1}
{"text": "21 Best Ways to Lose Your Information (Not-To-Do List)\nBuilding your firewall, Part 1\nBuilding your firewall, Part 2\nBuilding your firewall, Part 3\nCreating a basic padded cell\nCuring remote-access ailments with ssh\nDaemons on the Net\nDeconstructing DoS attacks 3/2/2001 - Building Blocks to Security\nDeveloping a security plan\nDomain name hijacking\nDown the rabid hole 9/1/2000 - Building Blocks to Security\nFeeding the frenzy\nFind out how vulnerable the Internet/Your machines really are...\nFirewall and Proxy Server HOWTO (Linux) - This document is designed to teach the basics of setting up a firewall on a Linux based PC. Also covered is the installation and use of Proxy Servers to allow greater access to the Internet from behind a firewall.\nFirewall Protection - The TIS Firewall Toolkit\nFirewall technologies and methods\nHardening a Unix computer for Internet use - by Hal Stern\nHow secure are you?\nHow to Improve Security on a Newly Installed SunOS 4.1.3 System\nHow to proceed with executing a security audit. Improving the Security of Your Site by Breaking Into it\nMy System's Been Compromised...\nOS identification 12/8/2000 - Building Blocks to Security\nSecurity basics, Part 1\nSecurity basics, Part 2\nSecure Sockets Layer (SSL) Protocol\nSecuring your Solaris server\nSecurity through obscurity\nSetting up sendmail on a firewall, Part 1\nSetting up sendmail on a firewall, Part 2\nSetting up sendmail on a firewall, Part 3\nShadow Password HOW-TO (Linux) - This document aims to describe how to obtain, install, and configure the Linux password Shadow Suite. It also discusses obtaining, and reinstalling other software and network daemons that require access to user passwords.\nSquare one 10/6/2000 - Building Blocks to Security\nTapping on the walls 11/17/2000 - Building Blocks to Security\nTools you need to check and correct.\nTripwire: The next generation of security tools\nSimple Digest Security Scheme\nUgly mistake for Pretty Good\nUnderstanding viruses 1/26/2001 - Building Blocks to Security\nVirtual Suicide - Exploiting this bug a hacker could potentionally crash every computer dialed into an ISP simultaenously\nWorld Wide Web Security FAQ", "label": 1}
{"text": "Increasingly often, mobile applications on web-enabled mobile phones and tablet computers do more than they appear to.\nIn secrecy, the \"apps\" forward private data to a third party. Computer scientists from Saarbrücken have developed a new approach to prevent this data abuse. They can put a stop to the data theft through the app \"SRT AppGuard\". The chief attraction: For the protection to work, it is not necessary to identify the suspicious programs in advance, nor must the operating system be changed. Instead, the freely available app attacks the program code of the digital spies.\n\"My smartphone knows everything about me, starting with my name, my phone number, my e-mail address, my interests, up to my current location,\" explains computer science professor Michael Backes, who manages the Center for IT-Security, Privacy and Accountability at Saarland University. \"It even knows my friends quite well, as it saves their contact details, too,\" says Backes. Therefore he is not surprised that several mobile applications, also known as apps, display simple functionality up front, while in the background, they send the identification number of the device, the personal whereabouts of the user, or even the contact details of friends, colleagues and customers to a server somewhere in the internet.\nThe producers of anti-virus software have been making vivid predictions of such scenarios for some time now; in the meantime, scientific studies also prove the threat. A study from the University of California in Santa Barbara (US) concluded that among 825 examined apps for the iPhone and its operating system iOS, 21 percent forward the ID number, four percent the current position, and 0.5 percent even copy the address book.\nMichael Backes and his team of researchers now bring this abuse to an end. Their approach focuses on Android. It is the most common operating system for smartphones and tablet computers. Developed by the Google software group, this freely available operating system is used by several mobile phone manufacturers, and since November 2011 is activated daily on more than 700,000 devices.\nHowever, Android is known for its rigorous policy on assignment of privileges. If a user wants to install a downloaded app, he learns via a list which access rights to data (location, contacts, photos) and functions (Internet, locating) will be claimed by that app. Now he has two options: Either he accepts all conditions, or the app will not be installed. After the installation, the privileges cannot be revoked. \"Moreover, many developers generally claim all rights for their app because the concept of privileges of Android is misleading, but they want to ensure the smooth functioning of their app nevertheless,\" explains Philipp von Styp-Rekowsky, PhD student at the chair in IT security and cryptography.\nThis \"sink-or-swim\" strategy is put to rest by the researcher from Saarbrücken. The app \"SRT AppGuard\" based on their approach determines, for every application installed on a smartphone, what it accesses, and shows this information to the user. Privileges can now be revoked or granted to the respective app at any time. The researchers have already published the app on the platform \"Google Play\". It can be downloaded there for free. It runs problem-free on Android 3.x.x and higher. The development of the app has been taken on by the enterprise Backes SRT, which was founded by Backes in 2010. It is also located on the campus in Saarbrücken.\nComputer Science on the Saarland University Campus\nApart from the Saarland University chair in computer science and the Center for IT-Security, Privacy and Accountability, the German Research Center for Artificial Intelligence, the Max Planck Institute for Computer Science, the Max Planck Institute for Software Systems, the Center for Bioinformatics, the Intel Visual Computing Institute and the Cluster of Excellence on \"Multimodal Computing and Interaction\" can also be found there.\nFor their approach, the Saarbrücken researchers use the fact that the Android apps work in a so-called virtual machine, which is written in the computer language Java. Therefore the apps are saved on the smartphone as executable \"bytecode\" after installation. That's when SRT AppGuard comes into play. While the suspicious app is running, it is checking its bytecode for the security-sensitive instructions, which it had been programmed to do by the experts from Saarbrücken. It adds a special control code in front of the suspect comment or procedure. This is only necessary once, as the secured bytecode replaces the original one afterwards. This overwriting process usually only takes a few seconds and a small number of lines of additional code. The computer scientists have reviewed 13 apps, among them the popular game \"Angry Birds\", the music identifying app \"Shazam\" and the social-media apps \"Facebook\" and \"What's app\". For the app belonging to the microblogging service Twitter, for example, it needs 16.7 seconds and 48 additional lines of code. \"It is just as in an art museum ,\" explains Styp-Rekoswky, \"Instead of checking every visitor, you only provide the most valuable paintings with an invisible alarm function.\"\nBut the Saarbrücken app can do even more than just providing alerts. It is also able to block suspicious requests or change them so they cannot do any harm. \"Thus, we can also prevent the use of known security vulnerabilities of the respective apps or Android operating system,\" adds Professor Michael Backes. This possibility is very important if the manufacturer cannot provide security fixes in time,\" says the professor.\nJuly 9, 2012", "label": 1}
{"text": "HHS prescribes 11 basic steps for securing mobile devices\n- By Kathleen Hickey\n- Dec 17, 2012\nThe Health and Human Services Department, acknowledging the privacy risks when dealing with health information, has released several online resources to help health care providers protect patient privacy when using mobile devices such as smart phones, tablets and laptop PCs. The tools include videos, fact sheets and posters to educate health care professionals on how to best safeguard patient health information.\nWhile mobile devices hold promise in improving health care, “it’s important that these tools are used correctly,” said Joy Pritts, chief privacy officer for HHS’ Office of the National Coordinator for Health Information Technology. “Health care providers, administrators and their staffs must create a culture of privacy and security across their organizations to ensure the privacy and security of their patients’ protected health information.”\nAccording to a recent Ponemon Institute survey, negligence is the main reason for patient privacy and data breaches, with the primary cause being lost or stolen computing devices (46 percent), most of which were mobile devices. On average, 51 percent of employees are bringing their own devices to health care facilities. Ninety-four percent of the health care organizations surveyed reported a data breach in the past two years.\nOther common mobile device risks include using an unsecure Wi-Fi network; inadvertently downloading viruses or other malware; and unintentional disclosure to unauthorized users when sharing mobile devices with friends, family and/or coworkers.\nHHS recommends several policy approaches to managing mobile devices, along with 11 specific steps organizations can take, and which would apply to any public-sector agency that deals with sensitive information.\n1. Use a password or other user authentication\nConfigure mobile devices to require passwords, personal identification numbers or passcodes for access, and set the devices to lock their screens after a set period of device inactivity.\n2. Install and enable encryption\nActivate the device's built-in encryption capabilities. If no such capabilities exist, install encryption software.\n3. Install and activate remote wiping and/or remote disabling\nUse remote wiping to permanently erase data on a device that has been lost or stolen. Remote disabling can lock data, making the device usable if it is recovered.\n4. Avoid file-sharing applications\nDisable file-sharing apps that are on a device, and do not install any new ones. File-sharing software enables collaboration and the trading of files but also provides a way for unauthorized users to access mobile devices.\n5. Install and enable a firewall\nUse a personal firewall on individual devices that will detect attempts to connect and will allow or block connection based on pre-set rules.\n6. Install and enable security software\nProtect against malicious applications, viruses, spyware and malware-based attacks with security software.\n7. Keep security software up to date\nEnsure security software is current.\n8. Research mobile apps before downloading\nOnly install and use apps from known, reputable providers and verify that an app performs only the functions it should.\n9. Maintain physical control\nKeep mobile devices in locked drawers if they are not being carried by the user. Device screens should be locked, and users should not share devices.\n10. Be careful with public Wi-Fi networks\nDo not send or receive health information via a public Wi-Fi network unless it has secure, encrypted connections.\n11. Delete all stored health information before discarding or reusing the mobile device\nFollow HHS guidance to remove health information and other sensitive data before throwing out or reusing a mobile device.\nHHS also recommends making devices undiscoverable by Bluetooth, not sharing devices and registering the device with your organization.\nHHS isn’t the only agency offering advice on the issue. In October, the National Institute of Standards and Technology released draft security guidelines for mobile devices.", "label": 1}
{"text": "PreparedStatement in Java is one of several ways to execute SQL queries using JDBC API. Java provides Statement,\nPreparedStatement and CallableStatement for executing queries. Out of these three, Statement is used for general purpose queries, PreparedStatement is used for executing parametric query and CallableStatement is used for executing Stored Procedures. PreparedStatement is also a popular topic in java interviews. Questions like Difference between Statement and PreparedStatement in Java and How to prevent SQL Injection attacks in Java are popular java interview questions. In this Java JDBC tutorial we will see why should you use use PreparedStatement in Java, What are the major advantages of using PreparedStatement in Java and how PreparedStatement prevents SQL Injection attacks in Java.\nThis article is in continuation of my earlier post on database and java like 4 tips to improve performance of Java application with database and Difference between truncate and delete in SQL.If you haven’t read them already you may found those tutorial useful and interesting.\nWhat is PreparedStatement in Java\nPreparedStatement is a class in java.sql package and allows Java programmer to execute SQL queries by using JDBC package. You can get PreparedStatement object by calling connection.prepareStatement() method.SQL queries passed to this method goes to Database for pre-compilation if JDBC driver supports it. If it doesn't than pre-compilation occurs when you execute prepared queries. Prepared Statement queries are pre-compiled on database and there access plan will be reused to execute further queries which allows them to execute much quicker than normal queries generated by Statement object. Here is an example of how to use PreparedStatement in Java:\nIn this example of PreparedStatement same query and access path will be used if you pass a different parameter e.g.\n\"Standard Charted\" or \"HSBC\". ResultSet returned by prepared statement execution is of \"TYPE_FORWARD_ONLY\" but can be customized by using overloaded method of prepareStatement().\nBenefits of Java Prepared Statement\nPreparedStatement in Java JDBC offers several benefits and it’s a recommended way to execute SQL queries in any enterprise Java application or in production code. Here are few advantages of using PreparedStatement in Java:\n1. PreparedStatement allows you to write dynamic and parametric query.\nBy using PreparedStatement in Java you can write parametrized sql queries and send different parameters by using same sql queries which is lot better than creating different queries. Here is an example of parametric query written using PreparedStatement in java:\nNow you can run this query for any loan type e.g. \"personal loan”, \"home loan\" or \"gold loan\". This example of SELECT query is called parametric or parametrized query because it can be invoked with different parameter. Here “?” is used as place holder for parameter.\n2. PreparedStatement is faster than Statement in Java\nOne of the major benefits of using PreparedStatement is better performance. PreparedStatement gets pre compiled\nIn database and there access plan is also cached in database, which allows database to execute parametric query written using prepared statement much faster than normal query because it has less work to do. You should always try to use PreparedStatement in production JDBC code to reduce load on database. In order to get performance benefit its worth noting to use only parametrized version of sql query and not with string concatenation. Out of following two examples of SELECT queries, first example of SELECT query will not offer any performance benefit:\nSQL Query 1: PreparedStatement with String concatenation\nSQL Query 2: Parameterized query using PreparedStatement\nSecond SQL query is correct use of PreparedStatement in Java and give better performance than SQL query1.\n3. PreparedStatement prevents SQL Injection attacks in Java\nIf you have been working in Java web application you must be familiar with infamous SQL Injection attacks, last year Sony got victim of SQL injection and compromised several Sony play station user data. In SQL Injection attack, malicious user pass SQL meta-data combined with input which allowed them to execute sql query of there choice, If not validated or prevented before sending query to database. By using parametric queries and PreparedStatement you prevent many forms of SQL injection because all the parameters passed as part of place-holder will be escaped automatically by JDBC Driver. Though It’s worth remembering that in above example of two PreparedStatement only second example will prevent SQL injection attacks and first example is not secure with SQL injection.\n4. At last PreparedStatement queries are more readable and secure than cluttered string concatenated queries.\nLimitation of Java PreparedStatement\nDespite of being very useful PreparedStatement also has few limitations:\n1. In order to prevent SQL Injection attacks in Java, PreparedStatement doesn't allow multiple values for one placeholder (?) who makes it tricky to execute SQL query with IN clause. Following example of SQL query with IN clause using prepared Statement will not work in Java:\nThough there are some workarounds and ways to execute IN queries using PreparedStatement but those are\nrather tricky or have performance impact.\nImportant points on PreparedStatement in Java\nHere are few important points about PreparedStatement Class in Java, worth remembering:\n1. PreparedStatement in Java allows you to write parametrized query which gives better performance than Statement class in Java.\n2. In case of PreparedStatement, Database use an already compiled and defined access plan, this allows prepared statement query to run faster than normal query.\n3. Parametrized query written using PreparedStatement in Java prevents many common SQL Injection attacks.\n4. PreparedStatement allows you to write dynamic query in Java.\n5. PreparedStatement are associated with java.sql.Connection object, once you drop a connection all PreparedStatement associated with that connection will be dropped by Database.\n6. \"?\" is also called placeholder or IN parameter in Java.\n7. PreparedStatement query return FORWARD_ONLY ResultSet, so you can only move in one direction Also concurrency level of ResultSet would be \"CONCUR_READ_ONLY\".\n8. All JDBC Driver doesn't support pre compilation of SQL query in that case query is not sent to database when you call prepareStatement(..) method instead they would be sent to database when you execute PreparedStatement query.\n9. Index of placeholder or parameter starts with \"1\" and not with \"0\", which is common cause of . So in a PreparedStatement t of two placeholder, first will be referred by index 1 and second will be reference by index 2.\nThese were the reasons Why PreparedStatement in java is very popular and useful. You can still use Statement object for test programmers but consider PreparedStatement before moving to production.\nOther Java tutorials you may like", "label": 1}
{"text": "Or email safely\nOriginal article by Maurizio Antonelli\nAs well as documentation for those interested, I sincerely hope that it can raise awareness of the non-security of “electronic mail” and help users to take the appropriate implementation tools.\nLet’s start with this basic idea: “Email is not a secure media for transmitting information.”\nIn fact, almost all e-mail when traveling in the network are in clear text, without any form of encryption. As you know, an e-mail message, from the time he leave the sender PC since it arrive to the destination PC, it’s crossing different networked machines, each of which deals with “forward” it in the right direction. Whoever is at the controls of any of these machines can then view (sniff) this message, at great risk to the privacy of the sender and recipient.\nAgain: travel in clear text also UserID and Password in the process of authentication to POP3 server (incoming mail) and SMTP (outgoing mail). For this reason it is always a good idea to use the servers that provide the service to authenticate using TSL or SSL encryption in order to avoid someone take control of your e-mail.\nAnother problem: the sender of an e-mail is never guaranteed. With a few tricks you can pretend to be anyone for most of the people on the net.\nFor example with Mozilla Thunderbird. In the configuration of email accounts anybody can set up a fake sender. I can fool anyone and make them believe to be an authority, a bank or whatever. Just so I can “cheat” easily 90% -95% of users. A few will be able to notice the anomalies that are still present, however, in the headers of the mail message. With some tricks, which are not shown here, you can also lead to the disappearance of these remaining tracks … Et voila … You’re done.\nLet’s Crypt it\nLet’s start with encrypt the mail. In this way only those we want can correctly read our message.\nThe world has always been full of coding systems. The most simple anagram words, replace characters and many other methods, more or less sophisticated.\nour e-mail will travel on the network as bytes in the form of X values between 0 and 255. Substitute these values for X to X+2 values for all values of X between 0 and 253. We replace then 254 and 255 respectively with 0 and 1. We have just invented an encryption key. Only those who possess this key (because we gave it to them or because they had discovered it) will be able to understand the content of the message, others will not be able to read it.\nThe one shown above is a simple example of symmetric key encryption: the sender and receiver use the same key the first to encode and the second to decode.\nIt is a system that will not be useful for our purpose, since it ‘s not extensible to a third party. In fact, if a user A and User B are using an encryption key for their own communications, this can not be used by the user A with C. In fact, that would make decay privacy between A and B.\nIf the user A, to overcome this problem, invented and used a key to every other person he would have to handle a huge number of coding systems, and soon the system would become unmanageable.\nSolution to problem: A certificate with asymmetric key.\nWe will adopt a system that will use a certificate that consists of two distinct keys, one private and one public.\nThe private key should remain exclusively in the hands of the owner of the certificate. Should be retained with absolute attention. The owner will use it to decrypt messages that are addressed to him and more it will be used to affix a digital signature to the message which will ensure the real identity of the sender.\nThe public key may instead be distributed to the whole world, without incurring any risk of danger. It will be used to encrypt messages addressed to the owner of the certificate, only the owner of the related private key can decrypt that message. Anyone else see a number of bytes/characters without any meaning. In addition, it will be used to verify the digital signature that has been affixed with the private key.\nThe public key can be distributed to anyone without control. The fact that fall into foreign hands will not constitute any danger. The greatest attention should be given exclusively to the private key, which must remain strictly in the hands of the legitimate owners. If it does not fall into foreign hands, the system will be 100% safe (although in many mathematics departments are continuing to check the security of this solution).\nLet’s try to understand how to operate an asymmetric key certificate. The following example is not applicable for those who will be our aim, however, gives a clear idea of how in mathematics exist non bijective functions that fit for purpose.\nImagine having to give these data: 4, -2, -1 and 5. Now the public key, which encrypts the sequence of four numbers, will consist in raising the square each. This will give us: 16, 4, 1 and 25. Another user who has in his hand only the public key can decrypt the data? The answer is no. In fact, information from the first number: 16. We know from the public key, that the number is the result of a number that was squared. Reverse: the square root, but the square root of 16 is not unique. 4 is a result yes, but it is also -4. How do we know which one to take? With only the public key we cannot.\nAs mentioned above, this example can not be used: the process of encryption is too simple to be efficient, but makes a very good idea of how more complex math functions not reversible, can be used for our purpose.\nFinding function much more fit, I can reach my goal: to create a certificate key-pair with which to encrypt with the public and be able to decrypt only with the private.\nAt this point, l’ll distribute the public key and anyone can encrypt messages they want to send to me. Only and only I, holder of the related private key, can decipher the e-mail.\nNow we see another possible use of an asymmetric key certificate. Imagine you can make a transaction using the private key on a message written by me. This operation, taking account of the sender and every single character that makes up the message, will give a unique result that can be obtained exclusively if that has been carried out with my private key. The result is a kind of checksum, because it takes into account all the individual bytes that make up the mail. If the sender had a different character or whether one was different, the checksum is different.\nHolders of public key can not do the same with the same results, however, they may conduct an audit to check that the result may have produced solely and exclusively by the owner of the private key associated with it.\nI just found a way to digitally sign my message: it was definitely sent by the owner of the private key, in addition, through the checksum, I can be sure that during his trip, the mail has not undergone any change of any kind, even 1 character has not changed.\nNow there is a little attention to maintain. I will have to distribute my public key. there are 3 way to do this meeting in person “face to face”, even through the key-party, the meetings organized to exchange public keys, I can put on my personal website, or there are available key-server where everyone can put your public key and where users can do research, as if the were online lists. The thing to check in all cases is that the public key is really associated to the person you think. If i’m sure that a key come from a guy, but in reality it is from another person, the authentication system has been seriously compromised.\nWhen possible exchange of key is always better when done in person. Even a website can give assurances, for example, who knows me, knows that maury.it is my site, and then follows that the key is on http://www.maury.it/gpg I had entered it there, so it is mine but in all other cases, authentication, face to face is the surest guarantee.\nI personally always carry in my pocket a note written the code of my certificate GnuPG: 0x51F1316C. In this way, anyone who meets me may ask me the code and check it, so that he could verify the one on my website, on a key-server or on my e-mail signed (many times I had attached the public key) is really mine; Once the authentication is done by me in person, he can be pretty sure that the certificate is really mine.\nLet’s see now how to obtain a digital certificate.\nSome companies issue certificates according to the standard S/MIME. This standard is supported natively by most email clients, so you will not need to install plug-ins and/or additional extensions.\nThe first company that i want to report is Thawte. it’s from South Africa and issues free certificates for personal use. Thawte, with the classic system of “Reply to this e-mail …” can verify the authenticity of your e-mail address. For the identity registry, in order to submit the certificate that is your name and your last name, use the system of notaries: the Web Of Trust. People thought to be reliable and authenticated by the company (public notaries) is delegated to give a score from 10 to 35, depending on your length of service, having personally verified the identity of a new user.\nA user, reaching 50 points, is declared authenticated by Thawte and then he will have his name entered in the certificate. Upon reaching the 100 points it enter in the notaries and it can then authenticate other users. Of course, the identity registry system is subject to the seriousness of notaries for the truthfulness of the email address you must, instead, to trust Thawte, a company that will act as guarantor.\nThawte notaries are now all over the world, some authenticate for free, others require small sum, on the Thawte website you can find the one closer to your area. If anyone needs, I am a notary and, knowing other notaries, i can get the authentication on the fly, totally free, because I like disclosure of information and security for pure passion.\nOther Digital certificates are awarded by Italian companies like GeoTrust, the Italian Post Office and several banks. GeoTrust certificates are also released free for personal use. The others, however, as a paid service: at the offices there will be the authentication procedure and then the software will be released containing the certificate in the appropriate CD-ROM.\nWith this system, the digital signature is enhanced by the recognized authority. Thawte is recognized worldwide from several years. The others, however, may have less confidence abroad: I do not know how much credibility can have, for example, in Canada a certified mail by an authority like the Italian Post.\nThis system of authority may not be the one i was searching for: I want to be the sole guarantor of my identity. So I need a tool to create a digital certificate with an asymmetric key. Here come GnuPG.\nEnd of the first part of this interesting article, in the second part it will be explained in detail the use of GPG with email.\n- Nightingale a Beautiful music player for Linux\n- Livarp – A lightweight Linux Distribution\n- Linux shell: Dfc – Check your disk space with style\n- How to convert YouTube Video to MP3 easily on GNU/Linux\n- 5 Comic Book Viewers for Linux", "label": 1}
{"text": "Here are some things to be aware of.\n1) Your password. Do you ever find it hard to manage your passwords? most of us do! It's important to have a robust password that is hard to guess--so it shouldn't be your name, your birthday, or anything obvious. The best passwords have a mixture of words and letters, and are at least 8 characters long. To make it unbreakable, consider using simple substitutions: 1 for I, 3 for E, 5 for S, 0 for O, @ for a. Thus, for example, the word \"Christian\" could be written \"Chr15t1@n\". (That's still a pretty obvious word, so I'd try something more obscure, like the name of your first grade teacher).\nDon't use the same password for \"mission critical\" online experiences (e.g., online banking, anything linked to your credit card) and more lightweight applications (facebook). You might also consider setting up a second email address, using one of the free providers (gmail, yahoo, hotmail) to use when you sign up for something, to keep your real address more secure and spam free.\nExperts say that if you have a robust password, and you guard it carefully, you don't need to change it very frequently. But that assumes that you are careful where you use it. So beware of\n2) Phishing. This is the name given to a wide variety of cons that try to get you to enter your username and password on a fake site, so that they can get access to your email, your bank, or your facebook. Generally, this is done by sending you a message, like an email, that has a link in it. The source appears trustworthy--your bank, a good friend--but is almost always \"spoofed\", or pretending to be from someone it's not. They may try to panic you (your account is being closed down!) or offer you a great deal (free supercomputer giveaway!) but don't fall for it. The link they want you to click may LOOK realistic but is usually coded \"under the hood\" to take you to a fake site. You may not even notice, when you click on it, that the address in the browser menu bar isn't the same as your bank's.\nThe solution? Always assume links in an email or a facebook message are tricks, and never, ever enter user information or password on a site you have reached by clicking on an email. Better yet, don't click on links in an email.\nIf you want to reach your bank, never \"click through\" from the email, but type in the correct address--less convenient, but reliable. Be suspicious--your bank or your internet provider will never send you an email asking you for your password, so if you get such an email, it's always fake. And if you click a link to a site that should be secure, look for the \"https\" in front of the address in your browser's menubar--indicating a secure connection. (And make sure the address is correct-- website.com is NOT the same as website.biz, and mybank.com.ru is not mybank.com!!)\n3)Facebook scams. When you choose to go on facebook, you are putting a lot of information out there--some of which is a gold mine for those more ethically challenged. Facebook defaults to expose most of your information to the public at large. Use the Accounts>privacy menu in your profile to restrict who can see what. For example, do friends of your friends need to know your birthdate, particularly the year? Does the world need that info? Err on the side of security and hide it. Remember, phishing can occur here too--messages aren't always from whom they claim to be. (And just because Facebook ASKS you for your hometown, doesn't mean you have to tell them.)\nA major problem with facebook is the facebook apps -- you know, the quizzes, games, and other links that pop up now and again. You may not even notice when you do a facebook quiz or click an online offer that you are also clicking something that says, \"allow Quizmondo to access your user settings\" which could give them access to your wall and your friends' walls. Moreover, if you allow your friends full access to your info, the apps that THEY choose may see more than you like on YOUR wall. If you have 300+ friends, do you really trust all of them to make wise decisions with your info? Consider how much of it they need to know.\nBy the way, there's an odd tendency to think that the only people who see what you post on Facebook are your actual friends. Remember that if you post something on a friend's wall, all THEIR friends see it too. Facebook allows you to message someone privately; consider doing that, if you want to give them your unlisted phone number or tell them how many weeks you'll be out of the country, rather than post it on their wall.\nFinally, you can ask Facebook to use a higher level of security (https). It will also monitor what computer you use to log in, and tell you if a log in occurs from a different computer. Go to account>account settings>account security to set this up.\n4. Gmail It turns out that Gmail is also susceptible to scams where unscrupulous vendors can gain access to your account and send emails in your name, which then attack the recipients. I think to most of us, it's a surprise that Gmail allows anyone to gain access the way Facebook does! The most notorious recently is something called \"ShoppyBag\" in which an email from a friend promised you a photograph.. Again, the usual rule holds true: don't open it if you don't know what it is regardless of who sent it. You can always contact your friend and ask what it is! And as with Facebook, check your Gmail settings regularly to make sure your account isn't compromised.\n- Sign in on the Google Accounts homepage.\n- Click the 'My Account' link displayed at the top right of the page.\n- Click 'Authorizing Applications & Sites'. This page will list all third-party sites you've granted access to.\n- Click the 'Revoke Access' link to disable access for a site.\nConclusion: You can have a pretty safe on-line life if you maintain a healthy skepticism. Most free offers are probably too good to be true. Guard your passwords, and when in doubt, err on the side of caution. It can be a mean online world out there, but with a little care you can keep on the light side.\nSusan Forsburg is the Cathedral blogmaster and an internet geek. She still writes HTML by hand.", "label": 1}
{"text": "Editor's note: Marc Goodman is a global security adviser and futurist. He is the founder of the Future Crimes Institute and serves as Chair of Policy, Law & Ethics at Silicon Valley's Singularity University. He spoke at TED Global in June 2012. TED is a nonprofit dedicated to \"Ideas worth spreading,\" which it makes available through talks posted on its website.\n(CNN) -- The future of science and technology sounds so promising. Unprecedented advances in computing, robotics, artificial intelligence, genetics, neuroscience and biotechnology hold the potential to radically transform our world for the better and create mass abundance for all.\nI sincerely want to believe in this techno-utopian vision of things to come, but my work as a police officer and global security strategist working in more than 70 countries around the world has taught me that there is a darker side to these emerging technologies.\nThe criminal underground is highly innovative and often acts as an early adopter of emerging technologies. As a young police officer, I observed gang members and drug dealers using beepers and mobile phones, long before they were in common use by the general public. Today, criminals are even building their own encrypted radio communications networks, such as the nationwide system developed by narco cartels in Mexico.\nTechnology has made our world increasingly open, and for the most part that has huge benefits for society. Nevertheless, all of this openness may have unintended consequences. Take, for example, the 2008 terrorist assault on Mumbai, India. The perpetrators were armed with AK-47s, explosives and hand grenades. But heavy artillery is nothing new in terrorist operations. The lethal innovation was the way that the terrorists used modern information communications technologies, including smartphones, satellite imagery and night-vision goggles to locate additional victims and slaughter them.\nMoreover, the terrorists created their own operations center across the border in Pakistan, where they monitored global news broadcasts, online reporting and social media in real time, leveraging the public's photos, videos and social network updates to kill more people.\nThe terrorists in the Mumbai incident even used search engines during their attack to identify individual hostages and to determine, based upon their backgrounds, who should live or and who should die. These innovations gave terrorists unprecedented situational awareness and tactical advantage over the police and the government.\nNewer forms of technology are also subject to criminal misuse. Robots are becoming more commonplace, and international organized crime groups and terrorists have lost no time in deploying these technologies as part of their field operations. For example, drug traffickers in Latin America are using robotic submarines to deliver thousands of tons of cocaine annually to the United States.\nLast year, the FBI arrested a man in Boston who planned to use remote-controlled robotic aircraft packed with explosives to attack both the U.S. Pentagon and Capitol building. In the future, as robots become more widely deployed, so too could their criminal use and exploitation.\nAdvances in the life sciences means it is now possible to design DNA on a computer screen and send the DNA code to a \"bio printer\" for assembly. Our ability to reprogram DNA itself will undoubtedly lead to great advances in medicine, but the danger is that these same techniques can be used to modify viruses, like H5N1 influenza, to become more and more lethal, potentially affecting millions around the globe. To hackers, DNA is just another operating system waiting to be hacked.\nWe are at the dawn of an exponentially advancing technological arms race between people who are using technology for good and those who are using it for ill.\nThough such battles have gone on since the beginning of time, what has changed is the pace of innovation. New technologies and capabilities are emerging so quickly, it becomes increasingly likely they will outpace the capabilities of public safety officials to respond. The threat is serious, and the time to prepare for it is now. I can assure you that the terrorists and criminals are.\nTechnology is proliferating at an exponential pace and despite law enforcement's best efforts, cybercrime grows unabated. In coming years, we will witness an explosion in the use of robotics, artificial intelligence, nanotechnology and synthetic biology. There is little to suggest police will be any more prepared for these emerging threats than they were for basic cyber crimes.\nOur current nation-based legal and policing paradigms have clearly not kept pace with the global threat. The paradigm shifts in crime and terrorism call for a shift to a more open and participatory form of law enforcement.\nGiven the rapid acceleration of technological development, any system that relies on a small, elite force of highly trained government agents may be doomed to failure. Good people in the world far outnumber those with ill intentions. But criminals and terrorists have shown their ability to take up technological arms to harm the general populace. This calls for increased vigilance on the part of ordinary citizens.\nThe tools to change the world are in everybody's hands. How we use them is not just up to me, it's up to all of us.\nFollow @CNNOpinion on Twitter\nJoin us at Facebook/CNNOpinion\nThe opinions expressed in this commentary are solely those of Marc Goodman.", "label": 1}
{"text": "blackhole list - sometimes simply referred to as a blacklist, the publication of\ndrive-by spamming - variation of drive-by hacking in which the perpetrators gain access to a vulnerable wireless network and use that access to send huge volumes of spam.\ne-mail spoofing - forgery of an e-mail header so that the message appears to have originated from someone or somewhere other than the actual source.\ne-mail virus - computer code sent to you as an e-mail note attachment which, if activated, will cause some unexpected and usually harmful effect\nfalse positive - a legitimate e-mail message mistakenly marked as spam by a spam filter.\nhash buster - program that generates a string of text for insertion in a spam message so that, to a spam filter, the e-mail appears to be a different message each time it is sent.\nJoe job - an e-mail spoofing exploit, often carried out as an act of revenge, in which someone sends out huge volumes of spam that appear to be from someone other than the actual source.\nlist washing - removing an e-mail address from a mailing list when the recipient either requests removal or complains to the sender's ISP that he is being spammed.\nmail bomb - sending a massive amount of e-mail to a specific person or system.\nMurkogram - unsolicited commercial e-mail that includes a disclaimer to the effect that the message cannot be considered spam because it is in compliance with government regulations.\nopen relay - e-mail server that allows third-party relay of e-mail messages.\nopt-in e-mail - marketing term for e-mail that recipients sign up to receive.\nphishing - scam where the perpetrator sends out legitimate-looking e-mails in an effort to fish for personal and financial information from the recipient.\nreverse DNS - method for changing an IP address into a domain name.\nself-sending spam - unsolicited e-mail that looks like you sent it to yourself.\nspam - unsolicited e-mail on the Internet.\nspamblock - text segment interjected into an e-mail address to foil a spambot.\nspambot - program designed to harvest e-mail addresses from the Internet in order to build mailing lists.\nspam filter - program that searches incoming e-mail messages for suspicious words or word patterns to identify UCE and prevent it from reaching the user's inbox.\nS4L - online chat acronyms for \"spam for life,\" the possible result of subscribing to an online service or becoming anyone's customer or client.\nspamhaus - ISP that allows the distribution of spam.\nspam trap - software filter used to block spam.\nteergrube - intentionally slow server set up to trap spammers using address harvesting programs.\nthird-party mail relay - e-mail message sent through a mail server where neither the sender nor the recipient is a local user.\nUBE - formal term for spam.\nUCE - legal term used to describe an electronic promotional message sent to a consumer without the consumer's prior request or consent.", "label": 1}
{"text": "The Week in Linux Newsby Baiju Thakkar\nYou can never be too secure. These articles will show you how to guard your Linux system.\nSecuring your root account with Linux\nSecurity of a Linux system can take many forms: physical security, network security, application security, and others. However, all security measures can be for naught if we fail to adequately lock down the superuser -- root.\nSecure Linux Distributions\nSecuring your Linux installation is something many administrators do quite well, and you may be among the people who have post-installation checklists to insure that your system is locked down. However, wouldn't it be nice if there was a distribution that automatically installed a secure version of Linux?\nInstalling and setting up SSH\n\". . . Somewhat unlikely, perhaps, but it illustrates a point; we have learned how to protect credit card and phone numbers in the real world. But what about user names, passwords, and confidential computer data on the Internet?\"\nWe were all newbies once\nRemember the days when you first started with Linux? Well there are more folks learning Linux today than ever before. These articles are aimed at the person who is just starting to use Linux and wants to learn the common commands.\nFirst Steps with GNU/Linux\nIf you have just installed GNU/Linux and don't know quite what to do next, then this article is for you. Some fundamental Unix concepts are explained in this paper.\nA crash course introduction to Linux.\nThe article gives a real fast-paced introduction to some of the common commands used in Linux. The article talks about creating a new user, setting a user's password, and other things for newbies.\nIntro to shell scripting\nShell scripting is a fascinating combination of art and science that gives you access to the incredible flexibility and power of Linux with very simple tools. Back in the early days of PCs, I was considered quite an expert with DOS's \"batch files,\" something I now realize was a weak and gutless imitation of Unix's shell scripts.\nIntro to NEdit 5.1\nThis article started out as a review of NEdit; but the more I used it, the more I appreciated it. After due consideration, I decided to turn the article into an \"Introduction to NEdit\" -- hopefully helping introduce people to this excellent editor.\nWant to know how much XML support there is in Perl? Or do fancy stuff with Python? Or you like to write device drives? The following set of articles will show you how.\nLinux Device Drivers\nTo begin to understand how device drivers operate and how to use them, you must first forget everything you know about installing device drivers in Windows.\nA Primer for Soft Real-Time Programming with Linux: Part 1\nThe purpose of this article is to give the reader an introduction to soft real-time programming with Linux, using both processes and Linux's implementation of POSIX threads. It is not a complete guide by any stretch of the imagination, and it assumes that the reader is comfortable with using C on a Linux platform.\nProcessing XML with Perl\nPerl has an unparalleled wealth of XML support, but where do you start? Can you tell a twig from a tree? Can you see the DOM for the groves? Read on to find out which Perl module to use for your XML processing.\nExploring parsing and virtual machines with Python\nThe design of compilers/interpreters is a challenging field -- one which offers a lot of scope for theoretical exploration as well as hands on coding. Being a Python fan, I tried to implement some of the ideas which I am learning about compilers/interpreters in this beautiful language. As I am neither a Python Guru nor a compiler expert, the implementation may be imperfect. But it was certainly lots of fun!\nWant to know what some of the top people in the community are thinking about? Here are two recent interviews, one with Alan Cox (kernel hacker) and Linus Torvalds (no introduction needed), and one with David Whitinger (founder of Linsight.com).\nInterview with Linus Torvalds and Alan Cox\n32 Bits Online interviews Linus Torvalds and Alan Cox in An exclusive interview with Linus \"Linux\" Torvalds and Alan \"Kernel Hacker\" Cox.\" This interview was held over the weekend of March 25 in Austin, Texas. Present at the interview were our fearless leaders, Linus Torvalds, and Alan Cox, the number one and two men in the Linux hierarchy, and me, freelance journalist with nothing to lose and everything to gain. \"\nInterview with David Whitinger\n\"Also, small handhelds might make the desktop obsolete (or, rather, it will create a new era of desktops). The work that the embedded Linux groups are doing is very important. When Transmeta-based devices start coming out, I'll be the first in line to buy one.\"\nBaiju Thakkar is the O'Reilly Network's Linux Bureau Chief.\nDiscuss this article in the O'Reilly Network Linux Forum.\nReturn to the Linux DevCenter.", "label": 1}
{"text": "The cloud holds many promises for companies, such as the possibility of optimizing costs by paying for computing resources on an “on-demand” basis, improved reliability, lower administration costs, and others still. At the same time, many issues still remain. There is still a lot of confusion related to the security of cloud solutions, both in terms of data security, that is, the capacity of cloud providers to protect their customer’s data, as well as in terms of legal security for the stored information, which is the compliance with legislation (many times from multiple countries) and the legal risks associated with it.\nWhile many different areas from IT can benefit from employing the cloud, for many different reasons, there are some use cases where cloud computing fits particularly well. These cases represent situations where the benefits from adopting a cloud solution clearly outweigh the potential risks associated with it, and are the use cases that many companies are choosing to experiment with in the cloud.\nThe first case where the cloud - mostly cloud servers - is being heavily used is for application testing. Developers have been using virtual machines to simulate different execution environments for quite some time already, but the cloud allows them to do this on a much greater scale. By creating virtual machine images that simulate the final production environment, any developer can quickly spin up a test machine, deploy their projects to them, and run “live” tests on a separate environment, without having to rely on running virtual machines on their own PC, or even on the corporate data center.\nThe public cloud infrastructure is very interesting in this case because it is a very low-cost alternative. With a few dollars, anyone can spin up servers with multiple hardware / software configurations to test applications under different environments. It also allows controlled testing of large-scale distributed applications, which would be much harder under conventional circumstances.\nSince the data being used for application testing isn’t (or at least, shouldn’t be) real customer data, the risk of data theft or of infringing some legislation regarding where data may or may not be stored is minimal. And since the test servers can be spun up for a test run, and then shut down, companies can greatly benefit from cost optimizations by moving their test environments to the cloud.\nApplication contingency is another area where the cloud shines. The ability to quickly replicate virtual machine images across different regions creates the possibility for companies to maintain very low-cost contingency infrastructures. If something goes wrong with the main site - a hardware failure, network connectivity problems, even software crashes - new instances of the application servers can be spun up in alternative locations, minimizing application downtime. This means that anyone can have a good contingency plan without much investment in infrastructure, and without having to actually pay for the contingency at all times.\nAnother possible scenario is to keep multiple servers running in geographically disperse regions. Most companies don’t have access to multiple datacenters at different locations internally, and here is where public cloud infrastructure can really help. All the top cloud infrastructure providers offer multiple datacenter locations where servers can be replicated, so it becomes easy to spin up servers in different places. They also offer load balancers and dynamic IPs that can be shared across servers, making contingency that much easier.\nFinally, contingency doesn’t apply only to disaster cases. Companies can use cloud infrastructure to deploy contingencies for situations where they need more computing power, such as handling peak loads that only happen sporadically. An e-commerce website that has a huge peak of visitors during the Christmas season could run cloud servers to balance out its load only during this time of the year, reducing total cost.\nWhile the risks in this usage scenario are greater, the potential benefits still outweigh them. Most companies can use the cloud to create a much stronger contingency plan than they would be able to relying only on their own infrastructure. There are also several strategies and tools that can be employed to mitigate the associated risks, ranging from data encryption to simply hosting the data separately from the application that is making use of it, on a more secure environment.\n“Big” data processing\nWhile there isn’t a very clear definition of what exactly constitutes “Big Data” and what doesn’t, companies can benefit from employing the cloud to do massive parallel processing of large quantities of data. For organizations that need to crunch massive amounts of data, the cloud brings the possibility to deploy huge numbers of servers for the task. In fact, many cloud providers are already offering servers or services based on the most commonly used tools for Big Data tasks, such as Hadoop.\nEven companies that don’t have petabytes of data to process every day can benefit from using the cloud for their processing needs. By deploying servers on an on-demand basis, they fine tune their processing jobs with respect to cost vs. execution time. Furthermore, relying on outside infrastructure means a much smaller initial investment in hardware (even if total costs may be higher in the long run), as well as no excess capacity. They can pay only for what they use, and nothing else.\nThis is the scenario with the largest risks. Companies looking to move processing loads to the cloud must carefully consider the nature of the processing job they want to run as well as the nature of the data being processed, and the risk of this data being stolen. At the same time, the potential benefits are great. For small companies that can’t afford to build their own infrastructure, the cloud gives the opportunity to do much more than what was possible before.\nAs with any other technology, there are places where the cloud shines and offers great benefits and others where that isn’t quite true. The scenarios compiled here are the top use cases where I’ve seen companies employing cloud computing, especially cloud servers. This list, however, is far from complete. It was built from personal experience, without relying on any kind of poll. If you have any other interesting cloud use cases, please share in the comments or let me know.", "label": 1}
{"text": "A virulent and widespread computer virus was found on Friday, March 26, 1999. This virus has spread all over the globe within just hours of the initial discovery, apparently spreading faster than any other virus before.\nMelissa works with Microsoft Word 97, Microsoft Word 2000 and Microsoft Outlook 97 or 98 e-mail client. You don't need to have Microsoft Outlook to receive the virus in e-mail, but it will not spread itself further without it.\nMelissa will not work under Word 95 and will not spread further under Outlook Express.\nMelissa can infect Windows 95, 98, NT and Macintosh users. If the infected machine does not have Outlook or internet access at all, the virus will continue to spread locally within the user's own documents.\nThe details below refer to the Melissa.A variant.\nThe virus spreads by e-mailing itself automatically from one user to another. When the virus activates it modifies user's documents by inserting comments from the TV series \"The Simpsons\". Even worse, it can send out confidential information from the computer without users' notice.\nThe virus was discovered on Friday, late evening in Europe, early morning in the US. For this reason, the virus spread in the USA during Friday. Many multinational companies reported widespread infections, including Microsoft and Intel. Microsoft closed down their whole e-mail system to prevent any further spreading of the virus. The number of infected computers is estimated to be tens of thousands so far and it is rising quickly.\n\"We've never seen a virus spread so rapidly,\" comments Mikko Hypponen, F-Secure's Manager of Anti-Virus Research. \"We've seen a handful of viruses that distribute themselves automatically over e-mail, but not a single one of them has been as successful as Melissa in the real world.\"\n\"The virus won't spread much during this weekend. We will see the real problem on Monday morning\", continues Hypponen. \"When a big company gets infected, their e-mail servers are seriously slowed down and might even crash, as people start to e-mail large document attachments without realising it.\"\nFor more information on Melissa, see Global Melissa Information Center at http://www.F-Secure.com/melissa/\nMelissa was initially distributed in an internet discussion group called alt.sex. The virus was sent in a file called LIST.DOC, which contained passwords for X-rated websites.\nWhen users downloaded the file and opened it in Microsoft Word, a macro inside the document executed and e-mailed the LIST.DOC file to 50 people listed in the user's e-mail alias file (\"address book\").\nThe e-mail looked like this:\n- From: (name of infected user)\n- Subject: Important Message From (name of infected user)\n- To: (50 names from alias list)\n- Body: Here is that document you asked for ... don't show anyone else ;-)\n- Attachment: LIST.DOC\nDo notice that Melissa can arrive in any document, not necessarily just in this LIST.DOC where it was spread initially.\nMost of the recipients are likely to open a document attachment like this, as it usually comes from someone they know.\nAfter sending itself out, the virus continues to infect other Word documents. Eventually, these files can end up being mailed to other users as well. This can be potentially disastrous, as a user might inadvertently send out confidential data to outsiders.\nThe virus activates if it is executed when the minutes of the hour match the day of the month; for example, 18:27 on the 27th day of a month. At this time the virus will insert the following phrase into the current open document in Word:\n- \"Twenty-two points, plus triple-word-score, plus fifty points for using all my letters. Game's over. I'm outta here\".\nThis text, as well as the alias name of the author of the virus, \"Kwyjibo\", are all references to the popular cartoon TV series called \"The Simpsons\". For more information on this connection, see this Simpsons web page:\nThe main difference between Melissa.I and Melissa.A is that this variant uses a random number to select subject lines and message bodies of outgoing messages from eight different alternatives:\n1. Subject: Question for you...\nIt's fairly complicated so I've attached it.\n2. Subject: Check this!!\nThis is some wicked stuff!\n3. Subject: Cool Web Sites\nCheck out the Attached Document for a list of some of the best\nSites on the Web\n4. Subject: 80mb Free Web Space!\nCheck out the Attached Document for details on how to obtain\nthe free space. It's cool, I've now got heaps of room.\n5. Subject: Cheap Software\nThe attached document contains a list of web sites where you\ncan obtain Cheap Software\n6. Subject: Cheap Hardware\nI've attached a list of web sites where you can obtain Cheap\n7. Subject: Free Music\nHere is a list of places where you can obtain Free Music.\n8. Subject: * Free Downloads\nHere is a list of sites where you can obtain Free Downloads.\nIn the last subject, the asterisk will be replaced with a random character.\nUnlike Melissa.A, this variant uses a different registry key (called \"Empirical\") to check whenever mass mailing has been done.\nMelissa.I contains an additional payload as well. If the number of minutes equals the number of hours, the virus inserts the following text to the active document:\n- All empires fall, you just have to know where to push.\nAt the same time, the virus clears the mark from the registry causing the mass mail part to be reactivated a soon as a document is opened or closed, a new document is created or the Word is restarted.\nThis Melissa variant sends itself to 100 recipients from each Outlook address book. The E-mail looks like this:\n- Subject: Duhalde Presidente\n- Body: Programa de gobierno 1999 - 2004.\nW97M/Melissa.U is a similar to Melissa.A. Unlike Melissa.A, this variant uses the module name \"Mmmmmmm\" and it has a destructive payload. This variant deletes the following system files:\nTo do this, the virus removes hidden, system, read-only and archive attributes from these files. Unlike W97M/Melissa.A, it sends itself only to 4 recipients. The message itself is also different:\n- Subject: pictures (user name)\n- Body: what's up ?\nWhere (user name) is replaced with Word's registered user name.\nThe following texts will be added to every infected document:\n- Loading... No\n- >>>>Please Check Outlook Inbox Mail<<<<<\nThis variant has been detected since October 13th, 1999.\nThis variant is similar to Melissa.U. This variant sends itself to 40 recipients and the message is different:\n- Subject: My pictures (user name)\nThe message body is empty, and (user name) is replaced with Word's registered user name. After Melissa.V has mailed itself, it will delete all files from the root of the following drives:\nWhen this has been done, the virus shows a message box with the following text:\n- Hint: Get Norton 2000 not McAfee 4.02\nThis variant has been detected since October 13th, 1999.\nMelissa.W does not lower macro security settings in Word 2000. Otherwise it is functionally equal with Melissa.A.\nMelissa.AO uses Outlook to send e-mail message with:\n- Subject: Extremely URGENT: To All E-Mail User -\n- Body: This announcement is for all E-MAIL user. Please take\nnote that our E-Mail Server will down and we\nrecommended you to read the document which attached\nwith this E-Mail.\nThe payload activates at 10 am on 10th day of each month when the virus inserts the following text to the active document:", "label": 1}
{"text": "The mobility trend holds great promise for improved productivity and new engagement models. These are most powerful in a learning effort—imagine learning anywhere and anytime. I just wish I had the Internet and the mobility that students have today when I went to school. Yet, mobility is an IT tsunami that will not recede. One of the most damaging aspects of this storm is the possibility of numerous personal devices that are entering organizations, accessing the network and eventually critical assets, and stealing sensitive data or mistakenly bringing malware. Many people know this policy as BYOD or bring your own device. This is not a new phrase but it is still quite prevalent. Inventory and provisioning of personal mobile devices is just the tip of this wave. Organizations want to control mobile devices to ensure acceptable usage and minimize security incidents.\nEducational institutions (the training grounds for our next workforce) are seeing this each day. Mobile devices create a great opportunity to expand the learning environment. Students can access lessons and information anytime and anywhere. Imagine the power of accessing a tutorial session on your tablet with the satisfaction of completing a tough assignment. Or a professor accessing recent research and sharing it with an international colleague in the early morning over collaborative video exchange. The power of mobility and the Internet of Everything offer a whole new learning platform for all.\nHow does a school provide a student access from their personal mobile device to learning services while ensuring the student does not have access to sensitive data—like grades for other students—or that the student does not visit a malware-infected website? Hear from some schools—a public school in Texas and a private higher education institution—on how they control mobile devices. You can also learn how educational organizations are managing the challenge of BYOD in the BYOD Security Challenges in Education: Protect the Network, Information, and Students whitepaper. Does your school have a BYOD policy? If so what is it?", "label": 1}
{"text": "Home - Knowledge\nCenter - Healthcare Technologies\n- Emerging Technologies\nHealthcare computer systems process a lot of data and there\nhas been rising concerns in an industry already committed to protecting patient\ninformation. The Health Information Portability and Accountability Act in the\nUnited States and the Data Protection Act in the United Kingdom, backed by the\nEuropean Directive on Data Protection, are some of the laws that have been\npassed to patients’ privacy and confidentiality are protected whenever their\ndetails are processed by healthcare computer systems.\nThe onus is now on healthcare organisations to secure data on\ntheir systems as stated out in these laws. Failure to comply will result in\nfines being brought against the offending organisations and in some cases\nSecurity technologies are available to assist prevent\nunauthorised access of patient information. Three areas that these technologies\nhave been addressing are\n- Data Theft –This includes unauthorised copy of data\nand equipment theft, especially common with mobile computing devices.\n- Unauthorised access of patient data – This can\noccur at remote access points, where the intruder accesses data at a computer\nthat has been left unattended. It could also occur when intruders hack\nexternally into the a network and either access the data at the central server\nor ‘listen’ for data as it is being passed round the network.\n- Unintentional access of patient data – This occurs\nin situations where members of a healthcare organisation are not authorised to\nview some or all of a patient’s information but still have access to it. This\ncan lead to events when such information is accidentally viewed.\nAll users logging into the information system need to be\ncorrectly and successfully identified. Typing in a password and an ID, both of\nwhich would be verified against one another, usually does this.\nIn large organisations with multiple systems, a single user\nmay have a variety of passwords with multiple IDs, to access data on disparate\nsystems. Having to remember all the passwords can be a burden and sometimes a\nsecurity risk, as users might tend to write down their passwords, which can be\nfound and used to illegally gain access to a system. Sometimes to make things\neasier for themselves, users might choose a password so trivial that intruders\ncan easily guess it.\nThe use of single-sign technology can eliminate that problem.\nSingle-sign technology, when installed across the various systems allows a user\nto have a single ID and password that can be used to log on to them. This\nsimplifies the setting up and managing of passwords and IDs for multiple users\nand address the security risk that are associated with multiple passwords.\nWhile the use of passwords is probably the most common and\neasiest way of identifying users, biometrics is another. Biometrics technology\nallows users to use distinct physical attributes about themselves such\nfingerprints or their iris to be scanned in order to identify themselves.\nAnother identification technology would be that of the smart\ncards. These are credit card sized plastic cards with embed microprocessor or\nmemory chips and when used with a reader provider an adequate method of\nThe use of firewalls provides the first line of defence in the\ndefence of illegal access to a network. Firewalls, which can either be software\nor hardware, sit between a system’s network and the outside world. It monitors\nand when necessary blocks traffic when triggered by a set of rules.\nUnauthorised access by employees of an organisation is also a\nworry. The user’s profession usually determines access to information and the\ntype of information the user is allowed to view. While medical data and\nsometimes therapeutic data of individual patients should be made available to\ncertain healthcare professional (such as their designated physician), it should\nbe made readily available to all. There are now systems that are available that\ncan determine the level of access whenever a user logs on the system.\nThis involves the encoding of data such that only personnel\nwith the proper authorisation can decode and view it. The most common method of\nencryption is the use of the Public Key infrastructure along with digital\ncertificates. This involves the use a secret key to encrypt information, which\ncan then be stored or transmitted. The encrypted data is digitally certified to\nauthenticate its validity and can only be decrypted through the use of a\nThe ease at which intruders can decrypt the data by other\nmeans depend son the strength of the encryption. The greater the strength, the\nharder it is to decrypt. 40 bits encryptions are generally considered weak and\nare easily decoded. Most security experts recommend encryption strengths of 128\nbits or more.\nThis has been a bone of contention for many US organisations\nas the US government has placed a restriction on systems that use encryption\nstrengths of more than 64 bits. Luckily the healthcare sector has been exempt\nfrom that rule and would definitely benefit from using systems that offer\nencryptions of 128 bits or more.\nWhile software and hardware might aid organisations in\nsecuring patient data, social and organisational factors might also need to\naddressed as well. Installing of hardware in secure places, not writing down or\nchoosing trivial passwords as well as periodically changing them, turning on\npassword protected screen savers when leaving a computer unattended are just\nsome of the things that could a long way in securing data.", "label": 1}
{"text": "If you have a wireless network at your home or business, it’s important to secure it against opportunistic hackers seeking to steal your data or hijack your Wi-Fi for their own wicked purposes. This blog will help you learn about the best ways to lock down your Wi-Fi.\nTo get started, you’ll need to log in to your router’s administrative console by typing the router’s IP address into your Web browser’s address bar. Most routers use a common address like 192.168.1.1, though alternatives like 192.168.0.1 and 192.168.2.1 are also common. Check the manual that came with your router to determine the correct IP address; if you’ve lost your manual, you can usually find the appropriate IP address on the manufacturer’s website. Read More\nAccessing your router’s setup page is important if you ever need to make changes to your wireless network. Your router is the box that makes your internet wireless. The setup page gives you access to many different settings for your network. This is especially useful if you need to change your network’s name or password. If you go to connect to your wireless network and you can’t remember the password you can find this information as well on the router’s setup page.\nSupportChoice.com offers you expert technical support on creating and securing a wireless (Wi-Fi) home network. We can also add your printer/scanner and other devices to your wireless home network. Here is the basic equipment you need to create a secure Wi-Fi network.\nNeeded to Set Up Home Network:\n1. An active network connection. For most home and small businesses the network is usually a DSL or cable based network. The internet connection is usually via a wired DSL or cable modem into the home.\n2. A wireless router. The wireless router takes the signal from the modem and provides internet access via a wireless network. You can use the Wi-Fi network as is from the router however it may not be secure. To prevent others from either hacking your home network or using your wireless home network it is best if you secure and encrypt your Wi-Fi network. The wireless home network can be secured via web access into the router.", "label": 1}
{"text": "(De Montford University, Leichester, UK) Patients recovering from surgery get infections far more often than is being reported, a new study led by De Montfort University has found. Infection prevention specialists are now calling on the Department of Health to bring in a clear and standardized system for hospitals to try to identify the true scale of surgical infections. They say a study of the way in which NHS hospital trusts in England has shown \"worrying inconsistencies\" between hospitals in how they defined surgical site infections and how rigorously they looked for them. As a result, published infection rates for hospitals do not always give a true picture.\nThe reasons hospitals gave for not submitting data was that the surveillance system was flawed and unwieldy and they didn't trust the system. Their paper, published today in the Journal of Hospital Infection, casts further doubt on the reliability of the national surgical site infection surveillance scheme in England. Lead researcher Professor Judith Tanner of De Montfort University said \"The national SSI surveillance system in England consistently under-reports the true scale of surgical infection and gives a false sense of security. This study shows there are so many inconsistencies that it's not possible to benchmark hospitals against the English national surgical site infection data\".\nSpecialists at De Montfort University, Leicester; Southport and Newcastle-upon-Tyne universities sent out a questionnaire to all 156 NHS hospital trusts in England asking how they collected and reported data on post-operative wound infection for the national surgical site infection surveillance scheme. Replies were received from 106 (68%). The results showed worrying inconsistencies between hospitals. For example, trusts which actively extended their surveillance to patients who had had knee replacement, after they had been discharged from hospital, reported an infection rate of 4.1 percent; hospitals that did not look so hard reported a lower rate, 1.5 percent.\nThe authors suggested that in order to identify the true scale of surgical infections, hospitals should contact every single patient, by letter or phone within 30 days after surgery. Professor Tanner said: \"The harder you look, the more that you find. Common sense tells you this and now we have demonstrated that with this study. Perversely, hospitals that conduct robust and high quality surveillance are penalized under the current system\".\nSurgical infection rates reported by the scheme were often noticeably lower than rates reported from published research studies. In 2009, after reviewing the scheme, the Public Accounts Committee concluded that the Department of Health did not have an understanding of the true scale of SSIs in England because of a lack of decent data. Examples include:\n- 10 percent of hospitals did not provide data on superficial infection.\n- Five percent did not use the HPA's standardised definition of wound infection.\n- There were significant differences in how hard Trusts looked for infection.\n- Only 9/106 hospitals looked for early infections developing before patients left the hospital.\n- 24/106 hospitals only included patients while they were in hospital, and if they happened to be re-admitted with a wound infection.\n- 73/106 hospitals used in-patient, re-admission follow up, and actively looked for infections by directly contacting patients after they had been discharged from the hospital.", "label": 1}
{"text": "FAQ - Spam\nWhat is a E-mail Spam?\nSpam is a flooding of e-mail on the internet and your mailbox. Often spam is the same message at a given time. It is an attempt to coerce individuals into acting in a manner they would not otherwise do. Spam is attempting to get your sensitive information by threatening users that they with losing their privileges if they do not respond immediately.\nWhere does Spam come from?\nE-mail spam lists are often created by scanning Usenet postings, stealing Internet mailing lists, or search the Web for addresses.\nWhat is some of the common spam:\na. Phishing scams\n1. Seen on campus almost everyday\n2. Requests user to enter Ball State username and password\n3. Dangerous form of e-mail fraud\nb. Get rich quick scams\nc. Online jobs\nd. Bank scams\ne. Healthcare scams\nf. Chain letters\ng. Solicitation of Illegal software\ne. Computer virus detected\nWhat should I do when receiving spam?", "label": 1}
{"text": "ALTER ASYMMETRIC KEY (Transact-SQL)\nChanges the properties of an asymmetric key.\nALTER ASYMMETRIC KEY Asym_Key_Name <alter_option> <alter_option> ::= <password_change_option> | REMOVE PRIVATE KEY <password_change_option> ::= WITH PRIVATE KEY ( <password_option> [ , <password_option> ] ) <password_option> ::= ENCRYPTION BY PASSWORD = 'strongPassword' | DECRYPTION BY PASSWORD = 'oldPassword'\nIf there is no database master key the ENCRYPTION BY PASSWORD option is required, and the operation will fail if no password is supplied. For information about how to create a database master key, see CREATE MASTER KEY (Transact-SQL).\nYou can use ALTER ASYMMETRIC KEY to change the protection of the private key by specifying PRIVATE KEY options as shown in the following table.\nChange protection from\nENCRYPTION BY PASSWORD\nDECRYPTION BY PASSWORD\nOld password to new password\nPassword to master key\nMaster key to password\nThe database master key must be opened before it can be used to protect a private key. For more information, see OPEN MASTER KEY (Transact-SQL).\nTo change the ownership of an asymmetric key, use ALTER AUTHORIZATION.\nA. Changing the password of the private key\nThe following example changes the password used to protect the private key of asymmetric key PacificSales09. The new password will be <enterStrongPasswordHere>.\nALTER ASYMMETRIC KEY PacificSales09 WITH PRIVATE KEY ( DECRYPTION BY PASSWORD = '<oldPassword>', ENCRYPTION BY PASSWORD = '<enterStrongPasswordHere>'); GO\nB. Removing the private key from an asymmetric key\nThe following example removes the private key from PacificSales19, leaving only the public key.\nALTER ASYMMETRIC KEY PacificSales19 REMOVE PRIVATE KEY; GO\nC. Removing password protection from a private key\nThe following example removes the password protection from a private key and protects it with the database master key.\nOPEN MASTER KEY; ALTER ASYMMETRIC KEY PacificSales09 WITH PRIVATE KEY ( DECRYPTION BY PASSWORD = '<enterStrongPasswordHere>' ); GO", "label": 1}
{"text": "[from the analogy with biological viruses]\nA cracker program that searches out other programs and 'infects' them by embedding a copy of itself inside, so that they become a Trojan. When these programs are executed, the embedded virus is executed as well, thus propagating the 'infection'. This normally happens invisibly to the user. Unlike a worm, a virus cannot infect other computers without assistance from the cracker.\n[a type of malware] Undetected software that can be installed on computers which collects small pieces of information on users without their knowledge. Typically, spyware is secretly installed on the user's personal computer with similar malicious software such as keyloggers by the owner of a shared, corporate, or public computer on purpose in order to secretly monitor other users.\n[coined by MIT-hacker-turned-NSA-spook Dan Edwards]\nA malicious, security breaking program that is disguised as something benign, such as a directory lister, archiver, game, picture, or even a program to find and destroy viruses.\n[short for malicious software] Programming (code, scripts, active content, and other software) designed to disrupt or deny operation, gather information leading to loss of privacy or exploitation, gain unauthorized access to system resources and other abusive behavior.\nA program that propagates itself, reproducing as it goes until it fills all of the storage space on the selected drive or network.", "label": 1}
{"text": "(BPT) - When it comes to your health, the old adage, “an ounce of prevention is worth a pound of cure,” still rings true. It’s doubly valid when you’re talking about the health of your digital and financial identity. Giving your identity a checkup is every bit as important as getting your annual physical and flu shot, or exercising regularly to maintain good health.\nYet many people avoid delving into the health of their financial identity – perhaps for the same reason that some people avoid medical exams. A checkup, while meant to confirm that everything is fine, can potentially turn up a problem – and no one likes bad news.\nBut avoiding or ignoring bad news doesn’t make it go away. Just ask the members of the nearly 9 million households that experienced identity theft in 2010, the most recent year for which the Bureau of Justice Statistics has published numbers.\nWhile you may already know that keeping an eye on your credit is an essential part of identity theft protection, it’s not the only step you need to take. Here are five important things everyone should do in order to give themselves an identity check up:\n1. Google your own name – What do you find? You may be amazed at how many hits the search engine returns, and just where on the Internet your name shows up. Is the information correct? Is any of it too personally revealing – does it include your address or telephone number? Take steps to correct inaccuracies and if your name appears on a particularly disturbing website, try to have it removed.\n2. Review your social networking accounts – In August, Facebook revealed that more than 83 million user accounts are fake or duplicates. It’s almost certain that identity thieves are among those users falsifying information as social networks can be a gold mine of personal information for crooks. To protect your information, use the most restrictive privacy settings provided by the social media sites you frequent. Turn off tools that allow the site to track your browsing history, and never accept a “friend” request from someone you don’t personally know.\n3. Change your passwords – Many of us access accounts online that are password protected – from bank and investment accounts to social media and even health care provider websites. Always use strong passwords that include lowercase and capital letters, numbers and symbols (whenever possible) and change your passwords regularly.\n4. Keep an eye on your credit – Checking your credit report once a year is no longer sufficient. This task is as much about managing your identity as it is about managing your personal credit. You need to keep an eye on your credit accounts regularly. Review every credit card statement every month. Check your credit report several times a year – more if you have reason to believe your identity might have been compromised. Consider enlisting help from ProtectMyID.com, a comprehensive identity theft detection, protection and resolution product.\n5. Review and monitor your health accounts – Health care providers collect a great deal of personal information. Doctors, hospitals, dentists, walk-in clinics – all collect your full name, birth date, home address, insurance information and, often, your Social Security number. You have the right to know what information health care providers have about you, how it is used, how they protect it and who has access to it.\nProtecting your identity requires a lot of smart, small steps. The risk of identity theft will always be there – just like the risk of a health crisis. But just as a healthy diet and lifestyle habits can reduce your health risks, preventive measures can help ensure identity theft doesn’t have to be a foregone conclusion.", "label": 1}
{"text": "How to Fix a Windows Infection Using Linux\nIf you use Linux on your company's desktop or server computers, you're already familiar with many of the security advantages the open source operating system offers over its Windows and Mac rivals. What many people don't realize, however, is that Linux can also be used to rescue a computer that has been crippled by malware.\nMalware is a frequent occurrence in the Windows world, in particular, and it can be devastating. When a Windows virus strikes, not only can it become difficult or even impossible to continue using the affected machine, but it can be dangerous as well, since prolonged use can further the infection.\nThat's where Linux can be a life-saver. Without ever having to install the free alternative, you can still use it temporarily on a PC to get rid of any infection. Here's how.\n1. Get a LiveCD or Live USB\nLiveCDs and USBs are a wonderful thing in the Linux world because they let you boot a machine directly from the CD or USB stick without ever having to access the computer's boot records. Not only are they a great way to take Linux for a test-drive, but they can also be put to work when Windows can't.\nBy far the fastest way to get a LiveCD or USB is to download the .iso file of the Linux distribution you'd like to use and then burn it onto a CD or USB stick. Since Ubuntu is the most popular distribution out there, I'll go with Maverick Meerkat--the latest version of the software--for this example.\nUbuntu can be downloaded from the project's Website for use on a LiveCD or USB; download links for other distributions can be found listed on FrozenTech. UNetbootin is another nice option if you want to go the USB route, which tends to run much faster.\nOf course, to take either of these options you'll have to have a working, Internet-connected computer. If you don't, or if your Internet connection is slow, you may want to order a LiveCD or USB via snail mail. OSDisc and LinuxCD both offer a variety of options; pricing is about $2.\n2. Boot into Linux\nOnce you're equipped with a Linux LiveCD or USB, you'll need to make sure the infected computer is turned off, and then turn it on again with the CD or USB installed. This will boot the computer into Linux, completely bypassing Windows and its infection. Again, nothing has been installed -- you're simply using Linux to get the machine running reliably again.\n3. Get Antivirus Software\nNext it's time to get the Linux-based ammunition you'll need to wipe out the malware: antivirus software. I'm going to use ClamAV, my favorite, via ClamTK, which provides a nice graphical front end.\nFrom the main Ubuntu desktop, then, go to \"Applications\" and then \"Ubuntu Software Center.\" Choose \"Edit\" and then \"Software Sources.\" You'll be presented with a box entitled, \"Downloadable from the Internet,\" and you should be sure all four boxes are checked before you click on \"Close.\"\nNext, from the main Ubuntu Software Center page, click on the \"Accessories\" icon and type ClamTK into the search box. It will be shown as \"Virus Scanner,\" but if you click on \"More Info\" you can verify it's the right package. Click \"Install\" and wait for it to download.\nOnce installation is finished, you should launch ClamTK by going to \"Applications\" in Ubuntu's main menu, then \"Accessories\" and \"Virus Scanner,\" which is how the software will still be shown.\n4. Run a Scan\nWhen the ClamTK window opens, click on the \"Scan\" tab and select the option for a Recursive Scan. Next, you'll need to tell the software which drive you want to check for viruses, which in this case is the one that includes Windows. Scanning may take some time, but once the infection is found you'll get the usual options for what to do with it, including quarantine and removal.\n5. Return to Normal\nAssuming the infection has now been removed, your computer should be clean once again, making it safe to remove the LiveCD or USB and boot back into Windows as usual. As you enjoy your malware-free machine once again, remember that it's all thanks to Linux. It's also not a bad idea to keep your LiveCD or USB handy so you'll be ready for the next time.\nFollow Katherine Noyes on Twitter: @Noyesk.", "label": 1}
{"text": "Zombies join the attack\nFor years they've worked in separate corners of the electronic world. Virus writers exploited computers for fun or curiosity or out of sheer malice. Spammers tried to bypass email filters to place unsolicited commercial advertisements in email inboxes.\nNow they're working together.\nInfecting personal computers has evolved into a lucrative industry. The emerging alliance between spammers, virus writers and even organised criminals threatens to make personal computer users unwitting parties to online crime.\nFormerly viruses carried a single hit or \"payload\" programmed to do anything from displaying an ironic or playful message on a user's screen to the more malicious actions of viruses such as the Gigger worm, which wreaked havoc with a hard drive. Once it had achieved its purpose, the virus would replicate and spread, having done its damage.\nNow, however, a new breed of virus is taking a more sophisticated and destructive approach. Viruses now seek to embed themselves on personal computers, creating security holes on individual PCs and allowing them to be controlled by hackers over the internet.\n\"What we're seeing now is a change in what viruses are aiming to do,\" says John Donovan, the managing director of Symantec Australia. \"A number of years ago programmers of malicious code would attempt to attack a system; now they try to compromise the security of a computer for personal gain.\"\nVirus writers target unprotected home computers, looking to bypass their security systems and take control of computer activity.\n\"The issue is average home users don't have the level of protection they need to secure their computers,\" says Allan Bell of McAfee Asia-Pacific, which makes anti-virus software. \"They don't see their machine as being a target for hackers. But just because they don't have valuable data on their machine doesn't mean that a hacker won't open up their computer.\"\nThe infected PCs or \"zombies\" are hijacked by internet criminals. \"These zombie computers are used by hackers to then do further damage,\" says Bell.\nVirus writers try to connect the PCs they've infected into networks or \"botnets\". Botnets usually consist of infected Windows PCs networked via the internet, ranging in size from 10,000 up to 100,000 PCs.\nOnce the botnet is established, virus makers can then lease access to email spammers. Sales are conducted via instant messaging programs and can fetch between $65 and $130 for an hour of access.\nSpammers will then use these infected computers to send millions of unsolicited messages in just a few hours, preferring to use networks because it makes it harder for recipients to block the emails and it protects the spammer's identity.\nThe unprotected users whose machines are being harnessed often don't notice the activity, with most hackers concealing their intrusions. \"This represents the biggest risk - people being infected but not knowing that they're being infected,\" Donovan says.\nThe chances of the average PC user becoming infected are increasing. Symantec estimates that Australia is fourth in the world in the level of PC virus infection, behind the US, Canada and China. The proliferation of viruses and the sophistication and power of virus code is attributed to an intricate global network of virus writers.\n\"We can see through things like the development of virus programs, from early scares like the  Michelangelo right through to the recent Sasser virus, that the newer versions have multiple additions to the code, making them more sophisticated and harder to detect, which points to a fairly well-developed network of people who are developing [the viruses],\" Donovan says.\nAuthorities are struggling to keep track of the fast-growing criminal industry. Virus writers have a diverse physical presence, with hot spots ranging from Russia to Indonesia and even the US. The only step that can be taken against the mounting threat is an awareness of the risk. \"The challenge is not a lack of anti-virus technology; it is understanding how to use that technology,\" Donovan says.", "label": 1}
{"text": "Back It Up\nProtect yourself against data loss by making electronic copies of important files, commonly referred to as a backup.\nOur computers contain vast amounts of data, from family photos and music collections to financial records and personal contacts. In fact, a recent National Cyber Security Alliance/Symantec study found that more than 68% of Americans store more the 25% of their photos digitally. For most people, the loss of that information could be devastating.\nData can be lost in several ways: computer malfunctions, theft, viruses, spyware, accidental deletion, and natural disasters.\nData backup is a simple, three step process:\nMake Copies of Your DataMany computers come with a backup software program installed, so check to see if you have one. Most backup software programs will allow you to make copies of every file and program on your computer, or just the files you’ve changed since your last backup.\nHere are links to backup utilities in popular operating systems:\nSelect Hardware to Store Your DataWhen you conduct a backup, the files will have to be stored on a physical device - such as CDs, DVDs, or USB flash drives, an external hard drive, or on the web using cloud-based online storage.\nSafely Store the Backup Device that Holds Your DataAfter setting up the software and copying your files on a regular basis, make sure you keep your backup device somewhere safe. Some ideas include a trusted neighbor’s house, your workplace, a safe, or a secure place at home that would likely survive a natural disaster. Keep your backup device close enough so that you can retrieve it easily when you do your regular backup.\nOther software programs are available for purchase if your system does not have a backup program or if you’re seeking other features. Ideally, you should backup your files at least once a week.", "label": 1}
{"text": "You know how it works. Your end users visit an infected site and inadvertently download the latest type of malware. If your antivirus software is up to snuff, it will prevent the download or, at the very least, locate and isolate the invading file on the user's hard drive. But what if there is no file on the hard drive to detect? What if instead the malware resides only in memory, running under a trusted process that you, the antivirus software and the operating system itself assume cannot be breached?\nThat's exactly what happened in Russia earlier this year, when more than 300,000 computers were infected with a unique type of malware -- the fileless bot. After the bot ran unencumbered for several months, Kaspersky Lab announced that it had discovered a rare type of infection being propagated through Russian online information resources. Advertisements supplied to the sites by AdFox, a third-party ad network, contained Java malware that directed browsers to a download server run by cybercriminals.\nHow the fileless bot works\nStep 1: Users visit the infected site. They don't need to take any other action. Without their knowledge, users are redirected to the cybercriminals' server, which we'll call the \"master server.\"\nStep 2: The master server injects an encrypted dynamic link library (DLL) file into the Java process (javaw.exe) on users' computers. The Java process runs in the machine's memory. The DLL takes advantage of a well-known vulnerability in Java (more on that in a bit).\nStep 3: The malware establishes communication between the user's computer and the master server. Included in the information sent to the master server are technical details about the infected machine. In this sense, the malware runs just like any other bot -- as a software robot that can execute automated tasks over the Internet. However, the AdFox bot is fileless and runs completely in memory.\nStep 4: The malware disables User Account Control (UAC), a Windows security component that's supposed to defend users' systems from hackers. The malicious software then seizes the permissions necessary to install a more robust type of malware. In the case of the Russian computers, that downloaded malware was the Lurk Trojan horse, an application whose main function is to steal sensitive data to gain access to online banking services.\nStep 5: The Lurk Trojan raids the cookie jar.\nAs noted above, the fileless malware exploits a known Java vulnerability (CVE-2011-3544). In Russia, cybercriminals exploited this vulnerability to attack Windows computers. However, Mac OS also supports Java, so Apple computers are potentially just as vulnerable. Fortunately, Oracle issued a patch in October 2011, so only computers that were not updated are susceptible.\nMore on malware and desktop security\nWindows 8 may be more secure, but don't ignore desktop vunerabilities\nProtecting endpoints with data loss prevention software\nSecurity expert praises Windows 8 memory defenses\nHow to thwart password attacks with user account security\nHowever, for those computers without the patch, the cybercriminals could easily load their bot into the trusted Java process. And the antivirus software, for the most part, had no idea it was there. In fact, the bot was essentially invisible.\nA world of fileless malware trouble\nAlthough attacks that took Russia by storm are relatively rare, similar ones have occurred in the past decade, most notably the Code Red and Slammer worms. Both of these worms took advantage of a vulnerability known as a buffer overflow, which also allows for a type of fileless attack similar to what we saw in Russia.\nGiven that these types of attacks have now occurred several times, there's no reason to assume that they won't happen again. And not necessarily just in Russia or against only Windows computers. And not necessarily limited to the Lurk Trojan. Other countries and operating systems are just as vulnerable, and other malware can spread just as easily.\nThe good news is that, because the fileless bot lives in memory, a simple system restart will get rid of the problem (if it's not already too late). As long as your users don't visit the same or other infected sites, they should have no further problems. And, of course, you should also ensure that the Java apps on their computers are up to date and that they have the latest security patches. This will at least protect them from the bot that hit Russia.\nBut as with any type of malware, the rules keep changing, and just because you can protect users from the latest fileless attack is no reason to assume that everyone is safe. What happened in Russia might not stay in Russia.\nIn addition, Apple recently announced that when it releases the next Mac OS update, Java will no longer be included with its browsers. Whether this has anything to do with the fileless bot is difficult to say. But Adam Gowdiak, a researcher at Polish firm Security Explorations, has reportedly identified two new security bugs in Java, so Apple is apparently playing it safe.\nThis was first published in December 2012", "label": 1}
{"text": "In general, you can't trust anything on an unsecured connection on any network where a MITM could be present (ie, you don't have complete physical control and security of the routing and wiring). A Man in the Middle could monitor and alter any unsecured connection by pretending to be you to the host and pretending to be the host to you. Neither system would be aware of the presence. The file could be entirely replaced or executable could be altered or replaced to do malicious things quite easily.\nThere are, however, a number of ways to prevent this. Authenticated connections such as HTTPS guarantee that only two end points (at least one of which is trusted) can communicate. In brief, HTTPS works by the server having a special piece of information that the browser can validate is the server you think it is. That information can then be used to send a key generated by your client to the trusted server in a way that only the server can understand. Because the MitM doesn't know the newly shared key, the server can then respond using that key to encrypt the connection and the MitM can no longer observe or alter the meaningful contents of that communication and any alterations would cause it to appear as gibberish (or possibly be detected based on the protocol in use).\nAnother technique is called checksums. A checksum is a small piece of information that can be independently provided to validate a much larger file. It generally consists of a hash of the file that is being sent which can then be rehashed after receipt in order to ensure the file didn't have any errors in transmission. If the checksum and the file are obtained from different connections, it is a little more difficult for the MitM to alter both, however it could still be possible for both to be altered. The checksum could also be cryptographically signed by the file distributor to ensure the checksum can not be altered by the MitM.\nThe best method is to combine the two approaches and include a cryptographically signed checksum that validates that the file came from the sender while also communicating the file over a secure connection. This ensures that the data isn't corrupted during transmission and also ensures that it comes from the expected host.", "label": 1}
{"text": "By Kyle Garrett – AviationSchoolsOnline.com\nThe Federal Aviation Administration has approved the use of the first Predator UAV (unmanned aerial vehicle) to patrol the U.S./Mexico border between Sierra Vista, AZ and Fort Huachuca, Texas, starting as soon as June 1, 2010. The U.S. Department of Homeland Security initially requested the use of UAVs and plans to bring another Predator online soon to patrol the remainder of the Texas border.\nAccording to a May 15, 2010 article on the El Paso Times web site, the Predator UAV will “look for potential underground tunnels and the travel patterns of drug-trafficking organizations.” The article goes on to say that the Department of Homeland Security has been testing drones for border surveillance since June, 2004.\nAs UAV technology improves and the uses for UAVs expand, more and more UAV pilots and sensor operators will be needed. Expect to see more schools offering UAV training in the future.", "label": 1}
{"text": "The Google Chrome Operating System (Chrome OS) was announced by Google nine months after it released the Chrome browser. Google Chrome OS is described as a lightweight operating system that will make its debut targeting netbook and mobile devices.\nThe OS, which is the Google Chrome Web browser running within a new windowing system on top of a Linux kernel, is expected to be able to run on x86 as well as ARM chips. Google is expected to open source the code in 2009, and netbooks running the Google Chrome OS will be available for consumers in the second half of 2010.\nThe Google Chrome OS will soon have competition from Firefox OS, a similar lightweight, open source operating system built on the Linux kernel. The Mozilla operating system project started out under the Boot to Gecko name, and devices powered by the Firefox OS are expected to start appearing in early 2013.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "Introduction to Cross Site Request Forgery (CSRF)\nWhat is Cross Site Request Forgery - CSRF\nWhen you take an action online - submitting a blog post, delete a photo, registering on a site, transferring money in a bank account - you are making a request to a site to perform that action for you. Several things happen automatically when you make a request to a site: lots of data is sent using either a \"POST\" or \"GET\" method of the HTTP protocol and your browser sends along any cookies you have for the site. The cookies contain your session identification for the site which is how the site knows who you are and what permissions you have.\nA CSRF occurs when a malicious user can trick you into making a specific kind of request to a site that you did not really intend to make AND when the site performs that action without confirming your intent. A simple example follows:\n- Your site has a list of accounts and presents links to delete accounts. That link points to a URL like http://example.com/admin/delete/user/2 which contains the account identifier for the account to be deleted (2 in this example)\n- A malicous attacker determines that you are an admin on the site and becomes your \"friend\" on a social networking site like twitter. They post a message to twitter @your_attention with a TinyURL that redirects to http://example.com/admin/delete/user/2\n- By the time you realize where the redirect is going, you've already deleted account #2. Depending on the system that may also delete all of the content associated with account #2.\nThe solution to this problem is a secret value associated with the action that is not easy to calculate called a token. When the form or link to take an action like deleting the account is sent to the browser the site sends along a string that includes something unique and only known by the site and the user. When the request is submitted the site validates that the token is still present and is appropriate for the action being taken. If it doesn't validate, the action is denied.\nVideo of CSRF in action\nThis video gives an example of CSRF. The problem is not in Drupal, but is in Tumblr. Tumblr does not confirm the intent of users using a CSRF token when a user deletes a submitted question.\nIn other operations on the site, Tumblr uses a session specific token that is the same during an entire session. This token is sent as a POST parameter and confirmed on the server side prior to accepting the operation.\nProtect Against Cross Site Request Forgeries in Drupal\nThe next step, of course, is to Protect your Drupal module against CSRF", "label": 1}
{"text": "Sandia tool puts disaster models into one picture\nThis season’s steady stream of natural disasters has underscored how important it is for first responders to plan and train for — and respond to — a variety of scenarios. But coordinating and sharing data can difficult because of the incompatibility of many modeling and simulation systems.\nNew software from an Energy Department lab could help solve the problem, allowing these different models to work together for the first time to create more realistic and precise models of disasters. And better models could improve coordination and response.\nThe Standard Unified Modeling, Mapping and Integration Toolkit (SUMMIT) was developed by the Sandia National Laboratories with funding from the Homeland Security Department's Science and Technology Directorate and the Federal Emergency Management Agency’s National Exercise and Simulation Center.\nThe origins of the software came from the need to coordinate the multiple disaster planning, simulation and management programs that federal agencies had developed over the years, said Karim Mahrous, Sandia’s SUMMIT project lead. It became evident that there was a large gap in how disaster response exercises are currently planned and managed, he said.\nMultiagency exercises rely on scenario planning, which traditionally involves numerous experts meeting to discuss and plot out issues. Although this produces good results for a single event, Mahrous noted that the data is not reusable since the scenario and information used in one regional exercise cannot be moved to another.\nSUMMIT is designed to remedy this problem by quickly porting disaster data and information from one exercise into another.\nFor example, Mahrous said that the University of Arkansas created a model of a chemical plume from a derailed freight train for a local exercise. The model and data for the plume were then pulled and reused for another exercise in another state via SUMMIT, he said.\nFederal agencies such as FEMA and DHS have spent years designing models and simulations for disaster planning, but these various systems cannot work together or share information. SUMMIT is designed to knit together these different models to allow planners to quickly swap data and to set up new scenarios with existing information within minutes or even seconds.\n“SUMMIT’s entire role is to leverage that federal investment across the board,” Mahrous said.\nThe software for SUMMIT is platform-independent. It can run on desktop and laptop computers or on handheld devices such as smart phones, Andriod devices and iPads. In a recent earthquake response exercise, the organization managing the event wanted to create a tool that allowed organizations to modify the scenario to meet their objectives. The event planners then wanted to be able to move this planning data to first responders on the ground, which allowed them to see buildings damaged by the simulated earthquake. SUMMIT allowed this tool to be moved seamlessly to handheld devices. The porting to the iPad was just a convenience move for us, Mahrous explained.\nBefore SUMMIT, disaster response teams had to rely on written descriptions or other information to tell them about the extent of damage depicted in a scenario. This often led personnel on the ground to sometimes make up information because they had no immediate tools to model or assess a situation besides some maps and charts. For the first time they were able to see the post-disaster world that they were role-playing, Mahrous said.\nStitching together different models allows exercises to become more fine-grained and flexible. During FEMAs recent National Level Exercise 2011 (NLE-11), SUMMIT allowed organizers to model casualties created by different disaster types and their impact on hospital resources.\nHowever, another important potential application for SUMMIT is to allow these capabilities to be used to support first responders in a real event. Based on data from NLE-11, in a real situation such as a building collapse, FEMA could use the modeling tools connected by SUMMIT to quickly estimate casualties and contact local hospitals to alert them about incoming patients in real time, Mahrous said.\nBesides modeling disasters, FEMA's next initiative is to take a whole-community approach to better prepare citizens to respond to emergencies. Although Sandia is in the early stages of working out the approach with FEMA, Mahrous said that the goal is to create a publicly accessible website that would allow entire communities to crowdsource data during a disaster. SUMMIT would be vital in helping to structure and map the data posted on such a site.", "label": 1}
{"text": "Learn how to make a safe and secure password in including three parts!\nA strong, secure password is the most important thing that someone who surf the Internet and has accounts that hold important information can have. You want to make sure that your password is very unique and that it is something that no one would think about. Everyday there are many people who are victims of theft on the Internet. People will continuously try to guess the password to your bank account on-line. Eventually one of them may get in, that should only happen though if you have a poor password. So here are some tips that will help you create the absolute best password!\nPasswords should consist of at least 3 different parts. A word, symbol, and numbers.\nImage via Wikipedia\nPart One – Word(s)\nA word in your password will help you better remember the password itself. You are going to want to pick a word that doesn’t relate to you. Do not let it be your name, nick-name, favorites, hobbies, and other stuff like that. Pick something completely opposite you or even better, pick a random word out of the dictionary. Just make sure it is at-least 4 or 5 characters long, it can be longer but 4-5 is the smallest it should be. Once you find the right word, learn how to spell it backwards. This will just add a little more difficulty and complexity in your password.\nPart Two – Symbol(s)\nOnce you have selected an appropriate word your password you are going to want to add one or more symbols after it. You can choose any symbol from the top of your keyboard. If you choose to use the number symbol, “#”, make sure you use at least one more after or before that. I say this because if you are going to add numbers for the final part of your password, adding a number symbol may not be very effective.\nPart Three – Numbers\nAs you can see I said numberS. You have to make sure you have at least four numbers. Numbers are a key part of the password because there can be an unlimited amount of them. You are going to want to choose some numbers that also have no relation to you. Don not let it be your age, birth year, or any other date of any other family member. Try your best to just make it a few random numbers. If you want you can just close your eyes and clatter away at the number pad and see what you come out with!\nSo if you follow these three simple steps you should be able to make a very secure password that you can use to protect your most important accounts! Below is an example of a password I made to give you an idea. (It’s not one I use) As you can see I spelled the word “tree” backwards and I added a dollar symbol followed by a number symbol. Then I added 6 numeric characters.\nGood luck with your password!", "label": 1}
{"text": "Cloud Control | Feature\nVirtualization and the Cloud: NOT the Same Thing\nThe terms cloud computing and virtualization are often--and mistakenly--used interchangeably. They are not the same. Indeed, comparing the cloud and virtualization is a bit like comparing an iPod to its earbud. While the earbud is a key component of the iPod, it is just one part of a bigger whole. The same goes for virtualization and the cloud.\nAnd just as an earbud can be used elsewhere, virtualization can happen without the cloud. Indeed, as many institutions can attest, virtualization often plays a vital role in university data centers, computer labs, and more--with no cloud in sight.\nSo what is virtualization exactly? Virtualization comes in many flavors: storage, desktop, memory, operating systems, servers. Put as simply as possible, virtualization allows you to do more with less. Most computers aren't used to their full capacity. Indeed, the average enterprise server runs at 5 to 10 percent of its capacity. Virtualization offers a way to consolidate the number of servers you operate by using just one machine to handle applications that had previously been handled by several physical servers.\nThis neat technological trick is performed with virtualization software, which was initially pioneered by IBM back in the 1960s. Today, it's one of the hottest IT fields on the planet, with players such as VMware, Citrix, Dell, Microsoft, and Oracle all duking it out for market share. Essentially, the software partitions a server into multiple virtual computers, each isolated from one another and with the capability to operate just like an actual server.\nIn a way, virtualization software acts like a mirrored fun house, tricking the system into believing there are more servers than there really are. But the benefits are very real. Virtual servers use less hardware, space, and power--and require less cooling--all of which reduces infrastructure and administrative costs. And when the need for more server space arises, users can carve a virtual server out of the existing hardware, rather than going out and buying another machine. What may have taken weeks to implement before can now be done in mere minutes.\nThe same principle underlies storage, desktop, memory, and operating system virtualization: The system fools the computer into handling multiple users' needs on one piece of hardware--a useful feature for universities that need to manage multiple machines from one location or provide identical services to multiple users.\nIt's safe to say that virtualization is already in place on the servers used by most public cloud providers, although the end user would never notice or see it. When it comes right down to it, the decision to virtualize an institution's servers or go to the cloud is not really a technological choice--it's a business decision.\nJennifer Skelly is a freelance journalist and screenwriter based in Los Angeles, CA.", "label": 1}
{"text": "Antivirus firms are concerned about the emergence of techniques that could render meaningless the use of checksums to mark applications as safe. The issue concerns hash functions - one way mathematical functions that produce a small fixed length checksum or message digest from a much longer batch of code or email message. When …\njust whitelist based on 2 (or more) different hashes - it is probably not feasible to add bits correctly in order to generate 2 files that collide in 2 different hash spaces at the same time.\nIANAC by the way\n(I am not a cryptographer)\nisnt the filesize a useful check in addition to the checksum? I'd be inclined to check both\nMost popular P2P apps use MD5 to hash the files for downloading.\nIf you're a nefarious spammer script kiddie than you could potentially inject legitimate files on index sites with nefarious code or if you're a low life soul selling scum bucket working for a large media organisation you could corrupt illegal shares of you lord and masters copyrighted products.\nCould cause a number of headaches that could.\nOr Arbitrarily Slice\nFind the length of the file and then divide it into two sections. Calculate the hash of each half. That should work with just the one hash function.\nChess may give hints\nChess programs use hash functions to check for collisions in a search tree - significantly increasing search depth. But false matches can lead to bad moves. In fact this is likely because the opposing side will tend to follow moves which are mis-judged, so avoiding collisions is important.\nOne way this is done is to use multiple \"independent\" hash functions. You only have to check the second if the first gives a match, so it isn't significantly slower than using a single hash function.\nAs the first poster suggests, this works.\nSurely this is a touch overblown\nI mean, for this kind of attack to be successful a malware author would need access to the source code of a safe application (to do the required additions to it) as well as this evil application.\nIf the bad guys have the ability to add code to your trusted apps then you're screwed anyway.\nEVERY hash function produces collisions\n\"SHA-1 is also known to produce collisions . . .\"\nSince the output of the hash function is a fixed number of bits, whilst the possible file inputs are nearly infinite, every hash function will produce collisions.\nThe weaknesses stem from tricks to FIND collisions. If I compute the hash for word.exe, AND I can produce a malware file then add some bytes so that it produces the same hash, I then have a file that can bypass hash-based whitelisting.\nHaving said that, I would agree with those above who suggest using 2 different hash functions on the same file. I'm not a cryptographer either, but I can't see why that wouldn't work.\nIn fact, I think this should be done anyway. Just because we think one method is secure now, there's nothing to say that it won't be circumvented tomorrow, either by ingenuity or increase in raw computing power. If a hash can be quickly calculated, do 3 different hashes anyway.\nIf PK encryption can be done with 1000-bit keys in a \"reasonable\" time now, then do so - never mind that we don't think even 128-bit keys can yet be easily broken. (Those are \"for example\" figures - I don't know how the state of the art is nowadays!). After all, how long will it be before botnets are decrypting confidential information between spam floods?\n128 bits is safe....\n>\"we don't think even 128-bit keys can yet be easily broken\"\nIt's not down to the number of bits. Brute force search of a 128 bit keyspace cannot be done, not now, not ever - the number is simply too big. This isn't a case of having a big enough bot net, it's a case of needing all the energy in a couple of suns to do it - not going to happen. Ever.\nNope... to break a code you need to find a flaw in the algorithm which makes brute force unnecessary. This is what happened to MD5.\nUsing two different checksum methods is probably a good idea.\nMD5 hash AND Cyclic Redundancy Check... is it too obvious???\nUsing multiple hash functions turns out not to improve things as much as one might expect. IIRC the paper showing this is by one Antoine Joux.\nFrom the get-go, Tripwire (you know, the filesystem integrity checker) was set up to use > 1 hash for this reason. IANAC either but would expect the probability of compromising 2 (or more) hashes to be extremely small -- at this point anyway. Ah, good ol' defense in depth...\n@Daniel du Preez\nWith a bit of tlc, you can add non-executing bytes to an executable without needing the source.\nThe idea as I understand it is that the malware author would write BOTH executables and have the clean sent to be whitelisted. Once it is then its hash will still match the malware code and the distribution can begin.\n\"whitelisted by submitting it to a classification server\"\nSorry, did I miss something? Either the \"classification server\" is run by someone *you* trust to show basic competence, or you are letting an untrusted agency run your whitelist and you are a cretin.\nre: Or Arbitrarily Slice\nProblem with dividing the file into 2 - it wouldn't take a lot of effort to make two sections with that match the two original file halves hashes and join them - after all the second half could just be junk just to get right hash (and pretty much all combinations of slicing and dicing I suspect with have same issues).\n> the possible file inputs are nearly infinite\n<chortle> Nearly infinite, hey? Well how big is that, since any quantity is by definition, er, infinitely smaller than infinite...\nDon't they hire real programmers?\nSo Symantec is looking for excuses of why its technology won't work. Don't they have smart people working for them? Maybe they should just close up shop.\nIt is funny how AV companies try to cover their #@$. Hash...hmmm...well I guess if every whitelisting company did it that way. Do any of you know how this whitelisting technolgy became popular? It all began about 7 years ago when a small company came to the Army Research Lab and then to the NSA SPOCK program. Everyone tried to figure out how this company did it...They tried using hash...Now everyone thinks that is how it is done. Why not find the company that started all this? www.seventhknight.com. They don't use hash and they surely are not going to tell you how they do it.\nOne thing I would like to remind everyone. Anything is better than AV technology. If it catches anything....guess what?....you are already infected....what a scam!!!!!!\nAV technolgy is a KNOWN failure.\n\"The idea as I understand it is that the malware author would write BOTH executables and have the clean sent to be whitelisted.\"\nWell, yes, that would work but why would you want to run even \"clean\" software from a dodgy vendor?\nThe point of whitelisting is that you or your IT department figure out the programs you need, find a reputable ISV and obtain the software from that ISV via a trusted path. Then everything else is sandboxed (or blocked). Where's the risk?\nWell your reputable ISV could have been taken over by malware types as you suggest. No new risk there, though. Given complete freedom to author software, I'm sure a competent programmer can insert malicious code that a whitelisting inspection fails to spot.\nAlternatively, the whitelisting might fail to reverse-engineer the entire app and prove that parameters to security-sensitive APIs can never take undesirable values. Actually that's inevitable and demonstrates why a \"whitelisting service\" is such a bad idea. It's likely that they'll just approve anything plausible from reputable ISVs. Rejection might lead to a lawsuit and they wouldn't want that! You, on the other hand, have no such fears, so you might actually be better able to whitelist than a commercial service.\nThe other approach\nWould an alternative not be to find some existing whitelisted app, and add appropiate extra bytes to some malware so that it matches? Wouldn't require access to anything but the malware.\nAC writes: \"Anything is better than AV technology. If it catches anything....guess what?....you are already infected....what a scam\"\nWhat are you smoking? AV tools prevent infection by detecting viruses (usually at time of download or time of reading/writing from/to disk). Typically, you only get infected when your AV software FAILS to detect the virus.\nAny AV software that detects a virus AND lets it infect your system is broken.\nBut what are the chance that you could successfully fake multiple different hashing algorithms at the same time?\nGentoo linux at least, maintains 4 different types of hash for each file it downloads.\n@Ken Hagan: @AC: @Daniel\nI think you're missing the point. It's not that the malware author would get you to run both executables. The author produces both files, and then submits the clean file to the AV companies for them to check and add to their whitelist. Then if you get the bad file on your machine your AV software won't pick it up since it will register it as being the good one.\nHere's a solution:\nSalt your hashes.\nIf each user prepended their own unique salt to an executable before hashing, a single maliciously crafted exe couldn't infect more than one person.\nI identified this sort of issue an while ago. Any simple hash function must produce the same value for countless combinations. Though most of those combinations might have limited/no practical use to an hacker, some intelligence can narrow down to an useful design.\nSo I devised an comprehensive idea (unimplemented) of multiple hash values that nullifies this potential threat. In reality, there maybe no file system supporting this level of comprehensiveness, so separate hash values would have to be maintained, and when an file change happens an comparison made (i.e. time consuming) until OS companies can incorporate such hash systems. Until then, the present hash systems can be incorporate with file change details, and file lengths. As an file change indicates something has happened (though the date might be got around, so OS companies will have to enforce, or at least enforce an flag that an change has happened). File length, because it is easy to make an hack that changes the file size without compromising file functionality, but hard to make one the same size, unless you refer to another file, in which case the files that the file passes execution to need to be pre-defined to easily detect unusual behaviour.\n@ Stephen B Streater\n\"One way this is done is to use multiple \"independent\" hash functions. You only have to check the second if the first gives a match, so it isn't significantly slower than using a single hash function.\"\nInitially this seems like a good idea, unfortunately the idea represents at least two fatally flawed assumptions.\n1) Significant time savings requires the file to not match the first hash result. This indicates the first hash function is sufficient. If the first is compromised then you have to run both to detect a bad match and you do have significantly slower verification. Since you expect files to verify most of the time, you are significantly slowing the verification process most of the time.\n2) Reading the file takes little time compared with calculating the result. Checking the access times for registers, cache, main memory and hard drives should show the flaw. If that is not enough then try this little experiment. Get a copy of md5sum, sha1sum, and whatever other hash functions you want. Create a simple program that reads a file 4KB at a time doing no processing on the data. Run these programs timing how long it takes to process the same really large file, try a DVD ISO or something. You will find it takes nearly the same amount of time to just read the file as it does to calculate the hash results.\nThe correct solution would be to always calculate two or more independent hash function results using a single program that only reads the file once. That way reading the file, the most time consuming part of the verification, only happens once. You get the benefit of multiple independent checks without significant increase in verification time.\nAV Technology....A known Failure\nWhen AV Technology detects a virus, unless detected in an email, you are already infected. It scans. Therefore, you can be infected until the scanner detects the virus. Have you ever noticed how a machine runs slow after being \"cleaned\". Have you ever had a virus that the scanner could not remove. AV technology is not proactive. It is reactive clean up. The damage is done. You could lose productivty, proprietary data, etc. Not to mention that is slows down your machine and constantly has to be updated. Oh, and where did all those updated come from. You guessed it, infected pcs. Now that is a joke.\n@ - AV Technology....A known Failure\nAV software is Reactive, you are right. As you can't predict an infection that's not been downloaded.\nJust like a Doctor can't treat an illness that you have never caught. Innoculations, sure. An innoculation works like a simple AV App's updates. Alert the system ( Your immune system / Anti-Virus application ) to a variation in the norm that's malicious, Antibodies ( Active/passive scanning of downloaded files ) are alerted in the system. Then the system ( Anti-Virus application / Immune System ) Jumps all over it once it penetrates the system and is detected ( Downloaded application / Caught an illness ). Only PC's are better since they scan EVERYTHING that comes in, a human's immune system is more of a dragnet.\nBut by the fact that you are downloading the file, the point of failure is the Luser, not the AV Application.\nIf you can create an Anti-Virus application that's Pro-active in it's workings, ( Heuristics? - HAHAHAHA *Thud* AAAHAHAHAHAHA! ) and comes up with less than say.. 2% ( Even this level is unaccepable in a medium sized organisation ) False-Posivive, and 0% False-Negative ( If you can't get this, then it's not Pro-Active, and things are defeating your hallowed app ) then by all means. Go for it.\nOtherwise, I'd suggest hitting the books and maybe Re-Education of yourself on a few matters.\nThe Damn Hash calc would use several hashing algorithms (plus variations) in a single file read.\nOf course you had to truse the author of the package in the first place\nIt's fairly easy in modern executables to hack a file without changing the file length, simply due to the number of 'caves' (caves being the term used by reverse engineers for blank space or redundant code). With current bloatware theres more than enough space to hide a whole operating system in there.\nWell, you're right, there can only be an infinite number of file inputs if infinite file length is possible which, of course, it isn't. The point is that the number of FEASIBLY possible file inputs might as well be infinite.\nIf, for example, you consider ONLY files of 4MB in size. There are 2^25 possible such files. A 128-bit hash has 2^7 possible values. Therefore, on average, each hash value can be derived from 2^18 different files.\nAs John Stag kindly pointed out, we can already provide security that is theoretically impossible to crack by brute-force methods. The problems arise when weaknesses in the security algorithms make it possible to bypass these theoretical limits and find a solution more directly.\nWinword.exe on my system is over 12MB in size. I'm pretty sure a decent (?) piece of malware could be written that would be a fraction of that size. If I then had some way to populate the other 11Mb with junk such that the MD5 (or whatever) hash of the whole file matched the original Winword.exe hash, it would pass a hash-based check.\nWithout actually being able to prove it, I am pretty well positive that there would be many different versions of my file that could be made to match the original MD5 hash. Whether it could AT THE SAME TIME match an SHA-1 hash, and/or an SHA-2 hash etc, would be a question for a REAL cryptographer!\nSurely there was never a better argument for open source than this\nI'm really not trying to start a flame war, but consider how hard it would be to infect an application that is recompiled on the target computer as part of the installation.\nSome form of compromise/infection surely can be done, but wouldn't it be harder to do, and much easier to fix if you could simply recompile?\nJust a note about key sizes (and heuristics)\nNot all crypto is equal: the \"safe\" key sizes for symmetric algorithms (AES et co) and asymmetric ie public-key (RSA et co) are vastly different simply because they're fundamentally different principles. Nevertheless the problem usually isn't the key space but some implementation/design mistake on a detail that allows the attacker to shortcut (or a major breakthrough in mathematics that allows \"easy\" solutions to problems previously thought to be \"hard\").\nAs for heuristics the engines have been pretty good for a long time and false positives can be managed with a signature list, nowadays with increasing computing power more thorough behaviour analysis is possible and at least F-Secure is doing reasonable job at it (http://www.heise-security.co.uk/news/100900)\nre: AV Technology....A known Failure\nEh? Maybe true(ish) for an active scanner that just looks for virus activity on a running PC but anyone who only uses that level of anti-malware protection on a Windows PC deserves viruses.\nMinimum basic precautions are..\nProperly configure (and use) your PC in as secure a manner as possible.\nScan all dangerous files at download time with a good, up-to-date virus scanner, preferably on a mail/proxy server and certainly before installing anything.\nRun an active scanner in case the other precautions failed.\nBack-up everything regularly in case you have to flatten your PC and start-over.\n\"If, for example, you consider ONLY files of 4MB in size. There are 2^25 possible such files. A 128-bit hash has 2^7 possible values. Therefore, on average, each hash value can be derived from 2^18 different files.\"\nReally? I don't think so. 2^7 possible values - that's only 128 values. A 128 bit hash has 2^128 possible values. That's over 3.4 X 10^38. As the sun has a mass of approx 1.9 X 10^30. That's 17 million times the mass of the sun in kilos. Or, in file sizes, a single file of 3.4 X 10^14 terrabytes. One file of this size would be needed to generate all the possible combinations.\nThat's (for current computers) not a space that can brute-forced.\nThere are 10 types of people in this world:\nThose who understand binary,\nThose who don't and\nThose who start counting at 0\n- Geek's Guide to Britain INSIDE GCHQ: Welcome to Cheltenham's cottage industry\n- 'Catastrophic failure' of 3D-printed gun in Oz Police test\n- Game Theory Is the next-gen console war already One?\n- BBC suspends CTO after it wastes £100m on doomed IT system\n- Peak Facebook: British users lose their Liking for Zuck's ad empire", "label": 1}
{"text": "(ARA) - By now, most parents are aware that the entertainment and educational value of the Internet also comes with risks, particularly for children. Protecting children from those risks is a vital concern for any parent whose child uses the web and any web-enabled device.\nOnline child safety measures should encompass steps that protect children from a variety of threats - including damage to a child's reputation, contact from predators, spamming, bullying, and risks of identity theft. Here are some common online risks and what parents should know about how to protect their children:\nAs soon as children become active online they need to understand that what they say and share on the Internet \"lives forever.\" With a growing number of employers, colleges and universities including social media outlets in the background check process, teenagers' online activity could potentially impact their ability to be admitted into their college of choice and even their later job prospects.\nProtecting a child's online reputation can be a complex task. Consider parental help sites like SafetyWeb.com. The online tool provides targeted monitoring and customizable utilities to help parents track their children's presence in cyber space. The tool filters mobile phone and Internet activity for both positive and risky behavior, provides parents with timely alerts, and allows parents to see accounts, photos, friends, tweets, posts, texts and calls through one convenient online dashboard.\nThe FBI notes that online predators often target children. Some invest a great deal of time, effort and even money into winning a child's trust, while others engage in immediate inappropriate behaviors and conversations with children. To minimize the risk of children falling victim to sexual predators, the FBI advises parents to make sure their children know to never:\n* Arrange a face-to-face meeting with someone they met online.\n* Share pictures of themselves with people they don't personally know.\n* Provide identifying information like their name, address, school name or phone numbers.\n* Download pictures from someone they don't know.\n* Respond to inappropriate online communication.\n* Believe that everything they're told online is true.\nAs soon as children learn they can communicate with others via email, they'll want their own email accounts. As soon as they have an email account, they can become victims of spamming, junk mail, hijacking and malware. To minimize the risks of your child's email being abused, take these precautions:\n* Teach children to not open emails, links, posts or online advertisements from someone they don't know.\n* Teach children to be wary of emails with attachments, even if they come from an email address they think they recognize.\n* Show kids how to create and use strong passwords.\n* Make sure your antivirus and security software is always up to date and active on computers and other mobile devices.\nCyberbullying is an assault on a child's online reputation and self-esteem, often by other children. The National Crime Prevention Association (NCPA) defines it as the use of the Internet, cell phones or other electronic devices to \"send or post text or images intended to hurt or embarrass another person.\" The organization says cyberbullying affects as many as half of all American teens.\nNCPA says children can help prevent cyberbullying by refusing to participate in it, speaking out against it when they see it occurring, blocking communication with cyberbullies, and reporting instances to adults they trust. Parents can also help by:\n* Developing rules for their children about cyberbullying and making sure the kids understand the rules.\n* Raising awareness of the issue within the community.\n* Sharing anti-cyberbullying messages and measures with friends.\nA 2009-2012 Carnegie Melon CyLab study of more than 42,000 children younger than 18 found that more than 10 percent had someone else using their Social Security numbers. The youngest victim was just 5 months old.\nTo reduce the risk of children falling victim to identity thieves, parents should protect minors' Social Security numbers. Never carry your child's Social Security card, and if a company, school or medical provider requests it, ask why it's needed and if you can provide some alternate form of identification. Teach children the importance of this valuable number and to never share it unless truly called for.", "label": 1}
{"text": "- Check your computer operating system's automatic update settings to ensure you're receiving updates.\n- Software Updates come in the form of software \"patches\" that replace defective section of software code with corrected code. All software manufacturers issue patches either on a regular schedule or as defects are discovered. Malware can infiltrate a computer through a software application that has not been patched.\n- Check your software programs for updates that may be available in the \"Help\" menu or on the software vendor's Web site.\n- Pay attention to pop-up messages within a program: these may be notices of available software updates.\n- Only apply updates from trusted sites. Beware of download requests from pop-ups or advertisements.\n- Create a new user on the computer that does not have administrative privileges and use that account for your primary logon when using the computer. Limit administrative rights on users' workstations to help prevent the inadvertent downloading of malware or other viruses.\n- Pay particularly close attention to Microsoft Windows, Microsoft Office, Adobe Flash, Adobe Reader, and Java updates. These applications are the most widely used and therefore most targeted.", "label": 1}
{"text": "2,295: The number of times a sequential list of numbers was used, with “123456″ by far being the most popular password. There were several other instances where the numbers were reversed, or a few letters were added in a token effort to mix things up.\n160: The number of times “111111″ is used as a password, which is only marginally better than a sequential list of numbers. The similarly creative “000000″ is used 71 times.\nProtect your information by creating a secure password that makes sense to you, but not to others.\nMost people don’t realize there are a number of common techniques used to crack passwords and plenty more ways we make our accounts vulnerable due to simple and widely used passwords.\nCommon Ways Hacks Happen\nDictionary attacks: Avoid consecutive keyboard combinations— such as qwerty or asdfg. Don’t use dictionary words, slang terms, common misspellings, or words spelled backward. These cracks rely on software that automatically plugs common words into password fields. Password cracking becomes almost effortless with a tool like John the Ripper or similar programs.\nCracking security questions: Many people use first names as passwords, usually the names of spouses, kids, other relatives, or pets, all of which can be deduced with a little research. When you click the “forgot password” link within a webmail service or other site, you’re asked to answer a question or series of questions. The answers can often be found on your social media profile. This is how Sarah Palin’s Yahoo account was hacked.\nSimple passwords: Don’t use personal information such as your name, age, birth date, child’s name, pet’s name, or favorite color/song, etc. When 32 million passwords were exposed in a breach last year, almost 1% of victims were using “123456.” The next most popular password was “12345.” Other common choices are “111111,” “princess,” “qwerty,” and “abc123.”\nReuse of passwords across multiple sites: Reusing passwords for email, banking, and social media accounts can lead to identity theft. Two recent breaches revealed a password reuse rate of 31% among victims.\nSocial engineering: Social engineering is an elaborate type of lying. An alternative to traditional hacking, it is the act of manipulating others into performing certain actions or divulging confidential information.\nTips to Make Your Passwords Secure\n- Make sure you use different passwords for each of your accounts.\n- Be sure no one watches when you enter your password.\n- Always log off if you leave your device and anyone is around—it only takes a moment for someone to steal or change the password.\n- Use comprehensive security software and keep it up to date to avoid keyloggers (keystroke loggers) and other malware.\n- Avoid entering passwords on computers you don’t control (like computers at an Internet café or library)—they may have malware that steals your passwords.\n- Avoid entering passwords when using unsecured Wi-Fi connections (like at the airport or coffee shop)—hackers can intercept your passwords and data over this unsecured connection.\n- Don’t tell anyone your password. Your trusted friend now might not be your friend in the future. Keep your passwords safe by keeping them to yourself.\n- Depending on the sensitivity of the information being protected, you should change your passwords periodically, and avoid reusing a password for at least one year.\n- Do use at least eight characters of lowercase and uppercase letters, numbers, and symbols in your password. Remember, the more the merrier.\n- Strong passwords are easy to remember but hard to guess. Iam:)2b29! — This has 10 characters and says “I am happy to be 29!” I wish.\n- Use the keyboard as a palette to create shapes. %tgbHU8*- Follow that on the keyboard. It’s a V. The letter V starting with any of the top keys. To change these periodically, you can slide them across the keyboard. Use W if you are feeling all crazy\n- Have fun with known short codes or sentences or phrases. 2B-or-Not_2b? —This one says “To be or not to be?”\n- It’s okay to write down your passwords, just keep them away from your computer and mixed in with other numbers and letters so it’s not apparent that it’s a password.\n- You can also write a “tip sheet” which will give you a clue to remember your password, but doesn’t actually contain your password on it. For example, in the example above, your “tip sheet” might read “To be, or not to be?”\n- Check your password strength. If the site you are signing up for offers a password strength analyzer, pay attention to it and heed its advice.\nIn the end, it’s the responsibility to the public to protect themselves. This disclosure now requires those currently exposed to change their password. The rule of thumb is to change your passwords frequently, every six months. It’s a cliché, but true, passwords need to be strong. Let the keyboard be your palate and be creative. A common mistake people make is that they use dictionary or slang terms. Beware. Dictionary attacks use software that automatically plugs common words into password fields making password cracking effortless for various tools.", "label": 1}
{"text": "By Geeta Dayal... via Wired.com\nDon’t you dare even think about your banking account password when you slap on those fancy new brainwave headsets.\nOr at least that seems to be the lesson of a new study which found that sensitive personal information, such as PIN numbers and credit card data, can be gleaned from the brainwave data of users wearing popular consumer-grade EEG headsets.\nA team of security researchers from Oxford, UC Berkeley, and the University of Geneva say that they were able to deduce digits of PIN numbers, birth months, areas of residence and other personal information by presenting 30 headset-wearing subjects with images of ATM machines, debit cards, maps, people, and random numbers in a series of experiments. The paper, titled “On the Feasibility of Side-Channel Attacks with Brain Computer Interfaces,” represents the first major attempt to uncover potential security risks in the use of the headsets.\n“The correct answer was found by the first guess in 20% of the cases for the experiment with the PIN, the debit cards, people, and the ATM machine,” write the researchers. “The location was exactly guessed for 30% of users, month of birth for almost 60% and the bank based on the ATM machines for almost 30%.”\nTo detect the first digit of the PIN, researchers presented the subjects with numbers from 0 to 9, flashing on the screen in random order, one by one. Each number was repeated 16 times, over a total duration of 90 seconds. The subjects’ brainwaves were monitored for telltale peaks that would rat them out.\nThe EEG headsets, made by companies such as Emotiv Systems and NeuroSky, have become increasingly popular for gaming and other applications. For the study, the researchers used the Emotiv Epoc Neuroheadset, which retails for $299.\nThe researchers — Ivan Martinovic of Oxford University; Doug Davies, Mario Frank, Daniele Perito, and Dawn Song of UC Berkeley; and Tomas Ros of the University of Geneva — analyzed P300 peaks, an important component of event-related potentials — electrical potentials that happen after the user is presented with a stimulus.\nThe P300 “occurs approximately 300 milliseconds after an event happens,” said Frank, a postdoctoral researcher at Berkeley, in a phone interview with Wired. “The potential arises if you already prime your thoughts toward a particular event…. An attacker could try to prime the thoughts of the victim towards a particular secret that a victim has in mind. For instance, if you know the face of some person, you might be able to observe a brainwave pattern that is evidence of the user thinking about the face.”", "label": 1}
{"text": "Image via CrunchBase\nThere is always malicious spy-ware lurking on the internet, otherwise known as malware, causing havoc on the computers of unsuspecting internet users. Lately, Google has warned users about an especially effective virus that becomes visible when the user gets a giant yellow warning screen at the top of his computer. Google has issued instructions to users on how to remove the malware, avoiding malware’s ability to use important banking and personal information from the home computers of internet users.\nGenerally a computer becomes infected with a virus like this through an accidental click by the user. The people sending out these viruses are trying to entice users with a free music or film download. Other times, you check your e-mail and find a link that looks very much like the home screen of your regular bank or place you shop. It is important to verify that the page you intend to visit is where you end up. Otherwise, thieves use your identity to take out credit lines and make purchases in your name.\nThere is free software available to help you combat malware and spyware from entering your computer. These free programs, such as a C-drive cleaner, or anti-spyware program, are easily installed and run several times a week to make sure that viruses are not found on your system. When a program detects a virus on your computer, make sure to quarantine the virus and then drop it off your system at your earliest convenience. Consult a professional if you are unsuccessful removing a virus.", "label": 1}
{"text": "About CVE Identifiers\nCVE Identifiers Defined\nCVE Identifiers (also called \"CVE names,\" \"CVE numbers,\" \"CVE-IDs,\" and \"CVEs\") are unique, common identifiers for publicly known information security vulnerabilities.\nCreation of a CVE Identifier\nThe process of creating a CVE Identifier begins with the discovery of a potential security vulnerability or exposure. The information is then assigned a CVE Identifier number by a CVE Numbering Authority (CNA), and posted on the CVE Web site by the CVE Editor. As part of its management of CVE, The MITRE Corporation functions as CVE Editor and Primary CNA. The CVE Editorial Board oversees this process.\nThe documents below explain CVE Identifiers and the creation of identifiers in more detail:\nLists the several organizations currently participating as CVE Numbering Authorities (CNAs). Includes an introduction to the candidate reservation process; defines CNAs and provides the requirements for being a CNA, describes CNA tasks, and explains the communication requirements from the CNA to MITRE; defines the role of vendor liaisons, and explains the researcher’s responsibilities in the process.\nA description of the process of how CVE Identifiers are added to the CVE List, including the roles of CVE Numbering Authorities (CNA) and the CVE Content Team.\nCVE Editorial Policies, also Content Decisions (CDs), are the guidelines the CVE Content Team uses to ensure that CVE Identifiers are created in a consistent fashion, independent of who is doing the creation. This page is a central location of information about, and related to, CDs including the following: Editorial Policies Overview; CVE Abstraction Content Decisions: Rationale and Application; and Handling Duplicate Public CVE Identifiers.\nSelected opinions and commentary about vulnerabilities, software assurance, and related topics by the CVE List Editor.\nEach CVE Identifier includes appropriate references. Each reference used in CVE (1) identifies the source, (2) includes a well-defined identifier to facilitate searching on a source’s Web site, and (3) notes the associated CVE Identifier. CVE also includes a Reference Maps page with links to documents from the commonly used information sources that are used as references for CVE Identifiers.\nA list of the organizations from the information security community that provide us with vulnerability information that helps MITRE create new CVE Identifiers.\nThis page provides an archive of the old CVE versions, the last of which was issued in 2006. As new CVE Identifiers are now added to the CVE Web site on a daily basis and are immediately usable by the community, the most current version of CVE is on the CVE List Master Copy page.\nFAQs from the Frequently Asked Questions page in the About CVE section also address specific questions about CVE Identifiers.\nRequesting CVE Identifiers\nIn most instances the CVE Initiative does not issue CVE-ID numbers directly but instead relies on certain mechanisms to handle newly emerging information that is eventually provided to CVE. Therefore, to receive a CVE-ID number for your issue you could:\nAlternatively, you may contact the CVE project to Request a CVE-ID and we will provide you with our \"CVE Identifier Reservation Guidelines for Researchers\" and work with you to assign a CVE-ID number while you work through the process of publicly disclosing the vulnerability. Please review the Researcher Responsibilities.", "label": 1}
{"text": "Recently, a non-programmer friend pointed out that there is no simple explanation of capabilities available on the web. Less than a week later, another friend -- this one a senior operating system developer for a major UNIX software company -- said to me that he really didn't understand what I was working on (capabilities). If neither the lay reader nor the experts understand what these things are, an introductory description is definitely needed, so I set out to write one. I quickly discovered that doing so isn't easy. Capabilities themselves are very simple, but they turn everything people ``know'' about security upside down. A lot of people look at them and say ``this is too simple to possibly work.''\nThis essay is a basic introduction to capabilities and capability-based systems. Rather than try to give an exhaustive discussion, I have taken some editorial liberties in the interest of clarity:\nThis essay will tell you what the term access control covers, what a capability is, and provide some examples of how capabilities can be used to provide flexible access to objects without giving up security. I'll describe some problems that currently popular access control mechanisms cannot handle. I'll talk about the problem of revoking access, and how this is solved. Finally, I'll give my own opinion on how capabilities came to be rejected by mainstream computing people.\nWhile this essay uses UNIX as its example system, the problems identified with UNIX exist in VMS, Windows/NT and Windows95 as well.\nIf you find this note helpful, or you have suggestions for improvement, please drop me some mail at email@example.com.\nThe basic problem of computer security is to control which objects a given program can access, and in what ways. Objects are things like files, sound cards, other programs, the network, your modem, and so forth. Access means what kind of operations can be done on these objects. Examples include reading a file, writing to a file, creating or deleting objects, communicating with another program, etc.\nWhen we talk about ``controlling access,'' we are really talking about four kinds of things:\nPreventing access: You want to make sure that one person cannot damage another, or peek at another person's private information. I should not be able to read your medical records, for example. You should not be able to delete my work. This is the what most people mean when they talk about computer security.\nLimiting access. You want to ensure that a program or a user doesn't do more than you mean them to. For example, you might want to run a program off of the Web but prevent the program from reading or writing any files so that it cannot plant a computer virus or give away your private phone book. This issue has been getting more attention lately with all of the hype around Java.\nGranting access. You may want to allow two people to work together on a document or to grant access to a particular file to someone else so that you can delegate a job to them. Note however, that you probably want to do this selectively. Just because we are working on a business plan together doesn't mean that I should get to read your medical records. From a practical perspective, this is just as important as the first two, but security people don't tend to think about it very much.\nRevoking access. Having allowed access to an object, you may later need to take that access back when the person is no longer authorized to look at a particular document.\nAccess control is about determining what a program can access, not about what a person can access. In computers, people do not access objects; programs do. This distinction has practical importance for several reasons:\nHaving set the stage, we can now turn to what capabilities are, and how access control is accomplished using them.\nThe term capability was introduced by Dennis and Van Horn in 1966 in a paper entitled Programming Semantics for Multiprogrammed Computations. The basic idea is this: suppose we design a computer system so that in order to access an object, a program must have a special token. This token designates an object and gives the program the authority to perform a specific set of actions (such as reading or writing) on that object. Such a token is known as a capability.\nA capability is a lot like the keys on your key ring. As an example, consider your car key. It works on a specific car (it designates a particular object), and anyone holding the key can perform certain actions (locking or unlocking the car, starting the car, opening the glove compartment). You can hand your car key to me, after which I can open, lock, or start the car, but only on your car. Holding your car key won't let me test drive my neighbor's Lamborghini (which is just as well -- I would undoubtedly wrap it around a tree somewhere). Note that the car key doesn't know that it's me starting the car; it's sufficient that I possess the key. In the same way, capabilities do not care who uses them.\nCar keys sometimes come in several variations. Two common ones are the valet key (starts, locks, and unlocks the car, but not the glove compartment) or the door key (locks/unlocks the car, but won't start it). In exactly this way, two capabilities can designate the same object (such as the car) but authorize different sets of actions. One program might hold a read-only capability to a file while another holds a read-write capability to the same file.\nAs with keys, you can give me a capability to a box full of other capabilities.\nCapabilities can be delegated. If you give your car key to me, you are trusting me not to hand it to somebody else. If you don't want trust me, you shouldn't hand me the key.\nCapabilities can be copied. If you give me your car key, there is nothing to stop me from going down to my local car dealer and having a duplicate key made. In practice, this isn't much of a problem, because you wouldn't have handed me the key if you didn't trust me. If it comes down to desperate measures, you can change the locks on the car, making all of the keys useless. This can be done with capabilities too; it is known as severing an object, which has the effect of rescinding all capabilities. A rescinded capability conveys no authority to do anything at all.\nIn fact, there are only a few ways that capabilities and ordinary keys are different. The important differences are:\nKey Points: Capabilities are simple and familiar. You use them every day, and they don't surprise you very often. If you think about ordinary keys and the sorts of access controls they provide you will not go far wrong.\nIn order to be useful, capabilities must be unforgeable. If you could just conjure up a key to any car you wanted, they wouldn't provide much protection. Protecting capabilities from forgery can be handled in either hardware or in system software. The software approach is more convenient because it can run on an ordinary PC. EROS, which is currently the fastest capability system in existence, does this in system software, and the data suggests that there wouldn't be any real benefit to doing it in hardware.\nIn a capability-based computer system, all access to objects is done through capabilities, and capabilities provide the only means of accessing objects. In such a system, every program holds a set of capabilities. If program A holds a capability to talk to program B, then the two programs can grant capabilities to each other. In most capability systems, a program can hold an infinite number of capabilities. Such systems have tended to be slow. A better design allows each program to hold a fixed (and small -- like 16 or 32) number of capabilities, and provides a means for storing additional capabilities if they are needed. The only way to obtain capabilities is to have them granted to you as a result of some communication.\nHolding a large number of capabilities is usually foolish. The goal is to make the set of capabilities held by each program as specific and as small as possible, because a program cannot abuse authority it does not have. This is known as the principle of least privilege.\nIn this kind of system, a program that wants to perform an\noperation on an object must hold a capability to that\nobject. To perform the action, it invokes the\ncapability and names the action that is to be\nperformed. In the UNIX® operating system, for\nexample, the system call\nThe main problem with capabilities is finding a way to save them to disk so that you can get them back. This is one of the main reasons that few capability systems have been built, and the main reason why most current capability systems break down at the file system boundary.\nAssume for a minute that your program had a capability that let it create a file and write things down in it. Suppose it does so, and all of the information you need has now been written down. My helpful dog, Sheena, now comes along and kicks your computer's plug out of the wall. We start the system up and we now have to answer a chicken and egg problem:\nThese problems basically stumped capability system designers until the early 1970's.\nThe usual solution has been to have some kind of file\nsystem, grant every program the right to use the\nfile system, and use some sort of user-identity based\nsystem to decide which programs can open which files. If a\nprogram is running on behalf of Natasha (my other dog), it\ncan open any of the files that Natasha created. Such a\nsystem is called an access control list (ACL)\nsystem. Every object has attached to it a list of users\nand the actions that each user is authorized to\nperform. If the user is on the access control list, then\nprograms operating on behalf of that user can obtain a\ncapability for that object. Once they have the capability,\nthey can manipulate the object itself. This is the purpose\nof the UNIX\nTake a minute to go back and look at the four things an access control mechanism was supposed to accomplish. ACL systems can prevent and revoke access, but they can neither limit access nor grant access. All programs running on behalf of Natasha -- even that raging inferno program written by a stranger in Norway -- can get access to any of Natasha's objects. In current ACL systems, there is no means to subset these rights. Also, there is no way for Natasha to delegate some of her authority (say, access to a single file she does not own) to me unless Natasha owns the object(s) in question. Unless she owns the object, she cannot modify the access control list.\nA better solution is not to have a common file system, and not to give any program access to the file system by default. File systems are very useful, but most programs and subsystems do not need access to them. A spell checker that runs as part of a word processor, for example, needs access to the particular files it works on, but has no need to open any other files (and therefore no need of access to a file system).\nIf things aren't remembered by writing them in a file, some other means must be found to remember them. The solution is to simply remember everything. Every five minutes, write down all of the things the computer is working on. If Sheena pulls the plug, the system simply comes back to the last saved copy. Since the saved copy includes all of the running programs, there is no need to figure out who is entitled to what when the system restarts.\nYou might think this is an inefficient approach. In practice it's actually faster than file systems and requires less code.\nOf course, the user may have walked away from the machine, so a means is needed to get back to their work. The solution is to give every user a program that runs on their behalf (the window system, if you like) at all times. The job of the login agent is to reconnect you to your window system, where all of your programs are still running.\nTraditional access control systems run into trouble with a variety of important problems. Here are some examples of these problems in today's computer systems, and an explanation of why the problems do not exist in capability systems.\nConsider the program that changes your password. It needs\nthe authority to read and write the password file, but\nmust not give that authority to you. In an ACL system the\nonly way to do this is to have access to the password file\nrestricted to a special user (\nBoth of these mechanisms are insecure. Giving the password program all of root's authority is simply too much. In the VMS mechanism, the program file itself can be attacked, leaving a hard to find security hole. The next time the program is run it will obey the new program, which can do absolutely anything.\nMaybe more important, such programs tend to get into trouble over time. As maintainers alter these programs without fully understanding their constraints, they become sources of new security flaws.\nThe right solution is to explicitly give the program access to the password file, and not leave the password program lying around in a file system where it can be overwritten. In a capability system, you simply give the program a capability to the password database and let it run forever. You then give out a capability that lets people run the password program but does not let them read or modify that program.\nSuppose you have a program that manages your financial data. You don't really want it sending that information to the IRS without your permission, but your computer is attached to the network. In an ACL system, since you have access to the network, so does the program. In a capability system you simply leave the capabilities for the network out when you install the program, guaranteeing that it cannot send data to those helpful, friendly people at the IRS.\nJava solves this problem by ad-hoc restrictions. You may have noticed that people keep finding new security problems with Java. This is because ad-hoc security mechanisms don't work. It is better to have done the job right in the first place. Capabilities have a formal, mathematically sound model that can be (and has been) used to prove their security.\nThe really hard part, however, is dealing with collaboration. Suppose I have a secret program that is very valuable. I'm afraid to give out the binary code, because somebody will decompile it and steal my program (yes, this really does happen). You have some very secret data concerning the results of a new drug trial. You need to run my program, but you're not willing to show me the data.\nIn a capability system, we can set things up so that you can run the program without being able to see the code, but you are able to control what authority my program is given. Since you control the authorities, you can ensure that my program will not tell me your secrets. Since you cannot gain access to the binary code, you cannot steal the program. Most computer security experts believe that this is impossible. In ACL systems, it really is impossible.\nOne problem with capabilities is that there is no way to say \"Remove all of Fred's access to this object.\" If Sheena (my dog) decides to leave me for another owner, how do I take away her capability for the dog food can? More realistically, if your employee leaves how do you make sure that their access to the file cabinet is cut. More importantly, suppose the user isn't fired, but is just moved to another department, and should no longer have access to sensitive documents in their old department?\nOn the face of it, there seem to be three different cases here:\nActually, the last two cases are the same.\nIn both capability and ACL systems, the first problem is solved by deleting the user's login.\nIn both capability and ACL systems, the second problem can be solved by creating a new login for the same user and selectively copying into the new account those personal documents that the user should retain access to. In many cases this is the best solution. In capability systems, another solution is possible: build a software-enforced special compartment that prevents the documents from being copied out of the compartment, and only let the user access those documents inside the compartment. This is not the same as a user group. In the user group approach, the user may have made copies of the documents. Deleting them from the group will prevent future damage, but does nothing to control theft while the user has legitimate access.\nRevoking access to a particular object is exactly like the special compartment problem. Either you build a special compartment in advance, or there really isn't any good way to prevent the user from absconding with the data.\nSo if capabilities are so much better than ACLs, why haven't they been used? How come so many companies are shipping insecure operating systems when we know how to solve these problems?\nPart of the problem is historical. The early capability systems were built in hardware before we knew a lot about hardware architecture, and used capabilities for access to main memory. This made them terribly slow and terribly complex. Those systems are a good bit less complex than today's operating systems, but their reputation persists.\nIn the 1970s, an operating system called MULTICS came along, and most of the world went galloping down the UNIX trail. UNIX is an extraordinary system, designed in a day when most computers were not connected to the outside world. In a world where all of the other users are known to you, collaboration is more important than security. The UNIX security mechanisms are adequate for a collaborative environment. Until the advent of the Internet and commonplace connectivity, only a few machines running dedicated financial applications needed to worry seriously about security, and those machines needed to implement it in the application anyway.\nIn the 1980s a lot of truly mediocre work was done on microkernels (which are similar to modern capability systems), and some equally bad analysis concluded that the problem was with microkernels in general rather than with the flaws of particular implementations. We now have examples of microkernels that are significantly faster than conventional operating systems, and at least one example of a capability system that is so.\nThe bottom line is that over the past 25 years a huge investment has been put into insecure systems, and until there is a compelling reason to change these systems the people who support them won't bother. In fact, computer software vendors have taken steps to ensure that they are not held liable for the flaws in their software, even when they are real, demonstrable, and incontrovertable. Until this changes, there is no reason to do secure systems. One of the arguments that has been made against capability systems is that capabilities and access control lists can be made formally equivalent (if you make enough repairs to access control lists, that is). This is a deceptive argument, because people think that means they are the same. Two things can be theoretically the same without being practically the same. I can imagine ways to augment traditional access control lists to handle suspicious collaborators on paper, but the solutions are both unacceptably draconian and too slow to actually use.\nThings are changing slowly. Java is a partial step in the right direction, and the PR around Java is starting to wake users up to how exposed they are. Over time you can expect to see some of the Java ideas embedded in mainstream systems.\nActually, compatibility environments for UNIX have been built that run securely on top of capability systems (it's worth noting that you can't build a capability system on top of an ACL system), so it may not be necessary to discard existing code.\nHopefully, you now know what a capability is, and can start to take part in discussions about them. At some point soon I'll add links here to other sources of information for people who want to read further.\nCopyright 1999 by Jonathan Shapiro. All rights reserved. For terms of redistribution, see the GNU General Public License", "label": 1}
{"text": "Within the last years, the increasing presence of large-scale architectures has introduced the era of Cloud Computing.\nThere is a huge number of different definitions available towards Cloud Computing. The term \"cloud\" itself is derived from the figurative abstraction of the internet represented as a cloud. The available definitions of Cloud Computing range from reductions it to be ``the next hype term\" over pragmatic definitions focusing on special aspects to definitions, that see Cloud Computing as a general paradigm shift of information architectures, as an ACM CTO Roundtable [Cre09] has shown in 2009. Of the various features that are attributed to the \"cloud\", scalability, a pay-per-use utility model and virtualization are the minimum common denominators.\nThe key concept of Cloud Computing is the resourcing of services. These services can be generally differentiated into three vertical layers:\nReferring to the terminology of Cloud Computing, a scalable web application is essentially a SaaS that requires appropriate execution/hosting environments (PaaS and/or IaaS).\nIn the following, we will consider some exemplary hosting providers and outline their service features.\nAmazon was one of the first providers for dedicated, on-demand and pay-per-use web services. It is currently dominating the multi-tenant Cloud Computing market. Their main product is Elastic Compute Cloud (EC2), a service providing different virtualized private servers. The provision of virtualized machines in scalable amounts forms an architectural basis for most of their clients. Instead of growing and maintaining own infrastructure, EC2 clients can spin up new machine instances within seconds and thus cope with varying demand. This traditional IaaS hosting is complemented by a set of other scalable services that represent typical architecture components.\nElastic Block Storage (EBS) provides block-level storage volumes for EC2 instances. Simple Storage Service (S3) is a key-value web-based storage for files. More sophisticated data storage systems available are SimpleDB, DynamoDB and Relational Database Service (RDS). The former two services represent non-relational database management systems with a limited set of features. RDS currently supports MySQL-based and Oracle-based relational databases.\nElastic Load Balancing (ELB) provides load-balancing functionalities on transport protocol level (e.g. TCP) and application level (e.g. HTTP). As a message queue, Simple Queue Service (SQS) can be used. For complex MapReduce-based computations, Amazon has introduced Elastic MapReduce.\nElastiCache is an in-memory cache system that helps speeding up web applications. CloudFront is a CDN, complementing S3 by replicating items geographically. For monitoring purposes, Amazon has come up with CloudWatch, a central real-time monitoring web service.\nBesides these services, Amazon has introduced their own PaaS stack, called Elastic Beanstalk. It is essentially a bundle of existing services such as EC2, S3 and ELB and allows to deploy and scale Java-based web applications. Furthermore, there are additional services that cover business services such as accounting or billing.\nThe Google App Engine is a PaaS environment for web applications. It currently provides support for Python, Go and several JVM-based languages such as Java. Applications are hosted and executed in data centers managed by Google. One of its main features is the automatic scaling of the application. The deployment of the application is transparent for the user, and applications encountering high load will be automatically deployed to additional machines.\nGoogle provides free usage quotas for the App Engine, limiting traffic, bandwidth, number of internal service calls and storage size among others. After exceeding these limits, users can decide to add billable resources and are thus getting charged for additional capacities.\nThe runtime environment of the application is sandboxed and several language features are restricted. For instance, JVM-based applications cannot spawn new threads, use socket connections and access the local file system. Furthermore, the execution of a request must not exceed a 30 seconds limit. This restrictions are enforced by modified JVMs and altered class libraries.\nBesides an application container, the App Engine provides several services and components as part of the platform. They are accessible through a set of APIs. We will now have a brief look at the current Java API.\nThe Datastore API is the basic storage backend of the App Engine. It is schemaless object datastore, with support for querying and atomic transaction execution. Developers can access the datastore using Java Data Objects, Java Persistence API interfaces or via a special low-level API. A dedicated API provides support for asynchronous access to the datastore. For larger objects, and especially binary resources, the App Engine provides a Blobstore API. For caching purposes, the Memcache API can be used. Either using a low-level API or the JCache interface.\nThe Capabilities API enables programmatical access to scheduled service downtimes and can be used to develop applications that prepare for the unavailablity of capabilities automatically. The Multitenancy API provides support for multiple separated instances of an application running in the App Engine.\nImages can be manipulated using the dedicated Images API. The Mail API allows the application to send and receive emails. Similarly, the XMPP API allows message exchange based on XMPP. The Channel API can be used to establish high-level channels with clients over HTTP and then push messages to them.\nThe Remote API opens an App Engine application for programmable access using an external Java application. Other web resources can be accessed using the URLFetch API.\nThanks to the Task Queue API, there is some support for tasks decoupled from request handling. Requests can add tasks to a queue, and workers asynchronously execute the background work. The Users API provides several means to authenticate users, including Google Accounts and OpenID identifiers.", "label": 1}
{"text": "Virtual Private Networking\nIf you've understood most of this document so far, the principles of Virtual private networking (VPN) will be easy to understand. The most confusing part of VPN is that many acronyms show up. This is partly because VPN requires data encryption to be \"private\" and there are many encryption techniques and terms. Also there are many complicated security issues relating to VPN concerning encryption and user authentication. This section will first explain the concept and methodology behind VPN, then explain some of the acronyms. I can't explain them all, there will be more tomorrow.\nPurpose of VPN\nThe function of VPN is to allow two computers or networks to talk to each other over a transport media that is not secure. To do this VPN uses a computer at each of the two or more points on the various ends of the transport media such as the internet. Each point at the end of the transport media (internet) is called a point of presence (POP). In this example, the transport media is the internet. In the example below our company \"Boats and More, Inc.\" has four offices. One in Boston, St Petersburg, Seattle, and San Diego. The owner wants a networking setup so he can access any of the 4 network locations at any time through the internet. He wants his data secure since some of it is confidential. His offices are set up on networks 10.1.x.x, 10.2.x.x, 10.3.x.x, and 10.4.x.x. Each of the four networks, when they need to send a data packet to one of the other networks, will route its data packet to its respective router, A, B, C, or D. For example if a computer on the 10.1.x.x network in Boston needs to send a packet to a computer with address 10.3.6.1 on the network in San Diego at 10.3.x.x, it will send its packet to its router, A. Since the network number, 10.x.x.x, is reserved for private use, the packet can't be sent going from computer A with 10.3.6.1 as its intended address. This is because the routers on the internet will not recognize this address as a valid destination. IP masquerading won't solve this problem since the computer on the other end would have no way of knowing that a packet that it didn't send was a masqueraded packet. Tunneling is the technique used to solve this problem.\nTunneling means that the complete IP packet to be sent from Boston to San Diego must be encapsulated into another IP packet. This new packet will have a legal internet IP address. Therefore, machine A will take the packet it needs to route (already has destination address 10.3.6.1) and roughly the following will happen:\n- Machine A will extract the IP packet.\n- Machine A will encrypt the packet.\n- Machine A will wrap the original IP packet in a new IP packet with destination address 126.96.36.199, which is machine C's true internet address.\n- Machine A will wrap the new IP packet in an ethernet packet and send it to the network.\n- The packet will be routed through the internet until it reaches machine C.\n- Machine C will extract the outer IP packet.\n- Machine C will determine that the IP packet contains another IP packet and extract it.\n- Machine C will decrypt the packet.\n- Machine C will examine the destination address of the inner IP packet, wrap it in an ethernet packet with the correct ethernet address, and send it to the internal network on its port 10.3.1.1.\nThis description is simplistic, but it is essentially what happens. This did not account for authentication and being sure machine C had the authority or ability to decrypt the packet. Therefore VPN can be examined in two main functional areas which are the tunneling mechanism and the security mechanisms.\nVPN tunneling Protocols\nThe list below describes the tunneling protocols which may be used for VPN.\n- L2F - Layer2 Forwarding, works at the link layer of the OSI model. It has no encryption. Being replaced by L2TP.\n- PPTP - Point-to-Point Tunneling Protocol (RFC 2637) works at the link layer. No encryption or key management included in specifications.\n- L2TP - Layer2 Tunneling Protocol. (RFC 2661) Combines features of L2F and PPTP and works at the link layer. No encryption or key management included in specifications.\n- IPSec - Internet protocol security, developed by IETF, implemented at layer 3. it is a collection of security measures that address data privacy, integrity, authentication, and key management, in addition to tunneling. Does not cover key management.\n- Socks - handled at the application layer\nIn addition ot tunneling, VPN needs to provide for authentification, confidentiality, data integrity and key management. This is important if you need to keep your data going across the transmission media, secret. The capability of sending the data is easy, but the security measures necessary make VPN a much more complex subject. Security functions that must be covered are:\n- Authentification - Making sure the data is from where it is supposed to be from.\n- Confidentiality - Keeping any third parties from reading or understanding the data.\n- Data integrity - Being sure the data received was not changed by a third party and that it is correct.\n- Access control - Keeping third parties without authorization from getting access to your data or network.\nEssentially the part of the system that must make the data secure, must encrypt the data and provide a method to decrypt the data. There are many different encryption formulas, but typically handling of decryption is usually done by providing a \"key\" to the party that must decrypt the data. Keys are secrets shared between two parties, that allow one party to pass encrypted information from one to the other without third parties being able to read it. It is similar to a house or car key that allows only members of your family to enter the house or use the car. Keys are a digital code that will allow the second party to decrypt the data. The digital code must be long enough to keep any third parties from being able to break the code by guessing. Key management can be a complex subject since there are many ways to implement it, but it needs to be secure so no third party gets, intercepts, or guesses the key.\nThere are many different protocols used to support each of the above functions. Each have various advantages and disadvantages including the fact that some are more secure than others. If you are going to use VPN as a data exchange method, and you want secure data, you or someone on your staff had better know what they're doing (Knowledge of the strengths and weaknesses of the protocols and how to implement them properly), or sooner or later, you may get burned.\nManaging user access rights and Key Management or Authentification Systems\nTwo key management protocols are:\n- RADIUS - Remote Authentication Dial-In User Service is used for dial in clients to connect to other computers or a network. It provides authentication and accounting when using PPTP or L2TP tunneling.\n- ISAKMP/Oakley - Internet Security Association and Key Management Protocol Authentication uses one of the following three attributes to authenticate users.\nMore than one means of authentification is recommended for stronger security.\n- Something you have such as a key.\n- Something you know such as a secret.\n- Something you are such as your fingerprint.\n- PPTP - Point to point tunneling protocol (RFC 2637)\n- L2TP - Layer 2 tunneling protocol (RFC 2661)\n- IPIP tunneling - Tunneling IP packets in IP packets.\nEncryption protocols, methods and terms:\n- CIPE - Crypto IP Encapsulation\n- SSL - Secure sockets layer\n- IPSEC - Internet protocol security\n- PAP - Password Authentification Protocol is a two way handshake protocol designed for use with PPP.\n- CHAP - Challenge Handshake Authentication Protocol is a three way handshake protocol which is considered more secure than PAP.\n- TACACS - Offers authentication, accounting, and authorization.\n- S/Key - A one time password system, secure against replays. RFC 2289.\nProjects and software:\n- SWAN - Secure wide area network\n- PoPToP Point to point tunneling protocol server.", "label": 1}
{"text": "Crime and Control\nThe Future of Computer Crime\nThe previous chapter discussed computer crime but its subject was metaphor. This time it is crime.\nTHE PAST AS PROLOGUE\nIn the early years, computers were large stand-alone machines; most belonged to governments, large firms, or universities. Frequently they were used by those organizations to control important real-world actions – writing checks, keeping track of orders, delivering goods. The obvious tactic for computer criminals was to get access to those machines and change the information they contained – creating fictitious orders and using them to have real goods delivered, arranging to have checks written in payment for nonexistent services,1 or, if the computer was used by a bank, transferring money from other people’s accounts to their own.\nAs time passed, it became increasingly common for large machines to be accessible from offsite over telephone lines. That was an improvement from the standpoint of the criminal. Instead of having to gain admission to a computer facility – with the risk of being caught – he could access the machine from a distance, evading computer defenses rather than locked doors.\nWhile accessing computers to steal money or stuff was the most obvious form of computer crime, there were other possibilities. One was vandalism. A discontented employee or ex-employee could crash the firm’s computer or erase its data. But this was a less serious problem with computers than with other sorts of machines. If a vandal smashes your truck, you have to buy another truck. If he crashes your computer, all you have to do is reboot. Even if he wipes your hard drive you can still restore from your most recent backup, losing only the most recent data.\nA more interesting possibility was extortion. In one British case, a supervisor of computer operations for a large multinational firm decided that it was time to retire. He took the reels of tape that were the mass storage for the firm’s computer, the backup tapes, and the extra set of backups that were stored offsite, erased the information actually in the computer, and departed. He then offered to sell the tapes – containing information that the firm needed for its ordinary functioning – back to the firm for a mere £275,000 (about $700,000).2\nIn a world with\nanonymous ecash, the payoff could have been made and the\ndelivered over the net via a remailer. In a world of strong\nhe could have located a criminal firm in the business of\npayoffs and subcontracted the collection end of his project.\nUnfortunately for the executive, he committed his crime too\ntried to collect the payoff himself – on a motorcycle – and\ncaught doing it.\nLarge computers controlling lots of valuable stuff still exist, but nowadays they are usually connected to networks. So are hundreds of millions of small computers. This opens up some interesting possibilities.\nA few years back, the Chaos Computer Club of Hamburg, Germany, demonstrated one of them on German television. What they had written was an ActiveX control, a chunk of code downloaded from a web site onto the user’s computer. It was designed to work with Quicken, a widely used accounting package. One of the things Quicken can do is pay bills online. The control they demonstrated modified Quicken’s files to add one additional payee. Trick a million people into downloading it, have each of them pay you ten marks a month – a small enough sum so that it might take a long time to be noticed – and retire.\nOne of the classic computer crime stories – possibly apocryphal – concerns a programmer who computerized a bank’s accounting system. After a few months, bank officials noticed that something seemed to be wrong – a slow leakage of money. But when they checked the individual accounts, everything balanced. Eventually someone figured out the trick. The programmer had designed the system so that all rounding errors went to him. If you were supposed to receive $13.436 in interest, you got $13.43, his account got .6 cents. It was a modest fraud – six-tenths of a cent is not much money, and nobody normally worries about rounding errors anyway. But if the bank has a million accounts and calculates interest daily, the total comes to about $5,000 a day.\nThat sort of fraud is called a “salami scheme” – nobody notices one more thin slice missing from a salami.3 The Chaos Computer Club had invented a mass production version. Hardly anyone notices a leakage of a few dollars a month from his account but, with millions of accounts, it adds up fast. It is the old computer crime of tricking a computer into transferring money to you modernized for a world with lots of networked computers that each control only small amounts. So far as I know, nobody has yet put this particular form of computer crime into practice, despite the public demonstration that it could be done. But someone will.\nA modern criminal who preferred extortion to theft could hold the contents of computers for ransom using either a downloaded ActiveX control or a computer virus – and take advantage of the power of public key encryption. Once the software gets onto the victim’s computer it creates a large random number and uses it as the key to encrypt the contents of the hard drive, erasing the unencrypted version as it does so. The final step is to encrypt the key using the criminal’s public key and erase the original.\nThe next time the computer is turned on, its screen shows a message offering to unencrypt the contents of the hard drive for twenty dollars in anonymous ecash, sent to the criminal through a suitable remailer. The money must be accompanied by the encrypted key, which the message includes. The extortionist will send back the decrypted key and the software to decrypt the hard drive.\nFrom the standpoint of the criminal, the scheme has two attractive features. The first is that since each victim’s hard drive is encrypted with a different key, there is no way one victim can share the information about how to decrypt it with another – each must pay separately. The second is that, with lots of victims, the criminal can establish a reputation for honest dealing; after the first few cases, everyone will know that if you pay you really do get your hard drive back. So far as I know, nobody has done it yet, although there was an old case involving a less sophisticated version of the scheme, using floppy disks instead of downloads.\nWhat else can be done in a world of lots of small networked computers? One answer is vandalism, familiar in the form of computer viruses. A more productive possibility is to imitate some of the earliest computer criminals and steal, not money, but computing power. At any instant, millions of desktop computers are twiddling their thumbs while their owners are eating lunch or thinking about what to type next. When you operate at millions of instructions a second, there’s a lot of time between keystrokes.\nThe best-known attempt to harness that wasted power is SETI – the Search for Extra-Terrestrial Intelligence. It is a volunteer effort by which large numbers of individuals permit their computers, whenever they happen to be idle, to work on a small part of the immense project of searching the haystack of interstellar radio noise for the needle of information that might tell us that, somewhere in the galaxy, someone else is home. Similar efforts on a smaller scale have been used in experiments to test how hard it is to break various forms of encryption, another project that requires very large-scale number crunching.\nOne could imagine an enterprising thief stealing a chunk of that processing power – perhaps justifying the crime on the grounds that nobody was using it anyway. The approach would be along SETI’s lines, but without SETI’s public presence. Download a suitable bit of software to each of several million unknowing helpers, then use the internet to share the burden of very large computing projects among them. Charge customers for access to the worlds’ biggest computer while keeping its exact nature a trade secret. Think of Randy Schwartz – who, whether or not he stole trade secrets, had the reputation of grabbing all the CPU power he could get his hands on. Nobody has done it. My guess is that nobody will, since the continuing access is too easy to detect. But two more destructive versions have been implemented repeatedly.\nOne is called a Distributed Denial of Service attack – DDOS, for short. To do it, you temporarily take over a large number of networked computers and instruct each to spend all of its time trying to access a web page belonging to some person or organization you disapprove of. A web server can send out copies of its web page to a lot of browsers at once, but not an unlimited number. With enough requests coming fast enough, the server is unable to handle them all and the page vanishes from the web.\nA second reason to temporarily take over lots of computers that don’t belong to you is to solve the spam problem – not the problem that you and I face in dealing with in-boxes clogged by hundreds of offers to expand various parts of our anatomy but the problem faced by the people sending spam. If you send it from your own computer, you might get into trouble – if not with the recipients, then with your own ISP. One solution is to use a computer virus to modify lots of other people’s computers in a way that gives you temporary access to them and then use them as your unwitting accessories.4\nSpam itself provides multiple examples of computer crimes made possible by the existence of enormous numbers of networked computers. Nobody with any sense would believe an email from a stranger in Nigeria offering to give him millions of dollars – after he first provides some small financial evidence of his reliability. But if you send out such an offer to a billion email addresses, ten million of which turn out to be actual people, you will reach the small minority of those ten million who are sufficiently credulous, or sufficiently greedy, to fall for the scam. A small minority of ten million people can still be a large number.\nDISTRIBUTED COMPUTING: THE SOLUTION THE PROBLEM COMES FROM\nMost of the problems we have been discussing involve software downloaded from a web page to a user’s computer. Such software originated as a solution to one of the problems of networked computing: server overload.\nYou have a web page that does something for the people who access it – draws a map showing them how to get to a particular address, say. Drawing that picture – getting from information on a database to a map a human being can read – takes computing power. Even if it does not take very much power, when 1,000 people each want a different map drawn at the same time it adds up and your system slows down.\nEach of those people is accessing your page from his own computer. Reading a web page does not take much in the way of computing resources, so most of those computers are twiddling their thumbs – operating at far below capacity. Why not put them to work drawing maps?\nThe web page copies to each of the computers a little map-drawing program – an ActiveX control or Java applet. That only has to be done once. Thereafter, when the computer reads the web page, the page sends it the necessary information and it draws the map itself. Instead of putting the whole job on one busy computer it is divided up among 1,000 idle computers. The same approach – distributed computing – works for multiplayer webbed games and many other applications. It is a solution – but a solution that, as we have just seen, raises a new problem. Once that little program gets on your computer, who knows what it might do there?\nMicrosoft deals with that problem by using digital signatures authenticated by Microsoft to identify where each ActiveX control comes from. Microsoft’s response to the Chaos Computer Club’s demonstration of a new use for an ActiveX control was that there was really no problem. All a user had to do to protect himself was to tell his browser, by an appropriate setting of the security level on Explorer, not to take controls from strangers.\nThis assumes that nobody can fool Microsoft into signing bogus code. I can think of at least two ways of doing it. One is to get a job with a respectable software company and insert extra code into one of their ActiveX controls, which Microsoft would then sign. The other is to start your own software company, produce useful software that makes use of an ActiveX control, add an additional unmarked feature inspired by the Chaos Computer Club, get it signed by Microsoft, put it up on the web, then close up shop and decamp for Brazil.\nSun Computer has a different solution to the same problem. Java applets, their version of software for distributed computing, are only allowed to play in the sandbox, designed to have a very limited ability to affect other things in the computer, including files stored on the hard drive. One problem with that solution is that it limits the useful things an applet can do. Another is that even Sun sometimes makes mistakes. The fence around the sandbox may not be entirely applet-proof.\nThe odds are\nboth ActiveX and applets will soon be history. Whatever form\ndistributed computing succeeds them will face the same problem\nthe same set of possible solutions. In order to be useful, it\nbe able to do things on the client computer. The more it can\ngreater the danger of its doing things that the owner of that\ncomputer would disapprove of. That can be controlled either by\ncontrolling what gets downloaded and holding the firm that\nit responsible for the software’s behavior or by strictly\nwhat any such software is allowed to do – Microsoft’s and\nReaders with high-speed internet connections may at this point be wondering if they ought to pull the plug. I don’t think so – and I haven’t.\nThere are two important things to remember about the sort of problem we have been discussing. The first is that it is your computer, sitting on your desktop. A bad guy may be able to get control of it by some clever trick, by getting you to download bogus software or a virus. But you start with control – and whatever the bad guy does, you can always turn the machine off, boot from a CD, wipe the hard drive, restore from your backup, and start over. The logic of the situation favors you. It is only bad software design and careless use that makes it possible for other people to take over your machine.\nremember is that this is a new world and we have just arrived.\ndesktop computers are running under software originally\nstand-alone machines. It is not surprising that such software\nfrequently proves vulnerable to threats that did not exist in\nenvironment it was designed for. As software evolves in a\nworld, a lot of the current problems will gradually vanish.\nUntil the next innovation.\nTHE WORM TURNS: CLIENTS FOOLING SERVERS\nWe have been discussing crimes committed by a server against clients – downloading chunks of code to them that do things their owners would not approve of. I once got into an interesting conversation with someone who had precisely the opposite problem. He was in the computer gaming business – online role-playing games in which large numbers of characters, each controlled by a different player, interact in a common universe, allying, fighting each other, gaining experience, becoming more powerful, acquiring enchanted swords, books of spells, and the like.\nPeople running online games want lots of players. As more and more players join, the burden on the server supporting the game increases, since it has to keep track of the characteristics and activities of an increasing number of characters. Ideally, a single computer should keep track of everything in order to maintain a consistent universe, but there is a limit to what one computer can do.\nOne solution is distributed computing. Offload most of the work to the player’s computer. Let it draw the pretty pictures on the screen, maps of a dungeon or a fighter’s eye view of the monster he is fighting. Let it keep track of how much gold the character has, how much experience he has accumulated, what magic devices are in his pouch, what armor on his back. The server still needs to keep track of the shared fundamentals – who is where – but not the details. Now the game scales; when you double the number of players you almost double the computing power available, since the new players’ computers are now sharing the load.\nLike many solutions, this one comes with a problem. If my computer is keeping track of how strong my character is and what goodies he has, that information is stored in files on my hard drive. My hard drive is under my control. With a little specialized knowledge about how the information is stored – provided, perhaps, by a fellow enthusiast online – I can modify those files. Why spend hundreds of hours fighting monsters in order to become a hero with muscles of steel, lightening reactions, and a magic sword, when I can get the same result by suitably editing the file describing my character? In the online gaming world, where many players are technically sophisticated, competitive, and unscrupulous – or, if you prefer, where many players regard competitive cheating as merely another dimension of the game – it is apparently a real problem. I offered him a solution; I do not know if he, or anyone else, has tried implementing it.\nThe server cannot be bothered to keep track of all the details of all the characters, but it can probably manage 1 in 100. Pick a character at random and, while his computer is calculating what is happening to him, run a parallel calculation on the server. Follow him for a few days, checking to make sure that his characteristics remain what they should be. If they do, switch to someone else.\nWhat if the character has mysteriously jumped twenty levels since the last time he logged off? Criminal law solves the problem of deterring offenses that are hard to detect – littering, for example – by scaling up the punishment to balance the low probability of imposing it. It should work here too.\nI log into the game where my character, thanks to hundreds of hours of playing assisted by some careful hacking of the files that describe him, is now a level 83 mage with a spectacular collection of wands and magic rings. There is a surprise waiting:\n\"You wake up in the desert, wearing only a loin cloth. Clutched in your hand is a crumpled parchment.”\n\"Look at the Parchment.”\n\"It looks like your handwriting, but unsteady and trailing off into gibberish at the end.”\n\"Read the Parchment.”\nThe parchment reads:\n\"I shouldn’t have done it. Dabbling in forbidden arts. The Demons are coming. I can feel myself pouring away. No, No, No … .”\n\"Show my statistics.”\nPossessions: 1 loincloth.\n5HIGH-TECH TERRORISM: NIGHTMARE OR EMPLOYMENT PROJECT?\nA few years ago, I participated in a conference called to advise a presidential panel investigating the threat of high-tech terrorism. So far as I could tell, the panel originated with an exercise by the National Security Agency in which they demonstrated that, had they been bad guys, they could have done a great deal of damage by breaking into computers controlling banks, hospitals, and much else.\nI left the conference uncertain whether what I had just seen was a real threat or an NSA employment project, designed to make sure that the end of the Cold War did not result in serious budget cuts. Undoubtedly a group of highly sophisticated terrorists could do a lot of damage by breaking into computers. But then, a group of sophisticated terrorists could do a lot of damage in low-tech ways too. I had seen no evidence that the same team could not have done as much damage – or more – without ever touching a computer. A few years after that conference, a group of not very sophisticated terrorists demonstrated just how much damage they could do by flying airplanes into buildings. No computers required.\nI did, however, come up with one positive contribution to the conference. If you really believe that foreign terrorists breaking into computers in order to commit massive sabotage is a problem, the solution is to give the people who own computers adequate incentives to protect them, to set up their software in ways that make it hard to break in. One way of doing so would be to decriminalize ordinary intrusions. If the owner of a computer cannot call the cops when he finds that some talented teenager has been rifling through his files, he has an incentive to make it harder to do so in order to protect himself. Once the computers of America are safe against Kevin Mitnick,6 Osama bin Laden won’t have a chance.\n1 A timeline of hacker history and an account of a legal setback for the Secret Service. For one early computer crime case see United States v. Jones, United States Court of Appeals Fourth Circuit 553 F.2d 351 (1977)\n2 Parker, 1983, pp. 50–51.\n4 A description of how DDOS attacks work. Lots of stories and discussions on attacks. A story on an extraordinarily sophisticated attack, via a computer worm, on Iran's nuclear program. An earlier but probably more reliable account—by a security expert, not a reporter. [Not in the hardcopy of the book--added 11/30/2010]", "label": 1}
{"text": "Top 10 tips for staying safe online\nWhile the ever-evolving conveniences of online shopping and digital communication often make life a little easier, sharing valuable information over the Internet comes with a considerable amount of risk. Consumers should not only be aware of the dangers of being online, but should also take preventative measures to avoid becoming a victim of online scams or fraud.\n“Protecting valuable information online is just as important as securing a home, car or personal possessions,” says Rebecca Smith, vice president of marketing for Master Lock. “It is essential that people educate themselves and take the proper precautions to safeguard their information online, ensuring important account data and passwords are protected within the digital space.”\n1. Firewalls are your friend: Be sure to activate your computer’s firewalls as they are great tools to provide you with a line of defense against hackers and Internet crime. Firewalls monitor all the communication occurring between your computer, a network (say at the office) and the Internet and can prevent strangers from accessing your information.\n2. Surf and shop safely: Consumers should be careful when surfing or shopping on a site they’ve never visited before. Good indicators that a site is secure include checkout pages with lock symbols or sites with the prefix \"https,\" indicating that a page is encrypted or scrambled.\n3. Download security software: There is a wide variety of security software available that automatically updates itself and can protect your personal computers from viruses, spyware and other online threats that are constantly in play. Sign on and scan your computer for viruses and other malware once a week to ensure your information stays safe.\n4. Create strong passwords: Short, easy-to-remember passwords, are typically not complex enough to prevent being hacked. When creating passwords for online bank accounts and other sites, use passwords with at least 10 characters that are a combination of letters, numbers and most importantly, symbols. It’s also a good idea to change your passwords on a monthly basis to keep it secure.\n5. Be cautious: Avoid posting any personal information online, do not open email messages from strange addresses and never give your browser permission to remember your passwords.\n6. Shut it down: We all know that with many advances in technology, one can be connected at all times. However, being online 24/7 comes with risks. Attackers and/or viruses are more likely to target your computer if you are always connected.\n7. Back it up: Consider backing up all of your most important information at least twice a month and rest easy knowing it is stored safely in more than one place.\n8. Use parental controls: Many Internet browsers offer the option to set parental controls. Check out your options to restrict the websites viewed on your computer and protect the settings you select with a password your kids won’t be able to figure out. This way, you’re keeping your information, and more importantly, your children safe from various online dangers.\n9. Lock up your valuable info: Consider utilizing a secure, online storage application or website, such as the free Master Lock Vault, to house all of your passwords, account numbers and essential information and documents under one easily accessible, yet completely secure location. Storing this information online is safer than keeping hard copies or a non-protected file on your computer. Services like the Vault can act as an encrypted digital safe deposit box and give users peace of mind that their vital information is locked up tight.\n10. Two is better than one: User authentication, also known as two-tier or device authentication, should always be enabled if offered by sites that collect your secure or private data at registration. With this enabled, you may receive an email or text message with a verification code to complete your account set-up. While this may seem inconvenient at the time of sign-up, the extra protection is well worth this extra step.\nFor more advice on online safety and security, visit www.masterlock.com or www.masterlockvault.com.", "label": 1}
{"text": "Does the name Bradley Manning mean anything to you? If you’re a government organization, the name is synonymous with “colossal data breach” – as Manning spearheaded the biggest leak of classified information in our nation’s history.\nTo briefly recap, Manning, a U.S. Army soldier, single handedly accessed more than 900,000 intelligence documents, including daily war logs from military operations in Afghanistan and Iraq. And he did it by downloading files onto CDs labeled “Lady Gaga”, which he shared with the whistleblower site, WikiLeaks.\nAccording to Manning’s published chat logs, the event was “childishly easy”; “no one expected a thing”; and the “weak servers, weak logging, weak physical security, weak counter-intelligence, and inattentive signal analysis created a perfect storm.”\nWith Manning’s trial just a few months away, we take a look back to share three important lessons learned from this monumental event:\nLesson #1: DLP is Important: While Manning had access to a classified network used by the Department of Defense and the State Department, having a data loss prevention (DLP) solution in place that scanned information, across all network points before it left the network, would have provided an additional line of defense to prevent the data from being downloaded – to a CD, flash drive, or any other storage mechanism.\nLesson #2: It’s Time to Cast a Wider Security Net: Because most government agencies are large, data security can be focused on the “core” or interior of the network versus the perimeter of the organization. But, big data security challenges arise as employees have new ways to view and share confidential data – via BYOD movements, wireless access points, and consumer-based, third-party file sharing sites. Now that networks have become more decentralized, agencies need to deploy a wider “net” to secure and manage data.\nLesson #3: Security and Large File Size Aren’t Mutually Exclusive: Large data transfers are not only common within the government domain, they are often required. But how are agencies securing and managing that data? And, can large files be shared simply and on demand? To address these needs, organizations are turning to mobile file sharing solutions that give employees the ability to send and synchronize large, classified and confidential documents with ease, while giving IT the security, authentication, encryption and file tracking and reporting capabilities necessary to support data security best practices.\nThese are three key lessons to remember as we move into 2013 and strive to keep newsworthy security breaches a part of our past, fully protecting government data exchanges of the future.", "label": 1}
{"text": "Protecting the American people from terrorist threats is the reason the Department of Homeland Security was created, and remains our highest priority.\nWe protect the nation’s health security by providing early detection and early warning of bioterrorist attacks.\nSome chemical facilities possess materials that could be stolen and used to make weapons. A successful attack on certain high-risk facilities could cause a significant number of deaths and injuries.\nThe threat posed by violent extremism is neither constrained by international borders nor limited to any single ideology.\n- Critical infrastructure is the physical and cyber systems and assets so vital to the United States that their incapacity or destruction would have a debilitating impact on our physical or economic security or public health or safety.\nDHS works to enhance the nation’s counter-IED capabilities and reduce the threat of explosive attack against critical infrastructure, the private sector, and federal, state, local, tribal, and territorial entities.\nA program to raise public awareness of indicators of terrorism and terrorism-related crime, and to emphasize the importance of reporting suspicious activity to the proper state and local law enforcement authorities.\nNTAS alerts communicate information about terrorist threats by providing timely, detailed information to the public, government agencies, first responders, public sector organizations, airports and other transportation hubs.\nDHS' nuclear detection and forensics missions are key elements of the U.S. government's wide-ranging approach to preventing attacks by terrorists and potential state sponsors.\nProtecting the United States from terrorism is the founding mission of DHS. While America is stronger and more resilient as a result of a strengthened homeland security enterprise, threats from terrorism persist and continue to evolve.\nWritten testimony of NPPD for a House Homeland Security Subcommittee on Cybersecurity hearing titled “Facilitating Cyber Threat Information Sharing & Partnering with the Private Sector to Protect Critical Infrastructure: An Assessment of DHS Capabilities”\nMay 16, 2013\nWritten testimony of the USCG for a Senate Appropriations Subcommittee on Homeland Security hearing on the Coast Guard’s Fiscal Year 2014 Budget Request\nMay 14, 2013", "label": 1}
{"text": "1 Systems Security\na. Differentiate among various systems security threats.\nb. Explain the security risks pertaining to system hardware and peripherals\nc. Implement OS hardening practices and procedures to achieve workstation and server security.\nd. Carry out the appropriate procedures to establish application security\ne. Implement security applications.\nf. Explain the purpose and application of virtualization technology\n2 Network Infrastructure\na. Differentiate between the different ports & protocols, their respective threats and mitigation techniques.\nb. Distinguish between network design elements and components\nc. Determine the appropriate use of network security tools to facilitate network security.\nd. Apply the appropriate network tools to facilitate network security\ne. Explain the vulnerabilities and mitigations associated with network devices\nf. Explain the vulnerabilities and mitigations associated with various transmission media\ng. Explain the vulnerabilities and implement mitigations associated with wireless networking.\n3 Access Control\na. Identify and apply industry best practices for access control method\nb. Explain common access control models and the differences between each\nc. Organize users and computers into appropriate security groups and roles while distinguishing between appropriate rights and privileges\nd. Apply appropriate security controls to file and print resources\ne. Compare and implement logical access control methods\nAlthough not a prerequisite, it is recommended that CompTIA Security+ candidates have at least two years of on-the-job technical networking experience, with an emphasis on security. The CompTIA Network+ certification is also recommended.\nAfter completing this course, students will be prepared for\nCompTIA Security+ 2008 certification exam SY0-201", "label": 1}
{"text": "The Windows 7 firewall controls traffic that your computer exchanges with the network or Internet and it uses rules to control this behaviour. A single firewall rule allows you to control how a specific type of network traffic behaves.\nThe best to way to understand WFAS (Windows Firewall with Advanced Security) is by setting up a test rule as we are going to see in this article. We will configure a firewall rule that accepts only authenticated RDP (Remote Desktop Protocol) connections from hosts on a specific or same subnet:\nWindows Firewall and WFAS work together on Windows 7 computers. WFAS allows you to configure inbound and outbound firewall rules based on ports, programs, and services. In addition, it allows you to set a rule scope and authentication. In this article we will see the main configuration elements you need to know when creating firewall rules using the WFAS.\nWindows Firewall with Advanced Security (WFAS) allows you to create rules based on port addresses and services, unlike the basic Windows Firewall where you can create rules based on programs. The basic Windows Firewall should be enough for the normal safe operation of your computer but advanced users can use WFAS to:\nWindows 7 native firewall is based on two sets of rules that complement each other. The basic Windows Firewall uses simple rules that directly relate to a program or service while the Windows Firewall with Advanced Security (WFAS) allows for more complicated rules that filter traffic on the basis of port, protocol, address and authentication.", "label": 1}
{"text": "A network firewall\nprotects a computer network from unauthorized access. Network firewalls may be hardware devices, software programs, or a combination of the two.\nNetwork firewalls guard an internal computer network (home, school, business intranet) against malicious access from the outside. Network firewalls may also be configured to limit access to the outside from internal users.\nNetwork Firewalls and Broadband Routers\nMany home network router products include built-in firewall support. The administrative interface of these routers include configuration options for the firewall. Router firewalls can be turned off (disabled), or they can be set to filter certain types of network traffic through so-called firewall rules\nNetwork Firewalls and Proxy Servers\nAnother common form of network firewall is a proxy server. Proxy servers act as an intermediary between internal computers and external networks by receiving and selectively blocking data packets at the network boundary. These network firewalls also provide an extra measure of safety by hiding internal LAN\naddresses from the outside Internet. In a proxy server firewall environment, network requests from multiple clients appear to the outsider as all coming from the same proxy server address.\nAlso Known As: proxy, gateway", "label": 1}
{"text": "First, when you're talking about encrypting passwords, then sending them to the server, that implies to me that you are storing the password in plain text, which is a very bad idea (if you are encrypting them in the database, it is slightly better, but still not ideal, since the key would still be stored on the server somewhere in plain text).\nNo, you're quite incorrect. PHP's encryption function resides on the server itself. He's not storing the passwords as unencrypted text, however, he is sending it unencrypted via the wire (from the browser to the server). His best bet is to get SSL encryption on the domain itself (https://) so everytime he logs in, the request (and corresponding response) is hashed using the latest algorithms.\nI think there is a bit of confusion with our definitions. When I'm saying encryption, I'm meaning applying a key to some plain text to encrypt it, so that it can be decrypted at a later date (such as AES, RSA, HTTPS, etc). By hashing, I mean applying an algorithm on some plain text to encrypt it, so that it cannot be decrypted later, by anyone (such as MD5, SHA-1, SHA-256, etc; not HTTPS).\nHe was talking about two different things: encryption between the client and the server and encrypting/hashing the passwords in the database. You're correct that the PHP/MySQL functions will handle the encryption/hashing of the passwords in the database, but they will do nothing for encrypting the communication between the client and the server (he'll need HTTPS).\nSecond, PHP code is not executed on the client's machine, so even if you did encrypt the password with PHP, it would still be sent to you in plain text, which is bad.\nThis is vague. When the client causes a POST in a form, the password is sent to the server unhashed. All HTTP traffic is insecure, if you want to secure traffic then use HTTPS (but you need to purchase an SSL license). This way, even if the user enters his password, the browser encrypts the request and sends it to the server encrypted.\nThat's correct (he could use a self-signed certificate for free, but that is not as secure as one from a certificate authority - i.e. if you can afford one, buy it).\nThat's one way of doing it. Sending it via an HTTPS session secures the unencrypted password over the wire by encrypted the request in itself.\nOn further thought, I don't think the first hash is necessary (the one done on the client's machine), because if they can get that hash, they can get access to the account, and if they have your password, they can determine the hash.", "label": 1}
{"text": "Implantable Medical Devices with Wireless Pose Threats\nSome medical devices such as implantable cardiac defibrillators and pacemakers are now equipped with wireless technology, allowing for remote device checks and freeing patients from repeated doctor visits. But this convenience may come with unanticipated risks. A team of researchers from three leading universities has demonstrated that patients’ private medical information could be extracted and their devices reprogrammed without the patients’ authorization or knowledge.\nThere has never been a reported case of a patient with an implantable cardiac defibrillator or pacemaker being targeted by hackers, and the researchers emphasized that the study was designed to identify and prevent future problems. Undertaking the study required a high level of technical expertise, and the published paper omits certain details in methodology that prevents the findings from being used for anything other than improving patient security and privacy.\nThe study was led by two computer scientists, Tadayoshi Kohno of the University of Washington and Kevin E. Fu of the University of Massachusetts Amherst, and cardiologist Dr. William H. Maisel of the Beth Israel Deaconess Medical Center and Harvard Medical School. Their scholarly peer-reviewed report will be presented and published at the Institute of Electrical and Electronic Engineers Symposium on Security and Privacy in Oakland, Calif., May 19, 2008.\nDr. Maisel, director of the Medical Device Safety Institute at Beth Israel Deaconess Medical Center in Boston, notes, “One of the purposes of this research is to encourage the medical device industry to think more carefully about the security and privacy of patient information, particularly as wireless communication becomes more common. Fortunately, there are some safeguards already in place, but device manufacturers can do better.”\nThe team expects this issue to take on greater importance as implantable cardiac defibrillators operate wirelessly at greater distances. These devices typically receive short-range wireless signals over several feet, but new technologies are expanding that reach even farther, creating the potential for information to be intercepted en route.\n“We hope our research is a wake-up call for the industry,” said Kohno, an assistant professor of computer science and engineering at the University of Washington. “In the 1970s, the Bionic Woman was a dream, but modern technology is making it a reality. People will have sophisticated computers with wireless capabilities in their bodies. Our goal is to make sure those devices are secure, private, safe and effective.”\nFu, an assistant professor of computer science at UMass Amherst, noted that the study developed several prototype defenses. “One of our primary contributions is the invention of three defense mechanisms that require no battery power, making them potentially easy to incorporate in the devices without extensive redesigning. While there has been much research that explores the biological safety of implantable medical devices, there is limited understanding about the related issues of wireless security and privacy. Understanding the security and privacy of implantable devices is essential for protecting the nation’s health and cyber infrastructure.”\nThe researchers’ experiments used an implantable cardiac defibrillator, a sophisticated device that automatically regulates the heart beat by sending small electrical signals to the heart to stimulate the heart rate or by delivering a large shock to restore a potentially fatal heart rhythm back to normal. Implantable defibrillators have improved survival in selected patients at risk for sudden cardiac death, and millions of the devices have been implanted worldwide. The model used in the researchers’ experiment contained computers and radios that allow health-care practitioners to diagnose patients, read and write private medical information, and adjust the device’s therapy settings wirelessly.\nIn computer laboratory bench tests, the research team used an inexpensive software radio to intercept and capture signals sent from the implantable device. They were able to obtain detailed information about a hypothetical patient, including name, diagnosis, date of birth and medical ID number. Researchers could determine the make and model of the device and access real-time electrocardiogram results as well as data on the hypothetical patient’s heart rate and cardiac activity.\nThe team then mounted several attacks. Researchers were able to turn off the therapy settings stored in the implantable device, rendering it incapable of responding to dangerous cardiac events. Additional commands were delivered, resulting in the delivery of a shock that could induce ventricular fibrillation, a potentially lethal arrhythmia.\nThree deterrence and prevention mechanisms were developed as part of the study, including a notification device that audibly alerts patients of security sensitive events, a device that authenticates requests for access from outside devices and a vibrating device that patients can sense. All three mechanisms require no power from the battery, and one of them was evaluated for effectiveness in a substance similar to human tissue.\nBecause the team studied one common model of implantable cardiac defibrillator, the susceptibility of similar devices to privacy and security risks is uncertain. The researchers believe future studies are needed to assess potential risks associated with other implantable devices equipped with wireless technology. The researchers feel strongly that nothing in their report should deter patients from receiving these devices if recommended by their physician. The implantable cardiac defibrillator is a proven, life-saving technology.\nPhoto Caption: Professors Kevin Fu (UMass, third from left) and Tadayoshi Kohno (UW, far right), with Ph.D. students (from left to right) Daniel Halperin (UW), Benjamin Ransford (UMass), Benessa Defend (UMass), and Shane Clark (UMass). Photo credit: Ben Barnhart.\nOn the Net:", "label": 1}
{"text": "First mobile phone virus identified\nA Series 60 mobile phone displays the Cabir virus message. Photo: http://symantec.com\nThe first ever computer virus that can infect mobile phones has been discovered, according to anti-virus software developers.\nThe French unit of the Russian security software developer Kaspersky Labs said that that virus - called Cabir - appears to have been developed by an international group of hackers called 29A, who specialise in creating \"proof of concept\" viruses which try to show that no technology is reliable and safe from their attacks.\n29A is the hexadecimal (a number system used in computing) equivalent of \"666\", otherwise known as the devil's number.\nCabir infects the Symbian operating system that is used in several makes of mobiles, notably the Nokia brand, specifically the Nokia Series 60 mobile.\nIt propagates through the new bluetooth wireless technology that is in several new mobile phones, scanning for other phones using Bluetooth wireless technology, then sends a copy of itself to the first vulnerable one it finds.\nOnce the worm is running, it will constantly search for Bluetooth-enabled devices, vastly shortened battery life because of the constant scanning.\nIf the virus succeeds in penetrating the phone, it writes the inscription 'Caribe' on the screen and is then activated every time that the phone is turned on.\n29A sent the code to anti-virus software developers on Tuesday, who have since verified in lab test that it can be spread from phone to phone.\nAs the virus has only been circulated in a controlled laboratory setting, it poses no risk to the wider public. There are no known cases of it \"in the wild\".\n29A is credited with the release of a recent virus called \"Rugrat\" that targets Windows 64 bit operating systems.\nIn May, researchers from the Symantec anti-virus software group identified W634.Rugrat.3344 and linked it to a family of six viruses that are all believed to be the work of the same author or group of authors. Each of the viruses demonstrates a different \"first ever\" infection technique.\nAccording to the anti-virus software developer F-Secure, the discovery of Cabir is proof that the technologies are now available to create viruses for mobile phones and that they are now known to the writers of computer viruses.\nAnti-virus experts have been warning for months that mobile phone viruses are set to multiply, given the increasingly diverse uses of mobile phones.\nIn 2000, the virus Timifonica forced infected PCs to send text messages to phones, but the Cabir virus is thought to be the first to spread from phone to phone.", "label": 1}
{"text": "In storage networking terminology, a Storage Area Network (SAN) is a high-speed subnetwork of shared storage devices. A storage device is a machine that contains nothing but a disk or disks for storing data.\nA SAN's architecture works in a way that makes all storage devices available to all servers on a LAN or WAN. As more storage devices are added to a SAN, they too will be accessible from any server in the larger network. In this case, the server merely acts as a pathway between the end user and the stored data.\nBecause stored data does not reside directly on any of a network's servers, server power is utilized for business applications, and network capacity is released to the end user.\nLearn more about storage networking on Enterprise Storage Forum.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "Windows NT has always had a rich access control model\nto protect sensitive system resources from modification by or\ndisclosure to unauthorized entities. Within this model, user accounts\nare typically given Administrator rights or User rights. Administrators\nhave complete and unrestricted\naccess to the computer and all its resources, while Users are\nrestricted from making changes to operating system configuration or\naccessing data belonging to other users. For historical reasons,\nhowever, until recently end users on Windows computers were frequently\ngranted administrative access, so many people have remained unaware that\nthese distinctions exist. (Even today, the first local user account\ncreated on a Windows 7 computer is a member of the Administrators\nUsers can have effective\nadministrative control over a computer without explicit membership in\nthe Administrators group if they are given the ability to configure or\ncontrol software that runs in a more powerful security context—for\nexample: granting users control over systemwide file or registry\nlocations used by administrators or services (as Power Users had before\nWindows Vista); granting users “admin-equivalent” privileges such as the\nDebug, Take-Ownership, Restore, or Load Driver privileges; or enabling\nthe AlwaysInstallElevated Windows Installer policy, under which any MSI\nfile launched by any user runs under the System account.\nwishing to improve security and reduce costs have begun moving toward a\n“non-admin” model for their end users. And with Windows Vista’s\nintroduction of User Account Control (UAC), most programs run by\nusers—including those who are members of the Administrators\ngroup—execute with user rights, not administrative rights. However, it\nsometimes becomes necessary to run a program with administrative rights.\nWhile many people didn’t know how to do this in Windows XP, Windows\nVista changed those methods significantly.\nMany of the\nSysinternals utilities always require administrative rights, while many\nhave full functionality without them. Some, however, are able to work\ncorrectly with standard user rights but have features that need\nadministrative rights, and thus operate in a “partially degraded” mode\nwhen executed with standard user rights.\n1. Running a Program with Administrative Rights on Windows XP and Windows Server 2003\nIf you log on to a Windows XP or\nWindows Server 2003 computer with an account that is a member of the\nAdministrators group, no special steps are required to run a\nSysinternals utility with administrative rights. Every program you run has full administrative rights.\nBut if you log on to that\nsame computer with an account that does not have the required\nprivileges to run a particular Sysinternals utility, you will need to\nget the administrative rights from a different user account. The\nSecondary Logon (Seclogon) service enables programs to start a new\nprocess as a different user on the current desktop by supplying\nalternative credentials. Two programs that expose this functionality are\nExplorer’s Run As dialog box and the Runas.exe command-line utility.\nuse the Run As dialog box to start a program with administrative\nrights, right-click on any program or shortcut in Explorer or the Start\nmenu and choose Run As from the context menu. In the Run As dialog box,\nchoose the second radio button (“The Following User) as shown in Figure 1,\ntype the credentials for an administrative account, and click OK. You\ncan make Run As the default for a shortcut by opening its Properties\ndialog box, clicking the Advanced button, and selecting the “Run With\nDifferent Credentials check box.\nFigure 1. The Windows XP Run As dialog box with the second radio button selected.\nTo start a program\nwith administrative rights with the Runas.exe command-line utility, open\na command prompt and start Runas.exe with this syntax:\nrunas /u:username program\nFor example, to run Process Monitor (Procmon.exe) with the local Administrator account, run the following command:\nrunas /u:administrator procmon.exe\nAfter you press Enter,\nRunas.exe prompts you for the account’s password. You must type the\npassword at the prompt; Runas.exe does not accept a password on the\ncommand line nor piped to it from the standard input stream. You can use\nthe /savecred command-line option to save the account’s password the first time you enter it; subsequent use of /savecred\nwith the same account will retrieve the saved password so that you\ndon’t have to enter it again. While this behavior is convenient, note\nthat the standard user under whose account the administrator’s password\nis saved can now use Runas.exe to launch any program without having to supply the password.\nTo use smartcard authentication instead of password authentication, add the /smartcard option to the command line. You will be prompted for a smartcard PIN instead of a password.\nmore information and tips about using RunAs, see Aaron Margosis’ “RunAs\nbasic (and intermediate) topics” blog post at the following URL:\nIf you need the\nSysinternals utility to run with full administrative rights but under\nyour nonadministrator account (for example, so that it can authenticate\nto domain resources), you can use Aaron Margosis’ MakeMeAdmin script. It\ninvokes Runas.exe twice to launch a command prompt that runs under your\ncurrent account but with full administrative rights. (Note that you\nmust have credentials for an administrative account to make this work.)\nFor more information, see his “MakeMeAdmin — temporary admin for your\nLimited User account” blog post at the following URL:\n2. Running a Program with Administrative Rights on Windows Vista or Newer\nWindows Vista and\nUAC changed everything when it came to running programs with\nadministrative rights. Running as a standard user is now the default\nstate for users’ programs, even when run by a member of the\nIf you log on to a computer\nrunning Windows Vista or newer with an account that is a member of\nAdministrators (the first account is the only one that defaults to\nAdministrators group membership on computers not joined to a domain) or\nanother powerful group such as Backup Operators or that has been granted\n“admin-equivalent” privileges, the Local Security Authority (LSA)\ncreates two logon sessions for the user, with a distinct access token\nfor each. One of these tokens represents the user’s full rights, with all groups and privileges intact. The other is a filtered\ntoken that is roughly equivalent to one belonging to a standard user,\nwith powerful groups disabled and powerful privileges removed. This\nfiltered token is used to create the user’s initial processes, such as\nUserinit.exe and Explorer.exe, and is inherited by their child\nprocesses. Starting a process with the user’s full token requires UAC\nelevation, mediated by the Application Information (Appinfo) service.\nThe Runas.exe command is still present, but it does not invoke the\nAppinfo service—so its effect is not quite the same as it was on Windows\nXP. If you start a program with Runas.exe and specify an administrative\naccount, the target program runs under the “standard user” version of\nUAC elevation can be triggered for a new process in one of several ways:\nThe program file\ncontains a manifest that indicates that it requires elevation.\nSysinternals GUI utilities such as Disk2Vhd and RAMMap that always\nrequire elevation contain such manifests.\nuser explicitly requests that the program run elevated—for example, by\nright-clicking it and choosing Run As Administrator from the context\nheuristically determines that the application is a legacy installation\nprogram. (Installer detection is enabled by default, but it can be\nturned off through a security policy.)\nThe application is associated with a compatibility mode or shim that requires elevation.\nIf the parent process is\nalready running with an administrative token, the child process simply\ninherits that token and the UAC elevation sequence is not needed. By\nconvention, console utilities that require administrative rights (for\nexample, Sysinternals LogonSessions) do not request UAC elevation.\nInstead, you should start them from an elevated command prompt or\nWindows PowerShell console.\nOnce triggered, UAC elevation can be accomplished in three ways:\nThe elevation occurs without end-user interaction. This option is\navailable only if the user is a member of the Administrators group. By\ndefault in Windows 7, silent elevation is enabled for certain Windows\ncommands. Silent elevation can be enabled for all elevation requests\nthrough security policy.\nPrompt For Consent The user is prompted whether to permit the elevation to occur with a Yes/No dialog box. (See Figure 2.)\nThis option is available only if the user is a member of the\nAdministrators group and is the default (for elevations other than the\ndefault silent elevations of Windows 7).\nPrompt For Credentials The user is prompted to provide credentials for an administrative account. (See Figure 3.)\nThis is the default for nonadministrative accounts and is the only way\nthat UAC elevation can be achieved by a nonadministrative user. You can\nalso configure this option for administrative users with a security\nNote that UAC elevations can\nbe disabled for standard users via security policy. When the policy is\nconfigured, users get an error message whenever an elevation is\nFigure 2. Windows 7 elevation prompt for consent.\nFigure 3. Windows 7 elevation prompt for credentials.\nUser Account Control is disabled, Windows reverts to a mode similar to\nthat of Windows XP. In that case, the LSA does not create filtered\ntokens, and programs run by members of the Administrators group always\nrun with administrative rights. Further, elevation prompts do not\ndisplay, but Runas.exe can be used to start a program with\nadministrative rights. Note that disabling UAC also disables Internet\nExplorer’s Protected Mode, so Internet Explorer runs with the full\nrights of the logged-on user. Disabling UAC also turns off its file and\nregistry virtualization, a feature that enables many applications that\nrequired administrative rights on Windows XP to work with standard user", "label": 1}
{"text": "A surprising 51 percent of traffic to an average Web site -- one with 50,000 to 100,000 monthly visitors -- is potentially bot generated, according to new research from Web security and performance company Incapsula.\nOn top of that, 31 percent of overall traffic to these such sites is malicious.\nThe news is worse for very small sites -- or those with fewer than 2,500 monthly visitors. Incapsula examined more than a thousand small sites and found that 83 percent of each site's traffic comes from non-human (bad bots and good bots) with bad bots accounting for 49 percent of traffic.\nSo what is the overhead represented by this automated bot traffic? Malicious bots will try to steal data, of course. But that's only some of the harm they pose to your Web site. Hosting providers are realizing that there is increased capacity overhead for each site deployed on any server because bots waste capacity, bandwidth, and power.\nMost this automated traffic is fixed, completely unrelated to the Web site's genuine human traffic volume. In other words, each Web site spun up by a hosting provider will automatically get a set level of bot traffic no matter how many real visitors it attracts. As a result, the lower any Web site's genuine human traffic, the higher the Web site's bot traffic percentage is going to be. This rule is similar to a phenomenon seen in aerodynamics known as parasitic drag. This parasitic drag occurs when moving a solid object through a gaseous medium -- for example, an airplane wing's drag during flight.\nWeb hosting companies tend to offer small site owners shared hosting with unlimited bandwidth plans. Any small Web site owner can quickly set up a site at a fixed cost and not be charged according to their storage, bandwidth, or CPU consumption. This is financially possible for the hosting provider because they can cram hundreds of sites onto a single server and enjoy the economies of scale.\nThe paradox created is that the more Web sites the hosting provider adds to the server -- in an attempt to increase overall utilization and drive more revenue -- the more the server's utilization decreases due to the increase in bot traffic, or parasitic drag.\nIn aerodynamics, drag is determined by fancy equations that show how drag changes dynamically with speed. Not so when it comes to automated traffic. In this case, the drag is linear and proportionate to the number of sites on the server. Ironically, the drag may not be apparent to Web site owners who believe they have unlimited capacity.\nAdditional points from Incapsula's research:\n- Shared hosting providers can lose over 50 percent of their server capacity.\n- Small Web site owners' page load times are increased by more than 50 percent.\n- 25 to 50 percent of Web site visitors abandon a site when load times exceed 4 seconds.\n- SEO ranking are affected (Although impossible to quantify, parasitic drag will impact SEO rankings.)\nThe security community talks a lot about the cost of a data breach but this typically assumes that hackers only incur a cost when they're successful. This assumption misses much of the real damage and cost. In reality, nearly all Web sites -- large and small -- need to sustain about 30 percent more traffic from visitors who will never click the buy button.\nThis parasitic drag incurs a tangible cost in utilization and even an intangible cost when it comes to customer experience. Imagine, for example, the impact of removing 30 percent of cars on a heavily trafficked road. The commute becomes a lot more enjoyable.", "label": 1}
{"text": "How can I tell if my computer has a virus?\nIf you can answer \"yes\" to any of the following questions, your computer might have a virus.\nIs your computer running very slowly? A common symptom of a virus is much slower than normal computer performance. However, there can be other reasons for slow performance, including a hard disk that needs defragmenting, a computer that needs more memory (RAM), or the existence of spyware or adware. For more information about spyware, see How to tell if your computer is infected with spyware.\nAre you getting unexpected messages, or are programs starting automatically? Some viruses can cause damage to Windows or some of your programs. The results of this damage might include messages appearing unexpectedly, programs starting or closing automatically, or Windows shutting down suddenly.\nIs your modem or hard disk working overtime? An e‑mail virus works by sending many copies of itself by e‑mail. One indicator of this is that the activity light on your broadband or external modem is constantly lit; another is the sound of your computer's hard disk continually working.\nThese are not always symptoms of a computer virus, but when combined with other problems, can indicate a virus infection.\nTo check for viruses, scan your computer with an antivirus program. New viruses appear every day, so keeping your antivirus program updated is important. For more information about computer security, go to the Security at Home page on the Microsoft website. To learn how to remove malicious software (malware) from your computer, go to the Microsoft Safety Scanner webpage.", "label": 1}
{"text": "How do I avoid getting spammed?\n1. Prevention: Prevention is the best medicine so avoid giving your email address to unfamiliar recipients. Use more than one email address; one for friends, family and colleagues and second for unfamiliar sources. If you have an e-mail address that receives a large amount of spam replace it with a new address. Once your e-mail address is on a spammer's mailing lists, it is likely that you will receive increasing amounts of spam. At work, use your work email address only for work communication.\n2. Use Filters: A second way to stop spam is to use your email application's filtering features. Most email applications allow you to block specific messages. When an offending email comes in, set the filter to block further incoming mails from that sender. At the network level, implementing spam and virus checking isn't very difficult. Depending on the mail server, implementing spam filtering such that it is able to reject spam before the SMTP session is over can be difficult.\n3. Report Spammers: A more aggressive approach to ridding unwanted email is to report the e-mailer to the spammer's ISP. This is not always an easy task. First you must determine the spam's origins. Many of the bigger and more commercial ISPs forbid spammers from using their services and, once discovered, will actively ban the offending parties from using their services. To find the spam's origins, instruct your email program to display all of the email header information. View the \"Received\" lines, and working from top to bottom you can often pinpoint the origin of spam.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "A processor, or Central Processing Unit, is one of those things most people take for granted. When you first got your computer, it may have been perfect for your needs. Everything worked the way it was supposed to work. Your pages loaded quickly, applications opened and closed quickly, and you were able to download files without any trouble. Then, there comes a time when your computer isn’t processing information as quickly as it once did. This doesn’t necessarily mean that it’s time to pop for a new PC or laptop. In fact, your CPU may just need a tune-up. Here are some easy tricks to help speed up your processor and end your frustration:\nUse Free File Cleaning Programs\nThe first step in boosting the power of your process is to get rid of files and other cyber clutter that you don’t need. One such program is CCleaner. The free program removes files you don’t need to allow your computer more time for other tasks that may be more demanding. There are many other free programs like this one that you can find online. Programs like CCleaner ask you to specify which types of files that can be deleted and you do get to confirm that you want to delete files before they’re removed.\nRemove Malicious Software\nAgain, there are plenty of free programs such as Malwarebytes that can be easily downloaded. Such programs usually start with a search and find all the “bad” things on your computer and present the results as a list. You are then given a few options of how to handle those items that are questionable.\nPrograms like Avast Free Antivirus detect and remove harmful viruses that are slowing down your processor. You want to look for a program that updates its virus definitions to ward off new attacks and variations of previous viruses that may have attacked your computer. Before removing the viruses, you usually get a list of the viruses that infected your computer. This is helpful in letting you know what type of attacks to look out for in the future.\nRemove Programs You’re No Longer Using\nRun a list of all programs your computer is running. Some programs automatically start running from the moment you turn on your computer, including programs you may have previously downloaded, but no longer use on a regular basis. Make sure you properly delete all unused programs. Deleting the icon from the desktop doesn’t do anything. You should notice a change in speed the next time you turn your computer on.\nEmpty Your Recycle Bin\nJust because you send something to the recycle bin, doesn’t mean that it’s gone. Think of as the difference between putting something in a trash can and physically taking it to the curb on trash day. If you have a lot of items stored in your recycle bin, emptying it could give your CPU a noticeable boost.\nTurn Off Indexing and Check Your Bookmarks\nMost servers automatically index the sites you visit. This feature can actually take up much-needed space over time. There’s really no need to index sites you either rarely visit or only visited once. As long as we’re on the subject, see what sites you have bookmarked. Odds are that there are some sites you don’t visit anymore or links that are no longer valid.\nCheck for Spyware\nOne of the top reasons for a slow CPU is due to the presence of spyware. Even some “trusted” websites may be carriers for spyware. Free programs to find, remove, and prevent spyware installation include Ad-Aware, Giant Antispyware, and SUPERAntiSpyware.\nDelete Browsing History, Cookies, and Temporary Files\nWhile it may not seem like a big deal, your browsing history can take up space. This is especially true if you haven’t reinstalled Windows recently. The same goes for cookies and temporary files. The more “clutter” you can get rid of, the faster your CPU will be.\nTransfer Your Stored Documents\nIf there are documents you want to keep, don’t leave them all on your hard drive. Consider creating a separate partition for your documents or use an external hard drive. If you do opt for an external drive, make sure you change your defaults so downloaded files save to this drive and not your hard drive.\nJust like you may not relish the task of cleaning your room, there comes a time when it’s necessary to remove clutter. The same is true with your CPU. Taking a good hour or so to remove old files, delete temporary files and cookies, and install updated antivirus protection can save you time and endless hours of frustration when things move slower than they should. You have to put some effort into any relationship, including the one you share with your CPU.\nKathleen Martins is a blogger for TorchBrowser, learn how to download torrent files with TorchBrowser.com here.", "label": 1}
{"text": "Overview of Cryptographic Techniques\nIntroduced in Chapter 1 (Cloud Computing and Security: An Introduction), cryptography is a complex and esoteric field. In modern times, cryptography has expanded from protecting the confidentiality of private communications to including techniques for assuring content integrity, identity authentication, and digital signatures along with a range of secure computing techniques. Given that range of functional utility, cryptography has been recognized as being a critical enabling technology for security in cloud computing. Focusing on data security, cryptography has great value for cloud computing.\nTo effect cryptographic data confidentiality, plaintext is converted into cyphertext by numerous means, but the ones of practical value are all based on mathematical functions that must meet several requirements, including:\n- The algorithm and implementation must be computationally efficient in converting plaintext to cyphertext, as well as in decryption.\n- The algorithm must be open to broad analysis by a community of cryptographers and others.\n- The resulting output must withstand the use of brute force attacks even by vast numbers of computers (such as in a computing grid or cloud).\nIn operation, plaintext is encrypted into cyphertext using an encryption key, and the resulting cyphertext is later decrypted using a decryption key. In Symmetric cryptography, these keys are the same (Figure 5.3).\nFIGURE 5.3 Symmetric encryption.\nSymmetric cryptography has broad applicability, but when it is used in communication between parties, the complexity of key management can become untenable since each pair of communicators should share a unique secret key. It is also very difficult to establish a secret key between communicating parties when a secure channel does not already exist for them to securely exchange a shared secret key.\nBy contrast, with asymmetric cryptography (also known as in public–private key cryptography), the encrypt key (public key) is different but mathematically related to the decrypt or private key (Figure 5.4).\nFIGURE 5.4 Asymmetric encryption.\nThe primary advantage of asymmetric cryptography is that only the private key must be kept secret—the public key can be published and need not be secret. Although public–private key pairs are related, it is infeasible to computationally derive a private key from a public key.\nThis use of public–private keys is a great enabler for confidentiality in cloud computing, and not just for encryption of content. A private key can be used to authenticate a user or computational component, and it can also be used to initiate the negotiation of a secure channel or connection between communicating parties.\nGoing one level deeper in our background treatment of cryptography, for the purpose of this book, there are four basic uses of cryptography:\n- Block Ciphers These take as input a key along with a block of plaintext and output a block of cyphertext. Because messages are generally larger than a defined block, this method requires some method to associate or knit together successive cyphertext blocks.\n- Stream Ciphers These operate against an arbitrarily long stream of input data, which is converted to an equivalent output stream of cyphertext.\n- Cryptographic Hash Functions Hash functions take an arbitrarily long input message and output a short, fixed length hash. A hash can serve various purposes, including as a digital signature or as a means to verify the integrity of the message.\n- Authentication Cryptography is also widely used within authentication and identity management systems.\nAlthough cryptography is a cornerstone of security, many an adopter has insecurely used it or worse attempted to implement cryptography to either save money or cut corners. The field of cryptography is well beyond the scope of this book, so the reader is encouraged to refer to widely available texts on cryptography in order to develop a better understanding of cryptography, its implementation, and secure application.\nSometimes you need to transfer files via secure physical media. When you do so, it is best to have the data secured on the media. To do this, you would typically create an encrypted image first and then copy it to the physical transfer media. However, you can also use encrypting media such as hardware encrypting USB flash drives. Two of the hallmarks of such devices are automated and integral encryption/decryption and hardware-based tamper resistance. They are very good as a backup for personal or sensitive data that you do not want to include in an unencrypted full disk backup. But these devices are excellent for transferring sensitive data in a highly protected manner when the transfer has to be physical.\nSince technology changes rapidly and vendors come and go, search for tamper resistant encrypting USB drive. Some of these products use very strong cryptography, and some have additional features.", "label": 1}
{"text": "While the security industry is predicted to focus on \"strike back\" measures, WatchGuard predicts these actions will be ineffective and ultimately unviable for most organizations.\nWatchGuard's 2013 security predictions include:\nA cyber attack results in a human death\nWatchGuard hopes it is wrong in this prediction. But with more computing devices embedded in cars, phones, TVs and even medical devices, digitally dealt death is not only possible, it's plausible. Security is still often an afterthought when developing innovative technical systems.\nCriminals, hacktivists, and even nation-states are launching increasingly targeted cyber-attacks, resulting in the destruction of physical equipment. Most recently, a researcher even showed how to wirelessly deliver an 830 volt shock to an insecure pacemaker, proving that digital attacks can have a real-world impact.\nMalware enters the matrix through a virtual door\nLast year was the first real-world instance of malware that sought out virtual machines (VMs) and infected them directly. Today, there is an emergence of malicious code that can recognize when it's running in a virtual system and can act accordingly.\nIn 2013, WatchGuard predicts attackers will create even more VM-targeted malware. It will be designed to take advantage of weaknesses found in many virtual environments, while attempting to avoid virtualized automatic threat detection systems.\nIt's your browser - not your system - that malware is after\nWatchGuard anticipates a steep rise in browser-infecting malware in 2013. With increased adoption of cloud services like online banking, a great deal of personal and sensitive data passes through web browsers. Many antivirus solutions are focused on catching traditional malware which infects an operating system and aren't as effective at detecting browser-based infections. Now, a new type of malware has emerged.\nStrike back gets a lot of lip service, but does little good\n\"Strike back,\" which refers to launching a counter-offensive against cyber hackers will receive a lot of attention but won't be implemented in most organizations according to WatchGuard. \"Strike backs\" can include filing lawsuits, launching cyber espionage campaigns, or even launching counter cyber-attacks against attackers.\nWatchGuard anticipates most organizations won't implement these measures given the jurisdictional challenges of digital attacks which bounce through several countries. Plus, criminals have the ability to plant \"false flags\" in malware, tricking victims and authorities into thinking someone else is behind the attack.\nWe'll pay for our lack of IPv6 expertise\nNext year, WatchGuard expects to see an increase in IPv6-based attacks and IPv6 attack tools. While the IT industry continues to be slow at adopting IPv6 into their networks, most new devices ship IPv6-aware and can create IPv6 networks on their own.\nMany IT professionals don't have a deep understanding of IPv6's technicalities, yet they have IPv6 traffic and devices on their networks. This also means most administrators haven't implemented any IPv6 security controls, opening the door to attackers looking to exploit unprotected weaknesses.\nAndroid pick pockets try to empty mobile wallets\nBased on the following three factors, WatchGuard expects to see at least one vulnerability, even if just a proof-of-concept, that allows attackers to steal money from Android devices.\n1. Mobile malware is skyrocketing.\n2. Cyber criminals are targeting Android devices more than any other because of the platform's openness.\n3. People are increasingly using mobile devices for online payments. Plus, many vendors, including Google, are starting to launch Mobile Wallets, which attaches credit cards to mobile devices.\nAn exploit sold on the \"vulnerability market\" becomes the next APT\nWatchGuard expects that at least one auctioned-off zero day exploit will emerge as a major targeted attack this year. Vulnerability markets or auctions are a new trend in information security, allowing so-called \"security\" companies to sell zero day software vulnerabilities to the highest bidder.\nWhile they claim to \"vet\" their customers and only sell to NATO governments and legitimate companies, there are few safeguards in place to prevent nefarious entities to take advantage.\nImportant cyber security-related legislation finally becomes law\nIn 2013, expect the U.S. government to pass at least one new cyber security act, which will likely impact private organizations. The U.S. government has been trying to pass cyber security bills that give the president and various government agencies some control over what happens in the event of cyber-attack on U.S. infrastructure.\nThe government also wants more cooperation among private infrastructure organizations and U.S. intelligence agencies. Many are pressing for the government to enact more detailed cyber crimes laws, which may help prosecute digital crimes. On top of that, some organizations are lobbying for tougher digital IP enforcement, which privacy advocates often oppose. While 2012 proved to be a difficult year for passing new cyber legislation, WatchGuard expects this year to be different.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "Digital Citizenship | Feature\nExperts say that schools need to stop worrying about external internet predators and take on the threat within: cyberbullying\nIn the late 1990s and early 2000s, as schools first started getting widespread access to the internet, many administrators saw the potential in this new technology, but also huge risks and liabilities. While billions were being spent on hardware and connectivity, the mainstream media was fueling parental fears with stories of online predators waiting at every exit of the new information superhighway. The response from many schools was initially to teach internet safety in terms of protection from the two P's: predators and pornography. With funding coming from the Department of Justice, teacher training was conducted by law enforcement personnel and student assemblies often included uniformed police officers. At the same time, numerous well-meaning nonprofits appeared, seeking to help educators communicate with parents and students, but still through a lens of fear and protection.\nMany experts now believe this was very much the wrong approach. \"We missed the boat by concentrating on internet predators,\" says Patti Agatston, a nationally recognized counselor and cofounder of Cyberbullyhelp.com. Larry Magid, codirector of ConnectSafely.org, concurs that \"predation is statistically so unlikely that it's not where we should be putting our resources.\"\nThe focus today, Agatston and Magid agree, should be on empowering kids to be good digital citizens. Groups such as Common Sense Media have in recent years helped to reframe their discussion in terms of the skills students need to live successful, technology-rich 21st century lives. Acquiring these proficiencies requires a positive and more holistic approach: how to protect personal information, interact in social forums, deal with cyberbullying, and critically judge online information are all among these vital skills. By focusing on how schools do want kids to behave online rather than on how we don't want them to behave, \"We let them assume responsibility for their own learning and their own online experience,\" says Linda Burch, Common Sense Media's chief education and strategy officer.\nElevating the Issue\nCommon Sense Media, along with groups such as Media Awareness Network, BrainPop, Learning.com, and Web Wise Kids, all offer a breadth of resources to address these issues. While these organizations strongly encourage administrators to institute the full range of digital literacy curricula, the combination of students with smartphones, the expanded usage of social networking sites, and high-profile media coverage of recent cyberbullying tragedies has elevated the issue of cyberbullying to the top of many administrators' worry lists.\n\"Bullying and cyberbullying have a lot in common, but in many ways, cyberbullying is even more pernicious,\" says Anne Schreiber, vice president of education content at Common Sense Media. Schreiber points out that the cyberbully doesn't see his or her victim, which makes it easier to have less empathy than in a face-to-face interaction. What's more, anything written in a text or online chat or on a social networking site can be forwarded to any number of people with just a few clicks, escalating the problem beyond, say, a corner of the school cafeteria.\nSchreiber recounts a recent cyberbullying incident that began with a series of hostile text messages at school in the morning. By the afternoon, a fight had broken out between friends of the bully and friends of the victim--the harsh words were forwarded over and over until the whole school was involved. \"Because the bullying spread so quickly through viral texting, there was no time for the individuals to cool off and think about how to behave rationally or ethically,\" Schreiber notes.\nAdministrators can't shrug off issues of cyberbullying by arguing that the bulk of the issues happen with kids outside of school or that they simply don't have time in the school day. Agatston, who is the coauthor of Cyber Bullying: Bullying in the Digital Age, says that although she appreciates that school leaders are pressed for time to confront these issues, \"if they can see the link between academic achievement and bullying, they'll see that it's well worth the time.\" Agatston's research suggests that addressing cyberbullying in school improves attendance as well as students' focus on their schoolwork.\nWhat's needed, ConnectSafely's Magid contends, \"is a sustained campaign where bullying is as 'out' as racism or smoking.\" To accomplish this, experts suggest a unified and comprehensive approach, which requires that schools integrate cyberbullying education into their curriculum and adequately provide for teacher training.\nAgatston says that schools must cast a broad net in terms of who they involve in the discussion of safe online usage. \"Within schools we need to move from the idea of anti-bullying being the responsibility of the school counselor to being the responsibility of the whole school community, which includes parents,\" she says.\nStaff Training Is Key\nIf school leaders are going to engage more members of the school community, recent data suggests that much work still needs to be done with classroom teachers. According to a 2010 survey from the National Cyber Security Alliance, just 50 percent of teachers who participated in the study felt prepared to discuss cyberbullying. Over three quarters of teachers surveyed spent less than six hours on any type of professional development education related to cyberethics, cybersafety, and cybersecurity within the last 12 months.\nMany states around the country, including Massachusetts, Maine, and Rhode Island, as well as districts such as Kentucky's Pike County Schools, have demonstrated that programs that educate their schools and, in some cases, their entire communities about the responsible use of technology can be effective. In Pike County, for example, the district was struggling in 2007 with extensive violations of its Acceptable Use Policy (AUP). After it implemented on-site professional development to support digital citizenship, the impact has been substantial. Since 2009, only two AUP violations have been recorded.\nBurch says she's optimistic about schools' abilities to substantially curb issues of cyberbullying, pointing out that more than 12,000 schools have already registered to use Common Sense Media's curriculum. Burch also sees a range of positive signs that both government and media companies are also focusing on the issue. In March, the White House launched StopBullying.gov to offer resources for students, parents, and educators on how to detect, intervene in, follow up on, and prevent bullying, including cyberbullying. The site, which was launched in concert with a White House Conference on Bullying Prevention, serves to shine a national spotlight on the issue.\nOn the media side, MTV recently launched its \"A Thin Line\" online campaign, which offers a brief user quiz followed by short, engaging videos that each highlight the message that there's \"a thin line\" between what may begin as a harmless joke and something that could end up having a serious impact on the person playing the joke or another human being. Nickelodeon recently announced that it will be creating a series of public service announcements around the issue of internet safety and will embed themes of healthy technology usage into such popular shows as iCarly. Cable in the Classroom, the public service arm of the cable industry, has numerous educational resources on digital citizenship, including cyberbullying.\nFacebook also announced that it would be making changes to how users report inappropriate activity. A new feature, dubbed \"social reporting,\" will give users new options for reporting offensive photos or Wall posts. For example, kids can now notify a trusted source, such as a parent or teacher, of foul play. In addition, when users click \"Report\" on a photo, a pop-up window will appear asking if the photo is about the user. If it is, the user can select \"I don't like this photo\" or \"This photo is harassing or bullying me.\"\nBack at school, many districts are in need of expanding or revising their policies and procedures around dealing with these important 21st century issues. The best digital citizenship programs have a number of features in common, which administrators can consider as best practices. Agatston offers the following guidelines:\n- Assess cyberbullying: Effective bullying prevention programs begin with an assessment of the problem in your school or district.\n- Develop clear policies: Policies should address both on-campus and off-campus acts that have or could have a substantial disruption on student learning or safety.\n- Provide staff training: Just as staff training is needed to adequately address bullying behavior and encourage positive bystander behavior (and in a broader sense, \"citizenship\"), training on preventing and responding to cyberbullying, as well as the broader topic of encouraging positive digital citizenship, is a necessary part of any digital citizenship program.\n- Spend class time on the topic of cyberbullying and positive digital citizenship: Classroom discussions should be part of the regularly held discussions on bullying and cover such topics as defining cyberbullying; school policies and rules regarding cyberbullying; how to report cyberbullying behavior; how to best respond to cyberbullying behavior; and the bystander role as it applies to cyberbullying.\n- Teach students online \"netiquette,\" safe use of social media, and how to monitor their online reputation: These vital social skills also have an impact on job preparedness, as social technology is increasingly being incorporated into most career paths. Lessons can be infused throughout the curriculum where appropriate. Discussions can take place when using technology in the classroom as well as when addressing career and college guidance.\n- Train and utilize student mentors: Effective prevention programming includes incorporating youth leadership, particularly to address school climate issues. Making use of student leadership sends a strong message to other youth and also recognizes that the peer group often has more legitimacy than the teacher in addressing social issues.\n- Form parent/community/school partnerships: Everyone has a role to play in encouraging positive digital citizenship. Schools need to partner with parents and community organizations in making sure that there is a consistent message about the responsible and ethical use of technology.\nUltimately, school districts should work to foster a school environment where young people are free to express themselves and their identity online, but do it in a safe, thoughtful, and respectful manner. Burch says this comes by empowering students to see that \"we all have roles and responsibility to ourselves, to our friends and family, and to the community we belong to, whether that's a school or an organization or an online community.\" Burch believes that kids respond well when leaders cast an affirming and inclusive frame around the issue of digital citizenship. \"This is their world,\" she says. \"They want to make it a positive one.\"", "label": 1}
{"text": "March 06, 2013, 3:12 PM — Deutsche Telekom launched a Web portal Wednesday that provides a real-time visualization of cyberattacks detected by its network of sensors placed around the world.\nThe website is called Sicherheitstacho.eu and aims to provide a situational overview of global cyberattack activity. The attack data is collected by 97 sensors known as honeypot systems deployed by the company around the world.\nThese sensors serve as decoys for automated attacks targeting vulnerabilities in network services, websites, smartphones and other types of systems. The incidents are displayed in real time on an interactive map as they hit the sensors and a live ticker lists their type, their country of origin and the targeted services.\nDeutsche Telekom uses the information gathered from the sensors to protect its own systems and to warn customers about the prevalence of specific threats. The company shares the data with the authorities and other security vendors.\nThe new website also provides attack statistics for the past month. For example, it shows that network services like SMB (Server Message Block), NetBIOS or SSH are frequently targeted by automated attacks. Website vulnerabilities are the second-most-common target.\nAccording to the site, last month there were more than 27.3 million attack attempts against the SMB services mimicked by the sensors; 937,476 against the NetBIOS services; 687,446 on port 33434; 669,589 against SSH; and 522,671 on port 5353.\nThe top countries from where attacks originated were Russia (2.4 million attacks), Taiwan (907,102 attacks) and Germany (780,425 attacks). The United States was in sixth place with 355,341 attacks originating from IP (Internet Protocol) addresses in the country.\nThis is not the first real-time cyberattack map based on data collected by honeypots. The Honeynet Project, a nonprofit security research organization, launched a similar service in September 2012, but the organization maintains fewer sensors than Deutsche Telekom.\nThe new Sicherheitstacho.eu portal was unveiled at the Cebit trade show in Hanover, Germany. It was built by Deutsche Telekom as part of the company's partnership with the Alliance for Cyber Security, an initiative of the German Federal Office for Information Security (BSI) and the German Federal Association for Information Technology, Telecommunications and New Media (BITKOM).", "label": 1}
{"text": "- Security Center\n- English ▾\n- Contact Us\nGhosts, Goblins and..Botnets?\nIn the spirit of Halloween, it's the perfect time to share with you some truly spooky information.\nGhosts and goblins may just be myths, but zombies have become a real threat, at least in computer terms.\nBotnets are collections of infected, zombie computers that are controlled autonomously by attackers to send spam remotely, install more spyware without consent, or for criminal purposes.\nA recent study claimed that more than 12 million computers worldwide are compromised by botnets. An industry analyst took the stats a step further, relating that botnet operators are controlling populations as large as mid-sized countries (even bigger than the home of Lavasofts headquarters, Sweden!).\nOther reports are saying that cyber criminals are working on assembling the biggest botnet seen in over two years, with a total that's already close to a million PCs. While no one knows the exact intent of this massive botnet, the speculation is that it will be used for a \"massive onslaught of phishing aimed at defrauding web consumers in the run up to Christmas.\"\nAnother seasonal malware threat that has been reported to be lurking online is a Halloween \"typo-attack.\" Cyber criminals have been creating links to web pages that host malware and spyware by taking advantage of increased searches for Halloween related content.\nOur intent, of course, isn't merely to give you a Halloween-style scare. Being informed on the latest security threats means that you are better equipped to protect yourself.", "label": 1}
{"text": "Have you ever heard the following? \"Welcome to the team! Here's a list of 15 applications to install, the instructions are in the team room, somewhere. See you in a week!\" Or: \"What do you mean it broke production, it runs fine on my machine?\" Or: \"Why is this working on her machine and his machine, but not my machine?\"\nDevelopment environments are becoming more complex, with more moving parts and tricky dependencies. Virtualization has been a huge boon for the IT industry in saving costs, increasing flexibility and maintaining control over complex environments. Rather than focusing on virtualization on the delivery side, let's look at how you can provide that flexibility and control to developers to manage multiple development environments easily using Vagrant.\nWhat Is Vagrant?\nVagrant is an open-source (MIT) tool for building and managing virtualized development environments developed by Mitchell Hashimoto and John Bender. Vagrant manages virtual machines hosted in Oracle VirtualBox, a full x86 virtualizer that is also open source (GPLv2).\nA virtual machine is a software implementation of a computer, running a complete operating system stack on a virtualizer. It is a full implementation of a computer with a virtual disk, memory and CPU. The machine running the virtualizer is the Host system. The virtual machine running on the virtualizer is the Guest system. As far as the Guest operating system is concerned, it is running on real hardware. From the perspective of the Host, all of the Guest's resources are used by the virtualizer program. A Box, or base image, is the prepackaged virtual machine that Vagrant will manage.\nStarting in version 1.0, Vagrant provides two installation methods: packaged installers for supported platforms or a universal install with Ruby Gems. This article covers installation using Gems. This method has three parts: 1) install VirtualBox, 2) install Ruby and 3) install Vagrant itself.\nVirtualBox is available from the VirtualBox home page with builds for Windows, OS X, Linux and Solaris. Note that Oracle provides the Oracle VM VirtualBox Extension Pack on the Download site that provides additional features to the virtualizer. The Extension Pack has a separate license (Personal Use and Evaluation License) and is not needed to use Vagrant, but if the Box you are using was created using the Extension Pack, you will need to install the Extension Pack as well.\nRuby is a popular dynamically typed object-oriented scripting language. Ruby is available out of the box in OS X, and most Linux distributions also have a Ruby package available. For Windows users, the RubyInstaller Project provides an easy way to install the Ruby runtime.\nRuby libraries and applications are available in packages called RubyGems or Gems. Ruby comes with a package management tool called gem. To install Vagrant, run the gem command:\n> gem install vagrant\nVagrant is a command-line tool. Calling\nvagrant without additional\narguments will provide the list of available arguments. I'll visit most of\nthese commands within this article, but here's a quick overview:\ninit— create the base configuration file.\nup— start a new instance of the virtual machine.\nsuspend— suspend the running guest.\nhalt— stop the running guest, similar to hitting the power button on a real machine.\nresume— restart the suspended guest.\nreload— reboot the guest.\nstatus— determine the status of vagrant for the current Vagrantfile.\nprovision— run the provisioning commands.\ndestroy— remove the current instance of the guest, delete the virtual disk and associated files.\nbox— the set of commands used to add, list, remove or repackage box files.\npackage— used for the creation of new box files.\nsshto a running guest.\nThe last thing you need to do in your installation is set up a base image. A\nBox, or base image, is the prepackaged virtual machine that Vagrant will\nmanage. Use the\nbox command to add the Box to your environment.\nvagrant box add command takes two arguments, the\nname you use to refer to the Box and\nthe location of the Box:\n> vagrant box add lucid32 http://files.vagrantup.com/lucid32.box\nThis command adds a new Box to the system called \"lucid32\" from a remotely hosted site over HTTP. Vagrant also will allow you to install a Box from the local filesystem:\n> vagrant box add rhel5.7 rhel5.7-20120120-1223.box [vagrant] Downloading with Vagrant::Downloaders::File... [vagrant] Copying box to temporary location... [vagrant] Extracting box... [vagrant] Verifying box... [vagrant] Cleaning up downloaded box... >\nFree Webinar: Hadoop\nHow to Build an Optimal Hadoop Cluster to Store and Maintain Unlimited Amounts of Data Using Microservers\nRealizing the promise of Apache® Hadoop® requires the effective deployment of compute, memory, storage and networking to achieve optimal results. With its flexibility and multitude of options, it is easy to over or under provision the server infrastructure, resulting in poor performance and high TCO. Join us for an in depth, technical discussion with industry experts from leading Hadoop and server companies who will provide insights into the key considerations for designing and deploying an optimal Hadoop cluster.\nSome of key questions to be discussed are:\n- What is the “typical” Hadoop cluster and what should be installed on the different machine types?\n- Why should you consider the typical workload patterns when making your hardware decisions?\n- Are all microservers created equal for Hadoop deployments?\n- How do I plan for expansion if I require more compute, memory, storage or networking?\n|Using Salt Stack and Vagrant for Drupal Development||May 20, 2013|\n|Making Linux and Android Get Along (It's Not as Hard as It Sounds)||May 16, 2013|\n|Drupal Is a Framework: Why Everyone Needs to Understand This||May 15, 2013|\n|Home, My Backup Data Center||May 13, 2013|\n|Non-Linux FOSS: Seashore||May 10, 2013|\n|Trying to Tame the Tablet||May 08, 2013|\n- RSS Feeds\n- Making Linux and Android Get Along (It's Not as Hard as It Sounds)\n- Using Salt Stack and Vagrant for Drupal Development\n- New Products\n- Validate an E-Mail Address with PHP, the Right Way\n- Drupal Is a Framework: Why Everyone Needs to Understand This\n- A Topic for Discussion - Open Source Feature-Richness?\n- Download the Free Red Hat White Paper \"Using an Open Source Framework to Catch the Bad Guy\"\n- Tech Tip: Really Simple HTTP Server with Python\n- Readers' Choice Awards\n- Android is Linux -- why no better inter-operation\n2 hours 11 min ago\n- Connecting Android device to desktop Linux via USB\n2 hours 40 min ago\n- Find new cell phone and tablet pc\n3 hours 38 min ago\n5 hours 6 min ago\n- Automatically updating Guest Additions\n6 hours 15 min ago\n- I like your topic on android\n7 hours 2 min ago\n- Reply to comment | Linux Journal\n7 hours 23 min ago\n- This is the easiest tutorial\n13 hours 37 min ago\n- Ahh, the Koolaid.\n19 hours 16 min ago\n- git-annex assistant\n1 day 1 hour ago", "label": 1}
{"text": "Every summer, computer security experts get together in Las Vegas for Black Hat and DEFCON, conferences that have earned notoriety for presentations demonstrating critical security holes discovered in widely used software. But while the conferences continue to draw big crowds, regular attendees say the bugs unveiled haven’t been quite so dramatic in recent years.\nOne reason is that a freshly discovered weakness in a popular piece of software, known in the trade as a “zero-day” vulnerability because the software makers have had no time to develop a fix, can be cashed in for much more than a reputation boost and some free drinks at the bar. Information about such flaws can command prices in the hundreds of thousands of dollars from defense contractors, security agencies and governments.\nThis trade in zero-day exploits is poorly documented, but it is perhaps the most visible part of a new industry that in the years to come is likely to swallow growing portions of the U.S. national defense budget, reshape international relations, and perhaps make the Web less safe for everyone.\nZero-day exploits are valuable because they can be used to sneak software onto a computer system without detection by conventional computer security measures, such as antivirus packages or firewalls. Criminals might do that to intercept credit card numbers. An intelligence agency or military force might steal diplomatic communications or even shut down a power plant.\nIt became clear that this type of assault would define a new era in warfare in 2010, when security researchers discovered a piece of malicious software, or malware, known as Stuxnet. Now widely believed to have been a project of U.S. and Israeli intelligence (U.S. officials have yet to publicly acknowledge a role but have done so anonymously to the New York Times and NPR), Stuxnet was carefully designed to infect multiple systems needed to access and control industrial equipment used in Iran’s nuclear program. The payload was clearly the work of a group with access to government-scale resources and intelligence, but it was made possible by four zero-day exploits for Windows that allowed it to silently infect target computers. That so many precious zero-days were used at once was just one of Stuxnet’s many striking features.\nSince then, more Stuxnet-like malware has been uncovered, and it’s involved even more complex techniques (see “The Antivirus Era Is Over”). It is likely that even more have been deployed but escaped public notice. Meanwhile, governments and companies in the United States and around the world have begun paying more and more for the exploits needed to make such weapons work, says Christopher Soghoian, a principal technologist at the American Civil Liberties Union.\n“On the one hand the government is freaking out about cyber-security, and on the other the U.S. is participating in a global market in vulnerabilities and pushing up the prices,” says Soghoian, who says he has spoken with people involved in the trade and that prices range from the thousands to the hundreds of thousands. Even civilian law-enforcement agencies pay for zero-days, Soghoian says, in order to sneak spy software onto suspects’ computers or mobile phones.\nExploits for mobile operating systems are particularly valued, says Soghoian, because unlike desktop computers, mobile systems are rarely updated. Apple sends updates to iPhone software a few times a year, meaning that a given flaw could be exploited for a long time. Sometimes the discoverer of a zero-day vulnerability receives a monthly payment as long as a flaw remains undiscovered. “As long as Apple or Microsoft has not fixed it you get paid,” says Soghioan.\nNo law directly regulates the sale of zero-days in the United States or elsewhere, so some traders pursue it quite openly. A Bangkok, Thailand-based security researcher who goes by the name “the Grugq” has spoken to the press about negotiating deals worth hundreds of thousands of dollars with government buyers from the United States and western Europe. In a discussion on Twitter last month, in which he was called an “arms dealer,” he tweeted that “exploits are not weapons,” and said that “an exploit is a component of a toolchain … the team that produces & maintains the toolchain is the weapon.”\nThe Grugq contacted MIT Technology Review to state that he has made no “public statement about exploit sales since the Forbes article.”\nSome small companies are similarly up-front about their involvement in the trade. The French security company VUPEN states on its website that it “provides government-grade exploits specifically designed for the Intelligence community and national security agencies to help them achieve their offensive cyber security and lawful intercept missions.” Last year, employees of the company publicly demonstrated a zero-day flaw that compromised Google’s Chrome browser, but they turned down Google’s offer of a $60,000 reward if they would share how it worked. What happened to the exploit is unknown.\nNo U.S. government agency has gone on the record as saying that it buys zero-days. But U.S. defense agencies and companies have begun to publicly acknowledge that they intend to launch as well as defend against cyberattacks, a stance that will require new ways to penetrate enemy computers.\nGeneral Keith Alexander, director of the National Security Agency and commander of the U.S. Cyber Command, told a symposium in Washington last October that the United States is prepared to do more than just block computer attacks. “Part of our defense has to consider offensive measures,” he said, making him one of the most senior officials to admit that the government will make use of malware. Earlier in 2012 the U.S. Air Force invited proposals for developing “Cyberspace Warfare Attack capabilities” that could “destroy, deny, degrade, disrupt, deceive, corrupt, or usurp the adversaries [sic] ability to use the cyberspace domain for his advantage.” And in November, Regina Dugan, the head of the Defense Advanced Research Projects Agency, delivered another clear signal about the direction U.S. defense technology is heading. “In the coming years we will focus an increasing portion of our cyber research on the investigation of offensive capabilities to address military-specific needs,” she said, announcing that the agency expected to expand cyber-security research from 8 percent of its budget to 12 percent.\nDefense analysts say one reason for the shift is that talking about offense introduces an element of deterrence, an established strategy for nuclear and conventional conflicts. Up to now, U.S. politicians and defense chiefs have talked mostly about the country’s vulnerability to digital attacks. Last fall, for example, Defense Secretary Leon Panetta warned frankly that U.S. infrastructure was being targeted by overseas attackers and that a “digital Pearl Harbor” could result (see “U.S. Power Grids, Water Plants a Hacking Target”).\nMajor defense contractors are less forthcoming about their role in making software to attack enemies of the U.S. government, but they are evidently rushing to embrace the opportunity. “It’s a growing area of the defense business at the same time that the rest of the defense business is shrinking,” says Peter Singer, director of the 21st Century Defense Initiative at the Brookings Institution, a Washington think tank. “They’ve identified two growth areas: drones and cyber.”\nLarge contractors are hiring many people with computer security skills, and some job openings make it clear there are opportunities to play more than just defense. Last year, Northrop Grumman posted ads seeking people to “plan, execute and assess an Offensive Cyberspace Operation (OCO) mission,” and many current positions at Northrop ask for “hands-on experience of offensive cyber operations.” Raytheon prefaces its ads for security-related jobs with language designed to appeal to stereotypical computer hackers: “Surfboards, pirate flags, and DEFCON black badges decorate our offices, and our Nerf collection dwarfs that of most toy stores. Our research and development projects cover the spectrum of offensive and defensive security technologies.”\nThe new focus of America’s military and defense contractors may concern some taxpayers. As more public dollars are spent researching new ways to attack computer systems, some of that money will go to people like The Grugq to discover fresh zero-day vulnerabilities. And an escalating cycle of competition between U.S and overseas government agencies and contractors could make the world more dangerous for computer users everywhere.\n“Every country makes weapons: unfortunately, cyberspace is like that too,” says Sujeet Shenoi, who leads the U.S.-government-sponsored Cyber Corps Program at the University of Tulsa. His program trains students for government jobs defending against attacks, but he fears that defense contractors, also eager to recruit these students, are pushing the idea of offense too hard. Developing powerful malware introduces the dangerous temptation to use it, says Shenoi, who fears the consequences of active strikes against infrastructure. “I think maybe the civilian courts ought to get together and bar these kinds of attacks,” he says.\nThe ease with which perpetrators of a computer attack can hide their tracks also raises the risk that such weapons will be used, Shenoi points out. Worse, even if an attack using malware is unsuccessful, there’s a strong chance that a copy will remain somewhere on the victim’s system—by accident or design—or accidentally find its way onto computer systems not targeted at all, as Stuxnet did. Some security firms have already identified criminal malware that uses methods first seen in Stuxnet (see “Stuxnet Tricks Copied by Criminals”).\n“The parallel is dropping the atomic bomb but also leaflets with the design of it,” says Singer. He estimates that around 100 countries already have cyber-war units of some kind, and around 20 have formidable capabilities: “There’s a lot of people playing this game.”\nUpdated 2.13.2013 to include a response from The Grugq.\nSmaller design teams can now prototype and deploy faster.", "label": 1}
{"text": "Patching over software problems\nJust as you would want to patch over a hole in your pants, you might find holes in your software that could be just as problematic and leave you with serious cyber security vulnerabilities. Patch those holes before something tears wide open.\nMark Trump, FoxGuard Solutions\nThe number of cyber attacks on industrial control systems has been increasing and the activity is visible on a global scale by site, manufacturer, and even by actual control system specific parameters. Many of those attacks are possible because of vulnerabilities in operating systems and applications, which need to be fixed using software patches. Having a sound patch management program in place will greatly reduce your risk and make you a hard target to a would-be attacker.\nThat sounds good, but what does it mean? What exactly is patching? According to dictionary.com, patch, in verb form means to mend, cover, or strengthen with or as if with a patch or patches. It’s also a noun, meaning a piece of material used to cover or protect a wound, an injured part, etc.\nIn the industrial world\nIn control system terminology, patching indicates the process required to address a known weakness in a platform with the ability to have patches or software fixes applied. Platforms include operator interfaces, human machine interfaces (HMIs), computers, networking devices, and associated software loaded on these platforms.\nPatches are typically electronic files with updated configuration information or executable processes that, when applied, correct a given weakness in the affected system. Patches are critical to the protection and security of a system and should be applied as soon as possible for many reasons. As stated above, patches address known weaknesses in a system. This should be disturbing to you as an industrial control system specialist as you do not want your weaknesses to be known. But the inherent nature of patching requires most software and hardware manufacturers to notify the public first, that there is a problem with their system or software and secondly, how to address or fix the weakness.\nSince the public is informed through various means of publications including Microsoft operating system updates and antivirus definition updates that immunize systems from viruses, the bad guys have a freely available method to learn of your weaknesses. Without a proven manageable process to validate and apply patches to your systems in frequent intervals, you are exposed and at risk of having your weaknesses exploited by hackers, disgruntled employees, or worse – terrorists.\nWhat is patch management?\nPatch management is a methodical process that includes documentation, validation, backup and recovery, and a step-by-step tiered approach to the application of change on your critical systems. The core of effective patch management is the actual validation of the change to ensure the updated patches or security enhancements do not disrupt the functionality of your system. Validation should be performed in a lab or non-production environment on equipment and software that is representative of your production environment. Without this validation, you may apply patches that change security parameters of your system that could stop communication between your devices.\nUpon effective validation, prior to application of patches to the actual production equipment, a sound backup and recovery or disaster recovery plan should be in place to backup your device information and configuration. As discussed, patches actually change your system or software from its original state. If the patch causes problems, you would want to restore to your previous state immediately to resume operation.\nTo apply patches to your production system, a strategy identifying the order that patches will be applied should be identified and documented to repeat as new patches are released. From your population, identify an early adopter or first unit that you can take off-line for the time it takes to apply the patch. Then monitor for a period of time before rolling patches out on the remainder of your devices. By taking this tiered approach – lab validation, early adopter, and remainder of devices – you are greatly reducing the risk of a change or patch causing disruption to your overall system. Any issues may be identified prior to the application of patches in a very controlled, documented, and repeatable manner.\nPatching your critical industrial control systems involves the collection of known fixes or patches, validation of these changes prior to application to your system, and then methodical application of patches in a controlled manner. The more frequently you repeat this process, the more up-to-date and less vulnerable your system will be to attack. FoxGuard Solutions specializes in the process of validating changes to industrial control system devices that have patching capability. We can work with your team to identify a strategy that meets your needs while making your critical system less vulnerable to attack.\nMark Trump is the security program manager for FoxGuard Solutions.\nSafety and security channel includes information on cyber security.\nCase Study Database\nGet more exposure for your case study by uploading it to the Plant Engineering case study database, where end-users can identify relevant solutions and explore what the experts are doing to effectively implement a variety of technology and productivity related projects.\nThese case studies provide examples of how knowledgeable solution providers have used technology, processes and people to create effective and successful implementations in real-world situations. Case studies can be completed by filling out a simple online form where you can outline the project title, abstract, and full story in 1500 words or less; upload photos, videos and a logo.\nClick here to visit the Case Study Database and upload your case study.\n2012 Salary Survey\nIn a year when manufacturing continued to lead the economic rebound, it makes sense that plant manager bonuses rebounded. Plant Engineering’s annual Salary Survey shows both wages and bonuses rose in 2012 after a retreat the year before.\nAverage salary across all job titles for plant floor management rose 3.5% to $95,446, and bonus compensation jumped to $15,162, a 4.2% increase from the 2010 level and double the 2011 total, which showed a sharp drop in bonus.", "label": 1}
{"text": "Cryptography is the use of codes to convert data so that only a specific recipient will be able to read it, using a key.\nMicrosoft cryptographic technologies include CryptoAPI, Cryptographic Service Providers (CSP), CryptoAPI Tools, CAPICOM, WinTrust, issuing and managing certificates, and developing customizable public key infrastructures. Certificate and smart card enrollment, certificate management, and custom module development are also described.\nCryptoAPI is intended for use by developers of Windows-based applications that will enable users to create and exchange documents and other data in a secure environment, especially over nonsecure media such as the Internet. Developers should be familiar with the C and C++ programming languages and the Windows programming environment. Although not required, an understanding of cryptography or security-related subjects is advised.\nCAPICOM is a 32-bit only component that is intended for use by developers who are creating applications using Visual Basic Scripting Edition (VBScript) programming language or the C++ programming language. CAPICOM is available for use in the operating systems specified in Run-Time Requirements. For future development, we recommend that you use the .NET Framework to implement security features. For more information, see Alternatives to Using CAPICOM.\nFor information about run-time requirements for a particular programming element, see the Requirements section of the reference page for that element.\nCAPICOM 126.96.36.199 is supported on the following operating systems and versions:\n- Windows Server 2003\n- Windows XP\nCAPICOM is available as a redistributable file that can be downloaded from Platform SDK Redistributable: CAPICOM.\nCertificate Services requires the following versions of these operating systems:\n- Windows Server 2008 R2\n- Windows Server 2008\n- Windows Server 2003\nKey cryptography concepts and a high-level view of Microsoft cryptography technologies.\nCryptography processes, procedures, and extended samples of C and Visual Basic programs using CryptoAPI functions and CAPICOM objects.\nDetailed descriptions of the Microsoft cryptography functions, interfaces, objects, structures, and other programming elements. Includes reference descriptions of the API for working with digital certificates.\nBuild date: 10/26/2012", "label": 1}
{"text": "IT Career Paths: Computer Security Specalists\nComputer Security Specialists plan, coordinate, and implement security measures for information systems to regulate access to computer data files and prevent unauthorized modification, destruction, or disclosure of information.\n- Developing plans and monitoring data usage to safeguard data and computer files against accidental or unauthorized modification, destruction, or disclosure and to meet emergency data processing needs.\n- Conferring with users to discuss issues such as computer data access needs, security violations, and programming changes.\n- Monitoring current reports of computer viruses to determine when to update virus protection systems.\n- Performing risk assessments and execute tests of data processing system to ensure functioning of data processing activities and security measures.\n- Encrypting data transmissions and erecting firewalls to conceal confidential information as it is being transmitted and to keep out tainted digital transfers.\n- Documenting computer security and emergency measures policies, procedures, and tests.\nExcellent interpersonal communication skills required for troubleshooting problems and effectively interacting with clients.\n- Technical certifications\n- Computer programming experience\n- 2-year technical school degree or Associate's Degree in computer science or related subject\n- Bachelor's Degree in computer science (or other fields)\nWhat to Expect:\nAccording to the Bureau of Labor and Statistics Occupational Outlook Handbook for 2008-09, demand for computer security specialists will grow as businesses and government continue to invest heavily in “cyber security,” protecting vital computer networks and electronic infrastructures from attack. The information security field is expected to generate many new system administrator jobs over the next decade as firms across all industries place a high priority on safeguarding their data and systems.\nSecurity Specialists that have specific knowledge on wireless networking and cyber-space management are in demand in today's technology driven businesses. Security Specialists who keep up on their skills, education and certifications will have the best career options.\n- Computer Security Specialist\n- Systems Administrator\n- Security Administrator\n- Data Communications Specialist\n- Computer SConsultant\nQuickCert Certification Courses:\nFor a printable listing, including our Career Roadmap, please Download our IT Certification Guide and Roadmap!\nReady to get started? Call 1.888.840.2378 to speak with a Career Consultant who will be happy to assist you.\nFor More Information E-Mail us at firstname.lastname@example.org\nor call us at 1.888.840.2378", "label": 1}
{"text": "As far as the strain, about 90 percent of cases coming in are type A, according to state health officials, and ER doctors are reminding people to think twice before making a trip to the ER.\n\"If you're a higher risk patient, if you're feeling a lot sicker, you're short of breath, that's something you need to come to the emergency department for,\" Webb said.\nAs far as where the state stands when it comes to the flu, according to the most recent influenza surveillance report released by the DHMH, 3.5 percent of patients visiting 13 surveyed doctors' offices had influenza-like illnesses -- the normal rate is 2.9 percent.\nThere were 4.3 percent of patients who went to the ER for influenza-like illness and 25 percent of lab tests of suspected flu came back positive, down from 30 percent the week before. For frame of reference, it never got above 25 percent for the swine flu outbreak in 2009.\nFinally, 199 people were hospitalized for the flu, down from 256 the week before.\nThere's still time to receive a flu shot, if you have not had one.\n- Flu picks up steam across the U.S.\n- Flu cases down in some areas; child deaths up\n- Maryland's flu season worst since 2009\n- Flu: Which states are most at risk?\n- 7 cold and flu fighters\n- The germiest places you touch\n- 8 common flu myths\n- History of flu outbreaks", "label": 1}
{"text": "Security researchers have uncovered some unexpected behaviors in a piece of malware called Stuxnet. The worm exploits a number of zero-day vulnerabilities in order to propagate itself over Windows networks, but it also targets embedded software developed by Siemens that runs in industrial equipment. The worm could be used to disrupt factories and other industrial environments.\nResearchers have found that the highest concentration of Stuxnet infections is located in Iran. That discovery, coupled with the very high level of sophistication exhibited by the malware, has led some researchers to speculate that it was crafted by a major government body with the aim of disabling Iran's nuclear power plant.\nReports indicate that the worm can exploit four separate zero-day vulnerabilities in Windows, giving it substantial spreading power compared to average malware. According to Symantec researcher Liam O. Murchu, who has been analyzing the worm, it relied on command and control severs located in Malaysia and Denmark. Those servers have been disabled, but the worm has a peer-to-peer update mechanism that allows the attacker to propagate changes and new control server addresses. The update feature will make it more difficult to centrally disable the malware.\nSymantec believes that Stuxnet has been under development since June 2009, but that it has been updated periodically as the developers rolled out new capabilities and exploits. One of the vulnerabilities that it exploits in order to propagate itself is a flaw in Windows that allows a specially crafted shortcut (LNK file) on a removable storage device to automatically launch arbitrary code when the device is connected to a computer. Exploiting that vulnerability makes it possible for the worm to infect USB thumb drives, for example, and then infect Windows computers where that thumb drive is subsequently used.\nIn an analysis of the worm, independent security researcher Ralph Langner contends that the design of the malware leaves no doubt that its function is sabotage and that it is a highly targeted attack developed with insider knowledge by a skilled group of attackers. Because of the manner in which it targets programmable logic controllers in industrial equipment, he says, it's unlikely that the equipment itself can be modified to deflect such an attack.", "label": 1}
{"text": "Teaching teens, tweens basic cybersafety rules\nInternet surfers should know how to protect their computers from viruses and hackers, but teens and tweens can be especially vulnerable...\nBy Julie Weed Special to The Seattle Times\n5 things parents should teachabout protecting computers\n• Use strong passwords that combine numbers, letters and symbols. Don't make passwords easy to guess and never share them.\n• Don't open attachments from people you don't know. If they're from someone you know but they look odd, don't open them.\n• Don't make an online purchase before checking out the company and asking parents.\n• Be wary of illegal and free downloadable media. They might harbor malware.\n• Keep anti-virus software up-to-date and periodically check PC for viruses.\nInternet surfers should know how to protect their computers from viruses and hackers, but teens and tweens can be especially vulnerable because they download media from so many sources, and may not be aware of the latest scams.\nYoung people who aren't vigilant might find their files corrupted, their hard drives wiped clean and the destruction spread to family and friends' computers. Their personal data can also be stolen and used for identity theft.\nParents need to be responsible for setting up firewalls and installing virus-protection software on every computer in the home, said Nancy Willard, author of \"Cyber Savvy: Embracing Digital Safety and Civility.\" But because teens' actions can significantly affect those computers, it is important to teach them basic cybersafety rules.\nTeens and tweens should be taught never to open attachments from people they don't know, because the files might contain malicious software, or malware. Malware can disrupt a computer's operation or secretly gather personal information.\nSome malware insert a virus that destroys data or software. Others install spyware, which records keystrokes in the hopes of accessing personal information and passwords. Still others take control of the PC and use its processing power remotely, sending spam from the owner's account, for example. Odd-looking messages and attachments, even from someone the user knows, should not be opened.\nFree illegal downloads of music and videos may be enticing for teens, but the media files can carry malware. Free games can also contain malware and should be downloaded only from reputable sites.\nComputer experts say that if a computer starts crashing often, slows down significantly or exhibits other unusual behavior, it may have a virus and should be checked.\nTeens also need to know about the most common kinds of online scams, said Willard.\nLegitimate companies generally no longer request personal information by email, so teens need to learn to recognize \"phishing\" messages, which pose as legitimate companies asking the user for login IDs, passwords, credit-card or bank-account numbers. Parents can point out these emails to their children when they encounter them in their own accounts.\nPop-up windows warning users of a virus that can be fixed are also usually scams. Teens should also avoid clicking \"yes\" or \"I agree\" to banner ads on unexpected pop-up windows or websites. Instead, they can press Ctrl + F4 on the keyboard to close the window on a Windows PC. They should trust their instincts when they see deals that sound too good to be true, or email congratulating them on winning a lottery they never entered, said Willard.\nTeens should learn to make strong passwords for all their online accounts, combining letters, numbers and symbols in a combination that isn't too easy to guess. If they see their email, social-media or game account has been used by someone else, they should change the password immediately (if possible) and report it to the provider. Teens should never share their passwords.\nCriminals on the Internet can compromise someone's computer without the victim finding out for months, sometimes ever. But teens, tweens and the rest of us can take steps to minimize that risk.\nJulie Weed is a free-lance writer in Seattle. For her other stories on Teens, Tweens and Technology, go to seattletimes.com/personaltechnology.", "label": 1}
{"text": "Having just discussed replication in Linux -- what it is, how it can be used and how it's not the same as a backup -- it's time to tackle a simple example of one of the replication tools: rsync. You will be surprised how easy it is to use rsync to replicate data to a second storage pool.\nRecently we discussed the importance of data replication for situations ranging from mission critical environments to home users. Replication ensures that you have a copy of your current data on a separate storage environment (secondary system) so that if you lose the first system (primary system), you still have access to the data.\nIn general there are two types of replication: synchronous and asynchronous. Synchronous replication, as the name implies, means that the primary storage and secondary storage are kept exactly the same. Any data writes (or deletes) have to complete on both the primary and secondary storage pools before returning to the application allowing it to continue. This means that the data in the data pools is an exact match.\nAsynchronous replication allows any writes (or deletes) from an application to finish on the primary storage pool. Then the data is copied from the primary storage pool to the secondary storage pool, typically outside of the application I/O path. This means that there can be some data difference between the two pools at any instance in time. The amount of data difference you can tolerate is up to you (your requirements) but you can shrink that data difference to something fairly small and tolerable.\nBut one of the most important aspects of data replication that you shouldn’t forget is that data replication and data backup are not the same thing. A backup can keep prior versions of data so that you can effectively go back in time over the life of the data to get prior versions. On the other hand, replication keeps a replica (copy) of the current data. You can get the most current state of the data from a backup but it will only be as accurate as when the backup was made. Replicas are much more recent so they will, in general, capture the data changes since the last backup. The question you need to answer is when do I need replication?\nThere is no universal answer to that question. You need to examine your data requirements and determine how important having the latest copy of the data is to your mission and the importance of the accessibility of that data. During your examinations you should also weave in discussions about off-site disaster recovery for your data center (or your home system).\nIn the previous article about replication, two replication techniques for Linux were discussed – DRBD and rsync. DRBD is a kernel based replication method that automatically replicates all data from the primary storage pool to a secondary storage pool without the user or administrator having to intervene. On the the hand, rsync is a file based approach allowing you to selectively replicate directory trees so that you don’t have to replicate an entire file system. However, rsync mush be invoked manually so it’s not as automatic as DRBD increasing the possible data differences between the primary and secondary storage pools. But many times the flexibility of replicating only portions of the data to one or more secondary storage pools make it a popular choice despite the possibility of increased data differences.\nSince rsync is so flexible and is file based, in this article I want to show a simple rsync example to illustrate what it can do for data replication.\nSimple example using rsync\nI want to present a simple rsync example to illustrate the basic steps involved in getting to replicate a directory tree. One of the advantages of rsync is that you don’t have to make a copy of the entire file system – you can just make a copy of a specific directory tree and even specific file types or file names. This makes it incredibly flexible since you can now replicate directory trees to various secondary storage servers as needed and/or focus on certain types of files or directory trees.\nFor this article I will be using rsync to replicate data from my laptop to my main storage box at home. The overall concept is that I come home from being on the road, I fire up the laptop on the home network and my data gets replicated to my home server. In addition, I will only be replicating a specific directory from the laptop to the home server since that is where I keep all the data I modify while I travel.\nLet’s start by defining terms within the rsync framework. The first two systems or terms that we need to define are the rsync server and the rsync client. One would think that the traditional client/server terms would apply, but a common source of confusion in rsync is that the rsync server does not necessarily have to be the system that has the original copy of the data and the rsync client does not have to be the recipient of the data. To better understand rsync, remember that there is a distinction between roles and processes in rsync. So to make sure we understand all the terms used in this article, there are four terms we’ll be using (taken from this link).\n- Client: This is a role within rsync where the client initiates the synchronization.\n- Server: This is a role within rsync and refers to the remote process (system) that clients connect to either within a local transfer, a remote shell, or with a network socket.\n- Sender: This is a role and a process within rsync and applies to the particular rsync process that has access to the original files being synchronized. So the “sender” process reads the data and sends it to the “receiver” process.\n- Receiver: This is a role and a process within rsync and describes the receiving process that receives the updates to the data and writes it to the storage device (i.e. the secondary storage pool).\nTo be honest, things can get a little confusing between roles and processes but I like to keep things simple. So for this example where I’m replicating data from my laptop to my home server I will define the home server as the rsync server\n, and the laptop as the rsync client\nand the laptop is the rsync sender\nsince it has the original data and the home server is the rsync receiver\n. The idea is that when I plug in the laptop to my home network, my data is automatically replicated to my home server so I have a copy in case the laptop dies.\nA reasonably good tutorial to use to start learning rsync is here. It is a bit old (1999) but it has a very good overview of rsync and explains things fairly well. There are other tutorials that cover useful topics such as how to use ssh with rsync or using stunnel with rsync.\nFor the rsync command used for my simple scenario let’s start with the simple example in the “everythinglinux” tutorial. Here is the script I used to perform the rsync that is taken from the article and adapted to my situation (notice that there are few changes).\nrsync --verbose --progress --stats --compress --rsh=/usr/bin/ssh \\\n--recursive --times --perms --links --delete \\\n--exclude \"*bak\" \\", "label": 1}
{"text": "Jun 27, 2008 (08:06 PM EDT)\nTPM: A Matter Of Trust\nRead the Original Article at InformationWeek\nThe Trusted Platform Module is a hardware-based cryptographic root of trust.\nThe idea behind hardware-based trust is that trust must start somewhere. Whether it begins in a preloaded bundle of certificates from various certificate authorities (as SSL does in browsers) or from a web of trust manually established at Pretty Good Privacy key-signing parties, cryptographic algorithms are only as strong as the trust they're built on.\nIf you want a secure transaction with someone, at some point in the past you must have verified the identity, or had someone you trust verify the identity--as SSL certificate authorities claim to do. Then, trust relationships are used to securely pass that information forward to a later transaction. Assuming there aren't any bugs in the crypto itself, this chain of trust allows for convenience later on from an initial trust relationship.\nTPM gets its own internal key from the manufacturer, and the manufacturer theoretically is unable to track those keys. TPM never releases its internal key to anything outside of itself, so it becomes its own root of trust.\nOf course, bugs do crop up. The cryptographic math is fairly well-understood at this point, but implementations often leave something to be desired.\nTake, for example, the recent weakness in the Nintendo Wii's code-signing and verification mechanism, which was meant to ensure that only authorized apps would run on the game console. Implementation flaws resulted in third parties being able to bypass the protection. Datel, which makes video-game peripherals and cheat systems, released a commercial product based on the flaw. A small group of Wii hackers also had been using the flaw to explore the Wii. Nintendo has since fixed the problem.\nA Tipping Point For The Trusted Platform Module?", "label": 1}
{"text": "In VPN technology, central tunneling is the process of forcing all traffic from a remote VPN through a central site. Central tunneling allows additional security as remote VPN users are protected by a firewall at the central site, and also enables NAT, IDS, IPS and anti-virus and spam filtering. Central tunneling does increase bandwidth at the central site.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "RICHMOND, Virginia (AP) — Experiencing nausea, headaches or other side effects from prescriptions or over-the-counter medicines?\nResearchers say tweeting about it or posting your concerns online could one day help alert drug companies and federal regulators to problems more quickly — potentially saving lives and money.\nThe project at the University of Virginia and West Virginia University, still in its infancy, capitalizes on the idea that many companies — pharmaceutical and otherwise — already use the Internet to get consumer product and service feedback.\nSifting through innumerable posts on Twitter, Facebook, online message boards and blogs, the researchers will search for early warning signs of adverse drug reactions and interactions normally reported to the Food and Drug Administration and pharmaceutical companies through official channels by consumers and doctors.\nPeople are increasingly turning to the Internet to find out what's ailing them, complain about their symptoms or read up on personal health issues, said Ahmed Abbasi, a professor of information technology at University of Virginia's McIntire School of Commerce in Charlottesville. He says using data from social media could help modernize drug surveillance and have major public health, safety and business impacts.\nFunded by a $130,000 grant through the National Science Foundation's Smart Health and Wellbeing program, the project builds on earlier work analyzing online posts from 2000 to early 2012 for mentions of 20 drugs. Researchers say the earlier effort detected adverse drug reactions — in some cases years earlier than current methods.\nAbbasi said their data mining of online sources was able to identify patients experiencing tendon ruptures after using the popular antibiotic Cipro at least two years before the FDA issued its most urgent \"black box\" warning for the drug and similar antibiotics in 2008.\nDespite the rigorous testing and clinical trials before new drugs are on the market, sometimes side effects don't show up until they are used by a large number of people.\nThe FDA primarily relies on physicians and patients to enter suspected adverse events into a database of voluntary reports that have nearly doubled over the last five years and totaled around 800,000 in 2010, the latest figure available from the agency. It can take multiple cases before someone at the agency detects a pattern worth investigating. Then it conducts an investigation to determine whether the drug caused the side effects.\nThe research team believes using social media would ideally help bring issues to light faster than that.\nSpeedier discovery of adverse drug reactions could have both pros and cons, according to people who keep close track of the pharmaceutical industry.\n\"The use of social media is just one way that may improve a company's ability to learn how patients are actually reacting to medicines,\" said Jeff Francer, assistant general counsel for the industry group Pharmaceutical Research and Manufacturers of America. \"We're always looking for better ways to ensure medicines are being used in a safe manner.\"\nWhile knowing about drug side effects sooner could help pharmaceutical companies pull a drug or make changes to stave off side-effect related lawsuits that have cost the industry billions, analyst Steve Brozak of WBB Securities noted that knowledge could make a company liable sooner too.\nSince the Internet is teeming with spam aimed at exploiting medical fears, selling unregulated remedies or promoting illegal online pharmaceutical sales, Abbasi said researchers will weed out fake medical websites with a fraudulent website detection system co-developed by members of the team. They will use other analytic tools to further filter the information. The results will be reviewed by independent pharmaceutical experts in partnership with medical professors at WVU's medical and pharmacy schools.\nDr. Jerry Avorn, an expert in pharmaceutical safety at Harvard Medical School, called the project intriguing, but added that \"... before we take that as gospel, I think we need to understand to what extent those reports might be either exaggerated or distorted.\"\nHe suggested that \"crowdsourcing\" research on something as subjective as drug effects may not yield the most reliable results.\nInstead, Avorn pointed to the FDA's Sentinel program, which, at the first hint of trouble, allows the agency to probe medical record databases covering tens of millions of patients to track the safety of drugs and medical devices once they're on the market.\nConsumers are still encouraged to report drug reactions to the FDA because its database is currently the official way of tracking those issues, said agency spokeswoman Sandy Walsh.\nThe research team hopes sharing its findings with the larger medical community through a manageable database would allow the industry and regulators to investigate adverse drug reactions sooner and help patients too, said West Virginia University computer science professor Donald Adjeroh, who is co-leading the team. \"If you get one thousand people saying the same kind of thing (about a drug), you know that there is maybe something going on somewhere.\"\nMichael Felberbaum can be reached at http://www.twitter.com/MLFelberbaum.", "label": 1}
{"text": "Phlashing is a permanent denial of service (DoS) attack that exploits a vulnerability in network-based firmware updates. Such an attack is currently theoretical but if carried out could render the target device inoperable.\nRich Smith, head of HP's Systems Security Lab, discovered the vulnerability and demonstrated the attack at the EUSecWest security conference in June 2008. In a real-world execution, an attacker could use remote firmware update paths in network hardware, which are often left unprotected, to deliver corrupted firmware and flash this to the device. As a result, the device would become unusable.\nThe likelihood of phlashing attacks is under some debate. Like other types of exploits, DoS has become increasingly profit-driven. Although phlashing would be cheaper to execute and more damaging than a traditional DoS attack, its potential for gain is limited because once the network hardware has been rendered useless, the victim has no incentive to pay the attacker. The attacker's only prospect for gain would be to threaten to attack and demand a payoff to refrain from doing so. However, as suggested on the Hack a Day blog, the same attack vector could be more effectively used to flash a device with malware-embedded firmware.", "label": 1}
{"text": "Forget iris and fingerprint scans -- scanning noses could be a quicker and easier way to verify a person's identity, according to scientists in the United Kingdom. Unlike other facial features used for biometrics, such as eyes or ears, noses are difficult to conceal and also aren't changed much by facial expression.\nAdrian Evans and Adrian Moorhouse, from the University of Bath Department of Electronic & Electrical Engineering, decided to investigate whether images of people's noses could be used to recognize individuals.\nThey used a photographic system called PhotoFace, developed by researchers at the University of the West of England in Bristol, to scan the 3D shape of volunteers' noses and analyzed them according to six main nose shapes: Roman, Greek, Nubian, Hawk, Snub and Turn-up.\nInstead of using the whole shape of the nose, the researchers used three characteristics in their analysis: the ridge profile, the nose tip, and the nasion (the section between the eyes at the top of the nose).\nThey combined the curvature of the ridge with the ratios of the tip and nasion widths and ridge length. This combined ratio was then used to distinguish between a database of 36 people.\nWhile the researchers used a relatively small sample, they found that nose scanning showed good potential for use as a biometric, with a good recognition rate and a faster rate of image processing than with conventional biometric techniques such as whole face recognition.\nEvans said: \"Noses are prominent facial features, and yet their use as a biometric has been largely unexplored. We wanted to find out how good they could be at recognizing individuals from a database...There's no one magic biometric -- irises are a powerful biometric, but can be difficult to capture accurately and can easily be obscured by eyelids or glasses. Noses, however, are much easier to photograph and are harder to conceal, so a system that recognizes noses would work better with an uncooperative subject or for covert surveillance...We've only tried this on a small sample of people, but the technique certainly shows potential, perhaps to be used in combination with other identification techniques.\"\nProfessor Melvyn Smith led the team at the University of the West of England (UWE) who developed the PhotoFace system. \"This collaborative project with Bath is very exciting work with great potential...It works by taking photos lit by a flash from several different angles so that four images are taken in very rapid succession of every point on the face, each under different controlled lighting conditions,\" Smith said.\n\"The technique is known as photometric stereo. The software then works out the color, surface orientation and depth of each point on the face by analyzing'the shading within each of the photos,\" Smith said. \"The technique is able to achieve a level of detail that is beyond current competing technologies and can be extended to a myriad of other applications, ranging from industrial surface inspection to cosmetics.\"\nThe researchers plan in the future to build up a larger database of noses to test and refine the software to see if it can pick out individuals from a larger group of people, or distinguish between relatives from the same family.", "label": 1}
{"text": "This MMWR supplement summarizes the deliberations of CDC/ATSDR scientists and managers who met in September 2009 in Atlanta as part of the 2009 Consultation on CDC/ATSDR's Vision for Public Health Surveillance in the 21st Century. The meeting was convened to reflect on domestic and global public health surveillance practice and to recommend a strategic framework to advance public health surveillance to meet continuing and new challenges. The first report is an adaptation of the keynote address for the meeting, which summarized the history of public health surveillance, the need to reassess its usefulness, the rationale for topics selected for discussion, and the charge to participants. Subsequent reports summarize the discussions of workgroups that addressed specific topics in surveillance science and practices.\nPublic health surveillance in the United States has evolved from monitoring infectious diseases to tracking the occurrence of many noninfectious conditions, such as injuries, birth defects, chronic conditions, mental illness, illicit drug use, environmental, and occupational exposures to health risks. In 2001, the intentional dissemination of Bacillus anthracis spores and subsequent cases of anthrax in the United States provided an impetus for automating surveillance to enable early detection, rapid characterization, and timely continuous monitoring of urgent public health threats.\nAs the topics of surveillance have evolved, so have the methods of surveillance, spurred by rapid advances in information technology. With the impending mass adoption of electronic health records, procedures for conducting surveillance are taking another turn, and new opportunities for strengthening surveillance capacities are emerging. Electronic health records offer an opportunity to improve links between health-care providers and public health departments, making surveillance more effective and timely, although fulfilling that promise poses substantial challenges.\nDespite these changes in scope and methods, the fundamental premise of public health surveillance remains constant. It should provide information to the public health community regarding the health of the populations served. Stewards of public health surveillance have a responsibility to ensure that the information is used to advance public health and to safeguard the confidentiality of persons who are represented in the data.\nTo begin the process of assessing the state of public health surveillance, CDC/ATSDR leadership conducted a survey of the opinions of CDC/ATSDR scientists and managers. The survey responses identified six major concerns that must be addressed by the public health community to advance public health surveillance in the 21st century:\n- Lexicon, definitions, and conceptual framework for public health surveillance;\n- Global health surveillance;\n- Roles of information sciences and technological advances in public health surveillance;\n- Public health surveillance work force of the future;\n- Accessing and using data for public health surveillance: legal, policy, ethical, regulatory, and practical concerns related to data sharing; and\n- Analytical challenges for emerging public health surveillance.\nEach CDC Center/Institute/Office (CIO) identified five public health surveillance scientists or senior scientists to participate in the meeting. Other participants included the planning committee members and invited workgroup leads, including representatives from the CDC's Surveillance Science Advisory Group (SurvSAG) — a CDC/ATSDR employee organization dedicated to advancing surveillance practice. Although representatives from organizations representing state and local health departments were invited as observers and reviewed drafts of the papers in this MMWR supplement, the meeting was intended to generate ideas from within CDC/ATSDR and to stimulate further discussion with partners. Participation in the meeting was constrained in part because it occurred during the midst of the fall 2009 upswing in cases of H1N1 pandemic influenza, and several persons from both CDC/ATSDR and health departments were unable to attend because of their involvement in the response to the pandemic. Altogether, approximately 100 surveillance specialists from across CDC/ATSDR participated in the one and a half day meeting. Participants were divided into six workgroups that were charged to describe challenges and opportunities for each of the topic areas identified above and to propose a vision for addressing those challenges and opportunities.\nThe 2009 meeting was planned and convened before the 2010 CDC/ATSDR reorganization created an office devoted to surveillance science and practice, the Public Health Surveillance Program Office, located within a new umbrella organization called the Office of Surveillance, Epidemiology, and Laboratory Services (OSELS). This program office has since been merged functionally with another program in OSELS focused on public health informatics to create the Public Health Surveillance and Informatics Program Office (proposed), reflecting the interdependence between surveillance and informatics. This new office provides the CDC/ATSDR nexus for addressing common concerns in surveillance and informatics. It manages three cross-cutting surveillance systems: BioSense, the Behavioral Risk Factor Surveillance System, and the National Notifiable Diseases Surveillance System. Beyond these systems, the majority of CDC/ATSDR surveillance systems are managed by programs across multiple CDC/ATSDR centers and offices and one institute.\nIn addition, the program office provides the focal point at CDC/ATSDR for addressing shared concerns in informatics, including those shaping surveillance practice, most notably opportunities arising for public health from Federal investments aimed at supporting the \"meaningful use\" of electronic health records to improve health care and population health.\nThe reports in this supplement arose from the 2009 meeting deliberations. While the reports do not reflect the insight and experience gained from surveillance practice since the 2009 meeting, the issues identified by the workshop remain relevant to surveillance practice. With the publication of this supplement, CDC/ATSDR will add to conversations about the future of public health surveillance.\nUse of trade names and commercial sources is for identification only and does not imply endorsement by the U.S. Department of\nHealth and Human Services.\nAll MMWR HTML versions of articles are electronic conversions from typeset documents. This conversion might result in character translation or format errors in the HTML version. Users are referred to the electronic PDF version (http://www.cdc.gov/mmwr)\nand/or the original MMWR paper copy for printable versions of official text, figures, and tables. An original paper copy of this issue can be obtained from the Superintendent of Documents, U.S. Government Printing Office (GPO), Washington, DC 20402-9371; telephone: (202) 512-1800. Contact GPO for current prices.\n**Questions or messages regarding errors in formatting should be addressed to firstname.lastname@example.org.", "label": 1}
{"text": "Over the past decade, there has been exponential growth in the Internet and in adoption of information technology worldwide. New ideas for software, hardware and ways of interconnecting networks has led to dramatic increases in productivity, spurred globalization, and literally changed the world. But this burst of activity has also brought some challenges. One of them is security.\nWe are now all familiar with the appearance of worms and viruses which circulate on the Internet. This malware is generally illegal and can cause varying degrees of harm - from the manageable to the serious. It can also be costly to respond to and to repair.\nGlobally, everyone is focused on information security. Customers demand it and vendors are supplying it. The security area of information technology is characterized by innovation, activity and adoption. Security technology is moving from passive to active and from isolated products to intelligent networks. Everyone -- customers, consumers and vendors -- has the incentive to get secure.\nThere is also the realization that security is not just technology, but must include processes and people as well. One size does not fit all, and all three have to be applied holistically to achieve security in all environments.\nAfter 9/11, policy makers in the US and around the world have become focused on the state of the information infrastructure. Policy makers want to ensure that users of networks employ technology, process and people best practices to make networks as secure as possible. Public-private partnerships have been formed to work through voluntary, market-based approaches to security.\nIn the US, President George W. Bush created the President's Critical Infrastructure Board in response to September 11th. Since its inception, the Board has examined issues related to cybersecurity. On February 17, 2003, the White House released its Cybersecurity Plan, and the Department of Homeland Security has been working to implement the recommendations.\nAmong other issues, the Plan urges computer users to create holistic approaches to security, and properly deploy technology, processes and people. It also suggests public-private dialogue to share information, best practices and keep current on new security approaches and challenges. The plan also encourages users to plan for and practice security response and recovery.\nPublic-private partnerships have increased their work on best practices and information sharing. For example, the National Cybersecurity Partnership (NCSP) created five cross-sector working groups. It also issued reports on awareness for home and small business users, early warning systems, technical standards and common criteria, software development and corporate governance.\nDuring 2004, the National Infrastructure Advisory Council (NIAC) to the President issued four substantive reports containing recommendations for improving security. The reports cover the role of government, cross sector interdependencies, information sharing and analysis and a vulnerability disclosure framework.\nThe National Cyber Security Alliance (NCSA) published its Top 10 tips for home, small business and education users and during 2004 launched a nationwide awareness campaign to Stay Safe online.\nThe National Institute of Standards and Technology (NIST) continues its work on voluntary best practices and guidelines, including its guide to a holistic approach to security: the NIST Guide for the Security Certification and Accreditation of Federal Information Systems, NIST 800-37.\nThe OECD published its Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security in 2002. The Guidelines constitute a foundation for working towards a culture of security throughout societies.\nIn 2004, the European Commission (EC) created the European Information and Network Security Agency (ENISA). ENISA is a pan-European \"center of excellence\" for security. It serves as the lead organization for public-private partnerships and information sharing throughout the EU on security best practices and voluntary guidelines.\nIn Asia, the Asia-Pacific Economic Cooperation (APEC)'s E-Security Task Force created a Cybersecurity Strategy to help deployment of best practices in the APEC economies.\nIt is now recognized that most cyber incidents are crimes. Law enforcement agencies have stepped-up the prosecution of these crimes at home and, in cooperation with others, abroad. As criminals attempt to use the network for theft, fraud, misrepresentation, extortion, vandalism and other crimes, more and more countries are ensuring that just as their laws make this activity illegal in the off-line world, their laws make this activity illegal in the on-line world and the laws must be enforced.\nSignificantly, security technology continues to innovate: networks are moving from passive to active and from point-products to system-wide, end-to-end approaches to security recognition, containment and quarantine. Further, Internet Service Providers (ISPs) are competing on security and consumer ISPs have begun to offer security as part of their service.\nFrom a public policy perspective, there are things that governments can do in partnership with industry. Governments can:\nRaise awareness of the importance of getting secure\nEducate users about best practices\nEmploy best practices to secure their own systems\nFund long-term research and development; and\nEnforce aggressively the laws against cyber crime\nGovernment should not regulate security.\nRegulation will: stifle innovation; always be several steps behind; and may make us less secure.\nCompetition is driving innovation in security, and it is this innovation that will ultimately ensure the most effective security.\nLooking forward, the next area of progress can include international cooperation on the socialization of best practices and a focus on the international prosecution of cybercrime.\nIt is critical to recognize that the threat has begun to change, from ad hoc malware to criminals, organized crime and monetizing cyber incidents.\nMany public-private partnerships from the National Cybersecurity Partnership, to the National Infrastructure Advisory Council, to the Partnership for Critical Infrastructure Security have brought hundreds of people together to create sound best practices and are making progress in achieving even more secure networks.\nCisco President and CEO John Chambers, in his personal capacity, is Vice Chairman of the U.S. National Infrastructure Advisory Council (NIAC), which advises the President on security issues.\nCisco will continue to create innovative security products and services.\nTogether, we can continue to work with partners and governments around the world to help ensure our information infrastructure is safe, secure and robust.\nSecurity has been and continues to be a core issue for Cisco -- we continue to build security into our own networks, help our customers protect theirs, and support efforts to strengthen critical public infrastructure.\nThe market is the most powerful driver of innovation. We are focused on meeting the security demands of our customers, and market-based solutions will provide the best results for them.\nFacts are important in this discussion and Cisco has reached-out to policy makers to share its factual expertise as a \"trusted advisor,\" and will continue to do so.\nU.S. Strategy to Secure Cyberspace\nNational Infrastructure Advisory Council (NIAC)\nThe Business Software Alliance Cybersecurity website\nThe Institute for Information Infrastructure Protection (I3P)\nTechNet CEO Cybersecurity Resource Center\nStay Safe Online\nOECD Guidelines: Towards a Culture of Security\nAPEC eSecurity Task Group\nAs of January 2005", "label": 1}
{"text": "Applying Risk Analysis Methods to University Systems\nW R Chisnall\nThe words \"Risk Analysis\" are used today in several different contexts. In safety critical situations such as the design and operation of nuclear power plants or oil and gas rigs, risk analysis is part of the process of making the chance of a disaster as small as possible. The same thinking applies to the design of aircraft blind landing systems and modern \"fly-by-wire\" avionics. In these cases the consequences of an accident are so horrendous, and therefore costly, that the chance of one happening must be made almost vanishingly small. The problem is to build a system where components are replicated and human actions are checked so that overall the system will meet its reliability targets.\nIf, on the other hand, you are a manager on a civil engineering or software development project you will want to know how the actual cost and time to completion of your project might differ from the nominal values. Large projects are composed of hundreds or even thousands of individual jobs, each of which will have had a separate estimate made of its likely duration and cost. But as the work proceeds these individual jobs will each take more or less time and cost more or less than was originally estimated. And the separate jobs are not all independent; some cannot be started until certain others have been completed. And if other constraints such as limited access to scarce resources are taken into account it is easy to understand how project slippages can easily get out of hand. In these circumstances every project manager wants to understand how sensitive his project is to the accuracy of the original estimates and how much freedom of action he will have if things start to go wrong.\nRisk analysis in the computer security context is different again. It is accepted that, in a computer system, both equipment and staff may fail, often in ways that are difficult to predict. There may be natural disasters and there may also be deliberate attacks against the system. Countermeasures are, of course, available and the most common ones are found in most installations. But very few installations are set up to safety critical standards to ensure uninterruptable working or to be totally impregnable against hacking or denial of service attacks. Instead they tend to focus on being reasonably resistant to attacks and able to restore normal working as soon as possible after an incident. The issue, of course, is one of cost. What is spent on countermeasures should be appropriate to the risks and to the costs that might arise following any disruption to normal service.\nIn this paper I shall discuss a particular risk analysis method that I have been using and which originated in UK government circles. I shall highlight some of the areas in which its use in academia differs from how it is used in the civil service and in commerce and discuss some of the benefits that would arise if it were applied more widely across the higher education sector.\nRisk Analysis in Government\nThe UK Government operates very many commercial computer systems either directly or through its various agencies. In the mid 1980s, computer security became recognised as a subject that needed to be taken seriously, even in non-military circumstances, and there was the inevitable competition for limited funds to spend on improved countermeasures. In 1985 the Central Computer and Telecommunications Agency (CCTA), part of the Treasury, studied existing methods of carrying out security reviews so that it could recommend one for use in government departments. None of the methods investigated met all the requirements so a new one was developed to meet the specification written for the study. This became known as CRAMM, the CCTA Risk Analysis and Management Method. Originally it was just that - a method, but soon the method was implemented as a computer program that would run on standard PCs and the package was made available to public and private organisations.\nCRAMM's aims are to:\n- Ensure that security requirements are fully analysed and documented for any type or size of IT system.\n- Avoid unnecessary expenditure on unjustified security measures which can arise through the use of subjective and pragmatic risk assessments.\n- Avoid inconsistencies associated with improvised risk assessments.\n- Involve and aid management in planning and implementing security throughout the various stages spanning the life cycle of IT systems.\n- Aid security reviewers to plan and carry out assessments in a reasonable time.\n- Reduce the need for clerical effort by implementing the method as a software tool for standard PCs.\nThese aims have, in general, been met. But CRAMM's critics said that it nevertheless betrayed its origins by being unnecessarily long winded and prone to generating lots of paper output. It was also seen as being good for large systems with lots of data and many users but unwieldy for the typical systems found in smaller companies. A further criticism was that the system was designed for government-style administrative operations and this flavoured all the interactions with the reviewer and the customer.\nMore recently, following several internal government reorganisations, the range of available risk analysis packages was reviewed. And CRAMM, in an updated form, again emerged victorious. There are now two major versions. One is for UK Government use only, including the military sector, and includes classified countermeasures in its data base. But alongside this is the commercial product, freely available to anyone wishing to buy a licence. Both products are now the responsibility of the UK Security Services - with the names, addresses and telephone numbers of the relevant management staff freely available.\nThe General Method.\nComputer security is about three things:\nThat information is only disclosed to those who are authorised to receive it.\nThat information can only be modified by those authorised to do so.\nThat information and other IT resources are available to authorised users when needed.\nSecurity risk analysis and management consists of two related but separate activities.\nRisk analysis involves the identification and assessment of the levels of risks calculated from the known values of assets and the levels of threats to, and vulnerabilities of, those assets.\nRisk management involves the identification, selection and adoption of countermeasures justified by the identified risks to assets and the reduction of those risks to acceptable levels.\nThere are three principal types of asset involved in an operational IT system:\n- Physical i.e. equipment, buildings and staff\n- Software i.e. the system and application software\n- Data i.e. the information stored and processed\nValuing the physical assets is relatively easy; one simply records the replacement cost. In many cases it may not be possible to buy exact replacements for lost or destroyed items but it is usually possible to find functionally equivalent pieces of equipment - often at less than the original price. And it isn't necessary to be very precise. CRAMM reduces all items to a non-linear \"value scale\" of between 1 and 10. For example, anything valued at less than 1K UKP is valued as 1; for values between 1K UKP and 10K UKP the scale value is 2. Losses of over 30M UKP are scored as a 10.\nThis use of a scale of values is important since it allows intangible losses to be equated with those which have a simple cash cost associated with them. We shall see how this is achieved when valuing the data assets is discussed.\nBuildings and staff are listed as physical assets and one can readily see how losses in these categories can be just as serious as equipment losses. But risk assessments can easily get too big to manage and one golden rule is to define, at the beginning, the scope of an assessment; and for the purposes of this paper I shall exclude buildings and staff from the discussion.\nSimilarly, it is easy to understand the value of software to an IT system. An installation that uses standard packaged software which is properly licensed and supported is at little risk since in the worst case new copies can be obtained from the vendor. But sites using bespoke software which may be old, written in an obscure programming language and inadequately documented are clearly much more vulnerable. An example of this is the \"millennium\" problem - even COBOL has become obscure to many of today's programmers.\nTo value data assets, the method looks at the impacts of accidental or deliberate :\nThere are many possible impacts which may be relevant:\n- Political or corporate embarrassment\n- Loss of commercial confidentiality\n- Infringement of personal privacy\n- Personal safety hazard\n- Failure to meet legal obligations\n- Financial loss\n- Disruption to activities.\nThe CRAMM method leads the reviewer through all combinations of the elements from the two tables above for each data asset that has been identified.\nFor example, the total loss of a company's payroll file would cause considerable embarrassment and disruption to activities but would not cause a personal safety hazard. It is unlikely to cause a financial loss directly, although there would be considerable cost associated with the disruption to normal activities while the file was rebuilt.\nA different example, and one which actually happened, concerns the deliberate modification by a hacker of patient treatment data in a hospital system. In this case at least one patient died. There would also have been direct financial loss to meet compensation claims and extreme corporate embarrassment.\nCRAMM deals with all these circumstances by using a series of guidelines which map the scale of the impact onto the scale of 1 to 10 as used for simple asset values. One example is the \"Embarrassment Guideline\" as shown below:\nEffect Value Contained in department 1 Other departments aware 2 Public made aware 3 Complaints to Members of Parliament 5 Widespread adverse publicity 7 Calls for Minister to resign 9 Minister obliged to resign 10\nThis is one table where the civil service wording is most obvious. But substituting \"director\" for \"Member of Parliament\" and \"Managing Director\" for \"Minister\" makes it quite usable in industry and commerce. It is also clear how it could easily be made compliant with the management structures in universities and other higher education establishments.\nThe equivalent \"Personal Safety Guideline\" is shown below:\nEffect Value Minor injury to an individual 2 More serious injury to an individual 4 Injury to several people 6 Death to an individual 8 Death to several people 10\n(Cynics have pointed out that it is apparently less serious to kill someone than to call for a Minister of the Crown to resign)\nIn making an assessment of a particular data asset, it is important that the reviewer does not make his own judgements about the possible impacts. He should interview the \"data owner\" and extract the information in this way, preferably without exposing the scoring tables. In this way the assessment becomes a collaborative effort; the reviewer simply the master of the process.\nThreats and Vulnerabilities\nWhen all the data assets have been examined it is necessary to consider the Threats and Vulnerabilities. The threats considered are:\n- Natural disasters e.g. fire, flood etc\n- Deliberate threats from outsiders\n- Deliberate threats from staff\n- IT equipment failures\n- Errors by staff\nThe likelihood of a threat manifesting is assessed by reference to known conditions and recent experience. For example, computer installations in earthquake zones or in the basement of a building below the flood level of a nearby river would be considered to have a significant threat level. Computer installations in buildings which are open to the public are at risk as are installations using old equipment and with a poor staff training record.\nVulnerabilities also need to be considered, and it is frequently difficult to separate a lack of vulnerability from the application of a countermeasure. For example, a computer in a wooden building and where the management of waste paper is poor is very vulnerable to fire. Appropriate countermeasures would be the installation of fire detection and extinguishing equipment - but these would not reduce the intrinsic vulnerability. Another example, particularly relevant in universities, would be that computer installations themselves should be secured, particularly in buildings which have public access.\nAt this stage the CRAMM process has information about the physical installation and the totality of the systems that run on it and their overall sensitivities. The package goes into its \"expert system\" mode and makes reference to its data base of countermeasures to find those which are known to be effective in the circumstances that have been identified. These are listed, cross referenced against the particular threats, and presented as recommendations to management.\nFor example, base line countermeasures which are generated in almost all assessments include doing back-ups of data and using passwords. In slightly riskier situations the use machine generated passwords and the formal examination of the audit logs might be recommended. At a higher level still the installation of trusted firewalls, encrypted message transfers and the positive vetting of operations staff might be suggested.\nAs with all consultancy reports, management reserves the right to accept or reject all or part of the report. Countermeasures cost money, some a great deal of money, and management may have important knowledge that was outside CRAMM's data gathering exercise and which, in its judgement, affects CRAMM's conclusions. Or it may just decide to accept the risks.\nSo, what are the advantages of using a method such as CRAMM? Well, it injects a strong measure of objectivity into the risk analysis process. Universities are multi-faceted institutions. Gone are the days when a university had a single computer installation. There are the machines which support the business functions of a university, those which are used by researchers, often on a faculty by faculty basis, and those which have moved into the basic teaching and learning processes. Institutions are being pressed to operate more and more effectively as businesses while the sources of revenue depend increasingly on quality assessments made of the teaching and research processes - certainly in the UK. And usually the entire campus is wired into the global internet with all the additional risks that brings.\nCRAMM enables the relative risks and threats to be assessed so that countermeasures appropriate to the particular system can be selected. It can also be used to show how the risks change with time as the systems evolve. But perhaps most importantly it provides new insights for IS Directors and other university managers about the ever increasing importance of computer based systems in academic life.\nThe University of Manchester\nManchester M13 9PL\nCopyright EUNIS 1997 Y.E.", "label": 1}
{"text": "Index on Censorship has submitted our concerns about the UK government’s proposed Communications Data Bill (widely known as the “snoopers charter”). We have several concerns about the government’s proposals, as surveillance and retention of data can undoubtedly have an effect on free expression. I’ll reproduce the introduction to our submission, which outlines our concerns, here, and you can read the full submission below.\nThe Communications Data Bill as currently drafted would directly undermine both the right to privacy and the right to freedom of expression by making surveillance and storage of UK citizens’ communications data the norm. These rights are enshrined in Articles 8 and 10 of the Human Rights Act 1998 and in the European Convention on Human Rights and in the Universal Declaration of Human Rights. The UNDR explicitly states that: “No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence”.\nCollection and filtering of communications data across the whole British population would not only represent an unacceptable breach of privacy but would also undermine freedom of expression. Index on Censorship – as one of the world’s leading freedom of expression organisations – has monitored censorship and surveillance around the world for forty years. The goals of widespread monitoring, information-collection and storage, and surveillance of a whole population are aims that are normally found only in authoritarian and totalitarian states, such as Iran and China, not in democracies who are bound, through their accession to the human rights conventions mentioned above, and through their commitments to democracy and freedom, only to limit free expression where it is necessary on clear grounds of national security and public order and to impose any limits in a proportionate and limited manner.\nPopulation-wide collection and filtering of communications data is neither necessary nor proportionate. Monitoring and surveillance of this kind impacts directly and in a chilling manner on freedom of expression, inhibiting and restricting individuals in how they receive, share and impart information and encouraging self-censorship. No other democracy has gone as far as the government proposes in this bill that the UK should go. As well as representing a major undermining of privacy and freedom of expression in the UK, this bill, if it became law, would be a direct encouragement and justification for authoritarian regimes to monitor in detail their entire populations online as well as off. It would make it difficult, if not impossible, for the UK to challenge these regimes on their censorship and surveillance of their populations. It is also remarkable that, in a memorandum attached to the draft bill on the compatibility of the bill with the European Convention on Human Rights, the government sees fit to focus only on the right to privacy and makes no mention of the potentially chilling and damaging impacts of the bill on freedom of expression.\nThe declared purpose of this bill is to tackle crime and to ensure national security. This type of in-depth monitoring of the entire population has at no point before been used or introduced as an appropriate crime-prevention or security-promoting tool in the UK. It would represent a reversal of the presumption of innocence and an unwarranted intrusion into the privacy of the British population.\nFurthermore, the fact that new technology makes such population-wide data collection, filtering and monitoring possible is not a justification for using the technology in that manner. Such data collection would represent a major step-change in the amount of information available on individual citizens and is not, as has been claimed, simply a step to ensure information already available offline is also available from online sources. The distinction between ‘subscriber’, ‘use’ and ‘traffic’ data and data content is also a misleading one. The range of data that would be collected as ‘communications data’ would enable a detailed picture of individual’s habits, activities, interests, and opinions to be built up going well beyond any population-wide accumulation of data that has happened until now in the UK.\nIf you want to add your voice, you can sign 38 Degrees petition here;\nAvaaz also has a petition here;\nAnd Open Rights Group allows you to write directly to your MP here", "label": 1}
{"text": "A password can be set for an Outlook Data File (.pst) (Outlook Data File (.pst): Data file that saves your messages and other items on your computer. You can assign a .pst file to be the default delivery location for email messages. You can use a .pst to organize and back up items for safekeeping.) to help prevent unintentional intrusion by other people who share your computer, such as members of your family. When a password is used, a password prompt appears when Outlook starts or when the file is first opened within an Outlook session.\nSecurity Outlook Data File (.pst) passwords are not intended to provide security against intentional malicious attempted to access your information. For a better way to restrict access to your data, create a password-protected Windows user account for person who uses the computer. For more information, see Windows Help and Support.\nAfter you set a password on an Outlook Data File (.pst), it is a good practice to change the password periodically.\n- Click the File tab.\n- Click Account Settings, and then click Account Settings.\n- On the Data Files tab, click the Outlook Data File (.pst) for which you want to create a password, and then click Settings.\n- Click Change password.\nNote The Change Password button does not appear if you are using an Exchange account. Your network password is used to access your Exchange account and information.\n- In the Change Password dialog box, in the New password and Verify password boxes, type the new password. The password can be up to 15 characters and is case-sensitive.\nLearn more about password best practices\nUse strong passwords that include and mix of a minimum of eight uppercase and lowercase letters, numbers, and symbols such as Y6dh!et5. A longer and complex password helps improve password protection.\nImportant It is critical that you remember your password. If you forget your password, Microsoft cannot retrieve it. Any password that you write down should be kept in a secure location, away from the information that it helps protect.\n- Click OK to set the password.\n- There is no logon password for the Outlook program itself; the password you set with the instructions here protects only the Outlook Data File (.pst) that you use in Outlook.\n- Your computer can remember your password so that you don’t have to type it in each time that you pen the Outlook Data File (.pst). If your Microsoft Windows user account is password protected, and no other person has access to your Windows user account, you can select the Save this password in your password list check box after you verify your new password.\n- When you set an Outlook Data File (.pst) password, it is set for the entire file. You cannot set a password for individual folders within the Outlook Data File (.pst).\nTop of Page", "label": 1}
{"text": "posted last year in Dev Platform category by Donghyun Lee\nThe internals of an RDBMS is extremely profound and sensitive. When updating a record in the table, not only the size of columns to be updated affects the performance but also the size of the record itself. Updating a variable-length column is less favorable than updating a fixed-length column in terms of performance, and when updating a variable-length column, you need to change the unfill_factor value and adjust the percentage of disk space.\nIn this article, I will explain why these details affect an UPDATE performance, and what happens inside CUBRID when an UPDATE query is executed. My story will be based on the latest version of CUBRID as of today 8.4.1.\nUPDATE in RDBMS\nLet's make an analogy between the process that implements an UPDATE query in RDBMS and the process of selling products in a shopping mall.\nAt a shopping mall the employee keep frequently bought products on the shelves and less frequently purchased products in the main storage. When customers come, they can buy the products available on shelves quickly without waiting. For products not available on the shelves, they have to wait while the shopping mall employees go and retrieve them from the storage. It is the same in RDBMS. To have fast access to the data, you need to put frequently requested data in a memory buffer. How and what products are displayed on the shelves will have a profound impact on the shopping mall's sales. Likewise, depending on which data is in the memory buffer, it will have a decisive effect on RDBMS.\nIn order to improve performance, RDBMS handles data input/output by page (the default value in CUBRID is 16KB). Operations for the memory buffer used for cache are also processed by pages.\nThere could be a shortage of space if too many products are displayed on the shelf. Suppose you want to remove slow-selling items off the shelves and display other more frequently sold products. However, the latter ones are too big to be displayed. What should you do? You will have to move products around on the shelf to allocate more space for big ones.\nWhich method should you use if you do not want to rearrange a page when the new data to be UPDATED from RDBMS is bigger than the old record?\nMaybe the employees at the shopping mall could display products on the shelf all together. It would be effective to divide areas but it is impossible in RDBMS. In RDBMS, reading and writing can occur in one record at the same time, or there could be a race in limited buffer space. Therefore, you should be able to access a record exclusively by using record locking.\nHow do we actually make this work?\nUPDATE athlete SET name = 'Cheolsu Kim' WHERE code = '10980';\nThe above SQL implementation process can be summarized in the flowchart below:\nFigure 1: Implementation process flowchart for UPDATE query.\nTo be precise, we should also express the process of SQL parsing, SQL optimization, transaction process, data locking, data correction, data storing, operation logging, and operation restoration. However, this article will focus only on what happens in memory buffer and disk while updating.\nThe first thing to be done is to find the record we need to update. If the conditions used in the corresponding query can use index, then we can use index navigation.\nIf the details of the our record are in the memory buffer, use them as they are. If the record is not found in the memory buffer, we need to read it from the disk and transfer it to the memory buffer. This process is called FIX.\nIn CUBRID, index is composed of a B+ tree (for details refer to CUBRID Query Tuning Techniques and What is Covering Index in CUBRID 8.4.0?). Generally speaking, a B+ tree stores the location (VPID) of previous and next key nodes in a non-leaf node while the disk location of the actual data which corresponds to the key is stored in a leaf node. Therefore data search process is affected by the type of a B+ tree configuration.\nFigure 2: Storage structure of a B+ tree index.\nSometimes the size of a column (like text) can be bigger than a page (16KB). In this case you need a separate storage other than the node of a B+ tree. Therefore, you might have to allocate a separate storage space except the B+ tree when searching for data.\nFurther I will explain about which index configuration is likely to cause the overflow key file or overflow OID issues when UPDATE-ing a record.\nFirst, let's look at a very large node that configures index.\nCREATE INDEX idx_history ON athlete(history); UPDATE athlete SET gold = 3 WHERE history = $history_string;\nIf history field data used by key is roughly 100KB, it will be greater than a page (16KB), a unit that stores regular data. This is called an overflow key, and you cannot save the key value to a page. In a node, you should store ID (OFID, Overflow File ID), which refers to a file that stores the key value.\nAs CUBRID manages data by page, it is burdensome if data is divided into several pages, as many memory copies (memcpy) are needed to configure a single piece of data. Hence, it is recommended to consider the size of a key so that it can be stored in one page if possible.\nNow let's look at a situation in which keys are overlapped.\nCREATE INDEX idx_gender ON athlete(gender); UPDATE FROM athlete SET gender_type = 'Male' WHERE gender = 'M'\nAssume gender column is indexed. Low-selectivity of the gender field (only two values \"M\" and \"F\", or DISTINCT(column) is low) may result in many OIDs being stored in the same node in B+ tree for the same index key. If space necessary for storing OID is bigger than a page by 1/4, it will be stored in a separate Overflow OID (OOID) page. If the number of separate overflow pages increases, it would affect the performance as there would be a burden to navigate between these additional links.\nThe following is a structure of a B+ tree in case overflow files and overflow OID pages exist.\nFigure 3: A storage structure of OFID and OOID.\nModifying the Column Value\nThis process finds the record to be updated and modifies the necessary column data of the record. The following flowchart summarizes this process:\nFigure 4: Data update flowchart.\nSince RDBMS implements read and write operations in pages, you will need to read or write more than one pages. Data stored in the memory can be read/written faster than the data stored on a disk, thus you should minimize disk I/O operations by maximizing the memory.\nTo do this, you can use a memory buffer, which is an intermediate storage space. As shown in the above Figure 4, first, check if the necessary data is in the memory buffer. If there is no data, load it to the memory buffer from the disk (DB Volume). Then update the data in the memory. When the data is updated, the data to be modified is recorded in logs, and, finally, it is recorded to the database volume (disk) at the checkpoint.\nMemory and Disk Management\nThe following figure summarizes the policy and main tasks used for memory and disk management.\nFigure 5: Work that occurs when storing updated data.\nPage Management Policy\nLRU (Least-Recently Used)\nIn order to effectively use the limited buffer size and maintain recently used data, remove the data which has not been used for a long time and free up the space. This is a memory method used by the STEAL policy.\nTasks of Buffer Administrator\nThe task acquires a latch for a buffer in competition with other transactions when reading a page from a disk using a memory buffer. Therefore, you cannot use different transactions while acquiring a latch for a buffer to be used in your transaction. If there is a corresponding page in a buffer, a page is not loaded from a disk (database volume).\nThis is a different concept from FIX in a way that the task is for a page that is no longer used in a transaction. It is not always the case that an UNFIXed page is flushed to a disk.\nIn this task you will write a DIRTY page in a buffer to a disk. As you have to write a log file (WAL - Write-Ahead Log) to a disk, just before executing the task a race can occur in which two or more files write in the same log file.\nLogging Policy to Restore Failure or Rollback\nWAL (Write-Ahead Logging)\nWrite-Ahead Logging is a policy to enable restoration upon system failure, i.e. always write UNDO/REDO logs to a disk before writing the data page. UNDO includes the data before UPDATE and REDO includes the new data after UPDATE.\nYou can use STEAL/NO STEAL, FORCE/NO FORCE policies to specify when to reflect the page stored in a memory buffer to a disk.\nWhen a transaction attempts to use a memory buffer, the STEAL policy flushes the Least Recently Used (LRU) dirty pages and frees up the memory buffer. To use the STEAL policy, you need UNDO logging in order to recover old data when you rollback a transaction.\nIn contrast, the NO STEAL policy keeps a DIRTY page in a buffer until a transaction is completed. Therefore, there should be enough buffer space to keep all pages that have been changed by all transactions in progress.\nThe FORCE policy reflects all pages updated by a transaction to a database volume when commit is called. Using the FORCE policy affects performance, as disk write has to be carried out every time a transaction commits. If a page has to be corrected 20 times by several transactions in a brief period of time, the disk also needs to be written to 20 times.\nThe NO FORCE policy does not necessarily reflect all pages renewed by a transaction during a commit process. The costs for rewriting a page could be reduced, if other transactions are renewing the same page while commit is not reflected to a database volume. However, to ensure data changes by a successfully committed transaction, REDO logging is necessary in the event of a system failure.\nThe NO STEAL and FORCE policies will be the easiest implementation, but their performance is the worst. As the STEAL and NO FORCE policies are the best, most databases including CUBRID are implemented via these policies. For this reason both UNDO logging and REDO logging are necessary, and the entire record should be logged not just the column to UPDATE. When UNDO logging, the record before the change is stored as-is and the record after the change is compressed and stored when REDO logging.\nYou must note that a big record size will affect logging, even if the size of column to UPDATE is small. If there are a lot of records that are very big and the number of columns to UPDATE frequently is small, it is preferable to gather these UPDATE-able columns and create a separate table for them. This is recommended only considering the size of logging records.\nPage Storage Structure\nNow let's learn about how a page is stored depending on the size of data to UPDATE. The following figure shows the basic structure where a page is stored in the record:\nFigure 6: Record storage structure inside a page.\nWhen a new value is entered, records are assigned from the front of a page while slots are assigned from the end of a page in the opposite direction. One record consists of a header (header), fixed-length columns (Fix Col), and variable-length columns (Var Col). The following explains each component.\n- page header: Stores the following information about total slots within a page\n- a number of slots and records\n- the size of total extra space and contiguous extra space\n- the initial offset of contiguous space\n- transaction ID\n- heap page header: Stores initial record location and schema information location.\n- record: Stores a record value.\n- slot: Stores information about record location (offset, length).\nIf there is a variable-length column in a record, the size of the record to UPDATE may be changed. If the record to UPDATE is smaller than the existing size, data can be UPDATEd in the same location. However, if the size is bigger, assign the record to UPDATE in the same page, and the existing slot indicates the record to UPDATE. If there is no space in the same page to UPDATE a new record, a separate page will be assigned as shown in the following figure, and the existing record indicates a new record.\nFigure 7: The structure of record storage when space to UPDATE in the existing page is insufficient.\nIf the size of a record to UPDATE is bigger than a page, data is divided and stored by page as shown in the following figure, and the page that stored the previous data indicates the page that stored renewed data.\nFigure 8: The structure of a record storage when the record to UPDATE is bigger than a page.\nWhen writing data in this case, data should be split into several pages, and to read, the split pages should be loaded in a series of memory, which may negatively affect the performance.\nExclusive Record Lock\nTo this point we have explored how CUBRID uses system memory and disk when UPDATE query is requested. Now I will explain how to manage records within the corresponding range when executing an UPDATE query.\nGenerally, a shared lock is used to search for a specific record to allow other transactions to see [SELECT] the same record you are currently navigating. For INSERT, UPDATE, or DELETE, an exclusive lock is used to block access from other transactions.\nIn the searching process using WHERE condition, however, you must use an update lock instead of shared lock when acquiring the lock for the record in the target range of UPDATE. You also need to acquire the key of the record in operation and the lock for the next key to block your operating range from other transactions.\nWe will describe why an additional update lock is necessary besides exclusive lock during UPDATE, and why key locking is needed.\nThe following explains lock acquisition/release for UPDATE execution.\n- Request UPDATE query with the WHERE condition to the database server.\n- Acquire update lock while searching for the record with the corresponding range condition.\n- In this case, acquire the key lock for the following corresponding key in the WHERE condition range.\n- While executing actual data UPDATE, convert update lock to exclusive lock.\n- Commit transactions and release all acquired locks.\nThe action of an update lock can be explained as:\nas this is the only transaction authorized to UPDATE until the UPDATE transaction is completed, other transactions cannot not UPDATE.\nAnother transaction can acquire an update lock on a transaction that has a record with shared lock. However, if a transaction has acquired update lock, another transaction cannot obtain shared lock.\nConcurrency may decrease if an exclusive lock of the record to UPDATE can be obtained immediately, and thus using shared lock seems to be a better option while searching for a target by condition. Why do we have to use an update lock instead of shared lock? The reason is to minimize deadlock. For better understanding, let's look at the following table, which has no update lock.\n|Transaction 1||shared lock1 (Record A)|\n|Transaction 2||shared lock2 (Record A)|\n|Transaction 1||exclusive lock1 (Record A);|\n|Transaction 2||exclusive lock1 (Record A);|\nThe situation above is the one in which Transactions 1 and 2 of the same Record A acquired the shared lock, and they are about to upgrade the lock to exclusive lock. However, they both are waiting for the other transaction to free shared lock; that is, they are in deadlock. What would happen if there is an update lock?\n|Transaction 1||update lock1 (Record A);|\n|Transaction 2||update lock2 (Record A);|\n|Transaction 1||exclusive lock1 (Record A);|\n|Transaction 2||update lock2 (Record A);|\nexclusive lock2 (Record A);\nTransaction 1 has acquired an update lock and Transaction 2 is in the standby mode to obtain an update lock. Transaction 1 changes the update lock to exclusive lock, UPDATEs Record A and releases the lock. Transaction 2 acquires the update lock2, which was in a standby mode, and thus it can execute UPDATE. When the update lock is introduced, you can avoid some of the deadlock effects caused by UPDATE.\nThe following deals with specific examples of the situations above. Automatic commit mode is released and isolation level is 4 (REPEATABLE READ SCHEMA, READ COMMITTED INSTANCES).\ncreate table t1(id int, num int); create unique index idx_t1_id on t1(id); insert into t1 values (10,10), (20,20), (40,40), (80, 80); commit;\n|Transaction 1||Execution (update ... where id = 40;)|\n|Transaction 2||Standby (update ... id = 40;); Standby|\n|Transaction 2||Execution (update ... where id = 40;)|\nWhen a transaction is acquiring an update lock, other transactions cannot UPDATE or DELETE the corresponding record. Therefore, if you use an update lock and access the same record above, you can avoid deadlock resulting from UPDATE. An update lock is used not only for UPDATE, but also for DELETE tasks with the WHERE condition that uses index.\nAn update lock can be obtained even when the record to UPDATE is in the shared lock with other transactions; however, two or more transactions cannot be acquired at the same time.\nFor data consistency, update lock alone is insufficient. Let's consider the following example.\n|Transaction 1||delete table where id = 1|\n|Transaction 2||insert into t1 (id) values (1)|\nThere are many models that can be used to handle the request above, and approach methods vary depending on RDBMS.\nCUBRID 2008 R4.1 places the INSERT task of Transaction 2 in a standby mode. However, Transaction 1 cannot put Transaction 2's tasks in the standby mode by using an update lock as the data of the corresponding key will be deleted from the B+tree when executing DELETE. This problem can be solved by using a key lock.\nWhen performing DML tasks, a key lock acquires lock authority of the record indicated by the next key of the record for processing. If table locking is executed without obtaining a key lock, it will deteriorate concurrency; thus, a lock to a certain area should be obtained to ensure maximum concurrency.\nTypical example of using key locks is a unique index. When performing DML tasks, you should obtain a key lock for the record indicated by the next key of the corresponding record and the target record, to ensure there are no DML tasks by other transactions within the range.\nLet's learn about the operating process of key locks with the following example: Automatic commit mode is released.\ncreate table t1 (id int, num int); create unique index idx_t1_id on t1(id); insert into t1 values (10,10), (20,20), (40,40), (80, 80); commit;\n|Transaction 1||update t1 set num=400 where id=40;|\ninsert into t1 values (30, 30); Standby… rollback;\ndelete from t1 where id=20; Standby… rollback;\ninsert into t1 value (70, 70); Standby… rollback;\ndelete from t1 where id=80; Standby… rollback;\nupdate t1 set num=444 where id=80; Standby…rollback;\n- When Transaction 1 executes UPDATE of the id=40 record, the transaction will acquire the key lock for the id=40 key and id=80, the next key. In this case, other transactions within the range cannot INSERT, UPDATE, or DELETE new records.\n- For Transaction 2 to INSERT the id=30 record, it should acquire the key lock for id=40; as Transaction 1 already acquired the key lock for id=40, the work is in standby mode.\n- As Transaction 1 already acquired the key lock for id=40 and id=80, all other tasks, which require the work with these keys, are all in standby mode.\nIt is likely that other transactions can be in standby mode because of key lock. The more indexes you have on a column you plan to UPDATE, the occurrence of key lock may increase which results in a greater negative effect on UPDATE performance. Thus, we recommend that you remove index for the corresponding columns, considering both SELECT and UPDATE performance.\nFigure 9: Key lock related scenario about records being updated.\nConsidering the occurrence of deadlock between indexes due to key lock, we recommend that you retry the corresponding task. In the following scenario, we will learn about deadlocks resulting from key lock. Deadlock may occur under the assumption that Transaction 1 and 2 are implemented at the same time.\ncreate table t1(id int, num int); create unique index idx_t1_id on t1(id); insert into t1 values (10,10), (20,20), (40,40), (80, 80);commit;\n|Transaction 1||update t1 set num = 40 where id = 1 using index pk_t1_id; (pk)|\n|Transaction 2||update t1 set id = 30 where num = 7 using index i_t1_num; (idx)|\nFigure 10: Deadlock scenario caused by key lock.\nTransaction 1 attempts to UPDATE the column num of id=1 record and obtains the key lock for id=1 and id=5 as well as the exclusive lock for record (1,9). In this case, Transaction 2 attempts to UPDATE the column id, which is num = 7, and acquires the key lock for num=7 and num=9 as well as the exclusive lock for record (5 and 7).\nTransaction 1 needs the key lock for index idx 9 to UPDATE the column num of id=1 record but Transaction 2 has already acquired the corresponding lock. While Transaction 2 needs the key lock for index pk 5 to UPDATE the column id of num=9 record, Transaction 1 has already acquired the corresponding lock. That is, deadlock has occurred.\nKey lock has key shared lock and key exclusive lock. The lock that the INSERT task acquires for the next key is key shared lock, and the lock that UPDATEd or DELETEd tasks will acquire for the next key is key exclusive lock. When UPDATE or DELETE is working on the record of a specific range, other transactions must not change the record within the corresponding range; this is to allow INSERT by other transactions into the key lock range of the next location during INSERT operation. Let's examine the following figure:\nFigure 11: Key lock related scenario for record being INSERTed.\nWhen Transaction 1 INSERTs id = 90 record, it acquires the key shared lock for id = 100, the next key. When Transaction 2 INSERTs id = 95 record, it acquires the key shard lock for id = 100, which is also the next key. Lock sharing by transactions that are different from one another on the same key id = 100 is possible because key lock is acquired in key shared lock mode.\nIn this article we have observed the events that occur in the memory and disk storage structure during UPDATE of data in CUBRID and how to obtain locks so as to block other transactions from the record within the UPDATE range.\nIt is a mistake to think that the processing costs will be small if just one record or a small column is UPDATEd. When searching for the WHERE condition to find the UPDATE target, yes, the use of index will affect the searching time. But also you must remember that the size of a record also affects UNDO/REDO logging, not the size of UPDATE target column. We can assume that the smaller the size of record to be UPDATEd and the longer the fixed-length compared to the existing size, the more advantageous it is for UPDATE performance.\nUnder the assumption that UPDATE of a variable-length column occurs always, you can consider adjusting the system parameter unfill_factor (the default value 0.1) value, which controls the disk space of a pre-allocated page for data UPDATE. For example, suppose the value of unfill_factor is 0.1, there will be about 10% of extra space in a page when data INSERT occurs continuously; thus, the remained 10% of extra space could be used for INSERT for the same page or for UPDATE.\nUPDATE requires update lock and key lock. You should understand that these could lead to standby or deadlock of competing transactions. If an unexpected delay or deadlock occurs, you should check if an index configuration for UPDATE column is appropriate, or if the number of indexes on the column could be minimized.\nI hope that this article and the recommendations I gave to reduce the burden of UPDATE execution provide you an opportunity to understand the locking and storage structure usage methods in CUBRID database when executing UPDATE operations.\nBy Lee Donghyun, CUBRID Manual and Release Notes writer, CUBRID DBMS Development Lab, NHN Corporation.", "label": 1}
{"text": "Onion Routing Averts Prying EyesBy Ann Harrison\nStory location: http://www.wired.com/news/privacy/0,1848,64464,00.html\n02:00 AM Aug. 05, 2004 PT\nComputer programmers are modifying a communications system, originally developed by the U.S. Naval Research Lab, to help Internet users surf the Web anonymously and shield their online activities from corporate or government eyes.\nThe system is based on a concept called onion routing. It works like this: Messages, or packets of information, are sent through a distributed network of randomly selected servers, or nodes, each of which knows only its predecessor and successor. Messages flowing through this network are unwrapped by a symmetric encryption key at each server that peels off one layer and reveals instructions for the next downstream node.\nIn contrast, messages traveling across the Internet are generally not encrypted, and the path of a message can be seen easily, linking users to activities like website visits.\nThe Navy is financing the development of a second-generation onion-routing system called Tor, which addresses many of the flaws in the original design and makes it easier to use. The Tor client behaves like a SOCKS proxy (a common protocol for developing secure communication services), allowing applications like Mozilla, SSH and FTP clients to talk directly to Tor and route data streams through a network of onion routers, without long delays.\nOnion routing does not guarantee perfect anonymity. But it helps protect users from eavesdroppers who aren't watching both the initiator and recipient of the message at the time of the transaction. Developers say Tor can be used to prevent websites from tracking their users; block governments from collecting lists of website visitors; protect whistleblowers; and circumvent local censorship by employers, ISPs or schools that restrict access to certain online services.\nThe Navy is financing Tor because it wants to hide the identity of government employees who have long used anonymous communications systems for intelligence gathering and politically sensitive negotiations.\n\"The point of the Tor system is to spread the traffic over multiple points of control so that no one person or company has the ability to link people,\" said programmer Roger Dingledine. Dingledine and Nick Mathewson, both based in Boston, are building Tor as a research platform with a worldwide community of open-source software developers.\nTheir goal is to blend together a wide range of users and avoid the weakness of many anonymizing services that are located on a handful of machines and vulnerable to a single point of failure.\nCompanies could also use Tor for discreet competitive research, said Dingledine, or to route their employees' Web browsing so employment sites like Monster can't determine which of them are trolling for a job. \"Plenty of people don't want their source IP listed in Web logs, especially .mil or .gov visitors,\" said Dingledine.\nThe security of the Tor service is proportional to the number of nodes in the system. Tor is slowly scaling and looking for tens of thousands of participants who can provide enough nodes to prevent the service from being compromised by what the project website describes as \"curious telcos and brute-force attacks.\"\n\"The current Tor version very effectively builds on 20 years of development in anonymous designs,\" said cryptographer David Chaum, whose 1981 paper on untraceable e-mail, return addresses and digital pseudonyms set the groundwork for the Tor service.\nTor is distributed as free software under the commonly used 3-clause BSD license. About 1,000 users (it's an anonymous network, so developers aren't exactly sure) are running the service in client or server mode.\nThe Tor network currently includes 35 servers that forward each data stream at least three times. Each server averages 10 Kbps of bandwidth. Those with reliable Internet connections, who can support at least 1 Mbps in both directions, are being recruited as potential servers in the network.\nUsers are permitted to operate an unrestricted number of nodes. But Dingledine pointed out that a well-funded adversary could sign up for a large number of servers and potentially take over the network.\nThose who want to operate Tor routers must therefore convince the Tor directory server operators that they are trustworthy and reliable. Dingledine said developers are trying to find ways to scale the system without having to have a human check the integrity of every new server that becomes part of the network.\nDingeldine said the developers of another online anonymity project, called JAP, were forced by the German government to insert a backdoor into the program and were barred from revealing it. If anyone insisted on similar measures for Tor, Dingledine said the community of open-source developers who analyze source-code changes for each Tor revision would expose it -- as they did with JAP.\n\"The reason Tor works is that it's free and available software,\" said Dingledine. \"If it was a closed source or a proprietary system, there is no way to know.\"", "label": 1}
{"text": "Setting up a VPN Gateway\nA virtual private network (VPN) is a tool that enables the secure transmission of data over untrusted networks such as the Internet. VPNs commonly are used to connect local area networks (LANs) into wide area networks (WANs) using the Internet. Perhaps you need to build a VPN between two offices but are not sure if the large infrastructure costs associated with an enterprise-level VPN solution are justifiable. The performance of applications that are intended for use over LANs (for example those that use network file sharing) seriously can be degraded over WAN connections. Likewise, lower bandwidth and longer latency in WAN connections can affect adversely the reliability and performance of groupware and thin-client applications. Perhaps you have a home office and would like to use your high-speed internet access to connect seamlessly and securely to your office LAN through an IPSec-capable router. Or perhaps you are just curious about VPNs and IPSec in general and want to experiment.\nThe VPN firewall discussed in this article will run on just about any 486-or-better PC that has 16MB or more main memory and two Linux-compatible Ethernet network cards. The idea is to provide a starting point from a single, self-contained package that will allow you to create robust, secure, scalable and highly configurable VPNs that also are interoperable with many common commercial VPN implementations. If you wish to experiment on a low-maintenance firewall-VPN gateway, then the package discussed here might be ideal for you.\nThis article shows you how to set up, at minimal expense, a working VPN gateway that uses the IETF's (Internet Engineering Task Force) IPSec (internet protocol security) specification. IPSec is an open standard and is supported by virtually all major firewall software and hardware vendors, such as Lucent, Cisco, Nortel and Check Point. This package will give you a widely interoperable IPSec that uses the de facto standard 3DES encrypted, MD5-authenticated site-to-site or point-to-site VPN. You should be able to do this without resorting to a full Linux distribution or recompiling a standard Linux kernel with a kernel IPSec module.\nThe VPN system we examine here is based on FreeS/WAN (www.freeswan.org), a portable, open-source implementation of the IPSec specification. FreeS/WAN has been demonstrated to interoperate, to various degrees, with Cisco IOS 12.0 and later routers, Nortel Contivity Switches, OpenBSD, Raptor Firewall, Check Point FW-1, SSH Sentinel VPN 1.1, F-Secure VPN, Xedia Access Point, PGP 6.5/PGPnet and later, IRE SafeNet/SoftPK, Freegate 1.3, Borderware 6.0, TimeStep PERMIT/Gate 2520, Intel Shiva LanRover, Sun Solaris and Windows 2000. The official FreeS/WAN web site has a regularly updated compatibility list with the latest version of its on-line documentation. FreeS/WAN version 1.5 is included in this package.\nI have created a single-diskette distribution that installs the base configuration of a VPN firewall based on the Linux Router Project (LRP, www.linuxrouter.org), a compact Linux distribution that can fit on a single, bootable floppy diskette. The distribution here is essentially Charles Steinkuehler's Eiger disk image with Steinkuehler's IPSec-enabled kernel and LRP IPSec package. Firewalling is carried out through Linux ipchains. This particular version is based on the 2.2.16 kernel of Linux. This distribution is called DUCLING (Diskette-based Ultra Compact Linux IPSec Network Gateway). Compact Linux distributions have a twisted history. LRP technically refers to Dave Cinege's compact distribution. There are many variants around, including Charles Steinkuehler's distribution (EigerStein) of Matthew Grant's defunct Eiger version (lrp1.steinkuehler.net). Another such distribution is David Douthitt's Oxygen (leaf.sourceforge.net/content.php?menu=900&page_id=1). Also, there is LEAF (Linux Embedded Appliance Firewall), a developer's umbrella that tries to coordinate releases and documentation, sort of like a one-stop shop for compact Linux distributions (leaf.sourceforge.net). I use the term LRP to refer to the compact Linux distribution presented here, even though some may consider this terminology incorrect.\nIf you are running MS Windows 9x, the distribution self-extracts and installs itself onto a standard 3.5\", high-density floppy diskette. You also can write the image to a boot floppy if you have a system running Linux. Once the extraction is done, you will need to boot off the floppy disk you have created, copy the network drivers for your network cards over and edit the appropriate configuration files. That's it—no creating and formatting disk partitions or messing with boot managers on your hard drive. If you are not happy with the distribution, just pop the diskette out, throw it away (or reformat it) and reboot your PC. Check the links on leaf.sourceforge.net/devel/thc for more information on these options.\n|Non-Linux FOSS: libnotify, OS X Style||Jun 18, 2013|\n|Containers—Not Virtual Machines—Are the Future Cloud||Jun 17, 2013|\n|Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer||Jun 12, 2013|\n|Weechat, Irssi's Little Brother||Jun 11, 2013|\n|One Tail Just Isn't Enough||Jun 07, 2013|\n|Introduction to MapReduce with Hadoop on Linux||Jun 05, 2013|\n- Containers—Not Virtual Machines—Are the Future Cloud\n- Non-Linux FOSS: libnotify, OS X Style\n- Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer\n- Linux Systems Administrator\n- Introduction to MapReduce with Hadoop on Linux\n- RSS Feeds\n- New Products\n- Weechat, Irssi's Little Brother\n- Validate an E-Mail Address with PHP, the Right Way\n- Tech Tip: Really Simple HTTP Server with Python\n- Poul-Henning Kamp: welcome to\n18 min 58 sec ago\n- This has already been done\n19 min 58 sec ago\n- Reply to comment | Linux Journal\n1 hour 5 min ago\n- Welcome to 1998\n1 hour 53 min ago\n- notifier shortcomings\n2 hours 17 min ago\n3 hours 54 min ago\n- Android User\n3 hours 55 min ago\n- Reply to comment | Linux Journal\n5 hours 48 min ago\n8 hours 38 min ago\n- This is a good post. This\n13 hours 51 min ago\nFree Webinar: Hadoop\nHow to Build an Optimal Hadoop Cluster to Store and Maintain Unlimited Amounts of Data Using Microservers\nRealizing the promise of Apache® Hadoop® requires the effective deployment of compute, memory, storage and networking to achieve optimal results. With its flexibility and multitude of options, it is easy to over or under provision the server infrastructure, resulting in poor performance and high TCO. Join us for an in depth, technical discussion with industry experts from leading Hadoop and server companies who will provide insights into the key considerations for designing and deploying an optimal Hadoop cluster.\nSome of key questions to be discussed are:\n- What is the “typical” Hadoop cluster and what should be installed on the different machine types?\n- Why should you consider the typical workload patterns when making your hardware decisions?\n- Are all microservers created equal for Hadoop deployments?\n- How do I plan for expansion if I require more compute, memory, storage or networking?", "label": 1}
{"text": "\"I AM continually shocked and appalled at the details people voluntarily post online about themselves.\" So says Jon Callas, chief security officer at PGP, a Silicon Valley-based maker of encryption software. He is far from alone in noticing that fast-growing social networking websites such as MySpace and Friendster are a snoop's dream.\nNew Scientist has discovered that Pentagon's National Security Agency, which specialises in eavesdropping and code-breaking, is funding research into the mass harvesting of the information that people post about themselves on social networks. And it could harness advances in internet technology - specifically the forthcoming \"semantic web\" championed by the web standards organisation W3C - to combine data from social networking websites with details such as banking, retail and property records, allowing the NSA to build extensive, all-embracing personal profiles of individuals.\nAmericans are still reeling from last month's revelations that the NSA has been logging phone calls ...\nTo continue reading this article, subscribe to receive access to all of newscientist.com, including 20 years of archive content.", "label": 1}
{"text": "When to trust a website\nKnowing when to trust a website depends in part on who publishes the website, what info they might want from you, and what you want from the site. If you're not sure whether to trust a website, consider these questions:\nSmartScreen Filter in Internet Explorer helps protect you from phishing and malware attacks by warning you if a website or download location has been reported as unsafe.\nWindows SmartScreen checks the reputation of apps downloaded from the Internet and warns you if the app isn't well-known and might be malicious.\nIf Windows SmartScreen isn't turned on, then SmartScreen Filter in Internet Explorer will check the reputation of downloaded apps. If the app doesn't have established reputation, a warning dialogue is shown.\nIf you're visiting the website with a secure connection, you'll be able to identify the website through the site's certificate. A secure or encrypted website address will begin with HTTPS rather than HTTP, and you'll often see some sort of icon in the browser, such as a padlock indicating that the website is secure. Secure connections use certificates to identify the website and to encrypt your connection so that it will be more difficult for a hacker to view.\nDepending on the type of certificate the website has, you can see the website address or the company address that the certificate was issued to. Extended Validation (EV) certificates will turn the address bar green in some browsers, and will contain a confirmed name and address for the website owner. Non-EV certificates will contain the website address or the domain of the site. If you can view a security report, and it only shows the website's address, be sure it's the address you wanted to visit. Phishing or fraudulent websites will often use similar website names to trick visitors into believing they're visiting trusted sites.\nCertificates are issued by companies called certification authorities. Windows contains a list of the most common certification authorities. If Windows doesn't recognise the issuer of the certificate, a warning message will appear. However, Windows can be configured to trust any certification authority, so you should not rely solely on receiving a warning message when a website is potentially fraudulent.\nAn Internet trust organisation is a company that verifies that a website has a privacy statement (a posted notification of how your personal information is used) and that the website gives you a choice of how they use your information. Websites approved by Internet trust organisations are able to display the privacy certification seals, usually somewhere on their home page or order forms. However, these seals don't guarantee that a website is trustworthy; it just means the website complies with the terms acceptable to the Internet trust organisation. Additionally, some unscrupulous websites might display the trust logos fraudulently. If you're not sure whether a trust logo is legitimate, contact the trust organisation to see if the website is registered with them.\nTo learn more about these trust organisations, you can go to the TRUSTe website, the BBB Online website\nor the WebTrust website.\nIf you're asked for personal info, such as credit card numbers or bank information, only provide it if there's a good reason to do so. Also, make sure there's a secure entry form for recording info. Look for a message stating that the info will be encrypted and check for a lock icon or ensure that the web address starts with HTTPS:// (don't enter confidential information if neither of these are present). Also, try to find out what the website's policy is about storing info: Do they keep your credit card number on file? Do they have partners that they share info with? You should be confident that the site is using your info properly and in a secure manner before you provide it.\nDo they have a phone number that you can call if you have a problem, or that you can use to place an order? Does the website list a street address? Is there a posted return policy with acceptable terms? If the site doesn't provide a phone number or physical address, try contacting the company by email to ask for that info.\nIf you're not familiar with a website or it doesn't have a privacy certification seal, you might still be able to trust it. Ask reliable friends or colleagues about the site. Search for references to the site on the Internet to see if a source, such as a magazine or company that you do trust, has referred to it. Read the website's privacy statements or other disclosures (but keep in mind that the site might not necessarily abide by them).\nA website might not be trustworthy if:\nThe site is referred to you through an email message from someone you don't know.\nThe site offers objectionable content, such as pornography or illegal materials.\nThe site makes offers that seem too good to be true, indicating a possible scam or the sale of illegal or pirated products.\nYou're lured to the site by a bait and switch scheme, in which the product or service isn't what you were expecting.\nYou're asked for a credit card as a verification of identity or for personal info that doesn't seem necessary.\nYou're asked to provide a credit card number without proof that the transaction is secure.", "label": 1}
