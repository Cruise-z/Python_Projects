{"text": "Maybe you are dealing with a Virus or Malicious code right now and your quest for information on this subject has brought you to this very site.\nBelow we have listed some of the most common forms of viruses, how they are spread, as well as information on Trojans and Worms and how to deal with them.\nWhat is a Virus?\nA Virus on a computer is a program that attaches to another file or program, usually an executable file and is self replicating. The virus is not usually active until the infected file or program is opened. A computer virus can be spread from one computer to another replicating itself on each computer. A Computer Virus is only spread through human action, (such as running an infected program or mailing such a program). There are different levels of severity in computer viruses. Some are mainly annoying, causing your computer to slow down while others can permanently damage your Hardware, files, software and system security.\nViruses were originally spread through Diskettes or floppy disks but now are most commonly spread through the internet. There are many ways to transfer a virus on the internet. Some methods include Spam email, shared online files like Music and Images, free downloads, plugins, free scans or just by trying to close a popup on an unfamiliar site. The methods used to spread malicious code and viruses are many and grow more and more sophisticated. That is why it is important to have up to date internet security or antivirus software on your computer. Unfortunately, while anti-virus software and internet security software catch a large amount of common viruses, malware, trojans and worms, they don’t protect you from all threats. There are many Viruses that are designed to go undetected by Antivirus software i.e. the Redirect Virus and some viruses that are constantly changing and not detected, such as a Polymorphic Virus. That is why it is important to be careful when entering an unfamiliar websites and never open email from an unfamiliar source.\nBoot Sector Virus\nThe Boot Sector Virus is more of an old school virus that originated with floppy disks. The Virus would be introduced to the computer via an infected Floppy Disk. The Virus would then replicate to the Boot Sector where the disc type and format are stored . The virus would then move on to the Hard Drive. Then every time a new disk was introduced to the drive the virus would replicate to the new floppy disk. Today Floppy disks are rarely used so a Boot Sector Virus is transmitted in other ways and targets the operating system. Most Anti-Virus Software have no problem eliminating this Virus.\nRedirect Virus or Browser Hijack\nThe Redirect Virus (AKA Browser Hijack, Google Redirect Virus, Hijack Virus, etc…) is a common occurrence on the internet. This Virus is spread many different ways including voluntary download. There are many purposes for this Virus but the main action is to direct your browser to sites the hacker wants you to go to. Often your search results will look fine but when you click the link you will be brought to a site that has nothing to do with your search. These may just be ad sites or products sites the hacker wants you to buy or it could be more sinister. Often these sites look to install malware on your computer. The intent is much more harmful than selling you something. These sites may instal Spyware or Trojans seeking to capture personal and financial information for the hacker.\nRemoving the Redirect Virus is a big problem. The Redirect Virus hides successfully from most anti-virus software. Often the Security Software will find and eliminate the malware that was installed on your computer but not the Redirect Virus. After a short time the Redirect Virus will send your browser to the bad sites to reinstall the malware, starting the whole process over.\nFor successful removal of the Redirect Virus, you need a program or system specifically designed to remove it. Click here for more info.\nFile Infector Virus\nThe File Infector Virus attaches itself to program files with the extensions .exe or .com. When the host program is activated the virus acts. The virus can be crafty and go unnoticed. It often alters only part of a file or none of it, only replacing unused files in a program. The File Infector Virus is one of the most common viruses and is usually detected by Antivirus Software.\nA Polymorphic Virus has the ability to change and Morph its appearance thus making it very difficult to detect. The inner workings and function of the virus remain in tacked while the outer structure is ever changing. A Polymorphic Virus often changes its’ code every time it is enacted. Often this Virus uses an encryption algorithm that will alter itself when certain conditions occur.\nAnti-Virus Programs search for specific codes to detect viruses. With a Polymorphic Virus ever changing its’ code, it is very difficult to detect.\nIt is important to stay current on your Anti-Virus Software updates. They are continually adding new IDs to new and new versions of old viruses.\nBy the commissioning of the 32-bit operating system Windows 95, it became possible to include macros. A Macro Virus is therefore also called a 32bits-virus. A macro is typically used to change font or to automatically insert a piece of text. However, when a word macro includes a virus, it enacts the virus immediately when the file is opened. This Virus can also be transmitted from other software packages in MS Office that support macros. Macro viruses work as an independent platform, so if the virus is included in an attachment from a windows pc, it can also works on a Mac.\nThe most popular version of this virus was the Melissa Virus. This Macro Virus exploited Word’s link to Microsoft Outlook and would mail itself to everyone on the hosts mailing list. Ouch!\nMost Anti-Virus Software have no problem finding this Virus.\nA Multipartite Virus or Multi-Part Virus attacks you system in several ways at once. It will attach to the Boot Sector and your Executable files at the same time. While the virus attaches to your Boot Sector files it attacks your system files. When it attaches to your system files i.e. your .exe and .COM, files it attacks your Boot Sector files. The only way to get rid of this Virus is all at once. Otherwise it will just continue the ping pong game until it is fully removed.\nA Resident Virus is one that remains in the system memory after it is executed. In other words, the infected file is installed and executed on your computer. The virus imbeds itself in the system memory and acts independently from the infected file. So even when the infected file is detected and removed, the Virus remains in the system memory.\nDirect Action Virus\nThe Direct Action Virus is another old school type virus and is not seen as much today. The Direct Action Virus is a One Trick Pony that only opens when the infected file is opened. It then lays dormant unless the infected file is opened again. This type of Virus is easily detected with AntiVirus (AVS) Software.\nWeb Scripting Virus\nThe use of complex code in order to execute and play video on websites has opened up a whole new set of script to be exploited with viruses and malware. These are known as Web Scripting Viruses. Most of the time these scripting viruses are not forcibly introduced to a system but innocently introduced through code uploaded without the webmaster being notified.\nAlthough a Web Scripting Virus can seriously compromise the security of your system. The Web Scripting Virus can be easily removed using your free Microsoft tool.\nYour Microsoft Tool software is easy to run and comes defalt with windows Vista, Windows 2000, and windows 7. To use your Microsoft Tool to remove a suspected Web Scripting Virus, simply follow these steps.\n- Select the RUN button\n- Go to the start menu and type MRT.\n- Click next\n- Select Full Scan or Quick Scan\n- Click next\n- Observe the prompts\n- Click finish\n- Restart the machine.\nWhat is Spyware?\nThe sole purpose of Spyware is to collect information on a users computer without the user knowing it. While Spyware is considered a Malicious Software it is also used by computer owners in the corporate world to monitor employees on shared computers. Spyware can be designed to collect almost any data on a computer such as Key logging, browsing and surfing habits as well as personal information. Spyware is also sometimes used by parents to monitor children’s internet habits.\nUnfortunately Spyware is also used as Malicious software. Spyware can be very hard to detect and collect almost any kind of information. When installed on an unsuspecting users computer Spyware can be used to capture personal and financial data. Spyware used as Malware can be a huge security threat to any computer system.\nWhat is a Computer Worm?\nA Worm is very similar to a Virus by design and spreads from computer to computer. One big difference though is that a worm needs no human help, it will spread all on its’ own. A worm takes advantage of information and file transfer operations on your computer which allows it to travel and replicate by itself.\nAn example of the effects of a Computer Worm is one that self replicates on your computer, then access your contact list and emails everyone on it. Not only do all your contacts get multiple emails from you, but when they open these emails the worm spreads to their computer and continues the same process of mailing itself to all their contacts and so on, and so on.\nThe continued replication of a Worm on your computer can eventually eat up all your memory and slow your computer to a crawl or worse, shut it down. In the case of the Blaster Worm, the worm dug its way into the system and allowed hackers to then control the host computer remotely\nWhat is a Trojan Horse?\nMuch like the mythology it is named after a Trojan Horse is not what it seems to be. The Trojan is introduced to a system disguised as a legitimate file or software program. Unlike Worms and Viruses, Trojans do not reproduce or self replicate. Instead, once it is opened the devastation begins. Trojans are sometimes just an annoyance, altering your desktop or damaging and deleting files. Trojans are also known to compromise your system by opening a back door, allowing malicious users to access sensitive personal files and information. Not only can this compromise the security of your personal computer system but all the accounts you have online. Yikes!!!\nHow do I protect myself from all these Viruses, Worms and Trojans?\nThe best way to protect your self from all these menacing malicious codes is to be very careful about anything you download. Don’t open emails from people you don’t know, (No matter how tempting the offer). Keep your Anti-Virus Software and Internet Security software up to date. Check for updates once a week. If you think you have a Redirect Virus, take care of it as quickly as possible before it gets more serious.\nThis site has a full range of Software reviews available under each category listed in the menu bar.\nAs well as Categories such as Anti-Virus Software, we have a Featured Software page that list Best User Reviewed Software from all categories.", "label": 1}
{"text": "become an editor\nthe entire directory\nonly in Security/Honeypots_and_Honeynets\nHoneypots and Honeynets\nOpen Directory - Computers: Security: Honeypots and Honeynets\nComputers: Security: Internet: Research\nComputers: Security: Intrusion Detection Systems\nAn Evening with Berferd\n- A hacker is lured, endured, and studied. One of the first examples of a honeypot. First published in 1992.\nAnton Chuvakin Honeynet\n- Live honeynet status data, papers produced as a result of research, and other related resources.\n- A program that acts as a honeypot for spammers who use spambots to harvest email addresses from Web sites.\nBuilding a GenII Honeynet Gateway\n- A short guide to build a GenII Honeynet Gateway, also called a Honeywall, under Linux, broaching the most common problems and providing several solutions and tips.\n- A high interaction client honeypot. A client honeypot is a security technology that allows one to find malicious servers on a network.\nDeception ToolKit (DTK)\n- A toolkit designed to make it appear to attackers as if the system running DTK has a large number of widely known vulnerabilities.\nDeploying and Using Sinkholes\n- Sink Holes - an ISP Security Tool [pdf]\nFor Stronger Password Security, Try a Spoonful of Honeywords\n- Describing new scheme of password protection called honeywords.\nGlastopf Honeypot Project Page\n- Glastopf is a small Python webserver which emulates thousands of web application vulnerabilities.\nGoogle Hack Honeypot (GHH)\n- Emulates a vulnerable web application by allowing itself to be indexed by search engines. Project information and free download.\n- A free windows based medium interaction honeypot solution.\nHoneyC Low-Interaction Client Honeypot\n- A platform independent low interaction client honeypot that allows identify rogue servers on the web.\n- A virtual appliance containing various honeypot software packages.\n- A community of organizations actively researching, developing and deploying Honeynets and sharing the lessons learned.\nHoneySink: Beta Release | The Honeynet Project\n- HoneySink is an open source network sinkhole that provides a mechanism for detection and prevention of malicious traffic on a given network.\n- A tool for semi-automatically creating emulators of network server applications.\n- A weblog about with IT-security, honeypots, and honeynets.\n- A system for automated generation of signatures for network intrusion detection systems (NIDSs).\n- Small daemon that creates virtual hosts on a network (honeypot). Can be used as a virtual honeynet, for network monitoring, or as a spam trap. For *BSD, GNU/Linux, and Solaris.\nHoneyd Control Center\n- Honeyd configuration wizard, a SQL Interface, and reports.\n- Brazilian Honeypots Alliance. Includes tools to summaries honeyd logs, mydoom.pl (A Perl script which emulates the backdoor installed by the Mydoom virus), and an OpenBSD LiveCD Honeypot.\nHoneypot (computing) - Wikipedia\n- Brief encyclopedia article describing Honeypots.\n- Information covering intrusion detection and prevention systems, research and production honeypots, and incident handling. Also provides general overview of network security issues.\nHoneypots: Monitoring and Forensics Project\n- Techniques, tools and resources for conducting Honeypot Research and Forensic Investigation. White papers include monitoring VMware honeypots, apache web server honeypots, and VMware honeypot forensics.\nHoneypots: Tracking Hackers\n- White papers, mailing list and other resources related to honeypots.\n- The Honeywall CDROM is a bootable CD that installs onto a hard drive and comes with all the tools and functionality for you to implement data capture, control and analysis.\n- A honeynet gateway on a bootable CDROM.\nHoneywords: Making Password-Cracking Detectable\n- Research paper suggesting a simple method for improving the security of hashed passwords: the maintenance of additional \\honeywords\" (false passwords) associated with each user's account.\n- Impost can either act as a honey pot and take orders from a Perl script controlling how it responds and communicates with connecting clients; or it can operate as a packet sniffer and monitor incoming data to specified destination port supplied by the command-line arguments (pre-release version available).\nKeyFocus - KF Sensor - Honey pot IDS\n- A Windows honeypot designed to attract and detect hackers by simulating vulnerable system services and trojans.\nKnow Your Enemy: GenII Honeynets\n- An Introduction to second generation honeynets (honeywalls).\n- A program that creates a tarpit or, as some have called it, a \"sticky honeypot\".\nMedium Interaction Honeypots\n- Document outlines the weaknesses of different existing approaches to catch malware – especially bots – and shows how Medium Interaction Honeypots solves these problems. [pdf]\n- Seller of HoneyPoint family of products.\n- A low interaction honeypot designed to emulate vulnerabilties worms use to spread, and to capture these worms.\n- European Network of Affiliated Honeypots.\nNorwegian Honeynet Project\n- Aninternational, non-profit (501c3) research organization dedicated to improving the security of the Internet at no cost to the public.\nOpen Proxy Honeypot\n- Web Application Security Consortium Distributed Open Proxy Honeypot Project.\nProject Honey Pot: Distributed Spam Harvester Tracking Network\n- A free, distributed, open-source project to help website administrators track, stop, and prosecute spam harvesters stealing email addresses from their sites.\nSCADA HoneyNet Project\n- SCADA HoneyNet Project: Building Honeypots for Industrial Networks (SCADA, DCS, and PLC architectures).\nSecurityFocus: Defeating Honeypots: System Issues, Part 1\n- This two-part paper discusses how hackers discover, interact with, and sometimes disable honeypots at the system level and the application layer.\nSourceForge.net: Project - HoneyView\n- A tool to analyze honeyd-logfiles of the honeyd-daemon. Generates graphical and textual results from queries against the logfile data.\n- Website set up to deliver almost infinite numbers of bogus email addresses to email harvesting bots.\nSpanish Honeynet Project\n- Independent non-profit research organization of security professionals dedicated to information security focused on honeynet technologies.\nSweet Password Security Strategy: Honeywords - Security - Intrusion\n- To improve detection of database breaches, businesses should store multiple fake passwords and monitor attempts to use them, according to researchers at security firm RSA.\nSysenter Honeynet Project\n- A volunteer no-profit research organization. Aim is to provide information about emerging security threats and vulnerabilities active in the wild in order to learn tools, tactics, and motives of the blackhat community and to share such information with IT community in order to improve the security of the Internet.\nThe Bait and Switch Honeypot System\n- A system that redirects all hostile traffic from your production systems to a honeypot that is a partial mirror of your production system. Once switched, the would-be hacker is unknowingly attacking your honeypot instead of the real data.\nThe Strider HoneyMonkey Project\n- Microsoft Research project to detect and analyze Web sites hosting malicious code using client-side honeypots.\nThe Team Cymru Darknet Project\n- A Darknet is a portion of routed, allocated IP space in which no active services or servers seemingly reside. However, there is in fact include at least one server for real-time analysis or post-event network forensics.\nThug low-interaction honeyclient\n- A Python low-interaction honeyclient aimed at mimicing the behavior of a web browser in order to detect and emulate malicious contents\nTiny Honeypot (thp)\n- A simple honey pot program based on iptables redirects and an xinetd listener.\nUK Honeynet Project\n- Provides information surrounding security threats and vulnerabilities active in the wild on UK networks. Home of Honeysnap, tool to analyse Honeywall pcap files and extract summary information.\nWebMaven (Buggy Bank)\n- WebMaven is an intentionally broken web application. It is intended to be used in a safe legal environment (your own host) as a training tool, as a basic benchmark platform to test web application security scanners and as a Honeypot.\nWikipedia: Client Honeypot\n- Encyclopedia article about the security devices, including several examples.\n- Generates thousands of counterfeit 802.11b access points for use as part of a honeypot or to confuse Wardrivers, NetStumblers, Script Kiddies, and other undesirables.\nkippo - SSH Honeypot - Google Project Hosting\n- A medium interaction SSH honeypot designed to log brute force attacks and, most importantly, the entire shell interaction performed by the attacker.\n- A collection of programs to deploy, run and analyse network and host simulations in IP networks.\nKnow your Enemy: Phishing\n- This white paper aims to provide practical information on the practice of phishing and draws on data collected by the German Honeynet Project and UK Honeynet Project. (May 16, 2005)\nKnow Your Enemy\n- A series of white papers describing the concepts and technology of the Honeynet Project and Research Alliance and sharing lessons learned. (May 09, 2005)\nHoneynet.org: Tracking Botnets\n- Paper on the use of honeynets to learn more about botnets. Covers uses of botnets, how they work and how to track them. (March 05, 2005)\nSecurityFocus: Defeating Honeypots - Network issues, Part 1\n- Article discussing methods hackers use to detect honeypots. (September 28, 2004)\nSecurityFocus: Wireless Honeypots\n- Article discussing the use of honeypot technology to combat attacks on wireless networks. (February 13, 2004)\nSecurityFocus: Problems and Challenges with Honeypots\n- Article discussing issues with Honeypot technology, focusing on dealing with the possibility of your Honeypot being detected (and potentially abused) by an attacker. (January 14, 2004)\nSecurityfocus: Fighting Spammers With Honeypots\n- This paper evaluates the usefulness of using honeypots to fight spammers. (November 26, 2003)\nSecurityFocus: Fighting Internet Worms With Honeypots\n- This paper evaluates the usefulness of using honeypots to fight Internet worms and perform counterattacks. (October 23, 2003)\nSecurityFocus: Dynamic Honeypots\n- Honeypots that dynamically learn your network then deploy virtual honeypots that adapt to your network. (September 15, 2003)\nSecurityFocus: Honeypot Farms\n- This article is about deploying and managing honeypots in large, distributed environments through the use of Honeypot Farms. (August 03, 2003)\nSecurityFocus: Honeytokens -The Other Honeypot\n- This paper discusses honeytokens, honeypots that are not computers, but rather digital entities that are stored in a restricted part of the network. (July 21, 2003)\nHoneypotting with VMware\n- An article about how to use VMware to produce honeypots to catch system intruders. (February 05, 2002)\nHoneypot + Honeypot = Honeynet\n- Article discussing the creation of the Honeynet Project. (September 24, 2001)\nHoneypots and Honeynets\n\" search on:\nCopyright © 2013 Netscape\nVisit our sister sites\nLast update: Monday, April 8, 2013 12:14:33 PM EDT -", "label": 1}
{"text": "NIST and others work on how to preserve data for later use\n'One of the big challenges of long-term archiving is deciding what to keep for how long. We're not doing a very good job on that now. There's a long way to go.' JOSH LUBELL, NIST\nIt's a threat to any agency data-sharing initiative. It can render a knowledge\nmanagement system obsolete. And in the future, it could mean the difference between a successful space launch and a trip back to the drawing board. It is, simply, data loss. Or data degradation. Or even data alteration. As more of what government creates in support of its mission is rendered digitally, experts must struggle with questions of how to ensure that digital data is available'and reliable'for future users.\nThe National Institute of Standards and Technology hosted a workshop in March on\nlong-term knowledge retention, looking for answers to the questions of what digital data government, industry and academe should be saving, and how it should be saved.\nThey came up with no immediate answers, but they confirmed that a problem certainly exists and it's growing, said Josh Lubell, a computer scientist in NIST's Manufacturing Engineering Laboratory.\nAccording to estimates offered at the workshop, the world churns out enough digital\ndata to fill the Library of Congress every 15 minutes. Much of that is of no interest to anybody and can be discarded quickly. But in areas such as engineering, the production of information is outpacing our ability to ensure\nit will be available to those who may\nneed and want to share it later on. As\ncomputer-aided evolves into computergenerated,\nterabytes of data are disappearing,\nor becoming inaccessible or corrupted\n'So much information is digital, and\npeople are feeling the pain of losing access\nto their information,' Lubell said.\nThe attendees at the workshop agreed\non the need to establish a business case\nfor long-term data archiving and to develop\nstandards for ensuring\nof data across time\nas well as across\nhardware and software\ndrawings are routinely\nsaved today, said Doug Cheney, an interoperability\nconsultant and product director\nfor ITI TranscenData of Milford,\nOhio. But unlike blueprints of the past,\ncomputer-aided design drawings, which\nare becoming increasingly important elements\nof geospatial initiatives, represent\nonly the tip of the design iceberg.\n'Digital data is not hardened, especially\n3-D geometry,' Cheney said. 'It is very interpretive,\nso it's easy for unexpected\nthings to creep in.'\nThe problem is compounded, because\nchanges that creep in when data is moved\nfrom one platform to another often are\n'It's what we don't know that will kill\nus,' Cheney said.\nThis dilemma came to light in the aftermath\nof an industrial accident in Green\nBay, Wis., when a pipe feeding a boiler exploded,\nscalding two men to death. The\nimmediate problem was corrected, but in\nthe next few years the company involved\nchanged hands several times, said Crispin\nHales, an engineering forensics investigator\nin Winnetka, Ill. In the process, a lot of\ninstitutional knowledge was lost.\n'They almost had a repeat of the failure,\nand they had no records of what had happened\nonly five years before,' Hales said.\nTacit knowledge goes missing\nThe problem is the disappearance of what\nHales called tacit knowledge. Forty years\nago, organizations were stable, people remained\non the job for years and there was\na community of knowledge that could be\n'That is gone,' Hales said. It has been\nreplaced by a more fluid environment,\nwhere access and exchange of complex\ndata has replaced knowledge.\nAt the same time, data has become\nmore complex. Too often that data, if it\nwas retained, is not reliable because the\nsystems used to generate it\nare no longer available.\n'The government has this\nproblem in spades,' said\nWilliam Regli, associate professor\nof computer science at\nLarge engineering projects by\nthe Defense and Energy departments\namounts of data on systems\nthat quickly become obsolete.\nNASA's space shuttle program,\none of the most complex engineering\nprojects in history,\nkicked off in 1981 and the last\nshuttle is not scheduled to be\nretired until 2009. The B-52\nStratofortress, for years the\nbackbone of the Air Force's nuclear\narmada, first flew in 1954,\nand its operational life span is\nexpected to extend to 2040.\nThe preservation and maintenance\nof electronic data is a\nproblem many agencies are\nwrestling with, including the\nNational Archives and Records\nAdministration and the\nLibrary of Congress. The library has for\nseveral years been digitally preserving information\nfrom other media, from audio\nrecordings to parchment manuscripts.\nNow, under the National Digital Information\nInfrastructure and Preservation Program\nauthorized by Congress in December\n2000, it's working with other federal agencies\nand private-sector organizations to develop\na national strategy for collecting,\narchiving and preserving the growing volume\nof materials created only in digital formats\nBut NIST and others are particularly\nconcerned about preserving the engineering\ndata that goes into missions throughout\ngovernment. The Library of Congress\nand NARA funded some of Regli's work at\nDrexel University on digital preservation.\n'I got into the engineering side of it\nabout five years ago,' he said. 'The digital\nCAD process has a wealth of information\nthat isn't saved in any meaningful way.'\nEngineering data had become too complex\nfor humans to process on their own,\nhe said. In the recent past, drawings produced\nby a draftsman with pen and\npaper were based on a human level of\nknowledge. Computer-aided designs are\nbased on levels of complexity and assumptions\nthat are not reproduced when\nthe final drawings are printed or displayed.\nThese often ephemeral assumptions\nand calculations can be as important\nas the drawing.\nBeyond our comprehension\nCAD systems today deal with higher orders\nof geometry beyond our comprehension,\n'You can't write an equation for the\ngeometry,' he said. 'The geometry is closely\ntied to the software that interprets it.'\nThat software changes through a design's\nlifecycle as it moves from one platform\n'Each time it is produced, it's slightly\ndifferent,' he said.\nOne solution offered now by ITI TranscenData\nis a CAD add-on tool that analyzes\npotential shape and fit problems in\nCAD models as they are translated between\nIndustry is aware of the problem of design\ndrift and corruption, but the solutions\nso far are mostly industry- or even\n'There is a lot of redundant effort in\nAmerican industry,' Regli said. This translates\ninto wasted effort and interoperability\nproblems. And it does not address the question\nof long-term retention as systems become\nobsolete. 'How do you ensure\nThese issues often get little\nattention in the private sector\nbecause they don't produce\n'The ultimate beneficiary is\nnot the current business unit,\nbut some future entity,' Regli\nCurrent shareholders often\nare reluctant to pay for things\nfuture shareholders will bene-\nfit from, Lubell said.\nThat is why government is\ngetting involved in developing\ntechnical standards for longterm\npreservation. But government\nwill not be able to solve\nthe problems by itself.\n'The business case has to be\nmade first,' to convince people\nto use standards, Lubell said.\n'It's a challenging area because\nit's not dealing with an\nimmediate issue,' Regli said.\nThere are some standards in\nplace, most notably the International\nStandard for the Exchange\nof Product Model\nData. But none answer all the\nneeds for interoperability\nwith long-term integrity and\nWithin government, NIST's Manufacturing\nEngineering Lab has an exploratory\nprogram for developing data standards,\nand the IT Laboratory has a digital\npreservation program that is investigating\nhow digital data degrades over time.\nEfforts are under way by industry groups\nto extend STEP for archiving quality by\nadding geometry exchange specifications,\nand to include definitions for validating\naccuracy when data is exported. The European\naerospace industry has begun a standards\nprocess for archiving 3-D images\nthat at least some of the U.S. aerospace industry\nOnce adequate standards exist, the\nquestion will remain, what needs to be\nAs storage becomes cheaper and access\nquicker, Regli said one philosophy is:\n'Why not just store everything?' But\nyears down the road, that approach could\nproduce the equivalent of digital archeology,\nas engineers and researchers sift\nthrough terabytes of data searching for\nthe nugget they need.\n'You have to strike a balance,' Lubell\nsaid. 'One of the big challenges of longterm\narchiving is deciding what to keep for\nhow long. We're not doing a very good job\non that now. There's a long way to go.'", "label": 1}
{"text": "Smartphones have become a global phenomenon and in Japan in particular people are rapidly replacing their old cellphones with new handsets that are more like small computers with ever-increasing applications.\nBut with the boom comes concerns for security, and fears that personal information may be leaked via malware or some applications. The malicious software, often in the form of a virus, can work its mayhem unnoticed, bent on disrupting the operation of certain systems.\nWe look at recent smartphone security issues and how users can protect themselves:\nHow can the information of smartphone users be at risk?\nAccording to Tokyo-based Trend Micro Inc., an antivirus software provider, certain malware has the potential to do serious harm.\nOne type records user phone conversations and stores it in memory for later transmission.\nAnother type of malware can be used to remotely control infected smartphones, enabling perpetrators, for example, to place calls for paid phone services, leaving the owner stuck with a huge bill.\nMedia reports have also recently highlighted personal information leaks from smartphones, including phone number, device identification number, location information and the kinds of applications the user has downloaded.\nFor instance, Manuscript, a Tokyo-based application provider, created a program called Karelog that enables users to track another smartphone user’s location information and battery life.\nThe application may be handy for people to keep track of loved ones, but smartphone users may be registered without their knowledge, and thus information about them could be leaked.\nThis application differs from a virus attack, but it has caused controversy because it exposes the vulnerability of personal information via seemingly benign services.\nDo all smartphones have the potential to leak information?\nIndustry watchers say Google Inc.’s Android system is more vulnerable than competitors, including the iPhone by Apple Inc., the BlackBerry by Research in Motion Ltd. and Windows mobile phones by Microsoft Corp.\nThis is because the Android OS, which has greatly expanded its global share in recent years, is an open platform that makes it easier for application developers to incorporate and spread malware in their products.\nAccording to U.S.-based IT consultancy Gartner Inc., as Android led the world in market for smartphone operating systems, accounting for more than a 40 percent share in the second quarter of this year.\nTrend Micro also said Android-targeted malware has been increasing dramatically. While there were only five kinds last December, the number had jumped to 533 by October.\nAs for iPhone applications, all have to be checked by Apple before they are released, so malicious applications are mostly blocked by the firm.\nHave smartphone users been victims of swindles?\nWhile many users may have unknowingly experienced relatively harmless personal information leaks like location data, no cases of fraud have been reported. The communications ministry said it has not confirmed any serious incidents involving money.\nKeisuke Takemori, a researcher at KDDI R&D Laboratories who tracks smartphone malware, said in a recent online streaming program that he has no knowledge of users falling victim to a serious malware attack. Over the past two years, Takemori has been trying applications with malware every day but has not received any bills or calls demanding money, he said.\nWhat countermeasures are smartphone carriers taking against malware attacks?\nTakemori said KDDI’s au brand runs its own Android application market and monitors to see if applications are incorporated with malware or are designed to gather more user personal information than necessary.\nHe also said KDDI is advising application developers to clearly inform users about the kinds of personal information they seek and for what purposes and over what time span after users open applications for the first time or if they double-check their status.\nDoCoMo provides a free antivirus application for its Android users, while Softbank offers a smartphone security service, including an antivirus application, for ¥498 a month.\nSoftbank and KDDI, which both now offer the iPhone, said Apple handles security for those handsets.\nHow can users best ensure security?\nTakemori said users should make sure they update their operating system to the latest version, which should reflect updates to protect devices from new and evolving malware.\nAndroid users should also get applications through reliable sources, such as those that are managed by the phone carriers.\nMarket observers said using programs designed to combat malware are effective.\nIt is also important to educate users and raise the comprehensive understanding of smartphone security, they said.\nFor instance, some users don’t really bother to read messages from application developers, but that can result in them unknowingly providing personal information.\nThe Weekly FYI appears Tuesdays. Due to editorial reasons it appears Wednesday this week. Readers are encouraged to send ideas, questions and opinions to email@example.com", "label": 1}
{"text": "Computer Security for Schools and Small Businesses\nFor a small-to-medium enterprise like a business or library, protection of its computer network is not easy. Hackers are constantly concocting new ways to infect the network (with viruses and other malware) by way of the web pages that network users visit. Although the enterprise can choose from an array of tools to protect its network, those tools can be expensive and cumbersome. No tool or combination of tools is perfect. Finding the right mix of cost, effectiveness and easy of use is a problem.\nTo answer this problem, CyberPatrol has developed a smart service for steering network users away from dangerous web sites. Known as SiteSURV, the service relies on CyberPatrol’s SiteCAT system, which constantly crawls (spiders) the web to assess and categorize web pages. The service provides two layers of filtering. One layer examines sites according to their content and purpose, and then blacklists those that appear to be dangerous. The second layer specifically analyzes files and downloads from each site to ascertain whether they contain signatures for known malware.\nI asked Chris Overton, VP of CyberPatrol, to explain these two layers of protection. First, he highlighted the security achieved just by keeping users away from sites of questionable content: “Certain types of sites tend to deliver malware more than others. Along with adult and XXX sites, “parked domains” and “warez” sites are more likely to deliver malware than other site categories. We know this because files pulled from these sites have a higher percentage of malware infection than files from other sites. So, we can infer that preventing access to these dangerous site categories will advance the fight against malware infections. Preventing access to a dangerous site protects against all the malware at that site, regardless of whether anyone has developed signatures to detect any or all of the different malware there.”\nChris further described what SiteCAT does when it crawls a web site: “SiteCAT’s algorithms analyze a web site based on several factors – content, structure, link count, link references, and so on. Based on this analysis, our system decides which pages/files to download from that site. Typically we’ll download the main index page of a site and analyze it; then our algorithms decide how much deeper to dig. All files we want to analyze are pulled by the crawler and saved into our analysis archive. Then the files feed into a malware detection engine, which looks for the signatures of malware such as a virus or a worm. If we detect any malware when we crawl the site, we can blacklist it and prevent all of the malware the site might deliver, even malware that we have not specifically detected.”\nIn other words, SiteSURV allows an enterprise to adopt a conservative, one-strike-and-your-out approach toward web sites. If a site either contains suspicious content or manifests one instance of infection, the enterprise can block it entirely.\n–Ben Wright, advisor to CyberPatrol", "label": 1}
{"text": "Patient data is more accessible than ever thanks to patient and provider mobile connectivity. Data protection and patient ID verification have become critical parts of health care infrastructure. Providers want to identify their patients as quickly as possible, if they’re in need of emergency treatment, but they also need to ensure the data they're reading is accurate and secure.\nRead this guide to understand how different health care patient ID verification technologies and trends, including single sign-on, data breach protection and response, and more, have affected and will continue to shape the health IT industry.\nTable of contents:\nIdentification numbers or codes can be used to authenticate doctors and verify the accuracy of patient data. Hospitals also use IDs to control what information doctors can access through the use of their mobile devices. Read more to see other ways in which IDs are currently used in health care facilities.\nSingle sign-on in health care\nSingle sign-on technology enables doctors and patients more convenient access to their information by giving them one login name and password that grants them access to various processes. Read how else single sign-on is used to protect and grant access to critical data.\nPatient info data breaches\nInstances of compromised or stolen data are preventable through patient and physician education. However, there have been examples of data breaches in which patient information has been exposed, including a notable breach at Beth Israel Deaconess Medical Center in Boston.\nFuture patient ID options and regulations\nA national system consisting of a unique patient ID for every American has been a stated goal of some health care personnel. This is one possible option for secure patient identification in the future. There are other areas, like cloud and mobile devices, that are changing the way that health care IDs will be used.", "label": 1}
{"text": "Kaspersky Lab, an international data-security software developer, reports the detection of the \"Donut\" virus, which is the first malicious program to infect .NET files.\n\"Donut\" has been developed by the notorious Czech hacker going by the pseudonym \"Benny\", who is a part of the \"29A\" virus-writers group. \"Benny\" is known to be the author of many proof-of-concept viruses among which are \"Stream\" (the first NTFS alternate data streams infector), \"Inta\" (the first Windows 2000 virus), \"HIV\", \"Champ\", \"Eva\", \"Begemot\", etc.\nThe most intriguing aspect about this virus is that the .NET technology, which Microsoft presents as the future substitute for Java, has not yet been officially released and intrinsically is still under development.\n\"It is well-known that virus writers are primarily interested in the most popular and wide-spread software products, which nowadays are undoubtedly the Microsoft technologies. The appearance of 'Donut' confirms the opinion that the company's products are guaranteed to be popular not only among users but also among virus-writers,\" commented Denis Zenkin, Head of Corporate Communications for Kaspersky Lab. \"This time the computer underground decided not to wait for the official release of the promising technology and to start developing the .NET-specific malicious programs beforehand, anticipating the technology's future commercial success.\"\nWhen the virus-carrying file is executed, \"Donut\" loads itself into the system memory and starts searching for the .NET-files on the target computer. If such files are found, the virus infects them by modifying the files' entry point. Thus, when the infected file is launched, the virus code is executed, which then passes control to the .NET-files processor in order to execute the original .NET-file:\nIt is important to note that \"Donut\" is not a pure .NET-virus. It simply infects .NET-files, but is virtually an ordinary Windows-executable code written in Assembler.\nExcept for infecting other .NET-files, the virus has no additional dangerous side-effects and no destructive payload.\nKaspersky Lab believes that \"Donut\" poses no real danger to computer users because of the low prevalence of .NET technology. Therefore, even if a user accidentally starts an infected file, the virus will not do any harm to the computer due to the absence of the .NET-files processor and other .NET-files necessary for infection.\nDefense procedures against \"Donut\" have already been added to the Kaspersky Lab daily anti-virus database update as of January 10, 2002.\nMore detailed information about this malicious program is available in the Kaspersky Virus Encyclopedia.", "label": 1}
{"text": "> View this now\nPublished on: May 19, 2011\nType of content: EGUIDE\nLength: 6 pages\nThe possibility of a data breach is very real – no matter how proactive your security measures are. So, how can you effectively respond to security incidents to ensure a proper breach investigation?\nLearn about computer forensics, a technology used to secure, collect and analyze digital evidence related to security incidents and data breaches.\nAccess this expert FAQ guide for further insight into how computer forensics can help put a well-formed incident response plan that is aligned with your information risk management and compliance strategies. Get answers to your compliance questions, including:\n- What’s the difference between computer security and computer forensics?\n- Is a formal forensics analysis needed for every suspected or known security breach?\n- How do I integrate computer forensics with my compliance programs?", "label": 1}
{"text": "Sharing software code via free open source has been around since the 1980s and has enjoyed much success. Open source has been applied to content, websites, technological parts, and other materials. Can and should an open source platform be monetized?\nOn GitHub, anyone with an account can share improvements of existing code by downloading it from public repositories (online storage spaces for code) on that website, modifying this downloaded copy, and submitting his or her modifications to the original owner for approval. If the original owner likes the modification, the originator can combine it with the original code and share this updated version with others, and the modifier will get credit for his or her contribution.\nGitHub uses a source code management system called Git, but with a twist—users can make contributions through a web-based graphical interface (instead of the command line tool of regular Git), control who has access to their code with a paid account, and collaborate with an unlimited number of users.\nSince its launch in 2008, GitHub has been funded through paid subscriptions, which range from $7 to $200 per month for individual subscribers and start at $5,000 per year for bigger businesses. That is, until recently. In June 2012, GitHub accepted $100 million investment funding from the venture capital firm Andreeson Horowitz. Reportedly this funding will be used to hire more employees, expand to new platforms such as mobile, develop new features and improve existing ones, and in general make GitHub more user-friendly for a broader range of clients from individual hackers to large enterprises, thereby expanding its subscription base.\nBut how and why monetize open source code? The open source movement itself promotes free redistribution and access to source code, and started as a collaborative effort by members in the technological community in response to proprietary software. Monetization of open source is not entirely new. Red Hat, Inc. has been since 1993 “monetizing” subscriptions for support, training, consultation, and integration services to help customers in using open source code available via its company. Still, GitHub’s financing and business models are notable. GitHub gives free subscriptions to users who keep their repositories public, but it also offers private repositories for a fee.\nIn addition to making it easier for users to network and collaborate, because the website keeps track of a user’s contributions through his or her profile, corporate users can easily find examples of code work someone has done. Therefore, a person’s profile functions as a resume and may lead to paid assignments. In fact, Forbes magazine has referred to it as “a one-stop shop for people looking for talent” because of its popularity among recruiters.\nUnder GitHub’sTerms of Service a user, by enabling the user’s pages to be public, allows others to “fork your repositories,” i.e., gives others a license to copy his or her code and modify it. Although GitHub claims no intellectual property rights over the material uploaded by users, who owns the modifications of the code? Also, even if the modifications of a forked repository belong to the user making the modifications, do the IP rights of the modifier transfer to the original owner upon merging the modifications?\nThe answer lies in the license under which the repository owner distributes his or her software code. For example, the Apache Software Foundation open source license (version 2.0) states that a modifier may add his or her own copyright statement to modifications of their code and provide additional or different license terms for use, reproduction, or distribution of those modifications, provided that the statement complies with the conditions of the original Apache license. The key step is to check the applicable open source license agreement of the original owner, for GitHub only provides a meeting place for collaboration—the code is still subject to the applicable licensing agreement, and any negotiations for using the code can be established between the collaborators themselves.\nCode from GitHub has been used for mobile, web, desktop, and browser apps, among other things. Both Facebook and Etsy use GitHub. The German federal government has even published federal law through GitHub. By allowing citizens to make suggested changes to the law, the German government is able to hear suggestions from everyday people. In this case, it could give brand new depth to the meaning of a government “for the people, by the people.” Open source, which is an undoubted success, may become bigger still.", "label": 1}
{"text": "Bitfrost is the OLPC proposed security specification. It does not cover all aspects, e.g. OLPC boot patches, which will likely \"be enabled by default\" according to author Ivan Krstić, who claims that \"by default, whenever the laptop connects to the Internet, it will ask the school's server if there are patches or updates available. This will be in place even if you're not in contact with the school server, you can ask the OLPC server to push down the update\" over mesh networks \"all managed by schoolteachers and kids with no computer experience\". He describes Bitfrost's goals:\n- No user passwords\n\"With users as young as five years old, the security of the laptop cannot depend on the user's ability to remember a password. Users cannot be expected to choose passwords when they first receive computers.\"\n- No unencrypted authentication\n\"Authentication of laptops or users will not depend upon identifiers that are sent unencrypted over the network. This means no cleartext passwords of any kind will be used in any OLPC protocol and Ethernet MAC addresses will never be used for authentication.\"\n- Out-of-the-box security\n\"The laptop should be both usable and secure out-of-the-box, without the need to download security updates when at all possible.\"\n- Limited institutional PKI'\n\"The laptop will be supplied with public keys from OLPC and the country or regional authority (e.g. the ministry or department of education), but these keys will not be used to validate the identity of laptop users. The sole purpose of these keys will be to verify the integrity of bundled software and content. Users will be identified through an organically-grown PKI without a certified chain of trust — in other words, our approach to PKI is KCM, or key continuity management.\"\n- No permanent data loss\n\"Information on the laptop will be replicated to some centralized storage place so that the student can recover it in the even that the laptop is lost, stolen or destroyed.\" Data backup retains all versions\n\"The machine will also feature an anti-theft kill switch that gives school administrators the ability to permanently disable lost laptops. Krstić said the OLPC received \"very strong requests from certain countries\" for a powerful anti-theft mechanism, leading to the decision to add a call-home feature that pings an anti-theft server for authentication.\"\n\"The security process actually starts at the time the machine is manufactured, Krstić said, pointing out that a randomly generated serial and UUID number is fitted into each laptop at the manufacturing plant. A brand new OLPC machine is largely non-functional unless it it activated with the key and UUID number.\"\n\"This helps to deal with a potential weakness in the distribution component, when millions of machines are shipped internationally. The OLPC will generate and deliver the [software] keys on a [hardware] USB key to the schools and, once an OLPC server is installed, the keys for specific laptops can be turned on to bring the machine to life.\"\n\"The spec assumes the machines will be potential targets for many of the threats on mainstream computes — from data theft to viruses and malware to botnets — and Krstić said the threat model calls for the machine to be resilient even if an attacker is successful.\"", "label": 1}
{"text": "On July 16, 2001, vulnerabilities in the Windows\nInternet Information Services Server (IIS) made media headlines when the\ncomputer worms Code Red I and\nlater Code Red II propagated within hours of each other and moved rapidly\nacross the Internet, taking over every vulnerable computer on the Internet.\nBy definition, a worm is a virus-like program that spreads\nfrom one computer to another without human intervention. Code Red II was\nespecially dangerous because it altered approximately 100,000 Windows NT and\nWindows 2000 Web servers on the Internet and PCs, permitting any unauthorized\nuser to log onto them and exercise total control. As of August 10, 2001,\nSymantec Security Response created a tool to perform a vulnerability assessment of computers\nand to remove both Code Red I and II.\nMalware; Vulnerabilities of Computers; Worm.\nSymantec Security Response. CodeRed Worm. [Online, July 29, 2001.] Symantec\nSecurity Response Website.", "label": 1}
{"text": "Set up a security key for a wireless network\nPersonal information and files on your wireless network can sometimes be seen by people who pick up your network signal. This can lead to identity theft and other malicious acts. A network security key or passphrase can help protect your wireless network from this type of unauthorized access.\nThe Set Up a Wireless Router or Access Point wizard will guide you through setting up a security key.\nOpen Set Up a Wireless Router or Access Point by clicking the Start button , clicking Control Panel, clicking Network and Internet, and then clicking Network and Sharing Center. In the left pane, click Set up a connection or network, and then click Set up a wireless router or access point.", "label": 1}
{"text": "Events for all Levels and InterestsStay\nJump Start Your Career GrowthStay\nGet on the Higher Ed IT MapStay\nUncommon Thinking for the Common Good™Stay\nIdentity management refers to the policies, processes, and technologies that establish user identities and enforce rules about access to digital resources. In a campus setting, many information systems–such as e-mail, learning management systems, library databases, and grid computing applications–require users to authenticate themselves (typically with a username and password). An authorization process then determines which systems an authenticated user is permitted to access. With an enterprise identity management system, rather than having separate credentials for each system, a user can employ a single digital identity to access all resources to which the user is entitled. Federated identity management permits extending this approach above the enterprise level, creating a trusted authority for digital identities across multiple organizations. In a federated system, participating institutions share identity attributes based on agreed-upon standards, facilitating authentication from other members of the federation and granting appropriate access to online resources. This approach streamlines access to digital assets while protecting restricted resources. [Source: 7 Things You Should Know About Federated Identity Management]\n- New! 2011 ECAR Identity Management in Higher Education Report\n- EDUCAUSE/InCommon Partnership: EDUCAUSE has partnered with the InCommon Federation to provide members who use our web resources, the benefits and ease of Federated Identity Management access.\n- Identity & Access Management (IAM) Working Group: This EDUCAUSE working group operates an open mailing list for general discussion of Identity and Access Management (IAM) topics and maintains a website with additional resources and links. The Higher Education Information Security Council (HEISC) also maintains a chapter dedicated to Access Control as part of the Information Security Guide.\n- IAM Tools & Effective Practices Wiki: The IAM Tools & Effective Practices project team (IAM-TEP) is focused on providing a set of resources for IAM Architects to use in implementing a cohesive program on their respective campuses.\n- IAM Online: IAM Online is a new monthly series delivering interactive education on Identity and Access Management (IAM), including federated identity management essentials, advanced issues in IAM, and hot topics from the EDUCAUSE Identity and Access Management Working Group. Experts will provide overviews, answer questions and lead discussions.\n- InCommon: The InCommon Federation eliminates the need for researchers, students, and educators to maintain multiple passwords and usernames. Online service providers no longer need to maintain user accounts. Identity providers manage the levels of their users' privacy and information exchange. InCommon uses SAML-based authentication and authorization systems (such as Shibboleth®) to enable scalable, trusted collaborations among its community of participants. InCommon also offers a Certificate Service for the higher education community, as well as a number of training and education programs such as CAMP.\n- National Strategy for Trusted Identities in Cyberspace (NSTIC): Resources include a July 2011 response to the Department of Commerce Notice of Inquiry for Models for a Governance Structure for NSTIC (prepared by EDUCAUSE, Internet2, and InCommon).\n- Shibboleth®: The Shibboleth System is a standards based, open source software package for web single sign-on across or within organizational boundaries. It allows sites to make informed authorization decisions for individual access of protected online resources in a privacy-preserving manner.\n- US Trust Federations: This community collaboration group is exploring the building of federations within and across state boundaries. Invited participants include StateNets and Higher Education Systems staff. This effort is supported by and .\nUpdated July 2011\nInCommon will be heavily involved in a $1.8 million grant awarded to Internet2 to build a consistent and robust privacy infrastructure. Partners include Carnegie Mellon, Brown, University of Texas...\nVirginia Tech has become the first identity provider to achieve Bronze and Silver certification as part of the InCommon Assurance Program.\nThe annual EDUCAUSE Conference in Denver will provide an opportunity to explore the range and depth of issues that campuses must consider as they build...\nAdvance CAMP will be held October 4-5, 2012, after the Internet2 Fall Member Meeting in Philadelphia, PA. The meeting will feature an unconference-style agenda, providing substantial time for...\nNSTIC Welcomes Trusted Federal Systems as Secretariat of the Identity Ecosystem Steering Group (IESG)\nA major milestone in the implementation of the NSTIC, \"Trusted Federal Systems (TFS) will facilitate collaboration among multiple stakeholders to help drive the creation of consensus standards...\nEve Maler, an expert on emerging identity and security at Forrester Research, discusses the past, present, and future of SAML in this webinar recording.\nLibrary Items on this Topic\nEDUCAUSE Library Items for Identity and Access Management\n- Preparing for Back-to-School BYOD\nAugust 8, 2012\nWith the BYOD trend on campus growing ever stronger, an IT network analyst shares his checklist to help ensure that your campus network is ready to manage the onslaught. …\n- Can Big Data Help Universities Tackle Security, BYOD?\nJuly 31, 2012\nUniversities have some of the most complex IT infrastructures around, and BYOD is a reality they can't escape. Chief Security Officers at universities are increasingly turning to Big Data an…\n- Domain 12: Guidance for Identity & Access Management V2.1\nOctober 5, 2010\nThis publication discusses the following major IAM functions that are essential for successful and effective management of identities in the cloud: Identity provisioning/deprovisioning …\n- Business Value of Federated Login for Enterprises, Enterprise SaaS Vendors, and Consumer Websites\nMarch 24, 2010\nThis presentation by Eric Sachs from Google was part of the RSA 2010 seminar, \"Kantara: Technology, Policy, and Compliance for Identity Services in 2010 & Beyond\". 2010 brings new o…\n- Security Guidance for Critical Areas of Focus in Cloud Computing\nDecember 18, 2009\nAdopting cloud computing is a complex decision involving many factors. It is the Cloud Security Alliance hope that the guidance contained in this work will help others better understand what que…\n- Evolution or revolution: The future of identity and access management for research\nMay 22, 2009\nIdentity and access management have become central issues for the future of the web following the unprecedented growth in user-generated content, collaboration and social activity. This year&…\n- Digital Footprints: Online identity management and search in the age of transparency\nDecember 16, 2007\nInternet users are becoming more aware of their digital footprint; 47% have searched for information about themselves online, up from just 22% five years ago. However, few monitor their online pr…\n- OpenID: Decentralised Single Sign-on for the Web\nApril 30, 2007\n\"OpenID is a single sign-on system for the Internet which puts people in charge. OpenID is a user-centric technology which allows a person to have control over how their Identity is both man…\n- Fifteenth Fed/Ed PKI Coordination Meeting\nJune 14, 2007\nThese are presentations from the Fifteenth Fed/Ed PKI Coordination Meeting, held in Washington DC, June 14 , 2007. These are presentations from t…\n- GPN: Building a Regional Middleware Infrastructure\nJanuary 1, 2006\nThe Great Plains Network (GPN) is a regional consortium of public universities in seven states: Arkansas, Kansas, Missouri, Nebraska, North Dakota, Oklahoma, and South Dakota. The long-term goal …", "label": 1}
{"text": "Honeyd can be used effectively to battle spam. Since June 2003,\nHoneyd has been deployed to instrument several networks with spam\ntraps. We observe how spammers detect open mail relays and so forth.\nThe diagram on the right shows the overall architecture of the system.\nThe networks are instrumented with open relays and open proxies. We\nintercept all spam email and analyze why we received it. A single\nHoneyd machine is capable of simultaneously instrumenting several\nC-class networks. It simulates machines running mail servers, proxies\nand web servers. Captured email is sent to a collaborative spam\nfilter that allows other users to avoid reading known spam.\nCuriously, this setup has also been very successful in identifying\nhosts infected with worms.\nOur findings are going to be made available as research paper in the\nnear future. For questions, please contact Niels Provos.\nHoneyd Spam Research Overview\nOperating System Distribution and Spam Frequency\nAn interesting question for understanding how spammers operate\nis what operating system do they use.\nUsing the support for passive fingerprinting in Honeyd 0.7, it is\npossible to identify the operating system that opens a connection to\nour spam traps. For each such connection, we try to identify the\nremote operating system on the TCP SYN segment. To determine the\ndistribution of operating systems used to send spam, we count the\nnumber of times that an operating system connects to one of the spam\ntrap systems and attempts to relay spam email.\nEven though we can not identify the operating system for 53% of the\nconnections, Linux is being used for at least 43% of all spammy\nconnections. Solaris, Windows and FreeBSD are used infrequently.\nIn summary, most machines that submit spam are running or compromising\neither Linux or Solaris. It seems\nthat Unix is the favorite operating system flavor used to send spam.\nOperating System Distribution Across Spammers\nWhen looking at the number of spam emails intercepted by the\nhoneypots, we see a noticeable increase in spam email in\nThis can be explained for several reasons. Spammers have\nbecome more aggressive in probing for open mail relays\nand some of the honeypots have been published in MX records\nfor mail domains.\nWe also see that the number of IP addresses submitting spam\nhas increased over the months, too.\nNumber of spam emails and IP addresses\nIf you have suggestions on how to improve catching spam or would like\nto make resources available, please let me know.", "label": 1}
{"text": "What Is Anonymous Web Surfing?\nYou're reading the day's headlines and you're noticing a lot of horror stories about computer security. Everyone should know to install anti-virus and anti-spy-ware on their computers, but some aren't aware that they can use a feature within their browser to ensure that people are checking out, say your bank statements. But what exactly is anonymous web surfing? And why would you want to do so?\nAnonymous web surfing is the act of surfing the web without giving sites information about you, like your IP address, your time zone, etc. Websites track this information, usually to give a more personal experience to the user while they are on the site. Browsers, like IE or Firefox, will also save the information and history of your browsing session.\nThis is where anonymous web surfing comes in handy.\nThis type of surfing usually involves using a proxy server; sort of like a middle man between your computer and the Internet. Corporations or businesses will sometimes use proxy servers, especially if they work with sensitive materials like hospital records. If using a proxy isn't going to work for you, no worries. If you've upgraded to either Internet Explorer 7 or 8, there's a built in anonymous surf feature built in. Here's some steps to activate it -\n- Open Internet Explorer. Open IE-either 7 or 8-and allow it to open to your homepage.\n- Open Safety Menu. On the upper right hand side, click on the \"Safety\" open in order to expand its options. If you don't have the \"Safety\" text or anything at all on the right hand side, you may need to enable the command bar.\n- Choose In Private. When the \"Safety\" menu is expanded, choose the option for \"In Private Browsing\". If you like shortcuts, you can also use CTRL+Shift+P to bring up another browsing window. Use this window for whatever you don't want to be tracked with, say like certain sites you don't want your parents or your boss discovering that you were on. This is especially useful if you are using a temporary computer, like at a friend's house or at the public library.\nOnce you're finished, just close the window and go about your merry way. If you use Firefox, they also have a built in anon surfing feature, but there are also more secure add-ons if you'd like to give those a try.", "label": 1}
{"text": "Posted in: Website Security\nWhile website administrators fret over the security of their software from a programming standpoint, most of them fail to realize that they’re their own worst enemy. The single biggest threat to your security is a weak password. By understanding how to make a strong password, you can avoid becoming the victim of hackers.\nStep #1: A Password is not a Word\nSadly, the word “password” makes it seem like your security credentials have to be a word. Nothing could be farther from the truth. A password should be a mix of numbers, upper and lowercase letters and symbols. For example, instead of the word “security”, you’d do better to use a symbolic password such as “53UritE!”. This makes guessing the password nearly impossible.\nStep #2: Length\nUsing a longer password is always more secure. Each character increases the security of the password exponentially. The minimum length accepted by most websites is 8 characters. Remember that this is a minimum, not an optimum. You should endeavor to make your password as long as is practical for you.\nStep #3: Convenience is Dangerous\nOne of the most dangerous security trends is the “convenience” offered by sites that allow you to log in to several different sites with the same password. This is akin to using the same key for your house, your car, your safe deposit box and everything else. Avoid this at all costs. It’ll save you a lot of headaches in the future.\nStep #4: Change them Frequently\nRemember to change your password frequently. If you suspect the security of your site has been compromised, change the password to something completely unrelated to your former password. This is imperative. If you’ve made sure that you don’t use any of your passwords on more than one site, you can be more certain that one hack won’t cascade into a series of other hacks.", "label": 1}
{"text": "By Peter Horne, one of Patty’s Pioneers\nHow Does the Internet Verify Identity? But what if they have your passport number and have the government machine that makes passports? What are the odds the bad guy will get through the process? They are now close to 100%. Your web browser is nothing more than a TSA official that checks web site passports (using Secure Socket Layer or SSL technology). It is trained to look at web sites using a set of black lights that are shipped with it. It uses these black lights to check the passport a web site presents to the browser to see if it has an “official” stamp on it. If it sees the right stamp under the right light, it tells you the site is who it says it is.\nWe all know that when you travel internationally, your passport ties the whole security process together. So let's play a thought experiment. If someone wanted to pretend to be you and travel with your identity, they would have to have your passport number so that they could book an international flight, then they would need a fake passport as photo ID at the counter to pick up the ticket, and then they would have to present the fake passport to a TSA or customs official who has been trained to study passports, including what to look for when they shine the ultra violet, or black light, on your passport. Let’s assign some very low odds to the chances of success. Let’s say that they have a 1/100 chance of getting your passport ID without detection and being able to book a flight in your name. Now let’s assume they have a 1 in 100 chance of producing a fake passport that has your passport number and photo that fools the airline ticket staff and their computer, or works in the auto check-in kiosk. Now let’s assume that there is a 1/100 chance the passport is of high enough quality to beat the trained official with their black light and experienced eye. That gives the bad guy a 1 in a 1,000,000 in making it through the process. Nice odds against the bad guy.\nHow Does the Internet Verify Identity?\nBut what if they have your passport number and have the government machine that makes passports? What are the odds the bad guy will get through the process? They are now close to 100%.\nYour web browser is nothing more than a TSA official that checks web site passports (using Secure Socket Layer or SSL technology). It is trained to look at web sites using a set of black lights that are shipped with it. It uses these black lights to check the passport a web site presents to the browser to see if it has an “official” stamp on it. If it sees the right stamp under the right light, it tells you the site is who it says it is.\nThere are two parts to the SSL passport system. There is the technology — the Public Key Encryption or PKE technology (very nerdy math) — which allows encryption and validation using keys and certificates to occur. And there are the processes — the Public Key Infrastructure or PKI — that manages how keys and certificates are created and distributed.\nPublic Key Infrastructure is organized as a tree of trust, where, at the very top, or root of the tree, are the root-certifying authorities or CAs. These are the “officials.” Root CAs issue their own certificates and apply to have them shipped by vendors with the vendors’ browser software. Once you are in this select group, you can sign other peoples’ certificates. So your company, if it has an SSL website, will have gone to one of these companies, or their delegate, and paid some money so that when your certificate is shown to a browser, the black light shines through and sees one of the CA certificates that the browser has in its list of included certificates.\nWhen you pay to setup your SSL web site, you are paying for nothing more than to get your certificate certified by someone who has got their certificate in the special list. If you use a certificate that is not ultimately certified by a CA in the special list (it's actually quite easy to create and sign your own certificate), then your browser will give you a big warning telling you that the site is not trusted, and it is on your head if you go any further. Sites can pay even more and have their company information officially checked and certified as well — those are the web sites that show the company name in the green area of your browser address bar.\nPublic Key Infrastructure Has Failed\nThose of you responsible for critical business functions or technology processes know that any system that has a single point of failure will ultimately end up failing. You've probably already worked out that the PKI infrastructure is built on a single point of failure — the certificates from the CAs. And the bad news is that it has failed — the bad guys have compromised some CAs. This means that they have the passport printing machine, and your browser’s black lights are no longer trustworthy. Sure, your browser still works, it's black lights still work and can be shone on a passport and show the right stamp — but the infrastructure that produces the passports has been compromised.\nIt is known that someone has hacked at least two certifying authorities and has used these certificates to produce bogus SSL certificates. In one case, it was known that bogus Google, Microsoft, Yahoo, etc. web mail web site certificates were produced, and, in another more comprehensive attack, bogus certificates were produced for *.*.com and *.*.net. With those certificates, you can pretend to be anyone. So how does that work?\nA simple, real life, and chilling example: I have read a report that described that when some of the CAs were identified as compromised and their certificates were added to the certificate revocation list that browsers (may) use, a web mail provider received support calls from some users in some extremely internet- & freedom-unfriendly countries to say that they were getting security warnings using the web mail website. Why? The likely answer was that someone had put a false site in between the user and the real web mail site using a bogus SSL certificate. This allowed the false site to pretend it was the real site, and the browser told the user everything was OK. If this account is true, that user would have been putting their username and passwords into an unfriendly proxy site, which would have seen their login details \"in the clear\" as it passed data back and forth between the user and the real site. This is called a “man in the middle” attack, and if you live in a country that takes out dissidents, the stakes can be life threatening.\nBrowser Providers Are Covering Up This Issue!\nBut it's not just the keys that have been compromised. In my opinion, the way the browser providers have acted has also compromised any level of trust we could have in them. The way we know this is because there are some seriously motivated, seriously skilled people who are thankfully watching what browser providers are doing. The Tor project is a project that allows users to create and communicate over anonymous SSL sessions. This is handy if you need to hide from state powers, and it is used in countries that practice internet surveillance with unfriendly intent. (Note that it may also be used in friendly states by people with unfriendly intent, but the bad guys will always find a way to do their evil, so I prefer to focus on the positives.) So the Tor project is motivated to watch what is happening in SSL land. Jacob Appelbaum from Tor noticed some changes in certificate management in both the Chrome and Firefox open source projects, and basically proved that the browser producers were quietly working to remove compromised certificates. You can read the story here.\nWhat Does This Mean for You?\nWhat does this mean? It is in neither the browser nor the CA authorities’ interest to \"fess up\" to a broken system. It’s their system, and there are business models at stake. However, as I write, the list of compromised SSL certificates has gone from a few, to many, to many hundreds, and no one knows how many other certificates are compromised. So this means that the single point of failure has been realized, and without wanting to sound alarmist, the whole CA trust system is probably hopelessly compromised at this point, and many browser root certificates are probably being changed as we speak. We can't rely on the CAs or the browser manufacturers to tell us, either.\nWhat does this mean for individuals and companies? I'm not really sure how to assess the threat level at the moment, and I think it’s too early to say whether this is the start of some major change. I, for one, am going to keep doing my banking online and hope for the best. However if the system is broken, then we will start to see a whole body of SSL-related attacks in such areas as identity theft or anonymity breaches, and the questions about the system will escalate. However, at this point it is hard to tell. My hunch is that the next few years will see identity and anonymity start to become major issues and there will have to be a technology change in response.\nTime will tell.\n~ Pete Horne", "label": 1}
{"text": "When spoken of database warehousing broadly, it is a database which is used for reporting and analysis. Different operational systems upload the data into a data warehouse. The main function of data warehousing is storage of data. The data that is uploaded in a data warehouse is free from bugs and is highly indexed. Thus data warehousing can be considered as the database which includes business intelligence tools which are basically tools to extract and transform and load the data into a repository. It also has the tools to manage and retrieve the metadata of the database.\nGenerally a data warehouse will maintain a copy of the data that is provided by different operational systems. Thus this complex structure enables the data warehouse to maintain the data history. A data warehouse will keep the history even if the source is not keeping it. It integrates the data from different source systems, thus enables a central view for the enterprise, which is very important and crucial for a big organization. The data warehouse is able to improve the data quality. It does that by making codes consistent. It flags the bad data or can even fix it. With all these features it is able to provide a consistent view of data to the organization. It provides a single view of the data of interest and does not let the source operational systems, to interfere. It is also capable to change the structure of the data without making any changes to the contents.\nIn a dimensional approach the transactional data is partitioned into numeric transaction data or into reference information. Thus in this approach the data can be broken into either facts or dimensions. The main advantage of this approach is that it is easier to understand and to use for the user. To retrieve data from this data warehouse structure is very fast. It is easy to understand because it is broken into measurements and their contexts. The main disadvantage is that loading the data from various operational systems is a complicated process, thus it becomes very difficult to maintain the data integrity. With dimensional approach it is next to impossible to change the structure of the data warehouse.\nIn a normalized way of uploading the data into the warehouse is done after reaching certain level of normalization. The normalized structure of the data divides it into different entities, which is converted into different physical tables at the time of implementation. This approach allows different operational systems to upload the data into the database. The disadvantage is that to reach a certain level of normalization it becomes difficult to join different tables from various sources, and then to access the information from these normalized tables without having prior knowledge of the source is quite a complex activity.\nHigh quality of dba expertise needs to maintain data warehouse databases. Dbametrix is the team of expert database dba to provide high level of Oracle database support with remote database monitoring and remote dba. For more details, contact our sales department using contact us form.", "label": 1}
{"text": "This article is the second of two focusing on tunneling VPNs and Public Key Infrastructure (PKI). The first article provided a simple overview of the technology for people without a deep computer security background. This article is a walk-through tutorial that implements the concepts covered previously. We assume that the reader has some knowledge of VPN and digital certificate basics and wants to see exactly what it takes in practice to extend a private network by deploying a secure VPN. This tutorial presents code examples that will require novice- to intermediate-level system administration skills to reproduce, but anyone should be able to follow along with the discussion.\nThe tutorial implements a certificate-based security infrastructure using OpenSSL and uses this to secure both OpenVPN client and server endpoints. We will highlight two great new features to appear in OpenVPN-2.0 (now in beta) that will make it a good choice for any VPN--single-instance server mode and certificate revocation list support.\nIn part one of this series, we covered VPN and PKI at a conceptual level. We discussed the benefits that VPN technology offers to a business network and touched on three different techniques or protocols that can actually implement a VPN tunnel. These were PPTP, L2TP/IPSec, and the relative newcomer, OpenVPN. An advantage of OpenVPN is that it encapsulates network traffic inside of UDP or TCP packets, which improves the odds of it working when deploying a VPN across unknown third-party network equipment and the Internet as a whole.\nThe previous article also talked about PKI and loosely defined the term as a system for issuing, publishing, and revoking digital certificates. These digital certificates are simple data structures containing, at the minimum, a subject's name, his public key, and the name of an issuer who has verified the subject's identity. When the issuer digitally signs the certificate and attaches the signature, the data structure becomes a digital certificate. The public key inside of the certificate can encrypt any message, producing a message decipherable only by the named subject in the certificate using the closely guarded private key.\nFor our step-by-step description of establishing connections across a VPN tunnel, secured with PKI, we will focus on two separate software packages, OpenVPN-2.0 (beta 8) and OpenSSL 0.9.7d. This version of OpenSSL was the latest stable version of the package at the time of writing. The OpenVPN beta version includes a couple of new features that really make it quite acceptable for a business VPN, namely, Certificate Revocation List (CRL) support and single-instance server mode. We'll use a generic GNU/Linux system to host both the PKI and VPN server endpoints. Our sample client configuration will be platform-neutral, meaning that the same client configuration should work on any supported OS, including Linux and the BSDs, Solaris, Mac, and Windows. Setup and operation for both OpenSSL and OpenVPN is similar on any supported platform.\nFirst, we will configure OpenSSL to act as our root Certificate Authority (CA) by creating a self-signed certificate that will sit at the top of our trust hierarchy. Then, we will create certificate requests for our clients and actually issue certificates. Next, we will use OpenSSL's built-in test framework to make sure everything works smoothly before we complicate things by throwing a VPN into the mix. After running the OpenSSL test framework, we will configure both the OpenVPN server and client endpoints. Finally, we will demonstrate a CRL by revoking a user certificate, generating a CRL containing the revoked certificate, and effectively terminating the user's access to our VPN.\nOpenSSL is primarily a library of cryptographic functions that provides an\nextensive crypto API to programmers. However, it also includes a shell tool\nthat exposes that API to users and batch scripts. Start the shell by typing\nopenssl at the command line. From there, you can type commands\n[admin@tamarack admin]$ openssl OpenSSL> version OpenSSL 0.9.7d 17 Mar 2004 OpenSSL>\nYou can also issue OpenSSL commands in batch mode. In batch mode, each OpenSSL command executes separately. Shell scripts usually use this approach; we'll do the same in this tutorial:\n[admin@tamarack admin]$ openssl version OpenSSL 0.9.7d 17 Mar 2004 [admin@tamarack admin]$\nOf the many commands provided with the OpenSSL shell, this tutorial will only cover five:\nca: Certificate Authority management\nreq: Certificate request management\nverify: Certificate verification\ns_server: Secure server test mode\ns_client: Secure client test mode\nWhen installing an OpenSSL Certificate Authority, we need to provide a\nmaster configuration file. This file contains default parameters for all\nOpenSSL commands. Compiling the library hard-codes its default location; its\nname is openssl.cnf. To find the default location of this file, use\nversion command with the\n[admin@tamarack admin]$ openssl version -d OPENSSLDIR: \"/home/admin/install\" [admin@tamarack admin]$\nOnce you know where to look, edit this file with a text editor. The OpenSSL distribution includes a heavily commented example configuration file, but it's more complex than the simplified version we will work with in this tutorial. Hopefully, by paring the configuration down to a minimum, we will simplify our deployment without sacrificing security. Specifically, our configuration file removes many of the certificate extension definitions that appear in the prepackaged OpenSSL configuration.\nIt's probably a good time to mention these extensions. Part one of this series listed the minimum amount of information that must appear in a digital certificate: a subject name, the subject's public key, and the name of an issuer. Certificates that limit themselves to this minimum amount of information and conform to the X.509 encoding format are X.509v1 (version 1) certificates. Presently, the current standard specifies additional information that can appear in the certificate to increase security and aid applications that work with them. Most certificates used with Internet-enabled applications currently conform to the X.509v3 (version 3) specification and include some extensions. OpenSSL can produce either v1 or v3 certificates depending on the configuration file settings.\nIn this tutorial, we will configure OpenSSL to produce v3 certificates and\nbasicConstraints extension to limit how\npeople can use the certificates that we issue, as this is the recommended\nconfiguration. Here is the configuration file that we will use:\n# openssl.cnf # # OpenSSL example configuration file. # # This configuration file has been derived from the original # example file included with the OpenSSL distribution. It # has been edited mostly to eliminate extensions in order to # simplify it for the purpose of an online tutorial. It has # also been reformatted to limit the maximum line length to # 60 characters for online publication. ############################################################ # This section will configure the ca (Certificate Authority) # command. We will use the ca command to sign user # certificates and periodically generate CRLs. ############################################################ [ ca ] default_ca = CA_default # The default ca section [ CA_default ] dir = /home/admin/CA-DB # Top crl_dir = $dir/crl # The crl location database = $dir/index.txt # Database index file new_certs_dir = $dir/newcerts # Location for new certs certificate = $dir/cacert.pem # The CA certificate serial = $dir/serial # The next serial number crl = $dir/crl.pem # The current CRL # All DNs need to be unique. This is the default behavior # but due to an OpenSSL library bug in the 0.9.7d release, # if we don't supply this redundant definition here we will # see a cryptic message when signing certificates. unique_subject = yes # The CA private key private_key = $dir/private/cakey.pem # Private random number file RANDFILE = $dir/private/.rand # Issued certificates will be valid for 1 year default_days = 365 default_crl_days= 30 # Hashing function default_md = md5 # This assignment causes the extensions defined in the # 'user_extensions' section to be included in any # certificates that are signed using the ca command. x509_extensions = user_extensions # This sections describes the policy that will be enforced # on a request to be signed, the subject organization name # must match that in the CA certificate. The request may # contain an optional organizational unit name. The common # name is assigned the policy format 'supplied' which means # it must be present in the certificate request. policy = policy_any [ policy_any ] organizationName = match organizationalUnitName = optional commonName = supplied ############################################################ # This section configures the req (certificate request) # command. ############################################################ [ req ] # The default key length and the filename that will contain # a private key. The public key will be contained in the # certificate request. default_bits = 1024 default_keyfile = privkey.pem distinguished_name = req_distinguished_name # The makeup of our subject name [ req_distinguished_name ] organizationName = Organization Name (eg, company) organizationName_default = Inyo Technical Services organizationalUnitName = Organizational Unit (eg, west) commonName = Common Name (eg, YOUR name) commonName_max = 64 # This assignment mimics that in the ca section but causes # the following extensions to be included in a certificate # request. In our case these extensions will only be # included when we self-sign a certificate using 'req # -new -x509'. x509_extensions = CA_extensions ############################################################ # Extensions that will be added to certificates that are # issued. The 'user_extensions' sections contains # definitions that will be included in certificates that are # signed by this CA. The CA_extensions section contains # extensions that will be included when we create a # self-signed certificate using the req command. ############################################################ [ user_extensions ] # CA:FALSE will not permit this certificate to sign other # certificates. basicConstraints = CA:FALSE [ CA_extensions ] # CA:TRUE will allow this certificate to sign others. basicConstraints = CA:TRUE\nThere are quite a few things to note about this file. First, note that\ncomment blocks divide it into logical sections. In this sample, those sections\n[ ca ], the configuration for the\nca (Certificate Authority) command;\n[ req ], the section containing\nitems to include in a certificate request with the\nand finally, a section defining some extensions. We only include one extension\nand assign it two different values depending on the certificate that we are\nOur self-signed CA certificate will include the extension\nbasicConstraints = CA:TRUE. This allows a Certificate Authority to\nuse the certificate to sign other certificates. When we issue certificates to\nusers, we will use the extension\nbasicConstraints = CA:FALSE,\ndenying users the ability to create subordinate certificates and thereby extend the\nchain of trust beyond our control.\nThe start of the\n[ ca ] section defines the directory\nhierarchy. This lets the OpenSSL library know where to find important files,\nand the definitions here should be clear. The assignment\n= user_extensions adds the extensions defined in the\nuser_extensions ] section to any certificates signed by this CA. As\nexplained before, the only extension we will include is\nbasicConstraints, which was explained previously. Next come the\ndefinitions of the certificate request subject's name-matching policy and\nDistinguished Name structure.\n[ policy ] section defines the Distinguished Name\ncomponents to allow in certificate requests. To understand this, we need to\ndescribe the encoding of subject names in X.509 certificates.\nX.509 certificates encode subject names in a structure called a\nDistinguished Name (DN)--a sequence of name components called\nRelative Distinguished Names (RDNs). This naming structure comes from\na complex specification for methods and syntaxes defining communication between\ncomputer programs as seen in RFC\n1274, which gives the attribute definitions for the DN components that we\nwill use in our certificates. The\n[ policy ] section specifies\nwhich RDNs or DN components must appear in a certificate\nrequest and which of these components must match the subject DN\nin the CA certificate prior to signing. Here, we have configured our CA to\nencode a subject's DN as follows:\norganizationNamepart that matches our CA certificate exactly--\nIn our application, we will try to be consistent and issue user certificates\ncommonName component that matches the user's login ID, but\nOpenSSL will not enforce this.\nThe next section, labeled\n[ req ], contains default configuration\nvalues for the\nreq command. We will use this command to create\ncertificate requests. The\ndefault_keyfile definitions set the length of the private key and\nits location in the file system. More interesting here is the\nreq_distinguished_name ] section, which defines default values for the\nRDN components that will make up our subject's Distinguished Name. Here we\ndefine the prompts that will appear at the terminal when we execute the\nreq command. We assign a default value to our\nInyo Technical Services.\nFinally, the assignment\nx509_extensions = CA_extensions includes\nthe extension defined in the\n[ CA_extensions ] section in a\nThis extension assignment is similar to that in the\n[ ca ]\nsection. The difference here is that these extensions will appear only in\ncertificate requests, while extensions in the\n[ user_extensions ]\nsection will appear in a certificate signed by our CA. By default, if an\nextension is present in a certificate request but does not appear in the\n[ user_extensions ] section, then the extension will not\nbe present in the issued certificate. The extension\nCA:TRUE will only appear in the certificate when we use the\nreq command with the\n-x509 option to create a\nself-signed root certificate.\nWith the master configuration file taken care of we can now set up the directory structure to hold our CA. We choose a suitable location and make our directories and initialize the serial file.\n[admin@tamarack admin]$ mkdir CA-DB [admin@tamarack admin]$ cd CA-DB [admin@tamarack CA-DB]$ mkdir crl [admin@tamarack CA-DB]$ mkdir newcerts [admin@tamarack CA-DB]$ mkdir private [admin@tamarack CA-DB]$ echo \"01\" > serial [admin@tamarack CA-DB]$ touch index.txt [admin@tamarack CA-DB]$\nNotice that we seed the file serial with the first serial number. As we issue certificates, the number stored in this file will automatically increment so each certificate will receive a unique serial number. The file index.txt will record all certificates issued. Records in this file will map the subject DN in a certificate to its assigned serial number. Using index.txt, we can look up the serial number for any certificate using the subject's DN. This will become important when we decide that we need to revoke a certificate and need to find the original.\nAs defined in the configuration file, the new_certs_dir will hold copies of all certificates issued by this CA. The filenames for these certificates will consist of the serial number assigned to the certificate by the CA followed by an extension.\nWith the directory structure in place, we can create our self-signed root certificate. This certificate will sit at the top of our trust hierarchy. We will use it to sign all of the rest. For our tutorial, we will only use a single layer of trust, but a more robust design would probably use more.\n[admin@tamarack CA-DB]$ openssl req -new -x509 -keyout \\ > private/cakey.pem -out cacert.pem Generating a 1024 bit RSA private key ...................................................... writing new private key to 'private/cakey.pem' Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Organization Name (eg, company) [Inyo Technical Services]: Organizational Unit (eg, west) : Common Name (eg, YOUR name) :Root CA [admin@tamarack CA-DB]$\nNote: here and in the code examples that follow, the output has been reformatted to a maximum width of 60 characters.\nTo clarify some potential confusion, the\n-x509 option will\nreq command to output a self-signed certificate rather\nthan a certificate request. We will only use this option with the\nreq command one time when we create our root certificate.\nNext, we create a certificate request for the OpenVPN server endpoint\ninstalled on our local network. Note that we use the\nargument. This prevents the private key generated with the request from being\nencrypted and password-protected. We will need to guard the key carefully\nbecause of this. We don't password protect this one private key because later\nwe may want to start our OpenVPN server automatically at boot time when there\nis no interactive user available to supply the password. We could enter the\npassword into the boot script itself, but that would sort of defeat the purpose\nof having a password in the first place. Physical security (such as locking the\ndoor to the server room) is the best way to protect this non-encrypted private\n[admin@tamarack admin]$ openssl req -new -nodes -keyout \\ > vpnkey.pem -out vpncert-req.pem Generating a 1024 bit RSA private key ........................................................ writing new private key to 'vpnkey.pem' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Organization Name (eg, company) [Inyo Technical Services]: Organizational Unit (eg, west) : Common Name (eg, YOUR name) :vpn.inyotech.com [admin@tamarack admin]$\nNow we digitally sign the server certificate using the root certificate we created initially. OpenSSL will retrieve the location of the root certificate from the configuration file, which is why it does not appear as a argument on the command line. This command will update the files serial and index.txt when it completes.\n[admin@tamarack admin]$ openssl ca -out vpncert.pem \\ > -in vpncert-req.pem Using configuration from /home/admin/install/openssl.cnf Enter pass phrase for /home/admin/CA-DB/private/cakey.pem: Check that the request matches the signature Signature ok The Subject's Distinguished Name is as follows organizationName :PRINTABLE:'Inyo Technical Services' commonName :PRINTABLE:'vpn.inyotech.com' Certificate is to be certified until Aug 18 22:50:07 2005 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Data Base Updated [admin@tamarack admin]$\nAfter creating the server certificate, we can create certificates for all of\nthe clients to whom we want to give VPN access. The procedure is the same,\nexcept we don't specify the\n-nodes option with the\nreq command. This will encrypt the private key, and OpenSSL will\nprompt for a password use when seeding the cipher.\nNow, after we have issued a couple of user certificates, we can make sure\nthat our procedures are all correct by taking advantage of the two test\ncommands provided by the OpenSSL package. The programs\ns_client (secure client) can exercise almost the\nentire library and their operation is straightforward.\nStart an OpenSSL secure server session in one terminal window. Start an OpenSSL secure client session in another. The client will contact the server using the SSL/TLS protocol at localhost using port 4433. You will be able to type messages into the console hosting the secure client and see them appear at the secure server. It will be immediately obvious if your certificates are not correct or there is a problem with your OpenSSL library installation.\nHere we start an OpenSSL secure server at the command line. For arguments,\nwe include the server certificate and server private key. The argument\n-verify 1 causes the server to ask any connecting client to send a\ncertificate for authentication. (Note that the output from these commands\nis more verbose than these trimmed code examples indicate.)\n[admin@tamarack admin]$ openssl s_server -cert vpncert.pem \\ > -key vpnkey.pem -verify 1 verify depth is 1 Using default temp DH parameters ACCEPT ... [admin@tamarack admin]$\nNow, in another console window, we start an OpenSSL secure client using the\n-cert to provide a certificate to send to the\nserver for authentication. The\n-key argument gives the private key\nto use when encrypting messages and the\n-CAfile argument points to\nthe root certificate.\n[admin@tamarack admin]$ openssl s_client -CAfile \\ > CA-DB/cacert.pem -cert client1cert.pem -key client1key.pem Enter PEM pass phrase: ... [admin@tamarack admin]$\nWhen the connection attempt succeeds, you can send sample messages between\nthe client and server by typing text into either secure endpoint. To quit the\nQ in the terminal window.\nNow we know that our certificates can encrypt messages passed between\ntwo OpenSSL applications. However, we have not yet made sure that we can use\nour certificates with any arbitrary X.509-certificate-secured application.\n-WWW option to the\ns_server command will\neffectively create a secure web server that can serve any local file to a\nweb-browsing client connecting using SSL/TLS. We will exercise this feature\nIn the current working directory, create a small HTML file containing text similar to the following:\n<html> <body> <h1>Hello World!</h1> </body> </html>\nGive the file a name such as hello.html and then start a secure web\nserver from the same directory as the file using the\n[admin@tamarack admin]$ openssl s_server -cert vpncert.pem \\ > -key vpnkey.pem -WWW Using default temp DH parameters ACCEPT\nStart any modern web browser, such as Mozilla, Netscape, or Opera. Internet\nExplorer should also work, if you are following along with this tutorial on\nWindows. Enter the following URL in the address bar, noting that the protocol\nhttps and not\nThe web browser should alert you to the fact that it does not recognize the subject in the certificate offered by the server. Most browsers will allow you to accept the authenticity of a server certificate temporarily for a single session. After clicking through any such warning messages, you should see the sample page appear in the browser window. A client can connect to the secure web server from a remote server, as well.\ns_server is an extremely useful test tool. Secure\napplications using certificates can be difficult to debug, especially if you\nare not sure where a potential problem may exist. OpenSSL's test client and\nserver let an administrator more easily isolate problems to either a network\napplication or its supporting certificate infrastructure.\nAfter creating our certificate infrastructure and testing our server and client certificates, we are ready to set up the VPN itself. OpenVPN uses a secure protocol called Diffie-Hellman to negotiate authentication (see RFC 2631 for a technical overview). We need to generate a set of parameters to facilitate this in a file called dh1024.pem. This file only needs to exist at the server VPN endpoint.\n[admin@tamarack admin]$ openssl dhparam -out dh1024.pem 1024 Generating DH parameters, 1024 bit long safe prime, generator 2 This is going to take a long time ...................................................+........ [admin@tamarack admin]$\nNext, we need to configure our operating system for OpenVPN. This is the only\nplatform-dependent configuration step in this tutorial. As we noted earlier,\nour target server platform is generic GNU/Linux. If you are installing OpenVPN\non a Windows platform from pre-compiled binaries, the installer will\nautomatically perform the following step. On our Linux system, we configure the\ntun (tunneling) software driver. If it does not already exist, use the following\ncommands to create the device interface file in /dev/net/ and load the\ntun kernel module.\n[root@tamarack /]# mkdir /dev/net [root@tamarack /]# mknod /dev/net/tun c 10 200 [root@tamarack /]# /sbin/modprobe tun\ntun module allows the operating system kernel to redirect\nnetwork packets between the tunneling network device driver and a user-space\nprogram, in our case OpenVPN. When an application wants to send a network\npacket out through the VPN, it will send it through the\nThe kernel will then pass the packet to OpenVPN, which will use functions from\nthe OpenSSL library to encrypt the packet before sending it out a real network\ninterface to the client. Applications will receive packets from the client in\na similar way. OpenVPN will read the packet from the real network device,\ndecrypt it using OpenSSL functions, and then pass the decrypted packet to the\nkernel that will redirect it to the\nA configuration file tells OpenVPN how to operate. There are many different variations possible. Here, we will set up separate server and client configurations. We want the VPN to operate in single-instance server mode. This allows all client connections to go through the same server port, and it makes configuration much easier. As mentioned before, this single-instance mode greatly reduces the burden on an administrator to support multiple clients connecting simultaneously. Previously, each client connection would require its own separately configured server instance.\nIn single-instance server (hereafter simply referred to as \"server\") mode,\nifconfig parameter works a little differently than the way it\nused to in older versions of OpenVPN. The first parameter is the IP address of\nthe local end of the tunnel, but the second parameter is not the remote IP\naddress. Instead, it is the address of the gateway interface that OpenVPN will\nipconfig-pool parameter gives a range of IP addresses to\ndistribute to connecting clients. The\nroute parameter is the route\nthat will be set up on the local network to direct packets out of the VPN, while\npush \"route ...\" command is the network route to set up on the\nclient. Here is the configuration file for our OpenVPN server endpoint.\n# openvpn-server.conf # # Tunnel mode dev tun # Run as a single instance server mode server # Server endpoint appears first, followed # by the gateway interface ip ifconfig 10.1.0.1 10.1.0.2 # Range of IP addresses reserved for clients ifconfig-pool 10.1.0.4 10.1.0.254 # route setup on the server route 10.1.0.0 255.255.255.0 # route command pushed to the client push \"route 10.1.0.1 255.255.255.255\" # Specify tls-server for certificate exchange tls-server # Diffie-Hellman Parameters (tls-server only) dh dh1024.pem # Root certificate ca CA-DB/cacert.pem # Server certificate cert vpncert.pem # Server private key key vpnkey.pem # Check for revoked client certificates. crl-verify CA-DB/crl/crl.pem\nNotice that we use the\ndh option to specify the file containing\nthe Diffie-Hellman parameters that we created earlier. The\noption only needs to appear in the server's configuration file and not in the\nclient's. Next, we list files containing the certificates that we will use,\nstarting with the root. Finally, we indicate that we want OpenVPN to check our\ncertificate revocation list before authorizing a client to connect to our\nprivate network by specifying the\ncrl-verify option and assigning\nit the location of a current CRL. We will demonstrate the CRL verification\nThe client configuration file is a little simpler. The only configuration\nitem that we have not seen before is\npull, which complements the\npush \"route ...\" command we included in the server configuration.\npull will set up the route that we want packets destined for\nour VPN to use by receiving it from the server.\n# openvpn-client.conf # # Set tunnel mode dev tun # Hostname for the VPN server remote vpn.inyotech.com # This end takes the client role for # certificate exchange tls-client # Certificate Authority file ca cacert.pem # Our certificate/public key cert client1cert.pem # Our private key key client1key.pem # Get the rest of our configuration # from the server. pull\nThe next step is to install OpenVPN on the client. This step will only be covered here by saying that installation of OpenVPN as a client is identical to installing it as a server. After installation, complete the process by distributing the following files to the client:\nBefore starting the server, we have one last step to perform. We need to\ninitialize the CRL. The CRL will hold a list of user certificates that our CA\nhas revoked. Even though we have not revoked any user certificates yet, our\nconfiguration still asks the OpenVPN server to check the CRL using the\ncrl-verify option in the server configuration. If our VPN server\ncannot find a CRL, it will exit prematurely.\nFor now, we will initialize an empty CRL. Later, we will revoke a user\ncertificate and update the CRL. To initialize the CRL simply ask the CA to\ngenerate one. (The cryptic message beginning\nDEBUG[load_index] comes from a harmless bug in this particular\nrelease of OpenSSL; ignore it.)\n[admin@tamarack admin]$ openssl ca -gencrl -out \\ > CA-DB/crl/crl.pem Using configuration from /home/admin/install/openssl.cnf Enter pass phrase for /home/admin/CA-DB/private/cakey.pem: DEBUG[load_index]: unique_subject = \"yes\" [admin@tamarack admin]$ cat CA-DB/crl/crl.pem\nNow we are ready to use the following command line to start a VPN server endpoint on our local network. After executing this command, clients can connect.\n[root@tamarack admin]# openvpn --config openvpn-server.conf\nAfter the server starts, attempt to connect to it from a client. The command line at the client will be very similar, but remember to use the name of the proper configuration file. On Windows, right-clicking on the configuration file and selecting Start OpenVPN on this config file from the context menu is sufficient. Later, you will probably want to set up a shortcut on the desktop.\nYou should immediately be able to communicate over the VPN. If there is a\nproblem, it is time to troubleshoot. In this case, you will be glad that you\ntested your certificate infrastructure using\ns_client so you can better isolate what may be wrong.\nOf course, to use the VPN tunnel fully, you will probably want to make\napplicable additions to the client DNS and make sure that the routing table\nthat OpenVPN automatically sets up is correct for your network. We have only\nprovided a single host route from the client to the server. This tutorial will\nnot cover configuring DNS and routing. Treat the\ntun device like\nany other network interface.\nThe final task that we will tackle is reliably terminating VPN access for\nusers when we no longer want them to connect to our network. To do this, we will\nrevoke their certificates and update our CRL. To figure out what certificate\nbelongs to which client, use the file index.txt, located in the\ncertificate directory tree. Look in the file to find the record containing the\ncommonName attribute assigned to the certificate to revoke\n(remember that we established a policy of assigning the user's unique login ID\ncommonName attribute). This record will also contain the\nserial number that the CA assigned to this certificate.\nHaving identified the serial number, we can locate the client certificate under newcerts in our CA directory. This directory will contain a copy of each certificate issued by our CA. The file names contain the serial numbers assigned to these certificates.\nIn this example, we decide to revoke the certificate for user3.\nWe issued this certificate earlier following the procedure described in the\nsection User Certificates. After looking in index.txt, we\nfind that the serial number assigned to the certificate with the\ncommonName attribute matching user3 is\n04. We then know\nthat the correct certificate to revoke is newcerts/04.pem.\n[admin@tamarack admin]$ openssl ca -revoke \\ > CA-DB/newcerts/04.pem Using configuration from /home/admin/install/openssl.cnf Enter pass phrase for /home/admin/CA-DB/private/cakey.pem: DEBUG[load_index]: unique_subject = \"yes\" Revoking Certificate 04. Data Base Updated [admin@tamarack admin]$\nThe command has revoked the certificate and updated index.txt appropriately. Now we need to generate a new CRL that will contain this newly revoked certificate. Until we do this, OpenVPN will not know that we have revoked this certificate.\n[admin@tamarack admin]$ openssl ca -gencrl -out CA-DB/crl/crl.pem Using configuration from /home/admin/install/openssl.cnf Enter pass phrase for /home/admin/CA-DB/private/cakey.pem: DEBUG[load_index]: unique_subject = \"yes\" [admin@tamarack admin]$\nFrom this point on, user3 will not have access to the VPN, as long as the OpenVPN server endpoint checks the CRL. Remember, whenever you revoke a user's certificate, make sure to regenerate the CRL.\nOpenSSL also includes the\nverify command, which accepts the\n-crl_check option that will allow you to make sure that your\ncertificate revocation list works. The\nverify command requires\nthat the root certificate and CRL live in the same file. Before you exercise\nthis command, create a new temporary CRL by concatenating it with your CA\n[admin@tamarack admin]$ cat \\ > CA-DB/cacert.pem CA-DB/crl/crl.pem > tempcrl.pem\nverify command with the\nto specify the CRL to use. Here's how to verify the revocation of the\ncertificate for user3.\n[admin@tamarack admin]$ openssl verify -CAfile tempcrl.pem \\ > -crl_check user3cert.pem user3cert.pem: /O=Inyo Technical Services/CN=user3 error 23 at 0 depth lookup:certificate revoked [admin@tamarack admin]$\nIn order to try this with your own setup, revoke the certificate that you created for your client VPN endpoint and regenerate the CRL. You will find that you can no longer connect to the OpenVPN server from that client.\nIf you have followed along and experimented with the code samples provided, you should have an understanding of the basics of implementing a PKI using OpenSSL and a VPN using OpenVPN.\nWe have set up a certificate infrastructure including a root CA and issued\nuser certificates. This included configuring the OpenSSL library to add a v3\nextension into the certificates issued by the CA. We have also summarized the\ns_client test framework, which you can\nexplore further through the manual pages included with the OpenSSL\ndistribution. We demonstrated setting up both client and server VPN endpoints\nand provided certificates for both authentication and encryption. Finally, we\nhave shown how to use a CRL to revoke user certificates and terminate access to\nThis concludes our two-part series on VPN and Public Key Infrastructure. We hope you have found it useful. Of course, we need to extend special appreciation to the creators of the OpenVPN and OpenSSL software packages and the GNU/Linux operating system that provides the solid foundation that lets us all work and build great software together. If you have any questions, feel free to contact us.\nScott Brumbaugh has worked professionally as a software/systems engineer since 1987.\nReturn to the Security DevCenter\nCopyright © 2009 O'Reilly Media, Inc.", "label": 1}
{"text": "Science & Technology in Congress\nJust before the end of the year, the Clinton Administration announced that it would change the focus of its encryption proposals from requiring the use of a commercial \"key escrow\" system, often referred to as the Clipper Chip, to a new \"key recovery\" approach. In addition, it transferred regulatory oversight from the State Department to the Department of Commerce. However, the Administration continues to encounter strong resistance among Internet users, privacy advocates, members of Congress, and computer companies.\nIntroduced in 1993, the Clipper Chip proposal was intended to address the concerns of U.S. law enforcement and national security officials regarding access to encrypted communications and stored data that threatened national security or that are related to investigations of criminal activities. The Administration argued that widespread use of the Clipper Chip would ensure the government had the keys to access most of these communications or data. Due largely to concerns raised over the past several years by industry executives and privacy advocates, the Clipper Chip proposal was revised twice - first in 1995 to ease restrictions on the export of encryption products, and then again in 1996 to introduce this latest idea of developing a key management infrastructure.\nCentral to this new proposal is the recovery of the keys to encrypted material. According to the key recovery plan, a trusted third party \"could recover a secret key for the user or for law enforcement officials acting under the proper court authority,\" whereas the Clipper Chip plans required that encryption products include a special chip that would function as a backdoor and make it unnecessary to break a user's secret key to access the information in question.\nOn November 15, President Clinton issued an executive order, \"Administration of Export Control on Encryption Products,\" that would:\n· shift oversight of encryption product exportation from the State Department's U.S. Munitions List to the Commerce Department's Commerce Control List; · relax current export controls on 56-bit encryption products for the next two years as long as \"industry [commits] to build and market future products that support key recovery;\" · transfer jurisdiction over encryption export licensing from the State Department to the Department of Commerce, with the Department of Justice having a formal vote in the process; and · require that after these two years, all exportable products greater than 40-bits have key escrow capabilities.\nIn addition, the executive order named Ambassador David L. Aaron Special Envoy for Cryptography and made him responsible for promoting \"the growth of international electronic commerce and robust, secure global communications in a manner that protects the public safety and national security.\" Ambassador Aaron is currently the U.S. Permanent Representative to the Organization for Economic Cooperation and Development (OECD) in Paris.\nAs of December 30, 1996, these changes had gone into effect with the Department of Commerce Bureau of Export Administration's issuance of a call for public comment on a set of new combined national security and foreign policy regulations (Federal Register, December 30, 1996, Vol. 61, Num. 251, pp. 68572-68587).\nThe Administration believes these new regulations will \"support the growth of electronic commerce; increase the security of the global information infrastructure; protect privacy, intellectual property and other valuable information; and sustain the economic competitiveness of U.S. encryption product manufacturers during the transition to a key management infrastructure\" (Federal Register, p. 68573).\nOthers outside the government remain skeptical of this latest plan and the Clinton Administration is facing an uphill battle to convince its critics that a compromise is still feasible between making it easier for Americans to use strong encryption products and providing the technological means for law enforcement officials to access encrypted data with proper court authorization.\nUsers of the Internet are beginning to realize just how vulnerable their electronic communications and data are to various kinds of attacks and the need for strong encryption products. The Center for Democracy and Technology reported that surveys conducted by Georgia Tech and Louis Harris poll \"point to a growing public concern with the loss of personal privacy in the online world\" (CDT Policy Post, November 5, 1996). Privacy advocates continue to reject any government proposal that guarantees access to personal electronic communications for law enforcement purposes and they have attacked this recent initiative on the grounds that it fails to protect the privacy and security of Internet users here and abroad. Numerous leaders of America's high-technology companies continue to argue that the government's role in regulating the exportation of encryption products is still too restrictive and hinders their ability to market sophisticated data-security products overseas.\nThe most crucial people whose backing the Clinton Administration needs, however, are members of the 105thCongress. Following the announcement of the latest Clinton proposal, 21 members of the 104th Congress sent a letter to Secretary of Commerce Michael Kantor expressing their \"serious\" concerns that top-down, government-imposed restrictions are \"doomed to defeat.\" Senator Conrad Burns (R-MT) has promised to reintroduce his \"Pro-CODE\" bill from the last session which would have allowed for the unrestricted export of \"mass market\" or \"public domain\" encryption programs and would have prohibited the government from imposing mandatory key-escrow encryption policies (see Science & Technology in Congress, July 1996, p. 1). Also, it will be interesting to see whether the fledgling Internet Caucus, founded by Representative Rick White (R-WA) and Senator Patrick Leahy (D-VT), which now includes over 100 members, will become more active in opposing the Administration's crypto policies.\n- Alexander Fowler, AAAS", "label": 1}
{"text": "With the significant prevalence of Linux web servers globally, security is often touted as a strength of the platform for such a purpose. However, a Linux based web server is only as secure as its configuration and very often many are quite vulnerable to compromise. While specific configurations vary wildly due to environments or specific use, there are various general steps that can be taken to insure basic security considerations are in place.\nMany risks are possible from a compromise including using the web server into a source of malware, creating a spam-sending relay, a web or TCP proxy, or other malicious activity. The operating system and packages can be fully patched with security updates and the server can still be compromised based purely on a poor security configuration. Security of web applications first begins with configuring the server itself with strict security in mind.\nFind me on Google+", "label": 1}
{"text": "Art Fraud Forensics\nAn engineer helps curators foil forgers\nHow many engineering jobs let you take a van Gogh off the wall and hold it in your hands? The kind C. Richard Johnson Jr. landed. He’s both an electrical engineering professor at Cornell University, in Ithaca, N.Y., and an adjunct research fellow at the Van Gogh Museum, in Amsterdam. As such, Johnson says, he can ”speak the language of people on both sides.”\nAnd when the two sides talk, they mainly talk about fraud and how to detect it. Two years ago, Johnson organized a conference at the museum that brought together researchers from Pennsylvania State University and Princeton, in the United States and Maastricht University in the Netherlands. Together, they processed high-resolution images with specially designed signal-processing algorithms to help sort fake van Goghs from real ones at the brushstroke level. It was the first time that image-processing teams at different universities could compare authentication approaches on the same paintings. Another workshop will follow next year at the Museum of Modern Art, in New York City.\nPainting by numbers:\nC. Richard Johnson [left, center] uses signal-processing algorithms to authenticate canvases believed to be painted by van Gogh.\n”Fraud detection is a ’sexy’ topic, which is why it was an early focus of my activities,” says Johnson. ”But we’re 10 to 15 years away from the computer having any authority in it. So now my colleagues and I are pursuing a wide variety of issues of interest to conservators and art historians, where signal processing can provide assistance that reaches well beyond just the detection of frauds.”\nJohnson’s current focus is on canvas thread counts—the number of horizontal threads crossing a vertical line 1 centimeter long—to identify paintings from the same roll of canvas. ”Placing a questioned painting on the same canvas roll as a painting known to be from a particular artist supports authentication to an artist who bought canvas in rolls, as van Gogh often did,” he says. ”When canvas is prepared with a lead white ground, the grooves between the threads are filled with radio-opaque material,” says Johnson. ”This registers in an X-ray as an intensity pattern that reveals the individual threads, permitting a calculation of the weave density.” The pattern is then analyzed with a Fourier transform, the same technique that radio engineers use to break down a signal into a series of simple sine waves.\nThe team is distributing the software free to museums. The Van Gogh Museum already uses the data generated to identify paintings from the same canvas roll by determining how the sections were arranged on the roll before being cut for use.\nJohnson stumbled into art as he wandered through Berlin museums during a college year abroad while earning a bachelor’s in electrical engineering from Georgia Tech. Later, while working on his Ph.D. in EE at Stanford, he took a class in the Dutch masters, which rekindled his passion. In 1977, he became the first Ph.D. student to graduate from the university with a minor in art history.\nHe went straight into academia, teaching at Virginia Tech until 1981, when he moved to Cornell. He was named an IEEE Fellow in 1989 for his work in digital control and signal processing.\n”This kind of research is not something to recommend to Ph.D. students. There are no jobs, no one’s eager to fund this, and it’s career killing for any pretenure academic,” he says, laughing. ”But for me, it’s like having a backstage pass. I go to a conservation studio and can take a van Gogh out of its frame and examine it.”\nAbout the Author\nSusan Karlin lists among her achievements acting, drawing, traveling to every continent on Earth, and writing for publications such as The New York Times, Entertainment Weekly, and Spectrum. For this issue she follows the trail of a coffee-making cellphone in ”Phone-y Brew” [p. 22] and reports on an electrical engineer who helps museums spot fake van Goghs in ”Art Fraud Forensics” [p. 23].", "label": 1}
{"text": "|Data Recovery from RAID: RAID\n0, RAID 1, RAID 5 data recovery\nWe provide RAID hard drive recovery from servers and workstations and RAID arrays.\nData Recovery From Different RAID Array Configuration Under The Following Operating Systems:\nWindows NT, Windows XP, Windows 2000, Windows 2003, Microsoft Exchange, Sun, Solaris, IBM AIX HP UX, LINUX, UNIX:\nRAID-0 > Striped Array\nRAID Data Recovery\nData Recovery Lab technicians are capable of recovering and repairing inaccessible data from all forms of RAID system servers including: file servers, application servers, web servers, network attached storage RAID systems of any data size.\nWhat is RAID?\nRAID is an acronym for Redundant Array of Inexpensive (or Independent) Disks. A RAID array is a collection of drives which collectively act as a single storage system, which can tolerate the failure of a drive without losing data, and which can operate independently of each other.\nRAID storage systems are able to continue\nfunctioning even if a hard drive fails. When this happens however, the\nperformance is negatively affected, and the RAID is operates in a degraded or\ncritical state. This occurs because the lost information must be regenerated \"on\nthe fly\" using the parity data.\nWhat are the different RAID levels?\nA research group at Berkeley University in the United States coined the term \"RAID\", (short for Redundant Array of Inexpensive Disks) defining six RAID levels. Each level is a different way to spread data across multiple drives--a compromise between cost and speed. Understanding these levels is important, because each level is optimized for a different use.\nRAID Level 0 is not redundant, hence does not truly fit the \"RAID\" acronym. In Level 0, data is split across drives, resulting in higher data throughput. Since no redundant information is stored, performance is very good, but the failure of any disk in the array results in all data loss. This level is commonly referred to as striping.\nRAID Level 1 is commonly referred to as mirroring with 2 hard drives. It provides redundancy by duplicating all data from one drive on another drive. The performance of a Level 1 array is slightly better than a single drive, but if either drive fails, no data is lost. This is a good entry-level redundant system, since only two drives are required. However, since one drive is used to store a duplicate of the data, the cost per megabyte is high.\nRAID Level 2, which uses Hamming error correction codes, is intended for use with drives which do not have built-in error detection. All SCSI drives support built-in error detection, so this level is of little use when using SCSI drives.\nRAID Level 3 stripes data at a byte level across several drives, with parity stored on one drive. It is otherwise similar to level 4. Byte-level striping requires hardware support for efficient use.\nRAID Level 4 stripes data at a block level across several drives, with parity stored on one drive. The parity information allows recovery from the failure of any single drive. The performance of a level 4 array is very good for reads (the same as level 0). Writes, however, require that parity data be updated each time. This slows small random writes, in particular, though large writes or sequential writes are fairly fast. Because only one drive in the array stores redundant data, the cost per megabyte of a level 4 array can be fairly low.\nRAID Level 5 is commonly referred to as striping with distributed parity. RAID Level 5 is similar to level 4, but distributes parity among the drives. No single disk is devoted to parity. This can speed small writes in multiprocessing systems. Because parity data must be distributed on each drive during reads, the performance for reads tends to be considerably lower than a level 4 array. The cost per megabyte is the same as for level 4.\nRAID 0/1 or10 is a dual level array that utilizes multiple RAID1 (mirrored) sets into a single array. Data is striped across all mirrored sets. As a comparison to RAID 5 where lower cost and fault tolerance is important, RAID 0/1 utilizes several drives, in order to provide better performance. Each drive in the array is duplicated (mirrored). This eliminates the overhead and delay of parity. This level array offers high data transfer advantages of striped arrays and increased data accessibility (reads). System performance during a drive rebuild is also better than that of parity based arrays, since data does not need to be regenerated from parity information, but copied from the other mirrored drive.\nRAID 0/5 or 50 is a dual level array that utilizes multiple RAID5 sets into a single array. In RAID 0/5 array, a single hard drive failure can occur in each of the RAID5 without any loss of data on the entire array. Keep in mind, as the number of hard drives increase in an array, so too, does the increased possibility of a single hard drive failure. Although there is an increased write performance in RAID 0/5, once a hard drive fails and reconstruction takes place, there is a noticeable decrease in performance, data/program access will be slower, and transfer speeds on the array will be effected.\nData Recovery Lab can recover hard drives attached to RAID interfaces by the following manufacturers:\nAdaptec, AMI, Bus Logic, Compaq, HP, Mylex, PERC, Pinnacle, Promise, Raidtec, Software RAIDS, Storage Dimensions, Sun, 3ware,\nData Recovery Lab specialises in recovery of RAID Servers including:\nSATA RAID Data Recovery;\nCopyright 2000-2010 Data Recovery Lab (UBE Ltd). All rights reserved. Copying site contents, design or any portions thereof strictly prohibited. Data Recovery Doctorr and Computer Forensics Lab are trading names for Data Recovery Lab (UBE Ltd). All customers using the Data Recovery Lab services are bound by Terms and Conditions of Service. All trademarks are acknowledged and belong to their rightful owners. Data Recovery Lab (UBE Ltd) is registered in England & Wales.", "label": 1}
{"text": "Federal Regulations Tighten Web Privacy Rules to Protect Children\nHave you ever thought about what’s happening behind the scenes when your child is playing on their favorite website? Chances are that the site is running complicated analytics tools to capture information about your child to share with marketers for advertising dollars.\nIn a recent New York Times article called U.S. is Tightening Web Privacy Rule to Shield Young, Natasha Singer reported that popular sites aimed at children and run by companies like McDonalds, Nickelodeon, Disney , and WebKinz are likely to begin asking for parental permission when using cookies to track web browsing history.\nCurrent federal regulations put in place by the Children’s Online Privacy Protection Act (COPPA) require parent permission when information such as email addresses, names, phone numbers, and home addresses are required from children under the age of 13. COPPA is the reason why kids under the age of 13 cannot have a Facebook account.\nWhile new federal regulations designed to protect children even more are expected soon, it’s always important to have a conversation with your kids about the kinds of information they’re sharing online. Encourage kids to:\n- Think before you upload photos and video. It may be fun to take a photo or create a video using your computer’s built in webcam but where are those images and videos being stored? Have you ever thought about who might be able to see them after they’re shared? Talk to your child about the use of the camera on their home computer and how it not only captures their image but also what’s in the background that could give away important information about who they are and where they live. Discuss the fact that nothing is ever private on the internet, especially those user generated photos and videos your child just uploaded.\n- Discuss who it is and isn’t ok to share your name with. Personal privacy online is an important issue that is hard for kids to grasp. Just as you may not want to tell a stranger you meet in real life your name, you probably don’t want to share it on the internet either. Talk to kids about the difference of using your real name in an email to grandma, grandpa, and known friends and family members versus those on online sites. Work with your kids to develop an alias. Kids love pretending so talk to them about an online alias that they can always use on any website to keep their name private.\nWhile federal regulations are designed to keep our kids safer when using their favorite sites, it’s dangerous to assume that your kids are knowledgeable about the risks and rewards of being online.\nGirl is using tablet PC in a cafe via Shutterstock", "label": 1}
{"text": "Phishing has been defined as the fraudulent acquisition of personal information by tricking an individual into believing the attacker is a trustworthy entity . Phishing attacks are becoming more sophisticated and are on the rise. In order to develop effective strategies and solutions to combat the phishing problem, one needs to understand the infrastructure in which phishing economies thrive.\nWe have conducted extensive research to uncover phishing networks. The result is detailed analysis from 3,900,000 phishing emails, 220,000 messages collected from 13 key phishingrelated chat rooms, 13,000 chat rooms and 48,000 users, which were spidered across six chat networks and 4,400 compromised hosts used in botnets.\nThis paper presents the findings from this research as well as an analysis of the phishing infrastructure.\nThe phishing landscape\nIntroduction\"I have ways of making money that you know nothing of.\"— John D. Rockefeller\nPhishing has been defined as the fraudulent acquisition of personal information by tricking an individual into believing the attacker is a trustworthy entity . However, this definition is oversimplified and the fact is that phishing has become a thriving economic infrastructure.\nOnline phishing can be traced as far back as 1996  and has escalated to today’s levels of an estimate of more than 250,000 phishing attempts in a single day against a given financial institution and its customers.\nPhishing does not occur in isolation but rather operates within a complex network. In fact, individuals involved in phishing do not typically understand how to orchestrate an entire phishing attack.\nPhishing economies are selforganized merchants and consumers governed only by the laws of supply and demand. These laws govern all aspects from the global economics to the launch and spread of attacks. These systems are formally known as scalefree networks and researchers have only just begun to understand how they operate.\nThe major effects of phishing are identity theft and monetary loss.\nIdentity theft is a major fear for most consumers as a result of the awareness created by the media through second and third hand accounts on its effects.\nMonetary loss impacts both consumers and the corporate brands. For consumers, phishing usually translates to direct monetary loss via theft. For the label, it leads to rising costs of prevention and remediation, and soft monetary loss as a result of brand erosion and undermined consumer trust.\nCloudmarks SpamNET blocks close to 500 million email threats per day. Less than 1/10th of a percent of that number is estimated as phishing. However, the impact of phishing on consumers as well as on organizations is exponentially more severe than other email threats, such as spam.\nThe phishing landscape\nIn an environment of overloaded information people tend to congregate in locations that are easy to find . Phishing networks present information efficiently. Channels often have naming conventions that connect them clearly to the phishing underground. Newcomers can easily become acquainted with the basics by joining chat rooms or forums with simple names such as \"credit cards.\"\nChat room interconnectivity\nWe have uncovered viable and closely interconnected phishing networks with the following process:\nChat rooms across major IRC servers were \"spidered\" until the hub of the phishing economy was located.\nThe chatroom, #WAMU, was discovered on a public network.\nThe tool, IRC Spider, was used to uncover a maximum spanning tree on the discovered channels as depicted below. Each node within the graph represents a single chatroom, and the associated number of users found within that channel. Each edge connecting two channels represents the number of users in common between two channels.\nChat room content\nOn one particular chat network nodebreaking occurred constantly because of perserver chat room and namespace restrictions. Node breaking is a process that causes channel interconnectivity to be severed or significantly weakened. This results in disconnected islands of chatrooms; it becomes difficult for users to efficiently navigate through the community and engage in phishing transactions. Another chat network had networkwide channel restrictions which created more problematic namespace restrictions, making it difficult to navigate the potential phishing community. The most viable public network had an official channel services infrastructure to support enforcement and authority in registered chat rooms.\nHowever, unregistered chat rooms are unregulated. As long as participants in the phishing economy maintain authority over unregistered chat rooms and block attempts at nodebreaking from unsanctioned attacks, they remain viable hubs in the phishing community. Smaller peripheral and completely unregulated networks are used and endorsed by loosely affiliated fraud groups. Newcomers eventually discover these networks through wide area communications channels.\nWe have made an attempt to analyze individual interconnectivity through consistent monitoring of user idle times and by using a modified version of the tool, PieSpy . The main premise of the tool is that individual interconnectivity can be inferred by analyzing the frequency of communications between individual users and by then comparing the time gaps in communication to other individuals in a monitored group of users.\nAlthough a peripheral aspect of phishing, bots play a major role in the Internet chat community. A bot is an automated chat program that can perform certain tasks autonomously and can be remotely controlled by chat participants. A botnet is essentially a cluster of bots running on many computers, which can be centrally controlled to carry out any task it has been programmed for, whether en masse or individually. Botnet tasks vary, but a few common uses are synchronizing distributed denial of service attacks (DDoS), virusslike selfspropagation through exploiting vulnerable computer systems, as well as the more benign task of chatroom management.\nThe illicit nature of phishing chat rooms creates the need for alternative means to maintain authority and control on public servers. This is achieved through networks of bots. Their main role in Internet chat is to form a mercenary authority infrastructure in otherwise unregulated chat rooms. Although botnets need not be composed of compromised computers, the most powerful ones typically are.\nBotnets are also used for organizing massive attacks, such as flooding DDoS. These botnets usually consist of up to 10,000 compromised zombie computers. During this study, one our own research bots was attacked on two separate occasions by another botnet comprised of over 4,000 computers and with close ties to phishing chat rooms.\nPhishing scam pages and system analysis\nCloudmark conducted an analysis of 143 machines used to launch phishing scam pages. We observed that the ratio of Apache versus IIS based scam pages is 133:10 and Netcrafts Web server surveys findings of Apaches market share ratio to IIS of 33:10 . Our research confirms that Apache servers running Linux is the preferred platform for launching phishing scams. One possible reason for this is that it is easier to remotely manage and stage a phishing scam on a Linuxbased computer than on a Windowsbased computer. The relative difficulty in actually compromising these two platforms is questionable and difficult to compare; however, the high rate at which Windows computers are compromised is attested to by the prevalence of Windowsbased worms.\nScalefree networks have proved to be highly resistant to random failure . Eighty percent of participants can be removed in a social network before the core infrastructure completely collapses . However, scalefree networks are vulnerable to attacks on hub nodes. Hub nodes are essentially wellknown participants and key forums within the community, which fuel the constant influx of newcomers and connect peripheral systems together. Successful attacks on hubs sometimes trigger what are known as \"Nodebreaking Avalanches.\" When a key hub is successfully attacked, it can cause a chain reactions that successively causes channel connectivity to be severed a few degrees of separation away from the key hub node. Within certain chat communities, measures have been put into place by chat network administrators to successfully block the creation of viable phishing hubs.\nThe strategy of eliminating hubs is unlikely to be effective because the environment allows for them to be easily rebuilt. Smaller disconnected chat room islands simply reconnect when they can reassert their authority.\nAlthough it did not impact the phishing economy as a whole, an example where the phishing infrastructure was successfully dismantled on a single network occurred on a cluster of public chat servers collectively known as EFNET. Server administrators simply elected to prohibit users with fraudrelated names from joining chat rooms.\nProcess flow of a phishing attack\nThe phishing process is easily represented in a flowchart with input required from different players at various stages. Each step involves specialized skills from other members of the Internet community.\nThe planning step requires information to be collected, such as target email lists, scam page templates, as well as demanding knowledge from consumers of phishing credentials.\nDetailed information such as target email lists and scam page templates needs to be collected. The phisher need not be adept at Web design, but instead can obtain an already used scam page. Scam pages and email templates are widely available within the community. If more advanced templates techniques are preferred, skilled Web designers who advertise on known fraudrelated forums can be hired.\nThe trade of compromised computers, also known as Roots, is a thriving economy. Computers are easily compromised through various public exploits and Trojans with security holes in network software. The security community readily provides proofofconcept exploits which can be used to gain access to vulnerable computers so there is a constant supply of compromised hosts. Phishers do not require technical knowledge of how to compromise hosts and can purchase access to compromised hosts from hackers.\nThe next step involves ensuring the proper scam page infrastructure on the compromised hosts used in the phishing attack.\nMapping a process to send back credentials to an anonymous email address or a chat room.\nThis step requires minimal technical expertise and consists of little more than uploading Web site content, and setting up what is known as an eggdrop or a simple mail script. An eggdrop bot is a scriptable automated program that connects to a chat room, allowing the user to remotely control it and issue commands. It is also the basic unit of a botnet (a centrally controlled cluster of these chat room bots). An eggdrop bot used for the purpose of harvesting credentials from a scam page machine could be programmed to relay the collected information back to a chat room or sent to a specific user on demand.\nNumerous programs have been written to handle mass mailings, and there are commercial appliances which also generate mass mails. As with the preceding steps the phisher does not need specialized knowledge to send out emails en masse and only needs to acquire the right tool.\nThe primary protocol responsible for sending email, SMTP, inherently lacks a mandatory authentication facility as with most protocols designed during the same era. Many tutorials, including the HACK FAQ, provide simple explanations on how to send forged email via a Telnet program. Although some authentication schemes now exist to counter this problem, sender authentication is not universally deployed. The Sender Policy Framework (SPF) attempts to address one aspect of sender verification issues.\nBasic knowledge of HTML enables the phisher to copy the formatting and style of valid emails from the banking institution.\nThe collection phase of phished credentials is often performed anonymously; for example, a process on the scampage hosting machine periodically sends back phished credentials to anonymous Webbased email accounts. These accounts are then accessed via a proxy server or sent to a chat room by an eggdrop chat bot. It is also possible to place the credentials into a readable directory on the Web server and download new credentials directly from a browser pointed to the proper directory where the credentials are stored.\nThis is often the end of the line for the phisher. At this point phishers are now providers of credential goods with a limited supply of customers. Consumers of financial institution credentials are known as Cashers. The Cashers main role is to take the phished credentials and obtain currency directly from the accounts attached to the credentials. Phishing and Cashing are distinct and often separate roles.\nThe phishing marketplace\nThe phishing marketplace is a loosely tied group of forums where participants can trade goods, services, and money. The key goods are credentials. Credentials are then valued according to the level of detail. It is currently difficult for cashers to extract monetary value from credentials based on different measures each financial institution has in place.\nAdvertisements used in the phishing economy were collected and we observed a wide range of credential valuations, noting the relative demand for a number of banking institutions. We gained some insights into the characteristics that govern credential valuation. Some examples of preventative measures in place by banking institutions, namely security advancements in ATM card encoding processes, have resulted in greatly diminished demand for those institutions.\nCashers and the credential trade\nCashers often play no role in obtaining the credentials from customers but instead purchase credentials in bulk through bartering various goods and services, or taking commission on extracted funds.\nPurchase rates on a per account basis range from US$0.50 for supplierselected credit card samples and up to US$100 for high balance verified fulls, which consists of full cardholder information, banking and routing numbers, credit card numbers, expiration dates, the cvv2 code (the threedigit number on the back of a credit card directly following the credit card number), current account balance, and the ATM pin. Commission rates for cashers are as high as 70 percent of cash outs. Commissionbased cash outs are often wired over Western Union to the credential supplier because of its international presence and relative anonymity for the pickup party.\nFollowing are some typical casher advertisements:<SuperCash | #cctradez> I can cashoutWashington Mutual , Key bank , Money access , HouselHold, CitizensBank, Mellon Bank, Sky Bank, BankNorth , Zip Network , Commerce Bank, PNC bank (443071) , Regions Bank , Banknorth , Bank One (478200), Capital One (517805 , 529149, 493422, 412174) PEOPLE'S BANK , Bank Of America (440893 , 549105, 550535), The Hungtington National Bank , JAPAN , MBNA (549035, 426429, 549198), Republic Bank\n<ebayinfos | #WAMU> I can cashout all wamu bins, PNC, TCF, Citibank South Dakota, MBNA, Summit Visa Sweden Banknorth, Canadian Imperial Bank VSB International B.V, M& I BANK OF SOUTHERN WISCONSIN, and more bins....... your share is 60%.\nWhat is seen here, is that the user, SuperCash, is a member of the chatroom, #cctradez. They are advertising that they have the ability to cash a number of banks. Additionally, some banks have a list of BINs in parentheses to the right of the bank name. These BINs are listed because only a subset of the BINs associated with those banks can be cashed. One reason why only certain BINs for a bank can be cashed is that banks sometimes have BINs associated with management regions where the bank accounts were opened and each region uses a different tracking method. Another reason is that while an encryptionbased tracking method is used, a different encryption key is associated with each BIN and certain keys have been successfully cracked.\nCredential supply and demand\nAs expected, phishing reports and casher advertisements for specific financial institutions follow powerlaw distribution, but the largest institutions are not necessarily the most targeted or reported. The report rate data was collected from Fraud Watch International.\nThe reasons for targeting a specific brand may partly be due to demand for a given brands customer information. Information was collected about the consumers of phished credentials from various chat rooms and online forums. A graph was developed to show the relative demand of given financial institution credentials based on advertisements by the consumers of phished credentials. There are some similarities in ranking between credential demand and phishing reports.\nTracking and credential demand\nThere are varying degrees of difficulty to cashing out certain credentials. For banking credentials, the preferred though more difficult method is ATM fraud, where the casher actually encodes the banking information (tracking) onto an ATM card and withdraws the maximum daily funds from that account. The popularity of tracking has grown because it has become increasingly difficult to ship purchased goods to countries where credit card fraud is a major problem.\nThe main difficulty with tracking is the encoding of bank data to the ATM card. The preferred hardware used to encode information onto magnetic stripe cards is the MSR206. Although the MSR206 hardware most preferred by cashers can be easily obtained, each bank uses a specific encoding algorithm to translate the credentials into the encoded data written to an ATM card. The tracking algorithm may be as simple as appending the expiration date and cvv2 code along with a fixed numeric value to the end of a check card number, or as complex as encrypting the information with a secret key and then encoding the encrypted block to the card.\nIt is no surprise that Washington Mutual, Key Bank, and various other institutions are at the top of phishers lists. The tracking algorithms for these financial institutions are easily obtained from within the phishing economy, while Bank of America, a huge financial institution, is nearly off phishers radar because their encoding algorithm is very hard to obtain or crack. According to statements by phishers, it may be based on TripleDES, a strong encryption algorithm.\nOnly a subset of accounts from certain banks can be cashed out as the above advertisement shows. The names of the banks in the advertisement are followed by a number called a BIN. A BIN is a bank idenfication number which associates an account number with a banking institution. Some large institutions have many BINs due the large number of banking customers they have. Casher advertisement of BINs lets potential credential sellers know that only accounts associated with these BINs can be cashed out.\nThe rate at which a financial institution is targeted for phishing scams is affected more by the pressure cashers put on the financial institutions and customer credentials, and less by the phishers ability to supply. Additionally, demand for credentials is created by the cashers ability to cash out on a given financial institution. This is dependent on the level of difficulty used in the credential tracking.\nThe findings of this study illuminate both the activities and social environment of the phishing economy and some successful methods in undermining phishingrelated activities.\nChat network administrators can help thwart the phishing community from establishing a presence on a chat network simple by restricting chatroom names.\nThe phishing economy is comprised of many participants that play specialized roles which overlap with other online communities. Phishing participants are not an isolated set of individuals.\nKeeping computer systems uptodate with the latest security fixes will lessen the chance that they are compromised and possibly used in botnets and fraudulent activities.\nAlthough all banks are at risk of having their users private information phished, the impact of phishing can be reduced by using encrypted magstripe tracking methods which will thwart ATM fraud.\nPhishing emails are only a small aspect of the overall phishing economy and until now, the only aspect seen by the most people. The phishing economy is a decentralized and selforganized social network of merchants and consumers governed by laws of supply and demand. This clearer picture of the landscape, the players, and insight into phishing operations will hopefully assist in the fight against online fraud.\nAbout the author\nChristopher Abad is a research scientist with Cloudmark (http://www.cloudmark.com/), a San Franciscobased spam filtering service provider.\n1. Financial Services Technology Consortium, \"Understanding and Countering the Phishing Threat,\" at http://fstc.org/projects/counter-phishing-phase-1/, last accessed 16 August 2005.\n2. Next Generation Security Software Ltd., \"The Phishing Guide: Understanding and Preventing Phishing Attacks,\" at http://www.ngssoftware.com/papers/NISR-WP-Phishing.pdf, last accessed 16 August 2005.\n3. John Robb, \"ScaleFree Networks,\" at http://globalguerrillas.typepad.com/globalguerrillas/2004/05/scalefree_terro.html, last accessed 16 August 2005.\n4. PieSpy Social Network Bot, \"Inferring and Visualizing Social Networks on IRC,\" at http://www.jibble.org/piespy/, last accessed 16 August 2005.\n5. Netcraft, \"Web Server Survey Archives,\" at http://news.netcraft.com/archives/web_server_survey.html, last accessed 16 August 2005.\n6. Liang Zhao Kwangho Park and YingCheng Lai, 2004. \"Attack vulnerability of scalefree networks due to cascading breakdown,\" Physical Review, E 70, 035101(R), and at http://chaos1.la.asu.edu/~yclai/papers/PRE_04_ZPL.pdf, last accessed 16 August 2005.\n7. John Robb, \"Cascading System Failure,\" at http://globalguerrillas.typepad.com/globalguerrillas/2004/05/cascading_syste.html, last accessed 16 August 2005.\nReka Albert and AlbertLászló Barabási, 2002. \"Statistical mechanics of complex networks,\" Reviews of Modern Physics, volume 74, number 1 (January), pp. 4797, ; see also http://arxiv.org/abs/cond-mat/0106096, accessed 16 August 2005.\nAlbertLászló Barabási, Réka Albert, and Hawoong Jeong, 2000. \"Scalefree characteristics of random networks: The topology of the World Wide Web,\" Physica A: Statistical Mechanics and its Applications, volume 281, issues 14 (15 June), pp. 6977.\nCloudmark SpamNet, at http://www.cloudmark.com/, accessed 16 August 2005.\nFinancial Services Technology Consortium, \"Understanding and Countering the Phishing Threat,\" at http://fstc.org/projects/counter-phishing-phase-1/, last accessed 16 August 2005.\nFraud Watch International, \"Phishing Scams: Understanding the Latest Trends,\" at http://www.fraudwatchinternational.com/internetfraud/phishing/report.pdf, last accessed 16 August 2005.\nGraphviz, \"Graph Visualization Software,\" http://www.graphviz.org/, last accessed 16 August 2005.\nIRC Spider, at http://www.the-mathclub.net/site/code/ircspider.tar.gz, last accessed 16 August 2005.\nAdilson E. Motter and YingCheng Lai, 2002. \"Cascadebased attacks on complex networks,\" Physical Review, E 66, 065102(R), and at http://chaos1.la.asu.edu/~yclai/papers/PRE_02_ML_3.pdf, last accessed 16 August 2005.\nNetcraft, \"Web Server Survey Archives,\" at http://news.netcraft.com/archives/web_server_survey.html, last accessed 16 August 2005.\nNext Generation Security Software Ltd., \"The Phishing Guide: Understanding and Preventing Phishing Attacks,\" at http://www.ngssoftware.com/papers/NISR-WP-Phishing.pdf, last accessed 16 August 2005.\nLiang Zhao Kwangho Park and YingCheng Lai, 2004. \"Attack vulnerability of scalefree networks due to cascading breakdown,\" Physical Review, E 70, 035101(R), and at http://chaos1.la.asu.edu/~yclai/papers/PRE_04_ZPL.pdf, last accessed 16 August 2005.\nPieSpy Social Network Bot, \"Inferring and Visualizing Social Networks on IRC,\" at http://www.jibble.org/piespy/, last accessed 16 August 2005.\nJohn Robb, \"Cascading System Failure,\" at http://globalguerrillas.typepad.com/globalguerrillas/2004/05/cascading_syste.html, last accessed 16 August 2005.\nJohn Robb, \"ScaleFree Networks,\" at http://globalguerrillas.typepad.com/globalguerrillas/2004/05/scalefree_terro.html, last accessed 16 August 2005.\nPaper received 14 June 2005; accepted 21 July 2005.\nCopyright ©2005, First Monday\nCopyright ©2005, by Christopher Abad\nThe economy of phishing: A survey of the operations of the phishing market by Christopher Abad\nFirst Monday, volume 10, number 9 (September 2005),\nA Great Cities Initiative of the University of Illinois at Chicago University Library.\n© First Monday, 1995-2013.", "label": 1}
{"text": "There seems to be a lot of misunderstanding about Web Service security. Using password authentication doesn’t prevent unauthorized users to access your data, while SSL / HTTPS doesn’t give you any information about who is trying to access your services. And did you ever think of signing you messages with a digital signature?\nIn my introductory post I’ve elaborated on what type of security we’d typically want on Web Services.\nIn part 1 , I’ve dealt with Username Token authentication.\nIn this article, I will describe Transport Level Security (TLS), formerly known as Secure Socket Layer and message encryption.\nLets recap the security requirements I have discussed in my introduction.\nThe client must be sure it sends it messages to the correct provider;\nThe provider wants to be sure that the client is authorized to;\nThe provider wants to be sure that the client is who it says it is;\nBoth the consumer and provider want to be sure that the messages can only be interpreted by each other;\nBoth parties want to be sure that the message sent is received unchanged.\nTransport Level Security\nUsing “Transport Level Security” (TLS), formerly known as Secure Socket Layer (SSL), and also referred to as HTTPS, will take care of requirements 1 and 4.\nTLS is a technically very complex algorithm, with a lot of varieties. Fortunately, the general concept is not as hard to grasp. It works as follows:\nThe client will send a “Hello” to the server.\nThe server will response with a “Hello”, and send a certificate to the client\nThe client will decide whether it trusts the server’s certificate\nThe client will use the servers certificate to encrypt its own certificate and send it back to the server\nDepending on the exact algorithm chosen, the client and server will exchange some more encryption information to make the communication “water tight”.\nIf you really want to know the technical details of TLS, have a look at this page: http://an.wikipedia.org/wiki/Secure_Sockets_Layer. For the typical Web Service developer, these details are not really important. However, knowledge of how the first three steps work can help you prevent a lot of problems.\nEspecially step 3 is of great importance. The client has received a certificate from the server, and has to decide whether it is safe. This decision is based on a few factors.\nFirst of all, the certificate has to have been issued for the domain that has been requested. So if you access a service on http://somecompany.com/service and get a certificate issued for someothercompany.org, the client will reject the certificate. Some clients, such as web browsers allow the users to override this decision and accept the certificate anyway. A web service client doesn’t typically have a user, so there is no room for second chances.\nSecondly, the certificates timestamp has to be valid, meaning that it hasn’t reached it’s expiry date yet. Depending of the type of certificate, it is valid from 1 to tens of years.\nThe third requirement can sometimes give some problems: the client has to trust the certificate. This can best be explained using a real life example. Imagine yourself at the border control on a foreign airport. If you show them a paper with your name and a signature on it, chances are small that they let you through? Why? Because they can’t trust a self-signed certificate, or one that is signed by a relative. However, if that same name is written on a legal passport, given and signed by your country’s authority, border control will trust it, because they trust them. In TLS, it is exactly the same.\nIf you order a certificate from a certificate authority (CA), nobody will actually know that you have that certificate. And you don’t trust what you don’t know. However, you have paid the CA to sign your certificate. And maybe the CA certificate has been signed with yet another certificate. Now, if you trust the CA, you will automatically trust all certificates that have been signed with that CA. Back to our border control. If you trust the US government to issue correct passports to people, you will automatically trust all passports of US citizens, even if you don’t know that person.\nTo mark a certificate as trusted, the certificate has to be stored in a so-called “trust store”. Your browser has a truststore that includes the large CA certificates by default. Just look around in the configuration of your browser. You’ll be able to install other certificates if you like. For example, one that you have created and signed yourself.\nYou can also configure a truststore for your web service client. By default, your JVM will probably include the large CA certificates, such as Verisign and Thawte. If you’re running on an application server, chances are big there is a trust store configured in them, too. Of course, you can override the truststore by defining your own.\nOk, now that we’ve seen a lot of misery on the client side, let’s have a look at what has to happen on the server side. Well, luckily, not all that much. All you have to do is configure your web server to use SSL. Somewhere along the line it will require you configure a certificate to use. And since you probably want to be trusted, make sure to have your certificate signed by a large CA.\nThe good part is that all communication between client and server is encrypted in such a way, that only these parties are able to read the messages. And, as a bonus, the client is ensured that it is really talking to the server it was expecting to communicate with.\nTLS is nice, but if you have a message that will pass a few endpoints, or has to be logged in the mean time, it doesn’t really help you. If you have to keep your data secure after is has arrived at your first endpoint, message encryption could be your solution.\nLet’s start off with an example. Let’s image we have a service where consumers can place orders. Just for the sake of the example, the request will first be processed by an endpoint that checks the stocks. If the stocks are sufficient, the payment is processed. If TLS were used between the consumer and the first endpoint, the message would be sent unencrypted. Of course it is possible to encrypt that communication too, but that would probably be a performance hit.\nThe idea behind encryption is not really complex. The entire message, or part of it is encrypted using the public key part of the certificate. Since the private key is required to decrypt it, only the recipient (or at least only systems with access to the private key) will be able to so. Even if a message is stored for future reference, the contents will be unreadable to any third party.\nTypically, only parts of messages are encrypted. You could think of elements containing payment information or other private contents, such as social security numbers. The example project in go ogle code shows an example of a message where an ID is encrypted. Not a really powerful use case, but it shows how the technology works.\nAs with TLS, message encryption will deal with items 1 and 4. However, it will only do so for the parts of the message that have been encrypted.\nBoth TLS and message encryption give the communication between consumer and provider some form or privacy and protection against eavesdropping. If configured correctly, they can work transparently to the implementation of both the client and the consumer, but will claim some of your performance.\nMy next and last article in this series will discuss message signing, which will deal with the security item that hasn’t been covered yet: “Both parties want to be sure that the message is received unchanged”.", "label": 1}
{"text": "There's a joke e-mail that seems to circulate on the Web every eight months or so. It includes images of outrageous design blunders, like a surveillance camera mounted behind and pointing at the back of the monitor it feeds. There's a picture of a faucet that's about six inches away from the sink into which the water should fall. There's another of a man using an automatic teller machine that's about nine feet above the ground.\nAll good for a laugh, but the truth is, bad design is more common than most of us realize. Bad engineering design, specifically, is simply wasteful. Poorly designed processes and systems gobble up energy and resources as if they were free or nearly free, and the inefficiency is generally invisible to most observers, including consumers who have to pay for the energy and resources.\nThroughout the Institute's 27-year existence, RMI's staff has sought to influence the design, building, and retrofitting of power and industrial plants, commercial and residential buildings, and vehicles and transportation systems early in the development process so they're designed correctly upfront, eliminating costly late redesigns and inefficient creations.\nOne of the basic challenges our researchers run into, year after year, is that the people creating inefficient processes and systems are simply unaware they are doing so, and they don’t know how to do things differently. The reasons are many and complex, but often boil down to a few familiar parameters: assumed cost (e.g., capital resources, risk, reward, etc.), time (e.g., regulatory requirements, demand, etc.), tradition (e.g., what has worked before), and skills.\n\"Engineering schools don't specifically teach bad engineering design,\" notes Alok Pradhan, RMI's project manager for 10×E. \"It's just that current engineering practice is very siloed and there's a lack of integration and whole-system consideration. Designs are typically optimized for the wrong parameters. That is, they will optimize the component individually, and the pieces—when they fit together—don't work that great as a system.\"\nSeveral years ago, RMI kicked off a modest project to address these problems in engineering. Known around the Institute as Factor Ten Engineering (or 10×E for short, \"ten times the efficiency\"), this RMI initiative is fairly straightforward: the goal is to create a series of teaching tools that will help engineers design the things they design so that they use radically less energy and resources than they currently use to achieve the same goal or create the same product. These teaching materials—centered around a casebook of extremely efficient projects and systems—will be used to teach efficiency concepts and design to both engineering students and practitioners.\n10×E has its genesis in the Factor Four notion put forth by Ernst Ulrich von Weizsäcker, Amory Lovins and L. Hunter Lovins in their 1995 report to the Club of Rome, Factor Four: Doubling Wealth, Halving Resource Use. In the report, the authors argue that energy and resources can be used much more efficiently, to the tune of at least four times as efficient. \"Factor Ten represents Amory Lovins's belief that we can do even better,\" notes Alok. \"It might not necessarily be ten times the efficiency. It might be eight times or six times, but the basic premise of this project is to see, when these principles are applied, what's possible.\"\nThis year, the effort has gained some financial support and is picking up momentum.\n\"It's something we've been thinking about for a long time at RMI, but now, with Alok, we have a full-time project manager, a little seed money, and the momentum to move forward,\" notes Lionel Bony, who heads the Office of the Chief Scientist at RMI. \"We are going from concept phase to implementation, which is very exciting.\"\nA Different Kind of Engineering Ideal\nThe main focus of the 10×E project is the casebook. In it, RMI and the Institute's research partners (university engineering schools, engineering firms, and their customers) are assembling several dozen case-studies in which regular, dis-integrated engineering will be compared with highly efficient engineering design, laid out on facing pages so the reader can easily compare them and understand why the superefficient design typically costs less to build.\nThe cases themselves will span the range of engineering disciplines and main applications. More importantly, they’ll be chosen to illustrate and develop practical principles of design integration to achieve big energy and resource savings more cheaply.\n\"We do want to make these cases broad so they cover multiple disciplines, and, more importantly, demonstrate the whole-system considerations that have gone into the design,\" Alok notes.\nA case study of a data center that is currently being developed is a good example of the types of projects the book will include, he says. Researchers will compare the superefficient data center design with a normal one.\n\"In that particular data center they managed to eliminate chillers, which is a huge energy savings; they made the computer code more efficient so the center didn't actually have to do as much computing; they removed extra load and unnecessary servers; they changed some of the electrical hardware to make the servers 'best in class'; and they retrofitted the buildings,\" Alok notes. \"The project was made much more efficient in terms of at least three disciplines: mechanical, electrical, and civil engineering.\"\nWhile the cases will compare efficient engineering projects with projects that weren't designed to be efficient, not all the comparisons will be parallel. With Amory Lovins's 1982 superefficient home in Snowmass, Colorado, for example, researchers plan to do some energy modeling and compare the building as it exists (including an elaborate data-monitoring system now being commissioned) to a hypothetical version of the building built simply to meet the local building code.\nAt present, RMI researchers are working with partners along the engineering value chain to refine how the casebook will come together during the next few months, with the possibility of a \"summer study\" in July or August, convening researchers for intensive collaboration over a two-week period. The book itself will likely be published in 2010.\n\"It's very important that we drive change as soon as possible,\" Lionel says. \"The things we design now have a lifespan of anywhere between 15 and 20 years for a car and 50 and 100 years for a building. The more we wait, the longer it's going to take to have an impact.\"\nPerhaps more important will be 10×E's influence on people. Some leading professors and practicing engineers are already using the term \"brown engineering\" for standard engineering practices, and engineering students who've been exposed to \"green engineering\" quickly become diehard advocates, helping to build momentum for superior design. Once these young engineers enter the marketplace, their very existence will help create further demand for green engineering.\n\"10×E will hopefully foster an entire generation of newly and better-educated students who will go on to do amazing things because they have been properly trained,\" notes Lionel. \"This won't just change the built world around us; it'll change our fundamental relationships with both what we build and the Earth itself.\"\nOne interesting project related to 10×E is an effort by ABB engineer Robert Martinez, who recently took a sabbatical at RMI to complete a handbook on making fossil-fueled power plants more energy efficient. Robert focused his efforts not on the plants' primary fossil-fuel-driven generation but instead on the \"auxiliaries,\" also known as the \"balance of plant\" systems (fans, pumps, etc.) because they actually run on the electricity generated at the plant and can gobble up a whopping 8 percent to 15 percent of the electricity produced. He was able to reconfigure typical auxiliaries to achieve a 6 percent energy improvement with a three-year payback. This may not sound like much, but such power plants emit about 41 percent of U.S. and 32 percent of global fossil carbon.\nThe book will be made available to ABB's roughly 15,000 engineers. ABB is the number one provider of electrical infrastructure (transformers, transmission and distribution equipment, metering equipment, etc.) on Earth and strongly influences the electric power industry. Additionally, Robert and his ABB colleagues are helping apply their book to a new coal plant proposed in the western United States.\n\"I think it [the handbook] will inspire changes in a lot of designs,\" Robert says.\nCam Burns is RMI's Senior Editor\n--Published April 2009", "label": 1}
{"text": "Risk Assessment and Threat Modeling\nBefore you write a single line of code, take the time to design your software with security in mind. Doing this correctly is genuinely hard; if your security analysis process seems easy, you’re probably missing something fairly fundamental and losing most of the benefits of proper secure code design.\nRisk assessment and threat modeling happens in three steps:\nAssess risk. Determine how much you have to lose.\nDetermine potential threats. Figure out the various things your code does that could be attacked (including things that frameworks and libraries do on your behalf).\nMitigate threats. Ensure that the parts of your code that could be attacked are well protected.\nTo assess the risk that your code would pose if compromised, you should first assume that your program will be attacked.\nAssume Your Software Will Be Attacked\nThe amount of time and effort that an attacker will spend attacking your program depends on several factors, including:\nThe value of the data your program handles. Does it store thousands of credit card numbers or a user’s recipe collection?\nThe trustworthiness and security of companies who provide services that your code depends on.\nThe specific clients who purchased your program. Is your word processing app being used by Joe’s Auto Repair or by Big Megacorp, Inc.?\nHow widely your program will be distributed. Is it an app that is used by a single, small workgroup, or is it built into an operating system that is about to be released worldwide?\nBased on those same factors, you need to decide what level of risk is acceptable. A loss of data that will cost your company $1000 to rectify doesn’t justify a $10,000 development effort to close all potential security bugs. On the other hand, damage to your company’s reputation might be worth far more in the long run than it would cost to design and develop secure code.\nEvaluate the Risk\nHere are some factors to consider when evaluating risk:\nWhat is the worst thing that can happen if your software is successfully attacked?\nWill it allow theft of a user’s identity, allow an attacker to gain control of a user’s computer, or just enable a hacker to get an unusually high score in pinball?\nHow hard is it to mount a successful attack?\nIf exploiting a vulnerability would require installing a Trojan horse on the user’s computer that can take advantage of a race condition that occurs only once in 50 times the program starts up, you might decide the level of risk is acceptable. If the exploit can be put into a script and used by script kiddies (attackers who run prewritten attack scripts) or be automated to spread by botnets (networks of compromised computers), the level of risk is much higher.\nHow big a target is it?\nDid you sell a hundred copies of your app, or is it installed by default on hundreds of thousands of computers?\nIs it vulnerable by default, or only after a user chooses an unusual set of options?\nHow many users would be affected?\nAn attack on an end user’s machine usually affects one or two people, but a denial of service attack on a server might affect thousands of users if even one server is attacked. Similarly, a worm spread by a common email program might infect thousands of computers.\nHow accessible is the target?\nDoes running the program require local access, or does the program accept requests across a network? Is authentication required in order to establish a connection, or can anyone send requests to the program?\nDetermining Potential Threats\nA risk assessment gives you some indication of how likely you are to be attacked and how much damage an attack could cause. The next step is to figure out how you might be attacked, including attacks on all of your interests—not only attacks on your software but also on your servers, your company, and so on. To do this, you create a threat model that describes places in which anything of value (information, money, and so on) changes hands.\nCreate a Threat Model\nThe threat model for an app, daemon, or other software system should be a high-level data-flow model that diagrams every spot in which information moves into or out of your code or between major parts of your code. At a high level, it should include these pieces:\nThe types of data your app will work with\nThe situations in which your app must deal with untrusted data\nThe types of data transport your app uses\nWays that an attacker could exploit a piece of software that does what your app does\nStrategies for mitigating each of those types of exploits\nFor the purposes of this analysis, you should consider only theoretical categories of attack, not actual specific attacks. For example, a word processor could be compromised if it mishandles a corrupted file in such a way that allows an attacker to inject code. It is not important whether your specific code has specific bugs that make this possible.\nSome potential attack targets might include program input or output, stored data, and the program’s operating environment.\nProgram input. If an attacker can cause a buffer overflow, they might be able to run their own code or otherwise compromise the user’s data or system.\nProgram output (either to the user or to another software module). The attacker might be able to gain access to private information stored on the system, or to read and modify the information being passed between modules (a man-in-the-middle attack).\nData stored on the system (either permanently, as in a database, or temporarily, as in a global variable). This data could potentially be stolen and sent to an attacker, modified by an attacker, or otherwise compromised.\nProgram environment. A program’s execution environment includes its open file descriptors, environment variables, Mach ports, preference files, and so on.\nConsider Types of Threats\nThere are several types of threats to consider, including threats to data, service availability, and system integrity.\nThreats to Data\nAn attacker can modify data. This includes:\nData used internally by the program (such as interprocess messages)\nData acted on by the program (such as numbers on which the program does a statistical analysis or an audio track that the program filters)\nData stored on disk to which the program gives access..\nSimilarly, an attacker can compromise data and obtain access to secrets.\nAn attacker can modify or compromise data directly by telling the program to modify or return data that it shouldn’t have modified or returned. However, an attacker can also modify or compromise data indirectly by using your program to take control of the computer.\nFurther, direct modifications often lead to further access that can allow additional indirect modifications. For example, an attacker might modify internal program data directly, then use that modified data to inject arbitrary code that adds a new admin user to the system’s password database.\nThreats to Service Availability\nAn attack designed to reduce service availability is called a denial of service attack. These attacks can cause an app or daemon to stop functioning, or make a server so busy that legitimate users can’t get access to it.\nAn attacker can perform a denial of service attack in many ways:\nAttacking bugs in the networking stack\nOpen connections to the daemon, start sending a request, then continue sending it very, very slowly\nConvince thousands of people to voluntarily attack your server.\nOpen millions of connections to the daemon from a botnet.\nWhen a denial of service attack is carried out by a large number of machines, it is called a distributed denial of service attack, or DDoS.\nAttacks on System Integrity\nAttacks on system integrity build upon other attacks to modify the system in such a way that it can no longer be trusted. If an attacker can find a security flaw in your code, the attacker might be able to:\nExecute malicious code, especially with administrator or root access. The attacker might cause your code to execute the attacker’s code by exploiting a buffer overflow or by code insertion in a URL command, for example.\nIf your code is a daemon running with administrative privileges, the attacker’s code will be privileged as well. Once an attacker has administrative control of a computer, any efforts to mitigate threats become futile.\nSimilarly, a spoofed server might be able to convince a client app that it is a legitimate server, then get the client to give it data or get the user to provide secrets, such as passwords.\nFinally, a spoofed server might be able to convince a naïve user that the server is legitimate. For example, a user might not examine the window containing a web page sufficiently to notice that the lock icon (or other indicator of a secure site) is missing. Using such a malicious website to obtain user data is called phishing.\nRepudiate an action. A malicious user might modify your software in such a way that allows him or her to deny performing an operation (such as using a specific credit card number). There are a number of techniques you can use to ensure nonrepudiation, such as code signature verification, data integrity checks, and so on.\nAfter you have determined which parts of your software ecosystem (apps, servers, local daemons and agents, and so on) might be attacked, you must take steps to mitigate those threats—that is, to make them less damaging.\nUse Common Mitigation Techniques\nThe means of mitigating threats in computer software are many and varied, but a few core techniques are common:\nTake extra care when working with data from a potentially untrusted source. In particular, secure software must always validate its inputs.\nTake advantage of sandboxing—setting developer-defined limits on what your app can do—to minimize the damage that an app can cause if it gets compromised.\nMinimize the risk of information disclosure by compartmentalizing your apps and ensuring that each part of an app can access only the information that it needs.\nPerform fuzzing—sending bad data to your app or daemon to see if it breaks—and fix any bugs that you find in the process.\nTake advantage of the security functionality built into the operating system instead of reinventing the wheel.\nKnow the Trade-Offs\nWhen deciding how to mitigate a threat, keep in mind that there are often tradeoffs between security and convenience. Software security must strike a balance between security and usability. Consider two extreme examples of software design:\nOne program requires authentication using multiple authentication methods before performing any operation, runs only long enough to perform that operation, does not share use of the CPU with any other program, and then quits, requiring reauthorization for the next operation.\nThis mode of operation is very secure and might be appropriate for a program that launches nuclear missiles, but few would want to use a word processor that acted like that.\nAnother program always runs with root privileges and performs any operation you like without ever requiring authorization.\nSuch a program is easy to use, and on a physically secure computer that is not connected to a network, it might even be moderately safe. However, under most normal conditions, it would be a huge security risk.\nClearly neither of these extremes strikes an optimal balance between security and user convenience. As a developer, it is your responsibility to decide where your software should fit in this continuum based on the damage that might occur if your program is compromised (the risk) and the types of attacks the software is likely to face (the threat).\nAfter You Finish\nEven when you finish this assessment, your job is not done; you should repeat this assessment at regular intervals along the way. In particular:\nWhenever you make any design decisions, consider how the design decisions change your threat models and update your models accordingly.\nWhen you add new features or functionality, create threat models for those new components.\nAs you code, be aware of the threat model and make sure your code follows its guidance.\nIn addition to avoiding bugs in the design, you must also take steps to ensure that your code is robust against attacks on bugs in the implementation. You’ll learn more about how to do this in the next chapter.\nThe governments of the United States, Canada, the United Kingdom, France, Germany, and the Netherlands have worked together to develop a standardized process and set of standards that can be used to evaluate the security of software products. This process and set of standards is called the Common Criteria.\nAs an attempt to systematize security evaluations, the Common Criteria can be helpful in suggesting a large number of potential problems that you can look for. On the other hand, as with any standardization scheme, the Common Criteria cannot anticipate vulnerabilities that haven’t been seen before. Therefore, the Common Criteria standard is less flexible than one might wish.\nAlthough opinions of security experts vary as to the value of a Common Criteria evaluation, some government agencies cannot use software that hasn’t been through a full Common Criteria evaluation by an accredited laboratory.\nTo Learn More\nA number of third-party security books describe threat modeling in more detail. See “Other Security Resources” for a complete list.\n© 2012 Apple Inc. All Rights Reserved. (Last updated: 2012-12-13)", "label": 1}
{"text": "Network+ Study Guide & Practice ExamsBy\n- Robert Shimonski, Networking, Security, Systems, Servers, Storage, Cloud and Management\nThe Network+ Study Guide covers all the objectives on the CompTIA exam, including the features and functions of networking components, and ensuring that readers have the knowledge and skills needed to install, configure and troubleshoot basic networking hardware, protocols and services. It covers exam topics such as media and topologies, protocols and standards, network implementation, and network support, as well as new exam topics on technologies such as wireless networking and Ethernet.\nNetwork+ candidate is looking for a way to prove to potential employers that he has 9 months of networking experience. The Network+ certification does that and is now a requirement of many companies hiring technicians. Candidates are searching for low-cost yet comprehsenive study tools.\nPublished: April 2005\n- Introduction ; Domain I Media and Topologies ; Network Fundamentals ; Network Media ; Network Devices ; Wireless Technologies ; Domain II Protocols and Standards ; OSI Model ; Network Protocols ; WAN and Security Standards and Services ; Network Operating Systems ; Domain III Network Implementation ; Network Infrastructure and Security ; Fault Management and Disaster Recovery ; Domain IV Network Support ; Network Troubleshooting Tools ; Network Troubleshooting Methodology ; Self Test Appendix ; Index", "label": 1}
{"text": "LAMP is the application stack, but it need not all be installed on the same host. As others have noted for performance, security or scalability purposes often these are not installed on the same host. You can also find that hardware which is optimal for one part of the architecture may not be for another.\nFor instance, databases are all about storage management. The faster I can get information off of the disk then the faster I can get it to the requestor. If I am sharing a disk subsystem with several other application stack members, such as a web server, the contention I face on the shared resource of the read and write heds of the disk drives can actually hinder my performance. Also, having RAM split between web server and database server on a given host may not provide a large enough resource pool for either to run in its most efficient fashion, able to cache as much information in RAM without having to go to the disk either for an image, a page, or a query result set.\nAdministratively there are efficiencies to be gained as well. Imagine if you run your enterprise on open source applications which leverage MySQL as a common backend. Would you really want to have database server proliferation with each app? This could be a DBA nightmare, \"OK, which application uses this DB?\" You would have multiple versions, mulotiple configurations of hardware/software, multiple data retention strategies. You would also likely have very diffuse administrative skills. Instead, coalesce the instances to one physical piece of hardware optimized for the role and assign dedicated resources to manage the server and its data.", "label": 1}
{"text": "RADIUS: Secure Authentication Services at Your Service\nRADIUS ensures that remote users are who they say they are, keeps track of their network usage, and secures your network infrastructure from intrusion. Learn how deploying RADIUS in-house or as a managed service can benefit you and your company's network.\nIsn’t it wonderful that we can connect to ISPs or office networks from anywhere, using any access technology? Have you ever wondered how ISPs and office networks know whether or not a user has a legitimate account? And how does a provider keep track of a user's access time anyway? The answer is very likely RADIUS, the most widely deployed example of an Authentication, Authorization, and Accounting system (sometimes called AAA systems).\nRADIUS is a set of AAA standards that has been implemented by many vendors. It has been around for ages, quietly providing services that keep networks secure from unauthorized use. Let's delve in and learn more about this useful capability and how it can benefit you and your company's network.\nThirty years ago, ARPANET, the predecessor to the Internet, was built to permit dumb terminals to access remote computing resources. In the days before PCs and LANs, the hardwired connection between the terminal and computer was managed by a Terminal Interface Processor, or TIP. But even then, managers, developers, and users wanted to be able to work from home or on the road (dial-up via an acoustically-coupled modem). Bandwidth was scarce and expensive, and people wanted to protect the network, and the mainframes and minicomputers on it, from unauthorized access and possible disruption.\nIt quickly became apparent that the use of unlisted dial-in numbers was not a secure answer. Was there something that could be done to further protect the network from unauthorized access? TACACS, the original AAA system, was developed for the ARPANET to solve that problem. Later, commercial companies adopted and extended the technology in open and proprietary ways. With experience and the expanding use of data networks, the limitations of the original TACACS architecture became apparent.\nRADIUS was originally developed by Steve Wilens of Livingston Enterprises and then later acquired by Lucent Technologies in 1992, and is now an IETF standard. The most recent version is RFC 2865 (June 2000), which covers both authentication and authorization. A companion IETF document, RFC 2866, describes how to extend RADIUS to implement accounting services.\nWhat Is It Used For?\nThe need for AAA systems has grown tremendously over the years. Corporations (and carriers) still support dial-up lines of course, but now remote users also access networks via VPNs and broadband, while employees and guests connect to internal wireless networks simply by powering up their laptops and PCs. Today's AAA systems must be highly robust, scaleable, secure, and easily manageable to meet the needs of a modern IT environment.\nBasic RADIUS implementations provide access control by authenticating end users and authorizing their requests, while extended implementations include user accounting. Depending on the RADIUS product, you can:\n- Centrally administer access to your network resources, perhaps with fine control over access based on time of day or by regulating the number of simultaneous log-ins by a single user\n- Utilize the function and information from your other access control systems, such as the Netware NDS and Windows Active Directory\n- Allow your dial-in or VPN service vendors to query your access control database, so any changes you make are automatically available to them\n- Create central summary or real-time reports that can audit usage for tracking and billing\nIf you have not already implemented RADIUS in your network, new technologies like wireless Ethernet should prompt you to consider it for the future.", "label": 1}
{"text": "Shows & Panels\n- Accelerate and Streamline for Better Customer Service\n- Ask the CIO\n- The Big Data Dilemma\n- Carrying On with Continuity of Operations\n- Client Virtualization Solutions\n- Data Protection in a Virtual World\n- Expert Voices\n- Federal Executive Forum\n- Federal IT Challenge\n- Federal Tech Talk\n- Feds in the Cloud\n- Health IT: A Policy Change Agent\n- IT Innovation in the New Era of Government\n- Making Dollars And Sense Out of Data Center Consolidation\n- Navigating the Private Cloud\n- One Step to the Cloud, Two Steps Toward Innovation\n- Path to FDCCI Compliance\n- Take Command of Your Mobility Initiative\nShows & Panels\nWisconsin scientists help search for alien life\nSaturday - 2/16/2013, 7:04pm EST\nMADISON, Wis. (AP) -- Scientists at the University of Wisconsin-Madison are helping search for evidence of alien life not by looking into outer space, but by studying some rocks right here on Earth.\nSome of the rocks are up to 3.5 billion years old. The scientists are looking for crucial information to understand how life might have arisen elsewhere in the universe and guide the search for life on Mars one day.\n\"There's a story always hidden in rocks,\" said geoscientist Clark Johnson, the lead investigator for the Wisconsin Astrobiology Research Consortium. \"... It's up to (geologists) to be clever enough to find the tools that we need to interrogate those rocks to find what story they preserve.\"\nThe project is funded through NASA, which provided a $7 million, five-year grant that started in January. It was the group's second five-year, $7 million grant.\nThe consortium includes about 50 staff, students and post-doctoral fellows from 24 institutions in five countries. About 25 of the participants are at UW-Madison.\nThe consortium's goal is finding footprints of biological activity, or biosignatures, which are substances such as elements or isotopes that show evidence of ancient life. The scientists are looking for microscopic signs of life, including microbes, which are bacteria, and other tiny, one-celled organisms that are much more adaptable than more complex organisms.\nThe team is also sending microbes into Earth's orbit on the International Space Station to see how they react to radiation and a space environment.\nIn the process, they are learning more about Earth's history. They've found new details of microbial life that dates back 2 billion to 3 billion years, before the planet's atmosphere contained oxygen. They've found that microbes then relied more on iron than sunlight for energy.\nEventually their work will be used to interpret data beamed back from Mars by the six-wheel spacecraft Curiosity, which landed in August on a two-year mission to determine whether the environment was ever favorable for microbial life. Their work will also be used to prepare for future Mars missions.\n\"It may be that planets spent a long time in a microbial life condition and then only rarely evolved to advanced multicellular complex life,\" Johnson said. \"That's one of the hypothesis we would test.\"\nEdward Goolish, acting director at the NASA Astrobiology Institute, said the project supports one of NASA's major goals to find life or the potential for life elsewhere.\nThe project's results will provide a quantitative understanding of how life is preserved, he said.\n\"At the same time (Johnson's team is) contributing an immense amount to the understanding of life on Earth, which is equally important to astrobiology and science in general,\" he said.\nSee video at: http://www.youtube.com/watch?v=XTz0hSbWY1A\nCopyright 2013 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.", "label": 1}
{"text": "Credit: Visual Complexity.\nEver had your MySpace or e-mail account hijacked? Recently, Gmail experienced a cross-scripting vulnerability. Luckily, Google was able to patch it quickly, and so far there are no reported cases of people losing information. Getting your e-mail hacked is becoming a major issue. Hackers do not usually care to just read your latest gossip. Instead, as with most things, they “follow the money.” Often, your e-mails contain passwords to other accounts, such as your checking or savings account. So choose your e-mail provider carefully. (Think of e-mail as an entry point which provides access to all your other accounts).\nAs data has moved online, it is becoming common to hear of large companies and organizations losing millions of records or even worse having their entire system compromised by attackers.\nWhat happens when a social graph is compromised? More than you may think at first. There is a looming danger of having so much available data online. If it gets in the wrong hands, we may have to deal with serious consequences.\nAs you know, the social graph is a way to keep track of who you are connected to. It takes into account who are your friends, family, and colleagues. When your MySpace or Facebook accounts are hacked into, often the hacker uses it to send advertising spam to your network. However, the next level is more sophisticated and will become more frequent in the future.\nHackers are beginning to harvest all your connections and aggregate them into some sort of database. This information becomes valuable to advertisers, marketers, enforcement agencies, merchants, and just about any other organization. However, if the social graph is extended to include biographical information, e-mails, and other data that is linked to each account the data becomes more valuable and dangerous. Not only can hackers know things about you, but also about those you are affiliated with. Remember, you are often defined by whom you associate with.\nWhen these separate pieces of data are integrated into a universal social graph we will begin to feel “the powers that be” try to gain access to this wealth of information. Government agents will want access so they can “find” criminals. Banks will want access to find trends in the economy. Merchants will want this information to know what consumers want. Advertisers will want to know where consumers are spending their money. The list goes on. As this becomes increasingly common, we are left with the threat of an Orwellian society.\nUnfortunately, this problem will not go away. Google, Yahoo, Microsoft, MySpace, Facebook, LinkedIn and a host of other companies are building out their versions of the social graph. The social graph is a highly, lucrative form of data mining. (I am doubtful that there is more money in securing data than in mining it). In fact, a lot of companies are opening up their social graphs!\nThere is nothing wrong with creating a social graph. The problem is that there is no guarantees in safeguarding this information to protect users. If MySpace is hijacked, they cannot afford to shutdown their entire site for long periods of time. Millions of dollars of revenue are at stake each day that their site remains functional. Customers may be left to fend for themselves. And many users, unwittingly trade access for privacy.\nWhat is even worse about this situation is that users cannot really opt out of the universal social graph. Yes, they can stop using social networks, search engines, department store club cards, but as more data is moved online there aren’t many things users can do to protect themselves other than securing their own computers. Already, your bank, educational, e-mail, insurance, social network, search, shopping, and medical records are online. Are they secure? Good question.", "label": 1}
{"text": "Getting the most out of automated IT security management\nThe National Institute of Standards and Technology is updating guidelines for using the Security Content Automation Protocol (SCAP) for checking and validating security settings on IT systems.\nSCAP is a NIST specification for expressing and manipulating security data in standardized ways, including implementing security configuration baselines, verifying patches and known vulnerabilities, continuous monitoring of vulnerabilities and security configuration settings, looking for signs of compromise, and determining the security posture of systems.\nSpecial Publication 800-117, Guide to Adopting and Using the Security Content Automation Protocol Version 1.2, is being revised to provide an overview of its use as well as guidance to vendors for adopting the protocols in their products and services.\nUpdated SCAP specs aim to improve automated security checks\nNew SCAP testing requirements cover Windows 7, IE 8\nA draft of Revision 1 has been released for public comment.\nAutomating security is challenging because of the number and variety of systems being secured, the need to respond quickly to new threats, and the lack of interoperability of security tools. SCAP is an effort to provide a standardized approach to addressing these challenges. It is “a suite of specifications that standardize the format and nomenclature by which software flaw and security configuration information is communicated, both to machines and humans.”\nSeveral organizations created and maintain the SCAP components, including Mitre Corp., the National Security Agency, and the Forum for Incident Response and Security Teams. NIST provides SCAP content such as vulnerability and product enumeration identifiers via the National Vulnerability Database. All database content and the high-level SCAP specification are available free from NIST. Nongovernment organizations also create and make SCAP content available.\nThe specifications making up SCAP are divided into languages, reporting formats, enumerations, measurement and scoring systems, and integrity protection. The specifications included in the current version are:\n- Extensible Configuration Checklist Description Format (XCCDF) 1.2\n- Open Vulnerability and Assessment Language (OVAL) 5.10\n- Open Checklist Interactive Language (OCIL) 2.0\n- Asset Reporting Format (ARF) 1.1\n- Asset Identification 1.1\n- Common Platform Enumeration (CPE) 2.3\n- Common Configuration Enumeration (CCE) 5\n- Common Vulnerabilities and Exposures (CVE)\nMeasurement and scoring systems:\n- Common Vulnerability Scoring System (CVSS) 1.0\n- Common Configuration Scoring System (CCSS) 1.0\n- Trust Model for Security Automation Data (TMSAD) 1.0\n“Each of the SCAP components offers unique functions and can be used independently, but greater benefits can be achieved by using the components together,” the document says. “SCAP-expressed checklists use a standardized language to express what checks should be performed, which platforms are being discussed, and which security settings and software flaw vulnerabilities should be addressed.”\nNIST has established a SCAP product validation program and laboratory accreditation program to ensure that SCAP products conform to requirements. “Given SCAP’s complexity, this formal testing is needed,” NIST says.\nIn using SCAP, the NIST guidelines recommend that organizations:\nUse security configuration checklists that are expressed using SCAP. A SCAP-expressed checklist documents desired security configuration settings, installed patches, and other system security elements using a standardized format.\nTake advantage of SCAP to demonstrate compliance with high-level security requirements. SCAP-expressed checklists can map individual system security configuration settings to their corresponding high-level security requirements.\nUse standardized SCAP enumerations, identifiers and product names. The common understanding achieved through the use of standardized enumerations makes it easier to use security tools, share information and provide guidance to address security issues.\nUse SCAP for security measurement and scoring. SCAP enables quantitative and repeatable measurement and scoring of software flaw vulnerabilities and software security configuration issues across systems.\nAcquire and use SCAP-validated products.\nNIST also encourages software developers and organizations producing security checklists to adopt SCAP, rather than relying on manual checks or proprietary checking mechanisms. The depth of knowledge also makes product vendors particularly helpful in implementing SCAP and checklist developers can contribute applicable lists to NIST’s National Checklist Program to help ensure that they are available to the broadest possible audience.\nComments on draft SP 800-117 Revision 1 should be sent by Feb. 17 to email@example.com.", "label": 1}
{"text": "The debate on cybersecurity has produced a sideshow centered around the belief that added security means a reduction in privacy.\nSuch views are nonsense. Quite simply, digital privacy cannot exist without cybersecurity. Weak security equals weak privacy. Want better privacy? Raise your security game to prevent hackers from stealing private data. Let the experts from the private sector and government communicate with each other so when they see threats, they can alert others and work together to create a solution.\nDespite this common-sense connection, a seemingly never-ending debate drags on about how our nation can improve its cybersecurity. There is lots of talk, but little action to support privacy's enabler.\nThat could change if Congress passes The Cyber Intelligence Sharing and Protection Act (CISPA) and the President signs it into law. CISPA passed the House (248-168) about a year ago, and since then has been the subject of considerable discussion, with no discernible progress.\nCritics don't like the fact that CISPA enables information sharing between the federal government and the private sector in order to prevent cyberattacks and to pursue cybercriminals, hackers, fraudsters and others intent on harm. As they see it, such cooperation constitutes a potential privacy invasion that is so egregious as to merit no further consideration.\nTheir concerns are, no doubt, well intended. But they are also out of touch with reality and risk unintended consequences that only serve to allow cybercriminals to operate with impunity.\nThe breadth and scale of the threat of cyberattacks on our nation's critical infrastructure -- financial institutions, electric and water utilities and air traffic control systems, to name just a few -- to say nothing of consumers' personal data, is no longer in debate. Meanwhile, the avenues and opportunities by which hackers have to penetrate our networks are growing hand in hand with our increasingly mobile communications ecosystem. On the consumer side, for example, a recent study concludes more than 40% of U.S. smartphone users will click on unsafe links this year, potentially spreading malware that can steal data and dollars to their friends, family and colleagues.\nAttempts to breach networks happens tens of thousands a time a day, every day. Cybercriminals are smart, nimble and unencumbered by regulations. There's no penalty, and comparatively little risk, for failed attempts. That is, they only have to succeed once, whereas we -- the defenders -- have to prevail every time.\nDoes that sound like a dynamic we would be well served to leave unaddressed? Should we keep our fingers crossed and hope things go OK? Or should we work together to provide the nation with the most effective reality-based cybersecurity we can achieve?\nClearly, the latter is what we need: a cooperative approach, one that allows for lawful sharing of information on where, how, from whom, and in what guise cyberattacks and other forms of cybercrime are emerging so defenses can be prepared.", "label": 1}
{"text": "A type of port forwarding where outbound traffic on predetermined ports sends inbound traffic to specific incoming ports. Port triggering \"triggers\" an open incoming port when a client on the local network makes an outgoing connection to a predetermined port on a server. Port Triggering is more secure than port forwarding, because the incoming ports are not open all the time, they are open only when a program is actively using the trigger port. One major advantage of port triggering is that it allows computers behind a NAT-enabled router to provide services which would normally require a static host (one with an unchanging network address). The disadvantage of port forwarding is that it only allows one client on the network to use a particular service that occupies a particular port.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "What Is Virtualization?\nVirtualization is defined as creating something virtually rather than actually. It's a vague definition for a vague term. Virtualization, at its most basic level, removes physical barriers from the requirements of IT infrastructure, allowing for more flexibility and agility. For IT in midsize businesses, it can make a significant difference in the overall cost of IT infrastructure. Jumping on the virtualization bandwagon, however, without determining where and how virtualization can work to improve your IT, can be dangerous.\nWhat is Virtualization and How Does It Differ from Cloud Technology?\nVirtualization is a companion buzzword to cloud technology, but virtualization can encompass more than just cloud services. Cloud services are only one component of virtualization; a variety of additional resources can be virtualized.\nSo, what is virtualization? Virtualization is a way of meeting goals to improve efficiency while enhancing the scalability of an operation. Any component of IT can be virtualized, from application and operating systems to networks and data storage to client services and development.\nWhy Consider Virtualization?\nMaintaining servers is costly and does not offer any scalability. One of the most popular forms of virtualization is server virtualization, which allows you to more efficiently manage your network without falling victim to \"server sprawl.\"\nReduced Energy Consumption\nThe cost of keeping servers operational and cool is often a major hidden cost of IT, one that virtualization can eliminate or significantly reduce.\nImproved Backup & Recovery\nRather than having to back up, restore, and recover individual machines, virtual machines can be rapidly recovered and will not be impacted by hardware failures.\nSupporting IT Infrastructure\nWhether you have older applications you cannot afford to replace or you are a Mac-driven office in need of an occasional Windows environment, virtualization can provide you with an affordable solution that doesn't interfere with your ability to move forward.\nVirtualization can help IT in midsize business reduce costs and improve service levels, but there are factors that must be considered. Virtualization is still relatively new, so there are risks that come with shifting away from a physical environment that you control. If your business will have to invest in high-priced software or significant storage space, you will need to consider ROI and determine whether or not the cost is recoverable.\nRegardless of what area or component you are virtualizing, from software or hardware to server optimization and integration and data migration, start by evaluating the benefits of virtualization. Analyze your current operation and identify where virtualization might create cost savings. Research the available virtualization software platforms and services to determine which best suits your needs, evaluating the software against your use cases. Finally, migrate to your virtualized environment. There are migration solutions available to make the transition easier, and developing a project plan will ensure that all the necessary steps are controlled along the way.\nThis post was written as part of the IBM for Midsize Business program, which provides midsize businesses with the tools, expertise and solutions they need to become engines of a smarter planet. Like us on Facebook. Follow us on Twitter.", "label": 1}
{"text": "The frigid waters of the dark and briny deep may first appear uncharted, but in reality the data is out there, scattered across public sources. Getting three dimensional data from a few leagues of the sea can be a nightmare for researchers and industry professionals alike. The 3 petabytes of public ocean data out there is disconnected, often archived and never used again. Making even a fraction of that more accessible offers a huge value to anyone looking for it.\nOn top of that, once you find the data it is still difficult to work with. Mariexplore, a Tallinn/San Francisco based company estimates now that 80% of exploration time is spent on data processing. Marinexplore wants to cut that number fivefold. To do so, they have brought together a huge chunk of the publicly available data and release it into an easily tappable resource, while simultaneously building a community around their data.\n\"The problem with all of this is that the ocean and seas are very big, and no one can own all of the hardware in the world to gather it,\" Marinexplore founder and CEO Rainer Sternfeld explains.\nAt launch, Marinexplore offers more than 350 million measurements from 23 000 devices. These data are provided by public sources like NOAA stations, GTS buoys, oil platforms and drifters, JCOMMOPS Argo Program, Rutgers University gliders, Liquid Robotics PacX Challenge data, and others.\n\"The first problem we have solved is that we have created a tool that enables to search, find, and export ocean data faster and easier than any other tool out there,\" says Sternfeld. \"The main thing is that we want to become the number one footprint on the web for oceanographic data, bringing together all the public data.\"\nIn use, Marinexplore has put together a very simple interface built on top of Google Maps, where there they offer a three dimensional data structure where the data is positioned in geo-space. Scientists and industry professionals can easily grab chunks of three dimensional data without having to find and process the data themselves.\nAccessing the data is free, and in the beginning Sternfeld predicts that their customers will be oceanographers to reseachers, to geo-physicists, marine biologists, and many others in the public and private domain. On the private side, he predicts shipping, insurance, and stuff like that will also find their service useful.\nTo monetize that the company is looking into building data streaming products. They are building an API where you would be able to define an area in the seas and then only get that specific perimeter from that specific area. Potential customers include weather forecasting systems, shipping companies, and others who would like to predict better current models, risk models, and so forth.\n\"Data itself doesn't mean anything, right?\" Sternfeld says. \"Our intention is to build on top of machine learning systems so that we can actually provide forecasting products eventually. But for right now, we are providing very simple access to that data in an aggregated way.\"\nThe company has moved part of its operations to Silicon Valley, which initially seemed strange because the startup seems like it doesn't need to plug into the same ecosystem as your average social app. But Sternfeld tells me there is actually a lot of oceanographic talent to draw from in the Valley, and one way or another they needed to be on the east or west coast where the ocean community lives. Marinexplore is building a technical team of ocean modeling engineers, 3d visualization guys, and so forth. In the Valley, the company then has access to talent from the Jet Propulsion Lab, as well as the Google Earth guys that have worked with these challenges before.\nThe startup is definitely interesting for its societal value to the oceanographic community, and it will be interesting to see how Marinexplore will be able to expand as a central hub for ocean data, as well as connect knowledge between industry professionals and scientists. When talking to Sternfeld, he called themselves almost a git-hub for ocean data, which appears to be an apt metaphor of what they're trying to do. How many other industries could benefit from a central resource and community around data?", "label": 1}
{"text": "Parents everywhere should be concerned about the real dangers of Facebook and how kids are increasingly opting to connect with friends to perpetuate sharing, whatever kids like to share, with friends and possibly unknown users. In addition, these connected kids are becoming younger, and while the age limit for Facebook is 13; your child could be lying about their age to create an account and taking part in conversations with older kids, possibly sharing and receiving information about inappropriate subjects. At the same time, parents are concerned about openly hovering or monitoring kid’s activity, wanting to give them some sort of limited autonomy to be connected with their peers, realizing it is an important part of growing up. See (Should kids be allowed on Facebook?)\nWhat are Parents to Do?\nMany parents are reluctant to become a friend of children on Facebook. Kids know parents are monitoring, so do their friends; this creates a point of contention that some parents may want to avoid. The answer may lie in a company named ZoneAlarm. Created to protect PC’s from viruses, spyware, hackers and identity theft with its Check Point Software Technology, the company created SocialGuard, a way for parents to monitor kid’s activity on Facebook without them knowing they are being monitored. Parents do not have to have a Facebook account to monitor children, just the software from SocialGuard which scans millions of records using an algorithm and sends a message when certain pre-determined criteria for threats appear. It alerts parents to red-flag data relinquishing the need for inspection of all data on the account.\n- Cyberbulling: Detects inappropriate language in private messages, wall posts, and status updates\n- Strangers: Sends an alert when a stranger may be trying to interact with your child on Facebook\n- Age Concerns: identifies and Flags friends who are much older than they claim to be, or someone who may be pretending to be a kid\n- Dangerous Links: Checks and finds dangerous links in messages, wall posts, or status updates. Protects against viruses and identity theft\n- Hacked Account: Monitors your Childs account for signs it has been hacked\n- Inappropriate Content: Checks for content that has been posted related to sex, violence, drugs and more\nVideo: How to use SocialGuard\nSocialGuard is not free and is listed at $19.95 per year (with a free trial), downloadable on their website. It will handle up to 5 Facebook accounts.", "label": 1}
{"text": "DDoS attack though used criminally but is an intelligent technology. It has evolved with time and now follows the domain name and the IP address it points to. It is somehow a layered threat and hinders the access to the site in following different ways\n- Vulnerable Zoombies Attacks:\nA DDoS attack directs hundreds or even thousands of compromised \"zombie\" hosts against a single target. These zombies are unintentionally recruited from the millions of unprotected computers accessing the Internet through high-bandwidth or always-on connections. By planting \"sleeper\" codes on these machines, hackers can quickly build a legion of zombies, all waiting for the command to launch a DDoS attack. With enough zombie hosts participating, the volume of an attack can be astounding. DDoS Threats Over the last few years, attackers have refined their methods. As developers make software more reliable and more resilient to DoS, the attack vectors have changed to target hard-to-secure parts of a service.\n- Bandwidth and Traffic Bottlenecks:\nA server that has a bandwidth of 100 Mbit/s can easily be attacked by a DoS attack with a machine that has a little more bandwidth than this which will make it loss packets and finally will make it unusable. This creates bottle necks for other site surfers and will make the server itself dormant.\n- SYN Attacks:\nSYN (synchronous) stacks are becoming frequent nowadays. This attack can prevent access to your mailbox, WWW and other critical servers. The SYN attack (sometimes referred as SYN flood attack) sends TCP connections requests faster than a machine can process them. The SYN attacker creates a random source address for each packet and sets the SYN flag in each packet. Victim responds to spoofed IP address, then waits for confirmation that never arrives. Victim's connection table fills up waiting for replies. After table fills up, all new connections and legitimate users are ignored. Once attacker stops flooding server, it usually goes back to normal state (SYN floods rarely crash servers).\n- Making Applications Flawed:\nDDoS attacks do not only attack over the network layer but the their inscrutable nature is that they even make the applications malfunctioning. This might also be achieved by deploying load-intensive WebPages", "label": 1}
{"text": "- Apple Announces OS X Mavericks, The New Operating System For Mac Computers\n- 9 Rock Stars Who Toil In The Shadows For Apple Security\n- Typing these 8 characters in Mac OS X Mo\n- Siri And Apple Maps Might Be Coming To Your Mac Next Year\n- The New Angry Birds Game Shows How Much The World Has Changed For Apple And Microsoft\n- 11 Basic Steps You Should Take To Keep Your Computer Safe\n- Why Apple Won't Merge OS X And iOS In The Near Future\n- Before Mac OS X, There Was OS 1 Through 9: A History of Apple's Operating System\n- Apple's Mountain Lion Operating System For Macs Is Coming Really Soon!\n- Apple Is Working On 'Powerful Sharing Of Photos' In Its iPhone Photos App\nMac OS X is a series of Unix-based operating systems and graphical user interfaces developed, marketed, and sold by Apple Inc. Since 2002, Mac OS X has been included with all new Macintosh computer systems. It is the successor to Mac OS 9, released in 1999, the final release of the \"classic\" Mac OS, which had been Apple's primary operating system since 1984.\nMac OS X, whose X is the Roman numeral for 10 and is a prominent part of its brand identity, is a Unix-based graphical operating system, built on technologies developed at NeXT between the second half of the 1980s and Apple's purchase of the company in late 1996. From its sixth release, Mac OS X v10.5 \"Leopard\" and onward, every release of Mac OS X gained UNIX 03 certification while running on Intel processors.\nThe first version released was Mac OS X Server 1.0 in 1999, and a desktop-oriented version, Mac OS X v10.0 \"Cheetah\" followed on March 24, 2001. Releases of Mac OS X are named after big cats: for example, Mac OS X v10.6 is usually referred to by Apple and users as \"Snow Leopard\". The server edition, Mac OS X Server, is architecturally identical to its desktop counterpart, and includes tools to facilitate management of workgroups of Mac OS X machines, and to provide access to network services.\nThese tools include a mail transfer agent, an LDAP server, a domain name server, and others. It is pre-loaded on Apple's Xserve server hardware, but can be run on almost all of Apple's current selling computer models.\nApple also produces specialized versions of Mac OS X for use on its consumer devices. iOS, which is based on Mac OS X, runs on the iPhone, iPod Touch, iPad, and the 2nd generation Apple TV. An unnamed variant of Mac OS X powered the 1st generation Apple TV.\nMac OS X is based upon the Mach kernel. Certain parts from FreeBSD's and NetBSD's implementation of Unix were incorporated in NeXTSTEP, the core of Mac OS X. NeXTSTEP was the object-oriented operating system developed by Steve Jobs' company NeXT after he left Apple in 1985. While Jobs was away from Apple, Apple tried to create a \"next-generation\" OS through the Taligent, Copland and Gershwin projects, with little success.\nEventually, NeXT's OS, then called OPENSTEP, was selected to be the basis for Apple's next OS, and Apple purchased NeXT outright. Steve Jobs returned to Apple as interim CEO, and later became CEO, shepherding the transformation of the programmer-friendly OPENSTEP into a system that would be adopted by Apple's primary market of home users and creative professionals. The project was first known as Rhapsody and was later renamed to Mac OS X.\nMac OS X Server 1.x, was incompatible with software designed for the original Mac OS and had no support for Apple's own IEEE 1394 interface (FireWire). Mac OS X 10.x included more backward compatibility and functionality by including the Carbon API as well as FireWire support. As the operating system evolved, it moved away from the legacy Mac OS to an emphasis on new \"digital lifestyle\" applications such as the iLife suite, enhanced business applications (iWork), and integrated home entertainment (the Front Row media center).\nEach version also included modifications to the general interface, such as the brushed metal appearance added in version 10.3, the non-pinstriped titlebar appearance in version 10.4, and in 10.5 the removal of the previous brushed metal styles in favor of the \"Unified\" gradient window style.\nMac OS X is the tenth major version of Apple's operating system for Macintosh computers. Previous Macintosh operating systems were named using Arabic numerals, e.g. Mac OS 8 and Mac OS 9. The letter X in Mac OS X's name refers to the number 10, a Roman numeral. It is therefore correctly pronounced \"ten\" ( /ˈtɛn/) in this context. However, due to the tenth version being the first to be based on Unix origins, and a reason for the Roman numeral to be used for the number 10 in its honour, a common pronunciation is \"X\" ( /ˈɛks/).\nMac OS X's core is a POSIX compliant operating system (OS) built on top of the XNU kernel, with standard Unix facilities available from the command line interface. Apple has released this family of software as a free and open source operating system named Darwin. On top of Darwin, Apple layered a number of components, including the Aqua interface and the Finder, to complete the GUI-based operating system which is Mac OS X.\nMac OS X introduced a number of new capabilities to provide a more stable and reliable platform than its predecessor, Mac OS 9. For example, pre-emptive multitasking and memory protection improved the system's ability to run multiple applications simultaneously without them interrupting or corrupting each other.\nMany aspects of Mac OS X's architecture are derived from OPENSTEP, which was designed to be portable, to ease the transition from one platform to another. For example, NeXTSTEP was ported from the original 68k-based NeXT workstations to x86 and other architectures before NeXT was purchased by Apple, and OPENSTEP was later ported to the PowerPC architecture as part of the Rhapsody project.\nThe most visible change was the Aqua theme. The use of soft edges, translucent colors, and pinstripes – similar to the hardware design of the first iMacs – brought more texture and color to the user interface when compared to what OS 9 and OS X Server 1.0's \"Platinum\" appearance had offered. According to John Siracusa, an editor of Ars Technica, the introduction of Aqua and its departure from the then conventional look \"hit like a ton of bricks.\"Bruce Tognazzini (who founded the original Apple Human Interface Group) said that the Aqua interface in Mac OS X v10.0 represented a step backwards in usability compared with the original Mac OS interface. Third-party developers started producing skins for customizable applications and other operating systems which mimicked the Aqua appearance. To some extent, Apple has used the successful transition to this new design as leverage, at various times threatening legal action against people who make or distribute software with an interface the company claims is derived from its copyrighted design.\nMac OS X architecture implements a layered design. The layered frameworks aid rapid development of applications by providing existing code for common tasks.\nMac OS X includes its own software development tools, most prominently an integrated development environment called Xcode. Xcode provides interfaces to compilers that support several programming languages including C, C++, Objective-C, and Java. For the Apple–Intel transition, it was modified so that developers could build their applications as a universal binary, which provides compatibility with both the Intel-based and PowerPC-based Macintosh lines.\nThe Darwin sub-system in Mac OS X is in charge of managing the filesystem, which includes the Unix permissions layer. In 2003 and 2005, two Macworld editors expressed criticism of the permission scheme; Ted Landau called misconfigured permissions \"the most common frustration\" in Mac OS X, while Rob Griffiths suggested that some users may even have to reset permissions every day, a process which can take up to 15 minutes. More recently, another Macworld editor, Dan Frakes, called the procedure of repairing permissions vastly overused. He argues that Mac OS X typically handles permissions properly without user interference, and resetting permissions should just be tried when problems emerge.\nAs of September 2010, Mac OS X is the second most active general-purpose client operating system in use on the World Wide Web, after Microsoft Windows, with an 8.3% usage share according to statistics compiled by W3Counter. It is the most successful Unix-like desktop operating system on the web, estimated at over 5 times the usage of Linux (which has 1.5%).\nEighteen languages are available as the \"base\" language (that which is used for sub-user environments, such as the user login screen) at the first screen of the installation DVD. All of the eighteen user languages for the system menus, messages, and other functions are installed by default and can be chosen from the System Preferences. As of Mac OS X Snow Leopard, the languages are English, Japanese, French, German, Spanish, Italian, Dutch, Swedish, Danish, Norwegian, Finnish, Traditional Chinese, Simplified Chinese, Korean, Brazilian Portuguese, European Portuguese, Russian, and Polish. Input methods for typing in dozens of scripts can be chosen independently of the system language.\nOne of the major differences between the previous versions of Mac OS and OS X was the addition of the Aqua GUI, a graphical user interface with water-like elements. Every window element, text, graphic, or widget is drawn on-screen using anti-aliasing technology. ColorSync, a technology introduced many years before, was improved and built into the core drawing engine, to provide color matching for printing and multimedia professionals. Also, drop shadows were added around windows and isolated text elements to provide a sense of depth. New interface elements were integrated, including sheets (document modal dialog boxes attached to specific windows) and drawers.\nApple has continued to change aspects of the OS X appearance and design, particularly with tweaks to the appearance of windows and the menu bar. One example of a UI behavioral change is that previewed video and audio files no longer have progress bars in column view; instead, they have mouse-over start and stop buttons as of 10.5.\nThe human interface guidelines published by Apple for Mac OS X are followed by many applications, giving them consistent user interface and keyboard shortcuts. In addition, new services for applications are included, which include spelling and grammar checkers, special characters palette, color picker, font chooser and dictionary; these global features are present in every Cocoa application, adding consistency.\nThe graphics system OpenGL composites windows onto the screen to allow hardware-accelerated drawing. This technology, introduced in version 10.2, is called Quartz Extreme, a component of Quartz. Quartz's internal imaging model correlates well with the Portable Document Format (PDF) imaging model, making it easy to output PDF to multiple devices. As a side result, PDF viewing and creating PDF documents from any application are built-in features.\nIn version 10.3, Apple added Exposé, a feature which includes three functions to help accessibility between windows and desktop. Its functions are to instantly display all open windows as thumbnails for easy navigation to different tasks, display all open windows as thumbnails from the current application, and hide all windows to access the desktop. Also, FileVault was introduced, which is an optional encryption of the user's files with Advanced Encryption Standard (AES-128).\nFeatures introduced in version 10.4 include Automator, an application designed to create an automatic workflow for different tasks; Dashboard, a full-screen group of small applications called desktop widgets that can be called up and dismissed in one keystroke; and Front Row, a media viewer interface accessed by the Apple Remote. Moreover, the Sync Services were included, which is a system that allows applications to access a centralized extensible database for various elements of user data, including calendar and contact items. The operating system then managed conflicting edits and data consistency.\nAs of version 10.5, all system icons are scalable up to 512×512 pixels, to accommodate various places where they appear in larger size, including for example the Cover Flow view, a three-dimensional graphical user interface included with iTunes, the Finder, and other Apple products for visually skimming through files and digital media libraries via cover artwork. This version includes Spaces, a virtual desktop implementation which enables the user to have more than one desktop and display them in an Exposé-like interface. Mac OS X v10.5 includes an automatic backup technology called Time Machine, which provides the ability to view and restore previous versions of files and application data; and Screen Sharing was built in for the first time.\nFinder is a file browser allowing quick access to all areas of the computer, which has been modified throughout subsequent releases of Mac OS X. Quick Look is part of Mac OS X Leopard's Finder. It allows for dynamic previews of files, including videos and multi-page documents, without opening their parent applications. Spotlight search technology, which is integrated into the Finder since Mac OS X Tiger, allows rapid real-time searches of data files; mail messages; photos; and other information based on item properties (meta data) and/or content. Mac OS X makes use of a Dock, which holds file and folder shortcuts as well as minimized windows. Mac OS X Architecture implements a layered framework. The layered framework aids rapid development of applications by providing existing code for common tasks.\nVersion 10.0: \"Cheetah\"\nOn March 24, 2001, Apple released Mac OS X v10.0 (internally codenamed Cheetah). The initial version was slow, incomplete, and had very few applications available at the time of its launch, mostly from independent developers. While many critics suggested that the operating system was not ready for mainstream adoption, they recognized the importance of its initial launch as a base on which to improve. Simply releasing Mac OS X was received by the Macintosh community as a great accomplishment, for attempts to completely overhaul the Mac OS had been underway since 1996, and delayed by countless setbacks. Following some bug fixes, kernel panics became much less frequent.\nVersion 10.1: \"Puma\"\nLater that year on September 25, 2001, Mac OS X v10.1 (internally codenamed Puma) was released. It had better performance and provided missing features, such as DVD playback. Apple released 10.1 as a free upgrade CD for 10.0 users, in addition to the US$129 boxed version for people running Mac OS 9. It was discovered that the upgrade CDs were full install CDs that could be used with Mac OS 9 systems by removing a specific file; Apple later re-released the CDs in an actual stripped-down format that did not facilitate installation on such systems. On January 7, 2002, Apple announced that Mac OS X was to be the default operating system for all Macintosh products by the end of that month.\nVersion 10.2: \"Jaguar\"\nOn August 23, 2002, Apple followed up with Mac OS X v10.2 \"Jaguar\", the first release to use its code name as part of the branding. It brought great performance enhancements, a sleeker look, and many powerful enhancements (over 150, according to Apple ), including Quartz Extreme for compositing graphics directly on an ATI Radeon or Nvidia GeForce2 MX AGP-based video card with at least 16 MB of VRAM, a system-wide repository for contact information in the new Address Book, and an instant messaging client named iChat. The Happy Mac which had appeared during the Mac OS startup sequence for almost 18 years was replaced with a large grey Apple logo with the introduction of Mac OS X v10.2.\nVersion 10.3: \"Panther\"\nMac OS X v10.3 \"Panther\" was released on October 24, 2003. In addition to providing much improved performance, it also incorporated the most extensive update yet to the user interface. Panther included as many or more new features as Jaguar had the year before, including an updated Finder, incorporating a brushed-metal interface, Fast user switching, Exposé (Window manager), FileVault, Safari, iChat AV (which added videoconferencing features to iChat), improved Portable Document Format (PDF) rendering and much greater Microsoft Windows interoperability. Support for some early G3 computers such as \"beige\" Power Macs and \"WallStreet\" PowerBooks was discontinued.\nVersion 10.4: \"Tiger\"\nMac OS X v10.4 \"Tiger\" was released on April 29, 2005. Apple stated that Tiger contained more than 150+ new features. As with Panther, certain older machines were no longer supported; Tiger requires a Mac with a built-in FireWire port. Among the new features, Tiger introduced Spotlight, Dashboard, Smart Folders, updated Mail program with Smart Mailboxes, QuickTime 7, Safari 2, Automator, VoiceOver, Core Image and Core Video. The initial release of the Apple TV used a modified version of Tiger with a different graphical interface and fewer applications and services. On January 10, 2006, Apple released the first Intel-based Macs along with the 10.4.4 update to Tiger. This operating system functioned identically on the PowerPC-based Macs and the new Intel-based machines, with the exception of the Intel release dropping support for the Classic environment. Only PowerPC Macs can be booted from retail copies of the Tiger client DVD, but there is a Universal DVD of Tiger Server 10.4.7 (8K1079) that can boot both PowerPC and Intel Macs.\nVersion 10.5: \"Leopard\"\nMac OS X v10.5 \"Leopard\" was released on October 26, 2007. It was called by Apple \"the largest update of Mac OS X\". It brought more than 300 new features. Leopard supports both PowerPC- and Intel x86-based Macintosh computers; support for the G3 processor was dropped and the G4 processor required a minimum clock rate of 867 MHz, and at least 512 MB of RAM to be installed. The single DVD works for all supported Macs (including 64-bit machines).\nNew features include a new look, an updated Finder, Time Machine, Spaces, Boot Camp pre-installed, full support for 64-bit applications (including graphical applications), new features in Mail and iChat, and a number of new security features. Leopard is an Open Brand UNIX 03 registered product on the Intel platform. It was also the first BSD-based OS to receive UNIX 03 certification. Leopard dropped support for the Classic Environment and all Classic applications. It was the final version of Mac OS X to support the PowerPC architecture.\nVersion 10.6: \"Snow Leopard\"\nMac OS X v10.6 \"Snow Leopard\" was released on August 28, 2009. Rather than delivering big changes to the appearance and end user functionality like the previous releases of Mac OS X, Snow Leopard focuses on \"under the hood\" changes, increasing the performance, efficiency, and stability of the operating system. For most users, the most noticeable changes are: the disk space that the operating system frees up after a clean install compared to Mac OS X 10.5 Leopard, a more responsive Finder rewritten in Cocoa, faster Time Machine backups, more reliable and user friendly disk ejects, a more powerful version of the Preview application, as well as a faster Safari web browser.\nMac OS X v10.6 also features Microsoft Exchange Server support for Mail, iCal, and Address Book, new 64-bit technology capable of supporting greater amounts of RAM, an all new QuickTime X with a refreshed user interface and more functionality that used to be only available to QuickTime Pro owners.\nBack-end platform changes include improved support for multi-core processors through Grand Central Dispatch which attempts to ease the development of applications with multi-core support, and thus improve their CPU utilization. It used to be that developers needed to code their programs in such a way that their software would explicitly take advantage of the multiple cores, which could easily become a tedious and troublesome task, especially in complex software. It also includes advanced GPU performance with OpenCL (a cross platform open standard for GPGPU distinct from CUDA, Dx11 Compute Shader or STREAM) by providing support to offload work normally only destined for a CPU to the graphic card's GPU. This can be especially useful in tasks that can be heavily parallelized.\nSnow Leopard only supports machines with Intel CPUs, requires at least 1 GB of RAM, and drops default support for applications built for the PowerPC architecture (Rosetta can be installed as an additional component to retain support for PowerPC-only applications).\nVersion 10.7: \"Lion\"\nA preview of Mac OS X v10.7 \"Lion\" was publicly unveiled at Apple's \"Back to the Mac\" event on October 20, 2010. It will include support for the Mac App Store, and will bring many other developments made in Apple's iOS, such as an easily-navigable display of installed applications, to the Mac. It is scheduled to be released in the (Northern Hemisphere) summer of 2011.\nChanges made to the GUI (Graphical User Interface) include the Launchpad (similar to the home screen of iOS devices), auto-hiding scrollbars that only appear when they are being used, and Mission Control, which unifies Exposé, Spaces, Dashboard, and full-screen applications within a single interface. Apple also made changes to applications: they resume in the same state as they were before they were closed (similar to iOS). Because of this, the Dock no longer visually indicates whether an app is currently running. In addition to this, documents auto-save by default so users don't have to worry about manually managing their documents.\nA developer preview was released to developers on February 24, 2011.\nThis page has been adapted from Wikipedia on April 20th, 2011", "label": 1}
{"text": "Social Networking Risks Reduced by Frequency, Vigilance\nHow many social networking accounts do you have? Do you access them often? Have you set up profiles on multiple sites and then forgotten about them, or left others to wither on the vine after using them frequently for a time?\nWhile it may be impossible to completely prevent attackers from hijacking your accounts and attempting to aim threats at your friends and colleagues, managing your social networking accounts on a more active basis and enlisting all of the security and privacy tools that the sites offer can dramatically reduce the risk of such incidents, experts with Symantec maintain.\nThis advice may seem obvious, but, with the proliferation of so many social networking applications, let's face it, it's hard not to sign up for some sites, connect with people you know and then fall out of love with the apps.\nThe rise of multifarious social engineering attacks carried out over social networks has created a whole new world of risk for users of the systems, and all those that they connect with over the sites, as attackers have created a number of different means to abuse trust relationships formed by people to build targeted campaigns.\nWho among us hasn't received a malware or phishing ploy from the account of a trusted contact on Twitter (yesterday), or received messages asking them to check out videos of themselves posted on Facebook (every day)? Certainly most users of these wildly popular sites known this has become the reality.\nOne of the biggest drivers of risk is people's tendency to abandon accounts, allowing attackers to take them over and threaten all of their contacts without users' knowledge, or for users to fail to utilize key applications security and privacy settings that will make it harder for scammers and cyber-criminals to hijack their online personas, the researchers contend.\n\"These sorts of problems often happen when social networking profiles don't have their privacy settings administered properly. It could also be a problem with the social network service, which might not have maintained proper privacy regulations on behalf of their participants,\" said Symantec expert Vivian Ho in a recent blog post. \"Spammers can get onto these social network sites and collect user information, such as e-mail addresses or personal blog URLs, for example, and they can collect additional information from friends' profiles if those profiles are also set to be public.\"\nWhen people no longer actively manage their accounts, not only does it make it easier for attackers to assume their identities, but it allows for such attacks to carry on far longer, until someone finally clues the involved user into the fact that someone may be manipulating their reputation, and contacts.\nIf you decide to stop using a particular service, it's better to simply close your account, then it is to merely leave it to fester and become a new point of risk for your contacts. And enlisting the privacy tools of sites like Facebook, in particular, can create an extra hurdle for scammers that may encourage them to move on to the near next target.\nFor active social networking users, it is vital to carefully consider every message or invitation they receive before opening its contents (think shortened URL) or clicking \"yes\" to sign-up for a group or application that is being advertised. If anything makes you wonder, ad maybe even f it doesn't, reach out to the sender to ensure that the message or invite is legit, or do some background research on your own.\nA little vigilance can go a long way.\nNow, about that targeted spear phishing e-mail you just received from your boss on your work e-mail account...\nFollow eWeek Security Watch on Twitter at: eWeekSecWatch.\nMatt Hines has been following the IT industry for over a decade as a reporter and blogger, and has been specifically focused on the security space since 2003, including a previous stint writing for eWeek and contributing to the Security Watch blog. Hines is currently employed as marketing communications manager at Core Security Technologies, a Boston-based maker of security testing software. The views expressed herein do not necessarily represent the views of Core Security, and neither the company, nor its products and services will be actively discussed in the blog. Please send news, research or tips to SecurityWatchBlog@gmail.com.", "label": 1}
{"text": "Is It Safe to Shop on the Internet?\nWhen you shop on the Internet, you have the same concerns as you do when you use a\ncatalog to shop over the telephone.\n- Impersonation: Is the business that takes receiving my order authentic?\n- Eavesdropping: Could someone \"listen in\" to my order and steal my credit card\nIn the real world, you often give your credit card to cashiers or waiters, and you give\nout your account number over the phone when placing an order. Using your credit card\nnumber on the Internet is no more dangerous than these practices. In fact, it is often\nmore secure to give out your account number over the Internet, because many sites work\nwith your browser software to encode your transaction so if outside parties intercept it,\nthey won't be able to read it.\nWe counter security threats with a technology called SSL (Secure Sockets Layer). SSL is\na set of rules followed by computers connected to the Internet. These rules include\nencryption, which guards against eavesdropping; data integrity, which assures that your\ncommunications aren't tampered with during transmission; and authentication, which\nverifies that the party actually receiving your communication is who it claims to be.\nTo check a site's security status, look at the site's URL in your browser window. An\n\"s\" added to the familiar \"http\" (to make \"https\") indicates\nthat SSL is in effect. In Netscape Navigator 3.0 and earlier, the broken key symbol in the\nlower-left corner of your browser window becomes solid when you are in secure mode. In\nNetscape Communicator 4.0 and 4.5, the padlock symbol in the corner, usually open, is\nclosed in secure mode. In Internet Explorer 4.0, a closed padlock appears when you are in\nIf you're about to send information to a site that's not using SSL, your browser will\nwarn you first.\nSSL protects your communications during transmission. However, you must also protect\nyourself by dealing only with Internet companies you are certain you can trust, just as\nyou deal only with merchants who won't share your credit card numbers with others.\nThe Federal Trade Commission is increasing its surveillance of Internet fraud, and the\nNational Consumers League has created the Internet\nFraud Watch, an online service for reporting frauds.\nAre Internet Banking and Investment Transactions Safe?\nOnline banking and investment services, and your browser, also rely on encryption to\nprotect the information in your transactions. Before your computer transmits your\ninformation to an online financial service, the information is encrypted - turned into\ncode. When the information reaches its destination, it is decoded. Anyone who intercepts\nthe information during transmission receives only gibberish. Online financial services\nalso encrypt all information they transmit back to you.", "label": 1}
{"text": "Thousands of files are stolen from the Pentagon. Major oil companies have gigabytes of internal information taken. Cyber operators believed to be from Russia and China have even penetrated the U.S. power grid, and probably left programming behind that could shut down the electric grid. These examples alone should prove that cyber security is an issue of paramount concern for the U.S. While international cooperation may be of some use, the most effective way to contain this problem is to treat it as a national security issue.\n“Cyber-attack” is really a misnomer, since almost all of these operations are not offensive with the intent of causing direct damage to the nation or company. A more accurate term is “cyber-espionage,” since the ultimate goal of the state or non-state actors is almost always to obtain information. This also helps explain why a diplomatic, multi-nation solution will never occur.\nCyber-espionage is in the end a form of intelligence gathering, and almost every nation in the world is involved in it; not just the CIA and MI6. The French are notorious as industrial spies, stealing secrets from allies. China is infamous for its attempts to obtain U.S. military secrets, with some of their more notorious spies being naturalized U.S. citizens. In fact, most of the world’s governments and many non-state actors are believed to be collecting intelligence from within the U.S.\nChina is perhaps the most obvious example of one country using its cyber capabilities to obtain intelligence. The number of cyber-espionage operations believed to have been committed by the PRC is pretty astounding, with the funding and interest in the cyber world to back up this claim. Despite this, China continues to deny that it is involved in this type of espionage. The most obvious reason for this is that no one can be 100% sure of their involvement. The use of complicated software and proxy servers means that it is impossible to simply trace a hack back to an individual computer in a Chinese military base. The U.S. and others are not going to risk alienating a very important nation over stolen files that they cannot prove were taken by the PRC.\nInternational cooperation, no matter how well intentioned, could only ever be a small part of the solution. The most obvious example might be in combating non-state actors. The reason is that each state has a vested interest in not letting non-state actors (terrorists, militias, etc.) have a capability to harm them. The problem, however, is the same as in intelligence sharing: one does not know where the level of information shared ends.\nIf one country finds a hole in security that someone else has been exploiting, what would stop them from protecting themselves and then using this hole in security for their own purposes? Other than the PRC, numerous nations, including France and Russia, also have impressive cyber capabilities, and their documented history of espionage should make it clear that they are most likely willing to use cyber espionage against the U.S. as well.\nThe solution lies in improving the capabilities of the U.S. national security apparatus to prevent and defeat attempts at penetrating public and private networks. This is a very general statement, and the truth is that no one is completely sure how this can be done.\nA good place to start, however, may be looking across the pond. In 2010, the United Kingdom opened their Cyber Security Operations Centre (CSOC), a multi-agency organization working within GCHQ (the UK equivalent to the National Security Agency). Their goal is to coordinate efforts in order to find and neutralize threats and better prepare for future cyber operations.\nIn the U.S., there is the military’s cyber command, the NSA, the Department of Homeland Security, and the FBI are all working on cyber operations. While there are no public results from CSOC to determine if this effort at cooperation in the UK has been successful, perhaps the U.S. should consider a similar path in order to combine the information and methods used to protect military, public, and private computer networks. While international cooperation is ideal, the U.S. cannot simply place all her trust in foreign nations with a history of spying, and must take measures to defend her cyberspace from both friend and foe alike.\nPhoto Credit: Wikimedia Commons", "label": 1}
{"text": "Securing Data Access\nMost ASP.NET Web applications involve data access. Many applications collect data to be stored in a database or file, and the data to be stored is often based on information that comes from users. Because the original data can come from untrusted sources, because the information is stored in a persistent format, and because you want to be sure that unauthorized users cannot access your data source directly, you need to pay particular attention to security issues surrounding data access. The information in this topic describes best practices that will help you improve the security of the data access in your ASP.NET Web application.\nWhile following coding and configuration best practices can improve the security of your application, it is also important that you continually keep your Web server up to date with the latest security updates for Microsoft Windows and Internet Information Services (IIS), as well as any security updates for Microsoft SQL Server or other data source software.\nMore detailed information about best practices for writing secure code and securing applications can be found in the book \"Writing Secure Code\" by Michael Howard and David LeBlanc, or through the guidance provided on the Microsoft Patterns and Practices Web site.\nThe following sections provide information on helping secure different aspects of data access.\nConnecting to a database requires a connection string. Because connection strings can contain sensitive data, you should follow these guidelines:\nDo not store connection strings in a page. For example, avoid setting connection strings as declarative properties of the SqlDataSource control or other data source controls. Instead, store connection strings in the site's Web.config file. For an example, see How To: Secure Connection Strings when Using Data Source Controls.\nDo not store connection strings as plain text. To help keep the connection to your database server secure, it is recommended that you encrypt connection string information in the configuration file by using protected configuration. For more information, see Encrypting Configuration Information Using Protected Configuration.\nConnecting to SQL Server using Integrated Security\nIf possible, connect to an instance of SQL Server using integrated security instead of using an explicit user name and password. This helps avoid the possibility of the connection string being compromised and your user ID and password being exposed.\nIt is recommended that you ensure that the identity of the process (for example, the application pool) that is running ASP.NET be the default process account or a restricted user account. For more information, see ASP.NET Impersonation.\nIn scenarios where different Web sites connect to different SQL Server databases, it might not be practical to use integrated security. For example, on Web-hosting sites, each customer is typically assigned a different SQL Server database, but all users use the Web server as anonymous users. In such cases, you need to use explicit credentials to connect to an instance of SQL Server. Be sure that you store the credentials in a secure manner, as described in this topic under Connection Strings.\nSQL Server Database Permissions\nIt is recommended that you assign the minimum privileges to the user ID that is used to connect to the SQL Server databases used in your application.\nRestrict SQL Operations\nData-bound controls can support a wide variety of data operations, including selecting, inserting, deleting, and updating records in data tables. It is recommended that you configure data controls to perform the minimum functionality that is required on a page or in your application. For example, if a control should not allow users to delete data, do not include a delete query with a data source control and do not enable deleting in the control.\nSQL Server Express Edition\nWhen a process attaches to a SQL Server Express Edition database (.mdf file), the process must have administrative permissions. In general, this makes SQL Server Express Edition databases impractical for production Web sites because the ASP.NET process does not (and should not) run with administrative privileges. Therefore, use SQL Server Express Edition databases only under the following circumstances:\nUse as a test database while developing your Web application. When you are ready to deploy your application, you can transfer the database from SQL Server Express Edition to a production instance of SQL Server.\nUse if you are running a Web site that can use impersonation and you can control the privileges of the impersonated user. In practice, this strategy is practical only if the application is running on a local area network (not a public Web site).\nStore the .mdf file in your site's App_Data folder, because the contents of the folder will not be returned to direct HTTP requests. You should also map the .mdf extension to ASP.NET in IIS and to the HttpForbiddenHandler handler in ASP.NET using the following element in the site's Web.config file:\n<httpHandlers> <add verb=\"*\" path=\"*.mdf\" type=\"System.Web.HttpForbiddenHandler\" /> </httpHandlers>\nFor information on how to map a file name extension to ASP.NET in IIS, see How to: Register HTTP Handlers.\nMicrosoft Access Databases\nMicrosoft Access databases (.mdb files) include fewer security features than SQL Server databases. Access databases are not recommended for production Web sites. However, if you have reason to use an .mdb file as part of your Web application, follow these guidelines:\nStore the .mdb file in your site's App_Data folder because the contents of the folder will not be returned to direct HTTP requests. You should also map the .mdb extension to ASP.NET in IIS and to the HttpForbiddenHandler handler in ASP.NET using the following element in the site's Web.config file:\n<httpHandlers> <add verb=\"*\" path=\"*.mdb\" type=\"System.Web.HttpForbiddenHandler\" /> </httpHandlers>\nFor information on how to map a file name extension to ASP.NET in IIS, see How to: Register HTTP Handlers.\nAdd appropriate permissions for the user account or accounts that will be reading and writing in the .mdb file. If the Web site supports anonymous access, this is generally the local ASPNET user account or the NETWORK SERVICE account. Because Access must create an .ldb file to support locking, the user account must have write permissions for the folder that contains the .mdb file.\nIf the database is protected with a password, do not use the AccessDataSource control to establish a connection to it, because the AccessDataSource control does not support passing credentials. Instead, use the SqlDataSource control with the ODBC provider, and pass the credentials in the connection string. Be sure to secure the connection string as described in this topic under Connection Strings.\nIf you are storing data in an XML file, place the XML file in your Web site's App_Data folder, because the contents of the folder will not be returned in response to direct HTTP requests.\nIf your application accepts input from users, you need to make sure that the input does not contain malicious content that can compromise your application. Malicious user input can be used to launch the following attacks:\nScript injection A script injection attack attempts to send executable script to your application with the intent of having other users run it. A typical script injection attack sends script to a page that stores the script in a database, so that another user who views the data inadvertently runs the code.\nSQL injection A SQL injection attack attempts to compromise your database (and potentially the computer on which the database is running) by creating SQL commands that are executed instead of, or in addition to, the commands that you have built into your application.\nFor all user input, follow these guidelines:\nUse validation controls whenever possible to limit user input to acceptable values.\nAlways be sure that the value of the IsValid property is true before running your server code. A value of false means that one or more validation controls have failed a validation check.\nAlways perform server-side validation even if the browser is also performing client-side validation, to guard against users bypassing client-side validation. This is especially true for CustomValidator controls; do not use only client-side validation logic.\nAlways re-validate user input in the business layer of your application. Do not rely on the calling process to provide safe data. For example, if you are using the ObjectDataSource control, add redundant validation and encoding into the object that performs the data updates.\nTo avoid script injection attacks, follow these guidelines:\nEncode user input with the HtmlEncode method, which turns HTML into its text representation (for example, <b> becomes <b>), and helps prevent the markup from being executed in a browser.\nWhen using parameter objects to pass user input to a query, add handlers for the data source control's pre-query events and perform the encoding in those events. For example, handle the SqlDataSource control's Inserting event, and in the event, encode the parameter value before the query is executed.\nFor controls that can be put into edit mode, it is recommended that you use templates. For example, the GridView, DetailsView, FormView, DataList, and Login controls can display editable text boxes. However, except for the GridView control (see the previous point), the controls do not automatically validate or HTML-encode the user input. Therefore, it is recommended that you create templates for these controls, and in the template, include an input control such as a TextBox control and add a validation control. In addition, when extracting the value of the control, you should encode it.\nTo avoid SQL injection attacks, follow these guidelines:\nDo not create SQL commands by concatenating strings together, especially strings that include input from users. Instead, use parameterized queries or stored procedures.\nIf you are creating a parameterized query, use parameter objects to establish the values for the parameters. For details, see Using Parameters with the SqlDataSource Control and Using Parameters with Data Source Controls.\nEncrypting View-State Data\nData-bound controls, such as the GridView control, sometimes need to persist information that is considered sensitive. For example, the GridView control can maintain a list of keys in the DataKeys property, even if this information is not displayed. Between round trips, the control stores the information in view state.\nView state information is encoded and stored with the contents of the page and could be decoded and exposed to an unwanted source. If you must store sensitive information in view state, you can request that the page encrypt view state data. To encrypt the data, set the page's ViewStateEncryptionMode property to true.\nIt is recommended that you avoid storing sensitive information in the Cache object when client impersonation is enabled and the results from the data source are retrieved based on the client identity. If caching is enabled, cached data for a single user can be viewed by all users and sensitive information could be exposed to an unwanted source. Client impersonation is enabled when the impersonate attribute of the identity configuration element is set to true and anonymous identification is disabled for the application at the Web server.", "label": 1}
{"text": "Claiming to have more than 360 million users in 2010, Microsoft's Hotmail is the most popular free email service in the world. Spammers targeting Hotmail accounts may attempt to use your address to send spam or viruses without being caught. If this happens to you and Microsoft blocks your account, you can take steps to recover it rather than registering for a new email address.\nHotmail allows its users to report spam messages by clicking the \"Junk\" button in the message. Non-Hotmail members can report messages as spam by forwarding the message to email@example.com. Similarly, email recipients can report cases of impersonation to firstname.lastname@example.org if they believe someone has gained unauthorized access to your email address. If someone reports your account as a source of spam, Microsoft can block access to it to stop the spam. However, this prevents both you and the spammer from accessing any content on your Hotmail account. You may see the following message when you sign in: “It looks like this inbox has been blocked. To fix this problem, contact customer support.”\nHotmail's popularity means many email accounts are available to be compromised. Internet security company Commtouch stated in an October 2011 report that 30 percent of Hotmail spam came from compromised accounts, rather than phony accounts that exist solely for the purpose of spamming. Because Hotmail is a trusted website, other email servers include its Internet protocol address -- an identifying number -- on \"safe\" email lists. It's much more difficult for email servers to weed out spam using the common IP technology when it originates from a Hotmail account.\nAs of 2011, Microsoft provides an account recovery service if it blocks your account due to spam or someone accessed it without your permission. To begin the recovery process, you must fill out a form with your Hotmail or Windows Live ID, as well as an alternative email address. Microsoft then requests identifying information such as your location and birth date. The form also asks for the answer to your secret question, a list of contacts in your address book and recent subjects of emails you may have sent. After you submit this form to Microsoft, the company will contact you about recovering your Hotmail account.\nA few steps will minimize the chances of someone accessing your Hotmail account without permission, and make it easier to reclaim your account if necessary. The Windows Live Solution Center suggests creating unique, complex passwords for all your accounts, using numbers and characters, and changing them frequently. Microsoft also provides measures to secure your Hotmail account, such as adding another email address, a mobile phone number and a trusted computer to your profile. This \"Password reset information\" enables Microsoft to verify your identity as the rightful owner of an account and to send you information to reset your password if it becomes lost.\n- Windows Live Help: Configuring Your Password Reset Information\n- BBC News: Microsoft Hotmail Upgrade Targets Gmail and Yahoo\n- Windows Live Help: How to Report Abuse or Spam in Windows Live Hotmail\n- Windows Live Help: It Looks Like This Inbox Has Been Blocked\n- Windows Live Help: Important Security Information To Know\n- Commtouch: The State of Hacked Accounts", "label": 1}
{"text": "Here at Internet Retailer we see plenty of e-commerce jargon and marketing talk cross our PC monitors, but some buzzwords prove harder to translate than others. Big data is one of those. Everyone has heard of it, but not many believe they can define it—and those who do often disagree with each other on what it means.\nAt Wikibon, a professional online community of technologists from many industries, a manifesto about big data includes this definition:\n\"Underlying every business analytics practice is data. Traditionally, this means structured data created and stored by enterprises themselves, such as customer data housed in CRM applications, operational data stored in ERP systems or financial data tallied in accounting databases. But the volume and type of data now available to enterprises — and the need to analyze it in near-real time for maximum business value — is growing rapidly thanks to the popularity of social media and networking services like Facebook and Twitter, data-generating censored and networked devices, both machine- and human-generated online transactions, and other sources of unstructured and semi-structured data. We call this Big Data.\"\nThe volume of this data, the text continues, is on the scale of petabytes and exabytes (2^50 bytes and 2^60 bytes, respectively) rather than yesteryear’s gigabytes and terabytes (2^30 bytes and 2^40 bytes). One byte is a unit of computer information that consists of eight bits, zeros and ones that together make a binary string, which can thus encode one of 2^8, or 256, different pieces of data, such as a letter or number.\nRetailers and even the vendors who help manage and analyze their data for targeted marketing, among other things, might not be so precise about the exact volume. But everyone is aware of the massive amounts of information produced by online behavior tracking, opt-in profiles at e-retail sites and social conversations—not to mention behind-the-scenes information around hardware, such as tracking hits to a particular server or monitoring global web traffic.\nTherefore, we can all likely agree that big data in part refers to retailers having more data than they know what to do with. Even in the days of cataloging, retailers had access to tomes of information about their customers that informed their marketing campaigns. What seems to have changed is the approach. Today’s businesses are using tools and techniques originally developed by large online networks for solving problems on a large scale—accessing small sets of data from many sources quickly and processing it at the same time to produce near-instant responses: think Facebook’s news feed, which gathers stories from many sources in its network, and then produces a small sample of those stories in response to a user’s Likes and preferences.\nRichard Vermillion, CEO of analytics and marketing technology company Fulcrum, says big data does not necessarily imply a particular volume of data but a particular type, one that requires certain tools to cope with, like parallel processing systems or map-reducing algorithms. For example, he says, a retailer with three million customers who wants to optimize 50 different offers for them must deal with 3,000,000 x 50 pieces of data—a much taller order than posed by examining either the customers or the offers alone. “It actually might be small data, but the problem that you’re trying to solve blows it up to make it big,” he says.\nProbably, the definition of big data lies somewhere in the murkiness between the enormous volumes of data that a business captures and the more enormous volumes of data generated in their subsequent analyses, which in turn require special tricks and tools.\nProbably, the definition is not so important in the end.\nWhat is important is that retailers are prepared to tackle the onslaught—consumers demand more personalization, relevancy and engagement from them every day, and, short of omniscience, that takes some number crunching.\nAs the Wikibon manifesto puts it:\n\"Make no mistake: Big Data is the new definitive source of competitive advantage across all industries. Enterprises and technology vendors that dismiss Big Data as a passing fad do so at their peril and, in our opinion, will soon find themselves struggling to keep up with more forward-thinking rivals.\"\nFor those organizations that understand and embrace the new reality of Big Data, the possibilities for new innovation, improved agility, and increased profitability are nearly endless.\"\nNearly endless possibilities for profit? Sounds to me like what in earlier decades may have helped describe another elusive buzzword: Internet retail.\nNow, as before, it’s all a matter of not what a retailer has, but what it does with it. And what retailers have is data—growing, compounding, nearly endless, possibility-rich data.", "label": 1}
{"text": "Many people have Wi-Fi connections set up in their homes. It allows them to connect to the Internet conveniently on their laptops, tablets and other devices. With this convenience comes an added Internet security risk.\nSometimes people try to use their neighbor’s unsecured Wi-Fi connection to obtain a free Internet connection. If they should engage in illegal downloads or other Internet crimes, the IP address may point authorities to the wrong person.\nMore dangerously, hackers may use these connections to intercept personal and financial data from their victims.\nTo prevent these possible problems, users should take precautions with their home networks. Below are some tips for maintaining one’s home Wi-Fi security.\nPlace the Router or Access Point in a Strategic Location\nThe thing that protects users most from hacker interference with their Wi-Fi connections is the need for physical proximity. Hackers must be located within the Wi-Fi’s signal range.\nA wireless router placed within the home will allow the signal to broadcast outside the physical boundaries of the house. While this feature allows users to browse the Internet outside during pleasant weather, it also provides a path for hackers to gain entry.\nBy positioning the router near the center of the home, the range of its outside signal will be limited. If one places the router near an outside wall facing the street, a hacker may be able to work from the convenience of a parked vehicle.\nUsers setting up Wi-Fi connections in apartments or other close living quarters will not be able to limit their connections to their property and should therefore take additional precautions.\nChange the Default SSID and Administrator Passwords\nWhen users set up their access points or routers, they are given default SSIDs and administrator passwords. Oftentimes, the SSID (Service Set Identifier) name is the same for all routers made by the same manufacturer. If hackers find a wireless connection that is still called by its default SSID, they know it is l an easy one to break into.\nLikewise, the manufacturer will provide users with a default administrator password. Users need this password to set up their system on the device’s embedded webserver. There they will enter information such as their account information and firewall configuration.\nThese passwords are generally very simple and widely known. Users are advised to change the administrator password immediately when setting up their networks.\nA very secure password using both upper and lower case letters as well as numbers and special characters is highly recommended.\nUse WEP or WPA Encryption\nData encryption scrambles data that users send over their wireless networks. This will prevent snoopers within a user’s signal range from intercepting any information that is being sent.\nAll Wi-Fi equipment can support WEP and WPA encryption. However users can opt for only one of the two:\n- WEP (Wireless Encryption Protocol) provides security for your device by encrypting data over radio waves as it is transmitted. However, this protocol uses static key encryption and does not prevent hackers from actually intercepting the data.\nWhile difficult, the data can eventually be decrypted. This is therefore the least secure of the two options.\n- WPA (Wi-Fi Protected Access) is a newer technology that is more secure and provides stronger data encryption. However, as a relatively new technology, not all devices are configured to be compatible with WPA.\nIf all of a user’s devices are configured for WPA, it is clearly the better choice. However, if any of the devices are not, users must resort to the WEP protocol.\nUtilize MAC Address Filtering\nA MAC address is a unique identifier that is assigned to each piece of Wi-Fi gear. Access points and routers will monitor the MAC address of every device that connects through them. Manufacturers of Wi-Fi routers and access points will often include an option that allows users to enter the MAC codes of all their home equipment. They may then restrict all access to the network to only those devices.\nDoing this is a wise preventive measure but it is not foolproof. Many hackers are adept at faking MAC address and can bypass this security measure.\nAll in all, taking all possible security measure with one’s home Wi-Fi connection is important and highly recommended. Or a VPN for iPhone or Android phones should be considered to secure the connection. While no one thing is completely secure on its own, together these measures create a strong barrier against hackers.\nTunde writes about technology and techie stuffs on daily basis and of recent, he ventured into business and finance industry where he writes stuffs about www.speedyloan.com. You can check the site for more information.", "label": 1}
{"text": "You probably got to this page by clicking a link. Links are the ties that bind the Web. But each click is also a leap of faith. How do you know you're going to the page you think you're going to?\nGoogle search results let you preview pages before you follow the link, but elsewhere the best you can do is hover over the link to see at the bottom of the browser the URL of the page the link will open. (See below for more on free browser add-ons that rate the security of links in search results.)\nSince 1994 a Certificate Authority based on the Secure Sockets Layer (SSL) standard has managed the validation of Web sites. Several private companies sell various levels of certificates to organizations that own domain names and host Web servers.\nAccording to the recently released Volume 17 of Symantec's Internet Security Threat Report, on at least 10 occasions in 2011 an SSL certificate authority came under attack by Internet criminals.\nOne of the handful of successful attacks targeted a Comodo affiliate that had been granted authority to issue SSL certificates. The bad guys had stolen a user name and password. Elinor Mills and Declan McCullogh describe the attack in the Privacy, Inc. blog.\nSSL implementation survey gives sites low grades for security\nLast week more questions arose about SSL's ability to secure Web transactions. The Trustworthy Internet Movement's SSL Implementation survey of 200,000 popular SSL-secured Web sites found that only 10 percent of the sites were safe.\nThe organization's SSL Pulse page includes a link to SSL Labs' free service for testing a site's SSL security. Simply enter a domain name to run it through the labs' SSL Server Test.\nThere's nothing new about SSL vulnerabilities, which have been reported regularly by researchers since at least 2003. After nearly two decades and despite all the criticism, SSL has proven itself secure enough to protect nearly all online purchases and other sensitive Internet transactions. At least so far.\nBrowser add-ons add a safety rating to links\nUnless you're a network manager, there's not much you can do to ensure that the sites you visit are secure. One way to lower the risk is to be warned about a potentially insecure site before you click the link that opens it.\nMy favorite link authenticator is the free Web of Trust (WOT), which is available for Firefox and Google Chrome. WOT adds a green-yellow-red rating to links in Web search results and to the top of each page you visit.\nWhen you install WOT the program asks you to choose one of three settings: Basic (recommended), Light, and Parental Control, which blocks adult sites.\nThe Tech Support Alert site describes several services that let you copy and paste a link into a text field and search the URL in databases of known dangerous domains. The downside of these services is the extra time required to run Web addresses you're leery about through the checkers.\nPersonal sites and blogs most likely to be infected\nConventional wisdom says malware lurks in the seamy regions of the Web. Certain to be one of the most-discussed findings of Symantec's latest Internet Security Threat Report is that pornographic sites are less likely to be infected than any of the 10 categories of sites in the survey.\nOnly 2.4 percent of adult sites scanned by Symantec were infected, the lowest infection rate of the 10 site categories, which include shopping (7.7 percent), education/reference (6.8 percent), entertainment and music (3.8 percent) and automotive (also 3.8 percent).\nBe careful when you visit your brother-in-law's site highlighting his collection of 19th century beer bottles, though: nearly 20 percent of blogs and more than 15 percent of personal sites had malware, according to the report.\nWhen it comes to browser plug-in vulnerabilities, ActiveX continues to be the most likely source of a Web-borne infection, accounting for 29 percent of the 308 vulnerabilities Symantec detected in 2011. That's a decrease from the 34 percent of the 346 plug-in vulnerabilities detected in 2010.\nJava vulnerabilities accounted for 20 percent of the total recorded in 2011, up from 17 percent the year earlier. Likewise, Adobe Flash vulnerabilities represented 20 percent of the total number of browser plug-in vulnerabilities in 2011, a 2 percent increase from 2010.\nAs for the future, Symantec anticipates an increase in targeted attacks and advanced persistent threats, as well as malware authors using Facebook to take advantage of the lack of tech savvy among the service's users.\nAll the security software in the world will never take the place of a healthy dose of skepticism regarding the safety of any site. Whatever the address bar may say, if you get a bad feeling about the page you're on, close your browser (not just the suspicious tab).\nAnd while we're talking paranoia, when was the last time you ran a full manual scan on your PC? (I'll leave Macs out of it... for now.)", "label": 1}
{"text": "Given the current system of ip addresses, many users express their security concerns regarding the vulnerability of dynamic ip addresses in exposing their identities and subjecting them to various hacking acitivities.\nInternet protocol address serves as the address of a certain device on a computer or internet network. It serves as the virtual location of the users or the devices that they are using on browsing the network. It can possible tell the actual location of the user yet with only limited information.\nBefore internet becomes popular, all the devices in a particular network actually have a static ip address but because of the sudden influx of internet users, many internet service providers (ISP) developed the dynamic ip address. ISP randomly assigns an ip address from their pool of ip addresses to any online user for a specific period, the time the user spent on connecting to that network. After which, the ip would goes back to the pool and another/same ip address can be generated again when another user connects to the network. In this way, ISPS can utilize the available ip addresses for their benefit yet many are questioning the fact that it is more of like sharing an ip address to other users.\nGiven the current system of ip addresses, many users express their security concerns regarding the vulnerability of dynamic ip addresses in exposing their identities and subjecting them to various hacking acitivities. Dynamic ip address may be a little safer than static ip address as the latter can be traced easily. It is easier to monitor the activities of those that are using static or permanent ip address as they do all their activities in only one IP address. For those who are using dynamic ip address, the security risks are kinda less as new ips are assigned and generated randomly when users go online. However, some users tend to use ip addresses who had been associated with abusive users that could somewhat limit their activities online.\nSecurity and privacy concerns should be directed to the ISPs as it is their responsibility to keep the information and actual location of their clients, private. The vulnerability of the ip address also depends on the kind of protection the user has on their computers. It is important that firewalls and antiviruses software be installed on the computer to block any third-party access on the computer. Running spy-wares and preventing responses on Internet Control Message Protocol (ICMP) would also do the trick, as it would disable responses when another user pings the ip address. At the same time, keeping the PC or system password protected would ensure high level of security that I would be impossible to get access to the computer. The use of a router is also advisable as it serves as a gateway of the network especially for those that are using two or more computers from only 1 source or server. It provides a safe way in displaying the devices in which it can show those connected devices as indistinguishable from each other, providing less threats of getting the network or PC exposed. Giving out a lot of information to other users can be very dangerous as they can use that information in tracing and tracking activities.\nIP address may no be safe at all especially if safety measures are not practice by the users. It is important to practice safe and preventive measures in browsing the internet to control and prevent other people in getting access to our computers. There are software available that might be helpful in keeping the network or PC safe. At the same time, if you are not confident about your ip address, then it is better to hide it. Hiding one’s ip address would give no chance to other users to track and monitor your activities because you would appear invincible.", "label": 1}
{"text": "Since their introduction the USB memory stick has been hailed by those fed up with the shortcomings of the floppy. Their small physical size, satisfactory speed and ever-increasing storage capacity makes them the most convenient device to use for transferring files from one place to another. However, these very features can introduce new security risks and amplify risks that already existed with floppy disks. The primary risks associated with USB memory sticks can be identified as:\n- Virus Transmissions - Data sharing opens up an avenue for viruses to propagate\n- Corruption of data - Corruption can occur if the drive is not unmounted cleanly\n- Loss of data - All media is susceptible to data loss\n- Loss of media - The device is physically small and can easily be misplaced\n- Loss of confidentiality – Data on the lost physical media can be obtained by others\nWhenever files are transferred between two machines there is a risk that viral code or some other malware will be transmitted, and USB memory sticks are no exception. Some USB memory sticks include a physical switch that can put the drive in read-only mode. When transferring files to an untrusted machine a drive in read-only mode will prevent any data (including viruses) to be written to the device. If files need to be transferred from an untrusted machine, the only countermeasure is to immediately scan the memory stick before copying files from it.\nCorruption of Data\nIf the drive is physically lost or uncleanly unmounted, then data loss can occur. Physical loss is covered in the next section and corruption can usually be prevented. USB memory sticks differ from other types of removable media, such as CD and DVD-ROMs because the computer usually has no way of knowing when USB memory sticks are going to be removed. Users of USB memory sticks usually need to alert the computer that they intend to remove the device, otherwise the computer will be unable to perform the necessary clean-up functions required to disconnect the device, especially if files from the device are currently open. The OS will attempt to handle unexpected disconnects as best it can, so often no corruption will occur. However, it is still advisable to research the preferred method for unmounting the device according to the OS documentation.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "FTP “Lack of Security” Exposed\nFTP was designed as an easy mechanism for exchanging files between computers at a time when networks were new and information security was an immature science. In the 1970s, if you wanted to secure a server from unwanted access, you simply locked the computer room door. User access to data was controlled by the basic User ID and password scenario. (Right is a reminder of how much technology has advanced since the 1970s. The photograph, taken December 11, 1975, is the Apollo Project CSM Simulator Computers and Consoles. Photo Courtesy of NASA.)\nThe Internet did not yet exist and the personal computer revolution was still a decade away.\nToday, the security of business file transfers is of paramount importance. The exchange of business records between computing systems, between enterprises, and even across international borders has become critical to the global economy.\nYet, the original native FTP facility of TCP/IP wasn’t designed for the requirements of the modern, globally connected enterprise. FTP’s basic security mechanisms – the User ID and password — have long ago been outdated by advances in network sleuthing technologies, hackers, malware, and the proliferation of millions of network-attached users.\nRisks associated with using native (standard) FTP include:\n- Native FTP does not encrypt data.\n- A user’s name and password are transferred in clear text when logging on and can therefore be easily recognized.\n- The use of FTP scripts or batch files leaves User IDs and passwords in the open, where they can easily be hacked.\n- FTP alone, does not meet compliance regulations. (For example: HIPAA, SOX, State Privacy Laws, etc.)\n- When using an FTP connection, the transferred data could “stray” to a remote computer and not arrive at their intended destination leaving your data exposed for third parties or hackers to intercept.\n- Conventional FTP does not natively maintain a record of file transfers.\nThe first step is to examine how FTP is being used in your organization. The next step is to identify how your organization needs to manage and secure everyone’s file transfers. The final step is to evaluate what type of Managed File Transfer Product your company needs.\nFor more information download our White Paper – Beyond FTP: Securing and Managing File Transfers.", "label": 1}
{"text": "Duqu Mystery Code IdentifiedCategory: Bugs / Virus\nPosted: March 20, 2012 08:55AM\nNot very long ago the security researchers at Kaspersky Labs found some code in the Duqu virus they were not familiar with. To solve the mystery they crowd-sourced it by posting the code on their Secure List blog and the Internet succeeded.\nAmong the suggested languages was Object Oriented C, or OO C, and that a version of Microsoft Visual compiler (MSVC) was used. The use of MSVC was spotted because of certain commands in the code that are not typical of other compilers. This got the Kaspersky team working with the software and eventually they found that MSVC 2008 with the minimize size (/O1) and expand only __inline (/Ob1) options produced similar code to Duqu.\nThis proves that some form of OO C was used, but oddly the closest match was not published until after Duqu was released. This finding also sheds some light on the programmers of Duqu. How computer code works has been changing ever since it was first developed, and OO C uses an older custom that code like C++ does automatically. With many modern day languages, if not all, memory allocation is done automatically while in OO C this would have to be done manually. Some programmers prefer OO C for this reason, as they do not trust all of the features in newer languages. Also there was a time that different C++ compilers would give different results, while OO C was a standard with all systems.\nRegardless of the reasons behind the use of OO C, this shows a great deal of skill and experience in the making of Duqu. As described in the Kaspersky blog post, \"Duqu, just like Stuxnet, is a \"one of a kind\" piece of malware which stands out like a gem from the large mass of “dumb” malicious program we normally see.\"", "label": 1}
{"text": "Protect Your Privacy\nMake sure your PC is\nPrevent Identity Theft\nFraud Protection Software\nInternet Identity Theft\nPrevent Identity Theft\nIdentity Theft Protection\nIdentity Theft Prevention\nIt seems like everyday there is a story in the news about a new online scam that caused people to lose tons of money. It’s true that the Internet has become a dangerous place. The hackers of today aren’t just bored teenagers anymore. Today’s online criminals are highly skilled computer experts who know how to manipulate your PC in order to get the information they need to cause you a lot of trouble.\nFortunately for you, the online fraud risks you take when using the Internet can be dramatically reduced with a little bit of knowledge.\n1. How do hackers get information about me?\nOnline fraud has many different faces, but the most common way that hackers get information about you is through the use of spyware. A Spyware program is software that, once installed, collects information about you off your computer and sends it to some third party who uses that information against you. You may not know it, but your computer has files on it right now that contain information like your name, your address, what websites you visit, what kinds of online purchases you make, maybe even your credit card number. All a spyware program has to do is find these files and then send off whatever it finds. This is how a lot of online fraud starts and you probably wouldn’t have any clue that this was going on.\nYou may think that spyware can’t get on your computer unless you are the one to install it, but this is not the case. By manipulating a technology called ActiveX, hackers can remotely install whatever they want on your PC. They can do this if you simply visit a suspicious website.\n2. What do hackers do with that information?\nOnce hackers have installed their spyware on your PC to do their dirty work and have received your information, the sky is the limit in terms of what they can do with what they have.\nSometimes hackers will sell your information to another party who will use it to bombard you with spam and other advertisements and popups. But it gets worse. Every year thousands of people fall victim to identity theft. Identity theft is when someone else uses your personal information to assume your identity. If another person gains access to only a few key piece of information, they can make purchases in your name, take out loans in your name, or get government identification documents (like a passport) in your name.\nIdentity theft can be devastating. Most victims spend months or even years as well as thousands of dollars of their own money clearing their names and fixing their credit reports. And until all that is fixed, victims may lose job opportunities, be refused loans, education, housing or cars, or may even be arrested for crimes they didn’t commit.\n3. How do I keep myself safe?\nOnline fraud is an incredibly frustrating and financially taxing thing to have happen to you. So adding advanced protection from online fraud could very well be one of the best investments you’ll ever make. If you want solid protection from online fraud, then Fast Protector Browser Security fortified with Fast Protector privacy manager is your best choice.\nFast Protector comes with a built in Browser Shield that stops spyware at the point of entry. This powerful tool filters out prohibited ActiveX controls - the very tool that hackers use to download spyware!’\nIn addition, Fast Protector offers a unique approach to online security allows you to corral websites into three different security zones. The low security zone is for websites that you trust and want to allow certain security privileges (such as ActiveX, cookies, Java, etc). The medium security zone is for websites that you haven’t classified or are unsure of. Websites in this zone have only limited security privileges on your PC. The high security zone is for restricted sites. These are sites that you don’t want to allow any privileges like ActiveX, cookies or file downloads.\nAnd when you use Fast Protector, your security gets even better. Fast Protector was built to remove all the sensitive files on your computer that might contain private information about you.\nFast Protector will:\nAnd you can set all this to happen automatically. That way you know you aren’t leaving anything behind when you have to leave your computer in a hurry.\n- Delete Your Internet History\n- Delete Your Cookies\n- Delete Your Cache\n- Delete Your Temporary Internet Files\n- Delete Your Locked and Hidden index.dat Files\n- Delete Your Recent Documents List\n- Empty Your Recycling Bin\nOnline fraud is a dangerously easy trap to fall into, and is becoming increasingly common. Upgrade to Fast Protector Browser Security and Fast Protector you’ll have the best protection from online fraud available on the market today.\nCopyright © 2006 C-Privacy.com. All Rights Reserved.\n| | | | |\nspyware remover beta remover-beta.spyware-removal-4you - adware cleaner free spyware - free anti spyware download spyware removver beta microsoft spyware removeer beta spyware removerr beta more...\nDo you like best spyware adware remover? adware remmover best spyware adware remoover best spyware adware removver best spyware adware removeer best spyware adware removerr est spyware adware remover bst spyware adware remover bet spyware more...\nSpyware Blaster mac spyware Ad Aware Free Spyware\nFind the latest information on adware removeer right here computer problems, pc problems, pc diagnostics, pc check-up, pc check up, pc checkup, slow pc.\nfree spyware adware removal tool\ndownload free spyware removal software\nspyware virus removal\nbest spyware removal program\nfree spyware removal tool download\nnorton spyware removal\nadware download free removal spyware\nspyware removal review\nadware software removal spyware\nyahoo spyware removal\nbest spyware removal software\nmac spyware removal\nfree spyware detection and removal\nanti spyware removal\nfree ware spyware removal tool\nspyware and adware removal program\nbest spyware removal tool\nspybot spyware removal\nfree removal spyware strike", "label": 1}
{"text": "Your current filters are…\nAndroid applications can easily store data using the SQLite database engine. This data can then be heavily used without delays when passing information back-and-forth between the device and a remote database. How then can data be kept in sync if it needs to exist on the device and a remote database? What if you don't need all of the data found in the database to exist on the device?\nThis class will show you how to securely store data on your device and use a simple and secure synchronization utility to send that data to any remote database management system. It could be Oracle, MySQL, Sybase, or some other database. It could even be something completely different, such as XML or other textual flat files.\nWith Android activations reaching a million devices per day, it is no surprise that security threats against our favorite mobile platform have been on the rise.\nIn this session, you will learn all about Android's security model, including application isolation (sandboxing) and provenance (signing), its permission system and enforcement, data protection features and encryption, as well as enterprise device administration.\nTogether, we will dig into Android's own internals to see how its security model is applied through the entire Android stack - from the Linux kernel, to the native layers, to the Application Framework services, and to the applications themselves.\nFinally, you’ll learn about some of the weaknesses in the Android's model (including rooting, tap-jacking, malware, social-engineering) as well as what can be done to mitigate those threats, such as SE-Linux, memory protection, anti-malware, firewall, and developer best practices.\nBy the end of this session you will have a better understanding of what it takes to make Android a more trusted component of our personal and professional lives.\n6th–9th November 2011", "label": 1}
{"text": "The answer is that it's not that simple. It's important to understand all of the approaches to attacking passwords before you can say that complex is good or bad, as the different requirements are intended to deter different types of attacks.\nAs you point out, given two equally long passwords from the same character set, password complexity requirements do reduce the overall search space. For example, given a 1 character ASCII password that must include a letter vs a 1 character ASCII password that may be anything, it's easier to guess the first password.\nBut password character requirements should not be used in exclusion of length. Consider the following password requirement sets' minimum strength:\n- 8 printable ASCII characters = roughly 100^8 = 10^16 possible values\n- 16 printable ASCII digits = 10^16 possible values\n- 9 printable ASCII characters with at least 1 number, 1 letter (of any case) and 1 symbol = ((10 numbers)(52 letters)(30 symbols)*100^6) = 10^16\n[NOTE: I know that 100 is not the true number, it just makes the math easier]\nSo we see that three different password requirements are equally strong, in terms of brute force requirements. But we haven't done anything about dictionary attacks. In a dictionary attack, we simply test a list of well known words and see if any of them is the password. Make any of them longer and you've made it stronger than the others.\nPassword requirement 1 does nothing to prevent dictionary attacks, and 3 does little. You can use the word \"prevents\", which is extremely likely to be found in a dictionary. You can look at real password lists that have been leaked on the internet (or create your own popular service and collect passwords) and discover popular passwords to optimize your attack for the most likely values (ex. if everyone in New York picks a variation of \"Yankee1!\", then your attack will start by trying variations of \"Yankee1!\").\nSo the next natural thing to do is to prevent passwords that are dictionary words. This reduces the number of valid passwords, but it also removes an optimization available to the attacker. Make the password a little longer and you can keep the no-dictionary-words password equally strong or stronger.\nBut this does nothing for leet speak passwords. You won't find P4$$w0rd in a dictionary, but it's a pretty standard variation that brute forcing tools test. Take every word in the dictionary, run it through leet speek, prepend, postpend, and insert one or two other characters at every location.\nPassword complexity requirements can then be introduced to restrict these types of attacks - multiple symbols, multiple numbers, and a (yet again) longer password. Something that requires a password management tool to track. It's hard to brute force (because it's ever longer) and it's hard optimize because it's not in a dictionary or like anything in a dictionary).\nBut what happens when you break a particular password, and the user changes to a new one? Users often try to do the easy thing, and pick an easy to remember password - one very similar to the previous. P4$$w0rd1 becomes P4$$w0rd2. But the attacker will simply add P4$$w0rd1 to his dictionary, and he'll automatically test for P4$$w0rd2. So re-use of passwords is often disallowed.\nBut the heart of the issue is, \"Is it suitable to the organization's needs?\" You need a password that is strong enough to be secure for as long as it is useful (ex. it is changed or the account is disabled), given all other compensating controls that we haven't even started talking about. If the brute forcing speed is slow, or you only get a few chances, weaker passwords are okay (ex. IronKey allows something like 17 attempts and requires physical access, so a 10^16 password is more than strong enough).", "label": 1}
{"text": "The art and science of making and breaking locks is done by locksmiths as well as the profession is recognized as locksmithing.\nSometimes, called security engineering, a highly established way of cracking locks and home security systems was referred to as lock picking. We've got the technology behind making locks has not changed since middle ages. The fundamental technology involves the 'pin tumbler' methodology. Hence the role of the traditional locksmith has not yet changed much. However, using the advent of technology generally and digital and lasers, home security systems have undergone a metamorphosis. It is common that today's security engineer as he is recognized as is more adept with laser and computer or digital systems rather than the traditional lock.\nInside the the past, just one locksmith will make a lock single handedly. Hours at work with use of files and hammer would make a single lock. Today the method of manufacturing locks have changed. A same basic design is utilized with one part being unique to every lock. The part with the locksmith also has evolved where today he is more in repairs instead of manufacturing.\nThough their role has reduced in production, certain specialized segments such as family vaults remain the domain of the traditional locksmith. As these are exclusively designed odds of duplication such as locks that are produced in an assembly line environment.\nLocksmiths workout of commercial showrooms, they might be active in vehicles and do in-house servicing, employed by a company or forensic locksmiths whose job is to investigate burglaries and unearth evidence for investigations.\nA brand new strain of security engineers or electronic lock servicing locksmiths has emerged. They might benefit security companies and style the whole security systems focusing on access control. The locksmith would evaluate the level of security, the threats and design a security plan according to the threat level. The greater the security level the more expensive it might be. The locksmith needs to execute a trade-off between cost and security level for the customer.\nThe profession of the locksmith has additionally become specialized. It is common to determine locksmiths who deal exclusively on domestic locks and keys, automobile locks. Many have become security consultants. There are various certification levels that the locksmith can acquire today based on his levels of skills, areas of expertise and experience.\nMaster locksmith can be a term coined through the fraternity of locksmiths who claim they can supply round skills. However, many countries now insist upon certain Certification and registration requirements prior to the locksmith may use the tag of Master Locksmith.\nWith dwindling scope of work because of technologies such as digital locks, locksmiths are in possession of increased their scope of labor to door hardware, window and door frames, door hinges and electric strikes.", "label": 1}
{"text": "Software moles in your systems\nOld programs, utilities, and plug-ins languishing on your computer or control systems could threaten your security.\nIn the world of espionage, a mole is an agent or spy that infiltrates an enemy environment and establishes him- or herself as a normal citizen. The agent burrows in and simply carries on a quiet life in an effort to blend in, not appear suspicious, and develop relationships. Eventually, the mole will receive orders to carry out the spying functions originally planned, taking advantage of trust built up over the years.\nMoles may be living in your computer and control systems. They weren’t placed there deliberately, and they may not even realize that they’re moles, but they can be just as dangerous. In this context, we’re talking about software that has security vulnerabilities. One situation that has brought this to mind recently is Java, with reports that hackers have been able to exploit vulnerabilities in conjunction with dangerous websites.\nMany computers still have Java installed, possibly an old version, even though the user may not be aware of it. If a hacker discovers that it is there, it can become the port of entry for breaking into the system. The software in this case is the mole. It’s been on the computer for who knows how long because nobody has checked to see what’s there. If it doesn’t get used, it probably doesn’t get updated, so older versions with well-publicized vulnerabilities may still be in place.\nJava is certainly not unique in this sense. There are many other examples of programs that have been exploited in the same way. The U.S. Department of Homeland Security publishes alerts related to industrial software online at http://www.us-cert.gov/control_systems/ics-cert/#monthly-monitor. If you’ve never gone there and looked at the number of platforms that are compromised, brace yourself for a shock.\nThe threat is that a hacker will use one of those vulnerabilities to pry his way into your system. This could happen because a hacker has become proficient at exploiting some favorite vulnerability and goes around looking for targets of opportunity when he can find that software on a system. Or, if he is determined to break into your system specifically, he may hunt and probe to catalog what you have and figure out the weakest platform.\nThe first step of building a defense is knowing what you have on your systems. You need to look at all the software loaded on your individual computers and servers, and know everything that is there, right down to the revision level. You also need to know why you have what you have. The most frustrating situation would be if a hacker used a vulnerability in an old software platform still on your system that no longer even served a purpose. Worse yet, imagine that it was software totally unrelated to your process that some bored operator installed so he could watch DVDs in the control room. How would you explain that to your boss during the investigation of an intrusion?\nYou need to know revision level because platforms go through various iterations, some of which are better than others. Generally, the assumption is that the most recent revision will have more of the vulnerabilities fixed.\nChecking revision levels often exposes the reality that industrial users don’t patch software with any regularity. There are exceptions, of course, but studies show that users simply don’t implement patches as they should. There are some important reasons why users are cautious. If you have a control system that uses Windows and Microsoft sends out an update, it’s possible that there are elements of that update that aren’t compatible with the control system platform. You either need to test the patch yourself in a way that won’t interfere with your functioning system, or wait for the vendor to clear it for deployment. Whoever is responsible for that network probably has other things to do, and who has time to deal with that kind of thing anyway?\nThe sad truth is that most industrial users represent easy targets for a determined hacker. While it may not be practical to undertake more comprehensive efforts to protect your networks, you can keep track of your software collection. You may not be able to close off every conceivable hacker entrance, but this one is pretty strategic.\nSidebar: Recommendations on Java, Matthew E. Luallen\nThe US-CERT recently issued alert TA-13-010A on the Java vulnerability and guidance on how to respond to it. You will need to find out if Java is needed for any of your local or web-based applications and then disable it if it is unnecessary. Systems that are already not communicating to areas of less trust are not at risk, as the exploit must be transferred to local device over the network or through a local connection such as a USB drive.\nThe wider view of security is to not just worry about Java but to ensure continuous protection of your cyber system. This includes having or installing only the applications that are necessary, using a functional change management process to handle system changes, such as addition or removal of access, applications, and patches, and a monitoring and response mechanism. Some practical advice for these and more are available through the 20 critical security controls or the consensus audit guidelines.\nPeter Welander is a content manager for Control Engineering. pwelander(at)cfemedia.com\nRead more on industrial cyber security below:\n|Search the online Automation Integrator Guide|\nCase Study Database\nGet more exposure for your case study by uploading it to the Control Engineering case study database, where end-users can identify relevant solutions and explore what the experts are doing to effectively implement a variety of technology and productivity related projects.\nThese case studies provide examples of how knowledgeable solution providers have used technology, processes and people to create effective and successful implementations in real-world situations. Case studies can be completed by filling out a simple online form where you can outline the project title, abstract, and full story in 1500 words or less; upload photos, videos and a logo.\nClick here to visit the Case Study Database and upload your case study.", "label": 1}
{"text": "New York college students attending an antiwar rally in\nLafayette Square last month were convinced they saw small flying machines that\nwere \"definitely not insects\" hovering above.\nBernard Crane, a Washington Lawyer, saw them too and said he had never seen\nanything like them in his life.\nThese sightings are among a group\nof sightings occurring recently in Washington and New York. Some\nobservers think the unidentified flying objects may be miniature high tech\nsurveillance tools set loose by the Department of Homeland Security to observe\nthe protests. Others say that the devices are just dragonflies, despite observers’\ninsistence that the flying entities are not insects.\nNone of the various government organizations, have admitted to deploying\nrobotic spy bugs over the U.S., but many of these organizations and private\ncompanies they contract with acknowledge that they want to do so and are\nactively pursuing the technologies to make it possible.\nSome government organizations are not looking to redesign nature, but rather to\nmodify it. They are growing special live insects with computer chips in\nthem that control the insects' nervous system. The insects could also be\nmade to carry devices, like miniature wireless cameras.\nThese robobugs could have a plethora of uses, including crawling after sneaky\nsuspects, guiding our missiles, or exploring collapsed structures--and perhaps\nsnooping on protesters.\nGary Anderson the Defense Department's Rapid Reaction Technology Office, when\nquestioned by interviewers about if such drones existed responded, \"If you\nfind something, let me know.\"\nThe CIA, according to The Washington Post, developed a simple dragonfly\nsnooper in the 1970s.\nTom Ehrhard, a retired Air Force colonel, specializing in unmanned aerial\nvehicles admitted that the U.S. government can be pretty sneaky.\nThe armed forces have been using robotic fliers since World War II and\ncurrently have 100 official models ranging from the size of planes to the size\nof birds. These models flew 160,000 flights last year, according to\nRecent reports by the Army suggest that these unmanned flights may make air\ntravel hazardous, with their increased frequency.\nIt appears that designing robobugs is a bit harder than robotic planes\nthough. Insect flight is \"theoretically impossible\" and only\nrecent research at Cornell University has been able to fully explore how\nThe research revealed how the dragonflies conserve energy while hovering by\nfine wing adjustments. Such discoveries could help future robobugs hover\nin place while they watch their mark.\nThe CIA developed a gas powered dragonfly robot in the 1970s, which was\ndeclared a failure when it could not handle the crosswinds. It was\npowered by four small wings. The CIA's spokesman George Little said he\ncould not comment on what the Agency had been working on since.\nOnly the FBI officially denied having robobugs.\nDARPA declared though that they are hard at work implanting moth pupae with\ncomputer chips to make \"cyborg moths\" when the pupae emerge from\ntheir protective casing. The Hybrid Insect Micro-Electro-Mechanical\nSystems hopes to allow researchers to grow insect nerves into silicon computer\nchip connections to allow the insects to be remote controlled like RC\nairplanes. DARPA researchers also are raising cyborg beetles.\nAt a scientific symposium in August DARPA program manager Amit Lal announced\n\"You might recall that Gandalf the friendly wizard in the recent classic\n'Lord of the Rings' used a moth to call in air support. Today, this\nscience fiction vision is within the realm of reality.\"\nMany in the armed forces have serious doubts though about if the project will\never take off of the ground.\nFully robotic fliers may be a better way to go.\nThe California Institute of Technology and Vanderbilt both demoed robotic\nflying insects, though their devices looked robotic. However, Harvard\nUniversity managed to get a truly insect-looking robot to fly, by beating its\nrobotic wings 120 beats per second. The device, machined by lasers and\nweighing a mere 65 mg is a technical marvel. However, its power supply is\nstill too limited to allow it to be autonomous.\nJapanese researchers have succeeded in launching autonomous radio control\nfliers with four inch wing spans, though. These fliers are the size of\nThere are many practical challenges to designing insect fliers for example\ndangers from birds or spider webs that could take out the expensive pieces of\nelectronics in an instant.\nThe question still remains though what the sightings in Washington and New York\nEntomologists interviewed believe the entities to be black dragonflies, based\non descriptions. The dragonfly population of Washington \"can knock\nyour socks off\" according to one entomologist.\nUnfortunately, the entomologists could not explain the bulb shape attachments\nto their tails that many reported seeing; nor could they explain their\norganized flight which was widely reported by observers. Dragonflies do\nnot fly in packs, according to entomologists.\nWhile these strange sightings will certainly raise the paranoia level, they\nbring to light the large amount of fascinating research into autonomous aerial", "label": 1}
{"text": "February 22, 2011\nWhile the economic case for cloud computing is compelling, the security challenges it poses are equally striking. Authors Yanpei Chen and Randy H. Katz, both from the Computer Sciences Divsion; EECS Department at the University of California, Berkeley, survey the full space of cloud-computing security issues, attempting to separate justified concerns from possible over-reactions. The authors examine contemporary and historical perspectives from industry, academia, government, and “black hats”.\nWhile many cloud computing security problems have historically come up in one way or another, a great deal of additional research is needed to arrive at satisfactory solutions today.\nFrom our combined contemporary and historical analysis, we distill novel aspects of the cloud computing threat model, and identify mutual auditability as a key research challenge that has yet to receive attention. We hope to advance discussions of cloud computing security beyond confusion, and to some degree fear of the unknown.\nFor the rest of the feature, we will use the term “cloud computing” per the definition advanced by the U.S. National Institute of Standards and Technology (NIST). According to this definition, key characteristics of cloud computing include on-demand self service, broad network access, resource pooling, rapid elasticity, and metered service similar to a utility.\nThere are also three main service models—software as a service (SaaS), in which the cloud user controls only application configurations; platform as a service (PaaS), in which the cloud user also controls the hosting environments; and infrastructure as a service (IaaS), in which the cloud user controls everything except the datacenter infrastructure. Further, there are four main deployment models: public clouds, accessible to the general public or a large industry group; community clouds, serving several organizations; private clouds, limited to a single organization; and hybrid clouds, a mix of the others. Ongoing cloud computing programs and standardizing efforts from the U.S. and EU governments appear to be converging on this definition.\nOngoing Threats to Secure Clouds\nArguably many of the incidents described as “cloud security\" reflect just traditional web application and data-hosting problems. In incidents related to the industry, many underlying issues remain well-established challenges such as phishing, downtime, data loss, password weaknesses, and compromised hosts running botnets.\nA recent Twitter phishing incident provides a typical example of a traditional web security issue now miscast as a cloud computing issue. Also, recent Amazon botnet incidents highlight that servers in cloud computing currently operate as (in)securely as servers in traditional enterprise datacenters.\nIn the research community, cloud computing security is seeing the creation dedicated forums such as the ACM Cloud Computing Security Workshop, as well as dedicated tracks and tutorials at major security conferences such as the ACM Conference on Computer and Communications Security (CCS). To date, most papers published on cloud security reflect continuations of established lines of security research, such as web security, data outsourcing and assurance, and virtual machines. The field primarily manifests as a blend of existing topics, although papers focused exclusively on cloud computing security are emerging.\nIn the “black hat” community, emerging cloud computing exploits also reflect extensions of existing vulnerabilities, with several examples from a dedicated cloud security track at Black Hat USA 2009. For example, username brute forcers and Debian OpenSSL exploit tools run in the cloud as they do in botnets. Social engineering attacks remain effective—one exploit tries to convince Amazon Elastic Compute Cloud (EC2) users to run malicious virtual machine images simply by giving the image an official-sounding name such as “fedora_core”. Virtual machine vulnerabilities also remain an issue, as does weak random number generation due to lack of sufficient entropy.\nOld Threats Amplified\nSome established vulnerabilities would be significantly amplified in cloud computing and deserve separate consideration.\nFor black hats, cloud computing offers a potentially more reliable alternative to botnets. While the recent brute-forcer presentation claimed that using the cloud is presently more expensive than using botnets, Amazon EC2 recently added cluster compute and GPU instances to target HPC users, which could drastically shift the cloud-botnet cost balance. Note that the prices can be quite low. We estimate that some exploits amortize to as low as $2 per exploit. That said, botnets in the cloud face two complications.\nOnce found, “cloud bots” are easier to shut down than traditional botnets. However, the transient nature of cloud computing services makes cloud bots hard to detect. One could potentially run botnet command and control component using the reliable but transient cloud computing services, while leaving the bots themselves outside the cloud. In other words, cloud computing could become a botnet capability amplifier.\nAlso, because cloud computing introduces a shared resource environment, unexpected side channels (passively observing information) and covert channels (actively sending data) can arise. Traditional co-location services faced similar problems. In public, community, and hybrid clouds, the problem becomes much more challenging due to the transient instead of long-lease nature of services. Having dedicated machines only partly solve the problem, since the shared network may still yield side channels and covert channels.\nOne noteworthy research effort developed methods to place an attacker virtual machine (VM) on the same physical machine as a targeted VM, establish a side channel between two VMs on the same physical machine, and conduct a SSH keystroke timing attack to steal passwords. Additional research would establish what would be an acceptable level of isolation to limit the risk of side channels and covert channels.\nAnother issue comes from reputation fate-sharing, which has mixed consequences. On the plus side, cloud users can potentially benefit from a concentration of security expertise at major cloud providers, ensuring that the entire ecosystem employs security best practices. On the other hand, a single subverter can disrupt many users. For example, spammers subverted EC2 and caused Spamhaus to blacklist a large fraction of EC2’s IP addresses, causing major service disruptions. Thereafter, if someone wants to send email from EC2, they must fill out a form), provide a list of (static) EC2 addresses to authorize for sending, and document their use-case. Upon approval, Amazon forwards the EC2 addresses to Spamhaus for whitelisting. The issues are more severe than traditional fate-sharing, which describes acceptable correlated failure scenarios. In cloud computing, clearly the reputation of different cloud users should not be correlated.\nLessons from Time-Sharing Systems\nWhile cloud computing has taken off as providing today’s computing utilities, the concept of the “computing utility” originated as early as 1965 with time sharing systems such as Multics.\nThus, it comes as no surprise that a survey of historical work should yield counterparts to contemporary cloud security problems. Multics highlights several concerns worth re-emphasizing today.\nA striking aspect of Multics was its security design principles. First, Multics used permission-based protection mechanisms, rather than exclusion-based. Every access to every object checked current authority. Second, Multics embodied a form of Kerckhoffs’ principle, which maintains an open design for its mechanisms, with only the protection keys secret. Third, the design explicitly recognized the importance of human usability and implemented security mechanisms accordingly. These principles remain relevant today. For example, the EC2 spam incident revealed the problems of an exclusion-based design, and the adopted solution represents a permission-based system. Similarly, insufficient attention to usability issues facilitated the social engineering attacks. In contrast, it is somewhat unrealistic to expect completely open designs today, since both cloud providers and users would want to restrict access to their system design to preserve their competitive advantage.\nMultics security design also recognized the importance of preventing system administrators from becoming decision bottlenecks. Otherwise, users will bypass administrators by habit (in modern terminology, a form of “satisficing”) and compromise protection mechanisms. The contemporary counterpart is again the Amazon EC2 spam blacklist incident, where the solution imposed email limits that require administrator intervention to increase; this mechanism may become unscalable if EC2 users who wish to send email significantly increase.\nMultics offered a “spectrum of security” by allowing users to build subsystems that reflect a range of different security needs. Today, different cloud computing users also have different security needs, and a good design would offer a choice of security levels and subsystem boundaries with reasonable defaults. We believe this flexibility could prove to be a major improvement if done well. One possible approach would be to formulate the security primitives around defending different stakeholders against different threat models. An additional feature might support “plug-and-play” services readily compliant with common standards such as those of HIPAA or Payment Card Industry.\nDespite these parallel concerns, we note that a number of Multics security mechanisms, state-of-the-art at the time, remain prevalent today even though they do not work as well for modern computing environments. These mechanisms include access control lists (ACLs), machine-generated passwords, and weak encryption of the password file. Thus, while historical work can provide valuable insights into modern cloud security issues, naturally we must temper our assessment with due consideration to how computing has significantly changed over time.\nIntended Isolation vs. Complexity\nWe find early work on virtual machine monitors (VMMs) noteworthy because different kinds of virtualization constitute a major facet of cloud computing. Here, we review the original argument of why VMMs are more secure than ordinary computing systems to highlight that the core assumptions of this argument no longer hold.\nThe original secure VMM argument has several parts. First, lower levels of multiprogramming (i.e. concurrent execution) lead to lower risks of security failures. Second, even if the level of multiprogramming is the same, VMMs are more secure because they are simpler and easier to debug. Third, for a guest OS that runs on a VMM that in turn runs on bare metal, security violation occurs only when there is simultaneous security failure in both the guest OS and the VMM. Thus, a VMM running k guest OSs with each OS running n programs should experience security failures fails much less frequently than an OS running k × n programs. Fourth, the failure of each program is independent, and hence the failure probability is multiplicative.\nOverall, any one program on a VMM running k guest OSs with each OS running n programs should experiences failures much less frequently than the same program on an OS with k × n programs. The multiplication effect amplifies the reduction in each failure probability.\nThe argument makes three crucial assumptions. First, VMMs are simple. Second, guest OSs have a lower multiprogramming level. Third, the VMM and guest OS have independent failures. Modern VMMs violates all three. Modern VMMs are no longer “small\" in an absolute sense. For example, Xen has ~150,000 lines of code, considerably smaller than ~12 million lines for Linux 2.6.32, but comparable to ~180,000 lines of code for Linux 1.0, which was already a feature rich operating system. Additionally, users use guest OSs the same way they would use a native OS, undermining the assumption that guest OSs have lower multiprogramming levels. Further, some recent VMMs have the guest OS running on a VMM that in turn runs on a host OS. Clearly, the VMM is as (in)secure as the host OS, and the host OS significantly enlarges the trusted code base.\nAs cloud computing providers continue to offer finer granularity and hierarchy of virtualization (e.g. virtual machines, networks, racks, datacenters, clouds, applications), it becomes crucial to verify that each additional level of intended isolation does not undermine security elsewhere. The VMM discussion here highlights one example of the tradeoff.\nNew Threat Models\nCombining the contemporary and historical viewpoints, we arrive at the position that while many cloud computing security problems have historically come up one way or another, we need much additional research to arrive at satisfactory solutions today. We argue that the cloud computing threat model includes several novel elements, grouped into two major categories.\nNew Assets Worth Protecting\nData and software are not the only assets worth protecting. Activity patterns also need to be protected. Sharing of resources means that the activity of one cloud user might appear visible to other cloud users using the same resources, potentially leading to the construction of covert and side channels. Activity patterns may also themselves constitute confidential business information, if divulging them could lead to reverse-engineering of customer base, revenue flows, and the like.\nBusiness reputation also merits protection, a concern for both cloud providers and cloud users. When using shared resources, it becomes harder to attribute malicious or unethical activity. Even if there are ways to clearly identify the culprits and attribute blame, bad publicity still creates uncertainty that can tarnish a long established reputation.\nCloud computing inevitably has a longer trust chain. For example, the application end-user could potentially use an application built by an SaaS provider, with the application running on a platform offered by a PaaS provider, which in turn runs on the infrastructure of an IaaS provider. While to our knowledge this extreme example cannot occur in practice today due to a lack of sufficient cross provider APIs, it illustrates that with any model of cloud computing, stakeholders’ can find themselves with relationships considerably more complicated than simply a provider-user relationship. Some stakeholders could be subverters, who maintain the appearance of a regular cloud user or cloud provider, but in fact perpetrate cybercrime or other cyber attacks. Examples include cloud users who run brute forcers, botnets, or spam campaigns from the cloud; or cloud providers who scan cloud users’ data and sell confidential information to the highest bidder.\nA different, far more dangerous kind of subverters could be doing, say, nuclear simulations and ballistic computations in public clouds, or doing DNA analysis to attempt to create a biological super-virus, or just high-school students with operating a password brute-forcing service. It would be a major challenge to identify these kinds of subverters without an intrusive examination of user-supplied code.\nFurthermore, competitive businesses can operate within the same cloud computing ecosystem: using the same cloud, or ending up in a provider-user relationship. This can lead to strong conflicts of interest, generate additional motives to access the confidential information of a competitor, thus creating another kind of potential adversary.\nFinally, a subtle difficulty with understanding cloud computing threats arises from potentially inaccurate mental models of cloud computing as an always-available service. This viewpoint—which arises from the general paradigm of drawing upon a commodity service with much the flavor of a utility—can create a false sense of security, leading to inadequate security good practices, e.g. omitting regular data backups across multiple cloud providers. As such, we could find that cloud users become their own adversaries, leading to more severe consequences when clouds do fail.\nExisting contemporary works already explore many pertinent research topics. One important area that has yet to receive much attention is mutual auditability.\nAuditability is already a requirement for health care, banking, and similar systems. What is new to cloud computing is mutual auditability. Because the system includes stakeholders with potentially conflicting interests, cloud users and providers both need reassurance that the other operates in a fashion that is both benign and correct. In other words, trusted stakeholders prove that they are in fact trustworthy. Also, by auditability we mean more than just billing accuracy. It also encompasses the ability to detect and attribute malicious activity.\nSuch mutual auditability can have major benefits. First and foremost, it enables the attribution of blame. This capability acts as a deterrent in itself - attackers can no longer escape detection. Even if they escape identification, their malicious software would be removed. In incidence response, having real time mutual audit information would allow both providers and users to take timely damage containment measures.\nWithout the “mutual” part of mutual auditability, the burden to act rests entirely with the provider. Also, in search and seizure incidents, cloud providers can demonstrate to law enforcement that they have turned over all relevant evidence, and prove to users that they turned over only the necessary evidence and nothing more. Without the “mutual” part of mutual auditability, users would have a hard time verifying that cloud providers turned over only the necessary evidence.\nData from mutual audits can also trigger legal and contractual processes built into cloud computing user-provider agreements. Arguably, SLAs and compliance requirements would be toothless if stakeholders cannot demonstrate that the SLAs and requirements are violated. Enhanced mutual audit capabilities would facilitate the creation of new kinds of SLAs. Whether these SLAs would be created would then depend on engineering feasibility of meeting the requirements, rather than being held up by the inability to verify violations.\nOne complication in implementing mutual auditability is that the auditor fundamentally needs to be an independent third party, since the two primary parties in a audit relationship are potential adversaries. Note that this is also the reason that naive encryption fails to solve the problem, since the endpoints of the encrypted channel do not trust each other. A third-party auditor requires a setup quite different than today’s practice, in which cloud providers record and maintain all the audit logs.\nRecent work notes that implementing thorough auditing is not a simple matter even for straightforward web services. In cloud computing, it remains an open challenge to achieve thorough mutual auditing without impairing performance and violating the privacy of all stakeholders. Not all cloud users require the most sophisticated form of mutual auditability, but achieving some measure of it robustly would constitute an important security advance.\nWe find it interesting to contemplate whether security would become a significant cloud computing business differentiator. To some degree, the economics of cloud computing security is yet to play itself out. If security is indeed a business differentiator, it would be an unusual one in that adequately addressing security concerns may not create a competitive advantage, but address security poorly will result in a significant disadvantage.\nThat said, the history of commercial Internet offerings repeatedly shows that time-to-market and undercutting prices can greatly sway customers even in the absence of sound security underpinnings.\nWe believe the situation would be somewhat different this time around, however, given that much of cloud computing targets customers who have extensive business reasons (and scars from the past) leading them to treat security as an elevated priority. Nonetheless, history also teaches us that developing security architectures early in the process can pay off greatly as systems evolve and accrue more disparate security requirements. The challenge is to achieve some measure of adequate and affordable security without undermining the economic advantages of cloud computing.\nTo summarize, we believe many established threats would translate to cloud computing, including phishing, downtime, data loss, password weakness, etc. However, cloud computing would significantly amplify other threats, such as botnets, side channel and covert channels, and reputation fate sharing.\nHistorical work suggests many starting points for contemporary solutions, including applying good design principles, prevent administrator bottlenecks, offer a range of security options, quantifying side channel and covert channel bit rates, and examine the tradeoff between isolation and complexity. Novel aspects of the cloud computing threat model include new assets worth protecting, as well as new adversaries. Mutual auditability would be a major advance if achieved robustly. The economic considerations of cloud computing security are yet to fully play out.\nWe conclude our discussion by highlighting that breaking real clouds makes them stronger. Such studies involve obvious ethical issues, but provide much more compelling results than breaking hypothetical clouds. For example, the recent EC2 side channel study in CCS 2009 triggered a highly visible security effort by Amazon Web Services, and serves as a model for similar future work in academia. Such coupled attack and defense approaches serve as a model for potential government cloud security projects today and internal adversarial efforts to discover vulnerabilities at cloud providers. Black-hat perspectives would continue to provide valuable insight, and research partnerships between different types of stakeholders will likely prove very beneficial to advancing the field.\nAbout the Authors\nYanpei Chen is a fourth year Ph.D. student working with Professor Randy Katz at UC Berkeley . He received a B.S. and M.S. degrees from the University of California, Berkeley. His main research focus is data center workload characterization and performance improvements, with a side interest in network security. He is a National Science Foundation Graduate Research Fellow, and a member of the Reliable, Adaptable, and Distributed Systems Laboratory (RAD Lab).\nRandy Howard Katz received his M.S. and Ph.D. degrees from the University of California, Berkeley. He joined the Berkeley faculty in 1983, where since 1996 he has been the United Microelectronics Corporation Distinguished Professor in Electrical Engineering and Computer Science. He is a Fellow of the ACM and the IEEE, and a member of the National Academy of Engineering and the American Academy of Arts and Sciences. His current research interests are the architecture of Internet Datacenters, particularly frameworks for datacenter-scale instrumentation and resource management. He is a member of the Reliable, Adaptable, and Distributed Systems Laboratory (RAD Lab), and is a co-author of the paper \"Above the Clouds: A Berkeley View of Cloud Computing.\"\nMay 16, 2013 |\nWhen it comes to cloud, long distances mean unacceptably high latencies. Researchers from the University of Bonn in Germany examined those latency issues of doing CFD modeling in the cloud by utilizing a common CFD and its utilization in HPC instance types including both CPU and GPU cores of Amazon EC2.\nMay 10, 2013 |\nAustralian visual effects company, Animal Logic, is considering a move to the public cloud.\nMay 10, 2013 |\nProgram provides cash awards up to $10,000 for the best open-source end-user applications deployed on 100G network.\nMay 08, 2013 |\nFor engineers looking to leverage high-performance computing, the accessibility of a cloud-based approach is a powerful draw, but there are costs that may not be readily apparent.\n05/10/2013 | Cleversafe, Cray, DDN, NetApp, & Panasas | From Wall Street to Hollywood, drug discovery to homeland security, companies and organizations of all sizes and stripes are coming face to face with the challenges – and opportunities – afforded by Big Data. Before anyone can utilize these extraordinary data repositories, however, they must first harness and manage their data stores, and do so utilizing technologies that underscore affordability, security, and scalability.\n04/02/2012 | AMD | Developers today are just beginning to explore the potential of heterogeneous computing, but the potential for this new paradigm is huge. This brief article reviews how the technology might impact a range of application development areas, including client experiences and cloud-based data management. As platforms like OpenCL continue to evolve, the benefits of heterogeneous computing will become even more accessible. Use this quick article to jump-start your own thinking on heterogeneous computing.", "label": 1}
{"text": "Mobile Code Security\nDr Lawrie Brown\nSchool of Computer Science,\nAustralian Defence Force Academy,\nWith the growth of distributed computer and telecommunications systems,\nthere have been increasing demands to support the concept of \"mobile\ncode\", sourced from remote, possibly untrusted, systems, but executed\nlocally. The best known examples of this are WWW applets, but it also\nis manifest in dynamic email, and more recently, in supporting third party\nsuppliers in the emerging Telecommunications Information Networking\nArchitecture (TINA). Supporting mobile code introduces a number of\nserious security and safety issues that must be addressed. This paper\nwill introduce some of these issues, and outline some of the proposed\nsolution approaches, as utilised in languages such as Safe-TCL, Java,\n\"Mobile Code\" is code sourced from remote, possibly \"untrusted\" systems,\nbut executed on your local system. Examples include:\nweb applets, dynamic email, and TINA building blocks.\nThe concept of \"mobile code\" has been called by many names:\nmobile agents, mobile code, downloadable code, executable content,\nactive capsules, remote code, and others.\nAll these deal with the local execution of remotely sourced code.\nMobile Code Examples\nExamples of mobile code include:\n- Web Applets\n- Mini-programs written in Java, which are\nautomatically loaded & run on being named in an HTML document.\nA document can include a number of applets, and these may be sourced\nfrom a number of different servers, and run virtually without the user\nbeing aware of them.\n- Dynamic Email\n- One proposal for the provision of dynamic email suggested\nincorporating Safe-TCL scripts as components of MIME email.\nThese scripts could be run either on mail delivery, or when the mail\nis read by the recipient.\n- TINA Building Blocks\n- The evolving \"Telecommunications Information Networking\nArchitecture\" (see NDC95)\nincludes support for 3rd party service providers\nwho can supply TINA Building Blocks (objects), which can manipulate\nnetwork resources in order to provide value added services to clients.\nAn outline of some of the security and safety issues is given in\nAll of these examples illustrate that the use of mobile code will\nraise of number of serious security and safety issues.\nThis paper will outline some general approaches to,\nand specific examples of, \"safe\" systems.\nI finish by mentioning some flaws which have been\nfound in existing systems, in order to derive some lessons for future designs.\nLow-level Security Issues\nThe use of \"mobile code\" raises a number of obvious security issues:\n- access control -- is the use of this code permitted\n- user authentication -- to identify valid users\n- data integrity -- to ensure the code is delivered intact\n- non-repudiation -- of use of the code, for both the sender and\nthe receiver, especially if its use is being charged\n- data confidentiality -- to protect sensitive code\n- auditing -- to trace uses of mobile code\nTechniques for providing these security services are well known.\nTheir provision is not a technical problem, but rather a political\nand economic one. It involves the use of cryptographic extensions\nto communications protocols. These are well described in the\nOSI Security Framework, the ISO 10181 and CCITT X.810-X.816 standards,\nin the IETF IP-SEC proposals, and the Secure Web protocols.\nClearly a system which supports \"mobile code\" will need to\nprovide these services. Before too long, I believe we will see them.\nA more interesting question, though, is how to address the issue of\nhow to safely execute the code once it is validly and correctly\ndelivered to the end-user's system.\nMobile Code Safety\nThe prime focus of this paper is on the techniques which can be used\nto provide for the safe execution of imported code on the local system.\nThis has to address threats due to rogue code being loaded and run.\nOf course in many ways, these problems are not new: they have been a\nkey component of operating systems design on multi-user systems for\nmany years. The traditional approach to addressing these problems\nhas been to use heavy address space protection mechanisms, along\nwith user access rights to the file system and other resources.\nThe difference between the traditional problems, and those posed by\nmobile code, is one of volume and responsiveness. Mobile code\nis intended for quick, lightweight execution, which conflicts\nwith the cost of heavy address space mechanisms in most current operating\nsystems. Also, each mobile code unit can, in one sense, be thought of as\nrunning as its own unique user, to provide protection between\nthe various mobile code units and the system. Traditional methods\nof adding new users cannot cope with this demand.\nThe types of attacks which need to be guarded against include:\n- denial of service\n- disclosure of confidential information\n- damage or modification of data\n- annoyance attacks\nSome example scenarios which can be imagined include:\na Video-on-Demand service which discretely scans local files for information;\nAn online game which opens a covert connection to run programs locally;\nan Invisible program that captures system activity information.\nResource Access & Safety\nFundamentally, the issue of safe execution of code comes down to a\nconcern with access to system resources.\nAny running program has to access system resources in order to perform\nits task. Traditionally, that access has been to all normal user resources.\n\"Mobile Code\" must have restricted access to resources\nfor safety. However, it must be allowed some access in order to perform\nits required functions. Just which types of access, and how these are\nto be controlled, is a key research issue.\nThe types of resources to which access is required include:\n- file system\n- random memory\n- output devices (entire display, various windows, speaker ...)\n- input devices (keyboard, mic ...)\n- process control (access to CPU cycles)\n- user environment\n- system calls\nLanguage Support for Safety\nWhen considering means of providing safe execution, if heavy address\nspace protection mechanisms are not being used, then considerable\nreliance is going to be placed on the verified use of\ntype-safe programming languages. These ensure that\narrays stay in bounds, that pointers are always valid, and that code cannot\nviolate variable typing (such as placing code in a string and then executing\nit). These features are needed to ensure that various code units do not\ninterfere with each other, and with the system.\nIf type-safe languages are being used, we\nwant assurance of the type-system's soundness and safety,\nwant validation of type-checking implementations, and of course, all\nwithout compromising efficiency.\nIn addition, a range of usual sound programming proceedures need to\nbe followed. The system should be designed in a modular fashion,\nseparating interfaces from implementations in programs, and with\nappropriate layering of libraries and module groups, with\nparticular care being taken at the interfaces between security boundaries.\nOne general approach to designing \"safe\" execution evironments is to\nremove general library routines which could compromise security,\nand replace them with more specific, safer ones,\neg. replace a general file access routine with one that\ncan write files only in a temporary directory.\nGreat care is needed with this approach to ensure that unforeseen\ninteractions or implementation flaws do not negate the desired\nsecurity. This has been an area where failures have occured on a\nnumber of occasions.\nGranting Access to Resources\nOne of the key issues in providing for safe execution of \"mobile code\"\nis determining exactly which resources a particular code unit is to be\ngranted access to. That is, there is a need for a security policy which\ndetermines what type access any \"mobile code\" unit has.\nThis policy may be:\n- fixed for all \"mobile code\" units\n- very restrictive but easy, and the approach currently used to\nhandle applet security in web browsers such as Netscape.\n- user verifies each security related access requests\n- relatively easy, but rapidly gets annoying, and eventually is\nself-defeating when users stop taking notice of the details of the requests.\nWhilst there is a place for querying the user, it should be used exceedingly\n- negotiate for each \"mobile code\" unit\n- much harder, as some basis is needed for negotiation,\nperhaps based on various profiles, but ultimately this is likely\nto be the best approach.\nIn the longer term, some mechanisms are needed to permit negotiation of\nappropriate accesses. How this is expressed is, I believe, one of the\nkey research issues. Initially this is likely to be based on\na simple tabular approach, based on the various categories mentioned\nabove. While adequate for the simplistic applets seen to date,\nthis is unlikely to be sufficient for more complex \"mobile code\"\napplications. For these, some faily powerful language is going to be needed\nto express the required types of accesses, along with a means of reasoning\nabout those requests. For example, consider a simple \"mobile code\"\ntext-editor -- it should be able to change any textual\nfile specified by the user, have access perhaps to a preferences file,\nbut otherwise be denied access to all other files. How can this be expressed and\nreasoned with? This is an area that needs considerable additional work,\nbut will be a key to the successful use of \"mobile code\".\nMobile Code Technologies\nHaving considered some of the issues raised by the need for \"safe\"\nexecution of \"mobile code\", I will now summarise some approaches\nthat have been tried.\nOne method of categorising \"mobile code\" technologies, given in\nTW96, is based on the type of code distributed:\nThe first approach is based on distributing the\nsource for the \"mobile code\" unit used.\nThis source will be parsed and executed by an\ninterpreter on the user's system. The interpreter is\nresponsible for vetting source to ensure it obeys the required\nlanguage syntactic and semantic restrictions; and then for\nproviding a safe execution \"sand-box\" environment.\nThe safety of this approach relies on the correct specification\nand implementation of the interpreter.\nThe main advantages of the source code approach is the distribution of\nrelatively small amounts of code; the fact that since the user has the\nfull source, it is easier to vet the code; and that it is\neasier for the interpreter to contain the execution environment.\nDisadvantages include the fact that it is slow, since the source must\nfirst be parsed; and that it is hard to expand the core functionality,\nsince the interpreter's design limits this.\nOne early example which included aspects of \"mobile code\"\nwere some of the MUDs which were programmable (see Bro93)\neg MUCK, MOO, UberMUD. These systems could execute\nsource authored by arbitrary users anywhere in the world, manually transferred\nto the MUD system, and subsequently executed in the MUD interpreter environment.\nSafeguards were provided by the fact that the MUD interpreter had\nno other access to host system apart from the single MUD database file.\nHowever, any MUD program had full access (as the running user) to MUD data.\nOne limitation was that users needed explicit permission to author code:\nonce granted however, they were trusted not to abuse the privilege.\nThese systems are early illustrations of some of the concepts: the use\nof a \"sand-box\" interpreter, and restrictions on the source of code.\nThe most widespread and common example of the source code approach is\nSafe-TCL, a subset of the TCL language with restricted features for safety.\nTCL was designed by John Ousterhout as a\nsimple, clean, interpreted, embeddable command language,\nwith graphical toolkit (Tk) (see Ous94).\nSafe-TCL is restricted by having\nlimited file system access, and is prevented from executing arbitrary\nsystem commands. Safe-TCL code is usually\nexecuted by the \"untrusted interpreter\" (that is the interpreter\nwhich executes code from an untrusted source). A key component of the\nSafe-TCL system is the provision of another \"trusted interpreter\"\n(which executes code from a trusted source). Trusted code\ncan be used to extend the capabilities of the Safe-TCL system.\nSuch extension code can be invoked by any code running on the\n\"untrusted interpreter\", but the extension code uses the\nThis provides a clean mechanism for extending the system.\nSafe-TCL was designed by Nathaniel Borenstein and Marshall Rose as\na means of augmenting email to include active messages, termed\n\"Dynamic Email\" (see Bor94). With the addition\nof new MIME types: application/safe-tcl\nSafe-TCL programs could be incorporated into email messages,\nand executed either on delivery or access by the recipient.\nThe concepts in Safe-TCL were subsequently adopted by the Tcl group,\nand are now incorporated as standard in the latest Tcl/Tk releases.\nMore recently, Safe-TCL has been adapted for use on the web to execute\n\"Tclets\" -- Safe-TCL code downloaded by a web browser and executed by\nan interpreter on the user's system (see Tclet96).\nIt is currently handled by a\nplug-in on common browsers such as Netscape (see Lev96).\nSafe-TCL has also been extensively used in the First Virtual Internet\nembedded in an HTML document. It is NOT Java! It is\ninterpreted by the user's web browser, and\nallows control over most of the features of the web browsers.\nIt has access to most of the content of its HTML document, and has\nfull interaction with the displayed content.\nIt can access Java methods (& vica versa), providing access\nCurrently there is only a very coarse level of security management:\nit is either enabled or disabled. Its security features are not\nyet well documented.\nA second approach to providing \"mobile code\" is to have the\nprograms compiled to a platform-independent intermediate code,\nwhich is then distributed to the user's system.\nThis intermediate code is executed by an interpreter on the user's system.\nAdvantages are that it is faster to interprete than source,\nsince no textual parsing is required, and the intermediate code\nis semantically much closer to machine code.\nThe interpreter provides a safe execution \"sand-box\", and again, the\nsafety of the system depends on the interpreter.\nThe code in general is quite small, and the user's system can vet the\ncode to ensure it obeys the safety restrictions.\nDisadvantages of this approach are its moderate speed, since an interpreter\nis still being used, and the fact that less semantic information is\navailable to assist in vetting the code than if source was available.\nProbably the best known intermediate code technology today is Java.\nIt is Sun Microsystems' \"executable content\" technology, using an\ninterpreted, dynamic, type-safe object-oriented language\n(see GM95). Its safety features include the use of\nruntime bytecode verification, late dynamic binding of modules,\nautomatic memory management, and exception processing. Considerable effort\nhas gone in to ensuring its safety in design and implementation.\nThis safety is, however, dependent on the correct specification\nand implementation of both the verifier/interpreter AND the\nstandard library implementation (esp. SecurityManager). Failures\nin these areas have led to some security flaws,\nas described later.\nTelescript is a technology for creating distributed applications\nusing \"mobile agents\" (see Tar95). A key\ndifference between Telescript and Java is that a Telescript\n\"mobile agent\" is a migrating process that is able to autonomously\ntransfer its execution to a different system by asking to \"go\" elsewhere.\nLike Java, it is an interpreted, dynamic, type-safe object-oriented language,\ncompiled to an intermediate code, with runtime type checking and\nlate dynamic binding, automatic memory management, and exception processing.\nAdditional features include object persistence and remote access,\nenabling objects to access each other over the network.\nBecause of its migratory and remote access features,\nauthentication and protection features are integral.\nCurrently, Telescript is also supported via Netscape plugins for\nweb applications, as well as using dedicated interpreters for\nother distributed applications.\nNative Binary Code\nThe final category of code distribution uses native binary code,\nwhich is then executed on the user's system. This gives the\nmaximum speed, but means that the code is platform dependent.\nSafe execution of binary code requires:\nApproaches to ensuring this can rely upon:\n- restricted use of instruction set\n- restricted address space access\nA combination of verified use of a trusted compiler, and the\nsoftware fault isolation approach has created considerable interest,\nespecially when used with a Just-in-time Compiler.\n- tradional heavy address space protection, which is costly in\nterms of system performance and support;\n- the verified use of a trusted compiler, which guarantees to\ngenerate safe code that will not violate the security restrictions;\n- the use of \"software fault isolation\" technologies\n(see WLAG93) which augment the instruction stream,\ninserting additional checks to ensure safe execution\nJust-in-time Compilation (JIT) is an approach that combines the portability\nof intermediate or source code with the speed of binary code.\nThe source or intermediate code is distributed, but is then\ncompiled to binary on the user's system before being executed.\nIf source is used, it is slower, but easier to check.\nIf intermediate code is used, then it is faster.\nAnother advantage is that the user can utilise their\nown trusted compiler to verify code, and insert the desired\nsoftware fault isolation run-time checks.\nThis approach is being used with Java JIT compilers, and\nalso in the Omniware system.\nOmniware is yet another technology for \"mobile code\"\n(see LSW95). Omniware code is\nwritten in C++, which is then compiled to an intermediate\ncode for the OmniVM. This is distributed, and at run-time\nis translated to native code for execution.\nIt relies on \"software fault isolation\" techniques\nto enforce safe execution of binaries. This\nadds special checking code which emulates a MMU in software, placing\neach module in its own protection domain. The run-time environment\nvets access to resources. The major advantages claimed for Omniware\nare that it uses a standard, well known language, C++, that it\nis fast, since binary code is actually being executed, and yet it\nis safe, due to the use of the \"software fault isolation\" techniques.\nTheory vs Practice\nThere are a number of good proposals for providing safe execution of\n\"mobile code\". However, some flaws have been found in practice.\nMost of the recent effort has focused on Java (see below), although the\nresearchers believe that other systems would be likely to\nhave similar flaws if they were as closely scrutinised.\nBy examining the flaws found, some lessons may be drawn to assist\nwith future designs.\nJava Implementation Flaws\nA number of implementation flaws have been found in the Java system\n(see DFW96, Ban95,\nAll of these flaws can be corrected by changes to the standard Java\nrun-time environment: many have already been made.\n- Problems with network security, mostly created using DNS spoofing\nto subvert the interpreter's view of the domain namespace, and subsequently to\nviolate the restriction on opening connections only back to the source\nof the Java code.\n- There were some early problems with buffer overflows in sprintf\nin the original JDKs. These have mostly been fixed, except in javap\n(where care is still needed).\n- Some of the standard routines provide information about the\nlayout of storage for objects. This is probably not a serious flaw,\nbut more information is revealed than is perhaps necessary.\n- In HotJava, the proxy variables were public, which meant that any\nJava program could change them, and thus redirect all requests from the\n- There are some problems with inter-applet security. Applets are\nsupposed to be quarantined from each other. However, using the\nthread manager, an applet can discover which other applets have\nrunning threads, control attributes of these threads, and even\ndiscover the applets names (since these are encoded in the thread names).\nJava Language vs Bytecodes\nMore serious are some deficiencies in the design of the Java language\nitself, or more correctly, in differing semantics between the\nJava language, and the bytecodes of the Java Virtual Machine (JVM)\nto which the language is compiled.\nDFW96 have identified two significant flaws.\nThe first, and most serious, relates to superclass constructors.\nWhenever an object is created, a constructor is called for it.\nThese constructors are required to call the constructor for the\nsuper (parent) class first. Unfortunately the Java language prohibits,\nbut the bytecode verifier allows, the creation of a partially initialised\nclass loader, which can then be used to thwart some of the security\nchecks on object creation, and to violate the strong typing of objects.\nDFW96 have found by using this attack, they can\nget and set the value of any non-static variable, and call\nany method (including native methods with fewer security\nThe second flaw identified relates to the Java package names.\nAgain the bytecode verifier allows a leading \"/\" on package names,\nwhich is interpreted by the run-time system as an absolute pathname\nto some package. Since the package is on the local system, it\nis regarded as trusted code. If a user is running Java on a system\nthat allows any other type of network file access (eg FTP server\nwith an incoming directory), then that can be used to place code\non the system which can then be executed by the user's Java interpreter.\nAlso identified were some problems with object initialisation, where\nobject constructors are working with partially initialised objects.\nAll of these suggest that some further work is needed on the design of the\nJava language, and particularly on its relation to the JVM bytecodes.\nSecurity Failure Lessons\nExperience with systems (esp. Java) have highlighted some dangers,\nshowing that failures can occur in both the implementation and the\nspecification of the system. Correct specification does not prevent\npoor implementation, weakening its security. Great care is needed.\nIdeally it should be possible to formally verify the language design,\nand then validate its implementation. In practise, this is unlikely\nto be possible for some time. Some of the methods and procedures used in the\nIT Security Evaluation community may, however, assist in the creation\nof more reliable systems.\n\"Mobile code\" is here with increasing demands for its use.\nSafe execution of \"mobile code\" implies a need for\ncontrolled access to resources, access which ideally should be negotiated\nfor each \"mobile code\" unit. The means for achieving this is\na subject for considerable additional research.\nApproaches taken so far to providing \"mobile code\" include\nthe distribution of: source, intermediate code, or binary code,\nand the use of Just-In-Time compilers.\nExperience with these systems has shown that safe and\nsecure systems need both correct specification and implementation.\nThere is still considerable research and development needed\nin these systems. However I believe the goal of safe and secure\n\"mobile code\" execution is reasonable and achievable.\nThe material in this paper has been revised from survey work done by\nBahram Shahimi, as part of his Master's thesis:\n\"A Preliminary Framework for the Security of\nBuilding Blocks in TINA\" for NTNU. Bahram and I are also indebted\nto Fergus O'Brien for his invaluble comments and\ncritiques of this work, and his assistance in liasing with TINA-C.\nI would also thank several members of the\nSchool of Computer Science, ADFA for their comments and suggestions.\nMIT, December, 1995.\n\"Email With a Mind of Its Own: The Safe-Tcl Language for Enabled Mail\",\n\"MUDs - Serious Research Tool or Just Another Game\",\nSchool of Computer Science, Australian Defence Force Academy, Canberra, Australia, No TR CS14/93, September, 1993.\nDean, D., Felten, E.W., Wallach, D.S.,\n\"Java Security: From HotJava to Netscape and Beyond\",\nin Proceedings IEEE Symposium on Security and Privacy,\nIEEE, May, 1996.\nGosling, J., McGilton, H.,\n\"The Java Language Environment: A White Paper\",\nSun Microsystems, May, 1995.\nLucco, S., Sharp, O., Wahbe, R.,\n\"Omniware: A Universal Substrate for Mobile Code\",\nin Fourth International World Wide Web Conference,\nMIT, December, 1995.\n\"A Tcl/Tk Netscape Plugin\",\nin Proceedings Tcl/Tk Workshop 1996,\nNilsson, G., Dupuy, F., Chapman, M.,\n\"An Overview of the Telecommunications Information Network Architecture\",\n\"Tcl and the Tk Toolkit\",\nAddison-Wesley, Reading, Mass., 1994.\n\"A Preliminary Framework for the Security of Building Blocks in TINA\",\nDepartment of Computer Science and Telematics, NTNU, Trondheim, Norway, Masters Thesis, April, 1996.\n\"Adding Run-Time Checking to the Portable C Compiler\",\nSoftware - Practise and Experience, Vol 22, No 4, pp 305-316, April, 1992.\nTennenhouse, D.L., Wetherall , D.J.,\n\"Towards an Active Network Architecture\",\nComputer Communication Review, 1996.\n\"An Introduction to Safety and Security in Telescript\",\nGeneral Magic Inc., 1995.\n\"Tcl/Tk: Create Web Apps In Internet Time\",\nSun Microsystems Online, August, 1996.\nWahbe, R., Lucco, S., Anderson, T., Graham, S.L. ,\n\"Efficient Software-Based Fault Isolation\",\nin 14th ACM Symposium on Operating Systems Principles,\nACM, Asheville, NC, December, 1993.\n\"Low Level Security in Java\",\nin Fourth International World Wide Web Conference,\nMIT, December, 1995.", "label": 1}
{"text": "A log can be defined as a trace generated by an application, a system or a device capturing information about a specific event that has occurred. Logs can be physical, such as the logs contained in a visitors log book, or more usually electronic, such as web transaction logs, firewall logs, database logs etc. A typical midsized organization will have devices, computer systems and applications generating thousands of logs daily. Logs contain information of varying degree of sensitivity, such as information that needs to be kept confidential and stored securely for a defined number of years with specifc access control restrictions. For this reason logs need to be adequately managed to avoid exposing the organization to information security risks. This seminar address the challenges faced by modern organizations with regards to Log Management, which can be defined as the process of managing the confidentiality, integrity and availability (CIA) of logs in order to comply with business requirements, as well as the requirements imposed by the law, regulations and contractual agreements. In this seminar the author will present a risk-based approach to log management where the use of tools and technologies is only a means to an end and log management is a top down process driven by the company risk evaluation criteria (what is important for the organization) while also knowing which risks are defined as acceptable. The author will also reference tools and technologies which can be readily adopted for cost effective log management.\nMobile Device Management\nIn today's information economy every person has at least one mobile device, being that a phone, smartphone, a tablet pc, a laptop etc. In a business environment it is not uncommon for people to own multiple such devices, some of them provided by the company for business purposes, some others privately owned by the employee. Mobile devices such as smart phones have become extremely powerful, integrating the computing power and functionalities of small portable computers and, while the use of such devices can increase productivity and revenue, most modern organizations face enormous new challenges. How can an organization control the information stored, processed and communicated through mobile devices, such as corporate emails and sensitive documents? How can an organization draw the boundaries between personal use and business use of mobile devices? How can the information stored on mobile devices be protected from attacks when the user is inside and outside the organizational perimeters? How can an organization manage the risks associated to the use of personal mobile devices, i.e. non-company provided, such as powerful smart mobile phones? Should an organization allow the use of such personal devices? And if so, how can it be best achieved to minimize security risks while maximizing the user experience and well being? In this workshop the author will present a range of strategies that can help modern organizations successfully address the above challenges.\nAbout the Author - Dr. Almerindo Graziano\nAlmerindo Graziano is the CEO of Silensec, a management consulting, technology services and training company, specialised in information security services. Dr Graziano holds an MSc in Electronic Engineering and a PhD in mobile computer security, both from the University of Naples, Italy. For five years he also been the founder and course Leader for the MSc in Information Systems Security at Sheffield Hallam University, in collaboration with the British Standard Institution (BSI). He has personally authored a number of training courses from ethical hacking to intrusion detection, along with the ISO27001 Lead Implementer certification course offered by BSI worldwide. He has consulted in formation security for private and government organisations across Europe, Africa and Middle East. He is also a BSI-certified ISO27001 Lead Auditor trainer and auditor.", "label": 1}
{"text": "By default, Gmail uses a secure connection (SSL) to check your credentials (username and password), but after that it redirects to a http connection.\nGmail encodes with gzip all the sent/ received data to transfer it faster, but this can be easily unzipped if a network sniffer monitors the traffic.\nThe https protocol uses more resources on both ends to encrypt and decrypt the traffic, so that's why Google didn't make it the default option.\nIf you want to encrypt your connection to Gmail, there is a simple option: bookmark https://mail.google.com, and use it instead of gmail.com or install a Firefox extension called Customize Google. The extension also switches Google Calendar to a SSL connection.\nThis is an useful trick for many sites, including meebo.com or box.net.\nUpdated: replaced https://www.gmail.com with https://mail.google.com to prevent a warning about the domain name in Firefox.\nCreate encrypted volumes\nDo you trust your computer?\nNew features in Gmail\nROM CHECK FAIL\n1 hour ago", "label": 1}
{"text": "Cross-Site Scripting (XSS) is the most pervasive vulnerability present in Web applications today. That being said, it is possible to build Web apps that are impervious to XSS by arming yourself with an understanding of the threat and a basic toolbox of encoding functions.\nThe attack occurs in a variety of scenarios where data is taken in by your website and then replayed to the user as an executable script. For example, imagine navigating to the following URL:\nIf the website were to replay the query string parameter into its HTML markup verbatim, malicious script would execute on the page. Given the same-origin policy security model of the browser, this script could perform actions or access data on behalf of the user behind the keyboard.\nThere are numerous other ways that an XSS vulnerability might arise. For example, imagine your Web application presents a page with a list of users. If one of the users managed to set their visible name to a\nSCRIPT element, we then have XSS, though this scenario does not involve query string parameters per se.\nAlternatively, consider a situation where an\nonerror attribute results in malicious script execution (as opposed to a\nGenerally speaking, the strategy to pursue in building application code is to encode potentially untrusted content appropriately for the context in which it's being output on the page.\nIt's worthwhile to define these terms. Potentially untrusted content could be input from the user to the website, or even information stored in a database. If your Web application takes input from the URL, that data is potentially untrusted content because the data could have been supplied by an attacker. Information from cookies is not generally directly suspect because of restrictions enforced by the same origin policy; however, if the data originally came from the URL or an HTTP\nPOST, you should consider it suspect. Perhaps the easiest way to define potentially untrusted content would be to say that it's any content that the application did not itself define statically in its own business logic.\nThe context on the page into which the output is placed is also very important to consider as it dictates how you must encode output. Consider the following example in ASP.NET:\n<a href= \"http://contoso.com/app.aspx?var=<%:Server.UrlEncode(UntrustedVar)%> \"> <%: UntrustedTitle %> </a>\nNotice that the\nUrlEncode function is used to encode query string data. It's an IIS 6.0 function that converts spaces to + signs and non-alphanumeric characters to their hex equivalents. The default\nHtmlEncode-based encoding is used in the context of HTML. To understand why different encoding mechanisms are necessary, consider what malicious input might look like if encoding were not in place. In the HREF case, the output might close off the attribute and append a new attribute that would run script, for example:\n\" onload=[Malicious script]\nWhereas in the second case, an effective attack would be:\nSo the various encoding mechanisms must encode different sets of characters to offer effective protection. (In addition, URLs are percent-encoded so that they may be properly parsed by browsers and Web servers, whereas HTML markup is encoded into HTML entities. Using the wrong encoding would create URLs or markup that can't be properly parsed.)\nThere is one issue worthy of note: Your application might hand off data to an external control or API to render on the page. In such a case, what encoding should be applied? To find out, you may need to evaluate the security guarantee provided by the external code. It seems reasonable to assume API input is encoded appropriately for the output context, although any particular API might, in fact, push that responsibility to its caller. The documentation for any good API should specify any required encoding necessary to ensure that output is rendered securely on the page. The <%: %> syntax in ASP.NET 4 and later provides a clever solution to this problem, utilizing a new\nThe Microsoft AntiXSS Library\nAll major Web platforms provide some sort of API for output encoding. Microsoft's implementation for ASP.NET is a library of encoding functions referred to as the Microsoft AntiXSS Library. This library has been available since ASP.NET 4.5.\nThe first thing you'll want to do to leverage the AntiXSS Library on ASP.NET 4.5 is to enable it as the default encoder by adding the\nencoderType attribute to your Web.config file:\n<httpRuntime ... encoderType= \"System.Web.Security.AntiXss.AntiXssEncoder, System.Web, Version=18.104.22.168, Culture=neutral,PublicKeyToken=b03f5f7f11d50a3a\" />\nThis entry will cause default output encoding functionality in ASP.NET to use the conservative AntiXSS Library encoding. In addition, you may then begin to utilize APIs in the\nHtmlEncode(leveraged by the <%: %> syntax),\nEach of these APIs encode data for different contexts. As described previously, it is very important to make use of the proper function for a given context. Examine the surrounding markup on the page to determine context appropriately and choose the right function or combination of functions. In cases where it's necessary to encode more than once, be aware that order is important. For example:\nIn this example, only a single query string variable is encoded, using the\nUrlPathEncode are not appropriate for encoding entire URLs. If you need to encode a full URL, it is necessary to, at minimum, validate its URL scheme to avoid allowing URLs with the\nVBScript: URL schemes. To do this, construct a new\nUri object and then validate the URL scheme as acceptable.\nThat's really all there is to it. While there are other XSS-related security techniques to evaluate when building your Web technology (such as sandboxing, HTML sanitization, and the like), you will find that proper encoding is what's necessary to prevent the most prevalent XSS bugs.\nWhile XSS remains a pervasive Web threat, a good understanding of Web encoding techniques and their supporting APIs enables you to secure your Web applications. While all modern application platforms provide the necessary APIs to enable output encoding, it's up to individual developers to effectively apply the proper functions in the appropriate context.\nThe AntiXSS Library is available for download at no cost. Special thanks to Levi Broderick and Barry Dorrans for contributing to this article.\nDavid Ross is a Principal Security Software Engineer on the MSRC Engineering team at Microsoft. Prior to joining MSRC Engineering in 2002, Ross spent his formative years on the Internet Explorer Security Team.", "label": 1}
{"text": "in the biological world, multicellular computing has yet to\nevolve a taboo against code transfer. Some especially sensitive\napplication areas such as government, military and financial IT do\nbest to prohibit code transfer. Their best is not good enough.\nRecent nation-state attacks include Chinese\nattacks against the US Department of Defense, Stuxnet\na joint US/Israeli exploit against Iranian nuclear sites, and Flame\na very large and multi-function US malware package that exploits flaws\nin Windows Update. Banks and other financial institutions are\nhacked far more often than the public realizes. Commercial databases\ncontaining credit card and other private information of consumers\ncontinue to be compromised all too often. And the above cases\noccur despite professional management of the computers involved.\nDespite the increasing seriousness of such threats, many programmers\nfind it difficult even to imagine a world in which it is technically\nimpossible to alter\ncode in a computer. Moreover, the PC revolution was founded upon the\nfiction that Microsoft \"owns\" the code on every Windows computer and\nhas the right to modify it at will. Hence Windows Update is a\nlegally protected and vital part of the Windows software ecology. Thus\nthe business of PCs and tablets and now smartphones depends upon the\nmovement of code from the vendors to the users! Predictably, viruses\nhave already appeared\nthat exploit smartphone mobile code.\nLoading code, if it cannot\nbe prohibited entirely, should be a\nspecial, and carefully managed process\nmuch better managed than it is at present. Apple's AppStore\npolicies for iPod/Phone/Pad apps are a good start, but only a\nstart. Google's free-for-all policies for Android apps seem\ndesigned to replicate Windows' flaws.\nEnforcing such a taboo will be complicated by the fact that it is difficult to distinguish code from data. Code int the guise of data may sneak in as a supposedly innocuous file like a .jpg image and get executed as a result of a buffer-overrun exploit . In smart phones code may sneak in using an SMS messaging exploit . Fortunately, the importance of a taboo against transferring code is becomings more obvious, so perhaps we can expect the computing industry to incrementally improve its enforcement capabilities.\nin computing tends to reduce the need, hence the acceptability, of\ncode transfer. Compatibility\nWindows monoculture with its common APIs permits meaningful, if\ndangerous, code transfers. Outside of a monoculture, it simply makes no\nsense to base multicellular computing messages on transmitted code.\nSpecialized computers in communities of collaborating machines function\nin very different ways and in different contexts. Code for a router is\nmeaningless in a PDA or a\nparallel computation engine. It is neither practical nor useful for a\nmachine requesting a service to send code that specifies how that\nservice is to be\ncarried out. Only the receiving computer can know how best to provide\nAs code transfer loses popularity, the growing trend, Service Oriented Architectures (SOA) and Web Services in the \"Cloud\" are gaining popularity. Web Services mimic living system’s use of polymorphic message sending. The receiving computer, not the sender, determines the meaning of all SOA and Web Services messages. So the multicellular computing world seems already to be evolving the same basic architecture that evolved in biology. Future orchestrated collaborations between computers on the Internet likely will be based upon one variety or another of SOA. Heavyweight SOA, based upon SOAP, WSDL, and a host of other industry standards, is gaining favor in corporate IT systems. Lighter weight mashups, e.g., those based on AJAX are growing rapidly in the Internet at large. In either case, useful Web Services are emerging on the net and multicellular combinations of Web Services are becoming much more common.\nWhichever new protocols emerge, we must coexist for many years with legacy systems that use proprietary communication protocols, old EDI protocols, HTML protocols, and many less common formats. If biology is any guide, many of these will never fully disappear. They will become frozen historical accidents to puzzle future students of the history of computing.\nThe form of future collaborations between computers seems on its way to being settled, i.e., by some sort of Cloud Web Service conventions based on XML. But the substance is not. Polymorphic messages encoded in XML are syntactically self-describing but not semantically self-describing . If polymorphic messages are to be the basis of communication, there has to be some agreement on the meaning of the messages. Messaging semantics will be sorted out by the efforts of various standards bodies, by acceptance of conventions, and by much evolutionary trial and error. Yet none of these are completely satisfactory – standards are slow, conventions conflict, and evolution is messy. Nonetheless, if biology is any guide, evolution will dominate.\nMessaging semantics in multicellular organisms evolve under constraints from all aspects of the message process at once. An individual organism begins with a fertilized egg that divides. Its daughter cells all share the same DNA. These daughter cells differentiate, staying physically co-located. Hence, the organism’s DNA codes for all aspects of the messaging behavior, both the behavior of the “sending” cell, i.e., how and when it synthesizes and exports a given messenger molecule, and the shape and lifetime of the messenger molecule . The behavior of the “receiving” cell(s), i.e., those that have binding sites for a given molecule, depends upon which biochemical pathways are triggered by receipt of the molecule. If the semantics of a given message transfer are not beneficial or at least neutral to the health of the whole organism, the whole organism is at higher risk of death before it can pass the DNA on to the next generation. Thus survival of the fittest, which operates at the whole organism level, simultaneously punishes poor “syntax” and muddled “semantics” by culling mistakes at either end of the communication.\nA single corporate network infrastructure may play an evolutionary role similar to that of a single multicellular organism. That is, it is a unitary, logically contiguous, dedicated collection of computers that supports the whole organization, for good or ill. Its routers, firewalls, VPN links, LDAP servers, DMZs, and specialized application servers must share an agreed upon and internally compatible architecture and implementation. And the semantics of pairwise collaborations must be sensible. The corporate IT staff work to ensure this. If the system is not up to the job, disaster may well ensue for the whole organization. A corporation with a seriously flawed Web Services infrastructure may simply go out of business, thus failing to pass on its ineffective infrastructure architecture and semantics. Bank mergers are a classic case. A bank’s competitiveness often depends in large part upon its IT infrastructure, which is a carefully (or not so carefully) crafted multicellular computing organism. The weaker bank, when acquired by a stronger one, typically must remake its IT infrastructure to be compatible with the winning bank’s architecture. This sort of system evolves its messaging architecture in a manner similar to that of a multicellular organism, by a remorseless process of survival of the fittest.\nThe evolution of message semantics in the open Internet is more complicated, not to say haphazard. A person’s computer may play a different role in many different sets of multi-computer collaborations, some for private uses and some in their role as an employee, customer, or supplier in business relationships. This is similar to the more fluid and ambiguous semantics in ecologies of organisms where a single organism plays many different roles in different ecological collaborations. Predators recognize prey, and vice versa, by all sorts of chemical signals. So, chemical signals mean one thing between individuals of the same species and another to their predators or prey. For example, the musky smells of animals travel on the wind. Thus predators attack from downwind so as not to warn the prey. The “come hither” scent of a desert mouse is intended to attract a mate. That it also attracts a hungry snake is not simply an unfortunate accident. The snake co-evolves with the mouse. In a similar manner, especially valuable services (Google, eBay, Amazon, Twitter) support an API with defined semantics that attracts third party services. Or services with plentiful and demographically valuable users attract competing services that will offer the same API with the same semantics to attract those users. Successful poachers of either sort can then add to the API and the semantics in an attempt to freeze out competitors. Nonetheless, such co-evolution can result in richer and more useful semantics.\nSome efforts, such as UDDI have attempted to provide a semantic “yellow pages” service as a rendezvous point for finding services with the “right” semantics and to organize such semantic information into useful taxonomies. So far, these efforts have been premature, over-engineered and overly complex. It has been like attempting to start a telephone Yellow Pages before there are enough phones to matter. So, the semantics problem in the Internet remains difficult.\nAlan Kay  proposes that the semantics travel with the message by using objects as the message carrier rather than just data. An object carries both data and the code that provides some of the meaning. Security issues would be handled by assuming that the machines are specialized as object engines that provide separate address spaces for all objects so that one cannot interfere with another. However, object collaboration still requires some shared understanding of the semantics of the polymorphic messages. Reflexive systems, those in which metadata is available with which objects can “reason” about message interfaces of other objects, might be agreed upon and such reasoning might support the bootstrapping of enough semantics to dramatically speed the evolution of useful ways of collaboration. Or, SOA brokers could match up “compatible” parties. This object approach might offer real advantages, however it is a radical departure from the way our current machines work and would require substantial evangelism and investment to succeed. Nonetheless, one day perhaps some classes of computer applications might work very well in such general object engines\n Note that new hardware capabilities from Intel and AMD allow memory to be marked “ no execute” which may eventually make buffer-overruns less of a problem. In July, 2009, a security researcher discovered a way to use SMS messages to completely take over an iPhone without any interaction with the phone's owner. (See interview with Charlie Miller, the discoverer of the iPhone exploit). He also found exploits for Android and Windows Mobile smart phones. He explains the basics of the iPhone exploit thus: \"You can send a long [SMS] message in a series of messages and the phone will reconstruct it into a one long string. It accesses an array based on a value from the data. In the case where it thinks it reads -1, it actually accesses the memory before the array, not in the array. By setting things up just right and being tricky, you can actually leverage this to gain complete control of the device. The entire attack takes just over 500 messages, although the victim doesn't know they are being sent because they don't show up on the phone. Most of these messages have to do with setting things up 'just right.' Sixteen of them actually access the array out of bounds.\"\n XML does not encode semantics. Only the syntax is self describing. When people read XML, they subconsciously perceive the tags as carrying semantic information because the tags are usually human-readable words. The receiving computers cannot derive any meaning from those words. Semantics remains in the minds of the reader and writer of the text, not in the XML itself. Imagine, as a thought experiment, reading XML in which all the tags have been encrypted. The encryption removes none of the information in the XML but does remove the illusion of semantics.\n Intracellular mechanisms degrade almost all proteins including messagenger molecules, some quite rapidly. A molecular message's half-life determines its range and the duration of its effect – that is, messenger half-life is an explicit aspect of message management that evolves along with the functioning of the sending and receiving cells and of the organism as a whole.\n This paragraph is based on a personal communication with Alan Kay. Multicellular computing was the context for that discussion. He has long championed the view that “dumb” data should be avoided. In principle, I agree with him. The difficulty is in how to prevent the embedded \"smarts\" from providing an avenue of entry to viruses and other malware.\nContact: sburbeck at mindspring.com\nLast revised 6/6/2012", "label": 1}
{"text": "Encrypt Your Computer\nEncrypting your computer means that someone has to have your password (or encryption key) in order to peek at its contents should they get access to your hard drive. On a Mac, you just go to your settings, choose \"Security and Privacy,\" go to \"FileVault,\" choose the \"Turn on FileVault\" option. Boom goes the encryption dynamite. PC folk need to use Bitlocker.", "label": 1}
{"text": "Trivial File Transfer Protocol, and you\nThere is nothing trivial about TFTP let me assure you. It is actually a pretty neat protocol with some distinctive features. This protocol also happens to be a favorite of malicious hackers for the purpose of sending over, or retrieving files. TFTP is also quite quick, but more on the speed of TFTP a little later on. Much like other application layer protocols this one is ferried about by IP, and in turn uses UDP for its transport protocol.\nNow TFTP itself has five different message types that it can use. They are as follows;\n- RRQ, which breaks out as Read Request\n- WRQ, which breaks out as Write Request\n- ACK, which breaks out as Acknowledgement\n- ERROR, which breaks out as Error message\n- DATA, which breaks out as, to read or write the next chunk of data\nNow if you happen to capture any TFTP packets on the wire you will see these message types in the packet itself as noted in the packet further down below. (I have underlined it) TFTP also has a series of error codes, which can be found here. If you recall from our discussion of HTTP and SMTP these protocols also had status and error codes. These codes are required to build a coherent exchange of data, which will at times experience error conditions. Courtesy of these codes, whether they be status or error, are various conditions communicated between the client and server in question.\nTypical usage of the TFTP protocol is for the storage and retrieval of Cisco IOS and Catalyst switch configuration files. I also alluded to earlier, that this protocol is heavily favored by hackers as a means of retrieving and storing files on compromised computers. You are not restricted to simply transferring ascii content either, you can also transfer binary files as well. Due to this use of TFTP by malicious hackers you should always be suspicious of any TFTP traffic on your network.\nOn with the show!\nI have said it before, and I will say it again. There is nothing like “hands on practical” to cement lessons learned. With that in hand let’s take a look at some TFTP traffic. You will see below a small snippet, and I shall comment directly beneath the packet in question.\n10:43:20.926155 IP (tos 0x0, ttl 128, id 69, offset 0, flags [none], length:\n44) 192.168.1.102.1029 > 192.168.1.101.69: [udp sum ok] 16 RRQ \"example\"\n0x0000: 4500 002c 0045 0000 8011 b660 c0a8 0166 E..,.E.....`...f\n0x0010: c0a8 0165 0405 0045 0018 833b 0001 6578 ...e...E...;..ex\n0x0020: 616d 706c 6500 6f63 7465 7400 0000 ample.octet...\nThis traffic was collected using a different version of windump, and has thereby resulted in a slightly different look than what you may be used to. In the packet directly above us we have a read request for the file “example”. The read request is seen in the RRQ, which is underlined above. Following that, in brackets, is the file that is being requested from the TFTP server located at 192.168.1.101, on its port 69. Port 69 is the port associated with TFTP, and is also in the reserved port range of 0 to 1024. We can also see that “octet” follows the file name example.\nOctet signifies that the data will be transferred in eight bit bytes, unlike the other transfer mode of “netascii”. If it were netascii, then TFTP would interpret the file example as being lines of ascii text, and has slightly more overhead to it which I won’t cover here. Lastly I will point out that the 16 seen before the RRQ relates to the amount of TFTP data that is sent in this packet. If we do the math it works out. We have an overall packet length of 44 as seen in the header. The IP header accounts for 20 bytes, while the UDP header accounts for 8 bytes. The remaining 16 bytes of TFTP data fill out the packet size to the noted overall size of 44 bytes. Now because of the size difference between TCP and UDP it is clear why UDP is faster ie: it has 12 bytes less of header information to send. That makes for some quick file transfers.\n10:43:20.977012 IP (tos 0x0, ttl 64, id 8683, offset 0, flags [DF], length:\n130) 192.168.1.101.32768 > 192.168.1.102.1029: [bad udp cksum 424c!] UDP,\n0x0000: 4500 0082 21eb 4000 4011 9464 c0a8 0165 E...!.@.@..d...e\n0x0010: c0a8 0166 8000 0405 006e 849b 0003 0001 ...f.....n......\n0x0020: 5468 6520 6265 7374 2077 6179 2074 6f20 The.best.way.to.\n0x0030: 6c65 6172 6e20 6162 6f75 7420 7468 696e learn.about.thin\n0x0040: 6773 2069 7320 746f 200a 6163 7475 616c gs.is.to..actual\n0x0050: 6c79 2064 6f20 6974 2079 6f75 7273 656c ly.do.it.yoursel\n0x0060: 662e 204d 7563 6820 6c69 6b65 2077 6861 f..Much.like.wha\n0x0070: 740a 4920 616d 2064 6f69 6e67 206e 6f77 t.I.am.doing.now\n0x0080: 210a !.\nNow what we see above is the TFTP server located at 192.168.1.101 sending the requested file “example”. We can see within the ascii portion of the packet, that the contents of the file example are simply me saying that the best way to learn is to actually do it yourself.\n10:43:20.979434 IP (tos 0x0, ttl 128, id 70, offset 0, flags [none], length:\n32) 192.168.1.102.1029 > 192.168.1.101.32768: [udp sum ok] UDP, length: 4\n0x0000: 4500 0020 0046 0000 8011 b66b c0a8 0166 E....F.....k...f\n0x0010: c0a8 0165 0405 8000 000c f7af 0004 0001 ...e............\n0x0020: 0000 0000 0000 0000 0000 0000 0000 ..............\nNote that this packet above is actually an acknowledgement packet. Rather odd isn’t it as this is UDP and not TCP. Why are we seeing an acknowledgement packet then? Well this actually is part of the TFTP protocol itself, and the Opcodes that come with it. Where in the packet above is the Opcode you say? Good question! We know that our IP header ends at bytes 0165, as these are the last two octets of the destination IP address. Starting at bytes 0405 then is the UDP header, which in turn ends at bytes f7af.\nWe now know then that bytes 0004 are actually representing the Opcode for this packet. In this case the value is four, and that breaks out ACK, or Acknowledgement. After this Opcode value is the block number of 0001. This block number is also seen in the actual packet transferring the contents of the file “example”. Pretty neat eh? So in a way you are getting a connection oriented session even though it is UDP based. That though is courtesy of the TFTP Opcodes.\nIf you would like to play with the TFTP protocol then I encourage you to download a freeware one located here. The good folks at Solarwinds have been good enough to offer up this excellent win32 based TFTP server for free. Kudos to them! Once you have this installed on your win32 operating system, start to experiment with ferrying files back and forth by using the “GET” and “PUT” commands. You should also be sniffing your connection while doing this, so that you can then look at the resulting traffic. Well that’s it folks for our discussion of the TFTP protocol. I sincerely hope you enjoyed it. Till next time!", "label": 1}
{"text": "The Flashback Trojan, the one that seemed to spread like wildfire, infecting an estimated 1% of Macs around the world, continues to cause trouble. Symantec researchers estimate the malware is still on as many as 270,000 systems. Not all Mac owners run security software, and many fail to install computer and program security patches when they become available. “Flashback” is a flash point in internet security history because Mac owners realize they need to attend to the same security precautions as PC owners.\nNorton has just released a free tool that Mac owners can download and run to both check for Flashback on their system and remove it, neatly and cleanly. Then, whether your system was infected or not, you should install and use internet security software, such as Norton AntiVirus for Mac or Norton Internet Security for Mac. And after that, get into the habit of installing patches and security updates for your operating system and other programs.\nWhat is Flashback? Flashback is a Trojan program that takes advantage of a flaw in Java, a programming language used by many websites.\nWhat can Flashback do? It is designed to steal passwords and other private information .There are variants out there so it’s possible that other damage can be done by different designs.\nIs this a big outbreak? Flashback is the biggest malware outbreak we’ve ever seen for the Mac platform. But it’s not the first malware we’ve seen for Mac. Last year there was an outbreak of fake antivirus software called Mac Defender.\nWhy are Macs suddenly vulnerable to viruses? All operating systems have potential vulnerabilities. It’s just that up until now, cybercriminals focused their efforts on the PC platforms in order to make more money. Users of all internet-connected devices, regardless of platform, should seek to make their device as secure as possible and use security software, as well as other best practices. This includes mobile devices like cell phones and tablets.", "label": 1}
{"text": "With the recent revelation that computer hackers could have created mayhem by shutting down millions of Internet users through fake servers, this seems like the perfect time to remind people that being cautious on the Internet is always a wise thing to do.\nWorking with Information Technology with our newspaper and our company, I received emails regularly from security consultants who offer information on the latest threats and ways to combat those threats. In the last week, one firm sent out a \"Internet Safety Basics\" for customers, and I thought I'd share it with you.\nThe most important thing to remember about cyber security is that people using their touchpad or mouse are the last line of defense. Technologies such as anti-virus, safe browsers, firewalls, or anything else cannot help if an Internet user clicks on the wrong link or visits the wrong web site.\nThe following tips help computer users stay safe on the Internet by avoiding risky behavior and common traps:\n1. Don't rely on your browser to protect you from malicious websites. Browsers only warn you about sites but cannot stop you from going there. Even if you have high security settings and anti-virus software, visiting a risky web site can result in viruses, spyware or worse.\n2. Beware of windows or pages that prompt you to click a link to run software. Malicious web sites can create prompts that look like messages from your browser or computer. If you see a pop-up you think is risky, go to the company's web site for scans and downloads.\n3. Don't provide personal information to get something free online. Criminals may use this data to break into personal or work accounts.\n4. Watch for shortened URLs, and numbers, hyphens or special characters in a URL. Scammers manipulate URLs to trick users. Be wary of URL's posted in Facebook and sent via email. Use a search engine to identify the actual URL.\n5. When you use a search engine be very careful of the result you click on. Hackers use legitimate looking topics to trick you into clicking. Scrutinize the URL to ensure you are going to a legitimate web site.\n6. Never trust free content. Free movie, music and video downloads often include pirated content and just as often this content contains viruses and malware.\n7. Vary your passwords from site to site. When you use the same password across many sites it makes it easy for criminals to hack all of your accounts. Use more complex and varied passwords for sites with personal information such as banking sites.\n8. Be cautious of convenient features such as auto-complete for forms or \"remember your password\". Web sites can use hidden fields to steal the data from forms. Also, criminals can hijack your browsing session and steal your information if you stay logged-in to a site.\nOne of the biggest reasons that computer crimes are so common is the fact that there is usually never a face-to-face component where the victim faces the criminal. The anonymity of computer crime is what makes that type of offense so appealing, according to law enforcement authorities.\nSo there you have some of the most basic steps to preserve your Internet security. Just like scam phone calls, emails or Phishing attempts, if you ever feel your Internet account has been compromised, contact your Internet provider immediately for assistance.\nAnd, above all, never, ever give out any personal information such as bank account numbers, social security numbers or passwords to respond to any email request unless you initiated the email and know whom you are dealing with.", "label": 1}
{"text": "Principle of least privilege\nIn information security, computer science, and other fields, the principle of least privilege (also known as the principle of minimal privilege or the principle of least authority) requires that in a particular abstraction layer of a computing environment, every module (such as a process, a user or a program depending on the subject) must be able to access only the information and resources that are necessary for its legitimate purpose.\nThe principle means giving a user account only those privileges which are essential to that user's work. For example, a backup user does not need to install software: hence, the backup user has rights only to run backup and backup-related applications. Any other privileges, such as installing new software, are blocked. The principle applies also to a personal computer user who usually does work in a normal user account, and opens a privileged, password protected account (that is, a superuser) only when the situation absolutely demands it.\nWhen applied to users, the terms least user access or least-privileged user account (LUA) are also used, referring to the concept that all user accounts at all times should run with as few privileges as possible, and also launch applications with as few privileges as possible. Software bugs may be exposed when applications do not work correctly without elevated privileges.\nThe principle of least privilege is widely recognized as an important design consideration in enhancing the protection of data and functionality from faults (fault tolerance) and malicious behavior (computer security).\nBenefits of the principle include:\n- Better system stability. When code is limited in the scope of changes it can make to a system, it is easier to test its possible actions and interactions with other applications. In practice for example, applications running with restricted rights will not have access to perform operations that could crash a machine, or adversely affect other applications running on the same system.\n- Better system security. When code is limited in the system-wide actions it may perform, vulnerabilities in one application cannot be used to exploit the rest of the machine. For example, Microsoft states “Running in standard user mode gives customers increased protection against inadvertent system-level damage caused by \"shatter attacks\" and malware, such as root kits, spyware, and undetectable viruses”.\n- Ease of deployment. In general, the fewer privileges an application requires the easier it is to deploy within a larger environment. This usually results from the first two benefits, applications that install device drivers or require elevated security privileges typically have additional steps involved in their deployment, for example on Windows a solution with no device drivers can be run directly with no installation, while device drivers must be installed separately using the Windows installer service in order to grant the driver elevated privileges.\nIn practice, true least privilege is neither definable nor possible to enforce. Currently, there is no method that allows evaluation of a process to define the least amount of privileges it will need to perform its function. This is because it is not possible to know all the values of variables it may process, addresses it will need, or the precise time such things will be required. Currently, the closest practical approach is to eliminate privileges that can be manually evaluated as unnecessary. The resulting set of privileges still exceeds the true minimum required privileges for the process.\nAnother limitation is the granularity of control that the operating environment has over privileges for an individual process. In practice, it is rarely possible to control a process's access to memory, processing time, I/O device addresses or modes with the precision needed to facilitate only the precise set of privileges a process will require.\nThe original formulation is from Jerome Saltzer:\nEvery program and every privileged user of the system should operate using the least amount of privilege necessary to complete the job.—\nPeter J. Denning, in his paper \"Fault Tolerant Operating Systems\", set it in a broader perspective among four fundamental principles of fault tolerance.\nHistorically, the oldest instance of least privilege is probably the source code of login.c, which begins execution with super-user permissions and—the instant they are no longer necessary—dismisses them via setuid() with a non-zero argument.[original research?]\nThe kernel always runs with maximum privileges since it is the operating system core and has hardware access. One of the principal responsibilities of an operating system, particularly a multi-user operating system, is management of the hardware's availability and requests to access it from running processes. When the kernel crashes, the mechanisms by which it maintains state also fail. Even if there is a way for the CPU to recover without a hard reset, the code that resumes execution is not always what it should be. Security continues to be enforced, but the operating system cannot respond to the failure properly because detection of the failure was not possible. This is because kernel execution either halted or the program counter resumed execution from somewhere in endless, and—usually—non-functional loop.\nIf execution picks up, after the crash, by loading and running trojan code, the author of the trojan code can usurp control of all processes. The principle of least privilege forces code to run with the lowest privilege/permission level possible so that, in the event this occurs—or even if execution picks up from an unexpected location—what resumes execution does not have the ability to do bad things. One method used to accomplish this can be implemented in the microprocessor hardware. In the Intel x86 architecture, the manufacturer designed four (ring 0 through ring 3) running \"modes\".\nAs implemented in some operating systems, processes execute with a potential privilege set and an active privilege set. Such privilege sets are inherited from the parent as determined by the semantics of fork(). An executable file that performs a privileged function—thereby technically constituting a component of the TCB, and concomitantly termed a trusted program or trusted process—may also be marked with a set of privileges, a logical extension of the notions of set user ID and set group ID. The inheritance of file privileges by a process are determined by the semantics of the exec() family of system calls. The precise manner in which potential process privileges, actual process privileges, and file privileges interact can become complex. In practice, least privilege is practiced by forcing a process to run with only those privileges required by the task. Adherence to this model is quite complex as well as error-prone.\nSimilar principles \nThe Trusted Computer System Evaluation Criteria (TCSEC) concept of trusted computing base (TCB) minimization is a far more stringent requirement that is only applicable to the functionally strongest assurance classes, viz., B3 and A1 (which are evidentiarily different but functionally identical).\nLeast privilege is often associated with privilege bracketing: that is, assuming necessary privileges at the last possible moment and dismissing them as soon as no longer strictly necessary, therefore ostensibly avoiding fallout from erroneous code that unintentionally exploits more privilege than is merited. Least privilege has also been interpreted in the context of distribution of discretionary access control (DAC) permissions, for example asserting that giving user U read/write access to file F violates least privilege if U can complete his authorized tasks with only read permission.\nSee also \n- User Account Control\n- Capability-based security\n- Compartmentalization (intelligence)\n- Confused deputy problem\n- Encapsulation (object-oriented programming)\n- Need to know\n- Privilege escalation\n- Privilege revocation\n- Privilege separation\n- Saltzer 75\n- Denning 76\n- Jonathan, Clark. \"Virtualization Guru Writes \"User-mode is a Good Thing - Deployment to Locked-down Accounts without Security Elevation\"\". Retrieved 15 Mar 2013. More than one of\n- Aaron Margosis (August 2006). \"Problems of Privilege: Find and Fix LUA Bugs\". Microsoft.\n- Matt Bishop, Computer Security: Art and Science, Boston, MA: Addison-Wesley, 2003. pp. 343-344 cited Barnum & Gegick 2005\n- Saltzer, Jerome H. (1974). \"Protection and the control of information sharing in multics\". Communications of the ACM 17 (7): 389. doi:10.1145/361011.361067. ISSN 00010782.\n- Roger Needham, Protection systems and protection implementations, Proc. 1972 Fall Joint Computer Conference, AFIPS Conf. Proc., vol. 41, pt. 1, pp. 571-578\n- Schneider, Least Privilege and More\n- Ben Mankin, The Formalisation of Protection Systems, Ph. D thesis, University of Bath, 2004\n- P. J. Denning (December 1976). \"Fault tolerant operating systems\". ACM Computing Surveys 8 (4): 359–389. doi:10.1145/356678.356680.\n- Jerry H. Saltzer, Mike D. Schroeder (September 1975). \"The protection of information in computer systems\". Proceedings of the IEEE 63 (9): 1278–1308. doi:10.1109/PROC.1975.9939.\n- Deitel, Harvey M. An introduction to operating systems (revisited first ed.). Addison-Wesley. p. 673. ISBN 0-201-14502-2. page 31.\n- Sean Martin (April 2012). \"Are security basics getting lost under the cover of cloud and mobile?\". SC Magazine.\n- Managing least privileges from the cloud by Monique Sendze\n- The Saltzer and Schroeder paper cited in the references.\n- NSA (the one that implemented SELinux) talks about the principle of least privilege\n- A discussion of the implementation of the principle of least privilege in Solaris\n- \"Proof that LUA makes you safer\" by Dana Epp\n- Applying the Principle of Least Privilege to User Accounts on Windows XP, by Microsoft\n- Privilege Bracketing in the Solaris 10 Operating System, Sun Microsystems\n- \"Commercial enterprises are putting our critical infrastructure at risk\" CSO", "label": 1}
{"text": "With the nation’s air traffic expected to double by 2025, air traffic controllers will probably have to depend more and more on automation. But too much automation could lead to fatal mistakes when that automation fails, a former Texas Tech University psychology student discovered.\nThe Joint Planning and Development Office, made up of officials from NASA, the FAA and the Department of Defense, is developing initiatives to help controllers handle increased air traffic that include more automation, said Arathi Sethumadhavan, who recently earned a doctorate degree from the Department of Psychology.\n“Fully automated systems are not always desirable because they tend to leave the controller out of the decision-making loop,” Sethumadhavan said. “The controllers tend to become overly reliant on the automation, so that when it fails, it’s hard for the operator to take back control. The key is to find the right level and type of automation that benefits the controller and still keeps the controller in the decision-making loop.”\nTo help answer the question, Sethumadhavan trained 72 subjects to use a simple air traffic control simulator with four levels of automation. She found that controllers with more automation built into their systems were less able to detect collisions in their airspace when the systems failed than those who had less automation.\nHer work, titled Effects of Automation Types on Air Traffic Controller Situation Awareness, was published in the 2009 Proceedings of the Human Factors and Ergonomics Society. She will present her findings during the society’s annual meeting Oct. 19-23. Her research was funded by the American Psychological Foundation and the Council of Graduate Departments of Psychology.\nIn one group, color-coded altitudes aided controllers, while a second group’s automated system highlighted possible collisions in the airspace. The third group’s automated system provided recommendations to avoid the possible collisions. The fourth group’s system automatically resolved potential collisions between aircraft.\nWhen the simulation froze at random times, the controllers were asked to recreate aircraft location, altitude, heading, destination, and call sign from memory to determine their situation awareness. The first group with only the color-coded altitudes to assist them was able to recreate their screens far better than the other three groups who had more automated programming.\n“The first group had higher situation awareness far beyond those who had higher levels of automation,” she said. “I thought exposure to one automation failure would make the controllers more cautious. So, I made them complete another scenario in which the automation failed. What was shocking was that even after exposure to a failure in the automation, the groups with higher levels of automation continued to have lower situation awareness and were slower to detect a subsequent failure in the automation.\n“Automation technology has clear benefits when it functions correctly. But no system is 100% reliable. The trick to designing future air traffic automation systems will depend on coming up with the right level and types of automation. Psychology can help make these systems more user-friendly and more interactive to protect against over-reliance.”\nPat DeLucia, professor of psychology, sat on Sethumadhavan’s dissertation committee. She said it holds important information for designers who will implement plans for the next generation of air traffic control operations.\n“We know that automation can lead to less ability to recover after a system failure,” DeLucia said. “But Arathi’s dissertation goes deeper and looks into situational awareness with varying degrees of automation. Overall, her work could have the potential to influence the next generation of air transportation systems.”\nFor more information: TTU.edu.", "label": 1}
{"text": "Now days many peoples in the world use iPhone like a computer, because iPhone is nothing less than a computer as it provides many functions and allows you to do just everything which you can do with your normal computer. So, obviously, iPhone just like a normal computer will also be prone to hacking risks. But you may not think to protect it like one. iPhone is vulnerable to hacking, just like a computer. This puts at risk any information stored in your phone, including your contact lists,text messages, emails, passwords, and more.\nMany people either don’t know as yet enough about the hacking risks or may even be careless assuming the iPhone to be totally free from hacking risks. However, let me reiterate that iPhone is as prone to hacking risks as any other gadgets and one should take enough precautions to understand the hacking risks and prevent them before hackers could harm your device.Don’t forget to Subscribe to our RSS feed\nProtect Your iPhone/iPad From Hackers\nYou can take steps to keep your iPhone, ipad, and your information, secure from hackers. Step 1: Always Lock Your iPhone With Strong Password :\nKeeping your iPhone locked with a strong password is one of the best , basic and simplest way to protect your iphone or ipad from hackers. So it will prevent any one from picking up your iPhone and looking through it and also it will make the data in encrypted form. Step 2: Don’t Allow Your iPhone to remember passwords:\nRemember password is a common feature which allows users to save the entered password after using it once for a particular website or application. It is one of those very common feature which many people use quite carelessly without understanding the risk. However, for the same reason, it has become hackers favorite as they always have been looking for ways to somehow either get the password or could get direct access to the applications.\nSo It is always better to not to allow iPhone to remember passwords, and always enter the passwords manually.\nStep 3: Don’t click an unknown link\nBe careful where you click. Much like on a computer, clicking a link to a website set up to hack your iPhone will let a hacker do just that. Never click a link in an email or a link on a website you aren't familiar with. Instead of clicking links, type the name of the website you wish to visit directly into the address bar on your browser. Step 4: Switch off Wi-Fi and Bluetooth :\nWhen not in use, you should switch off Wi-Fi connectivity on your iPhone as Wi-Fi makes iPhone quite vulnerable to hackers. In the same way, you should always keep Bluetooth switched off on your iPhone when not in use as it also increases the hacking risks. Step 5: Keep a close watch on SMS attacks /virus :\nHackers generally try to send the SMS to the iPhone concerned with some special characters in the SMS message like one small square character or something similar to that (it could even be series of such characters). All this does is crashes your iPhone and hackers simply gets access to your device automatically. The worst part is and what makes this as most vulnerable is that you don’t even have to do anything with the SMS /text message. Simply receiving such message on your iPhone can do all the harm.\nSo, the only way to save your iPhone is to switch off your iPhone as soon as you notice any such character in your SMS /text message. Step 6: Always keep your iPhone updated\nKeep your iPhone up to date. When Apple and iTunes release new updates, many of those include new or improved security features. Check for updates often, and install them onto your iPhone as soon as they become available.\nSo, keeping your iPhone up to date with all the latest updates will help you a lot in protecting it from hackers and viruses. Update : If you want to hack Gmail, Myspace and other email account passwords, please use the best Hacking Softwares,\nSo friends, I hope you will like this article and you will find all the above tips quite useful in protecting your iPhone from hackers.", "label": 1}
{"text": "Press Release 98-035\nGrowth of Information Technology Is Changing the Face of the Economy\nS&E Indicators '98 Says IT Likened in Scope to Industrial Revolution\nJuly 1, 1998\nThis material is available primarily for archival purposes. Telephone numbers or other contact information may be out of date; please see current contact information at media contacts.\nThe impact of new information technologies (IT) has been pervasive on society but productivity benefits are more difficult to pin down, according to a new National Science Board (NSB) report to Congress, Science and Engineering Indicators 1998.\nThe NSB report notes a tremendous upward demand for employment in computers and data processing across a wide range of industries. These skills are increasingly in demand by manufacturing, service and other industries that are modernizing their processes.\nThe report also notes recent studies indicating that the impact of IT is mixed, saying there are measurable payoffs in productivity, but that IT has diffused unevenly throughout the economy. Its effects, therefore, are often difficult to measure precisely.\nHighlighting the challenge, says the NSB in a special chapter on IT, is the difficulty in tracking the rapidly developing and changing technologies that are permeating all sectors of the economy.\nNevertheless, the use of IT is widespread, says the report, and is contributing to the retooling of the U.S. economy.\n\"We've entered a new era. Information technology is shaping our economy and many elements of our society,\" Claudia Mitchell-Kernan, NSB chair of the Science and Engineering Indicators subcommittee, explains. \"Our high-speed, high-volume information systems need to enhance our international competitiveness, global research capabilities and our personal well-being.\"\nIndicators reports that in education, there has been a large jump in the use of computers and related technological tools. However, schools with a large percentage of economically disadvantaged students have one-third to three times less access to these technologies than schools attended by primarily white or nondisadvantaged students. In addition, disadvantaged students can't compensate in their homes for this lack of access in schools, the report points out. African Americans and Hispanics had (in 1993) about half as much ownership of home computers as whites. Research, meanwhile, indicates that when the \"informationally disadvantaged\" are given access to computers and the Internet, they use these resources effectively for self-empowerment.\nThe URL for the web version of Science and Engineering Indicators 1998 is:\nFor other press releases about S&E Indicators, see:\n- PR 98-34 Upswing in Industrial R&D Creating Positive Economic Benefits: New data released in S&E Indicators 1998\n- PR 98-36 Science and Engineering Indicators '98 Survey Shows Americans' Interest in Science Grows: But actual understanding of scientific terms and concepts still lags\nWilliam C. Noxon, NSF (703) 292-8070 email@example.com\nJennifer Bond, NSF (703) 292-8777 firstname.lastname@example.org\nThe National Science Foundation (NSF) is an independent federal agency that supports fundamental research and education across all fields of science and engineering. In fiscal year (FY) 2012, its budget was $7.0 billion. NSF funds reach all 50 states through grants to nearly 2,000 colleges, universities and other institutions. Each year, NSF receives about 50,000 competitive requests for funding, and makes about 11,500 new funding awards. NSF also awards about $593 million in professional and service contracts yearly.\nGet News Updates by Email\nUseful NSF Web Sites:\nNSF Home Page: http://www.nsf.gov\nNSF News: http://www.nsf.gov/news/\nFor the News Media: http://www.nsf.gov/news/newsroom.jsp\nScience and Engineering Statistics: http://www.nsf.gov/statistics/\nAwards Searches: http://www.nsf.gov/awardsearch/", "label": 1}
{"text": "The Birth of the Virtual Machine, a Quest for Hybrid CAD29 May, 2008\nArchimedes Project and Synchronous Technology take center stage at Siemens event.\nArchimedes, a classical mathematician who died 2,200 years ago, is about to become part of the PLM (product lifecycle management) lexicon.\nSoon after the ink dried on its acquisition of UGS, Siemens' Automation & Drives (A&D) division began working on a project dubbed Archimedes. Discussing it in the company's internal publication titled Pictures of the Future, publisher Arthur F. Pease wrote, \"Siemens' recent acquisition of UGS has given its [A&D] Group ... the tools to merge the real and virtual worlds of production\" (\"Factories of the Future — UGS and Siemens,\" Fall 2007). For more on the Archimedes Project, read \"Event Report:  UGS Media/Analyst Conference.\"\nAt Siemens' 2008 media and analyst briefing, which took place in Boston, Massachusetts, in May, Michael Weyrich, leader of new-generation business at Siemens A&D, introduced tangible evidence of Archimedes in operation. By marrying UGS's NX to Siemens' motion-control capabilities, Siemens has developed the Virtual Machine, which connects CAM (computer-aided manufacturing) to CNC (computer numerical control).\nCNC Behavioral Science\nGenerally, a CAM program simulates the machining operations by animating the machine's movements based on kinematics, the mechanical motions predicted based on physics. However, in the physical world, the CNC operator uses a controller attached to the machine to perform the required tasks.\n\"In the Virtual Machine, NX takes into account the unique machine-tool characteristics of the real machine's controller,\" Weyrich said, \"so information like how a machine is configured on a certain shop floor, for example, will be part of the simulation.\"\nWith Siemens' Virtual Machine, the simulation process is driven not only by kinematics but also by the motion algorithms used by an actual 840D controller. Therefore, it is expected to faithfully depict the cutting conditions, axis movements, collisions, work piece geometry, and motion behaviors of the machine tools equipped with a Siemens 840D control.\nThe virtual machine can physically be found at INDEX, a CNC machine supplier headquartered in Esslingen, Germany. It is now part of what the company delivers to its customers along with the physical hardware.\nThe Virtual Machine, a use-case scenario derived from Siemens' Archimedes Project, produces accurate simulation of machining operations by incorporating the controller's algorithm.\nWolfgang Schloegl, Siemens' digital factory team leader, followed Weyrich's virtual machine presentation with another that focused on the virtual factory, or E4DF (engineering for digital factory). In his view, the major shortcomings in today's engineering are:\n- unsynchronized processes\n- redundant data entry, processing, and storage\n- insufficient validation of engineering results\nHis recommendation? Use Siemens' SIMATIC Automation Designer software along with Teamcenter as the data backbone. In its online literature promoting SIMATIC's openness as an advantage, Siemens states, \"The previously separate worlds of mechanical components, electrical systems, and automation are now represented transparently in one plant structure. This guarantees data consistency. The result is that existing software tools can easily be used again and combined with SIMATIC Automation Designer.\"\nWith SIMATIC, CAD diagrams form the basis for plant layout. Once read into SIMATIC, they become the touchstones for configuring the production process. \"The product has been field-tested for 1.5 years,\" said Schloegl. \"It's now ready in a way that we can sell it.\"\nBy the end of this month, SIMATIC 3.0 should be available, along with E-CAD Extension Packages for automatically generating and integrating circuitry design. Schloegl revealed that SIMATIC will begin using JT, a lightweight file format developed by UGS, for visualization of factory components in 2009.\nLive Rules Overrule Feature History\nSynchronous Technology, Siemens' answer for combining freeform and parametric modeling, had been in incubation in a development lab at UGS before the acquisition. \"When Siemens found out we had been working on this, they were delighted,\" said Chuck Grindstaff, Siemens' executive vice-president of products. With Siemens' contribution to the R&D budget, Synchronous Technology swiftly made its debut last month (for more information, read \"Siemens Breaks Free from History.\"\nIn the first quarter of 2008, three history-based CAD vendors — Dassault, PTC, and Siemens — unveiled their own solutions that allow CAD users to employ a mix of modeling approaches. In February, PTC introduced a new version of Pro/ENGINEER that incorporates certain freeform-modeling features from CoCreate (acquired by PTC in October 2007). In April, Dassault previewed CATIA Live Shape, a freeform-modeling module for CATIA users.\nEvan Yares, a CAD industry veteran in attendance at the Siemens event, said that what CAD vendors are pitching as freeform modeling may be described more accurately as \"feature-imprint modeling.\"\nUnlike the freeform-modeling methods found in software programs widely used by animation artists and game developers (such as Autodesk 3d Studio Max or Maya), the method now making its way into CAD packages relies on the recognizable topology of mechanical features (holes, tubes, and shafts) and makes every effort to retain the surface and geometric relationships. Therefore, Yares argued, the deformation is based on the existing imprint of a feature.\nSynchronous Technology relies on Live Rules, a set of algorithms for detecting and recognizing standard mechanical features, to let the software intelligently reshape the affected geometry in response to a user's pushes, pulls, and dimension-driven changes. Live Rules can be disabled when a user wants to make an unorthodox change that might break the generally accepted associativities and constraints in a feature. Conversely, users also have the option to place locked constraints (or parameters) on a model.\nIn the demonstration, Dan Staples, director of Solid Edge product development, demonstrated how one can use Synchronous Technology to edit a Solid Edge assembly containing a SolidWorks part and an Inventor part. The new releases of NX and Solid Edge (dubbed Solid Edge with Synchronous Technology, or SEST for short) both feature Synchronous Technology.\nSiemens promotes upcoming releases of NX and Solid Edge with Synchronous Technology as CAD tools with the potential to offer dramatically higher productivity in multi-CAD environments.\nNX 6 features Product Template Studio, a way to publish a simplified parametric model from a complex part as input. The tool is designed to let users automatically generate a brand new part based on an existing one through guided input fields, bypassing the need to directly interact with the geometry.\nWith NX 6, using the mix-mesh approach, a user can prepare a mesh model for analysis with different mesh densities for different regions. The tool is particularly useful when dealing with products with a mix of simple and complex curvatures or a combination of thick and thin surfaces.\nThroughout the last several years, digital prototyping has become the new mantra for CAD and PLM vendors. It's an ambitious vision, wherein everything taking place on the factory floor — from the tilt of an automatic drilling arm to the posture of an assembly worker — is simulated with digital replicas first. Siemens' progress report on the Archimedes Project proves that having a hardware giant for a parent company can be an advantage.\nAutodesk Technical Evangelist Lynn Allen guides you through a different AutoCAD feature in every edition of her popular \"Circles and Lines\" tutorial series. For even more AutoCAD how-to, check out Lynn's quick tips in the Cadalyst Video Gallery. Subscribe to Cadalyst's Tips & Tricks Tuesdays free e-newsletter and we'll notify you every time a new video tip is available. All exclusively from Cadalyst!", "label": 1}
{"text": "First, we will investigate our observation of non-deterministic behavior of malicious web servers. Repeated interaction with a malicious web server did not consistently yield malicious behavior. Analysis of MPack/ IcePack exploitation kits allows us to - at least partially - explain this behavior.\nFigure 3 - MPack Administrative Interface\nMPack can be configured via the $BlockDuplicates option to only deliver an attack to a user it hasn't seen before. If this “IP tracking functionality” is enabled, MPack exectutes the CheckAddUser function shown in Figure 5 . The user's IP address with the browser identifier are hashed (line 08) and stored in the MPack database (mysql or txt file) (lines 48-49 and 23-25). Upon repeated visits by the user with the same IP address and browser identifier, the hash is once again generated and checked for existence in the MPack database (lines 15 and 29, 30, 41-42). If it is found, an “unhappy” emoticon is displayed and no attack is delivered (line 17 and 44). (Similar functionality exist in IcePack .)\nThe CheckAddUser function explains why certain URLs are malicious and then permanently go dormant. However, this would not explain URLs that exhibit malicious behavior, temporarily go dormant (maybe one or two requests), but then exhibit malicious behavior once again; this is a pattern we observed in our study. To explain this observation, we turn to an additional attack technique of Fast-Flux networks, which we more extensively describe in our Know Your Enemy: Fast-Flux Service Networks paper. Fast-Flux networks are networks computer systems with public DNS records that are constantly changing. If a malicious URL is part of such a network, it might resolve to actual different physical machines, which will only have access to their local IP tracking database. If a client honeypot accesses the same URL repeatedly, it might actually interact with several physical machines that each trigger initially, but then permanently go dormant. From the client honeypot's view, however, it appears as if it is sporadically attacked.\nFigure 4 - CheckAddUser Function", "label": 1}
{"text": "The Internet should add convenience, not headaches. From step-by-step instructions to helpful tips, we'll help you install your equipment, troubleshoot problems, and get the most out of your online experience – minus the migraine.\nProtect Yourself from Spam\nLast Updated: Mon, 18 Jul 2011 > Related Articles\nThis article provides general information about spam.\nHow Spammers Get Email Addresses\nSpammers use a variety of methods to gather email addresses, send their messages and cover their tracks. Sometimes they will send email from computers set up as email servers and configured specifically to send spam. They will also make use of computer virus programs, which enable them to use computers belonging to others to send the spam. Spammers generally get their address lists from several places. Searching public bulletin boards, web pages and newsgroups for valid email addresses is one common method. Preparing a list of common names (like jim, joe, jane...) then adding the @cox.net address to them is another. While it is nice to be a popular ISP, sometimes it makes Cox a bigger target for people sending spam than smaller regional ISPs.\nHow to Reduce the Amount of Spam Received\nHere are some tips for you to reduce the amount of incoming and outgoing Spam that you are experiencing:\n- Do Not Use Your Primary Email Address to Sign Up for Anything - Consider creating separate addresses that can be used for online purchases, chat rooms and other public postings. Many customers create a secondary email address for e-commerce, signing on to web sites, and entering sweepstakes.\n- Use a Unique Email Address - Select an address that is difficult for spammers to guess. Consider using long email address consisting of more than one word, as well as numbers and an underscore. Also, if chatting online, use a unique screen name that is not associated with your email address.\n- Do Not Unsubscribe From a Spammer's List - Some spam messages will include links for you to click on, such as a link that will “unsubscribe” you from the spammer's list. Once you click on the link, however, you have just told the spammer that your email address is a valid address, thus ensuring that you will receive thousands of additional spam messages. You should not use an “unsubscribe” link with a spam email, unless the email is from a company you trust.\n- Assume Mail from Unknown Senders is Spam -Friends and family do not typically spam you. If you receive an unsolicited commercial email (spam message), you may report it to the sender’s ISP. In order to do this you must first view the complete message header for the spam message to identify the source network, and then send a report to the network’s administrator. Some useful information on how to identify the correct data in the message header or within the message itself is available at http://www.xmarks.com/site/combat.uxn.com/.", "label": 1}
{"text": "On this episode, we talked about RAID and SSL.\nRAID stands for redundant array of independent disks. Companies requiring a decent backup solution, video editors, CAD designers and others use RAID. Today, we covered a few of the many standards available. You can do RAID set up with either 2, 4 or 6 hard drives.\nRAID 0: This is a striped array. Let’s imagine you have four hard drives, which are all 1 terabyte in size. If you put the drives into a RAID 0 array, then your computer will see the four hard drives as a big 4 terabyte hard drives. It also has the advantage of combining the speed of your hard drives to give you some super speedy goodness!. Should one of the four hard drives fail, then your data is gone, with only a small chance of getting the data back.\nRAID 1: This is a mirrored array. We have our four hard drives again. This means that you will have a copy of your data on all four hard drives. If a hard drive dies, then you can get a new hard drive, plug it in and tell your computer to copy the data to your new hard drive.\nRAID 0+1: This combines the speed of RAID 0 with the redundancy of RAID 1. This maybe good, but what if you don’t want to waste the storage space? This is where RAID 5 comes in\nRAID 5: essentially, RAID 5 will allow your data to be copied and split between 3 of the four hard drives. The fourth hard drive stores the information required to restore your data should a hard drive fail.\nRAID 5+hotspare: It has the functionality of RAID 5. Should one of the hard drives fail, then your computer can copy the data over from the other hard drives to a new hard drives.\nWindows and Mac already have software for setting up RAID built right into the OS. On linux, you have to download the software using apt-get.\nSSL stands for secure socket layer. It was developed by Netscape. It was the predecessor of TLS(transport layer security). It encrypts things such as usernames, passwords, addresses and other sensitive data.\nSSL certificates act as a passport that identifies a company or an individual. When using an internet browser, you will see a padlock icon in your browser’s status bar. In the address bar look for the prefix, HTTPS.\nSSL and TLS have both been implemented using open-source software, such as PolarSSL, CyaSSL, Open SSL, Gnu TLS and others.\nSSL can be set up in two ways, one-way SSL and two way SSL. With one-way SSL, the server must present a certificate to the client, but the client is not required to present a certificate to the server. The client must authenticate the server, but the server accepts a connection from any client. One-way SSL is common on the Internet where customers want to create secure connections before they share personal data. Often, clients will also use SSL to log on in order that the server can authenticate them.\nWith two-way SSL (SSL with client authentication), the server presents a certificate to the client and the client presents a certificate to the server. WebLogic Server can be configured to require clients to submit valid and trusted certificates before completing the SSL connection.\nTo get an SSL certificate, you need to go to companies like GoDaddy or domain.com. These companies will create and issue an SSL certificate. Tune in next time, when we cover CIsco’s iOS and SQL.\nSponsor:We thank CUBS the computer warehouse for all of their support. if they ask, tell them that the MHF Tech Network sent you.", "label": 1}
{"text": "According to the Kansas City InfoZine, at the American Association for the Advancement of Science's briefing on cyber security and the protection of U.S. infrastructure, University of Illinois computer science professor Carl Gunter said more efficient Internet security could improve the quality of living while reducing its cost.\nGunter said if more efficient Internet security techniques could be developed, assisted living programs, emergency response efforts and the cost of household electricity, among other fields, could be improved. Gunter described a scenario where a patient's medical information could be instantly transferred to hospitals and other health care providers from their homes. Such a system, which hinges on better Internet security, could take frequent, efficient readings of an individual's vital signs, which would be particularly helpful to sleep apnea and diabetes patients.\nIn a similar scenario, Gunter described how improved Internet security would allow for networked electrical meters, or \"smart meters,\" that automatically measure and report a household's electricity consumption, and because electricity is more expensive at certain times of the day, the smart meter would notify consumers of peak usage time, allowing people to \"shop for power.\"\nEmergency response networks would also benefit from improved Internet security, Gunter said, noting that the only communication system to withstand Hurricane Katrina was a surveillance camera network. However, Carnegie Mellon University's Software Engineering Institute senior staff member Howard Lipson cautioned that \"the Internet wasn't design to resist highly untrustworthy users. You can't be surprised when we apply all these high-level functions to the Internet, and there are security problems.\"", "label": 1}
{"text": "October 12th, 2001 11:38 AM\nOSI Security Concern\nI have a few questions based on the OSI model and security.\nI am no where near an expert in the topic, but have begun to closley study the open-systems interface face model, and have been very interested in what I have found.\nMy first question would be, to any one who may be willing to participate in this open-ended discussion... What security risks/issues are commonly associated with what layers?\nThus far, I have found that data encryption resides @ the Layer 6 (Presentation) layer. This concerns me. While this is data manipulation is done very early on the system building the data frames, it is consequently not recognized or 'decrypted' until very late on the recieving system, or the system that is 'un-packing' the information.\nI am interested in hearing if anyone is familiar with a Layer 1, or PHYSICAL device, that encrypts information @ lower layers, such as @ the bit level. If it were necessary for any computer to be able to recognize that a data 'group' was indeed a legitimate packet, then this device would not be able to be a layer 1 device, as fields, as well as data fields would be altered(processed) with the encryption algorithm. In this case, the device would need to be a physical, but 'thinking' device (i.e, a layer 2 device).\nHowever, if individual computers were configured with similiar or corresponding devices, then the header fields, as well as data fields, could necesarily be included in the encryption process, and only the computer(s) fitted with the appropriate physical mechanisms would be able to comprehend that these 'information groups' were even legitimate packets. Anyone else, (i.e., unauthenticated or remote users), would simply discard the information, and if used under some sort of connectionless (say, udp-like) standards, would move on, as if the data were never recieved.\nIf this were so, the only hurdle we would be facing now would be actually using this system in a switched, or rather, routing orientated network topology, as the router interfaces, using the example above, if not fitted properly, would not be able to comprehend the encrypted header fields, and would discard the information.\nPlease let me hear any thoughts one may have on what I have said.\n---....Loading: 1x 2x 3x", "label": 1}
{"text": "10 tips for protecting personal information\n1. Don’t give anyone your Social Security, credit card, or bank account numbers unless you know the source and/or have initiated the contact. If you are unsure, ask the person to send you a request by mail instead of asking for it over the telephone. Con artists working a scam can be very convincing.\n2. Don't just throw away papers that have important account or financial numbers listed on them. Tear up the papers or shred them. Thieves often go through the trash looking for intact bank account, credit card, etc. numbers so they can raid your accounts.\n3. Keep your credit card and ATM receipts in a safe place until you've paid the credit card bill or balanced your checkbook. Then tear up or shred them.\n4. Don't leave bill payment envelopes in a home mailbox for the mail carrier. Someone might take them. Instead, put your envelopes inside a postal mailbox.\n5. Reduce the circulation of your information through the mail. Stop receiving prescreened credit offers by calling 888-5OPTOUT (888-567-8688). You can also reduce direct mail marketing and telemarketing by contacting the Direct Marketing Association.\n6. Don't send your credit card number over the Internet unless you are sure the Web site is secured and your computer is protected by anti-virus, anti-spyware, firewall, and other security software. Keep your security software updated.\n7. Shred or tear up anything with your name, address, credit card information, or bank account numbers before putting it in the trash or recycle bin. This includes unused credit card offers.\n8. Don't get hooked by \"phishing.\" Scam artists looking to get personal information such as credit card numbers, bank account information, Social Security numbers, and other pieces of data send spam emails hoping to lure you into divulging this important information. If you get an unexpected email asking you to update or verify any important information, be careful. It might be a \"phisher\" trying to con you out of your personal information. For more information, visit www.phishinginfo.org.\n9. Review your credit card statements and telephone bills for unauthorized use. If you suspect fraud, call the company immediately.\n10. If you're a victim of identity theft, report the crime to the police immediately.", "label": 1}
{"text": "Data User Elements (DUE) is an important program within the European Space Agency (ESA). The program is conducted at the ESA Centre for Earth Observation in Frascati, Italy. DUE uses satellites to collect valuable data about the current state of the planet. The program is about demonstrating the usefulness of Earth Observation products and services to end users worldwide. DUE provides this data to scientists, governmental agencies, and private organizations around the world. The data is used for a myriad of purposes, including monitoring the environment, improving the accuracy of weather reporting, and assisting disaster relief agencies.\nAlthough much of DUE’s work is done by satellites, some of the program’s data storage and computing infrastructure is built on Amazon Web Services (AWS). DUE uses Amazon’s scalable Web storage, Amazon Simple Storage Service (Amazon S3), to house and retrieve its images and other end-user products. To manage its files within Amazon S3, the program utilizes a third-party tool based in s3fs, a FUSE filesystem.\nIn addition to Amazon S3, DUE is also using Amazon’s resizable computing environment, Amazon Elastic Compute Cloud (Amazon EC2), to execute a statistical system that examines the program’s service usages. DUE is using the third-party tool AWStat for its log analysis. In the future, the program hopes to expand its use of Amazon EC2 to include other remote sensing applications.\nDUE chose AWS because of its economical pay-as-you-go system, as well as its quick start-up. Jose Ramos, an Earth Observation computer systems engineer, says, “The implementation and deployment stages of our complete distribution and statistics system were unexpectedly quick and easy. It's typical to expect delays when procuring and installing new dedicated hardware, but AWS freed us from that worry and worked within our tight schedule.”\nDUE also benefits from the easy manner in which features can be scaled and customized with AWS. This ease-of-use prevents the program from having to hire an external entity to manage its infrastructure. Jose Ramos explains, “With AWS, we have a flexible infrastructure storage system for our data that can scale up to as much as we need. In addition, the solutions offered by AWS are simple to use, so we can manage them ourselves.”\nThe program reports that during peak usage, AWS helps DUE provide images and other products to over 50 thousand users around the world. This usage can equal 30 terabytes of information at one time.\nDUE plans to continue its partnership with AWS while it focuses on conducting its important mission to gather data about Earth. Ramos reiterates his enthusiasm for AWS, “Being able to implement everything in record time and forget about performance issues is a blessing. We love the ease of use and scalability of AWS.\"\nTo learn more, visit http://www.esa.int/ .\nAdded April 5, 2011", "label": 1}
{"text": "Phishing attacks are pretty cleverly designed, because they skip most virus checkpoints altogether and go for the true weak spot in human-computer interaction, the human. Lorrie Faith Cranor, a computer security researcher at Carnegie Mellon University, has been studying phishing attacks to identify new ways to fight them.\nSome of the things her research team has learned:\n- Users who are simply taught about phishing attacks don’t retain the info and keep falling for them, but users who are tricked into falling for a phishing attack first and then taught show far greater retention—it’s a “teachable moment” in the researchers’ terminology. (Idea: when phishers are caught, their punishment is to have them continue to phish but on behalf of government entities in order to create these “teachable moments.”)\n- Even when web browsers warned users they were on a phishing site, many ignored the warnings. People who used IE 7 were more likely to ignore warnings than people who used Firefox 2. You might assume this is because Firefox users are generally savvier computer users, but Cranor says the difference can be attributed to the clearer interface design of Firefox, where severe warnings stand out more dramatically than day-to-day warnings, so that users have a better chance of noticing them. (She says IE 8 has taken notice of this and improved its warning presentation.)\n- Antiphishing programs that rely on a combination of blacklists and heuristics are dramatically better at catching phishing sites immediately than those that rely on blacklists alone, which is crucial because many phishing sites are extremely short-lived:\nWe discovered that most of the blacklist programs caught fewer than 20 percent of the phishing sites when we tested them within minutes of receiving the URLs. After five hours, most could detect about 60 percent of the active phishing sites. The programs that used a combination of blacklists and heuristics fared much better, with one detecting almost 90 percent of phishing attacks from the beginning of our test.\nSo now you know what to look for in an anti-phishing program, but wait there’s more! If you’re bored this weekend and want to play a barely-entertaining game that will teach you more about phishing, check out Anti-Phising Phil by grad student Steve Sheng. You’ll have to catch worms with “good” urls and avoid phishing worms. We found it informative, but maybe a little less exciting than, say, Halo 3. Hmm, maybe save the link for Monday morning when you’re back at work and bored.\n“How to Foil “Phishing” Scams” [Scientific American]", "label": 1}
{"text": "Note: This message is displayed if (1) your browser is not standards-compliant or (2) you have you disabled CSS. Read our Policies for more information.\nIn these new and challenging times, we as citizens have a duty to help protect our communities. We can help provide safety and security in Indiana by remaining vigilant and reporting unusual behavior or events immediately.\nListed below are eight signs of terrorism that may help detect potential terrorist acts. Indicators of a potential event may occur weeks, months or even years apart. Documenting details of events or behaviors witnessed is important, no matter how small or insignificant they may seem.\nTerrorists will likely observe a chosen target during the planning phase of an operation. They do this to determine the strengths, weaknesses and number of emergency personnel that may respond to an incident. Suspicious actions during this phase may include someone recording or monitoring activities, drawing diagrams or making notes on maps, using vision-enhancing devices, or having possession of floor plans or blue prints of places such as high-tech firms, financial institutions, or government facilities, including military installations. Routes to and from the target are also usually established during the surveillance phase.\nA second sign, inquiries, entails attempting to gain information about a place, person, or operation pertaining to the target. Terrorists may attempt to elicit information about a critical infrastructure such as a power plant, water reservoir, maritime port, military base, bridge or tunnel by making unusual inquiries. They may inquire about usage and operations. Additionally, they may attempt to place people in legitimate employment at key locations to monitor day-to-day activities and gather detailed knowledge in order to make their mission or scheme more effective.\nTerrorists may also test a target’s security to gather data. To do this, they may drive by the target, moving into sensitive areas and observing security or law enforcement response. They are likely assessing how long before personnel respond to a security breech or the routes responders take to a specific location. Terrorists may also attempt to penetrate physical security barriers or procedures in order to assess strengths and weaknesses.\nAlthough this is a tough sign to pick up on, it is one of the most important. Without funding, terrorist activity will come to a dramatic halt. Terrorists are very creative in raising, transferring, and spending money they come in contact with. Some scenarios to look for include: (1) credit card fraud, (2) defrauding the elderly, (3) people asking for donations to legitimate organizations but in peculiar ways, and (4) very large amounts of cash used in business transactions.\nTerrorists may purchase or steal explosives, weapons, ammunition, or attempt to store harmful chemical equipment. In order to gain easier entrance to a secured area, they may also try to acquire uniforms, equipment or identification of first responders, including military personnel. Other items they may try to obtain include flight passes, flight manuals, passports or other pieces of identification. If they are unable to steal these types of things, they may attempt to create counterfeit copies.\nProfiling individuals is wrong, however, profiling behaviors may indicate suspicious behavior. Sometimes suspicious people just “don’t belong” or a behavior seems out of place. This may include a person in a workplace, building, neighborhood or business establishment that does not fit in because of demeanor, language usage or unusual questions they ask.\nBefore executing the final operation or plan, terrorists may engage in a practice session, or “dry run,” to work out flaws or unanticipated problems. Although they normal conduct multiple practice sessions at or near the target area, a “dry run” may be the heart of the planning stage of a terrorist act. During a “dry run,” terrorists may monitor police radio frequencies and record emergency response times.\nThe deploying assets or getting into position stage is an individual’s last chance to alert authorities before the terrorist act occurs.", "label": 1}
{"text": "This summer has seen a great number of data breaches all over the world. Some of these are high profile, like Epson Korea and the rash of Sony hacks. Some are small, like an incident in Louisiana where copies of confidential documents were found on a city street. And some just make you shake your head, like the play book of the Green Bay Packers being scattered all over the street.\n46 states in the US have data breach notification laws that address when personally identifiable information (PII) is breached. Many countries outside the US have data breach notification and security laws that cover similar circumstances, with some of the strongest in the EU. According to the Privacy Rights Clearinghouse, since 2005 there have been about 2600 data breaches made public affecting 535 million records – the real numbers may be higher, since laws differ on when to notify affected customers.\nCurrent US federal law requires a business or organization to notify a customer of a data breach only in limited circumstances. The law focuses on social security numbers, financial information, health data and other unique data that a criminal could use to steal your identity or money; remember that data breaches are primarily about making money. It doesn’t include names, phone numbers, email addresses and other obvious information.\nThe US Congress is looking to create more comprehensive legislation, since state laws are not consistent and may conflict when interstate commerce is affected. There are a number of pending data breach and security bills going through Congress. The White House also has a proposal on cybersecurity that addresses data breaches.\n- Data Accountability and Trust Act (DATA)\n- SAFE Data Act\n- Data Security and Breach Notification Act\n- Personal Data Privacy and Security Act\n- White House Cybersecurity Proposal\nThe bills and proposals focus on protecting data and specifying how and when to notify people when information is compromised. Some of the bills talk about identifying and fixing potential data security vulnerabilities. This includes determining what personal data to keep and for how long. This data minimization provision would mean that a business should retain only data needed for a legitimate business purpose and dispose of anything else as soon as possible. This would make it less likely that PII is compromised.\nIt is important that these proposed laws focus on breach notification, but it’s more important to encourage practices to reduce the risk of a breach in the first place. As has been proven over and over again, this involves people, process and technology. Developing processes and procedures and training people on using them is just as critical as the technology. You can have the greatest technology in the world, but if it’s not used properly or people ignore it, it’s worthless.\nConfidential data is typically in two places: databases and documents. Most database management systems can encrypt the data inside the database, which lends a level of protection to the information. For organizations dealing with customer data, it’s not just a matter of protecting privacy but also complying with regulations such as the Payment Card Industry Data Security Standard (PCI DSS).\nIt’s important to protect data inside a database, but increasingly the vulnerabilities come from information stored in documents. Whether you are in Healthcare and worried about medical records or an attorney worried about your client’s will, documents are your lifeblood. The best way to reduce the risk of a data breach from a document is using persistent document security. This encrypts a document and lets you control who can access the information inside it. The security goes with the document and is just random characters to anyone who isn’t authorized to use it. Most data breach legislation says that if data is encrypted, there is no need for notification if it is lost or stolen. The information is not accessible, so there was technically no breach.\nIt might be some time before the US government finalizes data breach and security legislation. Rather than waiting around, you can protect important information now. Determine what confidential information is in databases and documents and apply the appropriate technologies and processes to ensure it’s safety. You don’t want to fiddle while you are vulnerable.\nPhoto credit Fresh & Easy Buzz", "label": 1}
{"text": "Researchers: Password Crack Could Affect Millions\nA well-known cryptographic attack could be used by hackers to log into Web applications used by millions of users, according to two security experts who plan to discuss the issue at an upcoming security conference.\nThu, July 15, 2010\nIDG News Service — A well-known cryptographic attack could be used by hackers to log into Web applications used by millions of users, according to two security experts who plan to discuss the issue at an upcoming security conference.\nResearchers Nate Lawson and Taylor Nelson say they've discovered a basic security flaw that affects dozens of open-source software libraries -- including those used by software that implements the OAuth and OpenID standards -- that are used to check passwords and user names when people log into websites. OAuth and OpenID authentication are accepted by popular Web sites such as Twitter and Digg.\nThey found that some versions of these login systems are vulnerable to what's known as a timing attack. Cryptographers have known about timing attacks for 25 years, but they are generally thought to be very hard to pull off over a network. The researchers aim to show that's not the case.\nThe attacks are thought to be so difficult because they require very precise measurements. They crack passwords by measuring the time it takes for a computer to respond to a login request. On some login systems, the computer will check password characters one at a time, and kick back a \"login failed\" message as soon as it spots a bad character in the password. This means a computer returns a completely bad login attempt a tiny bit faster than a login where the first character in the password is correct.\nBy trying to log in again and again, cycling through characters and measuring the time it takes for the computer to respond, hackers can ultimately figure out the correct passwords.\nThis all sounds very theoretical, but timing attacks can actually succeed in the real world. Three years ago, one was used to hack Microsoft's (MSFT) Xbox 360 gaming system, and people who build smart cards have added timing attack protection for years.\nBut Internet developers have long assumed that there are too many other factors -- called network jitter -- that slow down or speed up response times and make it almost impossible to get the kind of precise results, where nanoseconds make a difference, required for a successful timing attack.\nThose assumptions are wrong, according to Lawson, founder of the security consultancy Root Labs. He and Nelson tested attacks over the Internet, local-area networks and in cloud computing environments and found they were able to crack passwords in all the environments by using algorithms to weed out the network jitter.", "label": 1}
{"text": "The recent, well-publicized cyberattack on Google was just the latest skirmish in a long war. And like most long wars, this one features an arms race, as hackers seek out new security holes, and web site administrators try to close them.\nSystems for detecting attacks against networked computers are commercially available, and academic and industrial researchers are constantly improving them. But when a web site is under attack, its only viable defense may be to take its servers offline, which, in the short term, can cost it money in lost revenue and productivity and, in the long term, could hurt its credibility. Indeed, knocking a site offline may be an attackers' sole intention.\nMIT researchers have developed a system to keep web servers -- or, for that matter, any Internet-connected computers -- running even when they're under attack. The work was funded largely by DARPA, and in a pair of tests whose thoroughness is unusual in academia, DARPA hired a group of computer security professionals outside MIT to try to bring down a test network protected by the new system. In both tests, says Martin Rinard, the professor of electrical engineering and computer science who led the research, the system exceeded all the performance criteria that DARPA set for it.\nThe MIT system was developed by a host of researchers, including not only Rinard but Jeff Perkins, a research scientist at MIT's Computer Science and Artificial Intelligence Lab, Postdoctoral Fellow Stelios Sidiroglou-Douskos and Michael Ernst, who has since moved to the University of Washington. During normal operation, it monitors the programs running on an Internet-connected computer to determine their normal range of behavior, and during an attack, it simply refuses to let them wander outside that range.\nTo take a simple example, suppose that a program running on a web server routinely stores data in one of two memory locations -- call them A and B. During an attack, malicious code tries to trick the program into storing data at location C instead. The MIT system won't let it: instead, it sends the data to either location A or location B.\nOf course, the data may not be of a type that belongs at either of those locations. And the system will modify behaviors that could be even more disruptive than data storage. But in sites with large banks of servers, the MIT system gets several chances to find the best response to an attack. If storing at location A causes one server in the bank to crash, the MIT system will tell the other servers to store it at location B, instead.\n\"The idea is that you've got hundreds of machines out there,\" Rinard says. \"We're saying, 'Okay, fine, you can take out six or 10 of my 200 machines.'\" But, he adds, \"by observing what happens with the executions of those six or 10 machines, we'll be able to deploy patches out to protect the rest of the machines.\" The entire process of recognizing an attack, testing a number of countermeasures and deploying the most effective ones can take a matter of seconds.\nIn the first of DARPA's two field tests, engineers at a computer security firm -- the \"Red Team\" -- were given the code for the MIT defense system. (In the real world, a company that marketed such a system would make every effort to keep its code secret, but Rinard says that it's standard practice in the security field to consider the worst-case scenario.) The Red Team had several months in which to devise attacks against a hypothetical network protected by the system. During the test itself, no malicious code was allowed to execute on the protected computers, and in 70 percent of cases, the MIT system kept the applications running on those computers from going down. DARPA also set performance goals for the system, such as the amount of extra processing power it required, and the extent to which it altered the applications' normal operation. In all cases, the system was well within DARPA's prescribed limits.\nThe first red-team exercise considered cases in which hackers tried to infect computers with malicious code, and the MIT researchers presented the results of the test at the Association for Computing Machinery's Symposium on Operating Systems Principles last fall. A second Red Team exercise, testing an updated version of the defense system that the MIT researchers developed together with defense contractor BAE Systems, concluded at the end of January. That test evaluated the system's ability to handle a different kind of attack, which seeks to circumvent security checks that web applications typically perform to ensure that users have permission to access protected information. Although the researchers are still sorting through the data from that test, Sidiroglou-Douskos says that the system's success rate in keeping applications up and running rose from 70 percent to 90 percent.\nIn a report entitled Automatically Patching Errors In Deployed Software, the Red Team present ClearView, a system for automatically patching errors in deployed software. ClearView works on stripped Windows x86 binaries without any need for source code, debugging information, or other external information, and without human intervention. In the Red Team exercise, ClearView survived attacks that exploit security vulnerabilities. A hostile external Red Team developed 10 code-injection exploits and used these exploits to repeatedly attack an application protected by ClearView. ClearView detected and blocked all of the attacks. For seven of the 10 exploits, ClearView automatically generated patches that corrected the error, enabling the application to survive the attacks and successfully process subsequent inputs. The Red Team also attempted to make ClearView apply an undesirable patch, but ClearView's patch evaluation mechanism enabled ClearView to identify and discard both ineffective patches and damaging patches.\nAngelos Keromytis, an associate professor of computer science at Columbia University, who works on related techniques for combating cyberattacks, says that the MIT approach is \"very original,\" but cautions that Web developers may be reluctant to adopt it anytime soon. \"They're wary of a system that changes another system automatically,\" Keromytis says. \"When they manually make changes to their systems, they break them, so they think that automatically doing it is going to be worse.\" Keromytis points out, however, that while DARPA has run a number of red-team exercises evaluating new technologies in a range of areas, \"This is probably one of the most successful exercises that I have seen.\" The mere fact that DARPA was willing to spend so much money testing the system, Keromytis says, indicates that \"they think it's close enough to a rough prototype that works, which is more than one can say for most academic research.\"", "label": 1}
{"text": "The term \"computer virus\" is sometimes used as a catch-all phrase to include all types of malware. Malware includes computer viruses, worms, trojans, most rootkits, spyware, dishonest adware, crimeware, and other malicious and unwanted software, including true viruses.\nComputer viruses are one of the most common threats to a computer. Any online computer can be attacked by viruses and other online threats. A virus infected computer can transmit the viruses to other connected computers in a network.\nViruses can harm your computer in a variety of ways - corrupt data, corrupt the hard disk, delete the operating system files and crash the system.\nSophos Antivirus is the corporate antivirus application provided and supported at the University of Newcastle.\nAs part of the on campus Managed Operating Environment (MOE), Sophos is automatically installed on all University owned computers.\nThe Sophos campus site licence also covers installation on computers owned by staff and students of the University of Newcastle.\nGo to our download page\nVisit the Sophos Antivirus website for further details about antivirus protection, including information on 'Simple steps to defend against viruses, spyware and adware'.", "label": 1}
{"text": "Cyber-Security Pros Create “Frankenstein” Monster\nPeter Suciu for redOrbit.com – Your Universe Online\nIt’s alive! Well, not quite, but UT Dallas computer scientists have created a new software that helps develop defense against new kinds of attacks, and in essence it is a monster of sorts.\nThe UT Dallas team, headed by Dr. Kevin Hamlen, associate professor of computer science, created software that can cloak itself as it steals and reconfigures information in a computer program. But Hamlen and doctoral student Vishwath Mohan didn’t create this software with criminal intention.\nInstead the software was designed as a way to stay ahead of cyber attacks by essentially being able to act like its own cyber threat. The result is a software program “Frankenstein” – named because of the potentially destructive nature of this technology, which is in keeping with the monster-creating scientist in Mary Shelley’s 1818 novel Frankenstein (also known as The Modern Prometheus).\n“Shelley’s story is an example of a horror that can result from science, and similarly, we intend our creation as a warning that we need better detections for these types of intrusions,” said Hamlen to the University of Texas at Dallas News Center. “Criminals may already know how to create this kind of software, so we examined the science behind the danger this represents, in hopes of creating countermeasures.”\nThe irony of course is that “Frankenstein” is in fact the scientist in the nearly two-centuries old novel, not the monster itself. Whether this fact is lost on Hamlen is unclear.\nWhat is clear is that Frankenstein the program is not in fact a virus at all, but rather it could provide cover for an actual virus or another type of malware. Antivirus software typically works by figuring out the pattern of change a virus creates on a machine, and malware typically mutates as it jumps from machine to machine.\nFrankenstein can provide a way to evade the scanning mechanism, by taking code from the programs that are already on a computer and re-purpose it.\n“We wanted to build something that learns as it propagates,” Hamlen added . “Frankenstein takes from what is already there and reinvents itself. Just as Shelley’s monster was stitched from body parts, our Frankenstein also stitches software from original program parts, so no red flags are raised. It looks completely different, but its code is consistent with something normal.”\nHamlen and his team are working to aid government counter terrorism efforts by providing a cover to infiltrate terrorist computer networks. This type of so-called cyber warfare is apparently on the rise, with various malware being used in recent months. The most notable is the so-called “Shamoon” malware attack, which took out a variety of oil industry computers.\nThat attack is now being blamed on hacktivists, especially as the code in the software reportedly featured amateurish coding errors. But earlier this year Iran’s nuclear energy facilities were hit with the Stuxnet malware, which is believed to have originated in Israel as a way to ensure that Iran couldn’t develop nuclear weapons.\nThe question is whether this type of malware could ever get out of control? For that we need only look to Cornell University student Robert Tappan Morris, who created the now notorious “Morris Worm,” in 1988. This was the first computer worm distributed on the Internet, and Morris maintained that it wasn’t designed to cause damage but rather determine the size of the Internet.\nA coding error – a critical error at that – transformed the worm and created a denial of service attack, that reportedly took down 6,000 major UNIX machines.\nOf course Frankenstein the scientist didn’t set out to create a monster either.", "label": 1}
{"text": "People use weak password practices to secure critical information. Weak password practices include using the same password for multiple systems regardless of the value of the asset, dictionary words, short phases and keeping the same passwords for extended periods of time. For example, it’s common to find a password on a non-critical asset such as a PlayStation 3 be the same as a person’s bank account login.\nThe more information an attack knows about your password profile, the more likely they will crack your password. For example, a policy of “6-10 characters with one upper case letter and special character” actually helps an attacker reduce the target space meaning passwords are weaker with the policy. If an hacker captures a password for another system and notices a formula such as ‘<dictionary word>’ followed by ‘<3 numbers>’, it helps the attacker prepare a dictionary attack (utilities such as Crunch makes this easy). Any password shorter than 10 characters is an easy target to brute force attack based on today’s system process power.\nHere are some tools that hackers can use to crack your passwords.\nJohn the Ripper is an old school yet powerful password cracking utility. It has several types of engines that can crack different types of passwords including encryption and hashes. John can detect most hash types (about 90% accurate) and generate matching hash outputs to map back to auto generated passphrases Attackers like John the Ripper because it’s very customizable\nHashcat is a password cracking utility. Hashcat is multi-thread tool meaning it can handle multiple hashes and password lists during a single attack session. Hashcat offers many attack options such as brute-force, combinator, dictionary, hybrid, mask and rule-based attacks\nOphcrack is a Windows password cracker based on rainbow tables (Rainbow tables are pre-computed hash tables). Ophcrack can import hashes from a variety of formats including dumping directly from the SAM files of Microsoft Windows.\nOphcrack Cracking Hashes\nFindmyhash is a python script which uses a free online service to crack hashes. Findmyhash will analyze against multiple website Rainbow tables.\nCrunch is a tool used to generate password lists. This can be extremely helpful if you are able to gather intelligence on how your target creates passwords. For example, if you capture two passwords and notice the target uses a phase followed by random digits, Crunch can be used to quickly generate a list of that phrase followed by all possible random digits. Perfect tool for defeating company password policies!\nCrunch output. List of all combinations of “pass” and two numbers\nAn alternative to breaking a Windows password is completely bypassing it. Chntpw is a software utility that can reset or remove a Windows passwords. This gives a hacker with access to your Microsoft Windows SAMs file the ability to obtain Administration privileges.\nThere are many tools available to break weak passwords. Best practices is using a password longer than 10 characters (having a repeated character at the end even helps!), don’t use dictionary words, change your password periodically, don’t use the same passwords for secure and non secure sources and don’t use a computer that accesses sensitive data for personal use (IE same system for Facebook and configuring routers). I suggest using the first letter of each word of a long sentence so you can remember the password yet the output is random. Hope this helps. All tools shown are free and available on BackTrack / Kali.", "label": 1}
{"text": "Quantum Attacks on Public-Key Cryptosystems\nThe cryptosystems based on the Integer Factorization Problem (IFP), the Discrete Logarithm Problem (DLP) and the Elliptic Curve Discrete Logarithm Problem (ECDLP) are essentially the only three types of practical public-key cryptosystems in use. The security of these cryptosystems relies on the three infeasible number-theoretic problems; no polynomial-time algorithms exist for these three problems. However, quantum polynomial-time algorithms for IFP, DLP and ECDLP do exist, provided that a practical quantum computer exists.\nQuantum Attacks on Public-Key Cryptosystems introduces the basic concepts and ideas of quantum computing and quantum computational complexity. The book discusses quantum algorithms for IFP, DLP and ECDLP, based on Shor’s seminal work. It also presents some possible alternative post-quantum cryptosystems to replace the IFP, DLP and ECDLP based cryptosystems.\nThis book is intended for graduate-level students and researchers in computing science, mathematics and digital communications as a second text or reference book. Cryptographers and professionals working in quantum computing, cryptography and network security will find this book a valuable asset.", "label": 1}
{"text": "This is a really interesting question. Cryptography, I think, is shrouded in uncertainty. History is riddled with instances where the world 'knew' that their method of encryption was completely secure, only to discover years later that wasn't the case. Usually once they were in jail, or the war was over already.\nYou see.. Eve (the nickname we give to the person trying to evesdrop in Cryptography http://en.wikipedia.org/wiki/Alice_and_Bob), is at an advantage if she knows how to decrypt a message if Alice and Bob don't know she can. Because they will continue to communicate while she eves drops.\nWhile a little out of my depth, people are well into the realms of Quantum Cryptography. Which as Simon Singh explains in his book 'The Code Book', will really blow most currently known encryption methods out of the water. Even if we were to simplify this, hackers are now using cloud architecture to increase computing power massively to decrypt information.\nYou only have to look at the competitions held at conventions like Defcon every year where the competitors seem to have machines and resources 10 times what they had last year :)\nYou could possibly argue, that as time has gone by code breaking has become just as much about computing power as it has about the method of decryption itself. I.e. it doesn't take a computer to break the Casesar Cipher (http://en.wikipedia.org/wiki/Caesar_cipher) but you better hope you have some computer power to break say, MD5 or DES.\nIn that sense, it's hard to answer what the most secure method of communicating is right now.. We can't be 100% safe in the knowledge that publically known encryption methods can't be broken.\nSo how can we securely communicate in the real world? Well.. I think we need to consider the very first communications.\nAssuming it's true that, given enough computing power, AES256 can be broken.. commonly considered 'military grade' encryption, I think we need to focus on other means of being safe. I think that is in the initial communication. If you assume we're utilising public key bases ideologies, once each person has the key, they need only send encrypted messages without the key. Some communications lend themselves well to that, I think.\nPGP encryption is good I think. Because you can physically pass the key on a piece of paper, memorise it, which you can later burn, for example.\nI quite like OCR (http://www.cypherpunks.ca/otr/) which is similar but also integrates with a few instant messaging programs.\ntl;dr ultimately nothing will always be secure, if trends in history prevail. But something where you can share a key and never repeat it out loud is possibly about as good as you can get right now.\np.s. i'm no expert. Just sharing what I know :)", "label": 1}
{"text": "Huge New Hydrogen-Powered Spy Drone Takes Test Flight\n(EWARDS AIR FORCE BASE, Calif.) -- A new unmanned surveillance drone that can stay aloft for four days at a time and has a wingspan bigger than a 757 successfully completed its first test flight over California's Mojave Desert, though it sustained minor damage on landing.\nBoeing's Phantom Eye drone, which is powered by liquid hydrogen, flew for less than half an hour at 4,000 feet before touching down on a dry lake bed at Edwards Air Force Base near Bakersfield. The landing gear dug into the ground on landing, causing minor damage.\nMost surveillance drones currently in use in the ongoing U.S. drone war against al Qaeda and the Taliban can stay in the air for a maximum of 40 hours without refueling. The Phantom Eye's unique liquid hydrogen propulsion system is meant to keep the spy plane aloft for up to four days at altitudes of 65,000 feet.\n\"This flight puts Boeing on a path to accomplish another aerospace first,\" said Darryl Davis, president of Boeing Phantom Works. Davis said the Phantom Eye would provide greater amounts of \"persistent intelligence, surveillance, and reconnaissance\" over broader swathes of land.\nThe Phantom Eye has two 150-horsepower engines, can carry 450 pounds of surveillance gear, and has a wingspan of 150 feet, 25 feet more than the Boeing 757. The Phantom Eye was unveiled in 2010.\n\"The team is now analyzing data from the mission and preparing for our next flight,\" said Phantom Eye program manager Drew Mallow in a statement. \"When we fly the demonstrator again, we will enter higher and more demanding envelopes of high-altitude flight.\"\nCopyright 2012 ABC News Radio", "label": 1}
{"text": "Windows NT Security\nNT Domains let the server allow or deny resource access to all networked shared resources.\nThe \"User Manager for Domains\" program is used on NT server to administer domain user accounts. The NT workstation User Manager program is still used to manage local users and groups on each machine.\nThe network control panel is used to change the computer name and the domain name.\nThe password may be up to 14 characters long and is case sensitive. User names may be 20 characters long and are not case sensitive. User names may not contain:\n\" \\ / [ ] ; : = | . + ? * < >\nNetBIOS names are 15 characters long with one invisible character.\nWhen a user logs on, authentication may be done using the local or domain database. The user will be able to make this selection at logon time, but if the logon is done using the local database, only local resources will be available. Domain authentication is done by the nearest BDC or PDC.\nAccess tokens, and Access Determination\nNT uses the following objects to control access security:\n- Security identifier - The user's group membership (security IDs) and user (security ID) information.\n- Access token - Passed to the user's machine when they log on. Even processes have access tokens. The access token contains:\n- The security ID for the user.\n- The security IDs for the user's groups.\nACEs (Access control entries) are entries in an access control list (ACL). Every object contains an access control list. Each ACE contain security IDs for users and groups along with the associated permissions for that user or group ID.", "label": 1}
{"text": "The Russian company “Doctor Web” Found the World’s Largest Botnet Consisting of 5,50,000 Apple Computers .All of the Computers, According To Experts, Have Been Infected Since February of This Year. Apple Has Closed the Vulnerability Only on April 3.\nprovided From The Info-Graphic Shows That the Majority Of Infected Computers BackDoor .Flash back Located in Countries Where Apple Computers Are Popular All Over and in the U.S (Let see in the graph More Than 50% of All Infected Computers), As well as in Canada ( 20% ) And UK ( 12.8% ) .\nAccording to the Expert, “Dr. Web“: This Once Again Denies Claims By Some Experts That there is No Threat For Users of Mac .Discovery of this Only Illustrates the Scale of the Botnet Threat. We Hope This Will Make to Think of Those Who, Having a Mac ,Blithely Refers to Security” .In “Doctor Web” Claim That Any Operating System is Vulnerable, The Problem is Only in its Popularity.If it is Wide-Spread, The Gaps And Vulnerabilities Must be Identified And Used Cyberhawks.\nIt is Noted That the Virus is Installed Silently, Almost Without Requiring Any Action From The User.At the Same Goal of Creating a Botnet Are Still Unknown.Back Door Flashback Can Replace the Contents of Web Pages in the Browser Of An Infected Computer to Send Data to a Remote Server and Download The New Malware.It is Likely That Hackers Stole Passwords, User Accounts and Systems in sots.setya banking.\nRecall that according to a “Kaspersky Lab” study, in 2011, despite the fight against botnets, malicious viruses has increased .", "label": 1}
{"text": "Social media tools like Twitter, Facebook, YouTube, and even email, instant messaging, and SMS have become the defacto way we communicate with each other. Because of the mainstream embrace of social media, we now live in a world where information is shared at lightning speeds and as a result, we're actually finding ways to use that free flow of data and information to make the world a safer place to live.\nFrom tracking trends in crime to finding the safest bike routes around a city, from getting emergency alerts during a disaster to understanding the spread of dangerous illnesses, social media is being used by both public officials and private citizens to make our cities safer. This post outlines just a few of the ways that social media tools are now being employed to keep the public safe and informed.\nFind a Safe Place to Live\nBefore you even move to a new city, social media and mashups can help you to identify the safest places to live. Apartment data tracking web sites Zilpy and Apartment Ratings can both provide neighborhood crime statistics for those searching for a new place to live, for example. Another helpful tool is CrimeReports, which shows data on crimes committed in the vicinity of any street address in the United States; and families with children may want to use Vision 20/20's Sex Offender Locator to identify the neighborhoods where accused sex offenders are residing.\nUsing tools like these you can find the safest places to hunt for a new home or keep on top of crime in your neighborhood and recognize trends. Is crime on the rise? If so, then perhaps it is time to start thinking about moving to a new place, or maybe people in your area need to organize around making the neighborhood safer. Other sites, like Crime Mapping, which puts public crime data on interactive maps, and the aforementioned CrimeReports, are actually being used by police to identify local crime trends.\nElk River, Minnesota Police Chief Jeff Beahen told USA Today that online crime maps recently helped the department nab criminals after a series of burglaries. The department used a crime map to more accurately predict which area the burglars were planning to hit next and deploy officers more efficiently. \"We caught them in the act,\" Beahen told the paper.\nLocal news site Everyblock also taps into public records to create mashups that can help keep people safe. In addition to plotting and tracking local crime, on many of the site's metro pages users can also get information about recent restaurant inspections, helping them to find a safe place to eat.\nGetting Around Safely\nGetting around a city safely can in many cases mean advance planning. Sites like Google Transit, HopStop.com, and PublicRoutes can help you navigate public transit systems more safely, while mass transportation-focused blogs like Inside Transit and Seattle Transit Blog keep people informed about the system and give them a place to sound off.\nSocial media is especially useful for those who get around on two wheels. In New York City, for example, NYC Bike Maps offers interactive views of the city's bike paths, lanes, and greenways, while Crashstat maps data about bike and pedestrian injuries and fatalities in the city. Both tools can be used to identify the most and least safe areas of the city to use a bicycle. And blogs, such as Bike Blog NYC, or Bike Portland in Portland, Oregon, and Bike Providence in Providence, Rhode Island, give bikers a way to come together, form a community, and stay informed about issues that affect bicycle safety in their city.\nFor those more interested in walking, maps mashups and social media sites can also be helpful in keeping you safe. The Stumble Safely site, for example, is a mashup that combines a crime map of Washington, DC, with a map of local bars, clubs, and eateries, helping you find the best places for safe nightlife.\nAnother way social media is helping to keep us more safe, is by keeping us more healthy. Social networks have allowed information to spread in new and unprecedented ways, but illness still spreads by human-to-human contact in the same way it always has. Social media is now allowing us to more easily track the spread of illnesses, however, and be more prepared to fight them. Both Healthmap and Who is Sick? track outbreaks of illness on a map (the former using public data from governmental sources, the latter using user generated reports).\nThis type of data can be helpful in keeping the public informed about potential outbreaks, helping us prepare better ways to stay healthy, and it can help researchers learn about how diseases spread. Researchers have actually used similar sites in the past to learn how sickness spreads around a population and can use that data to better predict the spread of infectious diseases.\nMaps and social media mashups are also being used to keep the public up-to-date on the latest potential pandemic illnesses, as well. For example, the Swine Flu Tracking Map can be used by concerned citizens to keep on top of the latest outbreaks of the particularly worrisome H1N1 flu strain.\nKeeping the Public Informed\nBecause social media channels offer such an amazing way to spread information, it's natural that many web services exist to keep citizens informed of important issues. CrimeWeb is a free, centralized, web-based clearinghouse for public safety information that is currently being used by many local government organizations across the US. Users can sign up to get alerts about missing children (Amber alerts) and adults, homeland security updates, major crimes and fugitives, as well as local community information. Similarly, crime data mapping web site SpotCrime offers free crime alerts by email, and also sells crime tracking iPhone applications (iTunes links) for New York City, San Francisco, Chicago, Baltimore, and London.\nMainstream social networking tools are also being used to keep the public informed and connected. The Police Department in Dallas, Texas, for example, uses Twitter to put out crime alerts, as do the police in Boston, Massachusetts with the @Boston_Police account. The Police Department in Richmond, Virginia, meanwhile, uses both Facebook and Twitter to connect with the public and answer questions, and in Michigan, the Department of Transportation is using social media tools like Twitter and YouTube to connect with those that use their services and keep people informed of changes and interruptions in the public transit system.\nLocal neighborhood crime watches are also finding social media tools useful. The Shreiber Crime Watch in Dallas, Texas uses a blog and SMS alerts to keep citizens up-to-date about potential threats, and the Safe Atlanta for Everyone neighborhood watch program in Atlanta, Georgia uses a Twitter account in addition to a blog to stay connected with the public.\nIn addition to keeping the public informed about matters of public safety, social media services have proven to be invaluable tools for organizing and connecting people and disseminating information during disasters. After the horrific massacre at Virginia Tech in 2007, for example, Facebook became an online gathering place as people began to reconnect with loved ones and work through their grief. And social media has been used each year as a way to track and get information about the seemingly annual wildfires in California (in 2009, 2008, and 2007).\nIn fact, web-based and social media resources are now among the first places people turn during a disaster. \"It's becoming more organized,\" says Leysia Palen, a researcher at the University of Colorado at Boulder. \"We see evidence that people are learning that online sources and communication can be very critical. Looking for help, searching lists of the missing, finding emergency housing online. It's become an important complementary news source and a way to get involved [...] People are increasingly going to online sources — with new ones emerging every day — and learning how to behave online in emergency situations.\"\nWith more and more public safety departments turning to social media to stay informed, it is becoming more commonplace for social media to be utilized in actual police work as well. In July, for example, the Boston Police used Twitter and Facebook to track down bicycle thieves, while the Los Angeles Police Department utilized YouTube in an effort to locate criminals that broke into actress Lindsay Lohan's home in August.\nAnd using social media is becoming a common trend in modern police work. From police in New Zealand using Facebook to catch a burglar, to police in Ohio utilizing social networks to circulate pictures of criminals, social media tools are becoming the modern equivalents of the Post Office wanted poster.\nPolice are also using the things people post on social networks and blogs as a way to track down law breakers. \"We are using this (Facebook) as a crime-fighting tool. It's becoming pretty common,\" said Indiana, Pennsylvania Police Chief William Sutton after his department utilized Facebook photos and videos posted on YouTube to identify out-of-hand party-goers at a post-Super Bowl street gathering last February.\nWhile the latter is a case of what happens when criminals incriminate themselves on social networks, it is clear that social media tools are being used in smart ways by police departments and neighborhood watch groups to make our cities safer.", "label": 1}
{"text": "The Microsoft antitrust trial took an interesting turn when the US government announced its proposal to break the company into two separate entities—one to sell Windows OSs and another to control everything else. Although Microsoft's guilt is infinitely debatable, the time has come to consider a future in which Microsoft in its current form no longer exists. In the short term, Windows users will feel negligible effects. But let's assume the Supreme Court upholds the government's proposal and look at how the Microsoft split will affect the hundreds of millions of Windows users worldwide.\nSimply splitting Windows from Microsoft Office and the company's other applications probably won't dramatically change the way that customers buy and use PCs. Windows will retain a vast monopoly in desktop sales and a respectable server market share with Windows 2000 and Windows NT. Windows will continue to derive the bulk of its sales from machine bundles in which the end user licenses the OS when purchasing a new computer. But the government's plan will change the way Microsoft sells and markets Windows to PC manufacturers and consumers.\nTo understand the change, let's look at the way Microsoft currently sells Windows. OEMs, such as PC manufacturers, can sell Microsoft's most recent consumer product, Windows Millennium Edition (Windows ME), but Microsoft determines what makes up the OS. Therefore, Microsoft determines the OS's startup sequence, desktop icons, and general look and feel. Microsoft also decides which add-on programs, such as Windows Movie Maker, Microsoft Internet Explorer (IE) 5.5, and Windows Media Player 7, are in the box. You can argue that such products are free because Microsoft includes them in the price of Windows. However, the inclusion of these products excludes third-party developers who make money from products that compete in an otherwise open market. Therefore, you can argue that Microsoft's practice of tying applications to Windows harms competitors.\nTo address this problem, the government's plan requires Microsoft to sell a Windows version that doesn't include middleware applications (i.e., applications that don't perform a key system function). Web browsers and media players aren't middleware applications, but memory management is. Therefore, customers who want a Windows version that includes Movie Maker, IE, or Windows Media Player will purchase the bundled Windows product, which would be essentially identical to what Microsoft currently offers. But users who don't want middleware applications can purchase a cheaper basic Windows version. The creation of two products moves the choice from Microsoft to the consumer.\nFor PC manufacturers, the choices are also exciting. OEMs can break Windows into its components and provide users with custom installations. And an OEM will pay Microsoft only for the components the OEM sells. PC manufacturers will have the freedom to change aspects of Windows, such as the startup sequence, desktop icons, and the user interface (UI), as long as the manufacturer offers an easy way for users to reset the Microsoft defaults. Computer manufacturers can also make system components and bundled applications accessible through the Control Panel Add/Remove Programs applet so that users can further customize the Windows installation to meet their needs.\nThe plan to split Microsoft isn't perfect, of course, and whether the government will have the opportunity to implement it remains to be seen. A lengthy court battle will ensue and some time will pass before Windows users learn the final outcome. However, users can hope for future versions of Windows that offer more choice, which is a welcome outcome regardless of your take on the Microsoft trial.", "label": 1}
{"text": "Passwords are something of a hot topic around here at DVICE, and password generators are nothing new. Though, most times they give us nothing more than more of the gibberish we already choose for our passwords. Web comic xkcd pointed this out in this pretty popular strip.\nJoel Walters was among those who saw the comic. But while most folks saw it, chuckled and moved on, Walters decided to go ahead and create a password generator that uses the logic expressed therein.\nFor anyone who didn’t read said comic, it basically points out that we often make difficult passwords by doing things like interchanging a zero and the letter “o” or coming up with words we can’t even spell, which is hard to remember but really just as easy for a computer to crack as any other word of the same length. It is, in fact, better to have a long password of random words.\nTo quote the Walters’ website, “Contrasting a seven letter password to a seven word password, a seven word password has 2 quadrillion times more complexity, or combinations. Exploit your brain's ability to memorize sequences of words with ease, and you will be rewarded with a more memorable-secure password.” Its dictionary has 4,000 commonly used English words, and it’ll stick ‘em together randomly for all your passwords needs.\nHere’s a link. Go nuts.", "label": 1}
{"text": "<networking, security> (VPN) The use of encryption in the lower protocol layers to provide a secure connection through an otherwise insecure network, typically the Internet. VPNs are generally cheaper than real private networks using private lines but rely on having the same encryption system at both ends. The encryption may be performed by firewall software or possibly by routers.\nLink-level (layer 2 and 3) encryption provides extra protection by encrypting all of each datagram except the link-level information. This prevents a listener from obtaining information about network structure. While link-level encryption prevents traffic analysis (a form of attack), it must encrypt/decrypt on every hop and every path.\nProtocol-level encryption (layer 3 and 4) encryption encrypts protocol data but leaves protocol and link headers clear. While protocol-level encryption requires you to encrypt/decrypt data only once, and it encrypts/decrypts only those sessions that need it, headers are sent as clear text, allowing traffic analysis.\nApplication (layer 5 up) encryption is based on a particular application and requires that the application be modified to incorporate encryption.\nTry this search on Wikipedia, OneLook, Google\nNearby terms: virtual path « virtual point of presence « virtual PoP « Virtual Private Network » virtual reality » Virtual Reality Modeling Language » Virtual Sequential Access Method", "label": 1}
{"text": "States around the world are faced daily with the challenge of protecting their populations from potential and real threats. To detect and respond to them, many governments surveil communication networks, physical movements, and transactional records. Though surveillance by its nature compromises individual privacy, there are exceptional situations where state surveillance is justified. Yet, if state surveillance is unnecessary or overreaching, with weak legal safeguards and a failure to follow due process, it can become disproportionate to the threat—infringing on people's privacy rights.\nInternationally, regulations concerning government surveillance of communications vary in approach and effectiveness, often with very weak or nonexistent legal safeguards. Some countries have strong regulations for the surveillance of communications, yet these regulations may be largely ineffective or unenforceable in practice. Other countries have no legal safeguards or legal standards differing vastly according to the type of communication data targeted. This is why, EFF organized at the end of last year a State Surveillance and Human Rights Camp in Brazil to build upon this discussion and focused on how states are facilitating unnecessary and disproportionate surveillance of communications in ways that lead to privacy violations.\nState-Mandated Identity Verification\nIn 2012 the Constitutional Court in South Korea declared that country's \"real-name identification system\" unconstitutional. The system had mandated that any online portal with more than 100,000 daily users had to verify the identity of their users.1 This meant that the individual has to provide their real name before posting comments online. The legal challenge to this system was raised by People's Solidarity for Participatory Democracy (PSPD)'s Public Law Center and Korean Progressive Network—Jinbonet among others.\nKorea University professor Kyung-shin Park, Chair of PSPD's Law Center told EFF that portals and phone companies would disclose identifying information about six million users annually—in a country of only 50 million people. The South Korean Government was using perceived online abuses as a convenient excuse to discourage political criticism, professor Park told EFF:\nThe user information shared with the police most commonly has been used by the government to monitor the anti-governmental sentiments of ordinary people. All this has gone on because the government, the legislature, and civil society have not clearly understood the privacy implications of turning over identifying information of individuals.\nThe decision by the South Korean Constitutional Court to declare the \"real identification system\" unconstitutional was a win for user privacy because it clearly showed that blanket mandates for the disclosure of identifying information, and the subsequent sharing of that data without judicial authorization, are a disproportionate measure that violates the rights of individuals.2\nStates Restrict Encryption and Demand Backdoors\nSome States are seeking to block, ban, or discourage the use of strong encryption and other privacy-enhancing tools by requiring assistance in decrypting information. In India service providers are required to ensure that bulk encryption is not deployed.\nAdditionally, no individual or entity can employ encryption with a key longer than 40 bits. If the encryption equipments is higher than this limit, the individual or entity will need prior written permission from the Department of Telecommunications and must deposit the decryption keys with the Department.3\nThe limitation on encryption in India means that technically any encrypted material over 40 bits would be accessible by the State. Ironically, the Reserve Bank of India issued security recommendations that banks should use strong encryption as higher as 128-bit for securing browser.4\nIn the United States, under the Communications Assistance for Law Enforcement Act, telecommunication carriers are required to provide decryption assistance only if they already possess the keys (and in many communications system designs, there's no reason carriers should need to possess the keys at all). In 2011, the US Government proposed a bill that would place new restrictions on domestic development or use of cryptography, privacy software, and encryption features on devices. The bill has not been adopted.\nAllowing only low levels of encryption and requiring service providers to assist in the decryption of communications, facilitates surveillance by enabling States easier access to data and preventing individuals from using crypto tools to protect their personal communications.\nStates Establish Blanket Interception Facilities\nIn Colombia, telecommunications network and service providers carrying out business within the national territory must implement and ensure that interception facilities are available at all times to state agencies as prescribed by law. This is to enable authorized state agencies to intercept communications at any point of time. In addition to providing interception facilities, service providers must also retain subscriber data for a period of five years, and provide information such as subscriber identity, invoicing address, type of connection on request, and geographic location of terminals when requested.\nThough Colombia has put in place regulations for the surveillance of communications, these regulations allow for broad surveillance and do not afford the individual clear rights in challenging the same.\nThe examples above demonstrate that, although State surveillance of communications can be justified in exceptional instances, it leads to the violation of individual privacy when implemented without adequate legal safeguards. Clearly there is a need for international principles articulating critical and necessary components of due process for the surveillance of communications. Those strong legal safeguards are necessary not only in countries that don't have laws in place, but also in countries where laws are lacking and fail to adequately protect privacy. Last year, EFF organized the State Surveillance and Human Rights Camp to discuss a set of International Principles on State Surveillance of Communications, a global effort led by EFF and Privacy International, to define, articulate, and promote legal standards to protect individual privacy when the state carries out surveillance of communications.\n1.Constitutional Court's Decision 2010 Hunma 47, 252 (consolidated) announced August 28, 2012.\n2.The illegality of this practice was proved by a High Court decision handed down 2 months after the Constitutional Court's decision in August 2012. Seoul Appellate Court 2011 Na 19012, Judgment Announced October 18, 2012. This case was prepared and followed singularly by PSPD Public Interest Law Center.\n3.License Agreement for Provision of Internet Services Section 2.2 (vii)\n4.Reserve Bank of India. Internet Banking Guidelines. Section (f (2))\nBE THE CHANGE! PLEASE SHARE THIS USING THE TOOLS BELOW", "label": 1}
{"text": "|by Jodi Ito\n“Cyber” threats are everywhere on the Internet -- from viruses, worms, spyware and other “malware” just waiting to invade your unprotected computer to very official-looking emails tempting you to give up your personal information (called “phishing”). The list of threats is endless and protecting our computers and personal information require constant vigilance and a growing awareness of our personal computing practices.\nAny desktop computer or server could be used to host viruses, trojan horses, and other malicious programs. We should all be aware of the security issues related to our daily use of computers. Here are some basic steps and precautions that you can take to help secure your computer and to protect you and your personal information.\n- Regularly download and install operating system and application security patches from your software vendors. (Microsoft users can go to: http://windowsupdate.microsoft.com and click on “Scan for updates”. Apple OS X users can click on “Software Update” in “System Preferences” under the “Apple” icon on the menu bar.)\n- Use anti-virus software to scan all files and email attachments before opening them. UPDATE VIRUS DEFINITION FILES REGULARLY ! UH faculty, staff and students are eligible to participate in the University's McAfee anti-virus site license. For more information, go to: http://www.hawaii.edu/antivirus.\n- Make regular backups of critical data (and test your backups to ensure they are readable).\n- Use strong passwords. (See sidebar) Do not leave passwords blank and change the manufacturer's default passwords. Change passwords frequently. And protect your passwords – do not share them with anyone. For more information visit: http://www.onlinesecurity.com/links/links47.php\n- Shutdown computers (or disconnect them from the network) when finished for the day (at work) or the evening (at home) or if leaving them unattended for long periods of time.\n- Do not open email attachments from strangers AND be suspicious of any unexpected or unusual email from people you do know. Disable \"previews\" and automatic viewing/downloading of attachments and files.\n- Test your systems for vulnerabilities. Use Web-based vulnerability assessment tools such as: www.symantec.com/securitycheck or www.grc.com (click on \"ShieldsUp\")\n- Do not run unnecessary servers on your computer such as Web servers Telnet, FTP, IRC, etc.\n- Download software from reputable sources such as: http://www.tucows.com and http://www.pcworld.com/downloads.\n- Scan your computer regularly for “spyware” and use spyware removal tools. Additional information on spyware and removal tools can be found at:\n- Visit only legitimate Web sites. Malicious Web sites can download and install malware on your computer turning it into a “spam generator” or a “zombie” which can be used to attack other machines.\n- Do not reply to unsolicited (spam) email.\n- Do not give out personal information (address, SSN, passwords, etc.) in response to unsolicited requests.\n- Encrypt your files that contain personal information (TurboTax files, PDA information, password lists, etc.) Viruses have been known to send out random files from your computer to any email addresses that it finds on your system. Free encryption software can be found at: www.pgp.com/products/freeware.html.\n- Be suspicious of email that appears to be from a legitimate organization (such as Citibank, Ebay, PayPal, FirstUSA, etc.) asking you to click on a link to update your personal information such as name, address, SSN, bank accounts, and credit card numbers. These are fraudulent schemes known as “phishing”. Personal information gathered is used (or sold) to commit fraudulent financial activities. NEVER update your personal information by clicking on the link in the email. If it seems legitimate, call the organization to verify the request and always type in the URL yourself. For more information on phishing and a list of current scams, visit: http://www.antiphishing.org.\n- Do not use public computers or wireless networks for personal/confidential transactions. Public computers may have keystroke loggers installed on them and information transmitted over wireless networks may be more vulnerable to being illegitimately captured and viewed.\n- Use only one credit card (with a low limit) for ALL online purchases.\n- For all EFT (Electronic Funds Transfers) transactions, use only one checking account.\n- Don't use your Social Security Number if at all possible.\n- Do an annual credit check.\n- Watch for unauthorized charges.\n- Report fraudulent activities at: www.ifccfbi.org\n|Create a Strong Password\nDo not use words found in dictionaries, birthdates, names, or variations of your UH Username\nUse a minimum of eight characters\nUse upper and lower case letters\nInclude numbers and symbols\nA good way to build a password is to use the first letter of each word in a phrase that you would easily remember, using numbers and symbols if possible. For example, \"One is the loneliest number by Harry Nilsson\" can be used to build the password: 1itl#bHN\nSafe Computing Definitions\nDefinitions from Webopedia.com\nMalware: Short for malicious software, software designed specifically to damage or disrupt a system, such as a virus or a Trojan horse.\nPhishing: The act of sending an email to a user falsely claiming to be an established legitimate enterprise in an attempt to scam the user into surrendering private information that will be used for identity theft.\nSpyware: Any software that covertly gathers user information through the user's Internet connection without his or her knowledge, usually for advertising purposes.\nTrojan Horse: A destructive program that masquerades as a benign application. Unlike viruses, Trojan horses do not replicate themselves but they can be just as destructive. One of the most insidious types of Trojan horse is a program that claims to rid your computer of viruses but instead introduces viruses onto your computer.\nVirus: A program or piece of code that is loaded onto your computer without your knowledge and runs against your wishes.\nWorm: A program or algorithm that replicates itself over a computer network and usually performs malicious actions, such as using up the computer's resources and possibly shutting the system down.\nInformation compiled from:\nUH IT Policies\nAdditional Resources on:\nGeneral Consumer Information", "label": 1}
{"text": "You can help your child become a responsible, ethical digital citizen with healthy online relationships. To do that, you’ll use the same successful parenting skills that you’re already using at home. Resilient digital citizens recognize and seek out the 3Cs—appropriate contact, content, and conduct—in all digital settings (e.g., iPods,instant messaging, chat, computer games, game consoles, cell phones, text messaging, webcams). To help you teach your children to safely and ethically use their digital devices, iKeepSafe has created the following programs:\nIt’s your identity. Defend it. Identity thieves and cyber-criminals are continually finding new ways to take advantage of those who are unprepared and unprotected—including online and through your home computer. It’s never been more important to protect your privacy, your credit, your money, and those you care about most.\niDefend® provides you with the 7 key areas of protection you need to defend yourself against today’s identity thieves and cyber-criminals. No other service gives you this level of protection – period.\nThe Faux Paw books and animated DVD series will captivate the attention of your young children and illustrate the important principles you desperately want to teach them about the safe and responsible use of technology.\nDigital Literacy Tour workshops are interactive discussions helping students learn, through hands-on scenario activities, how to steer clear of cyber tricks and be responsible digital citizens. Each workshop contains a resource booklet for both educators and students that can be downloaded in PDF form, presentations to accompany the lesson and animated videos to help frame the conversation.\nDesigned to teach parents how to help their teens strengthen their privacy and safety on Facebook, the guide features important topics such as risks involved in social networking, how to parent Facebook users, managing reputation in the digital age, managing your privacy on Facebook, reporting problems and more. The guide will also be translated into other languages such as Arabic and distributed internationally\niKeepSafe Generation Safe™ helps K-12 schools comprehensively navigate and embrace the digital environment. It includes a comprehensive suite of professional development, self assessment and incident response tools. It helps schools know how to best integrate technology into whole school initiatives to minimize liability and enhance classroom experiences.\nProject PRO is a partnership between the American School Counselor Association (ASCA), AT&T and iKeepSafe that has created an interactive program promoting the importance of security and online reputation to students nationwide.\nRead more about the digital citizenship topics students need to understand to become full, resilient digital citizens by clicking HERE.\niKeepCurrent Generation Safe News Feed is a weekly email newsletter using current events and news stories to build digital citizenship public awareness content, curricula and professional development . The units are tied to ALA and ISTE standards.", "label": 1}
{"text": "Protecting Yourself Against Viruses\nGuarding your computer against digital invaders\nYour computer can fall victim to many destructive events:\npower surges, coffee spills, a failed hard drive or worse. But your computer is\nalso susceptible to a digital invader called a virus.\nA virus is a program that attaches itself to another program and spreads\nfrom one file to another, causing varying degrees of damage. You may not even\nnotice some viruses, but malicious ones can erase your data files, corrupt your\napplications, cause your computer to crash, and in certain cases, render your\nhard drive completely useless.\nViruses can be transmitted via email attachments, so monitor your in-box for\nsuspicious messages. If you don't know the person who sent you a message, don't\nopen any attachment that came with it.\nYou can't get a virus from simply opening an email message, but your email\nclient may be configured to automatically open attachments, in which case you\nshould disable that feature. Be especially aware of attachments with the\nsuffixes .exe or .com. If you activate this type of virus, it can attack\nexecutable files, overwrite code and cause irrevocable damage.\nBeyond keeping a watchful eye on your incoming email, you should also be\ncareful about using removable media, especially from unknown sources. Floppy\ndisks, Zip disks and CD-ROMs can also transmit viruses.\nWithout a doubt, the best way to protect yourself against viruses is to\ninstall antivirus software. These utilities will scan for many types of viruses\nand keep watch over your system files, boot files and data files.\nSet your virus program to run a basic startup scan every time you turn on\nyour computer and a full system scan every few weeks. Most antivirus utilities\nlet you either set an automatic schedule for a full scan or do it manually. If\nthe utility finds a virus, it alerts you and tries to disinfect the file. If\nthe file can't be disinfected, you'll probably have to delete it.\nIt's also important to download updates to your virus software so that it\nwill recognize and protect you against the latest viruses. Keeping your\nantivirus software up to date greatly reduces the chances that you'll have to\ndelete any files.", "label": 1}
{"text": "Source: Security Focus\nLinux Kernel Hardening\nby Anton Chuvakin, Ph.D.\nlast updated January 23, 2002\nThis article will cover the issues of Linux hardening, with a specific focus on kernel hardening and its use on production systems. Several kernel-hardening approaches and their usability will be analyzed.\nIs Linux secure? The question is much less useful, than 'Is Linux \"securable\"?' The answer to the latter is a definite yes. Being securable means that Linux can be made more secure (to whatever degree necessary) by applying a clearly defined sequence of steps that always produces the same result, and that can be automated and applied to systems that have been in operation for a long time. It would be ideal to be able to make securing systems understandable by regular system administrators who donít have formal security training. However, the last requirement might be pushing it a bit, since security will likely always require expertise.\nLinux can be made more secure by hardening the system. It is beyond the scope of this article to discuss system hardening; however, there are a number of system hardening resources available, such as:\nThere are also utilities available, such as Bastille linux. The latter automate the hardening process with detailed explanations on each step. Hardened Linux distributions such as EnGarde Linux and Immunix are also available. Typical steps that are taken during the system hardening include:\n- Minimizing installed software\n- Patching the system\n- Securing filesystem permissions and S*ID binaries\n- Improving login and user security\n- Setting some physical and boot security controls\n- Securing the daemons via network access controls\n- Increasing logging and audit information\n- Configuring vendor supplied security software (IDS, host firewall)\nIt is curious to note that hardening is not just a matter of fixing bad defaults the vendors throw at users. It is believed that vendors ship systems with mostly open default setting based on customer feedback. Thus hardening should be viewed not as \"fighting the evil vendor\", but rather as optimizing the system based on local business and security needs.\nHardening is also a great example of defense in depth. Such a Linux system will be much harder to crack and utilize for nefarious purposes. There are examples of Linux servers running for years without a successful penetration and with no firewall. Their reliability is due to a professionally hardened OS.\nHowever, system hardening appears to be lacking in several aspects. For example, buggy SUID programs and network application will still give the attacker root and user access. If attacker gets \"root\", there is positively no way to stop them from anything on a normal Linux system. In addition, basic Unix access controls will not stop authorized system users from doing various bad things (port scanning, accessing unauthorized resources, running password crackers or banned network applications), which cannot be prohibited using Ďaccess controlí without rendering the system unusable. And while hardening, improved logging, audit and intrusion detection will complicate rootkit deployment by attackers, kernel-level rootkits can easily overcome those preventive measures.\nTo combat these threats, kernel hardening is needed. Kernel hardening can be defined as enabling additional kernel-level security mechanisms to improve the security of the system, while keeping system close to traditional Linux. What are some approaches to kernel hardening? Current Linux kernel security can be tightened a bit without adding any new features or patches. One can compile the kernel with no module support (in this case, most kernel rootkits cannot function) and some security-related kernel options can be turned on.\nThe full article can be wieved here.", "label": 1}
{"text": "Ads on the web have become essential tools for companies to promote their products, and for people to learn about bargains. But they’ve also caught the attention of cybercriminals who increasingly use them as virus and spyware-spreading channels. Their goal? Damage your data, steal your personal details or even control your computer remotely. This is when useful ads go malicious and harmful, and are referred to by specialists as “malvertisements”.\nThere are two common methods used by cybercriminals to spread viruses and other malware through ads on the Internet:\nOne entails criminals acting as trustworthy companies. They place a series of “clean” ads on trusted sites that host third-party ads, and leave them running for some time to gain a “good reputation”. Then, they attack – they insert a virus or spyware in the code behind the ad, and after a mass virus infection is produced, they remove the virus. In this case, because the ad network infrastructure is very complex with many linked connections between ads and click-through destinations, the criminals’ identity can hardly be traced.\nAnother common way for criminals to turn legitimate ads into malicious ads is by hacking trusted sites and injecting viruses into banner ads. Examples of trustworthy sites that have been hacked and used by cybercriminals to insert viruses in the ads are The London Stock Exchange and The New York Times. Usually, the next day – after the harm’s been done – they’re gone. These types of malvertisements can take the form of Google ads, pop-ups, antivirus notifications or even software upgrades.\nWhat can I do to avoid virus infections contracted from malvertising?\nKnow the exact type of the file! This is one of the most efficient and yet simple solutions: set your Windows to show the complete file name. This way you will be able to avoid most of the infections masked as ads, pictures or email attachments. For example, if you receive a picture which is named Cute_Kitten but the complete file name is Cute_kitten.exe, that's not a picture for sure. To enable this option, go to Control Panel ->Folder Options ->View ->uncheck the \"hide extensions for known file types\" box, then click \"Apply\" and \"OK\" buttons.\nDon’t be too trusting! If, say, a random pop-up appears on your screen saying you’re the one hundredth visitor and you won something huge (free), chances are that’s a malicious ad, and the only thing you can win by clicking it is a virus. Also, do not trust pop-up online surveys. Long story short, avoid such ads.\nUpdate, update, update! Out-dated software on your computer (browsers and other applications installed on your PC) makes you more vulnerable to hackers and viruses. And due to the fast evolution of malvertising methods, it’s always best to have a vulnerability scanner to check your system for out-of-date software and update it.\nBe extra careful during weekends! Malvertising campaigns are usually triggered over weekends, when IT resources are low and attacks are less likely to be noticed. Make sure you have effective antivirus protection that includes “safe browsing” functionality, so that with each site you visit, you’re notified whether it’s safe to access it or not. BullGuard Antivirus contains a feature like that.\nPrevent, rather than cure! While you can’t always figure out which ads are, in fact, malvertisements, you can lower the chances of getting infected by installing comprehensive internet security software. BullGuard Internet Security 12 is, in this respect, a great solution to all internet security problems – including malicious ads that run amok –, as it comes with the broadest selection of internet security features on the market and 24/7 free support .", "label": 1}
{"text": "SMTP-based email has long been considered insecure, and for good reason. The basic protocol doesn't include encryption, authentication\nAlthough SMTP itself is a fairly simple protocol, the idea of extending SMTP has been around for a long time. The mechanism to extend SMTP is a general one, and many different extensions have been defined to extend and stretch the capabilities of one of the Internet's oldest protocols.\nStart with TLS\nOne of the extensions within SMTP is the addition of the TLS (Transport Layer Security) encryption and authentication protocol. When a client and server that support TLS talk to each other, they can encrypt the data channel and thus guard against eavesdroppers.\nTLS is the IETF-standardized version of the SSLv3 protocol, which is widely used across the Internet. All popular Web browsers support SSL and TLS. SSL is the protocol that is negotiated when you use an \"https:\" URL. The differences between SSLv3 and TLS are not important, and most SMTP servers also support clients that want to talk SSLv3 instead of TLS. In this article, I'll only refer to TLS to simplify the discussion.\nWith TLS, the server side of the transaction sends down a digital certificate that is used to prove the server's identity. Optionally, the SMTP client can send up a digital certificate to prove the client's identity. Once the server's certificate is sent down, the client creates an encryption key, encrypts the key using the certificate of the server and ships the encrypted key up to the server. The client and server then start up an encrypted channel, and everything from that point forward is protected against eavesdroppers. This is how encryption works on the Internet with https: Web pages, and this is also the way it can work if you've enabled TLS support in your SMTP email server. (I am glossing over a lot of the potential variations in TLS that are allowed, but the cases that I'm describing represent 99% of the TLS use on the Internet today.)\nUsing TLS with your SMTP mail server is generally a simple matter. All modern email servers fully support TLS and have for many years. More importantly, TLS and SMTP are extremely interoperable. My company has been using TLS on our mail server since early 1999. Although we used to run into the occasional domain our mail server couldn't send out to, this hasn't happened in several years. In fact, almost all of the problems we encountered in TLS interoperability were caused by defective firewalls with poorly written SMTP protective code. Very old versions of WatchGuard's Firebox and Cisco's PIX had this problem, for example.\nHow to use TLS\nTo make use of TLS with your mail server, you've got to do two things: turn the feature on and get a digital certificate. How to enable TLS is beyond the scope of this article, but if you search for TLS or STARTTLS (the name of the SMTP service extension that enables TLS) in your mail server documentation, you'll probably find it very quickly. Getting a digital certificate is a little harder. In fact, this is probably why most people haven't turned on TLS -- they get to this step and freeze up. Fortunately, it's become a lot easier to get a digital certificate than it used to be. You can give Verisign a couple of hundred dollars and wait a week or so, but there are many options for getting an inexpensive digital certificate signed by a well-recognized certification authority, such as RegisterFly, within a few minutes.\nIn fact, you don't have to pay for a digital certificate to run TLS in your mail server. For testing purposes, and perhaps even for production, you can use a self-signed certificate. Your SMTP server might even have a built-in command to generate a private key and matching digital certificate. CAcert will also generate signed certificates for you for free.\nWith TLS enabled, all of your email traffic from your company's SMTP mail server to external TLS-enabled SMTP mail servers will be encrypted, from start to finish. If you are using a POP or IMAP email client that supports TLS -- and all modern ones do -- when you send mail from your client to the mail server, it'll be encrypted.\nAlthough TLS includes server and client identity, these are fairly vague concepts when it comes to SMTP-over-TLS. The binding between a server's identity and the identity in the digital certificate is a loose one. There is no clear and obvious standard for mapping the identity I want to talk to with the identity in the certificate. In addition, it's not clear to the SMTP client or server what action to take if the digital certificate doesn't seem to match. On the Web, a dialog box pops up and the user makes the decision whether or not to accept the certificate. A client and server have no one to ask when things don't look right.\nThe result of the TLS transaction is perfectly fine encryption, but rather weak authentication. If you don't match the server certificate to the identity you think you're sending to, you're susceptible to a man-in-the-middle attack. You could be sending encrypted traffic, but not to your intended recipient. Since we're accustomed to SMTP mail being forwarded in an uncontrolled manner through a number of different relays, all we're really doing is adding encryption against casual eavesdroppers. Not a huge benefit, but at virtually no cost.\nAll of this comes down to TLS not being the ultimate answer for email encryption. But like any good security system, it's a question of layers. Throw TLS on, and you're no worse off then you were before; in fact, you'll discover that about 10% of your email is encrypted. For an investment of a few hours of time, you're adding another layer of security.\nThere are some cases where TLS is critical. If you are supporting any sort of Internet, SMTP, POP and/or IMAP service, then TLS encryption on these services is a security requirement. Otherwise, you're sending passwords out in the clear when you authenticate people coming in to your mail service. Many companies are turning to SSL VPN appliances from companies such as Juniper and Nokia to front-end their SMTP, POP and IMAP services with TLS encryption.\nSophisticated mail systems often can be configured to be \"pickier\" about TLS services when talking to trusted partners. For example, if you've got a company that you often send commercially-sensitive information to (health care providers and insurance companies are good examples), you can use a Message Transfer Agent (MTA) that actually does make sure that the digital certificates match and that you're talking to who you think you are. Even if you don't have that kind of requirement, though, enabling TLS will improve your overall email security.\nJoel Snyder is a senior partner at Opus One, a consulting firm in Tucson, Ariz. He sent his first network email in 1980, and has been designing and implementing enterprise email systems ever since. He is partially to blame for the X.400 messaging standards and has been trying to atone for them ever since. Let us know what you think about this tip; email email@example.com.\nThis was first published in April 2005", "label": 1}
{"text": "Static source code analysis for bug finding (\"static analysis\" for short) is the process of detecting bugs via an automated tool that analyzes source code without executing it. The idea goes back at least to Lint, which was invented at Bell Labs in the 1970s, but static analysis has undergone a revolution in effectiveness and usability in the last decade. The initial focus of static analysis tools was on the C and C++ programming languages. Such tools are particularly necessary given C/C++'s notorious flexibility and susceptibility to low-level bugs. More recently, tools have flourished for Java and/or Web applications; these are needed because of the prevalence of easily exploitable network vulnerabilities. When using such tools, it is all too easy to deploy them in a way that looks good superficially, but misses important defects, shows many false positives, and brings the tool into disrepute. This article is a guide to the process of deploying a static analysis tool in a large organization while avoiding the worst organizational and technical pitfalls.\nLeading commercial static analysis tools with which I am familiar include Coverity, Fortify (now owned by Hewlett-Packard), and Klocwork. Klocwork and Coverity both initially focused on C/C++, although they came from opposite origins: Klocwork from the telephone equipment company Nortel, and Coverity from Stanford University. Fortify's initial focus was on security for Web applications in languages such as Java and PHP. All three companies are now encroaching on each others' territories, but it remains to be seen how well they will do outside of their core competencies.\nAn excellent, free, but limited, academic static Java byte code analysis tool is FindBugs. Its lack of an integrated database for defect suppression makes its large-scale use difficult in sizable organizations, but its use by individual developers within the Eclipse development environment can be extremely valuable. Similarly, recent versions of Apple's Xcode and Microsoft's Visual Studio development environments contain integrated static analysis tools for C/C++. These are useful for finding relatively shallow bugs while an individual developer is writing code; their short feedback loop bypasses the difficulties of broader deployment of tools that perform deeper analysis. A longer list of tools is provided in Figure 1 (which is taken from \"Magic Quadrant for Static Application Security Testing,\" by Gartner Inc.), albeit with a strong bias towards security and adherence to Gartner's strategy recommendations.\nThere is no general-purpose introductory textbook on the subject; the best general introduction is a short article by Dawson Engler, the inventor of Coverity, et al. Two of the leaders at Fortify have written an introductory textbook, but it focuses primarily on their tool and on security, and skimps on key static analysis concepts. There is a rigorous academic textbook on the more general concept of static analysis, but it preceded the revolution in static analysis for bug finding.\nGetting Started: The Politics\nThe first question to ask before deciding to do static analysis in an organization is not what tool to buy, nor even whether you should do static analysis at all. It's \"why?\"\nIf your purpose is genuinely to help find bugs and get them fixed, then your organizational and political approach must be different from the more usual, albeit unadmitted, case: producing metrics and procedures that will make management look good. (Fixing bugs should actually be your second goal: An even higher goal is preventing bugs in the first place by making your developers learn from their mistakes. This also contraindicates outsourcing the evaluation and fixing of defects, tempting though that may be.)\nPolitical Issues to Settle in Advance\nGet buy-in from your testing/quality assurance department. They must support the project and will have authority over quality-related issues, even if they inconvenience the other stakeholders. Quality has a much smaller constituency than the schedule or the smooth running of internal procedures, but it must be the final arbiter for crucial quality-related decisions (see chapter 22 of Joel On Software for more on this topic).\nGive some thought to what part of the organization, if any, should be in charge of running the tool once it's set up. If your organization has a tools team, it might seem the obvious owner, but this does need careful consideration. Static analysis for bug finding is probably not your organization's core competency, and you will need to worry about the Iron Law of Bureaucracy: Your tools team's institutional interest will be in the smooth running of the tool, not in the messy changes necessary for finding bugs. Even if you're reluctant to outsource the rest of the process, administration and configuration may be more flexible if done by external players rather than an internal team with its own interests, habits, and procedures. It may also be more productive to hire an expensive consultant for a few hours, rather than a lesser-paid internal resource full-time; an external resource may be more flexible and less prone to establishing an entrenched bureaucracy.\nThe conventional wisdom is that getting most developers to use a static analysis tool requires a high-ranking management champion to preach its benefits, ensure that the tool is used, and keep the focus on finding bugs and getting them fixed. The flip side to this is that any attempt to herd cats (or to get programmers to adhere to best practices) will cause a backlash. Your tool must withstand scrutiny from developers looking for excuses to stop using it.\nGet buy-in from engineering that they will make time in the schedule to review and fix bugs found, even if they are disinclined to do so, which they will be once they see the first false positive. (Or even the first false false positive; more on this later.) Ensure that it's not the least-effective engineers whose time is allotted for reviewing and fixing static analysis bugs (more on this momentarily). You'll also need agreement from the security team that sales personnel will get access to your real source code; more on that is also to follow.\nSmart Programmers Add More Value and Subtract Less\nHandling static analysis defects is not something to economize on. Writing code is hard, finding bugs in professional code should be hard, and evaluating possible mistakes in alleged bugs is even harder. Learning to evaluate static analysis defects, even in a developer's own code, requires training and supervision. It is necessary to tread delicately around the polite pretense that the code owner is an infallible authority on the behavior of that code. Misunderstandings about the actual behavior of unsigned integers and assertions are, for instance, regrettably common in my experience.", "label": 1}
{"text": "Security (IT Security) means protecting information and information\nsystems from unauthorized access, use, disclosure, disruption,\nmodification, or destruction.\nThe main protection priorities are the confidentiality, integrity\nand availability of information.\nGovernments, military, corporates, financial institutions, hospitals,\nand private businesses amass a great deal of confidential information\nabout their employees, customers, products, research, financial\nstatus and privacy. These informations must be protected by intruders\nand unauthorized accesses.\nHacker is generic term for a computer criminal, often with a specific\nspecialty in computer intrusion.\nHacking is breaking into computer systems, frequently with intentions\nto alter or modify existing settings. Sometimes malicious in nature,\nthese break-ins may cause damage or disruption to computer systems\nor networks. People with malevolent intent are often referred\nto as \"crackers\" as in \"cracking\" into computers.\nTheir main attack techniques are: Exploit, Buffer Overflow, Shellcode,\nCracking, Backdoor, Port Scanning, Sniffing, Keylogging, Spoofing,\nTrojans, Viruses, Spyware, Malware DOS and Browser CMD.\nThe main instruments of defense are: anti-virus softwares, antispyware,\nfirewalls, encryption, cryptography, authentication techniques,\nbackups, honey pots, Intrusion Detection System (IDS), Network\nIntrusion Detection System (NIDS), etc.\nEGI Security's Network Counterespionage\nequipment has a wide range of applications form the professional\nto the novelty uses as well as Hardware and Software Tactic Solutions\nand Countermeasures for private, corporate and governmental institutions.\nEGI Security guarantees quality and\nreliability in the Products and the proposed Solutions.", "label": 1}
{"text": "There are so many passwords in our daily life such as those for file encryption, Email and ICQ account, computer login, credit card and deposit book etc.\nIt’s a common occurrence that you forget one of your passwords one day.\nNow with \"Password Management\", you can manage all your passwords by just remembering one password, or even remember no password at all by using an authorized disk or a file as the password.\nWith \"Password Management\", you can select a password and paste it into password input box during encryption. You can also use \"Copy Password\" to copy a password into clipboard and then paste it into other applications. All passwords are completely safe since they are encrypted before saving.\nNever lose the password to enter \"Password Management\". Keep safe the authorized disk and backup the password file with \"Backup Information Files\".\nTo use \"Password Management\", first fill out the \"Caption\", \"Password\" and \"Commentary\" in the \"Edit Column\" and then click \"Append\" button.\nIf you have modified any information above, remember to click \"Modify\". Click \"Delete\" to erase an item. Before exit, click \"Save\" first. By clicking \"Save as a file\" button, you can save the password records as a .txt file which is convenient to modify or print. Click \"Change Password\" button, and you can change the password to enter \"Password Management\".", "label": 1}
{"text": "HTTPS Security Encryption Flaws Found\nThe flaw exists in the RC4 encryption algorithm that's often used to help secure the SSL/TLS communications that underpin secure (HTTPS) Web pages. The flaw was first disclosed last week by University of Illinois at Chicago professor Dan Bernstein at the Fast Software Encryption conference in Singapore, in a talk titled \"Failures of secret-key cryptography\" that's based on research he conducted with researchers from University of London's Royal Holloway and the Eindhoven University of Technology in the Netherlands.\n- Get Actionable Insight with Security Intelligence for Mainframe Environments\n- Getting a Grip on Mobile Malware\n- Gartner Magic Quadrant for Secure Email Gateways\n- Protecting Sensitive Data In and Around an Oracle Database\n\"The transport layer security (TLS) protocol aims to provide confidentiality and integrity of data in transit across untrusted networks like the Internet,\" according to the group's research presentation. \"It is widely used to secure Web traffic and e-commerce transactions on the Internet.\"\n[ Are hackers hacking for fun or for profit? Celeb Data Breach Traced To Credit Reporting Site. ]\nBut RC4, the researchers found, isn't sufficiently random, and with enough time and effort, an attacker could recover some plaintext from a communication secured using TLS and RC4. \"We have found a new attack against TLS that allows an attacker to recover a limited amount of plaintext from a TLS connection when RC4 encryption is used,\" they said. \"The attacks arise from statistical flaws in the keystream generated by the RC4 algorithm, which become apparent in TLS ciphertexts when the same plaintext is repeatedly encrypted at a fixed location across many TLS sessions.\"\nThe vulnerability has wide-ranging repercussions, given current RC4 use. \"Around 50% of all TLS traffic is currently protected using the RC4 algorithm,\" they said. \"It has become increasingly popular because of recent attacks on CBC-mode encryption on TLS, and is now recommended by many commentators.\" Those CBC-mode encryption attacks have included padding oracle attacks, the BEAST attack against browsers and the Lucky 13 attack that was first disclosed last month.\nSome cryptography experts have moved to reassure Internet users that they're in no immediate danger from the RC4 vulnerabilities. \"While interesting, the attacks don't represent an immediate practical threat to users of SSL/TLS (including online banking, e-commerce, social networking, etc.),\" said Symantec technical director Rick Andrews in a blog posted to the Certificate Authority Security Council website. \"Such attacks require an attacker to run malicious software on a user's computer, which would connect to a particular website and send the same message over and over again many times. In fact, if the attacker's software could send the same message over and over 10 times per second, it would still take more than three years for the attack to succeed.\"\nStill, once easily exploitable vulnerabilities have been discovered in an encryption algorithm, it's only a matter of time before more rapid and effective attack techniques get discovered. Furthermore, other researchers -- working at intelligence agencies, for example -- could have already discovered these vulnerabilities and put them to use.\n\"RC4 shouldn't be around,\" said Paul Ducklin, head of technology for Sophos in the Asia Pacific region, in a blog post. \"Experts have recommended avoiding it completely, at least for any newly written applications, for several years. But replacing or banning RC4 in existing cryptographic implementations is a much trickier problem.\"\nWhat's the solution? \"The most effective countermeasure against our attack is to stop using RC4 in TLS,\" according to the researchers. \"There are other, less-effective countermeasures against our attacks and we are working with a number of TLS software developers to prepare patches and security advisories.\"\nInstead of using RC4, the researchers strongly recommend switching to AEAD cipher suites such as AES-GCM, which are supported in TLS 1.2, which hasn't yet been widely adopted. Another approach, however, could be to use a CBC-mode cipher suite that's been patched against the BEAST and Lucky 13 attacks, and they said many versions of TLS 1.0 and 1.1 do now have such patches.\nSymantec's Andrews also emphasized that the discovery of vulnerabilities in RC4 doesn't reveal weaknesses in SSL/TLS. \"The designers of the SSL/TLS protocol anticipated that algorithms would become weaker over time, so the protocol was designed to support the easy addition of new algorithms,\" he said. \"Hence a weakness in one algorithm does not mean that SSL/TLS is broken. Newer, stronger algorithms have already been developed and incorporated into the latest implementations of SSL/TLS. What's needed now is for users of Web server and browser software to update to the newest versions to minimize or eliminate the use of weakened algorithms.\"", "label": 1}
{"text": "Before \"Cablegate\" (the Wikileaks diplomatic cables scandal), those of us who are relatively ignorant about the internet (non-geeks in other words) had never heard the term DDOS, or if we had, we thought it was some kind of software like Windows DOS. But in fact, DDOS attacks have been striking terror into the hearts of IT specialists in the major companies for over 10 years now, and they severely disrupted Wikileaks in late 2010. DDOS is a more radical and damaging version of a DOS attack: the acronym DOS means \"Denial of Service\". The idea of a DOS is to render a website inaccessible to its visitors. Either the site is blocked altogether, or it is severely slowed down. The pirate orchestrating the attack has a number of ways of paralysing a targeted website: he can cut the power supply to the server, though this is rare. The technique most often used is to inundate the target site with requests so that it becomes saturated. This involves thousands of computers attempting to download the same page of the target website at the same time. Once the number of requests exceeds the capacity of the server to handle them, this is enough to immobilise the website.\nDDOS is the acronym for “Distributed Denial of Service”, in other words a DOS on a larger scale.\nIn a DDOS attack, the pirate (known as the Master) starts by inflitrating people’s computers (maybe including yours or mine) so that they become his “slaves”, which he takes control of and instructs to attack the target or victim: the website in question. In fact, if your computer is badly protected it could well be used as a slave (also known as a zombie or demon) to take part in an attack without your knowing anything about it. If a pirate chooses your machine as a zombie, you haven’t heard the last of it. Many pirates \"rent out\" their network of zombies to other pirates preparing DDOS attacks. It is therefore possible for you to be implicated in several of these attacks.\nWhile it is easy to trace the perpetrator of a DOS attack – it’s the IP address (their computer identification) that gives them away — it is more difficult to track down all the IP addresses of thousands of zombies! As a preventive measure, instead of using just one server, it’s better to choose a configuration based on a number of servers, so that, if one of them is attacked, your website will still be accessible, even if it’s slowed down. Some people advocate using a buffer server designed to filter requests and “neutralise” any malevolent ones. A good firewall can reduce the risk of a DDOS attack, but it can’t eliminate it altogether.\nIf your website suffers repeated attacks, it is quite likely that the server on which it runs will just abandon you to your fate, in order to safeguard its other customer websites and ensure that they, too, are not brought down by the attack. It might decide to block your IP address, in which case you will have to find a different server.\nIn practice, if your website is the victim of repeated DDOS attacks, you will have to change your IP address or your server regularly, in the hope that the pirates will eventually get bored. Otherwise, you can set up \"mirror sites\", which provide an \"alias\" for the website you are trying to protect. That way, your visitors can always access the data on your website. This is the solution Wikileaks chose, with more than 700 mirror sites being set up. That should give the DDOS pirates something to think about!", "label": 1}
{"text": "Number Of Teenage Hackers Increasing\nExperts are concerned over the increasing numbers of teenagers dabbling in hi-tech crime.\nTeenagers swapping credit card numbers, phishing kits and hacking tips populate many net forums, computer security professionals say.\nBut the poor technical skills of many young hackers means they are very likely to get caught and arrested. Youth workers added that any teenager getting a criminal record would be putting their future at risk.\nChris Boyd, director of malware research at FaceTime Security, said he sees kids of 11 and 12 sharing credit card details and asking for hacks.\nTeens often get involved in low-level crime by looking for exploits and cracks for their favorite computer games. Communities and forums spring up where people start to swap malicious programs, knowledge and sometimes stolen data.\nOthers search for exploits and virus code that can be run against the social networking sites popular with many young people. They then try to peddle or use the details or accounts they net in this way.\nBoyd has spent a lot of time tracking down the creators of many of the nuisance programs written to exploit users of social networking sites and he said the culprit was often a teenager.\nFrom such virus and nuisance programs many progress to outright criminal practices such as using phishing kits to create and run their own scams.\n\"Some are quite crude, some are clever and some are stupid,\" Boyd said.\nBut most teenagers’ attempts to make money from cyber scams result in getting caught because of their poor technical skills.\n\"They do not even know enough to get a simple phishing or attack tool right,\" said Kevin Hogan, a senior manager Symantec Security Response.\n\"We have seen phishing sites that have broken images because the link, rather than reference the original webpage, is referencing a file on the C: drive that is not there,\" he said.\nMany teenagers manage to cripple their own PCs by infecting them with viruses they have written, Symantec researchers said.\n“Many of the young criminal hackers were undermined by their desire to win recognition for their exploits,” said Chris Boyd from FaceTime.\n“They are obsessed with making videos of what they are doing.”\nMany post videos of what they have done to sites such as YouTube and sign on with the same alias used to hack a site, run a phishing attack or write a web exploit.\nSome make it easy for computer security experts to track them down when they share photos or other details of their life on other sites.\nBoyd shut down one wanna-be hacker named YoGangsta50 and made the teenager promise to never get involved in petty hi-tech crime again.\nReformed teenage hacker Mathew Bevan said it was no surprise that young people were indulging in online crime.\n\"It’s about the thrill and power to prove they are somebody,\" he said. That also explains why they stuck with an alias or online identity even though it was compromised, he added.\nHe said what most of them do it to get fame within their peer group. \"They spend months or years developing who they are and their status. They do not want to give that up freely.\"\nTeenagers needed to appreciate the risks they take by falling into hi-tech crime, said Graham Robb, a board member of the Youth Justice Board.\n\"If they get a criminal record it stays with them,\" he said. \"A Criminal Record Bureau check will throw that up and it could prevent access to jobs.\"\nHe also said young people needed to appreciate the impact of actions carried out via the net and a computer.\n\"Are they going to be able to live with the fact that they caused harm to other people?\" he said. \"They do not think there is someone losing their money or their savings from what they are doing.\nOn The Net:", "label": 1}
{"text": "Redesign Enables NASA Site to Handle Traffic Surge, TragedyThe space shuttle Columbia disintegrated on entry Feb. 1. NASA's Web site received 72 million hits that day -- less than 24 hours after its revamp. By month's end, NASA.gov had attracted an unprecedented 512 million hits.\nDespite the enormous surge in traffic, not once did the site have problems, NASA officials said.\n\"NASA would not have been able to handle the volume of traffic were it not for overhauled technical infrastructure and information architecture,\" said Tyler Niess, account director at Calgary, Alberta-based Critical Mass, the interactive agency that handles the NASA account along with eTouch, Fremont, CA.\nFebruary's traffic volume was more than the previous five years combined. Perhaps the closest online interest NASA.gov received to the Columbia disaster was when NASA landed the Mars Pathfinder probe in July 1997, when it received 750 million hits over the probe's six-month mission.\nOf course, it helps that NASA is a government agency with the ability to install unlimited bandwidth. Still, many other government sites have buckled under traffic spikes or technical glitches.\nThere are lessons here for retailers and marketers. One is the efficient use of the Internet as a communications tool in times of crisis. Another is the technology preparedness when consumer interest is expected to peak, in this case, Columbia's descent to Earth.\nSo what happened when the Columbia disaster unfolded?\nA team at Critical Mass and eTouch assembled and put together recommendations for NASA less than an hour after the tragedy. A multimedia introduction on NASA.gov was replaced with the image of a U.S. flag at half-staff, and the tone changed from celebratory to mourning.\nAnother far more important addition was a microsite that included a schedule of events, biographies of the seven crew members and the ability to upload directions for video and photographs. The microsite was designed to handle information requests, serving as one of the most invaluable information portals in the crisis management chain at NASA.\nA few factors helped officials meet the demands created by the Columbia tragedy. NASA had, for the first time, outsourced site hosting. Next, it took advantage of its different in-place systems to conduct searches and balance the query load. Finally, NASA redesigned the site architecture to make it flexible enough to quickly add a new section that did not break the navigational conventions.\nDirect marketers, online retailers and even news sites in the aftermath of major events can learn from NASA's online experience. Retail sites undergo similar stress during the Thanksgiving and Christmas holiday shopping season.\nNASA had the foresight to erect load, traffic and peak bandwidth requirements that seemed outlandish.\n\"The information architecture and the stripped-down content delivery system were critical,\" Niess said. \"So, when planning for anything special or for anything unexpected, you have to maximize load times and accessibility.\"\nNASA has faced tighter budgets and diminished public interest in its activities. Last year, however, the E-Government Initiative became law, and government agencies were challenged to use the Internet to meet public needs as the private sector does. Encouraged, NASA decided to accelerate its awareness and advocacy by making its site a public outreach asset. NASA.gov now is the portal for 4 million pages of information from 2,922 disparate NASA sites.\nThis new philosophy will be put to test with the next Mars Exploration Rover Mission slated for takeoff this summer and a January landing. This mission is expected to generate 10 times the traffic as the previous Pathfinder spacecraft in 1997, a number running into billions of hits.\nCritical Mass will not delve into the specific features expected on the site with the new Mars probe. But the shop does disclose the efforts are going to be unprecedented.\nIn essence, NASA is in the midst of an online rebranding. As a government agency, it is aware that it needs to be more accessible to the public. More importantly, the site is the agency's only public interface. There is no NASA magazine or newsletter, and all communications are conducted online and via press conferences.\nBefore Critical Mass' online retooling -- it took only three weeks to prep NASA.gov for Columbia's return -- the site was aimed primarily at scientists. Now the site has a broader appeal.\n\"We think the site is unusual because it starts with user needs and modifies internal processes to meet those needs,\" Niess said. \"It is unprecedented for government agencies to think this way.\"", "label": 1}
{"text": "On September 17th, 2011, Natasha Singer wrote for the New York Times about the National Strategy for Trusted Identities in Cyberspace (NSTIC). Comparing NSTIC to a digital driver's license, Singer explained how NSTIC would make it so people have a simpler, safer way to prove who they are online with more than a flimsy password. To do so, consumers would choose among trusted third parties — such as banks, technology companies or cellphone service providers — that verify certain personal information about them and issue them secure credentials to use in online transactions. The system would allow Internet users to use the same secure credential on many Web sites; people could have their identity authenticator automatically confirm that they are old enough to sign up for Pandora without having to share their birthdate with Pandora.\nHowever, authentication proponents and privacy advocates disagree about whether Internet IDs like NSTIC would actually heighten consumer protection. Privacy advocates argue that identity verification online could make consumers more vulnerable because authentication companies would become \"honey pots for hackers.\" Lillie Coney, the associate director of the Electronic Privacy Information Center, noted that “You can have one key that opens every lock for everything you might need online in your daily life, or, would you rather have a key ring that would allow you to open some things but not others?”\nHowever, Jeremy Grant (senior executive adviser for identity management at the National Institute of Standards and Technology) noted that no system is invulnerable. Privacy concerns aside, better online identity authentication would improve the current situation where people use the same passwords for their e-mail, banking, and social network accounts. Mr. Grant went on to compare weak security to flimsly locks on bathroom doors: “If we can get everyone to use a strong deadbolt instead of a flimsy bathroom door lock, you significantly improve the kind of security we have.”\nThe source article can be found here.", "label": 1}
{"text": "The Browser Takes All\nGoogle's new computer throws out everything but the Web.\n- Friday, December 10, 2010\n- By Tom Simonite\nThis week, Google unveiled a computer like no other: the Cr-48, a notebook that relies on the Web for all its software applications. Yet the Web search giant thinks the notebook can compete with computers that run all kinds of installed software.\nThe matte black Cr-48 won't be sold to the public, but thousands are being sent to consumers and businesses who have volunteered to test it. It introduces a new kind of operating system, called Chrome OS, that turns to the Web for almost everything. Google is pitching Chrome OS as its vision for a new form of computing—one that shifts the data, functionality and almost everything else you would expect from your desktop computer into the cloud. Chrome OS will get its biggest test when Acer and Samsung start selling notebook computers customized to run the software in mid-2011.\nGoogle's Chrome OS vision is perhaps best understood by examining the differences between Chrome OS and the operating systems commonly used today, says Sundar Pichai, the vice president of product management for Chrome OS (and the related Chrome Web browser). Those differences come from a single design decision about the relationship between a person and his computer, Pichai says.\n\"Operating systems today are centered on the idea that applications can be trusted to modify the system, and that users can be trusted to install applications that are trustworthy,\" he says, \"it turns out those are bad assumptions.\"\nIn contrast, Chrome OS assumes that applications and users can't be trusted. And it has just one application: the browser. \"There's a cascade of things that happen when you make this core assumption,\" says Linus Upson, a Google VP of engineering working on the project, from making it easier to protect against malware, to reducing the need for users to act as administrator for their own system.\nChrome OS—based on a pared-down version of the Linux operating system—automatically downloads and installs its own updates. Any data downloaded in the course of using the Web is kept carefully in a secure place, separate from the OS.\nGoogle still needs to prove that the simplicity of Chrome OS doesn't undo its usefulness. To this end, it has built a Web \"app store\" to encourage developers to create Web-based software that will match the diversity and functionality of the applications that can be installed on the hard drive of a Windows or Mac computer. These apps are basically advanced websites that offer similar functionality to desktop apps software.\nUsers of Chrome OS—as well as the Chrome browser on a conventional computer—can search or browse the Chrome Web Store and with a single click install apps. The store has far fewer software applications than are available for a conventional machine. But some Chrome apps can compete with more traditional, desktop applications, for example a Photoshop-like image editor, Aviary.\nPichai says the fact the app store takes payments—either one off or subscriptions—should stimulate the creation of apps that otherwise wouldn't exist because developers couldn't make them profitable. \"I wouldn't find a random game on a website and give them my credit card details to pay $3.99. It's not worth the time or the risk.\"\nSomewhat surprisingly, given Google's claimed commitment to the open Web, Google's app store is not compatible with other Web browsers. But it is possible to easily modify apps developed for Chrome's store for other \"modern\" browsers, says Pichai, since they use HTML5 and other web standards designed to enable advanced functionality, including working while offline. The latest versions of Internet Explorer, and other browsers, support those standards. However some features of Chrome apps remain exclusive to Chrome, such as 3-D effects that tap into a machine's graphics processor. \"We need to make sure that apps can do everything that apps can do on the desktop today,\" Pichai explains. He expects other browsers to catch up as HTML5 and other new Web standards become more common.", "label": 1}
{"text": "How cloud storage could catch up with big data\n- By John Moore\n- Apr 17, 2012\nCloud computing has managed to make the world’s already colossal appetite for data storage even more voracious.\nLast year, IDC, an IT market research firm, cited public cloud-based service providers, from Amazon Web Services to YouTube, as the most significant drivers of storage consumption in the past three years. The government sector contributes as well: IDC noted that the private clouds of government and research sites compare in scope and complexity to their public cloud counterparts.\nThe so-called big data problem has surfaced in the past two years to rank among the primary IT challenges. Technologies such as the Apache Hadoop distributed computing framework and NoSQL databases have emerged to take on the challenge of very large — and unwieldy — datasets.\nAnd now another technology, already at work behind the scenes, could grow in importance in the coming years. Erasure coding has been around since the 1980s, but until recently its use in storage circles has mainly been confined to single storage boxes as a way to boost reliability more efficiently.\nNow erasure coding is moving into distributed storage. Its application becomes trickier here, but industry executives and storage researchers believe erasure coding — particularly in conjunction with increasingly popular techniques such as object-based storage — will play a growing role in cloud storage. Potential government adopters include Energy Department labs and other agencies with vast data stores.\nWhy it matters\nWhen it comes to storage, everything is getting bigger, whether it’s an individual disk, a storage system or a cloud-based repository. Erasure coding, an error-correcting algorithm, plays a role across this range of ever-growing storage platforms.\nVendors most commonly use erasure coding to boost the resiliency and performance of their Redundant Array of Independent Disks (RAID) storage systems, said Bob Monahan, director of management information systems at DRC, a consulting and IT services firm.\nBut it’s the use of erasure coding as an alternative to data replication that is attracting new interest in this storage mechanism. In many traditional cases, redundancy is achieved by replicating data from primary storage devices to target arrays at the data center or an off-site location. Mirroring data in that way provides protection but also consumes lots of storage, particularly when organizations make multiple copies of data for greater redundancy. The approach becomes particularly unwieldy for organizations that deal with petabytes or more of data.\nErasure coding offers an alternative way to achieve redundancy while using less storage space, said Russ Kennedy, vice president of product strategy, marketing and customer solutions at storage vendor Cleversafe, which uses erasure codes in its object-based storage solutions.\nOrganizations that rely on replication might make three or four copies of data — one copy at another location then a copy of the copy to be safe and so on. In comparison, the overhead to make a sufficiently fault-tolerant copy with erasure coding is less than double the size of the original volume, Kennedy said.\nJean-Luc Chatelain, executive vice president of strategy and technology at DataDirect Networks, said financial concerns are driving interest in erasure coding among customers who don’t want to replicate data two or three times. DataDirect takes advantage of erasure coding in its RAID system, file storage offerings and Web Object Scaler product for cloud storage.\nThe prospect of saving space and money hasn’t been lost on the cloud community. The major providers are on their way to adopting erasure coding, said James Plank, a professor in the Department of Electrical Engineering and Computer Science at the University of Tennessee. His research focuses on erasure codes in storage applications.\n“Pretty much every cloud installation you can think of is either using erasure coding or converting to erasure coding,” he said, citing Amazon, Google and Microsoft as examples. “They are using erasure coding for fault tolerance because the disk space savings is huge.”\nThere’s a bandwidth benefit as well. “While the big savings today would come from reduced capacity requirements, the big win, from my standpoint, is the two- or threefold reduction in bandwidth [compared to what is] used during replication,” said Galen Shipman, group leader of the Technology Integration group at Oak Ridge National Laboratory’s National Center for Computational Sciences.\nErasure coding might have implications for the nascent cloud, but the technology has been around the storage block a few times. In a storage setting, the technique encodes data into fragments from which the original data can be reconstructed.\nFor example, erasure coding is the underlying technology of Cleversafe’s dispersed storage method, which takes a data object (think of a file with self-describing metadata) and chunks it into segments. Each segment is encrypted and cut into 16 slices and dispersed across an organization’s network to reside on different hard drives and servers. If the organization has access to only 10 of the slices — because of disk failures, for instance — the original data can still be put back together, Kennedy said.\nNumerous experts see erasure coding paired with object-based storage as a good option for achieving more fault-tolerant repositories with petabytes and even exabytes of capacity.\nGovernment clouds and data centers have yet to jump on erasure coding, apart from agencies using RAID storage devices that embed the technique.\n“It is less well understood and therefore less mature in commercially available solutions,” Monahan said. “As it becomes more mature, the use cases for when it is more appropriate will drive implementation scenarios.”\nPerformance is another limitation. Shank Shome, a storage engineer at Agilex Technologies, said the impact of erasure coding on storage performance has yet to be fully explored. He added that reading the data back from an erasure-coded system is generally fast, but the real performance cost lies in writing the data to storage.\n“If the data is generally static with very few rewrites, such as media files and archive logs, creating and distributing the data is a one-time cost,” Shome said. “If the data is very dynamic, the erasure codes have to be re-created and the resulting data blocks redistributed.”\nErasure coding also runs into problems with high-performance computing. One complication arises when data is being written simultaneously from many sources and at a high rate, said Robert Ross, a computer scientist at DOE’s Argonne National Laboratory and a senior fellow at the University of Chicago’s Computation Institute. That activity requires a level of coordination that isn’t easy with current approaches.\nIn general, storage experts believe erasure coding faces the biggest obstacle in frequently accessed “hot data.” Accordingly, they believe a key initial use case lies in protecting data that has cooled enough to move to long-term storage.\nMonahan said the benefits of erasure coding are “higher local availability at a lower cost and highly available dispersed archival systems that are an order of magnitude less expensive than traditional systems.”\nThe trick is knowing when to use replication to get data out of a system quickly and when to use erasure coding to create more economical, resilient long-term storage, Ross said.\n“Both have important roles moving forward in high-performance computing,” he added.\nThe Oak Ridge lab is now exploring the use of erasure coding for the Oak Ridge Leadership Computing Facility. That facility already uses RAID 6 systems from DataDirect Networks. Shipman said erasure coding could play a significant role in two distributed storage systems: a Lustre parallel distributed file system and the large-scale archival High Performance Storage System, which uses replication for data integrity and resiliency.\n“Erasure coding will likely emerge as a viable alternative to replication due to savings in the media and bandwidth consumed for replication,” Shipman said.\nHe acknowledged the computational demands of the more advanced erasure-coding techniques but said ongoing research on algorithms aims to minimize that cost.\nNext steps: Updating the storage toolbox\nAs data storage needs continue to grow and cloud-based models introduce new options for distributed systems, agencies should constantly re-evaluate their storage strategies. Specifically, they should:\n- Monitor current storage options. Erasure coding might not be at the top of your agenda today, but if your storage growth is outpacing your budget, it probably makes sense to add the technology into the mix of current or near-term future options.\n- Assess likely use cases. Beyond data archiving, erasure coding could prove useful for maintaining and protecting large quantities of sensor-derived data. For example, Cleversafe recently signed GeoEye, a provider of high-resolution satellite imagery, as a customer.", "label": 1}
{"text": "Cross-Site Scripting attacks are a type of injection problem, in which malicious scripts are injected into the otherwise benign and trusted web sites. Cross-site scripting (XSS) attacks occur when an attacker uses a web application to send malicious code, generally in the form of a browser side script, to a different end user. Flaws that allow these attacks to succeed are quite widespread and occur anywhere a web application uses input from a user in the output it generates without validating or encoding it.\nAn attacker can use XSS to send a malicious script to an unsuspecting user. The end user’s browser has no way to know that the script should not be trusted, and will execute the script. Because it thinks the script came from a trusted source, the malicious script can access any cookies, session tokens, or other sensitive information retained by your browser and used with that site. These scripts can even rewrite the content of the HTML page.\nMore information: Wikipedia.", "label": 1}
{"text": "Recent events such as hurricanes Katrina and Rita, the 911 event, the attack on the USS Cole, and the Northeast U.S. blackout have demonstrated our vulnerability to disasters and our need to find methods that provide some degree of tolerance for large cyberspace systems in the presence of disasters. Disaster Tolerance in computing and communications systems refers to the ability of infrastructure, software, IT systems, communications infrastructure and business or organizational processes that depend on these systems, to maintain functionality throughout the occurrence of a disaster. The goal of Disaster Tolerance is to provide an ability to continue uninterrupted operations, despite the occurrence of a disaster that would normally interrupt organizational operations; where critical business functions and technologies continue operations, as opposed to resuming them.\n- Faculty: Theodore Manikas, Stephen Szygenda, Mitch Thornton\n- Students: Poramate Ongsakorn\nHardware Security and Electronic Design Automation\nThe mission of the Electronic Design Automation (EDA) laboratory is to create and design new techniques for the capture of system specifications and to automatically synthesize, verify, and test the resulting system. EDA laboratory personnel work on projects related to conventional electronic and emerging quantum and nano-based systems. An emphasis on the application of fundamental knowledge in discrete mathematics, algorithms, and system design principles is the underlying philosophy behind research projects.\n- Faculty: Jennifer Dworak, Theodore Manikas, Mitch Thornton\n- Students: Saurabh Gupta, David Kebo Houngninou, Xi Shen, Abhijit Sunil, Fanchen Zhang, Adam Zygmontowicz\nThe mission of the Cyber Security Lab is to nurture education, research and development of security technologies for systems ranging from the physical layer to the application layer. In that spirit, our projects range from border and transportation security to application layer security against phishing attacks. Over the past 10 years, research in the Cyber Security Lab has provided the basis for Security Engineering curriculum in the Computer Science and Engineering Department at SMU's Lyle School of Engineering.\n- Faculty: Tyler Moore, Suku Nair\n- Students: Bilal Alqudah, Will Bengtson, Ala' Eshmawi\nEconomics puts the challenges facing information security into perspective better than a purely technical approach does. Systems often fail because the organizations that defend them do not bear the full costs of failure. In order to solve the problems of growing vulnerability and increasing crime, solutions must coherently allocate responsibilities and liabilities so that the parties in a position to fix problems have an incentive to do so. This requires a technical comprehension of security threats combined with an economic perspective to uncover the strategies employed by attackers and defenders.\nThe security economics lab conducts research measuring various forms cybercrime in order to improve our understanding of how attackers and defenders behave. We emphasize empirical analysis of security incidents that can be directly observed, driven by the belief that security failures must be studied from the concrete, not the hypothetical. We also attempt to quantify the costs and benefits of security mechanisms where possible.\nWe collaborate with researchers at institutions across the US and internationally, including Carnegie Mellon University, Penn State, the University of New Mexico, the University of Cambridge, and the University of Münster. For more information and publications, see http://lyle.smu.edu/~tylerm/eis.html.\n- Faculty: Tyler Moore\n- Students: Marie Vasek, Jake Drew", "label": 1}
{"text": "Enabling Secure SSH Terminal Connections From Roaming Smartphones\nThe Secure Shell, or SSH, is a popular program that lets computer users log onto remote machines. Software developers use it for large collaborative projects, students use it to work from university servers, customers of commercial cloud-computing services use it access their accounts, and system administrators use it to manage computers on their networks.\nFirst released in 1995, SSH was designed for an Internet consisting of stationary machines, and it hasn't evolved with the mobile Internet. Among other problems, it can't handle roaming: If you close your laptop at the office and reopen it at home, your SSH session will have died; the same goes for an SSH session on a tablet computer that switches from a Wi-Fi connection to the cellular network.\nAt the Usenix Annual Technical Conference in Boston this month, researchers at MIT's Computer Science and Artificial Intelligence Laboratory presented a paper describing a new remote-login program called Mosh, for mobile shell, which solves many of SSH's problems. The researchers also believe that the communication scheme underlying Mosh could improve the performance of a host of other mobile applications.\nEven before they presented the paper, they made Mosh freely available on a number of different websites; it's now been downloaded at least 70,000 times. \"That's from the ones that we're able to track,\" says Keith Winstein, a graduate student in MIT's Department of Electrical Engineering and Computer Science and lead developer of Mosh.\nBesides roaming, another of the problems that Mosh addresses is the delayed \"echoing\" of keystrokes in SSH. During a standard SSH session, when a user strikes a key on the keyboard, nothing appears onscreen until information about the keystroke travels to the remote machine, which performs a computation and sends back the result. That's because, in many applications commonly run through SSH, keystrokes don't necessarily correspond directly to displayed symbols: In an email program, for instance, the \"N\" key might call up the next email; similarly, when a user enters a password, it shouldn't appear onscreen.\nMosh has an algorithm running in the background that deduces when keystrokes should be displayed and when they shouldn't. Until the remote computer confirms Mosh's predictions, the characters onscreen are underlined. \"I have never seen it display anything wrong,\" says Hari Balakrishnan, a professor in the Department of Electrical Engineering and Computer Science and Winstein's coauthor on the Usenix paper.\nThe reason Mosh handles roaming so much better than SSH does is that it abandons the Transmission Control Protocol, or TCP -- the framework that governs almost all the traffic in today's Internet.\n\"TCP has some wonderful ideas embedded in it -- congestion control, ways of doing reliability and so forth,\" Balakrishnan says. \"But it has this one big, big problem: It provides a reliable, in-order byte-stream abstraction between two fixed endpoints. If you were to pick the worst possible abstraction for the mobile world, it would be that.\"\nWith mobile applications, Balakrishnan explains, it's not as crucial that every byte of information be displayed in exactly the order in which it was sent. If you've lost connectivity while using the map application on a smartphone, for instance, when the network comes back up, you probably want an accurate map of your immediate surroundings; you don't want to wait while the phone reloads data about where you were when the network went down.\nWinstein and Balakrishnan developed their own communications protocol, which they call SSP, for state synchronization protocol. SSP, Balakrishnan says, works more like the protocols that govern videoconferencing, where getting timely data about the most recent state of the application is more important than getting exhaustive data about previous states.\nMosh is already proving itself useful: At his computer in his office, Balakrishnan pulls up the connection log for one of the servers in MIT's Athena network; a third of the people logged into it are using Mosh. But in ongoing research, Winstein and Balakrishnan are investigating how SSP can be improved and extended so that other applications can use it as well.\n\"We have sort of a broader agenda here,\" Winstein says. \"Mosh is a gracefully mobile application. But there's a lot of even more popular network applications that have the same problems, like Gmail, or Google Chat, or Skype. None of these programs gracefully handle mobility, even though they're intended for mobile devices.\"", "label": 1}
{"text": "Many people use their computers for months or years without ever knowing it's infected with a virus. An infected computer runs slowly and and the overall user ...\nUse these guidelines to protect your computer system from viruses.\nRegister now to access 7 million high quality study materials (What's Course Hero?) Course Hero is the premier ...\n... or simply keeping up ... AVG Free Edition has the presence of all necessary functions to protect your computer from viruses ... AVG Anti-Virus FREE Edition is ...\nBest Computer Protection - 5 Tips to Keeping Your PC Virus and Spyware Free EzineArticles.com.\nComputer Viruses- Protect computer against viruses ... It's happened to the best of us, it's happened to the worst of us. And when infected, it feels like your world ...\ngroovyPost 10 Step Security Guide to Keeping your Computer Virus Free and Your Data Safe!\nBattling Computer Viruses. As a computer user, you face a major challenge in keeping your computer free from destructive viruses. A virus is a program or piece of ...\nThe 3 Keys To Keeping Your Computer Network Virus-Free! To keep your computer virus-free, here are 3 key strategies from managed IT services provider, Cartish ...\nKeep your computer clean, quick and virus free with The FixMeStick® Virus Removal Device for $34 (reg. $64.99). Free shipping!\nHow do I remove a computer virus? If your computer is infected with a ... The scanner is a free online service that helps you identify and remove ... Keep in touch ...\nKeep your Computer free from Viruses, Trojans, Spyware and Malware - HelpWithWindows.com - News\nBy Preston Gralla, TechWeb From the moment you turn on your PC until the moment you turn it off, it's under assault. Hackers try to break into it; viruses,\nKeeping your computer virus-free is an active, ongoing job. You will need to update your virus definitions, run regularly scheduled scans of your computer, ...\nHere are some simple ways you can keep your computer safe: Use Anti-Virus Software; Don't Open Junk Mail; ... im jus about 2 start using the free antiviruses im so exited.\nKeep Your PC Clean With a Free Virus Cleaning Program. Article about Free Computer Virus Cleaning Programs. It's Easy To Find Computer Virus Cleaning Programs that are Free.\nAndroid phones are not unlike your typical computer, it can do many of the same things such as browsing the web, or playing games. But just like any typical computer ...\nThe following programs will help you keep your computer clean and running fast. Defraggler. ... but the anti virus protection is not free and has to be added.\n... viruses are able to cross the firewall and end up on your computer anyway. A virus ... , it's important to keep your virus ... Don't install \"free ...", "label": 1}
{"text": "Glossary What is a virus, trojan, spyware, malware or other badware\nThe technical terminology used in virus alerts and descriptions can be confusing. The glossary below contains definitions for some of the most common terms with the top ones linked just below.\nA legitimate, non-replicating program designed to display ads to the end-user, often based on monitoring of browsing habits. Often adware contains spyware in order for the program to know which advertisements to display based on the current user’s preference. Adware displays ads often in exchange for the right to use a program free of charge (a variation on the shareware concept).\nA program that opens secret access to systems, and is often used to bypass system security. A Backdoor program does not infect other host files, but nearly all Backdoor programs make low-level operating system modifications (i.e. it makes changes to the registry). Backdoors usually hitch a ride in on trojans. Once they are in place and they have executed, they hide themselves while opening a port on your computer to allow others in. Some backdoors are placed by hackers once they gain access allowing themselves easier entrance later, or if their original entryway is blocked.\nA virus which uses multiple infection techniques. This may include the exploitation of various program vulnerabilities, incorporation of trojan behavior, file infection routines, Internet propagation routines, network share propagation routines, and spreading without any human intervention.\nA trojan that, upon execution, logs every keystroke or activity in a system. Although they are similar to third-party parenting/monitoring software, some keyloggers actually employ the same techniques as parenting/monitoring software to gather valuable data such as usernames, passwords, and personal information from unsuspecting users.\nA “macro” is a saved set of instructions that users may create or edit to automate tasks within certain applications or systems. A Macro Virus is a malicious macro that a user may execute inadvertently and that may cause damage or replicate itself. Some macros replicate, while others infect documents. Unlike other virus types, macro viruses aren’t specific to an operating system and spread with ease via email attachments, floppy disks, Web downloads, file transfers, and cooperative applications. Macro viruses are typically written in Visual Basic and are relatively easy to create. They can infect at different points during a file’s use (for example, when a file is opened, saved, closed, or deleted).\nMalware (Malicious Software)\nPrograms that are intentionally designed to perform some unauthorized (and often harmful or undesirable) act such as viruses, worms, and trojans.\nA virus that contains a special routine that changes parts of the virus code with each replication to evade detection by antivirus software.\nA software program that monitors a user’s computing habits and personal information and sends this information to third parties without the user’s authorization or knowledge.\nTrojan (Trojan Horse)\nA program or a part of program code that performs unexpected or unauthorized, often malicious, actions. The main difference between a trojan and a virus is the Trojan’s inability to replicate. Trojans cause damage, unexpected system behavior, and compromise the security of systems, but do not replicate. If a malicious program replicates, then it should be classified as a virus. A Trojan, coined from Greek mythology’s Trojan Horse, typically comes in good packaging but has some hidden malicious intent within its code. When a Trojan is executed users will likely experience unwanted system errors, problems in operation, and sometimes loss of valuable data.\nA program or a part of program code that replicates – that is, “infects” another program, boot sector, partition sector, or document that supports macros, by inserting itself or attaching itself to that medium. Most viruses only replicate, though, many do a large amount of damage as well.\nA self-contained program (or set of programs) that is able to spread functional copies of itself or its segments to other computer systems. The propagation usually takes place via network connections or email attachments. The worm may do damage and compromise the security of the computer. It may arrive in the form of a joke program or software of some sort.", "label": 1}
{"text": "Uncertain State Of Cyber War\nJust what does \"cyber warfare\" mean? We're still figuring out tactics and capabilities.\nMilitary agencies worldwide are right in the middle of figuring out the tactics and capabilities that will be critical in any future cyber war. So far, any conflicts are playing out behind the scenes, with only the rare accusation or public request for technology giving a glimpse into what offensive attacks between countries might look like.\nEven what counts as \"cyber warfare\" remains an open question. Many cite as the first-known example of such operations the distributed denial-of-service (DDoS) takedowns and hijacking of government and business websites in the country of Georgia in 2008, at the same time as Russian military operations on the ground.\nMore Government Insights\n- Demystifying Big Data: A Practical Guide to Transforming the Business of Government\n- Single Source of Truth for Managing Critical Assets Application Consolidation across Public Sector Organizations\n- Continuous monitoring for government agencies\n- Strategy Guide to Security Information Management in Government\n- Research: Federal IT Priorities: Focus On The Foundation\n- Research: Federal Government Cybersecurity Survey\nBut there's scant proof that the Russian government launched or sponsored online attacks against Georgia, according to many security experts, including Robert David Graham, CEO of Errata Security. \"There's no evidence the cyber attacks were by the Russian government, or that they were anything more than normal 'citizen hacktivism,'\" he said in a blog post. It's notable that this supposed first-ever cyber war served no clear military purpose. Attackers compromised informational government websites, not critical infrastructure systems or military networks.\nTo be fair, even the would-be practitioners of cyber warfare -- namely, the U.S. military -- are themselves soliciting input on what offensive computer system attacks might look like, either on their own or in conjunction with physical operations and kinetic attacks.\nLast year, for example, the Defense Advanced Research Projects Agency (issued a call to tech vendors for \"cyberspace warfare operations\" capabilities, as part of what Darpa dubs Plan X. Darpa seeks a broad range of capabilities, from a scripted counterresponse to a cyber attack to IT infrastructure that could be hardened to withstand attacks.\nSimilarly, the Air Force Life Cycle Management Center last year called on contractors to submit concept papers for \"cyberspace warfare operations\" capabilities, including \"cyberspace warfare attack\" and \"cyberspace warfare support.\"\nCapabilities on the Air Force wish list include \"employing unique characteristics resulting in the adversary entering conflicts in a degraded state.\" In other words, why blow up an enemy's tank if you can instead somehow infect and kill the tank's electrical system?\nWho else is bolstering their cyber war capabilities? Iran is a strong candidate, and in April 2012, the VP of the American Foreign Policy Council, Ilan Berman, told a U.S. House committee that Iran has been boosting its cyber warfare resources in the wake of online attacks against the country. The attacks include Stuxnet, malware blamed in 2010 for trying to attack power plant infrastructure. U.S. officials have accused the Iranian government of sponsoring DDoS attacks against U.S. banks. China has reportedly mobilized its own cyber army, and Russia last year launched a recruitment drive to find the country's best hacking minds, seeking people versed in \"methods and means of bypassing antivirus software, firewalls, as well as in security tools of operating systems,\" the newspaper Pravda reported.\nBut while governments don't face the same legal problems that companies do when considering offensive attacks, they do face the same major intelligence challenge: accurately tracing an attack's true origin, a process known as attribution. While small-time cybercriminals may leave tracks, government-backed professionals will go to great lengths to hide what they're doing -- or perhaps, pin blame on another enemy.", "label": 1}
{"text": "This blog article is reposted in part, with permission, from the SANS Ouch! Newsletter.\n[Editor's Note: (Wyman) This month we present an overview of why and how the Bad Guys do it, what it's called, and what you can do to protect your computer.]\nBlackhats. Hackers who use their skills for explicitly criminal or other malicious ends, such as writing malware (malicious software) to steal\ncredit card numbers and banking data or by phishing; a.k.a. the Bad Guys.\nPhishing. The practice of sending out fake email messages that look as if they come from a trusted person or institution-usually a bank-in\norder to trick people into handing over confidential information. The emails often direct you to a website that looks like that of the real\nfinancial institution. But it is a fake and has been rigged to collect your personal information, such as passwords, credit card numbers and\nbank account numbers, and transmit them to the Bad Guys.\nMan-in-the-middle. An attack in which a criminal hacker intercepts information sent between your computer and the website of your financial\ninstitution and then uses that information to impersonate you in cyberspace. The hacker is able to defeat even very sophisticated\nsecurity measures and gain access to your account.\nBotnet. Botnets consist of large numbers of hijacked computers that are under the remote control of a criminal or a criminal organization. The\nhijacked computers-a.k.a. “zombies” or “bots” (short for “robots”) -are recruited using viruses spread by email or drive-by downloads. Worms are used to find and recruit additional computers. The biggest botnets consist of thousands and even millions of computers, most often\nunprotected home computers.\nVirus. A malicious program that usually requires some action on the part of a user in order to infect a computer; for example, opening an\ninfected attachment or clicking on a link in a rigged email may trigger a virus to infect your computer.\nDrive-by Download. A kind of malware that installs itself automatically when you visit a booby-trapped website. Symptoms of a drive-by download include: your homepage has been changed, unwanted toolbars have been added, and unfamiliar bookmarks appear in your browser.\nWorm. Self-replicating malware that, for instance, hunts down unprotected computers and recruits them for criminal or other malicious\npurposes. Unlike a virus, worms do not require any action on your part in order to infect your computer.\nFake Anti-Virus. Fake anti-virus software purports to be a helpful program than can find and remove malware, but in fact it is malware–the\nvery thing that it’s supposed to eliminate. After taking over your computer, it pretends to do security scans, tells you it has found\nmalware, and then asks you to pay to have the non-existent malware removed. Whether or not you pay, fake anti-virus is likely to install\nWhitehats. Hackers who use their skills for positive ends, and often for thwarting blackhats. Many whitehats are security professionals who spend their time identifying and fixing vulnerabilities in software that blackhats seek to exploit for criminal or other malicious purposes.\nSecurity suite. A set of software applications designed to protect your computer that consists of anti-virus, anti-malware and a personal\nAnti-virus and anti-malware. Helpful software applications that scan your computer for certain patterns of infection. The patterns they scan\nfor are the signatures, or definitions, of known forms of malware. Since Bad Guys are creating new forms of malware continuously, it is important that you keep your anti-virus and anti-malware definitions updated. See\nthe “Patches and Updates” section below.\nPersonal firewall. Software that monitors incoming and outgoing traffic on your computer and checks for suspicious patterns indicating the\npresence of malware or other malicious activity. A personal firewall alerts you to these threats and attempts to block them. Like anti-virus\nand anti-malware software, personal firewalls require frequent updates to provide effective protection.\nUpdates. Security software relies on frequent updates in order to be able to counteract previously undetected forms of malware. Consequently, your computer may suffer a “window of vulnerability” between the time a new form of malware is identified and the time when your security software can block it or remove the infection. Set your security software to update automatically.\nPatches. Operating systems, like Windows and OS X, and software applications, such as Internet Explorer and Firefox, may be found to contain security flaws or holes that make your computer vulnerable to attack. Their makers release patches to plug the holes. The fastest and surest way to get these installed quickly is to use auto-updating via the Internet. Some software applications require manual updating. See the “Patches and Updates” section below.\nBlack Tuesday a.k.a. Patch Tuesday. On the second Tuesday of each month Microsoft releases security patches for Windows, Internet Explorer, Office and its other software products. You can have these installed automatically using Microsoft Update. See the “Patches and Updates” section below.\nAuto-updating. A software tool built into Windows (“Microsoft Update”) and OS X (“Auto Update”) and many other applications which can download and install important security updates and patches for software installed on your computer automatically. See the “Patches and Updates” section below.", "label": 1}
{"text": "Citywire printed articles sponsored by:\nView the article online at http://citywire.co.uk/money/article/a599570\nRisk and return: how to strike the balance in your portfolio\nMike Deverell of Equilibrium Asset Management explains how finding the right level of diversification can reduce the riskiness of your portfolio.\nInvesting can be a risky business. Risk and return are highly correlated; the greater the return you want to make, the more risk you need to take to have a chance of getting it.\nIt is therefore vital that you understand what risks are inherent in any investment you make. Only once you understand the risks can you decide if the potential return is worth it. There is no point taking more risk than is required to meet a given return.\nRisk and return: the theory\nSay there are two stocks, company A and company B. Both are expected to return around 10% growth to investors. However, company A has a much more volatile share price than company B and a greater risk of loss. Given the choice, most investors would invest in company B, which offers similar upside but with less risk.\nFor an investor to buy company A, they would want to see a much greater potential return to justify the extra risk they are taking.\nSo what different types of risk do you need to take into account, and can you do anything to reduce your risk?\n- Stock-specific risk: This is the risk inherent in an individual company. If you invested in just one stock, that individual company could underperform its peers (or even go bust) due to poor management, poor products, or just plain old bad luck.\n- Sector-specific risk: This is the danger that an entire sector could underperform the market. For example, the UK banking sector has underperformed the FTSE over the past few years because of the financial crisis.\n- Market risk: Both stock specific and sector risk can be diversified away by choosing enough different companies and sectors. You are then left with market risk, the risk that the market could fall. Remembering that risk and return are correlated, we could rename this 'market opportunity', the potential that the market will rise.\nThere is some debate as to how many positions are required to diversify away stock- or sector-specific risk. It is generally thought that at least 25 to 30 individual stocks are needed to diversify away most of the specific risk.\nThe simplest way of diversifying this away is to use funds, particularly index tracking funds.\nOnce you start looking overseas for opportunities, other risks come into play.\n- Currency risk: Say you invest in Japan and your investment goes up by 10% in local currency terms. However, the Yen weakens by 15%. You’ve lost money, despite your apparently great stock picking! Some funds avoid this risk by currency hedging, but this increases the cost of investing.\n- Geographic risk: Some countries by virtue of simple geography are riskier to invest in than others. Last year’s Japanese earthquake and tsunami is an obvious example of how an economy and a market can be affected by natural disaster.\n- Political risk: This is the risk that government policy will have an adverse effect on your investment. This has historically been most prevalent in emerging market investing. For example, if you invest in China you would probably want an additional return compared to investing in the UK, due to the inherent political risk.\nUnfortunately, political risk now seems to be unavoidable in any market and is currently the main driver of price movements of virtually all assets. As the eurozone debt crisis and the implications for our financial system continue, this seems unlikely to change soon.\nConstructing a portfolio\nTo recap, risk and return are intrinsically linked, but some risks can be diversified away. By diversifying correctly, you can increase your potential return and reduce your risk.\nAs well as diversifying away specific risks in stocks, you can also diversify away some of the market risk of equities by investing in other asset classes, such as bonds and property. The asset allocation of a portfolio is the key driver of returns.\nGetting the mix of a portfolio right is difficult. It is possible to overdiversify, as once you get past a certain point each additional position makes a much smaller difference to your risk.\nMore about this:\nMore from us\n- Why passive funds beat active management\n- Asset allocation: where bonds fit in to the big picture\n- Sharpen your asset-allocation skills to profit from the volatility\n- Equilibrium Asset Management\nTools from Citywire Money\nFrom the Forums\nWeekly email from The Lolly\nGet simple, easy ways to make more from your money. Just enter your email address below\nAn error occured while subscribing your email. Please try again later.\nThank you for registering for your weekly newsletter from The Lolly.\nKeep an eye out for us in your inbox, and please add firstname.lastname@example.org to your safe senders list so we don't get junked.", "label": 1}
{"text": "Navy delves deeper into undersea robotics\nBy the end of the decade, the Navy plans to deploy squadrons of unmanned underwater robots to survey the ocean. But there are a lot of challenges operating underwater, and the robots will require a great deal of autonomy to carry out search and mapping missions.\nThat’s the goal of the Adaptive Networks for Threat and Intrusion Detection or Termination (ANTIDOTE) program. Funded by the Office of Naval Research (ONR), ANTIDOTE’s team of scientists from the Massachusetts Institute of Technology and the University of Southern California is developing software-based methods for large teams of robots to perform more sophisticated missions autonomously in dynamic, time-critical environments and with limited communications.\nA major part of the program focuses on autonomous planning and replanning methods, said Marc Steinberg, ANTIDOTE’s program officer at ONR.\nEnergy lab’s microscopic robots assemble selves, can move larger objects\nAndroid phones to be ‘brains’ of space station robots\nThe underlying theory behind ANTIDOTE was for persistent surveillance of dynamic environments, regardless of the vehicle type carrying out the mission, Steinberg said. For example, some successful simulation experiments have been conducted with unmanned air systems.\nUndersea vehicles have very limited communications compared with systems that operate above ground, Steinberg said. This drives a need for autonomy because the robot subs can’t rely on a human operator.\nAdditionally, there are unique challenges in navigation, mobility and sensing underwater. For example, the undersea glider robots in ANTIDOTE's experiments use changes in buoyancy for propulsion, rather than an active device such as a propeller. This enables them to have an extended endurance, but it also requires that gliders move up and down in depth in a saw-tooth-like pattern, which has a big impact on how to do autonomous planning to maximize the value of the scientific data being collected.\n“The sea experiments were a great way to examine how some promising theoretical results would work in a real-world situation of practical value to scientists,” Steinberg said. Prior theoretical work had looked at how autonomous vehicles can best perform persistent surveillance in a dynamic environment.\nIn the sea tests, the new software was used to generate paths for the underwater gliders to collect oceanographic data. The method takes into account both user priorities and ocean currents in determining these paths. The experiments, in southern California and in Monterey Bay, Calif., involved a glider using this new capability and a reference glider that followed a more traditional fixed path.\nResults of the experiment showed that the vehicle using the new method executed two to four times as many sampling profiles in areas of high interest when compared against the unmodified reference glider, while maintaining an overall time constraint for the completion of each circuit of the path, ANTIDOTE researchers said in a statement.\nOverall, the results validate that the theoretical results can be of value in solving real-world surveillance problems with autonomous systems, Steinberg said.\nThe ANTIDOTE program is near the end of its third year. After that, Steinberg said that it is up to ONR leadership to decide whether to fund it for an additional two years.\n“As a fundamental research program, the main products are new theory and methods,\" he said. \"Some of these are being implemented in software and will be available to other researchers via open architectures for robots.”\nHenry Kenyon is a contributing writer for Defense Systems.", "label": 1}
{"text": "updated Aug 18, 2008 8:55 pm | 6,384 views\nRevision as of 19:50, 24 July 2007\nSpyware is defined as a program that secretly monitors your actions on your computer. Any data collection program that gathers information about you and relays it to advertisers and/or other interested parties falls under this Internet jargon.\nSpyware is any software that employs a user's Internet connection in the background (the so-called \"backchannel\") without their knowledge or explicit permission.\nIn order to not be considered spyware, silent background use of an Internet \"backchannel\" connection must be preceded by a complete and truthful disclosure of proposed backchannel usage, followed by the receipt of explicit and informed consent for such use.\nAny software communicating across the Internet without these key elements is guilty of information theft and is properly and rightfully termed: Spyware.\nThe effects of spyware are varied and depend a lot on your system. The most common effects include:\nThe list could go on and on but I think you get the idea. So, do not just assume it is a virus when your system crashes, behaves strangely, or acts erratically.\nHere are the main players in the defense against Spyware (in no particular order):\nSpybot (Freeware), AdAware (comes in a variety of flavours; all with increasing levels of defense, control and cost), Pest Patrol (again, like Adaware it has a variety of Flavours), Spy Sweeper, Ewido, and A2Squared.\nSpyware is software that gathers information about your Web-surfing habits for marketing purposes. Spyware \"piggybacks\" on programs you choose to download. Tucked away in the fine print of user agreements for many \"free\" downloads and services is a stipulation that the company will use spyware to monitor your web habits for business research purposes.\nSpyware takes up memory and space on your computer. It can slow down your machine, transmit information without your knowledge, and lead to general computer malfunction. One of the most widely-used Web browsers, Internet Explorer is especially susceptible to spyware-related problems. You may choose to keep certain spyware programs on your computer in exchange for the free services that accompany them, but you should be aware of how that might affect your computer.", "label": 1}
{"text": "Once an attacker has physical access to the computer, he almost certainly has access to the data on it, writes Security Supersite Editor Larry Seltzer. If so, the OS doesn't really matter.\nVery often well hear reports about a serious security vulnerability. We look into it, and theres a catch: In order to execute the attack, physical access to the computer is necessary.\nYou can safely ignore these alleged vulnerabilities: Without physical security, no system is secure.\nIf I can open the computer, I can remove the hard disk, put it in as the second drive in another computer and read the contents of the disk. Bye-bye, security. But its not usually necessary to open the box. I can boot the system off a floppy disk or CD-ROM and read the hard disk that way. Given such access, there are commercial and free tools available\nthat can reset the Administrator password on the installation of Windows NT, Windows 2000 or Windows XP - gaining access to a Win9x system is even easier. (The existence of these tools is a good\nthing; administrators need to be able to access systems where the passwords are forgotten or changed for malicious purposes.)\nBut even thats not necessary; if you can boot off the floppy or CD, you can install a second copy of Windows on the hard disk and run that to analyze data on it.\nThis point is very important when considering whether attacks represent vulnerabilities in the computers operating system: If I boot the system off the floppy or CD-ROM, the operating system on the hard disk is not running. Its just a bunch of files.\nYour only potential protection when physical security is breached is to use an encrypted file system, such as Windows 2000 Pro and Windows XP Pros EFS. (See this article\non the SecurityFocus Web site for a good explanation of encrypting file systems.) No operating system (to my knowledge) employs such a file system by default.\nThe most recent such case of significance was an allegation by a famous writer that one could break into a Windows XP system by booting off a Windows 2000 CD and running the Recovery Console. The Recovery Console is a special console mode OS used to repair Windows 2000 and Windows XP. You run it by installing it to the hard disk and booting into it, or booting it directly off the Windows installation CD. See this Microsoft Knowledge Base article\nfor a description of the Recovery Console, and this one\nfor a description of the Windows XP Recovery Console.", "label": 1}
{"text": "MS10-047 is not categorized as virus, worm, Trojan or backdoor. It is a group of important vulnerabilities in the Windows Kernel on Windows 2008/Vista/XP computers, which allows to gain local privilege escalation and to launch denial of service attacks.\nThe kernel is the core of the operating system and provides basic services for all other parts of the operating system.\nIf exploited successfully, MS10-047 allows to gain unauthorized privileges on a computer or network. An example of privilege elevation would be an unprivileged user who could manage to be added to the Administrator's group. In such case, the hacker could take complete control of the system: create, modify or delete files, install programs, create new user accounts, etc. It could also cause the system to stop responding until it is restarted.\nMS10-047 is usually exploited by running a specially crafted program in the vulnerable computer. In order to do so, a hacker must be able to log on locally to the system.\nIf you have a Windows 2008/Vista/XP computer, it is recommended to download and apply the security patch for this vulnerability. Click here to access the web page for downloading the patch.\nBear in mind that this security patch replaces a previous one, called MS10-021.", "label": 1}
{"text": "In the course of a busy day, you may write a\ncheck at the grocery store, charge tickets to a ball game, rent a\ncar, mail your tax returns, change service providers for your\ncell phone, or apply for a credit card. Chances are you don't\ngive these everyday transactions a second thought. But an\nidentity thief does.\nIdentity theft is a serious crime. Identity\ntheft is a crime in which an imposter obtains key pieces of\ninformation such as Social Security and driver's license numbers\nand uses it for their own personal gain. People whose identities\nhave been stolen can spend months or years and thousands of\ndollars cleaning up the mess the thieves have made of a good name\nand credit record. In the meantime, victims of identity theft may\nlose job opportunities, be refused loans for education, housing,\nor cars, and even get arrested for crimes they didn't commit.\nHumiliation, anger, and frustration are among the feelings\nvictims experience as they navigate the process of rescuing their\nThere are four types of identity theft crime:\n- Financial ID Theft This type of\ncase typically focuses on your name and Social Security\nnumber (SSN). This person may apply for telephone\nservice, credit cards or loans, buy merchandise, lease\ncars or apartments.\n- Criminal ID Theft The imposter in\nthis crime provides the victim's information instead of\nhis or her own when stopped by law enforcement.\nEventually when the warrant for arrest is issued it is in\nthe name of the person issued the citation- yours.\n- Identity Cloning In this crime the\nimposter uses the victim's information to establish a new\nlife. They work and live as you. Examples: Illegal\naliens, criminals avoiding warrants, people hiding from\nabusive situations or becoming a \"new person\"\nto leave behind a poor work and financial history.\n- Business or Commercial Identity Theft\nBusinesses are also victims of identity theft.\nTypically the perpetrator gets credit cards or checking\naccounts in the name of the business. The business finds\nout when unhappy suppliers send collection notices or\ntheir business rating score is affected.\nNo matter what type of identity theft is involved, the result\nis a long and sometimes arduous road to recovery. As in all\ncrimes, preventing the crime from occurring in the first place is\nIdentity theft is a complex problem. You will\nnot be able to work on clearing your name as fast as you'd like.\nCompanies move slowly, partly to protect you. Most imposters are\nnever found, let alone arrested or convicted. This is often not\nthe fault of law enforcement, but rather the nature of the crime.\nSo, work with the police, help them out when you can, but let\nthem investigate. Work on clearing your name and getting your\nlife back to normal.\nthieves get your personal information\n»How identity thieves use your personal\n» Steps to Take When Identity Theft Happens\n» Chart of Action\n» Tips to Protect Yourself\n» File a Police Report\n» What You Can Do\n» Download Identity Theft Coach", "label": 1}
{"text": "2 Tips for a Secure Password\nWe were surprised to learn that some of the leading sites (LinkedIn, Dropbox) got hacked recently. The problem is that most of us have one or two passwords we use across multiple websites. This can cause a significant problem when a hacker discovers one of these passwords and gains access to virtually all the user’s accounts. Fortunately, there are two simple steps to creating an uncrackable password.\n1. Create an Acronym as Your Base Password Think of a sentence, something like “I like walking in the park on a sunny day”, or a refrain from your favorite song like “Billie Jean is not my lover, she’s just a girl who claims that I am the one” and take the first letters of the words. In the latter case, it would be BJINMLSJAGWCTIATO - nearly impossible to crack, but super easy for you to remember.\n2. Modify for Each Website Create a rule, where you append the base password with a variation based on the name of the site. It might be the first vowel, repeated twice, followed by the second consonant of the site’s name. So for Yahoo Mail, it would be AAH. For Dropbox it would be OOD. Or something like that. Now you have 1 set of rules, which are very easy for you to remember, but virtually impossible to crack. Best part, if any of the sites get hacked, your password will be completely safe.\nNow that you secured your email, it’s time to try SaneBox!", "label": 1}
{"text": "Making sense of vast amounts of data is made easier through processor improvements, faster networks and a growing amount of cloud storage capacity, but there’s another factor that’s accelerating the ability to sift through information: user communities. At the Structure Big Data event on Wednesday, Alfred Spector, a VP of Research and Special Initiatives at Google, illustrated how to combine low-level user data with the massive information stores and cloud computing services offered by his company.\nPerhaps the most prominent example is Google’s geographic data used both in both the Google Maps and Earth products. The company harvests global information to create useful products in their own right, but each can be supplemented through localized user data. A modern data management web app makes it easy for Google to host, manage, allow collaboration and publication of data tables or personalized maps. For example, Google Maps data combined with information from hospitals and doctors can easily show which nearby health-care providers have flu vaccines available.\nMaking large amounts of data usable and modifiable by end users has the potential to create solutions that Google hasn’t envisioned yet. But what it has done is allowed for what Spector calls a “hybrid intelligence” because users and computers are doing more together than either could do individually. Scientists that track global warming may only have access to limited datasets which show only a small picture of the overall situation. Google Earth, however, can augment its base data with sensor information from various satellites and datapoints, providing a more holistic view of global warming.\nThis user community and data combination approach is leading to smarter machines as well. The voice search features offered by Google are becoming more accurate due to speech recognition data provided by users. In effect, the speech service is training itself because it’s learning from all of the incoming data.\nJust as they can with Google Maps data, end users can leverage these smarter machines as well. Spector said that a spam-killing blog moderator could be created by end users if they train the system with both good blog posts and spam comments. Those inputs, combined with Google’s prediction APIs and Python scripts, would effectively create an intelligent automated moderator that could continuously improve its own performance.", "label": 1}
{"text": "What is identity theft?\nBasically, identity theft involves someone taking your personal information without your knowledge to commit fraud or theft. According to the Federal Trade Commission (FTC) identity theft costs Americans billions of dollars every year. It is estimated that as many as 9 million Americans have their identity stolen each year. Victims can spend hundreds of dollars and countless hours trying to repair their credit and good name. The latest trend involves thieves taking advantage of the current economic situation by targeting job seekers, by establishing fake online job sites.\nThe FTC recommends a deter, detect, and defend approach to protect yourself from identity theft. You can deter identity theft through safeguarding your information. Detect identity theft by monitoring your financial accounts and billing statements regularly.\nDefend yourself by following the following steps should you suspect a problem in order to minimize the damage:\n1. Place a “Fraud Alert” on your credit reports and review the reports carefully. The three nationwide consumer reporting companies have toll-free numbers and can place a 90-day Fraud Alert on your credit report:\nExperian: 1-888-EXPERIAN (397-3742)\nA call to any one of the three companies is sufficient and entitles you to free copies of your credit report once the fraud alert is placed.\n2. Close all accounts that have been opened fraudulently or any existing accounts that have been tampered with. Notify your bank to flag your accounts and to contact you should there be any unusual activity. Keep a record of your conversations regarding your accounts, including the date, time, and the name of the person you spoke with. Also, keep copies of documents regarding the theft.\n3. Contact your local police. Obtain a copy of the police report.\n4. Contact your nearest U.S. Postal Inspection Service office.\n5. Contact the Social Security Administration’s Fraud Hot line at 1-800-269-0271.\n6. Contact the Department of Motor Vehicles to find out if another license was issued in your name. If so, request a new license number and fill out a complaint form for the DMV to begin the fraud investigation process.\n7. Report the identity theft to the FTC which helps law enforcement across the country in the investigations. Call 1-877-ID-THEFT (438-4338) to report the theft.\nIf, after following all the above steps, you feel you need an investigator for follow-up investigation, or consultation, we are there to help.\nCall Toll Free for More Information and a FREE Consultation!", "label": 1}
{"text": "Asudhak, don't feel bad if this is a bit confusing. Inventing asymmetric cryptography was a huge advance in Mathematics. It seems very counter-intuitive if not down right impossible when one first encounters it.\nWhen a client (often a web browser) and a server (often a web browser) want to establish a secure communications channel they perform what is called a 'key exchange'.\nThe public key that the server provides to the client program contains nothing secret. It's only function is to encrypt information.\nThe client generates a one time secret password that only the web browser knows. The client then uses the server's public key to encrypt that one time use secret password. The public key can only encrypt, the public key can not decrypt!\nThe client can safely transmit this encrypted secret password to the server. Any man-in-the-middle who might intercept this key exchange will gain no useful information since he almost certainly can't decrypt that one time use secret generated by the client and encrypted with the server's public key.\nThe server, and only the server has the corresponding private key. The server's private key can only be used to decrypt. The server's private key is never transmitted to anybody!\nThe server uses the private key to decrypt the one time secret password that was generated by the client (web browser).\nThe client and the server now both know a secret that nobody else knows!\nUsing this secret they can encrypt their subsequent conversations using any traditional symmetric encryption algorithm with a high degree of confidence that the channel is secure.\nIn addition, the client has a store of 'certificates' that contain the public keys of organizations that it trusts. The actual TLS key exchanges will fail if the server doesn't present a digital document called a certificate that contains a hash value encrypted with the trusted organization's private key. The client can use this hash and the trusted public key to know that this server is considered trustworthy.", "label": 1}
{"text": "Put a somewhat less descriptive, but more conceptual way, basically you want to provide two different means to get to the same key. This is the idea of having a data key, typically unique to a record, or perhaps to all of a user's records, depending on security needs. You then encrypt that key with a key derived from their password and a key derived by some other piece of information. It could be an alternate thing that they know or it could be something that your server knows. This can either be symmetric cryptography, or for greater security, the information your server knows can use a public key for a private key that is not held on the server.\nThen if the user ever loses there password and is thus unable to access the data key, the alternate encryption of it can be decrypted to retrieve the key. In order of security, symmetrically storing the key on the server is least secure as if both the server and DB are compromised, the encryption is rendered useless. The user information might be a little better, but for it to be easily rememberable, it will also likely be easily researchable or guessable, which is insecure even if the server isn't compromised. The asymmetric option where the server doesn't have access to the information necessary for a reset (because it only knows how to encrypt the recovery version of the data key is the most secure, but it is also the most difficult from a usability standpoint as the decryption then has to either be done a) by hand or b) by a secondary, highly secured server, preferably holding the private key in a TPM (trusted platform module) or some other secure hardware keystore.\nEither way though, the basic principal is the same. You always make the key unrecoverable without the secret, you just store it multiple times with different secrets.", "label": 1}
{"text": "Cloud Computing Overview\nThe cloud computing engine is a natural extension of the Internet. One of the terrific advantages is the transition to the point where there are no major software upgrade releases; cloud is about building software capability that is continuously improved. It is about hosting software on an Internet platform that works, where the user does not have to worry about the platform. Major software releases are rare on the cloud. Software test and development are an ongoing process and software upgrades are released as appropriate, but certainly on a weekly basis.\nCloud software exposes syntax and applications to users across the board for all different kinds of applications. In a sense, cloud computing is so powerful that we can think of it as a black hole that depends on the creativity of the provider. Cloud initiatives are bound only by the user’s imagination. The quantity of data and the quality of analytics leave the possibility of innovation at every users desktop, laptop, netbook, tablet, smart phone, and Internet accessible device.\nCloud is in a sense another name for self-service computing. In this respect it is the opposite of the old batch oriented mainframe computers. It is a new, fleet footed, sure way for users to independently define and automate tasks in real time, using their own integration syntax and their own ability to create content modules that are meaningful. No more waiting one year for IT to prepare a mailing list that only IT can change, no more running tasks in batch. In the cloud, everything happens using open systems in real time.\nCloud computing provides a consolidated working environment where collaboration is possible and encouraged. Systems are dense. Systems use 80% less energy and transform systems management, creating automated process to replace what previously has taken hundreds of technicians. Hundreds of technicians that have been responsible for managing individual servers can be replaced with six technicians able to run a virtualized system, achieving significant savings in operations costs Running virtualized workloads on consolidated platforms is called modernization. This virtualized, software managed cloud computing environment depends on hypervisors and software systems that streamline workload deployment.\nSo, from the users perspective the cloud is an altogether new and different approach to computing, a utility like service where the machine is always on, always available, and intuitive to use. But, from the IT administrators perspective, the advent of cloud computing brings some of the old along with the new. The old mainframe workload manger has been revitalized, achieved new capabilities, and been given an industry transformational status, given new life under a new, more powerful cover, the IBM zEnterprise 196. The era of hybrid computing has been ushered in under the name of cloud computing.\nMore and more, the cloud is used to implement enterprise applications. Customization, optimization, security, privacy, availability, and reliability are key to keeping automated process producing revenue consistently. Modular systems have become key, some are built with some application SOA services orientation, and some to support Web applications based self-service.\nPrepackaged, self-contained, purpose-built service delivery platforms combine the best of hardware, software and services to quickly accelerate the creation of service platforms for all types of workload.\nOver the next few months I will be sharing with you my thoughts on cloud computing, across topics like the business case for cloud computing, Infrastructure as a Service, Software a a Service, Platform as a Service, and Process as a Service all in the context of cloud virtualized systems. And I will be passing along some insights from some IBM cloud experts, as they continue to grow their enterprise cloud capabilities, most recently showcased on December 1. https://events.unisfair.com/rt/ibm~cloudlaunch Come back often and stay well-informed about cloud computing.and x86", "label": 1}
{"text": "Quality of Service for Web Services-Demystification, Limitations, and Best Practices, Page 2\nWeb Services Accessibility\nAccessibility defines whether the Web Service is capable of serving the client's request. High accessibility of Web Services can be achieved by building highly scalable systems.\nBuilding scalable systems are expensive, and this may cause smaller companies to defer this requirement. Also, this becomes an infrastructure issue for companies that deploy Web Services within their enterprise.\n- Service pooling\n- Load balancing (Scalability)\nWeb Services Availability\nAvailability defines whether the Web Service is ready for immediate consumption. Associated with availability is Time-to-Repair (TTR). TTR represents the time it takes to repair the Web Service.\nBuilding fault-tolerant systems for highly available Web Services is expensive. As companies roll out Web Services, the ability to manage this diverse, dynamic, distributed environment will become critical. Questions such as the following arise:\n- Has one of my key servers become unavailable?\n- Is a system being overly burdened?\n- Why are requests taking so long?\n- Web Service Management\n- Web Service Clustering\nWeb Services Interoperability\nThe fundamental goal of interoperability in Web Services is to cross the lines between the development environments used to implement services so that developers using those services don't have to think about which programming language or operating system the services are hosted on.\nMost of the Web Services specifications are defined under standards bodies. As these activities are under way, there seems to be a delay in the implementations. Vendors partly implement the specification in their products due to the competitive nature of this market. This results in poor interoperability.\n- Key to enabling seamless Web Services interoperability is the ability of one Web Services framework to consume the WSDL documents generated by other frameworks.\n- Web Services-Interoperability (WS-I) Profiles.\nThe Basic Profile defines how a selected set of specified Web Services technologies, such as messaging and discovery, should be used together in an interoperable manner.\nWeb Services Security\nWith the increase in the use of Web Services, which are delivered over the public Internet, there is growing concern towards security. Security for Web Services means providing non-repudiation and confidentiality by authorizing the parties involved, encrypting messages, and providing access control. The Web Service provider may apply different approaches and levels of providing security policy depending on the service requestor.\nSOAP is a de-facto messaging standard for Web Services; inherently, it does not support many security features. Some of the Web Services-enabled applications also require role-based security features, which expose different functionalities, depending on user credentials. Underlying technologies used by Web Services currently do not support these features.\nThe security-related issues in Web Service must be dealt with greater vigor, as it will build confidence among users. The following measures can be used while architecting the secure Web Services:\n- Use of XML Encryption.\n- Use of XML Key Management Specification.\n- Use of Private WANs, Web Service Network, and VPNs.\n- P3P (Platform for Privacy Preferences) is an emerging standard for specifying privacy preferences for a user while using Web Services.\n- Use of security assertions.\nConclusionQoS for Web Services is about bringing business value to service providers by guaranteeing a competitive edge through their ease of adoption and implementation. With these collections of best practices for the design and implementation of Web Services, one can think of Web Services as a perfect replacement for traditional integration problems that are being faced by the enterprises today. We will be analyzing each of these proposed best practices in forthcoming articles.\nAbout the Authors\nRajesh Sumra is a senior software engineer in HP's Wireless Solutions Lab. He has worked with the espeak project for more than a year and was involved in developing UDDI Server functionalities for the HP's UDDI Server. Currently, he is involved with designing and developing a Web Services-based framework for the mobile infrastructure. Rajesh holds a Masters degree in Information Technology from IIIT, Bangalore. He can be reached at firstname.lastname@example.org.\nArulazi D has been designing and building Java-based applications and SDK for more than three years. He was also involved in the API development of UDDI4j project (http://uddi4j.org). He works with Hewlett-Packard (ISO), where he is involved in the development of an open-service framework for mobile infrastructures. He holds a Master of Computer Applications degree from the PSG College of Technology, Coimbatore. He can be reached at email@example.com.", "label": 1}
{"text": "(ARA) – The app world is booming and today there are more than 1 million mobile apps available for download through online stores run by companies like Apple and Google. Many apps are available free of charge and collect user data for advertising purposes, raising the question: What is the true cost of these “free” apps?\nSmartphones today collect and store a wealth of personal information because they’re always “on,” and typically go wherever their users go. Consumers store extensive contact information, calendar data, and personal videos and photos on these devices. Modern smartphones may also contain GPS technology capable of collecting precise data about the phone’s movement and location in near real-time.\n“Personal data collection online has been happening for years on traditional PCs,” says Babel. “The difference today is that these ‘computers’ now sit in our pockets in the form of smartphones, and are capable of collecting more types of data, in greater quantities, than ever before. It’s a far more complex ecosystem and it can be difficult for consumers to understand what’s happening with their data. ”\nUnwelcome data collection on smartphones can lead to unwanted and intrusive advertising, and increase the risk of data breaches as companies build ever-larger databases of personal information profiling consumers. Before you click that next free download, TRUSTe recommends taking these steps to protect your privacy:\nSet app and smartphone privacy settings\nMany apps contain privacy settings that can control behaviors like what information the app collects, how it interacts with other apps or a user’s contacts, and how it communicates with and alerts the app user about its background activity. In some cases, these settings may have their own section under a “privacy” tab within the app, but more often than not these privacy settings are found alongside standard settings within the app, like volume levels or sound effects.\n“We commissioned a Harris Interactive survey and found that nearly three quarters of the population worries about their privacy when using mobile apps,” says Babel. “App developers not only have a responsibility to provide consumers with mobile-appropriate privacy disclosures, but also meaningful choices about how their data is collected and used.”\nThe settings tab of your smartphone operating system (like iOS for Apple devices) may also contain important privacy choices, allowing you to control the types of personal information that apps may collect from the device. Depending on your device, these settings may also provide you with granular privacy control over apps, preventing one app, for example, from collecting GPS data while allowing other apps to collect this data.", "label": 1}
{"text": "Schneier on Security\nA blog covering security and security technology.\n« Power and the Internet |\n| Jared Diamond on Common Risks »\nJanuary 31, 2013\nThe Eavesdropping System in Your Computer\nDan Farmer has an interesting paper (long version here; short version here) discussing the Baseboard Management Controller on your computer's motherboard:\nThe BMC is an embedded computer found on most server motherboards made in the last 10 or 15 years. Often running Linux, the BMC's CPU, memory, storage, and network run independently. It runs Intel's IPMI out-of-band systems management protocol alongside network services (web, telnet, VNC, SMTP, etc.) to help manage, debug, monitor, reboot, and roll out servers, virtual systems, and supercomputers. Vendors frequently add features and rebrand OEM'd BMCs: Dell has iDRAC, Hewlett Packard iLO, IBM calls theirs IMM2, etc. It is popular because it helps raise efficiency and lower costs associated with availability, personnel, scaling, power, cooling, and more.\nTo do its magic, the BMC has near complete control over the server's hardware: the IPMI specification says that it can have \"full access to system memory and I/O space.\" Designed to operate when the bits hit the fan, it continues to run even if the server is powered down. Activity on the BMC is essentially invisible unless you have a good hardware hacker on your side or have cracked root on the embedded operating system.\nWhat's the problem?\nServers are usually managed in large groups, which may have thousands or even hundreds of thousands of computers. Each group typically has one or two reusable and closely guarded passwords; if you know the password, you control all the servers in the group. Passwords can remain unchanged for a long time -- often years -- not only because it is very difficult to manage or modify, but also due to the near impossibility of auditing or verifying change. And due to the spec, the password is stored in clear text on the BMC.\nIPMI network traffic is usually restricted to a VLAN or management network, but if an attacker has management access to a server she'll be able to communicate to its BMC and possibly unprotected private networks. If the BMC itself is compromised, it is possible to recover the IPMI password as well. In that bleak event all bets and gloves are off.\nBMC vulnerabilities are difficult to manage since they are so low level and vendor pervasive. At times, problems originate in the OEM firmware, not the server vendor, adding uncertainty as to what is actually at risk. You can't apply fixes yourself since BMCs will only run signed and proprietary flash images. I found an undocumented way of gaining root shell access on a major vendor's BMC and another giving out-of-the box root shell via SSH. Who knows what's on other BMCs, and who is putting what where? I'll note that most BMCs are designed or manufactured in China.\nBasically, it's a perfect spying platform. You can't control it. You can't patch it. It can completely control your computer's hardware and software. And its purpose is remote monitoring.\nAt the very least, we need to be able to look into these devices and see what's running on them.\nI'm amazed we haven't seen any talk about this before now.\nEDITED TO ADD (1/31): Correction -- these chips are on server motherboards, not on PCs or other consumer devices.\nPosted on January 31, 2013 at 1:28 PM\n• 44 Comments\nTo receive these entries once a month by e-mail, sign up for the Crypto-Gram Newsletter.\nHmm. How are those BMCs accessed? Do they have their own IP? Take over some port from the OS? Or wait for some secret protocol? Have their own port and connection?\nIf someone 20 or 30 years ago had written a science fiction story about something like this happening in the future, they would have been laughed at. Nobody could ever be so stupid as to allow a situation like this to happen! Yet here we are.\nThe conclusion that I've reached is that humans, for all their self-advertised intelligence, are basically stupid beasts who do whatever seems convenient and easy at the moment. They have no ability to envision future possibilities in any real sense, and will not change their behavior to avoid disaster. Instead, they adapt to the consequences when the time comes.\n@EPh - BMC has its own IP address. Ethernet port can be dedicated or shared with OS.\nOn my MacBook:\nbash-3.2# networksetup -showBMCSettings\nUnable to determine if BMC is supported - error 0xFFFEF92D.\n** Error: BMC is not supported on this device.\nI work with these facilities quite a bit as a server administrator. It's not entirely true that these are unable to be patched.\nWorking with Sun(now Oracle), HP, Dell, IBM server hardware, we've had to patch and in fact did patch these controllers consistently, most often due to bugs, or secondly to pick up new features that we wanted to use to help us with either performance (Patches usually also contain BIOS firmware upgrades) or to help keep them managed efficiently.\nFor the big guys at least, they are able to be patched, but admittedly, it can be a pain in the butt, and I don't know how many actually do it outside of my own practices, but they are certainly possible to be patched to fix any bugs they might be found to contain. I'm sure this varies by hardware vendor, or perhaps age of systems, so there is some risk there too.\nAnton Yuzhaninov has it right. And there are a few things you can do to mitigate this risk.\na. don't plug in the management port if you don't want to use it.\nb. restrict access to the VLAN (or physical switch) that you connect it to if you do connect it.\nc. restrict access to the IP addresses you assign to them if they are connected.\nAfter that, if someone gets access to them you'll have to fall back on strong passwords and staying current with the patches. Fortunately, the patches are usually easy to apply and do not require rebooting the server since they are are on a sub-system of that server.\nEPh: They have their own ethernet port on the box. Smart money is to put them on their own (unrouted) VLAN and behind a firewall.\n@Kryai - as with other closed source products you are depend on vendor. If vendor don't want to ship new BMC firmware version after some bug in code is reported, you servers will be vulnerable.\n@EPh: BMCs may have a dedicated ethernet port or share a main system port, depending on a particular system's configuration. They're assigned an IP address, usually in private / nonrouteable space (10.0..0/8, 172.16.0.0/12, or 192.168.0.0/16) that's accessible only within the datacenter LAN for an entity. However access may be forwarded outside (say, to the office LAN where admins are located), or made available through a bastion host or port-forwarding to specific network ranges or IPs.\nYou're going to find BMCs of some sort on virtually all server-grade hardware (and few admins would accept hardware that doesn't offer such functionality because of the utility of the remote management provided). Typical uses are to provide a \"failsafe\" serial-console access to a system, and allow hard/soft reboots. Vendor extensions to IPMI (iDRAC, iLOM, etc.) often rely on additional technologies such as Java (what could possibly go wrong). And there is often a Web interface to at least some functionality. IPMI will generally offer SNMP traps (monitoring facilities), which is a protocol with its own host of security concerns.\nIn addition to BMCs there are other \"under the OS\" systems with similar concerns. Virtualization systems such as Xen (used by Amazon for its AWS / EC2 services), VMWare (used by many organizations to virtualize systems and services for managment), and others (VirtualBox, Parallels, KVM, qemu, ...). Boot systems including particularly EUFI, but also bootloaders which are themselves increasingly small operating systems themselves. The guys who sweat security and trust really sweat this stuff.\nIn addition to BMC on server boards, many laptops now have Intel's AMT which serves a similar purpose. In my experience it's always disabled by default, but it seems like it would be subject to the same security concerns.\nIt's nothing new really. We've deployed many servers with these functions, and best practice is to have them in their own private & secure VLAN without the ability to connect outwards to anything.\nBasic measures, just like protecting ssh and root access to the server OS.\nThis isn't a new concern. On an individual scale it's akin to having the TPM (Trusted Platform Module) or NIC firmware compromised.\nIn 2010 whitepapers/security presentations were done on all three threat vectors.\nWhat's odd is not much has been said since.\nOf note is that I once found an attempt to infect a Broadcom chipset via it's ASF - In the Wild.\nThat short version really is short...\nIn addition to the points that Brandioch Conner noted, checking your log files regularly would help to identify a pending or possible compromise (i.e. HP servers have a logger that tracks who logged or attempted to log into what they call iLO (integrated lights out), the ip, username etc.).\nI'm less familiar with Dell but have used their equivalent iDRAC (no idea offhand what that stands for) on the handful of Dells we run but it's similar too.\nFor the truly paranoid, you could perform a packet capture for traffic destined to the mgmt ip earlier in the stream and log it elsewhere to protect against missing an attacker erasing their tracks (or to correlate logs for integrity, etc. :)\nI was gonna say - I *wish* my desktop had IPMI! I would have uses for that.\nBut no. While it CAN share a NIC with with OS (and Supermicro's do by default, which is very naughty of them especially since the default password for the just-grabbed-a-DHCP-address interface is \"ADMIN/ADMIN\"), that's configurable, and most of the time accessing IPMI means plugging a new wire into the management port. If you run that to your shared LAN switch, then sure, you've opened the IPMI interface to everyone on the LAN - but the solution is *don't do that*. If it's physically connected only to a physically secure network, then you're fine unless the attacker physically has your server. And if the attacker physically has your server, you're already screwed.\nDell DRAC ~ Dell Remote Access Controller. The DRAC comes in several levels; the systems I maintain have the lowest level version and have their network support disabled, which is typically over a NIC shared with the OS. We run FreeBSD which, by default, doesn't support IPMI, and run the servers in a mode that prevents kernel modules from being loaded once the system is in multi-user. In theory this would prevent the IPMI support modules from being loaded. Also, in theory, communism works.\nI've recently concluded that IPMI gives us some additional monitoring capabilities that are useful (e.g., determining system temperature, fan RPMs, etc.), but do not trust the network stack on these devices to be fully hardened and am allowing IPMI access only by root locally on the system. This seems to be a reasonable tradeoff between usability (being able to monitor system health) and security (exposing IPMI capabilities to root).\nBiggest problem: some BMCs seem to default to RFC1918 addresses and ARP out periodically, even when their network connectivity is supposedly disabled. Not routing this traffic internally helps mitigate this brain-damaged behavior.\nThis is the same kind of exposure that network equipment management interfaces have and is mitigated through much the same techniques by segmenting the management traffic so it's not accessible by users. I think this is a threat model that is pretty well understood intuitively and would require some kind of willful misconfiguration to be a problem in most cases.\nActually some \"desktop\" systems do have BMC chips in them.. it all depends if they are enterprise systems or not. [I have seen laptops respond to BMC scans.. I think it was a class of Dell but it might have been a whitebox laptop.] Because the BMC sits before the OS on the ethernet bus you can send it all kinds of things that you think your local firewall blocks but doesn't.. this allows for script kiddies to have fun at various times.. [they do it for a short time and then go away.] There was a \"bug\" in one set of BMC where even if you had set its IP address to something unreachable if you sent the proper Xmas tree packet to the main system it would cause the BMC to reset itself and ask for a DHCP address which you could then probe for and get to.\nCorrection -- these chips are on server motherboards, not on PCs or other consumer devices.\n... so far as we know ...\nIt is all a little late to the party... we have been talking about this quite a lot, there have been talks about AMT (Intel's IPMI-equivalent) and simply nobody cared.\nIt is far more fashionable to talk about browser exploits than it is to look at hardware.\nHow about Charlie Miller's Mac battery firmware hack? Or the PCI hacks (amongst others) by John Heasman? eEye's work in about Tigon2 backdoors which was pretty much at the same time as my own on Broadcom NICs? Andrea Barisani and Daniele Bianco on AMT?\nThat was all 2007 vintage and I don't think we're done yet (I'm not for sure).\nIt is my opinion this scheme of functionality has some amount of economic origins, stemming from 24x7 systems not necessarily staffed appropriately.\nThat is to say, an on-call admin using this function can remotely access an otherwise unresponsive system and potentially resolve issue(s). Thus negating the requirement for on-site staff during \"off-hours\".\ncalvin? hobbes' computer isn't working any more...\n>these chips are on server motherboards, not on PCs or other consumer devices.\nYes they are, they're built into Intel's vPro chipsets, intended for business users. Note that if you want to detect them you can't access them from the same machine the device is in because it performs (primitive) access-control filtering to prevent that (supposedly done for \"security\" reasons to prevent a local priv-esc by the end user, but it also means you can't easily check whether your own machine has this enabled or not).\nPeople who say \"just put the IPMI on its own private network\" didn't read the paper, where I explicitly address that. If you compromise the server you can change and talk to the network interface to compromise the BMC. You can also hop networks once that's done and also have complete control of the server. Plus you can get the IPMI password from the BMC from memory or files. Any server that's compromised has to be viewed with extreme suspicion as to the integrity of the BMC. This is true for physical access and other methods as well - do you de-provision your server by shredding the BMC and where it stores the passwords?\nRE: patching - again, read the paper. It's not that you can't patch them, its that you can't use *your* patches - a vulnerability found cannot be addressed until the vendor gets around to getting you a fix (if it works at all.) In addition with the heavy use of OEMs (also noted in paper) there are a handful of vendors who supply the major servers means that a problem in the firmware is likely to mean a cross *server vendor* problem that transcends your typical bug. (I'm sorry if conclusions were drawn without context; I put caveats and such on my page that tries to provide context.)\nThis isn't theoretical, I've gotten root on BMCs, recovered passwords, and try to provide further details in the paper.\nI welcome responses (I'll try to check here, flying cross country in the AM.)\nI think every point I see in the comments were explicitly addressed in the paper (if not, me know!) I try to illustrate that it is categorically not the same set of problems as it always was thought to be. If I fail feel free to let me know, but I'd ask folks to read my perhaps laborious but hopefully telling arguments that I try to supply with ample support and details before dismissing my claims.\nThe one pager is meant as a teaser to the larger one - one of primary points I try to drive home is that it's a confluence of a *lot* of different points that individually don't matter, but when taken as a whole is (I claim) a much larger toxic mess. I simply couldn't crush all the details into a page, but wanted to have something one (if convinced or even worried) could hand to a perhaps less technical but business savvy person for a different response.\nIt also doesn't matter if some of your servers in an IPMI group are \"safe\" (whatever that means) - if *ANY* are compromised your entire group has the ability to be compromised - and while the BMC has complete and utter control of the server you simply cannot view any activity on the BMC at all.\nWhen I find a backdoor that allows shell access to the BMC from a major vendor (details TBD; I'm try to let them patch it before releasing details) I find it more than troubling - these things are designed for remote control and managing of servers at a very low level - I think it's utter folly to allow this to continue.\nMany thanks for bruce for putting the pointers here, and the discussion post-post.\n@ dan farmer\n\"I think every point I see in the comments were explicitly addressed in the paper (if not, me know!)\"\nMostly seem to be after a quick read of the HTML paper. Great work on this. I've always suspected the management computers were a security risk. When asked about them for high security networks, I gave people three options:\n1. Disable the port physically & use trusted software on the machine to gather statistics.\n2. Put a little gateway between the management computer and the network that only allows authenticated traffic.\n3. If you trust the networking gear, use it to restrict and monitor access to them.\nI don't trust Cisco et al, hence option 2 existing. However, options 1 and 2 may be impractical for groups with very large numbers of servers. Their default will be option 3. Always tradeoffs...\nRe \"Correction -- these chips are on server motherboards\"\nThat's actually not correct. This functionality is present in modern \"business class\" notebook chipsets from Intel; for example, QM67 which can be found in e.g. Lenovo T420.\nThe technology is called AMT, or Active Management Technology. (Also, Wikipedia has a nice summary which is better than Intel's own).\nThere have been a number of BMC vulnerabilities in the past, for instance:\nfor HP iLO3/iLO4.\nIt's a fairly well understood risk in the datacentre worlds, and is why many larger companies are segmenting and controlling the networks these console ports are connected to.\nUseful things to know:\n* The vendors are fairly responsive to critical vulnerabilities.\n* They almost always have a default password (either a vendor default, or the serial number of the machine).\n* You can always disable the functionality in the BIOS (though I'm not sure whether this disables power to the BMC chip itself).\n@q: Mr Farmer's paper does mention AMT, but it seems it is distinct from IPMI:\n\"Intel launched a similar effort for personal computers called Active Management Technology ( AMT) that shares many features with IPMI, but while hazardous I don't personally view it to be as threatening as IPMI.\"\nOne of the 'additional reading' entries has an analysis on AMT specifically, which on reading doesn't exactly fill me with confidence.\nI'm keen to know more about AMT's vulnerabilities, for several reasons:\n* There are many more consumer devices.\n* Consumer devices definitely don't have the dedicated management port & infrastructure that has been discussed here so far.\n* Consumers aren't going to know how to turn it off, even if it can be turned off.\n* Consumers definitely aren't going to manage it, which means default configuration every time.\n* They can even be accessed via wireless.\nNow if you'll excuse me, I'm going to see if my most recent PC, which I know has AMT, can have it turned off...\n@Jeff H: I did a talk at Breakpoint about AMT/ME stuff that might be interesting to you. The short story is that while it does have its share of issues it's much more mature than IPMI and Intel took its security very seriously, especially in later versions. For example, it supports SSL and certificate-based/Kerberos authentication, remote boot/KVM requires user consent and so on. Here's a nice post outlining some of the details on how it's configured: http://www.symantec.com/connect/articles/...\nEverytime that I update the firmware on a server whether it is IBM, Dell, or HP I always have a new firmware that said vendor has provided fixes for. I think we are bit addicted to the conspiracy theories aren't we? News Flash!! All this crap is built in China. In fact, I don't know of a single vendor that doesn't have a major portion of their production coming right from our friendly communists across the Pacific. This is another false alarm from a conspiracy theorist.\n\"If you compromise the server you can change and talk to the network interface to compromise the BMC.\"\nBut in order to get to there you have to:\na. get onto the server network\nb. exploit a vulnerability in a service that gives you root/admin access that is running on a server that is on the server network.\nc. then you can get access to the BMC.\nBut once you have \"b\" you have lots of options for compromising other systems.\n\"Often running Linux, the BMC's CPU, memory, storage, and network run independently.\"\nIf it's running Linux, and you can't get access to the Linux source code as specifically modified for the BMC on your server's motherboard in order to check for vulnerabilities, your server manufacturer's committing software piracy. Read the GPL and know your rights.\nHmm I'm a little late to this party...\nAnd firstly to those who are saying this is old news etc, yes whilst that is true, it takes time to compile the information test etc, so please Don't Shoot the Messanger. Firstly it's not polite, secondly it's a significant disincentive for others to come forward with similar information.\nNow as to this \"computer within a computer\" in one way or another all PC's have had another computer in them since day one (in the keyboard). Some systems have had limited state machines set up bits of hardware. Almost all standalone modems had a 6502 or equivalent 8bit CPU built in and many hard drive controlers had microcontrolers or bitslice processors built in as have all hard drives in recent times. Likewise most peripherals including every real USB device and as others have noted in bateries and other unexpected but perhaps unsurprising places. And they will continue to appear in more and more places as time goes on and their price drops to cents or less in chips (many real time clock chips are now actually baby microcontrolers).\nBoth Nick P, RobertT, myself and others have repeatedly said over many years, from the security perspective peripherals are as much if not more of a danger to system security as malware. Primaraly because not only do they run \"beneath the OS\" in most cases they run \"beneath the CPU\" and thus control what the Main CPU does or does not see.\nAs a simple rule of thumb anything that runs beneath the Main CPU cannot be audited by the Main CPU thus any kind of nasty can be on there, and more importantly it can access anything the Main CPU can either directly or by getting the Main CPU to do it. Thus it will always be able to work around the \"don't plug in the maintanence port\" as will any command and control messages sent to it from any other connected system...\nWhilst we might not like this there is little we can actually do about it as we will almost certainly get less attention than the big company wish to have less people do more work. That is their stated aim is to reduce costs by (supposadly) making those lucky few who still have jobs \"more efficient\".\nNow as I'm in the habit of repeatedly saying you have the general case of \"Efficiency -v- Security\". That is unless you realy realy know what you are doing at all levels then making a system more efficient makes it less secure. The problem is nobody these days knows enough at all levels to know what they are doing so our systems become more insecure with time.\nNow as I also say with regular monotony \"technology is agnostic to it's use\" like a knife it cares not if it cuts you food or your throat, you however do. In the same way in times befor the safety razor you trusted your barber not to \"Sweeny Tod you\". One way you built up such trust was to go to the barber with a friend untill you both got to know him, then on going on your own you would by way of conversation let the barber know that immediatly after you had been shaved you were meeting a friend who knew you were there. Likewise you almost always let your friends and family know you were going to the barbers and they knew from experiance exactly which one it was. Thus the barber if he had any sense would know you had marked him, so if you disappeared your friends and family would know where to point the finger.\nWe call this process \"building up trust\" unfortunatly it does not always work, that is past behaviour is no indicator of future behaviour and Con artists rely on abusing trust because they have planned their exit strategy so they are not there to have fingerrs pointed at them.\nAnd that's tthe point when it comes to all types of cyber-crime the perpetrator generaly aranges so that they are not there to have the finger pointed at them, or be safely in another safe jurisdiction when the authorities come knocking.\nFor instance Stuxnet and the code signing keys, how did the malware writers get hold of them, and are the people who stole them still around to have fingers pointed and their collars felt? unlikely (unless they were blackmailed etc).\nI've always disliked code signing because it is not a security mechanism just an at best attestation method. All it says is that on such and such a date a body of code was hashed, and digitaly signed. Nothing else, thus steal the key, factor it or add malware upstream of signing or find a hash collision the result will be the same properly signed code... not audited code, not tested code, not bug free code or even secure code just signed code...\nThus there is a myth that has been proved repeatedly wrong that \"signed code is good code\" it's not.\nThe advantage of code signing is that finding hash collisions, factoring or stealing signing keys and getting code into the developers database should be at best very difficult problems.\nBut are they? Unfortunatly in many cases they are not. I've been on a walk through of an organisations development process where in many respects they had gone to a lot of trouble to be secure in how they did their code signing via automated processes. Unfortunatly on a little anaylasis it all rested on knowing the name of a senior member of the developer or test teams that had admin rights over the code repository and their remote login password...\nPublicaly available information gave the names and thus their predictable usernames and the organisations remote access server was vulnerable to having malware put on it so finding out the passwords via a bit of malware was not going to be difficult... And in one case the password was fairly easily crackable even though it followed the usual rules for security on passwords.\nSecurity involving humans is hard because by and large we trust other people and we can be persuaded to turn by various human failings.\nWhilst eliminating many humans from the loop by technical measures is possible you cann't make the systems \"perfectly secure\" and thus ultimatly there is atleast one human (the admin) kept in the loop, making it less secure etc.\nThe other solution is of course issolation or air gapping the systems entirely, but again as I worked out and Stuxnet later showed humans breach the air gap as a simple matter of getting their job done. But as others have noted over and over again computers in general are only as of as much use as the other computers they are connected to. Thus to get not just some but most jobs done requires connectivity.\nIs there a solution? well no because perfect security does not exist, but there are mitigations. The first is \"Eternal Vigilance\" that is you realy have to not only monitor and store what comes in and goes out your door. You have to know exactly what is on your systems and where, and have easy but effective ways to verify whats there. You further have to profile the behaviour of the systtems and humans that use them. And these systems are not efficient or easy to use...\nAt the end of the day \"you pay your money and make your choice\" and currently those in walnut corridor are chosing short term small gain over longterm stability and more secure income...\nI think most people who run lots of servers are very familiar with this. Administration of many machines is involves many trade-offs. These things exist to make machines much easier to remote manage they are the equivalent to the serial consoles unix machines might have attached to a modem pool in the old days.\nI think the thing that surprises security people here is that most large computing rooms have a gooey center behind the hard shell. I think this is the real problem. Once an attacker in inside there is little defense against an attacker who understands the 'enterprise crap' they could hop to any other machine.\nThe problem is not limited to DRAC/Lights-out systems, but its essentially the same for: backup agents, KVMs, SANs (iSCSI, FC, etc...), and \"cluster stuff\" often are designed with the idea that traffic can only come from a special network on which each node is trusted or forgery is impossible.\nThe problems here are:\n1) Security is too fixated on stopping threats from breaching the outer layer and not enough focus on people hopping between enclaves or even acknowledging the size of the perimeter of the crust vs the volume of gooey center.\n2) Often service architects forget these things are there because they often have no control over it. The \"systems folks\" just put it there. Its not a choice if it is used, just which bad product is used.\nIt sounds like technology making a full circle again. In the \"old days\" of mainframes and large minicomputers, they typically had a \"front-end\" or \"console\" processor. It would be responsible for loading the initial bootstrap code into memory, debugging, and stuff like that, by being able to access the main computer's memory and having its (own) disk drive and tty.\nYou can easily tell whether your system has one of these things by watching the BIOS messages on the (console) display when you power the system up. If it's there, it will make itself obvious. We've got a couple of PowerEdge servers at work that have these features. They're not enabled, but they still cause 30+ seconds of delays at firmware boot time. (The RAID controller causes an *additional* 30+ seconds of delays, and there's other stuff too. All of this is before the software boot loader starts. Server hardware takes a lot longer to boot up than consumer hardware.)\n@Jonadab: \"If it's there, it will make itself obvious.\"\nNope. Before reading this thread, I would have interpreted \"Network IPMI enabled\" as an obscure feature, possibly related to bios trying to boot from a variant of ISCSI, thus under my radar.\nThis is quite an eye opener.. Somewhat reminds me of purpose build \"back-doors\" in Chinese grey kit!\nThe desktop version of this is Intel's AMT. This is sold to medium and large enterprises as a desktop management solution.\nThe BMC on the systems I use has all sorts of things other than IPMI 2.0 included. It has a web server embedded along with a proprietary interface running on another port. There is no documentation on this OS (although it can be seen to be linux based). The vendor seems to fix bugs in the BMC software every couple of months. More recent systems do seem to let you turn off the network interfaces for this other junk.\nI have asked the vendor for their security evaluation of the BMC and they are unable to provide it. This vendor has at least one major design problem with the BMC software.\nMy lab has a couple of older HP/Compaq 1U rack-mounted servers with iLO. They've got separate Ethernet ports, get their own IP addresses, and we've done very little with them, but they look like they'd be useful if we were running a server farm. You can at least talk to the machine and decide whether it's up or down.\nBack when the VAX 11/780 was still cutting-edge, it had a PDP-11-on-a-chip for booting, and an 8\" floppy disk, and there were drivers for 4.1BSD that could access the disk. Somebody sent us some data on 8\" DEC floppies, and after some thought we decided it was ok to use the boot floppy drive to read them; worked ok. Traditionally you'd use a DECwriter paper terminal on the PDP console to manage the system, though eventually we shifted over to CRTs. (Hint: Don't play Rogue on the console; the ^P gets interpreted as a request to talk to the microcontroller, which asks if you want to reboot the system. But at least we never put a modem on that port.)\nRecent intel chipsets are full of Intel Management Engine (this appears to be mandatory on all new Intel chipsets), vPRO, AMT and other Intel technologies herein referred to as \"intel embedded rootkit\" from now on\nHow can you disable Intel AMT and related technologies on your motherboard, can you simply de-solder the chip that contains the intel embedded rootkit ARC processor (and firmware, private memory etc)\nI am seriously thinking of desoldering the intel embedded rootkit chip on my new motherboard... Could this introduce any unforeseen problems?\nSchneier.com is a personal website. Opinions expressed are not necessarily those of BT.", "label": 1}
{"text": "Frequently Asked Questions - Security & Policies\n1) How do I protect myself from computer viruses?\n- Install anti-virus software on your computer (Students - please click on this link for further information)\n- Update your virus definitions regularly\n- New virus definitions are released almost every day. By updating your virus definitions the risks of becoming infected is greatly reduced\n- Use good judgment when opening strange or unexpected email attachments and/or files\n- Never open an email attachment from someone you don’t know.\n- It is a good practice to check with a known user if you receive an attachment from them that you were not expecting. (Don’t assume that it is legit!)\n- The type of attachment can also be a tip that something is not right. If you get an email attachment that has two periods in it i.e. .txt.doc, .xls.exe, or any combination of file extensions, DO NOT OPEN IT!!! To find out the real name of an attachment, right click on it and choose “properties”. If the file has an .exe, .vbs, .com, .cmd, .pif or .lnk extension, do not open it UNLESS you were expecting it or it was sent by a known (trusted) user AND you have confirmed that they meant to send it to you.\n- Backup your data\n- The original file that has become infected and/or was destroyed can be restored if you have it backed up.\n2) What should I know about securing my personal computer?\n- The following computer security tips are recommended best practices:\n- Use strong passwords. Choose passwords that are difficult or impossible to guess but easy to remember. Give different passwords to all accounts. See Choosing Good Passwords for additional help.\n- Make regular backups of critical data. Backups should be made at least once each day. Larger organizations should perform a full backup weekly and an incremental backup every day. At least once a month the backup should be verified. (In other words restore something from the backup.)\n- Use virus protection software. That means three things:\n- having it on your computer in the first place\n- checking daily for new virus signature updates\n- actually scanning all the files in your computer periodically (once a week).\n- Use a personal firewall as a gatekeeper between your computer and the Internet. Firewalls can be either hardware or software. In most instances for home use the software firewall should be sufficient. Firewalls are very important for computers that access the Internet via DSL and cable modem connections, but they are also valuable for those who still use dial-up.\n- Do not keep computers online when not in use. Either shut them off or physically disconnect them from the Internet connection.\n- Do not open email attachments from strangers, regardless of how enticing the subject line or attachment may seem. Be suspicious of an unexpected email attachment from someone you do know because it may have been sent without that person’s knowledge from an infected machine.\n- Regularly download security patches from you software vendors. These include but are not limited to your OS (operating system) and office products.\n- Do not use older OS’s such as Windows 95 or 98, there are a great many vulnerabilities in these operating systems and Microsoft does not support them anymore, which means you cannot get fixes and updates for them.\n- Be wise about cookies. Some web sites require that your computer accept cookies before allowing access, but these little programs can reveal a great deal of information about you. Compromise is the key, disable cookies and only enable them when necessary to visit a web site you really need to see.\n- If you use Windows and share files with other Windows users (remember this is against UVA-Wise policy and could result in denial of network privileges), be sure your computer’s permission settings require them to enter a username and password before gaining access. Without this safeguard practically anyone can tamper with your disk drive (with or without your knowledge).\n3) How do I know if my computer has been compromised?\n- If your computer and/or programs running on it are behaving unexpectedly or out of the ordinary.\n- An indicator that your computer may be infected and/or is under attack is if the computer’s speed suddenly becomes very slow and sluggish. Your awareness of this performance change is important. It is recommended that you use antivirus software, keep the definitions up-to-date, and scan your computer frequently so that you may be advised of infections and attacks. (Please note that the best antivirus software will not catch 100% of all viruses/attacks. You may want to use more than one method of identifying malicious activity such as Spybot, Adaware, etc…A word of caution, don’t go overboard.)\n- One way to identify suspicious behavior on your computer is to look for files and/or programs that you did not install.\n- If a program runs or opens by itself (but it didn’t use to do so), you may be infected with a Trojan horse.\n- If you think that your computer has been compromised get assistance immediately\n- Faculty and Staff should get in contact with the Technical Assistance Center (TAC) in 110 Darden or at extension 4509.\n- Students may either call TAC at extension 4509 or seek outside assistance. (If your computer is compromised and it is identified during a routine scan of the network you risk having your port disabled and a possible reconnection fee. See the Student Computing Handbook for more information.)\n4) Can I connect my game system or play PC games on the College network?\nThe Office of information Technology does not explicitly prohibit the use of campus network resources for student gaming purposes; however we do not actively support (ie. fix problems) gaming across the network and/or the Internet. For network security, requested changes to our network system to support gaming will not be accommodated. In the future, if gaming causes a problem for other users on our network, UVa-Wise reserves the right to block this gaming traffic without notice.\n5) What should I know about creating a good password?\n- Literally thousands of computers are compromised each year due to weak or non-existent passwords. The following is a list of some of the things not to do:\n- Write down a password on a sticky note or piece of paper and place it near your computer. (This includes the center drawer in your desk, the sliding shelf in your desk, the monitor, under the keyboard, etc.)\n- Use a word found in the dictionary. That includes foreign dictionaries.\n- Use a word from a dictionary followed by a couple of numbers.\n- Use the names of spouses, children, friends, enemies, relatives, pets, or other common items.\n- Use dates such as anniversaries, birthdays, christenings, etc.\n- Share you password with someone (anyone) else\n- Use the same password for more than one account, and for an extended period of time.\n- Use the default password provided by the vendor.\n- Why would this be a problem?\n- Passwords are one of the first lines of defense in the protection of computer systems. Most computer users don’t recognize the importance of using strong passwords, especially when they can be very complicated and hard to remember. In fact, the more complicated and hard to remember the password is the better the protection. One of the first things that a hacker will attempt to do against a system is to run a program that will attempt to guess the correct password. These programs can be very simple or very sophisticated. Most of the programs begin with the simple things like words from a dictionary and not just English dictionaries; they usually include dictionaries from several different languages. For information on how to create a good, strong password see Choosing a Good Password.\n- Understanding human weaknesses and/or failings makes a hackers job that much easier. One of our major weaknesses is the reluctance to remember several long and/or difficult passwords. Hence the likelihood that the same password will be use for several accounts is very high. It is also very likely that the password will be used for a long period of time, allowing the hacker a greater length of time to access the system. Any password can be cracked given enough time; therefore passwords should be changed at least every 60 days.\n6) How do I know if I am on a “secure” Web page?\n- There are a couple of things you can look for to ensure that you are on a “secure” web page.\n- Look for a closed padlock symbol in the lower right corner of the Internet Explorer 4.0 or greater window or in the lower left corner of the Netscape 4.0 or greater window.\n- If there is an s on the end of the “http” (making it https) in the address line. Such as https://ibank.amsouth.com/\nNever give personal information on a Web site that you cannot verify is secure and even then proceed with caution. Identity theft is rampant and we don’t want you to be the next victim. Protect yourself and what you have worked to achieve.\n7) What campus policies, procedures and/or guidelines should I be aware of?\n- Most of our existing policies, procedures and/or guidelines can be found on this web site under the Computing Policies and Guidelines section and under the Secure Computing section.\n- Be aware that work is ongoing to create and update our policies, procedures and guidelines and the most up-to-date information can be found on our web pages.\n8) What constitutes harassing or inappropriate e-mail, and what can I do about it?\n- Examples of inappropriate e-mail include but are not limited to, SPAM, pyramid schemes, mass-mailings, marketing one or more products or services, and chain letters. Harassing e-mail messages include messages that offend, intimidate or threaten an individual or group.\n- These should be reported immediately to email@example.com.\n9) How do spammers get my name and how can I protect myself?\nFree services. Many Web sites carry paid advertising as a way to generate revenue. But many web-based services also require that you register, by supplying your name and e-mail address, before you can use their “free” services. Selling the information they collect is part of their business plan. And guess who buys that information? (The correct answer is “spammers”).\nNewsgroups. Think twice before posting to a newsgroup. Spammers often release information-gathering programs called “bots” to collect the names and e-mail addresses of people who post to specific newsgroups. Bots can get this information from both recent and old posts. And, since many newsgroups are special-interest communities, spammers can learn what you’re interested in—which makes you a better target for spam.\nHow to protect yourself:\nNever reply to a spammer. Replying to spam—no matter how good the offer sounds—will guarantee that you get more spam, because you’ve shown yourself as susceptible. Also ignore any offer to “click here to be removed from our list.” All your request does is tell the spammer the message arrived and that a live person is reading the mail at that address. Any response increases your value to list-sellers.\nUse filters. Every e-mail program has some sort of built-in filtering system. Check your client’s online help section for info on setting up filters. Filters aren’t perfect, though, because you have to enter the spammer’s e-mail address, and the addresses change often and are commonly disguised. Another good use for filters: blocking messages from one person who keeps sending you unwanted (but not spam) messages.\nHow to complain\nBe sure to include the expanded header when you forward a message. The expanded header identifies every computer that handled the message before it arrived at your in-box. We need this information to determine the origin of the message. Every e-mail client has its own way to expand headers; click the online help section to learn more.\nIn Eudora, for example, select the message by double-clicking on it in the inbox, then click on the button that says “blah blah blah” to expand the header.\n10) How can I automatically delete/clear private data when exiting Mozilla Firefox?\nTo automatically clear private data in Mozilla Firefox:\n1. Open Firefox.\n2. Select Tools from the toolbar.\n3. Select Options from the pull-down menu.\n4. Select the Privacy Tab.\n5. Click on the checkbox, to put a check mark, under Private Data section: “Always clear my private data when I close Firefox”.\n6. Click on the Settings… box.\n7. Make sure that all of the checkboxes are selected with checks.\n8. Click OK.\n9. Click OK.\n10. Every time you close Firefox you will prompted to “Clear Private Data Now”.", "label": 1}
{"text": "We need passwords for just about everything anymore. A fear my next toaster will require me to sign in and agree to terms before I can toast a bagel.\nHere are a few tips to keep yourself protected:\n1) Don’t reuse passwords.\nIt’s true, keeping track of all those passwords is tough. At a bare minimum, you probably have online accounts with Facebook, Google, your bank, your email, and your website admin. And many of you will also have Flickr, Twitter, Pinterest, Amazon, eBay, LinkedIn, Spotify, Foursquare, etc. My personal password manager keeps track of more than 300 logins.\nBut if you use the same password across multiple accounts, that means the weakness of one service becomes a weakness for all the services you use. Suppose you have a really strong password like\nle8'a6[Nwva7Y)lq/RSy that you use everywhere. If just one of your accounts gets hacked, then it is only a matter of time before the hacker uses that to gain access to your other accounts.\n2) Don’t use common passwords.\nIf you can find your password in the dictionary, don’t use it. Those passwords are the easiest to guess. Remember, we’re not worried about a person sitting at a computer trying these passwords one-by-one, we’re worried about bot-attacks which can try thousands of passwords per second.\nIf your password is one of these 25 most common passwords, don’t use it, and change it immediately: password, 123456, 12345678, abc123, qwerty, monkey, letmein, dragon, 111111, baseball, iloveyou, trustno1, 1234567, sunshine, master, 123123, welcome, shadow, ashley, football, jesus, michael, ninja, mustang, password1\n(More information about that list)\nYou should also make sure that your password isn’t your username, real name, email address, or some combination thereof. Children’s and pets’ names should be avoided too.\n3) Try a pass-phrase\nWe have been conditioned to not use spaces in our passwords (I’ll admit that I often don’t), but this is a great way to use a strong password that is easy to remember.\n4) “Retire” old passwords\nIf a password has been in use for a while, it might be time to retire it. In case a site was compromised, changing your password regularly will help ensure that the password that someone else has is out-of-date by the time they try to use it.\n5) Find a system\nYour system might be to find a tool like 1Password or LastPass to keep track of your various passwords (as well as storing other secure information). Or you might want to use some sort of naming convention to make it easier to remember your passwords (for example, having a base password like “myDogHas3Legs” and prefix it for the site like “facebook-myDogHas3Legs”).\nThe important thing is to pick whatever method works best for you.\nReady to change your password?\nHere’s how to change your inndx.com password:\n6) Bonus: Watch out for those security questions!\nA good password is worthless if a hacker can reset it by answering a security question or two. You wouldn’t give your password out, but sometimes we don’t think twice about leaking information like where you were born, your first pet’s name, or the street you grew up on. So be mindful that security questions are a second point of entry, and should be just as difficult to get past as your password.", "label": 1}
{"text": "Virtual machine live migration is a virtualization process that moves a virtual machine (VM) from one physical host server to another. It moves the memory and state of a VM without shutting down the application,\nThe process captures the complete memory space occupied by the VM—along with the exact state of all the processor registers currently operating on the VM—then sends that content across a TCP/IP link to memory space on another server. Processor registers are then loaded, and the newly moved VM can pick up its operation without missing a step.\nMost VM live migrations occur between similar hypervisors, so the migrated VM retains its name and other unique identifiers. Even though the VM is on a different server, it's the exact same machine as far as the users are concerned.\nLive migration is a key benefit of virtualization, allowing workloads to move in real time as server or data center conditions change. Consider the impact on business continuity: A virtual server scheduled for maintenance can migrate its workloads to a spare server or to other servers that have extra computing capacity. Once the maintenance is complete and the server returns to service, these workloads can all migrate back to the original server without disruption.\nLive migration helps server consolidation by allowing IT administrators to balance workloads across data center servers, ensuring that each server is used efficiently without being overtaxed. Live migration helps with disaster recovery too because VMs can just as easily be moved from one site to another, relying on spare servers at a remote site to receive and operate the migrated VMs.\nAll of the major virtualization software platforms include VM live migration tools. These include VMware VMotion (part of vSphere), Microsoft Live Migration (part of Hyper-V R2) and Citrix Systems XenServer live migration.\nMigration tools typically allow administrators to prioritize the movement of each VM so that failover and failback processes occur in a predictable and repeatable manner. Mission-critical VMs usually take priority and are often moved to spare servers with ample computing resources.\nSecondary VMs can be addressed next, although the migration software may be left to move noncritical VMs automatically based on the computing resources on each available server. Migration audits allow administrators to locate VMs and track their movements to refine and optimize ongoing migration behaviors.\nLive migration works between almost all virtual host servers, but it's important to test migration behaviors between servers with various processor manufacturers. Processors from Intel and AMD both include extensions that provide hardware assistance for virtualization tasks, including migration. However, Intel VT and AMD-V processors use different architectures to facilitate migration, and moving VMs between Intel and AMD-based servers may result in unexpectedly poor migration performance.\nThis was first published in October 2009", "label": 1}
{"text": "Article written on 26 October 2010\nDuring the European Security and Information System congress, the CNIL released a guide regarding the security of personal data. This guide aims at helping security managers to respect the law « Data Processing, Data Files and Individual Liberties » and to ensure the security of personal data. The present article is a summary of the recommendations of this guide.\nContext and presentation\nThere are more and more personal data manipulated, and threats affecting information systems are in parallel increasing (see on this topic Cert-IST 2009 annual report on the vulnerabilities and attacks). During all their lifecycle, personal data must therefore be protected against the loss of confidentiality, the loss of integrity, the usurpation or the simple loss.\nOrganisation of the guide\nThe CNIL guide is made of 17 datasheets allowing security managers to evaluate the level of security of personal data in their organisation.\nThese sheets are divided into three sections mentioning the elementary precautions for data security, the things to avoid and a third section enabling the reader to go further on the topic dealt in the sheet. The themes developed are as follows: risk management, user authentication, accreditation management and user awareness, workstation security, mobile equipment security, backups and activity continuity, maintenance, traceability and incident handling, office security, internal network security, server and application security, externalisation, storing, exchange of information with other organisations, computer development, anonymisation and encryption.\nThe following examples give an idea of the sheets presented in this guide.\nSheet n°1: Which risks ?\nThis first sheet allows the persons responsible for the data handling to take the necessary measures to protect these data from the possible risks they encounter.\nThe elementary precaution is to formalize the risks in a complete document, which will have to be kept up to date regularly. This document must gather the personal data and the associated treatments, by identifying the supports on which these treatments rely. The possible impacts on private life will have to be identified, as well as risks and threats, in order to set up the appropriate security measures.\nThree things must in particular be avoided, managing a risk study alone, performing a too much detailed study and choosing inappropriate measures.\nSeveral orientations enable the reader to go further, for instance the implementation of a security budget, the use of a method such as EBIOS, the formation of the persons in charge of the risk analysis or the realisation of a security audit.\nSheet n°5: How to secure mobile devices?\nThis sheet deals with the protection of data manipulated by mobile computers and phones, USB keys and any other mobile device. The risks related to these devices have indeed been mentioned in the Cert-IST 2009 annual report quoted above, it is therefore essential to secure personal data manipulated by these devices.\nAs an elementary precaution, the guide recommends to encrypt store spaces either at hardware level, or at software level, or to use file encryption or at last to create encrypted containers.\nThe thing to avoid is keeping personal data in these mobile devices when travelling abroad. This guide reminds the advices published by ANSSI in the document named « Passport advice to travellers ». The section « To go further » recommends to lock the device after some time of inactivity, as well as to use a fingerprint reader.\nSheet n°8: Traceability and incident handling\nAnother interesting example for personal data is the one of logging the actions performed on a system. This is indeed crucial in case of investigation on incident (i.e. unauthorised access to personal data or fraudulent use of these data).\nThe elementary precaution recommended by the CNIL is to set up a reliable logging system, allowing to record accesses, errors, and security events on a period of time that does not exceed six months.\nThe CNIL recommends, in the section « things to avoid », not to use these data for other things than the good use of the information system.\nThe section « To go further » gives recommendations on the synchronisation of information systems and the treatment of security vulnerabilities that may affect these systems.\nSheet n°15: Computer developments\nThe last example that we will take is the protection of personal data during the development of applications.\nIn the section « Elementary precautions », the CNIL reminds the basic principles in term of security for developments, which are the use of a development environment distinct of the production environment and the integration of security since the conception of applications. These principles have been known for a long time, but are still often neglected.\nThe thing to avoid is to use real personal data for development, or in this case to impersonate these data.\nTo go further in its advices regarding developments, the CNIL recommends to reduce the personal data collected, to use a format compatible with the time of conservation of these data, to integrate access control to these data during development and to avoid free text areas (or then with a mention regarding access rights to the information entered).\nAt the end of this guide, a questionnaire allows computer managers to evaluate the security level of the personal data in their organisation.\nThe CNIL president (Alex TÜRK) also mentions that this guide is probably not perfect and is either too much or not enough detailed depending on the reader profile, but also indicates that a more precise document is under elaboration.", "label": 1}
{"text": "A VPN (virtual private network) encrypts and tunnels all Internet traffic between yourself and another computer. This computer might belong to a commercial VPN service, your organization, or a trusted contact.\nBecause VPN services tunnel all Internet traffic, they can be used for e-mail, instant messaging, Voice over IP (VoIP) and any other Internet service in addition to Web browsing, making everything that travels through the tunnel unreadable to anyone along the way.\nIf the tunnel ends outside the area where the Internet is being restricted, this can be an effective method of circumvention, since the filtering entity/server sees only encrypted data, and has no way of knowing what data is passing through the tunnel. It has the additional effect of making all your different kinds of traffic look similar to an eavesdropper.\nSince many international companies use VPN technology to allow employees who need access to sensitive financial or other information to access the companies' computer systems from home or other remote locations over the Internet, VPN technology is less likely to be blocked than the technologies used only for circumvention purposes.\nIt is important to note that the data is only encrypted as far as the end of the tunnel, and then travels unencrypted to its final destination. If, for example, you set up a tunnel to a commercial VPN provider, and then request the Web page http://news.bbc.co.uk through the tunnel, the data will be encrypted from your computer to the VPN provider's computer at the other end, but from there it will be unencrypted to the servers run by the BBC, just like normal Internet traffic. This means that the VPN provider, the BBC and anyone with control over a system between these two servers, will, in theory, be able to see what data you sent or have requested.\nUsing VPN services\nVPN services might or might not require installation of client-side software (many rely on existing VPN support in Windows, Mac OS or GNU/Linux and so need no extra client software).\nUsing a VPN service requires you to trust the owners of the service, but provides a simple and convenient method of bypassing Internet filtering, for free or for a monthly fee generally between 5 and 10 US dollars, depending on the service. Free services are often either ad-supported, or limit the bandwidth and/or the maximum traffic allowed over a given period.\nPopular free VPN services:\n- Hotspot Shield, https://hotspotshield.com\nAccording to a 2010 report from the Berkman Center, Hotspot Shield is overwhelmingly the most popular VPN service. For more details on how to get and use Hotspot Shield, read the \"Hotspot Shield\" chapter of this manual.\n- UltraVPN, http://www.ultravpn.fr\n- FreeVPN, http://www.thefreevpn.com\n- CyberGhost, http://cyberghostvpn.com\n- Air VPN, https://airvpn.org\nAirVPN offers free accounts without bandwidth or traffic restrictions and without ads for activists by request.\n- Vpnod, http://www.vpnod.com\n- VpnSteel, http://www.vpnsteel.com\n- Loki Network Project, http://www.projectloki.com\n- ItsHidden, http://itshidden.com\nExamples of paid VPN services include Anonymizer, GhostSurf, XeroBank, HotSpotVPN, WiTopia, VPN Swiss, Steganos, Hamachi LogMeIn, Relakks, Skydur, iPig, iVPN.net, FindNot, Dold, UnblockVPN and SecureIX.\nVPN standards and encryption\nThere are a number of different standards for setting up VPN networks, including IPSec, SSL/TLS and PPTP, that vary in terms of complexity, the level of security they provide, and which operating systems they are available for. Naturally, there are also many different implementations of each standard within software that have various other features.\n- While PPTP is known to use weaker encryption than either IPSec or SSL/TLS, it may still be useful for bypassing Internet blocking, and the client software is conveniently built into most versions of Microsoft Windows.\n- SSL/TLS-based VPN systems are relatively simple to configure, and provide a solid level of security.\n- IPSec runs at the Internet level, responsible for packet transfer in the Internet architecture, while the others run at the Application level. This makes IPsec more flexible, as it can be used for protecting all the higher level protocols, but also difficult to set up.\nSet up your own VPN service\nAs an alternative to paying for commercial VPN services, users with contacts in unrestricted locations may have these contacts download and install software that sets up a private VPN service. This requires a much higher level of technical knowledge, but it will be free. Also the private nature of such a setup means it is less likely to be blocked than a commercial service that has been available for a long time. One of the most widely used free and open source programs available for setting up this kind of private VPN is OpenVPN (http://openvpn.net), which can be installed on Linux, MacOS, Windows and many other operating systems.\nTo understand how to set up an OpenVPN system, read the \"Using OpenVPN\" chapter in this manual.\nA VPN provides encrypted transfer of your data, so it is one of the safest ways to bypass Internet censorship. Once configured, it is easy and transparent to use.\nVPNs are best suited for technically capable users who require secure circumvention services for more than just web traffic and who access the Internet from their own computer where they can install additional software. VPNs are an excellent resource for users in censored locations who do not have trusted contacts in non-filtered locations. VPN technology is a common business application that is not likely to be blocked.\nDisadvantages and Risks\nSome commercial VPNs (especially the free ones) are publicly known and may be filtered. They normally cannot be used in public access locations where users cannot install software, such as Internet cafés or libraries. Use of VPNs may require a higher level of technical expertise than other circumvention methods.\nA network operator can detect that a VPN is being used and determine who the VPN provider is. The network operator should not be able to view the communications sent over the VPN unless the VPN is set up incorrectly.\nThe VPN operator (much like a proxy operator) can see what you're doing unless you use some additional encryption for your communications, like HTTPS for Web traffic; without additional encryption, you have to trust the VPN or tunnel operator not to abuse this access.", "label": 1}
{"text": "In computing, a denial-of-service attack (DoS attack) or distributed denial-of-service attack (DDoS attack) is an attempt to make a machine or network resource unavailable to its intended users. Although the means to carry out, motives for, and targets of a DoS attack may vary, it generally consists of efforts to temporarily or indefinitely interrupt or suspend services of a host connected to the Internet.\nPerpetrators of DoS attacks typically target sites or services hosted on high-profile web servers such as banks, credit card payment gateways, and even root nameservers. This technique has now seen extensive use in certain games, used by server owners, or disgruntled competitors on games such as Minecraft. The term is generally used relating to computer networks, but is not limited to this field; for example, it is also used in reference to CPU resource management.\nOne common method of attack involves saturating the target machine with external communications requests, so much so that it cannot respond to legitimate traffic, or responds so slowly as to be rendered essentially unavailable. Such attacks usually lead to a server overload. In general terms, DoS attacks are implemented by either forcing the targeted computer(s) to reset, or consuming its resources so that it can no longer provide its intended service or obstructing the communication media between the intended users and the victim so that they can no longer communicate adequately.\nDenial-of-service attacks are considered violations of the Internet Architecture Board's Internet proper use policy, and also violate the acceptable use policies of virtually all Internet service providers. They also commonly constitute violations of the laws of individual nations.\nSymptoms and manifestations \nThe United States Computer Emergency Readiness Team (US-CERT) defines symptoms of denial-of-service attacks to include:\n- Unusually slow network performance (opening files or accessing web sites)\n- Unavailability of a particular web site\n- Inability to access any web site\n- Dramatic increase in the number of spam emails received—(this type of DoS attack is considered an e-mail bomb)\n- Disconnection of a wireless or wired internet connection\nDenial-of-service attacks can also lead to problems in the network 'branches' around the actual computer being attacked. For example, the bandwidth of a router between the Internet and a LAN may be consumed by an attack, compromising not only the intended computer, but also the entire network.\nIf the attack is conducted on a sufficiently large scale, entire geographical regions of Internet connectivity can be compromised without the attacker's knowledge or intent by incorrectly configured or flimsy network infrastructure equipment.\nMethods of attack \nA denial-of-service attack is characterized by an explicit attempt by attackers to prevent legitimate users of a service from using that service. There are two general forms of DoS attacks: those that crash services and those that flood services.\nA DoS attack can be perpetrated in a number of ways. The five basic types of attack are:\n- Consumption of computational resources, such as bandwidth, disk space, or processor time.\n- Disruption of configuration information, such as routing information.\n- Disruption of state information, such as unsolicited resetting of TCP sessions.\n- Disruption of physical network components.\n- Obstructing the communication media between the intended users and the victim so that they can no longer communicate adequately.\n- Max out the processor's usage, preventing any work from occurring.\n- Trigger errors in the microcode of the machine.\n- Trigger errors in the sequencing of instructions, so as to force the computer into an unstable state or lock-up.\n- Exploit errors in the operating system, causing resource starvation and/or thrashing, i.e. to use up all available facilities so no real work can be accomplished or it can crash the system itself\n- Crash the operating system itself.\nIn most cases DoS attacks involve forging of IP sender addresses (IP address spoofing) so that the location of the attacking machines cannot easily be identified and to prevent filtering of the packets based on the source address.\nICMP flood \nA smurf attack is one particular variant of a flooding DoS attack on the public Internet. It relies on misconfigured network devices that allow packets to be sent to all computer hosts on a particular network via the broadcast address of the network, rather than a specific machine. The network then serves as a smurf amplifier. In such an attack, the perpetrators will send large numbers of IP packets with the source address faked to appear to be the address of the victim. The network's bandwidth is quickly used up, preventing legitimate packets from getting through to their destination. To combat denial of service attacks on the Internet, services like the Smurf Amplifier Registry have given network service providers the ability to identify misconfigured networks and to take appropriate action such as filtering.\nPing flood is based on sending the victim an overwhelming number of ping packets, usually using the \"ping\" command from unix-like hosts (the -t flag on Windows systems is much less capable of overwhelming a target, also the -l (size) flag does not allow sent packet size greater than 65500 in Windows). It is very simple to launch, the primary requirement being access to greater bandwidth than the victim.\nPing of death is based on sending the victim a malformed ping packet, which might lead to a system crash.\n(S)SYN flood \nA SYN flood occurs when a host sends a flood of TCP/SYN packets, often with a forged sender address. Each of these packets is handled like a connection request, causing the server to spawn a half-open connection, by sending back a TCP/SYN-ACK packet (Acknowledge), and waiting for a packet in response from the sender address (response to the ACK Packet). However, because the sender address is forged, the response never comes. These half-open connections saturate the number of available connections the server is able to make, keeping it from responding to legitimate requests until after the attack ends.\nTeardrop attacks \nA teardrop attack involves sending mangled IP fragments with overlapping, over-sized payloads to the target machine. This can crash various operating systems because of a bug in their TCP/IP fragmentation re-assembly code. Windows 3.1x, Windows 95 and Windows NT operating systems, as well as versions of Linux prior to versions 2.0.32 and 2.1.63 are vulnerable to this attack.\nLow-rate Denial-of-Service attacks \nThe Low-rate DoS (LDoS) attack exploits TCP’s slow-time-scale dynamics of retransmission time-out (RTO) mechanisms to reduce TCP throughput. Basically, an attacker can cause a TCP flow to repeatedly enter a RTO state by sending high-rate, but short-duration bursts, and repeating periodically at slower RTO time-scales. The TCP throughput at the attacked node will be significantly reduced while the attacker will have low average rate making it difficult to be detected.\nPeer-to-peer attacks \nAttackers have found a way to exploit a number of bugs in peer-to-peer servers to initiate DDoS attacks. The most aggressive of these peer-to-peer-DDoS attacks exploits DC++. Peer-to-peer attacks are different from regular botnet-based attacks. With peer-to-peer there is no botnet and the attacker does not have to communicate with the clients it subverts. Instead, the attacker acts as a \"puppet master,\" instructing clients of large peer-to-peer file sharing hubs to disconnect from their peer-to-peer network and to connect to the victim's website instead. As a result, several thousand computers may aggressively try to connect to a target website. While a typical web server can handle a few hundred connections per second before performance begins to degrade, most web servers fail almost instantly under five or six thousand connections per second. With a moderately large peer-to-peer attack, a site could potentially be hit with up to 750,000 connections in short order. The targeted web server will be plugged up by the incoming connections.\nWhile peer-to-peer attacks are easy to identify with signatures, the large number of IP addresses that need to be blocked (often over 250,000 during the course of a large-scale attack) means that this type of attack can overwhelm mitigation defenses. Even if a mitigation device can keep blocking IP addresses, there are other problems to consider. For instance, there is a brief moment where the connection is opened on the server side before the signature itself comes through. Only once the connection is opened to the server can the identifying signature be sent and detected, and the connection torn down. Even tearing down connections takes server resources and can harm the server.\nThis method of attack can be prevented by specifying in the peer-to-peer protocol which ports are allowed or not. If port 80 is not allowed, the possibilities for attack on websites can be very limited.\nAsymmetry of resource utilization in starvation attacks \nAn attack which is successful in consuming resources on the victim computer must be either:\n- carried out by an attacker with greater resources, by either:\n- controlling a computer with greater computation power or, more commonly, large network bandwidth\n- controlling a large number of computers and directing them to attack as a group. A DDOS attack is the primary example of this.\n- taking advantage of a property of the operating system or applications on the victim system which enables an attack consuming vastly more of the victim's resources than the attacker's (an asymmetric attack). Smurf attack, SYN flood, Sockstress and NAPTHA are all asymmetric attacks.\nAn attack may utilize a combination of these methods in order to magnify its power.\nPermanent denial-of-service attacks \nA permanent denial-of-service (PDoS), also known loosely as phlashing, is an attack that damages a system so badly that it requires replacement or reinstallation of hardware. Unlike the distributed denial-of-service attack, a PDoS attack exploits security flaws which allow remote administration on the management interfaces of the victim's hardware, such as routers, printers, or other networking hardware. The attacker uses these vulnerabilities to replace a device's firmware with a modified, corrupt, or defective firmware image—a process which when done legitimately is known as flashing. This therefore \"bricks\" the device, rendering it unusable for its original purpose until it can be repaired or replaced.\nThe PDoS is a pure hardware targeted attack which can be much faster and requires fewer resources than using a botnet in a DDoS attack. Because of these features, and the potential and high probability of security exploits on Network Enabled Embedded Devices (NEEDs), this technique has come to the attention of numerous hacker communities.\nPhlashDance is a tool created by Rich Smith (an employee of Hewlett-Packard's Systems Security Lab) used to detect and demonstrate PDoS vulnerabilities at the 2008 EUSecWest Applied Security Conference in London.\nApplication-level floods \nOther kinds of DoS rely primarily on brute force, flooding the target with an overwhelming flux of packets, oversaturating its connection bandwidth or depleting the target's system resources. Bandwidth-saturating floods rely on the attacker having higher bandwidth available than the victim; a common way of achieving this today is via Distributed Denial of Service, employing a botnet. Other floods may use specific packet types or connection requests to saturate finite resources by, for example, occupying the maximum number of open connections or filling the victim's disk space with logs.\nA \"banana attack\" is another particular type of DoS. It involves redirecting outgoing messages from the client back onto the client, preventing outside access, as well as flooding the client with the sent packets.\nAn attacker with shell-level access to a victim's computer may slow it until it is unusable or crash it by using a fork bomb.\nA Nuke is an old denial-of-service attack against computer networks consisting of fragmented or otherwise invalid ICMP packets sent to the target, achieved by using a modified ping utility to repeatedly send this corrupt data, thus slowing down the affected computer until it comes to a complete stop.\nA specific example of a nuke attack that gained some prominence is the WinNuke, which exploited the vulnerability in the NetBIOS handler in Windows 95. A string of out-of-band data was sent to TCP port 139 of the victim's machine, causing it to lock up and display a Blue Screen of Death (BSOD).\nOWASP HTTP Post Denial of Service Tool \nFrom the authority of web application security OWASP Foundation the OWASP HTTP Post Tool completes the request headers phase however it sends the request body (post payload) very slowly (e.g. - 1 byte/110sec). When you consider that, by default, Apache will accept a request body of up to 2GB in size, you can can see how effective this attack can be.\nR-U-Dead-Yet? (RUDY) \nThis attack is one of many web application DoS tools available to directly attack web applications by starvation of available sessions on the web server. Much like Slowloris, RUDY keeps sessions at halt using never-ending POST transmissions and sending an arbitrarily large content-length header value.\nSlow Read attack \nSlow Read attack sends legitimate application layer requests but reads responses very slowly, thus trying to exhaust the server's connection pool. Slow reading is achieved by advertising very small number for the TCP Receive Window size and at the same time by emptying clients' TCP receive buffer slowly. That naturally ensures a very low data flow rate.\nDistributed attack \nA distributed denial of service attack (DDoS) occurs when multiple systems flood the bandwidth or resources of a targeted system, usually one or more web servers. This is the result of multiple compromised systems (for example a botnet) flooding the targeted system(s) with traffic. When a server is overloaded with connections, new connections can no longer be accepted.\nMalware can carry DDoS attack mechanisms; one of the better-known examples of this was MyDoom. Its DoS mechanism was triggered on a specific date and time. This type of DDoS involved hardcoding the target IP address prior to release of the malware and no further interaction was necessary to launch the attack.\nA system may also be compromised with a trojan, allowing the attacker to download a zombie agent (or the trojan may contain one). Attackers can also break into systems using automated tools that exploit flaws in programs that listen for connections from remote hosts. This scenario primarily concerns systems acting as servers on the web.\nStacheldraht is a classic example of a DDoS tool. It utilizes a layered structure where the attacker uses a client program to connect to handlers, which are compromised systems that issue commands to the zombie agents, which in turn facilitate the DDoS attack. Agents are compromised via the handlers by the attacker, using automated routines to exploit vulnerabilities in programs that accept remote connections running on the targeted remote hosts. Each handler can control up to a thousand agents.\nThese collections of systems compromisers are known as botnets. DDoS tools like Stacheldraht still use classic DoS attack methods centered on IP spoofing and amplification like smurf attacks and fraggle attacks (these are also known as bandwidth consumption attacks). SYN floods (also known as resource starvation attacks) may also be used. Newer tools can use DNS servers for DoS purposes. See next section.\nSimple attacks such as SYN floods may appear with a wide range of source IP addresses, giving the appearance of a well distributed DoS. These flood attacks do not require completion of the TCP three way handshake and attempt to exhaust the destination SYN queue or the server bandwidth. Because the source IP addresses can be trivially spoofed, an attack could come from a limited set of sources, or may even originate from a single host. Stack enhancements such as syn cookies may be effective mitigation against SYN queue flooding, however complete bandwidth exhaustion may require involvement.[further explanation needed]\nUnlike MyDoom's DDoS mechanism, botnets can be turned against any IP address. Script kiddies use them to deny the availability of well known websites to legitimate users. More sophisticated attackers use DDoS tools for the purposes of extortion – even against their business rivals.\nIf an attacker mounts an attack from a single host it would be classified as a DoS attack. In fact, any attack against availability would be classed as a Denial of Service attack. On the other hand, if an attacker uses many systems to simultaneously launch attacks against a remote host, this would be classified as a DDoS attack.\nThe major advantages to an attacker of using a distributed denial-of-service attack are that: multiple machines can generate more attack traffic than one machine, multiple attack machines are harder to turn off than one attack machine, and that the behavior of each attack machine can be stealthier, making it harder to track and shut down. These attacker advantages cause challenges for defense mechanisms. For example, merely purchasing more incoming bandwidth than the current volume of the attack might not help, because the attacker might be able to simply add more attack machines.\nIn some cases a machine may become part of a DDoS attack with the owner's consent. An example of this is the 2010 DDoS attack against major credit card companies by supporters of WikiLeaks. In cases such as this, supporters of a movement (in this case, those opposing the arrest of WikiLeaks founder Julian Assange) choose to download and run DDoS software.\nReflected / Spoofed attack \nA distributed reflected denial of service attack (DRDoS) involves sending forged requests of some type to a very large number of computers that will reply to the requests. Using Internet Protocol address spoofing, the source address is set to that of the targeted victim, which means all the replies will go to (and flood) the target.\nICMP Echo Request attacks (Smurf Attack) can be considered one form of reflected attack, as the flooding host(s) send Echo Requests to the broadcast addresses of mis-configured networks, thereby enticing many hosts to send Echo Reply packets to the victim. Some early DDoS programs implemented a distributed form of this attack.\nMany services can be exploited to act as reflectors, some harder to block than others. DNS amplification attacks involve a new mechanism that increased the amplification effect, using a much larger list of DNS servers than seen earlier.\nTelephony denial of service \nAccording to the US Federal Bureau of Investigation, TDoS has appeared as part of various fraudulent schemes:\n- A scammer contacts the victim's banker or broker, impersonating the victim to request a funds transfer. The banker's attempt to contact the victim for verification of the transfer fails as the victim's telephone lines are being flooded with thousands of bogus calls, rendering the victim unreachable.\n- A scammer contacts consumers with a bogus claim to collect an outstanding payday loan for thousands of dollars. When the consumer objects, the scammer retaliates by flooding the victim's employer with thousands of automated calls. In some cases, displayed caller ID is spoofed to impersonate police or law enforcement agencies.\n- A scammer contacts consumers with a bogus debt collection demand and threatens to send police; when the victim balks, the scammer floods local police numbers with calls on which caller ID is spoofed to display the victims number. Police soon arrive at the victim's residence attempting to find the origin of the calls.\nTelephony denial of service can exist even without Internet telephony. In the 2002 New Hampshire Senate election phone jamming scandal, telemarketers were used to flood political opponents with spurious calls to jam phone banks on election day. Widespread publication of a number can also flood it with enough calls to render it unusable, as happened with multiple +1-area code-867-5309 subscribers inundated by hundreds of misdialed calls daily in response to a popular song 867-5309/Jenny.\nTDoS differs from other telephone harassment (such as prank calls and obscene phone calls) by the number of calls originated; by occupying lines continuously with repeated automated calls, the victim is prevented from making or receiving both routine and emergency telephone calls.\nUnintentional denial of service \nThis describes a situation where a website ends up denied, not due to a deliberate attack by a single individual or group of individuals, but simply due to a sudden enormous spike in popularity. This can happen when an extremely popular website posts a prominent link to a second, less well-prepared site, for example, as part of a news story. The result is that a significant proportion of the primary site's regular users – potentially hundreds of thousands of people – click that link in the space of a few hours, having the same effect on the target website as a DDoS attack. A VIPDoS is the same, but specifically when the link was posted by a celebrity.\nWhen Michael Jackson died in 2009, websites such as Google and Twitter slowed down or even crashed. Many sites' servers thought the requests were from a virus or spyware trying to cause a Denial of Service attack, warning users that their queries looked like \"automated requests from a computer virus or spyware application\".\nNews sites and link sites – sites whose primary function is to provide links to interesting content elsewhere on the Internet – are most likely to cause this phenomenon. The canonical example is the Slashdot effect when receiving traffic from Slashdot. Sites such as Reddit, Digg, the Drudge Report, Fark, Something Awful, and the webcomic Penny Arcade have their own corresponding \"effects\", known as \"the Digg effect\", being \"drudged\", \"farking\", \"goonrushing\" and \"wanging\"; respectively.\nRouters have also been known to create unintentional DoS attacks, as both D-Link and Netgear routers have created NTP vandalism by flooding NTP servers without respecting the restrictions of client types or geographical limitations.\nSimilar unintentional denials of service can also occur via other media, e.g. when a URL is mentioned on television. If a server is being indexed by Google or another search engine during peak periods of activity, or does not have a lot of available bandwidth while being indexed, it can also experience the effects of a DoS attack.\nLegal action has been taken in at least one such case. In 2006, Universal Tube & Rollform Equipment Corporation sued YouTube: massive numbers of would-be youtube.com users accidentally typed the tube company's URL, utube.com. As a result, the tube company ended up having to spend large amounts of money on upgrading their bandwidth.\nDenial-of-Service Level II \nThe goal of DoS L2 (possibly DDoS) attack is to cause a launching of a defense mechanism which blocks the network segment from which the attack originated. In case of distributed attack or IP header modification (that depends on the kind of security behavior) it will fully block the attacked network from Internet, but without system crash.\nPerforming DoS-attacks \nA wide array of programs are used to launch DoS-attacks. Most of these programs are completely focused on performing DoS-attacks, while others are also true Packet injectors, thus able to perform other tasks as well. Such tools are intended for benign use, but they can also be utilized in launching attacks on victim networks.\nDefensive responses to Denial of Service attacks typically involves the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate. A list of prevention and response tools is provided below:\nFirewalls can be set up to have simple rules such to allow or deny protocols, ports or IP addresses. In the case of a simple attack coming from a small number of unusual IP addresses for instance, one could put up a simple rule to drop all incoming traffic from those attackers.\nMore complex attacks will however be hard to block with simple rules: for example, if there is an ongoing attack on port 80 (web service), it is not possible to drop all incoming traffic on this port because doing so will prevent the server from serving legitimate traffic. Additionally, firewalls may be too deep in the network hierarchy. Routers may be affected before the traffic gets to the firewall. Nonetheless, firewalls can effectively prevent users from launching simple flooding type attacks from machines behind the firewall.\nSome stateful firewalls, like OpenBSD's pf(4) packet filter, can act as a proxy for connections: the handshake is validated (with the client) instead of simply forwarding the packet to the destination. It is available for other BSDs as well. In that context, it is called \"synproxy\".\nMost switches have some rate-limiting and ACL capability. Some switches provide automatic and/or system-wide rate limiting, traffic shaping, delayed binding (TCP splicing), deep packet inspection and Bogon filtering (bogus IP filtering) to detect and remediate denial of service attacks through automatic rate filtering and WAN Link failover and balancing.\nThese schemes will work as long as the DoS attacks are something that can be prevented by using them. For example SYN flood can be prevented using delayed binding or TCP splicing. Similarly content based DoS may be prevented using deep packet inspection. Attacks originating from dark addresses or going to dark addresses can be prevented using Bogon filtering. Automatic rate filtering can work as long as you have set rate-thresholds correctly and granularly. Wan-link failover will work as long as both links have DoS/DDoS prevention mechanism.\nSimilar to switches, routers have some rate-limiting and ACL capability. They, too, are manually set. Most routers can be easily overwhelmed under a DoS attack. Cisco IOS has features that prevent flooding, i.e. example settings.\nApplication front end hardware \nApplication front end hardware is intelligent hardware placed on the network before traffic reaches the servers. It can be used on networks in conjunction with routers and switches. Application front end hardware analyzes data packets as they enter the system, and then identifies them as priority, regular, or dangerous. There are more than 25 bandwidth management vendors.\nIPS based prevention \nIntrusion-prevention systems (IPS) are effective if the attacks have signatures associated with them. However, the trend among the attacks is to have legitimate content but bad intent. Intrusion-prevention systems which work on content recognition cannot block behavior-based DoS attacks.\nAn ASIC based IPS may detect and block denial of service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.\nA rate-based IPS (RBIPS) must analyze traffic granularly and continuously monitor the traffic pattern and determine if there is traffic anomaly. It must let the legitimate traffic flow while blocking the DoS attack traffic.\nDDS based defense \nMore focused on the problem than IPS, a DoS Defense System (DDS) is able to block connection-based DoS attacks and those with legitimate content but bad intent. A DDS can also address both protocol attacks (such as Teardrop and Ping of death) and rate-based attacks (such as ICMP floods and SYN floods).\nLike IPS, a purpose-built system, such as the well-known Radware DefensePro, can detect and block denial of service attacks at much nearer line speed than a software based system.\nBlackholing and sinkholing \nWith blackholing, all the traffic to the attacked DNS or IP address is sent to a \"black hole\" (null interface or a non-existent server). To be more efficient and avoid affecting network connectivity, it can be managed by the ISP.\nSinkholing routes traffic to a valid IP address which analyzes traffic and rejects bad packets. Sinkholing is not efficient for most severe attacks.\nClean pipes \nAll traffic is passed through a \"cleaning center\" or a \"scrubbing center\" via various methods such as proxies, tunnels or even direct circuits, which separates \"bad\" traffic (DDoS and also other common internet attacks) and only sends good traffic beyond to the server. The provider needs central connectivity to the Internet to manage this kind of service unless they happen to be located within the same facility as the \"cleaning center\" or \"scrubbing center\".\nSide effects of DoS attacks \nIn computer network security, backscatter is a side-effect of a spoofed denial-of-service attack. In this kind of attack, the attacker spoofs (or forges) the source address in IP packets sent to the victim. In general, the victim machine cannot distinguish between the spoofed packets and legitimate packets, so the victim responds to the spoofed packets as it normally would. These response packets are known as backscatter.\nIf the attacker is spoofing source addresses randomly, the backscatter response packets from the victim will be sent back to random destinations. This effect can be used by network telescopes as indirect evidence of such attacks.\nThe term \"backscatter analysis\" refers to observing backscatter packets arriving at a statistically significant portion of the IP address space to determine characteristics of DoS attacks and victims.\n|This section requires expansion. (January 2011)|\nIn the US, denial-of-service attacks can considered a serious federal crime under the Computer Fraud and Abuse Act with penalties that include years of imprisonment. Many other countries have similar laws.\nThe US situation is under court ruling with a case in California.\nSee also \n- Billion laughs\n- Black fax\n- Industrial espionage\n- Intrusion-detection system\n- Network intrusion detection system\n- Regular expression Denial of Service\n- Virtual sit-in\n- Wireless signal jammer\nNotes and references \n- Shabtai, A.; Fledel, Y.; Kanonov, U.; Elovici, Y.; Dolev, S.; Glezer, C. (March–April 2010). \"Google Android: A Comprehensive Security Assessment\". IEEE Security & Privacy Magazine 8 (2): 35–44. doi:10.1109/MSP.2010.2.\n- Mindi McDowell (2007). \"Cyber Security Tip ST04-015\". United States Computer Emergency Readiness Team. Retrieved May 2, 2008.\n- \"Types of DDoS Attacks\". 2001. Retrieved May 2, 2008.\n- \"RFC 4987 – TCP SYN Flooding Attacks and Common Mitigations\". Tools.ietf.org. Retrieved 2011-12-02.\n- \"CERT Advisory CA-1997-28 IP Denial-of-Service Attacks\". CERT. 1998. Retrieved May 2, 2008.\n- \"Windows 7, Vista exposed to 'teardrop attack'\". ZDNet. Retrieved 2011-12-02.\n- \"Microsoft Security Advisory (975497): Vulnerabilities in SMB Could Allow Remote Code Execution\". Microsoft.com. Retrieved 2011-12-02.\n- Zhang, C.; Yin, J.; Cai, Z.; Chen, W. (May 2010). \"RRED: Robust RED algorithm to counter low-rate denial-of-service attacks\". IEEE Communications Letters 14 (5): 489–491. doi:10.1109/LCOMM.2010.05.091407.\n- Leyden, John (2008-05-21). \"Phlashing attack thrashes embedded systems\". theregister.co.uk. Retrieved 2009-03-07.\n- \"Permanent Denial-of-Service Attack Sabotages Hardware\". Dark Reading. 2008. Retrieved May 19, 2008.\n- \"EUSecWest Applied Security Conference: London, U.K.\". EUSecWest. 2008. Archived from the original on 2009-02-01.\n- \"The \"stacheldraht\" distributed denial of service attack tool\". Retrieved 2011-12-02.\n- Phillip Boyle (2000). \"SANS Institute – Intrusion Detection FAQ: Distributed Denial of Service Attack Tools: n/a\". SANS Institute. Retrieved May 2, 2008.\n- Leyden, John (2004-09-23). \"US credit card firm fights DDoS attack\". Theregister.co.uk. Retrieved 2011-12-02.\n- Paxson, Vern (2001), An Analysis of Using Reflectors for Distributed Denial-of-Service Attacks\n- Vaughn, Randal and Evron, Gadi (2006), DNS Amplification Attacks\n- Shiels, Maggie (2009-06-26). \"Web slows after Jackson's death\". BBC News.\n- \"Google Discussiegroepen\". Google.com. Retrieved 2012-02-11.\n- \"YouTube sued by sound-alike site\". BBC News. 2006-11-02.\n- Loukas, G.; Oke, G. (September 2010) [August 2009]. \"Protection Against Denial of Service Attacks: A Survey\". Comput. J. 53 (7): 1020–1037. doi:10.1093/comjnl/bxp078.\n- Froutan, Paul (June 24, 2004). \"How to defend against DDoS attacks\". Computerworld. Retrieved May 15, 2010.\n- \"Some IoS tips for Internet Service (Providers)\" (Mehmet Suzen)\n- Patrikakis, C.; Masikos, M.; Zouraraki, O. (December 2004). \"Distributed Denial of Service Attacks\". The Internet Protocol Journal 7 (4): 13–35.\n- \"DDoS Mitigation via Regional Cleaning Centers (Jan 2004)\" (PDF). Retrieved 2011-12-02.\n- \"VeriSign Rolls Out DDoS Monitoring Service\". Darkreading.com. Retrieved 2011-12-02.\n- \"DDoS: A Threat That's More Common Than You Think\". Tatacommunications.com. 2011-09-07. Retrieved 2011-12-02.\n- \"AT&T Internet Protect Distributed Denial of Service Defense\". 2012-10-16.\n- An educational animation describing such backscatter can be found on the animations page maintained by the Cooperative Association for Internet Data Analysis.\n- U.K. outlaws denial-of-service attacks, November 10, 2006, By Tom Espiner – CNET News\n- \"United States Code: Title 18,1030. Fraud and related activity in connection with computers | LII / Legal Information Institute\". Law.cornell.edu. 2010-06-28. Retrieved 2012-02-11.\n- DDOS Attack: crime or virtual sit-in?, October 6, 2011, by RT.COM\n- \"Anonymous DDoS Petition: Group Calls On White House To Recognize Distributed Denial Of Service As Protest\". 2013-01-12.\nFurther reading \n- \"Distributed Denial of Service Attacks Against Independent Media and Human Rights Sites\". The Berkman Center for Internet & Society at Harvard University. December 2010. Archived from the original on 2011-05-01. Retrieved 2011-03-02.\n- \"DDOS Public Media Reports\". Harvard. Archived from the original on 2011-05-01.\n||This article's use of external links may not follow Wikipedia's policies or guidelines. (November 2012)|\n- RFC 4732 Internet Denial-of-Service Considerations\n- Radware Global Security Report  GlobalApplicationNetSecurityReport_HP\n- W3C The World Wide Web Security FAQ\n- Understanding and surviving DDoS attacks\n- cert.org CERT's Guide to DoS attacks. (historic document)\n- ATLAS Summary Report – Real-time global report of DDoS attacks.\n- linuxsecurity.com An article on preventing DDoS attacks.\n- Is Your PC a Zombie?, About.com.\n- Report: Distributed Denial of Service Attacks Against Independent Media and Human Rights Sites Berkman Center for Internet and Society Report on DDOS\n- News on DDoS Latest DDoS news and techniques\n- Mitigating Slow HTTP Denial of Service", "label": 1}
{"text": "[Dogbert] took a look at the security that goes into BIOS passwords on many laptops. He starts off with a little background about how the systems work. People are bound to forget their passwords, so when you enter a wrong one three times in a row you get a message similar to the one above that locks you out until all power is removed from the system (then you get three more tries). But check out that five-digit number in the picture. That’s a checksum of the password. Some BIOS versions display it automatically, some require you to hold down a certain key during POST, but it’s the pivotal data needed to crack the password.\n[Dogbert's] post doesn’t go into verbose detail about the algorithms he uses to brute force the passwords. But he has posted the Python scripts he uses to do so. Learning how to generate the passwords based on the checksum is as simple as studying the code, which is often the best way to learn.", "label": 1}
{"text": "A rootkit typically patches the kernel or other software libraries to alter the behavior of the operating system. Once this is happening, you cannot trust anything that the operating system tells you.\nFor example; a simple change to the\ndir program could hide the existence of malicious files from a user, but this is easily detectable by many anti-virus packages as the alteration of an executable is something that can be noticed. If however, the malware alters the mechanisms by which userland programs query the file system, by patching the kernel itself, any user-space program can be tricked into thinking that the executable has not been altered.\nOnce malware has started altering the behavior of the system calls/kernel api, it can hide any activity effectively, including network interactions.\nAll of this only applies if you are monitoring the infected machine locally. If you have firewall logs or some other remote method of monitoring the infected machine, this information can be trusted (the network connections still have to exist, but they can be hidden from the infected OS).", "label": 1}
{"text": "- Language Tips\nFlame, one of the most complex computer viruses ever discovered, has been detected in China and could potentially cause widespread damage - including information leakage - to company and government networks as well as individual computers, experts warned.\n\"According to our analysis, the virus was designed mainly to target governments, firms, schools and scientific institutions,\" said Liu Siyu, director of the research and development section of Rising International Software, a Chinese Internet security company.\n\"However, the technology it used could be adopted by other lower-level Trojan viruses and cause damage to the networks we use in our daily lives,\" he said.\nThe company issued a notice on its website last week, calling on companies to take all necessary measures to protect themselves from the virus.\n\"We first intercepted this virus on Wednesday and have not received any report of damage caused by it yet,\" said Liu.\nInitial analysis has revealed the complexity of the virus. It contains many components, each with a different function that can integrate with others to cause complex harm to the infected network, Liu said.\n\"The total size of the virus package is nearly 20 megabytes, while a normal virus is less than one megabyte.\"\nAccording to Liu, the virus could even record sound and video stored in the infected computer and steal the information.\n\"It is arguably the most complex virus discovered,\" said Hungary-based Laboratory of Cryptography and System Security in a 64-page technical report released on Thursday.\nFlame has very advanced functionality to steal information and to propagate, and covers all major intelligence gathering possibilities, including monitoring keystrokes, screens, microphones, storage devices, networks, WiFi, Bluetooth, USB and system processes, according to the report.\nLiu said Rising has upgraded its anti-virus software, which is capable of eliminating the virus. It also offered a free anti-virus software that anyone can download, he said.\nThe lab's report said Flame first appeared in Europe in December 2007, but it \"may have been active for five to eight years\".\n\"The result of our technical analysis supports the hypotheses that sKyWlper (Flame) was developed by a government agency of a nation with significant budget and effort, and it may be related to cyber warfare activities,\" the report said.\nAccording to a report by Iran's Kayhan daily on Thursday, which was quoted by Xinhua New Agency, Iranian cyber experts have detected and contained Flame, which it called an Israeli spy virus.\nFlame has targeted Iran's oil industry, the report said, adding that, however, Iranian experts have been able to detect and contain it.\nThe report said that the malware was different from other viruses and was more destructive than Stuxnet.\nIran announced in October 2010 that it had detected and thwarted the Stuxnet virus aimed at infecting the country's nuclear plant system.\nAccording to the Iranian intelligence service, Stuxnet had infected 30,000 IP addresses in the country.", "label": 1}
{"text": "VMware vSphere For Dummies\nWith virtualization, a single server can host dozens or hundreds of virtual machines running a variety of operating systems, and even hook them together in a virtual network or cloud infrastructure. This practical guide shows you how to create a virtual system using the VMware VSphere environment. You'll find all the information you need to understand, design, and deploy one—without getting overwhelmed with technical detail. And once you’re up and running, this book is the perfect reference for maintenance and troubleshooting issues.\n- Introduces you to virtualization and VMware’s virtualization/cloud computing technology, the most recent version is VMware vSphere Shows you how to design a vSphere environment\n- Covers installation, deployment, management, maintenance, and troubleshooting\n- Provides what IT managers and system administrators need to roll out their first virtualized or cloud infrastructure, or to get up to speed on VMware’s technology\nGet up and running on the cloud with VMware vSphere For Dummies!", "label": 1}
{"text": "Those of us who interact with or manage the results from penetration testing teams all (hopefully!) understand the ramifications when a XSS vulnerability is found.\nWe may even all understand the differences between a reflected XSS vulnerability and a persistent (stored) XSS vulnerability.\nWhat about those higher up the food chain? Do those who interact with the executives within an organisation fully understand the risks from a XSS vulnerability? Do they paint a realistic picture to those who are ultimately responsible for said website of just what is possible?\nA reflected XSS vulnerability is when ‘code’ is injected into a website in such a way so as to deliver a payload or to produce a result on the end users browser. Reflected XSS vulnerabilities are delivered to a victim via various means such as an email causing the user to click on a malicious URL which in itself normally contains the malicious ‘code’.\nA persistent XSS vulnerability is one in which the ‘code’ is actually injected into the website itself, and remains for multiple users to be attacked by. For example, placing XSS code within the database that a forum uses would mean anyone who viewed that specific forum or thread would be affected by said code. The URL used to access this forum would not appear malicious…\nIn this post I’d like to provide some examples of what is possible with a reflected XSS vulnerability, it is in no way an exhaustive list. I created a purposefully weak and simple application that prints (or executes) the text placed in the relevant fields. It uses the GET method which means the code is visible within the browsers address bar…\nAs can be seen the application is a simple form asking for a Name and CustomerID which are then printed on the next page\nNotice that the URL contains now the ‘code’ for an alert, and its being executed without restriction.\nTime for some fun… Any one remember Rick Astley?\nFrom a PR point of view, an XSS can be very embarrassing. Executed in a certain manner and it could be used to launch a variety of ‘inappropriate’ popup windows which would appear to be from the ‘corporate’ website, it could equally be used to redirect any users accessing the specific URL to a company’s main competition.\nOne last example is the embedding of new forms into websites so as to try and steal users legitimate credentials. Now it could be said that vigilant users would see something wrong with the URL, but what about if it was hidden behind a ShortURL? How many of your users would fall for this in that scenario?", "label": 1}
{"text": "'End of passwords' predictions are premature - Cambridge boffin\nNice fresh well-salted hash will keep them healthy\nAdvances in the power of computers won't automatically make passwords obsolete, according to a top computer science researcher.\nJoseph Bonneau, a postgrad researcher at Cambridge University, looked into the perceived wisdom that runs along these lines: \"Since computers are getting exponentially faster, yet the human brain is constant, then password crackers will eventually beat human memory.\"\nRemarks such as this are often made when the latest advances in increasingly powerful graphics processors for password cracking or similar stories hit the news. Bonneau doesn't dispute that password cracking is getting faster or that easily guessable or reused passwords are toast. Instead he disputes the idea that well thought out, complex passwords stored using a sufficiently robust hash function with proper salting have had their day.\nA hash function is a mathematical process that takes a \"message\" and forms a message digest or hash from it. Storing plain text passwords as part of an online authentication system is an obviously bad idea. If a website is broken into and the passwords are lifted then even well thought out passwords are exposed.\nInstead websites need to store password hashes, protected by salting, in order to prevent brute force attacks using rainbow tables.\nA password hash is computationally easy to create but working out the corresponding password from a hash ought to be nearly impossible, given a correctly implemented hash function. Rainbow tables circumvent this snag by creating a large data set of hashes from nearly every possible password. Faster number-crunching chips make it possible to derive and run through an increasing volume of possible passwords, increasing the potency of such brute force attacks.\nBonneau argues however that this points towards an arms race necessitating the development of better hashing algorithms rather than an inexorable move towards the end of days for passwords.\n\"Password cracking is certainly getting faster,\" Bonneau explains. \"In my thesis I charted 20 years of password cracking improvements and found an increase of about 1,000 in the number of guesses per second per unit cost that could be achieved, almost exactly a Moore’s Law-style doubling every two years.\n\"The good news though is that password hash functions can (and should) co-evolve to get proportionately costlier to evaluate over time. This is a classic arms race and keeping pace simply requires regularly increasing the number of iterations in a password hash. We can even improve against password cracking over time using memory-bound functions, because memory speeds aren’t increasing nearly as quickly and are harder to attack using parallelism,\" he adds.\nBonneau cautions against complacency: hashing passwords isn't going to get any more efficient over time and older algorithms will need to be replaced by more complex successors. As well as the brute force problem, hashing algorithms can come under increasing pressure from new types of cryptanalysis.\n\"Moore’s Law has indeed broken MD5 as a password hash and no serious application should still use it. Human memory isn’t more of a problem today than it used to be though. The problem is that we’ve chosen to let password verification become too cheap,\" Bonneau argued.\nBooneau's remarks come days after Deloitte Canada warned that the password was doomed. It predicted more than 90 per cent of user-generated passwords will be vulnerable to hacking during the course of 2013.\n“Passwords containing at least eight characters, one number, mixed-case letters and non-alphanumeric symbols were once believed to be robust. But these can be easily cracked with the emergence of advanced hardware and software,” Duncan Stewart, director, Deloitte Canada Research said. Deloitte Canada made the point while arguing for more widespread use of two-factor authentication using either tokens or mobile phone technology. Password vaults, secured by two-factor authentication, can play a role in driving the wider use of more complex passwords that users don't necessarily have to remember, the management consultancy argues, adding that disaster beckons for continued use of current password choices.\n\"In a recent study of six million actual user-generated passwords, the 10,000 most common passwords would have accessed 98.1 percent of all accounts,\" Deloitte Canada adds.\nEasily guessable passwords are arguably a lesser problem than password re-use. The average user has 26 password-protected accounts, but only five different passwords across those accounts, according to a recent study by credit reference agency Experian.\nDeloitte Canada's prognosis on password problems can can be read on page 11 of a larger report on tech trends here (PDF). ®", "label": 1}
{"text": "Enforcing data integrity ensures the quality of the data in the database. For example, if an employee is entered with an employee_id value of 123, the database should not allow another employee to have an ID with the same value. If you have an employee_rating column intended to have values ranging from 1 to 5, the database should not accept a value of 6. If the table has a dept_id column that stores the department number for the employee, the database should allow only values that are valid for the department numbers in the company.\nTwo important steps in planning tables are to identify valid values for a column and to decide how to enforce the integrity of the data in the column. Data integrity falls into these categories:\n- Entity integrity\n- Domain integrity\n- Referential integrity\n- User-defined integrity\nEntity integrity defines a row as a unique entity for a particular table. Entity integrity enforces the integrity of the identifier column(s) or the primary key of a table (through indexes, UNIQUE constraints, PRIMARY KEY constraints, or IDENTITY properties).\nDomain integrity is the validity of entries for a given column. You can enforce domain integrity by restricting the type (through data types), the format (through CHECK constraints and rules), or the range of possible values (through FOREIGN KEY constraints, CHECK constraints, DEFAULT definitions, NOT NULL definitions, and rules).\nReferential integrity preserves the defined relationships between tables when records are entered or deleted. In Microsoft® SQL Server™ 2000, referential integrity is based on relationships between foreign keys and primary keys or between foreign keys and unique keys (through FOREIGN KEY and CHECK constraints). Referential integrity ensures that key values are consistent across tables. Such consistency requires that there be no references to nonexistent values and that if a key value changes, all references to it change consistently throughout the database.\nWhen you enforce referential integrity, SQL Server prevents users from:\n- Adding records to a related table if there is no associated record in the primary table.\n- Changing values in a primary table that result in orphaned records in a related table.\n- Deleting records from a primary table if there are matching related records.\nFor example, with the sales and titles tables in the pubs database, referential integrity is based on the relationship between the foreign key (title_id) in the sales table and the primary key (title_id) in the titles table.\nUser-defined integrity allows you to define specific business rules that do not fall into one of the other integrity categories. All of the integrity categories support user-defined integrity (all column- and table-level constraints in CREATE TABLE, stored procedures, and triggers).", "label": 1}
{"text": "Why a Surveillance Society Clock?\nSurveillance is an urgent issue. That isn't always obvious amid the constant blur of new technologies and one-day privacy stories, but when you step back it is clear we are at a crucial moment for the future of privacy and freedom, in danger of tipping into a genuine surveillance society completely alien to American values. That is why the ACLU has made this new Surveillance Clock – to dramatize the urgent situation we face.\nMake a Difference\nYour support helps the ACLU defend privacy rights and a broad range of civil liberties.\nAmazing new technologies enter our lives at such a steady pace that we have gotten used to constant change – change that often comes to us wrapped in the promise (and often the reality) of pleasing new conveniences and efficiencies. Yet the dark side of new technologies is usually slower to emerge – and often builds in the shadows, without an advertising budget or corporate cheerleader to thrust it into public view.\nIt doesn't require some apocalyptic vision of American democracy being replaced by dictatorship to worry about a surveillance society. There is a lot of room for the United States to become a meaner, less open and less just place without any radical change in government. All that's required is the continuation of trends that have continued unimpeded in recent years:\n- Powerful new technologies\n- Weakening privacy laws\n- The \"War on Terror\"\n- Courts that are letting privacy rights slip away\n- A president who thinks he can ignore laws against warrantless spying on citizens\n- Big corporations willing to become extensions of the surveillance state\nThe Surveillance Clock symbolizes the potential for a dark future where our every move, our every transaction, our every communication, and eventually our every thought, is recorded, compiled, and stored away, ready to be examined and used against us by the authorities whenever they want.\nThe Surveillance Society Clock was inspired by the \"Doomsday Clock\" created in 1947 by the Bulletin of the Atomic Scientists to warn about the potential for nuclear war. Today we face the prospect of the complete loss of our privacy. In that way, the Surveillance Society Clock is a fitting sign of the times we're now living in.\nBut, as dire as things have gotten, it's not too late - there is still time to save our privacy. Doomsayers who say \"it doesn't matter, we've already lost all our privacy\" are wrong. In America we still enjoy many protections despite everything that is happening – a reflection of the wisdom of our founders and the strength of our traditions. But to keep those traditions alive, our generation will have to work harder. We need modern privacy laws and new technologies that enhance our privacy rather than destroy it.\nWe hope that our clock will help to remind people of the emergency we face, and spur them to take action on our Web page.\nGo to www.aclu.org/clock", "label": 1}
{"text": "This blog was originally posted here: Windows 8: The right way to Read & Write Files in WinRT\nAlso, check out our Windows Runtime (WinRT) sponsored section.\nWindows 8: The right way to Read & Write Files in WinRT\nWindows 8 Metro development leverages WinRT; and, in WinRT, there are new namespaces – and namespace constriction in the .Net Framework. What you think you know, you may not.\nMSDN: In some cases, a type that you used in a .NET Framework desktop app doesn't exist within the .NET APIs for Metro style apps. Instead, you can use a type from the Windows Runtime. For example, the System. IO. IsolatedStorage. IsolatedStorageSettings class isn't included in the .NET APIs for Metro style apps, but the Windows.Storage.ApplicationDataContainer class provides similar behavior for storing app settings. Examples of common changes you might have to make are included in the section Converting your existing .NET Framework code.\nRead Isolated Storage\nEvery Metro application has three folders. A Local folder, a Roaming folder and a Temp folder. Each is accessed the same way. Local is meant to store assets in a local, application-specific folder.\nMSDN: You can access files in the local app data store using the \"ms-appdata:///local/\" protocol. To access files in the app package, use Windows. ApplicationModel. Package. Current. InstalledLocation.\nTo request that Windows index your app data for search, create a folder named \"indexed\" under this folder and store the files that you want indexed there. Windows indexes the file content and metadata (properties) in this \"indexed\" folder and all its subfolders.\nRoaming is meant to store assets that should be synchronized with any other desktop where the current user has the same application installed.\nMSDN: The sync engine has restrictions on the file name conventions that you must follow to ensure the items in the roaming folder can roam. Be sure that your file and folder names do not contain leading whitespace. The sync engine may limit the total size of settings and files that can roam. You can access files in the roaming app data store using the \"ms-appdata:///roaming/\" protocol.\n<img src=\"ms-appdata:///roaming/myFile.png\" alt=\"\" />\nTemp is a throw-away location that will be cleaned, potentially, every time the application is launched.\nMSDN: You can access files in the temporary app data store using the \"ms-appdata:///temp/\" protocol.\nHere’s how you use them:\nGet the code here.\nThe code above is a simple Unit Test demonstrating the core functionality of writing and reading to Isolated Storage. You might notice that there is no mention of Isolated Storage in the code or namespaces (like there is in the Windows Phone API). Just know that all of this takes place in Isolated Storage, and for the same reason – to compartmentalize your application and it’s ability to break the user’s machine.\nRead Project Files\nHere’s a fun one. What if you have a resource (a file) in your project that you want to read? Lots of time this is for sample data or settings or something. It could be an XML file, a JSON file, or something else. Can you do it? Of course.\nAdd the file to your project. Note: since this is your file, you will need to deal with the type. Somewhere else you can learn how to deserialize JSON and XML.\nChange your file’s Build Action to Content. And, change Copy to Output Directory to Copy Always. This will ensure the file itself ships with your application. If it doesn’t, you wont have a file to read!\nRead your project file like this:\nGet the code here.\nThe code above is a simple Unit Test demonstrating how to read a file that is included in your project’s folder structure. The two most important parts is the unique path and Installed Location folder. Pay close attention. The correct path will include your project name (mine is Metro.Helpers.Tests).\nRead Local files w/a Picker\nHere’s a great one. You want to read a file in the Documents Library? Let the user select the file using a picker, and take it from there! Let’s do it.\nJust Do It\nThere’s nothing special you have to do in order to use a file picker. No changes to the AppXManifest, I mean. The reason is, using a File Picker puts the user in charge. Only the user can pick a file. And so, the picker itself is sort of its own Capabilities declaration and consent.\nGet the code here.\nIn the code above we initialize the FileOpenPicker (just like we have always done in .Net). We invoke the picker using PickSingleFileAsync() where we get a StorageFile (just like all the techniques above) and we go from there. I added a MessageBox (aka MessageDialog) to show some details. Clearly in your application you will do something else.\nRead Local files w/o a Picker\nWhat if you want to read a file without using the File Picker. Can you do that? You bet. But, it takes more effort because you need to update your applications AppXManifest to request the Document Library Access capability.\nBut wait there’s more.\nSee that red X on the Capabilities tab title? That tells you that something is not right. The manifest designer is pretty cool. What’s left?\nYou also need to update your AppXManifest by declaring what file type(s) you want to access. Then, even with access to the folders, you only have access to a limited set of file types. (in case you wondered *.* is not allowed)\nNote: Accessing the file system without user interaction is dangerous for the user. These extra steps are not meant to make your life (the developer) easier. It is meant to make the user’s experience easier and more safe.\nSo, in my case I will only want access to TXT files. The Declarations tab can be complex – to learn more about it, look here. I set a new file type (.txt) and let it role from there.\nWhen the user installs your application, they will be promoted to consent to the capabilities your application requests. Its capabilities are constrained by the manifest. And, your app’s capabilities are reviewed by Microsoft store curators.\nNow, get that file!\nYou have probably noticed with all the samples in this article that I have to write and read in order to have a reliable test. This one is no different. This will create the HelloWorld.txt file and read it. For added fun, I also will delete the file at the end of the method so your folder is not polluted.\nGet the code here.\nThe only reason the code above works is because we have declared the capability to read TXT files from the Documents Library folder in the AppXManifest file. Reading the file is easy because, once you get it, it’s just a simple WinRT StorageFile.\nPretty simple really, eh?\nSome Interesting StorageFile Methods\nI might take a moment to talk about StorageFolder, too. One of the most common requests I get is to iterate files and folders on user’s system. You really can’t – if what you mean is to start at c:\\. Try to iterate through c:\\ and you get this:\nYou can, however, iterate the files in a Library (Documents, Photos, Music, Videos, and even Home Group) folder – if you have requested this capability in the manifest. It is important to note that the files returned for a folder will be automatically filtered to the file types you declare in your manifest. (Did I already mention *.* cannot be declared?) Let me restate that as a developer you have intentional restrictions like this that ultimately improve the user’s experience and safety.\nRead those files people. Whatever your reason, they are there for you to get them. Yes, the sandbox of a Metro application prevents access to files and resources outside user’s Libraries. But in about 2 seconds you can appreciate this decision. We are approaching a brave new world.\nNow, should your application REQUIRE such access (that is otherwise restricted), you might consider the choice between desktop and metro applications – or consider a clever alternative; we all know you are a clever developer, keen at problem solving. You can do it!\nBest of luck!\nJerry Nixon is a Microsoft Developer Evangelist in Colorado. He has been developing and designing on the Microsoft platform for 15 years. He speaks at universities, events and groups on Kinect, XAML, Windows Phone, and Windows 8. Most of Jerry’s days are spent teaching his three daughters Star Trek character backstories and episode plots.", "label": 1}
{"text": "DNSSEC: Security for Essential Network Services - Page 3\nHow DNSSEC Works\nFrom our discussion so far, it is clear that DNS has some major security issues that urgently need to be addressed. The Internet and security engineering communities have responded to the threats by developing DNSSEC, a new secure DNS protocol, which addresses the data integrity and source-spoofing issues by means of a public key distribution. Interestingly, the extensions do not protect against buffer overruns or DDoS types of attack, nor do they provide confidentiality -- another major issue.\nTo maintain as much backwards compatibility as possible, the DNSSEC protocol requires only minor changes to the DNS protocol. DNSSEC has added four additional record types (SIG, KEY, DS, and NXT) and two new message header bits (CD and AD). Because the UDP protocol has a packet size limit of 512 bits, DNSSEC requires the use of EDNS0 extensions that override the limitation so that larger key sizes can be accommodated.\nThe DNSSEC implementation uses the familiar public/private key system. The site administrator generates a key pair for the secured domain. The private key is generally kept on the domain's primary master name server, and the public key is published in the domain in a KEY record. The administrator signs the domain's data record to verify its authenticity and adds a SIG record, which contains the signature for each domain record. The administrator submits the public KEY to the administrator of the domain's parent to sign with proof that he is the administrator of that domain. The parent domain's administrator signs the domain's public KEY and returns it. Unfortunately, a major unresolved issue is that nobody has really determined key authentication and verification methodologies. How keys are configured initially and how they are updated has yet to be determined as well.\nDNSSEC solves many of the worst DNS security problems. It is based on generally known technology and is backwards compatible with the existing DNS infrastructure. It is completely transparent to the user population and downstream administrators if they choose not to implement the extensions. While it does require installation of BIND 9 or later, you should upgrade to BIND 9 for many other beneficial reasons.\nSo why has DNSSEC not been widely adopted by the Internet community to date? After all, increased security of such a vital service should be an important priority for the maintenance of the Internet. Unfortunately, the implementation of DNSSEC is problematic because of the large increase in the computational load it puts on the servers, the hierarchical model of trust, the lack of tools to support the additional administrative overhead, the need for a higher level of time synchronization between the servers, and most critically, DNSSEC by itself does not begin to solve all the known DNS security vulnerabilities.\nIncreased Computational Load\nDNSSEC significantly increases the size of DNS response packets, which drastically increases the computational load on the DNS servers and also increases the query response time. Just the process of verifying signed resource records is computationally intensive, particularly if you choose larger key sizes. The DNSSEC standard allows up to 1024 bit keys. Adding digital signatures to a domain increases each record size 5-7 times, which puts a burden on upstream name servers.\nHierarchical Trust Model\nLike DNS itself, DNSSEC's trust model is almost totally hierarchical. Any compromise in the chain between the root servers and a target machine can damage DNSSEC's ability to protect the integrity of the data owned by that downstream system.\nLack of Management Tools\nDNSSEC is an order of magnitude more complex than DNS. Since the system is relatively new, there are few tools to help with the cumbersome task of maintaining a signed domain. Serious problems can occur with configuration errors and expired keys, and monitoring and log analysis tools are virtually non-existent. Debugging the errors by hand can be time consuming and difficult.\nForces Stricter Time Synchronization\nDNSSEC requires at least some time synchronization between the primary and secondary name servers. This is problematic because NTP (Network Time Protocol) itself is insecure, which opens up the possibility of DoS attacks based on invalid times.", "label": 1}
{"text": "In the past, I've written about \"phishing.\" Basically, it's a way for unscrupulous thieves to steal your identity. They send you an e-mail that includes a link to a bogus site that asks you to type in your personal information. Keeping yourself safe from phishing is simple: never, ever click a link in your e-mail that asks for any personal information. If you are a PayPal or eBay member, for example, and you get an e-mail that seems to be from them, don't click the link in the e-mail. Take the three extra seconds to open up a new browser window and type in www.paypal.com or www.ebay.com directly into the address bar.\nAvoiding this form of identity theft is easy, however, there's a new type of attack that's more complex. A term called \"pharming\" describes a new way to trick you out of providing personal information. Pharming is another name for something that's been around for a while called \"domain spoofing.\" Instead of sending an e-mail, pharmers attack a fundamental piece of the Internet called domain name servers (DNS).\nTo understand pharming, you need understand a bit about DNS. Basically, the Internet is really made up of numbers, not names, to describe the location of Web sites. So a site called www.mywebsite.com might really be 188.8.131.52. Domain name servers sit out there, and by accessing large databases of sites, they translate the text you type into the numbers the Internet needs to take you to the site you requested. Unfortunately, DNS is a weak link because a number of years ago, hackers figured out how to \"poison\" DNS and change the records for certain sites. They pretend to have authority to change the destination of a Web address. If they do this to an information site, it's really not a big deal as far as identity theft is concerned. If they do it to a banking site, it becomes a really big deal.\nThe scary reality of pharming is that even if you were to type in www.mybank.com into your browser's address bar, you could be taken to a site that looks like mybank.com, but really is not. However, by paying attention you can keep yourself safe. Any reputable banking or ecommerce site has a security certificate (or SSL certificate) from an authority such as Verisign or Thawte. That's what gives you the little lock icon or https:// in the address bar. A pharmed site won't have a valid certificate.\nSo you want to make sure your Web browser checks for a valid SSL certificate. To do that, you need to set some options. In Internet Explorer, choose Tools|Internet Options. In the Advanced tab, look under the Security section. Add check marks next to: Check for publisher's certificate revocation, Check for server certificate revocation, Use SSL 3.0, and Warn about invalid site certificates.\nSure, people are working on making DNS more secure. But the criminals are working just as hard on ways to defeat new security. So when you surf, always pay attention. If something looks a little \"off\" with a site, it may be, so exercise caution before providing any important information.", "label": 1}
{"text": "Nov 18, 2011 11:45 AM, By Mark Mayfield\nIs it ready for AV control?\nThe definition of cloud computing has, until recently, been as translucent as the gaseous cluster of water vapor molecules after which it is named.\nTo help add shape to the issue, the National Institute of Standards and Technology (NIST) released a draft document in January 2011, titled “The NIST Definition of Cloud Computing.” It begins with the definition: “Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.”\nAs part of its definition, NIST also defines three service models, including Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). Saas is the capability to use the provider’s applications running on a cloud infrastructure, where the applications are accessible from various client devices through a thin client interface such as a web browser (e.g., web-based email). Platform as a Service (PaaS) refers to the capability to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider. Cloud Infrastructure as a Service (IaaS) allows the capability to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components (e.g., host firewalls).\nIn the IT world, cloud computing is here today, and most experts predict significant expansion. Gartner is projecting rapid growth in public cloud services worldwide, with revenue growing from $68.3 billion in 2010 to $102.1 billion by 2012 and $180 billion by 2015. Somewhat more conservatively, IDC predicts that public cloud IT spending will grow from $21.5 billion in 2010 to $72.9 billion in 2015. While Gartner focuses on revenue, which allows for the inclusion of new business model growth, both firms expect the cloud market to grow at more than five times the rate of traditional IT products.\nBut is AV going to the cloud? It depends on whom you ask. Many would say that it already has. Any time you access music, video or other AV content that’s hosted on a server that you don’t own, that’s cloud AV access. Cloud AV is already well entrenched in the consumer AV world. Do you use Netflix? That’s cloud-based AV access. So is YouTube.\nApple’s iCloud allows users to stream images and other types of media to other devices, primarily manufactured from Apple. And Amazon’s Cloud Player is all about storage and streaming of music—all you do is “reserve” as much cloud storage as you need.\nBut what about cloud-based AV control for out-of-the-home applications? If the current trend of consumer technologies migrating to commercial applications continues, it’s probably already on its way.\n“Today, I can control devices in my home today over the cloud, using my iPhone or iPad,” says Dave Sobel, CEO of Fairfax, Va.-based Evolve Technologies. “As commercial AV moves closer to the IT model, it’s only logical that this type of control will extend to AV systems in the workplace.” Sobel cites figures from CompTIA, which projects that 20 percent of businesses will have fully cloud-based IT services by the end of 2012. It’s no big stretch to envision that commercial AV devices and systems—already considered part of the IT infrastructure—aren’t far behind.\nNot everyone agrees with Sobel’s assessment, including Steve Greenblatt, president of independent programming firm Control Concepts. “At this point, I think it’s pretty far off,” he says. “A lot of people had been thinking, for years, that you wouldn’t need anything more than a computer in a room to control an AV system, but AV systems have really gotten a lot more complicated than that. I think cloud-based control would be some time in the future.”\nOne of the problems with the idea of cloud-based AV control is that, for many AV devices, you still need a dedicated control processor to perform basic functions, like projector on/off, audio system volume levels, or camera pan/tilt/zoom. Serial commands delivered by IR or RS-232 and simple contact closure signal is still the most common way to control many AV products. But most control processors today are software-configurable, so it’s logical that as these devices become more like IT appliances, the software that drives control functions could be accessed via the cloud.\nAMX has announced a cloud-based systems configuration tool that allows AV technicians or IT professionals to easily configure an AMX system by using a step-by-step, wizard-based approach. Rapid Project Maker (RPM) is stored on AMX servers, so users never have to worry about “who owns the code” or what happens if an on-premise system should fail. It’s always there, “in the cloud”; no additional software is required. Once configuration of an AV control system is complete, the code is downloaded to the on-premise controller, and it’s ready to go. But just as configuration moves to the cloud, is it feasible that the control processor itself could disappear as an on-premises piece of hardware, and become a cloud-based IaaS function?\nAcceptable Use Policy blog comments powered by Disqus", "label": 1}
{"text": "(1) (Solid State Lighting) See LED lighting.|\n(2) (Secure Sockets Layer) The leading security protocol on the Internet. Developed by Netscape, SSL is widely used to do two things: to validate the identity of a Web site and to create an encrypted connection for sending credit card and other personal data. Look for a lock icon at the top or bottom of your browser when you order merchandise on the Web. If the lock is closed, you are on a secure SSL or TLS connection (see TLS).\nHTTPS and Port Number 443\nAn SSL session is started by sending a request to the Web server with an HTTPS prefix in the URL, which causes port number 443 to be placed into the packets. Port 443 is the number assigned to the SSL application on the server (see well-known port).\nAfter the two sides acknowledge each other, the browser sends the server a list of algorithms it supports, and the server responds with its choice and a signed digital certificate. From an internal list of certificate authorities (CAs) and their public keys, the browser uses the appropriate public key to validate the signed certificate. Both sides also send each other random numbers. For more details on certificates, see digital certificate.\nData for Secret Keys Is Passed\nThe browser extracts the public key of the Web site from the server's certificate and uses it to encrypt a pre-master key and send it to the server. At each end, the client and server independently use the pre-master key and random numbers passed earlier to generate the secret keys used to encrypt and decrypt the rest of the session. See TLS, server-gated cryptography, security protocol and public key cryptography.\nThese steps take place to negotiate an SSL session before any user data are transmitted. Steps 5 and 6 verify the integrity of the handshake, ensuring that nobody tampered with any messages. These checksums are called \"message authentication codes\" (see", "label": 1}
{"text": "Cloud computing is a growing trend in information technology as organizations look for ways to save money and add flexibility to their operations. Cloud computing, while still an evolving service, provides on-demand network access to a shared pool of computing resources such as networks, servers, storage and applications. The pooling of resources allows the provider to rapidly scale to meet changing customer demands. The service is typically provided through a large data center. Cloud computing can be divided into three types: Software as Service, Platform as Service, and Infrastructure as Service.\n- Software as a Service (SaaS): Provides ready for use web-based applications such as email that are maintained centrally by a provider (e.g., Gmail, Salesforce.com).\n- Platform as a Service (PaaS): Provides programming languages and tools that can be used by application developers to create and deploy applications on the web.\n- Infrastructure as a Service (IaaS): Provides computing resources, such as virtualized servers and storage, whose usage is rented from a provider (e.g., Amazon EC2, Windows Azure).\nIn addition, cloud computing can be private, available for a single organization/group of users, open to the public, or some combination of these models.1\nThe growth in cloud computing is fueled by economies of scale. Cloud computing allows users to pay for what they need, when they need it.\nThere are security and privacy concerns that must be considered before moving to cloud computing, including the following:\n- Vendor Security: Cloud computing customers rely on providers to implement appropriate security measures to protect the confidentiality, integrity, and availability of data. Be wary of providers who are reluctant to share details of their security architecture/practices with customers.\n- Isolation/Segregation: Users access cloud computing resources via a virtual machine hosted on an unknown physical machine2. The physical machine may be shared with other users. Providers must ensure that multiple customers do not interfere with each other, maliciously or unintentionally.\n- Data Location: Providers may have data centers located in other countries. Be sure your vendor contract stipulates any restrictions you may have on the physical location of where your data is stored.\n- Management Interface: Customers access the cloud management interface via the Internet, thus increasing exposure to potential attack.\n- Reputation Sharing: Bad behavior by one cloud customer may impact others using the cloud. For example a customer engaging in spamming may cause a common cloud IP address to be blacklisted.\n- Provider Viability: What happens to your organization’s applications and data in the event that the provider goes out of business?\n- Compliance: Placement of data in the cloud does not eliminate an organization’s need to meet legal and regulatory requirements such as PCI or HIPAA. Organizations will need timely assistance from cloud computing providers to fulfill investigation/audit requirements.\nOrganizations should fully research the risks and benefits of cloud computing before moving to that environment. It is critical that security requirements are addressed in contractual agreements in advance. In addition, there are steps organizations should take when using cloud computing:\n- Data Classification: Consider the sensitivity of your data before making a decision of whether or not to put it in the cloud.\n- Encryption: Encrypt sensitive data before placing it in the cloud.\n- Authentication: Consider requiring multifactor authentication for access to cloud computing resources.\n- Vulnerability Assessment: Include a requirement for a security review or vulnerability assessment as part of the service level agreement with the provider.\n- Monitor: Require close monitoring of cloud computing resources by providers for unauthorized activity.\n- Backup: Ensure that your backup data is not comingled with other customers.\n- Notification: Require providers to provide timely notification of any potential data security breach.", "label": 1}
{"text": "Using a new grid computing system, radiologists, physicians and pediatric oncologists at 40 hospitals all over North America are now quickly and securely exchanging high-resolution medical images.\nOne hoped-for result will be that the doctors of young cancer patients will know more quickly whose treatment is not working and be able to change course. Others include making second opinions from specialists anywhere easily available; and quicker, closer monitoring of ongoing clinical research and diagnostic practice.\n\"We have broken the medical image communication barrier,\" says Stephan Erberich, a computer scientist who is the Director of Functional Imaging and Biomedical Informatics at Childrens Hospital Los Angeles and a faculty member of both the USC Keck School of Medicine and the USC Viterbi School of Engineering.\nHe will demonstrate the Globus MEDICUS system at the upcoming annual meeting of the Radiological Society of North America (RSNA) in Chicago every day from Sunday Nov. 26 through Thursday Nov. 30.\nThe Globus MEDICUS project makes pediatric cancer researchers and the medical imaging profession at large the latest in the rapidly growing number of scientific and professional communities using Globus open-source grid collaboration software developed at the USC Viterbi School of Engineering's Information Sciences Institute (ISI) and Argonne National Laboratories (ANL).\nCarl Kesselman and Ann Chevernak of ISI, who worked with Erberich in creating MEDICUS, built the system basing themselves directly upon earlier work by the Digital Imaging and Communication In Media (DICOM) standards committee.\nDICOM created a uniform electronic format for medical images, one that allow the whole range of commercial imaging devices -- X-ray, MRI, and CT -- to display and manage images from any other.\nBut DICOM's potential for transparent exchange between collaborating researchers, and physicians has so far not been realized, because of technological, administrative, and security challenges of confidential patient data, according to Erberich.\nAs a result, access to the interchangeable data was limited to the hospital where the images are acquired -- not even available to a patient's point-of-care facility, if different, unless physically carried there.\n\"Today if you leave the hospital, you either leave your digitized images behind or you have to carry them on a CDROM,\" said Erberich. \"This is not the 21st century healthcare we need in a networked society. All kinds of other fields, from banking to air travel now rely on instant information exchange and decision making online. We should be able expect the same level of sophistication in healthcare.\"\nThat day has now arrived, says the scientist. Using the DICOM Grid Interface Service (DGIS) DICOM records at medical facility anywhere are now easily accessible and exchangeable over Grid-secured Internet connections.\nThe MEDICUS project began when Erberich approached ISI grid experts Kesselman and Chervenak asking them \"to translate DICOM into Grid,\" as Erberich described it.\nKesselman had, as part of the Globus project previously helped more than a dozen scientific communities ranging from high-energy physicists to earthquake simulating engineers and geologists share instruments and data, securely and easily.\nHe immediately saw that the need was a perfect fit for Globus open-source Grid solution. \"There had to be new code developed to handle the medical-specific things like DICOM translation and patient confidentiality assurance,\" Kesselman said, \"but the cool thing is this leverages all of the existing underlying Globus technology that we use in so many other projects.\"\nIn creating key grid components for MEDICUS, ISI research scientist Chervenak and Kesselman, who is director of the center for grid technologies at ISI and a research associate professor of computer science in the USC Viterbi School of Engineering worked with Manasee Bhandekar, a computer engineer at the USC Alfred E. Mann Institute. ISI researchers Robert Schuler, Shishir Bharathi and Gaurang Mehta also made significant contributions.\nErberich developed the DICOM to Grid interface and led the inter-disciplinary collaboration between the engineering and clinical teams, working with Childrens Hospital radiologist-in-chief and Chairman Marvin D. Nelson.\nThe system has been in place since September, and as Nelson describes it, \"it's totally transparent. Each facility is now connected to the Grid, using its own interface -- you only have to one interface at the hospital, and that serves the whole hospital, reusing the hospital's capital investment in DICOM visualization devices.\"\nThe cost of installing a DGIS node is \"trivial,\" said Erberich: on the order of $1000 for a Grid gateway, attached to a high-bandwidth net connection. The gateway provides two-way access to the Grid, allowing upload of local images (after de-identification) and also continuing access to a catalog of archived DICOM records. \"The nice thing, \" said Nelson, \"if a researcher has authorization for a specific record in the catalog, it can be downloaded for use on her own image display.\"\nOne dramatic change in practice will be the ease of review. Researchers can look at observations made anywhere on the grid without leaving their offices.\n\"We store the images here in the Data Center, \" said Erberich, \"but the people who have been assigned to review images, can review them from virtually anywhere.\"\n\"Before\" he continued \"when we were documenting a research study, it meant that radiologists would have to physically come to a single facility and look through a file cabinet full of physical images. Now, radiologists all over the planet can look at the images at their leisure in their own offices, on their own favorite commercial medical imaging system.\"\nOne critical advantage of this is elimination of backlogs reviewing images, with potentially life-saving results for patients in studies. \"We'll probably have a more timely review of scans,\" said Robert C. Seeger, M.D., of the Saban Research Institute of Childrens Hospital Los Angeles, a specialist in neuroblastoma who is part of one of the research groups now using the system.\nBesides the 13-institution New Approaches in Neuroblastoma Therapy group (NANT.org) that Seeger is part of, the 27-member Children's Oncology Group (CURESEARCH.org) is now active.\nBoth the doctors and the computer scientists involved expect this number to skyrocket in coming years, because the entry cost is so low and the possibilities are only beginning to be tapped. Other advantages include:\nGreatly increased ease of radiological consultation and study. Any radiologist practicing on rare or unusual conditions can now see only see the small fraction of the total cases that present in one place. Now, \"he could sit in Boston and potentially review every single case, from anywhere in the country,\" says Seeger.\nImaging research. Scientists studying new techniques will be able to exchange samples instantly. And \"we can develop expertise not just for reading, but also processing images,\" said Erberich.\nDrug development. New techniques depend on imaging experimental animals, typically mice, using bioluminescent markers. Analysis of large bodies of such images requires great computing power. Grid techniques can both share images and the computing power necessary to extract their meaning.\nThe Globus Alliance is a community of organizations and individuals developing fundamental technologies behind the \"Grid,\" which lets people share computing power, databases, instruments, and other on-line tools securely across corporate, institutional, and geographic boundaries without sacrificing local autonomy.\nGrid computing work has been named one of \"Ten Technologies that Will Change the World\" by M.I.T. Technology Review, and has received a \"Top 100\" award as well as a \"Most Promising New Technology\" honor from R&D Magazine.\nThe Globus MEDICUS project was supported by the Children's Oncology Group Phase-I Consortium, NIH (grant UO1-BA97452), and the NANT Cancer Foundation.\nAAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert! system.", "label": 1}
{"text": "Sandia computer scientists successfully boot one million Linux kernels as virtual machines\nLIVERMORE, Calif. - Computer scientists at Sandia National Laboratories in Livermore, Calif., have for the first time successfully demonstrated the ability to run more than a million Linux kernels as virtual machines.\n(Media-Newswire.com) - LIVERMORE, Calif. — Computer scientists at Sandia National Laboratories in Livermore, Calif., have for the first time successfully demonstrated the ability to run more than a million Linux kernels as virtual machines.\nThe achievement will allow cyber security researchers to more effectively observe behavior found in malicious botnets, or networks of infected machines that can operate on the scale of a million nodes. Botnets, said Sandia’s Ron Minnich, are often difficult to analyze since they are geographically spread all over the world.\nSandia scientists used virtual machine ( VM ) technology and the power of its Thunderbird supercomputing cluster for the demonstration.\nRunning a high volume of VMs on one supercomputer — at a similar scale as a botnet — would allow cyber researchers to watch how botnets work and explore ways to stop them in their tracks. “We can get control at a level we never had before,” said Minnich.\nPreviously, Minnich said, researchers had only been able to run up to 20,000 kernels concurrently ( a “kernel” is the central component of most computer operating systems ). The more kernels that can be run at once, he said, the more effective cyber security professionals can be in combating the global botnet problem. “Eventually, we would like to be able to emulate the computer network of a small nation, or even one as large as the United States, in order to ‘virtualize’ and monitor a cyber attack,” he said.\nA related use for millions to tens of millions of operating systems, Sandia’s researchers suggest, is to construct high-fidelity models of parts of the Internet.\n“The sheer size of the Internet makes it very difficult to understand in even a limited way,” said Minnich. “Many phenomena occurring on the Internet are poorly understood, because we lack the ability to model it adequately. By running actual operating system instances to represent nodes on the Internet, we will be able not just to simulate the functioning of the Internet at the network level, but to emulate Internet functionality.”\nA virtual machine, originally defined by researchers Gerald J. Popek and Robert P. Goldberg as “an efficient, isolated duplicate of a real machine,” is essentially a set of software programs running on one computer that, collectively, acts like a separate, complete unit. “You fire it up and it looks like a full computer,” said Sandia’s Don Rudish. Within the virtual machine, one can then start up an operating system kernel, so “at some point you have this little world inside the virtual machine that looks just like a full machine, running a full operating system, browsers and other software, but it’s all contained within the real machine.”\nThe Sandia research, two years in the making, was funded by the Department of Energy’s Office of Science, the National Nuclear Security Administration’s ( NNSA ) Advanced Simulation and Computing ( ASC ) program and by internal Sandia funding.\nTo complete the project, Sandia utilized its Albuquerque-based 4,480-node Dell high-performance computer cluster, known as Thunderbird. To arrive at the one million Linux kernel figure, Sandia’s researchers ran one kernel in each of 250 VMs and coupled those with the 4,480 physical machines on Thunderbird. Dell and IBM both made key technical contributions to the experiments, as did a team at Sandia’s Albuquerque site that maintains Thunderbird and prepared it for the project.\nThe capability to run a high number of operating system instances inside of virtual machines on a high performance computing ( HPC ) cluster can also be used to model even larger HPC machines with millions to tens of millions of nodes that will be developed in the future, said Minnich. The successful Sandia demonstration, he asserts, means that development of operating systems, configuration and management tools, and even software for scientific computation can begin now before the hardware technology to build such machines is mature.\n“Development of this software will take years, and the scientific community cannot afford to wait to begin the process until the hardware is ready,” said Minnich. “Urgent problems such as modeling climate change, developing new medicines, and research into more efficient production of energy demand ever-increasing computational resources. Furthermore, virtualization will play an increasingly important role in the deployment of large-scale systems, enabling multiple operating systems on a single platform and application-specific operating systems.”\nSandia’s researchers plan to take their newfound capability to the next level.\n“It has been estimated that we will need 100 million CPUs ( central processing units ) by 2018 in order to build a computer that will run at the speeds we want,” said Minnich. “This approach we’ve demonstrated is a good way to get us started on finding ways to program a machine with that many CPUs.” Continued research, he said, will help computer scientists to come up with ways to manage and control such vast quantities, “so that when we have a computer with 100 million CPUs we can actually use it.”\nSandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin company, for the U.S. Department of Energy’s National Nuclear Security Administration. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major R&D responsibilities in national security, energy and environmental technologies, and economic competitiveness.\nSandia news media contact: Mike Janes, email@example.com ( 925 ) 294-2447\nThis story was released on 2009-08-03. Please make sure to visit the official company or organization web site to learn more about the original release date. See our disclaimer for additional information.", "label": 1}
{"text": "The Distributed Checksum Clearinghouses or DCC is an anti-spam content filter that runs on a variety of operating systems. The counts can be used by SMTP servers and mail user agents to detect and reject or filter spam or unsolicited bulk mail. DCC servers exchange or \"flood\" common checksums. The checksums include values that are constant across common variations in bulk messages, including \"personalizations.\"\nThere are graphs of recently detected spam. Those graphs suggest the effectiveness of the system. For example, if you assume that 80% of all mail is spam and those graphs indicate that DCC finds 70% of mail is spam, then DCC detects 88% of spam.\nclick for more graphs\nThe idea of DCC is that if mail recipients could compare the mail they receive, they could recognize unsolicited bulk mail. A DCC server totals reports of checksums of messages from clients and answers queries about the total counts for checksums of mail messages. A DCC client reports the checksums for a mail message to a server and is told the total number of recipients of mail with each checksum. If one of the totals is higher than a threshold set by the client and according to local whitelists the message is unsolicited, the DCC client can log, discard, or reject the message.\nBecause simplistic checksums of spam would not be effective, the main DCC checksums are fuzzy and ignore aspects of messages. The fuzzy checksums are changed as spam evolves. Since DCC started being used in late 2000, the fuzzy checksums have been modified several times.\nUnless used with isolated DCC servers and so losing much of its power, DCC causes some additional network traffic. However, the client-server interaction for a mail message consists of exchanging a single pair of UDP/IP datagrams of about 150 bytes. That is often less than the several pairs of UDP/IP datagrams required for a single DNS query. SMTP servers make DNS queries to check the envelope Mail_From value and often several more. As with the Domain Name System, DCC servers should be placed near active clients to reduce DCC network costs. DCC servers exchange or flood reports of checksums, but only the checksums of bulk mail.\nDo not send comments or questions about your \"DCC listing\" to any address at Rhyolite Software unless an SMTP server operated by by Rhyolite Software LLC rejected your mail. Contact instead the operators of the system that rejected your mail.\nDCC does not \"list\" domain names or IP addresses, but detects bulk mail messages. Domain names, IP addresses, and so forth are \"listed\" independently. by DCC users. If DCC users want to receive your bulk mail, they must whitelist it by adding your IP address, SMTP envelope sender, RFC 2369 SMTP List-* headers, or other characteristics of your mail to their whiteclnt files. Do not send \"please remove my address\" requests unless you want your domain name, mailbox, or IP address added to a blacklist.\nA separate facility called DCC Reputations supported by the commercial verson of the DCC software does automatically compute the reputations for sending bulk mail. However, it makes no sense to ask for IP addresses to be removed from the distributed DCC Reputation database. A reputation for sending lots of bulk mail expires automatically a week to 30 days after the last bulk email reported by a DCC Reputation client mail system.\nSpam is unsolicited bulk mail, and only mail targets can say whether a message is solicited. A virtue of DCC and DCC Reputations spam filtering is that mail targets decide whether they have subscribed to bulk mail or want to hear from senders with DCC Reputations for sending bulk mail. The opinions of bulk mail senders about whether their messages are spam are irrelevant.\nThe current version of the DCC source is version 1.3.145, May 16, 2013. It is available at dcc-servers.net and Rhyolite Software. It is usually best to update an existing installation with the /var/dcc/libexec/updatedcc script. Some previous versions are available.\nThe variations of version 1.2.74 redistributed by some organizations is very old; it dates from May, 2005. Many problems have been fixed and improvements made since that version was released. Some of the problems in that old version cause problems for the public DCC servers. DCC clients of that version and older can be expected to stop working with the public DCC servers in coming months when the version of the DCC client-server protocol that they use is finally disabled on the public DCC servers.\nThe non-commercial DCC software is distributed under a license that is free only to organizations that do not sell filtering devices or services except to their own users and that participate in the global DCC network. ISPs that use DCC to filter mail for their own users are intended to be covered by the free license. You can redistribute unchanged copies of the free source, but you may not redistribute modified, \"fixed,\" or \"improved\" versions of the source or binaries. You also can't call it your own or blame anyone for the results of using it.\nOrganizations that do not qualify for the free license are welcome to inquire about licensing the commercial version of the DCC software by email to firstname.lastname@example.org or via the form. The commercial DCC version supports DCC Reputations.\nPlease note that contrary to obsolete web pages you might find with search engines, Rhyolite Software is currently the exclusive source of commercial DCC software. No other organizations can sell or market DCC software except as part of their own products.\nSelling the bandwidth and, most important, human system administration work of the public DCC servers to third parties has always been wrong. Sellers of products, \"appliances,\" or managed mail services must contract for or provide their own DCC servers, as well as obtain a commercial license for the DCC software.\nIncorrectly configured firewalls are the a common causes of problems of DCC client using the public DCC servers. Your firewalls must allow responses to requests from dccproc or dccifd on your system to come from UDP port 6277 at the public servers.\nAnother common cause of DCC client problems is the use of ancient versions redistributed by some organizations including Linux packagers. Those versions can try so hard to get answers that they triggers the denial-of-service (DoS) defenses in the public DCC servers. See a discussion of problems associated with old versions of the DCC software.\nExcessive requests are a third common cause. The public DCC servers have various defenses against DoS attacks including rate limiting or delaying responses based on the maximum of the requests made today and a recent daily average. When the delays would reach 4 seconds, the public servers completely ignore additional requests. If your mail system processes more than 100,000 messages per day, you should use your own, probably private DCC server connected to the global network of DCC servers.\nIf the public DCC servers not working for you, your firewalls allow UDP port 6277, and you are not sending an excessive number of requests, then the cause might be excessive or objectionable DCC operations that have been received from your network. See the blacklist of DCC clients used by the public DCC servers.\nEach of the several parts of DCC have its own man page including:\nThere are also\nThe code seems to be compatible with flavors of UNIX-like systems. See the list of systems in the installation instructions. The long range plan is to port the DCC client code widely, including to common personal computer operating systems.\nA useful anti-spam scheme is more than just code, and that is particularly true of the Distributed Checksum Clearinghouses, DCC, which are based sharing information about bulk mail If you do not run your own DCC server, you need to point your DCC client to someone else's server. The DCC client code does the right thing when it cannot contact any of the servers it knows about; it quickly passes the mail without worrying about its bulkiness. Given more than one server, the DCC client code uses the fastest or closest.\nWhen using someone else's server, you must either contact them for a DCC client-ID and corresponding password.\nPublic DCC servers for anonymous DCC clients handling fewer than 100,000 mail messages per day are provided by people and organizations in the following list. The default contents of /var/dcc/map file point to these servers.\n|DelMarVa OnLine||Sven Willenberger|\n|INFN (National Institute for Nuclear Physics) - Bari||Domenico Diacono|\n|INFN (National Institute for Nuclear Physics) - Turin||Alberto D'Ambrosio|\n|INAF IASF (National Institute for Astrophysics)-Palermo-Italy||Giacomo Fazio|\n|Peregrine Computer Consultants Corporation||Kevin A. McGrail|\n|Quonix Networks||John Von Essen|\n|Sonic,net, Inc.||Kelsey Cummings|\n|Tilastokeskus - Statistikcentralen||--|\n|Universitšt Trier||Horst Scheuermann|\n|Vienna University of Economics and Business Administration||Franz Schaefer|\nThe IP addresses of the public DCC servers define the DNS names dcc1.dcc-servers.net, dcc2.dcc-servers.net, dcc3.dcc-servers.net, dcc4.dcc-servers.net, and dcc5.dcc-servers.net. Use them by adding those names to your /var/dcc/map file with cdcc \"add dcc1.dcc-servers.net\" and so forth. The names are automatically installed when the DCC programs are installed with the ./configure script and Makefile in the source. See the installation instructions.\nNote well that it has been wrong to take and resell the bandwidth and, most important, human system administration work of the public DCC servers to third parties. Blunt words for that include theft and stealing. Vendors of \"spam appliances\" or services including DCC such as \"managed email\" must provide DCC servers of their own or contract for DCC services from others. They must also buy a license for the commercial version of the DCC software.\nThe effectiveness of DCC filtering increases with checksums \"flooded\" or exchanged with other DCC servers. The spam filtering results of violating the free license by not connecting a local, private server to the global network of DCC servers may be disappointing.\nMail systems that handle more than 100,000 mail messages per day should have a local DCC server so that processing incoming mail is not delayed by the time required for the UDP packets used by the DCC client protocol to cross the Internet. Organizations that deal with more than 500,000 mail messages per day benefit from two or more local DCC servers to ensure that at least one local DCC server is available despite system maintenance. Organizations that deal with fewer than 100,000 mail messages per day use less bandwidth of their own and of the servers in the global network by using the public servers.\nThe first step in configuring a DCC server to flood checksums is agreeing on the server-IDs of all participating servers. There is a private list of the DCC servers, server-IDs and so forth in the global network of DCC servers at //www.rhyolite.com/dcc/private/. It is readable only by server operators. Contact Vernon Schryver at email@example.com for server-IDs. Subscriptions to the DCC-servers mailing list are available only to operators of servers in the global network.\nThe DCC source includes a script named /var/dcc/libexec/fetch-testmsg-whitelist intended to be invoked by cron to periodically fetch new copies.\nThere are also mailing lists for DCC server operators and public DCC server operators, but they are closed except to operators.\nThe DCC FAQ also answers questions about the resources needed by a DCC server.\nTechnical questions or comments can be sent to Rhyolite Software. More extensive assistance can also be hired from Rhyolite Software.\nDCC Reputations are a distinct mechanism based on and contributing to DCC data. In part to minimize abuse by anonymous users, DCC Reputations are available only in the commercial version of the DCC software.\nDCC is based on an idea of Paul Vixie and on fuzzy body matching to reject spam on a corporate firewall operated by Vernon Schryver starting in 1997. The DCC software was designed and written at Rhyolite Software starting in 2000. It has been used in production since the winter of 2000/2001.\nContact Vernon Schryver at firstname.lastname@example.org or use the form.", "label": 1}
{"text": "Click on any phrase to play the video at that point.Close\nThe idea behind the Stuxnet computer worm is actually quite simple. We don't want Iran to get the bomb. Their major asset for developing nuclear weapons is the Natanz uranium enrichment facility. The gray boxes that you see, these are real-time control systems. Now if we manage to compromise these systems that control drive speeds and valves, we can actually cause a lot of problems with the centrifuge. The gray boxes don't run Windows software; they are a completely different technology. But if we manage to place a good Windows virus on a notebook that is used by a maintenance engineer to configure this gray box, then we are in business. And this is the plot behind Stuxnet.\nSo we start with a Windows dropper. The payload goes onto the gray box, damages the centrifuge, and the Iranian nuclear program is delayed -- mission accomplished. That's easy, huh? I want to tell you how we found that out. When we started our research on Stuxnet six months ago, it was completely unknown what the purpose of this thing was. The only thing that was known is it's very, very complex on the Windows part, the dropper part, used multiple zero-day vulnerabilities. And it seemed to want to do something with these gray boxes, these real-time control systems. So that got our attention, and we started a lab project where we infected our environment with Stuxnet and checked this thing out. And then some very funny things happened. Stuxnet behaved like a lab rat that didn't like our cheese -- sniffed, but didn't want to eat. Didn't make sense to me. And after we experimented with different flavors of cheese, I realized, well, this is a directed attack. It's completely directed. The dropper is prowling actively on the gray box if a specific configuration is found, and even if the actual program code that it's trying to infect is actually running on that target. And if not, Stuxnet does nothing.\nSo that really got my attention, and we started to work on this nearly around the clock, because I thought, \"Well, we don't know what the target is. It could be, let's say for example, a U.S. power plant, or a chemical plant in Germany. So we better find out what the target is soon.\" So we extracted and decompiled the attack code, and we discovered that it's structured in two digital bombs -- a smaller one and a bigger one. And we also saw that they are very professionally engineered by people who obviously had all insider information. They knew all the bits and bites that they had to attack. They probably even know the shoe size of the operator. So they know everything.\nAnd if you have heard that the dropper of Stuxnet is complex and high-tech, let me tell you this: the payload is rocket science. It's way above everything that we have ever seen before. Here you see a sample of this actual attack code. We are talking about -- around about 15,000 lines of code. Looks pretty much like old-style assembly language. And I want to tell you how we were able to make sense out of this code. So what we were looking for is, first of all, system function calls, because we know what they do.\nAnd then we were looking for timers and data structures and trying to relate them to the real world -- to potential real world targets. So we do need target theories that we can prove or disprove. In order to get target theories, we remember that it's definitely hardcore sabotage, it must be a high-value target and it is most likely located in Iran, because that's where most of the infections had been reported. Now you don't find several thousand targets in that area. It basically boils down to the Bushehr nuclear power plant and to the Natanz fuel enrichment plant.\nSo I told my assistant, \"Get me a list of all centrifuge and power plant experts from our client base.\" And I phoned them up and picked their brain in an effort to match their expertise with what we found in code and data. And that worked pretty well. So we were able to associate the small digital warhead with the rotor control. The rotor is that moving part within the centrifuge, that black object that you see. And if you manipulate the speed of this rotor, you are actually able to crack the rotor and eventually even have the centrifuge explode. What we also saw is that the goal of the attack was really to do it slowly and creepy -- obviously in an effort to drive maintenance engineers crazy, that they would not be able to figure this out quickly.\nThe big digital warhead -- we had a shot at this by looking very closely at data and data structures. So for example, the number 164 really stands out in that code; you can't overlook it. I started to research scientific literature on how these centrifuges are actually built in Natanz and found they are structured in what is called a cascade, and each cascade holds 164 centrifuges. So that made sense, that was a match.\nAnd it even got better. These centrifuges in Iran are subdivided into 15, what is called, stages. And guess what we found in the attack code? An almost identical structure. So again, that was a real good match. And this gave us very high confidence for what we were looking at. Now don't get me wrong here, it didn't go like this. These results have been obtained over several weeks of really hard labor. And we often went into just a dead end and had to recover.\nAnyway, so we figured out that both digital warheads were actually aiming at one and the same target, but from different angles. The small warhead is taking one cascade, and spinning up the rotors and slowing them down, and the big warhead is talking to six cascades and manipulating valves. So in all, we are very confident that we have actually determined what the target is. It is Natanz, and it is only Natanz. So we don't have to worry that other targets might be hit by Stuxnet.\nHere's some very cool stuff that we saw -- really knocked my socks off. Down there is the gray box, and on the top you see the centrifuges. Now what this thing does is it intercepts the input values from sensors -- so for example, from pressure sensors and vibration sensors -- and it provides legitimate program code, which is still running during the attack, with fake input data. And as a matter of fact, this fake input data is actually prerecorded by Stuxnet. So it's just like from the Hollywood movies where during the heist, the observation camera is fed with prerecorded video. That's cool, huh?\nThe idea here is obviously not only to fool the operators in the control room. It actually is much more dangerous and aggressive. The idea is to circumvent a digital safety system. We need digital safety systems where a human operator could not act quick enough. So for example, in a power plant, when your big steam turbine gets too over speed, you must open relief valves within a millisecond. Obviously, this cannot be done by a human operator. So this is where we need digital safety systems. And when they are compromised, then real bad things can happen. Your plant can blow up. And neither your operators nor your safety system will notice it. That's scary.\nBut it gets worse. And this is very important, what I'm going to say. Think about this: this attack is generic. It doesn't have anything to do, in specifics, with centrifuges, with uranium enrichment. So it would work as well, for example, in a power plant or in an automobile factory. It is generic. And you don't have -- as an attacker -- you don't have to deliver this payload by a USB stick, as we saw it in the case of Stuxnet. You could also use conventional worm technology for spreading. Just spread it as wide as possible. And if you do that, what you end up with is a cyber weapon of mass destruction. That's the consequence that we have to face. So unfortunately, the biggest number of targets for such attacks are not in the Middle East. They're in the United States and Europe and in Japan. So all of the green areas, these are your target-rich environments. We have to face the consequences, and we better start to prepare right now.\nRalph Langner: Okay, you really want to hear that? Yeah. Okay. My opinion is that the Mossad is involved, but that the leading force is not Israel. So the leading force behind that is the cyber superpower. There is only one, and that's the United States -- fortunately, fortunately. Because otherwise, our problems would even be bigger.\nYou can share this video by copying this HTML to your clipboard and pasting into your blog or web page.\nneed to get the latest Flash player.\nGot an idea, question, or debate inspired by this talk? Start a TED Conversation.\nWhen first discovered in 2010, the Stuxnet computer worm posed a baffling puzzle. Beyond its sophistication loomed a more troubling mystery: its purpose. Ralph Langner and team helped crack the code that revealed this digital warhead's final target. In a fascinating look inside cyber-forensics, he explains how -- and makes a bold (and, it turns out, correct) guess at its shocking origins.\nRalph Langner is a German control system security consultant. He has received worldwide recognition for his analysis of the Stuxnet malware. Full bio »", "label": 1}
{"text": "Ten students, working for ABC News, visited nuclear reactors on 25 college campuses and found many gaping security holes at many of them, prompting a federal investigation. Here's what the team found at MIT.\nReactor Name: MIT Nuclear Reactor Laboratory\nFuel: Highly-enriched uranium, possession limit 40 kg.\nPower Level: 5 MW\nBegan Operating: 1958\nLocation: In a highly populated area just off Massachusetts Avenue, the heavily traveled main artery that runs through Cambridge. The dense area includes campus buildings, pharmaceutical laboratories, shops and restaurants.\nSecurity Obervations: Two armed guards. No metal detectors. No searches. Tour available with advance request and interview. Multiple forms of identification requested and photocopied before tour. Backpacks allowed inside the complex, though not inside the reactor building. Wallets permitted on reactor tour.\nWhat We Found: Detailed information (including labeled diagrams and photographs of the reactor core and its full operation schedule) was easily located on the Internet. Even more information was available using campus computer terminals available to the public at the MIT library, where the Fellows found detailed floor plans of the reactor.\nThe Fellows scheduled a tour by e-mail and, after a brief interview with a few staff members, toured the reactor.\nAn ABC News producer parked a large Ryder truck next to the reactor facility and was not questioned or challenged.\nUniversity Reaction: In a written statement, Denise Brehm, senior communications officer, said given the small size of the reactor facility, it is not a likely target for terrorism.\nBrehm said an independent study assessing the impact of possible terrorist acts against the reactor concluded that in all likely scenarios the core of the reactor would not be breached and radiation would not be released. According to Brehm, the study also determined that a large truck bomb within even a few feet of the reactor building would not breach the containment of the reactor's core. The core is fully enclosed in a radiation-shielded structure consisting of several feet of concrete and other materials, which itself is housed within the containment building, \"all of which would impossible to breach at one time,\" Brehm said.\nTours are by appointment only and names, addresses and identification are run through a security review prior to the tour, Brehm said, adding that visitors are not allowed to bring bags or cameras into the reactor building, but must leave them in the administrative offices.\n\"MIT moved its reactor floor plans and exterior diagrams from its Web site following the 9/11 terrorist attacks,\" according to Brehm. Posting of the operating schedule does not pose a security threat because it does not indicate \"when MIT is conducting sensitive operations, such as a refueling.\"\n\"Fresh fuel is not stored in the facility and is never present in large enough quantities to create a nuclear weapon,\" Brehm said.\nAdditional Comment: The federal official responsible for security at the nation's campus reactors told ABC News that he was not happy to see the wide availability of detailed information on the Internet. \"That's something I'd want us to pursue, and we will,\" said Roy Zimmerman, director of the Office of Nuclear Security and Incident Response for the Nuclear Regulatory Commission.", "label": 1}
{"text": "As defenses against network DDOS attacks improve, hackers find a new target\nPart of GCN's series on DOS attacks.\nDenial of service attacks, which traditionally have bombarded networks with an overwhelming number of requests, are getting more efficient. And as these attacks mature, it's more important than ever that agencies understand the kind of attack they're facing so they can mount an effective defense.\nDenial of service is a descriptive term rather than a technical one: It describes the goal of the attack rather than the tools or techniques used. Although there are a variety of ways to carry out the attacks, they fall into two broad categories -- network and application.\nNetwork DOS attacks can be fairly simple brute-force affairs, flooding servers with high volumes of requests or packets to overwhelm the resources. In general, the way to counter them is to maintain enough bandwidth and computing power to withstand the flood, but this might be impractical in a well-orchestrated attack that can generate hundreds or thousands of times the agency's usual traffic levels. Or agencies can identify the malicious packets and block them before they hit their servers, which is best done as close to the source of the attack as possible.\nTo date, network DOS attacks probably remain the most common, but as defenses against them improve, \"we are seeing more attacks move up the stack to Layer 7 application attacks,\" said Rob Rachwald, directory of security strategy at Imperva. Application attacks do not rely on a flood of packets, but use specially formed — or malformed — queries and requests that servers have to deal with slowly until the number of available connections or the processing capacity is exhausted.\nApplication attacks can require less firepower than a network attack and can focus on a specific application or process rather than an IP address or range of addresses, making them more efficient.\nBoth types of attack often are strengthened by using multiple sources to deliver malicious traffic, a technique called distributed denial-of-service, or DDOS. Distributed attacks not only can deliver more firepower, but they can more easily hide by spreading out the source of the malicious traffic, making it more difficult to block. Botnets — networks of compromised computers often managed by a criminal enterprise — traditionally have powered this distribution, but hacktivist organizations also have encouraged volunteers to participate in attacks with easy-to-use tools. More recently, the rise of virtual computing has opened new avenues for distributed attacks.\n\"Now what we’re seeing is compromised cloud-hosting structures,\" said Fran Trentley, senior service line director for Akamai Technologies’ public sector business. Even more than botnets, cloud computing gives attackers access to large amounts of processing power and the ability to quickly move through large IP address spaces to hide their activities. This tactic \"makes it extremely challenging to fight,\" he said.\nAccording to a recent Prolexic report on observed DDOS activity in the fourth quarter of 2012, the majority of attacks targeted infrastructure (layers 3 and 4 of the OSI Model) by a wide margin, with application layer attacks accounting for just 25 percent. But Imperva’s Rachwald said attack tools for Web applications appear to be a growth area in the underground economy. \"There is something going on when black hats start developing tools,\" he said.\nOne such tool that has gained attention in the past year is the Low Orbit Ion Cannon (LOIC), apparently used by Anonymous in its January 2012 Operation MegaUpload attacks that targeted government and entertainment industry sites.\nBoth network and application layer attacks have traits in common. It is the motive — denial of service — that defines them, not malware. They exploit a network or a server’s finite resources rather than its vulnerabilities, so it is difficult to defend against them by patching or updating software and hardware, although hardening systems can help. Operating systems and applications can be configured to disable services and applications not required for their missions; blacklists can be used to block traffic from known malicious sites; and service screening at edge routers can help to decrease loads from unwanted or improper traffic.\nBut while these steps can help reduce the attack surface, attacks still are possible and can quickly overwhelm resources. And although a denial-of-service attack usually does not damage systems or steal information, neither are the attacking infrastructures affected by the defense; the attackers remain capable of launching another attack as soon as the guard is lowered.\nPREVIOUS: Surviving denial-of-service? You need outside help to keep from going under.\nNEXT: How to mitigate and defend against DOS attacks", "label": 1}
{"text": "Worms, viruses, Trojan horses, and spyware: BEWARE!\nThe National Science Center, or NSC, is now training kids to stay safe from cyber attack malware when they’re surfing the web or using email and cell phones. A new online game called Cyber Swarm Defenders is targeted to 6th-8th grade students and is also appropriate for younger students.\nThe game is part of the NSC’s newest Cyber Ops education outreach program. The NSC is a public-private partnership between the U.S. Army and NSC, Inc., that uses its resources to stimulate and increase science, technology, engineering, and mathematics, known as STEM, proficiency in U.S. students, especially those in grades 4-9.\n“Anything we can do to make the young students of our country understand the cyber threat and get them excited about STEM technologies has a big payoff,” said Ron Ross, chairman of the NSC.\n“Educating students about cyber security threats and how to counteract them is imperative,” said Mike Krieger, the Army deputy chief information officer, who serves as the secretary of the Army’s proponent for the NSC. He also serves as the co-chairperson for the NSC’s Partnership Executive Committee, which provides overall direction and oversight for the NSC.\nCyber Swarm Defenders is deployed through the social networking site, which was built for children ages 13 and under. Kid-safe requirements are built in, including a parental control feature. This tower-defense strategy game integrates cyber security education and “learn to earn” mini-exercises. Students earn points, badges and game coins as they strengthen their defenses to advance through the game levels.\n“Installing the game on a social network site allows us to reach a variety of students and an existing community of users,” said Krieger.\nTo access the game from the NSC’s website and click on the Cyber Swarm banner button. Or, go directly to this site. To play, participants must first register on jabbersmack–which is not accessible on some older versions of browsers.\n“Our additional focus on cyber threats also significantly enhances the value proposition of the NSC Partnership,” Ross said.\nCreated by Congress in 1985, the NSC ‘s outreach programs include online teacher tools, two 18-wheeler Mobile Discovery Center vans, Junior ROTC STEM Outreach activities, and Cyber Ops. In addition to the new game, the Cyber Ops program links to a Malware Comic Book and Malware Mystery game that are also appropriate for older students.\nBy Margaret McBride, CIO/G-6\nDisclaimer: The appearance of hyperlinks does not constitute endorsement by the Department of Defense of this website or the information, products or services contained therein. For other than authorized activities such as military exchanges and Morale, Welfare and Recreation sites, the Department of Defense does not exercise any editorial control over the information you may find at these locations. Such links are provided consistent with the stated purpose of this DoD website.", "label": 1}
{"text": "You never know when malware can sneak up on you.\nNow that you can browse the web and check your e-mails anywhere, at any time, from your smartphone, you have more control over your actions. But acting on rapid mode might make you less attentive to visual details in your search results, e-mails etc. Also, the mobile screen, because of its small size, cannot comprise all the elements you’re used to see on a PC screen. Even though this may seem like simplifying things, it actually makes it more difficult to spot virus activity. And thus, cybercrooks’ mobile security attacks and scams are more successful. Even those initially designed for PC, which you might otherwise easily recognize on the “big screen”.\nThis is the case with drive-by downloads. Cybercrooks have figured a way to adapt them to the mobile environment and now the risks of falling victim to them are significantly higher. More so if you don’t have proper mobile antivirus protection.\nWhat’s the deal with drive-by downloads?\nThe drive-by download technique has been used in computer infections for some time now. It basically refers to downloads of files that you don’t know are taking place – often spyware, a Trojan or some other form of malware.\nHow does it work? – by exploiting vulnerabilities in web browsers, additional browser software or lowered security settings.\nHow can you trigger it? – by visiting a compromised website, viewing an e-mail or by clicking on a misleading pop-up window. In some cases, users who want to download, say a browser add-on they’ve seen on a not-so-reputable website, may end up installing the add-on and a sneaky piece of malware, too.\nDrive-by downloads versus mobile security\nOn smartphones, especially those with little or no mobile antivirus protection, drive-by downloads work pretty much the same way. But there have been cases where the user triggered a drive-by download by clicking on a malicious link in a text message – this being part of the whole “adapting to mobile devices” idea. Here are two scenarios that paint a clearer picture of how drive-by downloads can compromise your mobile security:\n- You browse the web on your smartphone. You go to a webpage and suddenly, a small window, looking like the one that usually appears when someone calls you, pops up on your screen. You click on that window to answer the alleged call, and a file starts downloading to your phone. Without a doubt that’s malware compromising your mobile security. The same could happen with an ad suddenly popping up on your screen.\n- You receive an SMS supposedly from your mobile network operator urging you to click on a link it provides. Once you click on it, you go to a website which exploits your mobile browser and silently plants a Trojan on your smartphone. The malware gives cybercrooks remote access to your device, which, clearly, is a dangerous threat to your mobile security. Such links can also be embedded in phishing e-mails.\nThe most common mobile drive-by downloads are those exploiting mobile browser vulnerabilities. They enable crooks to remotely run commands within the phone’s operating system and change the way it works. It’s similar to rooting or jailbreaking the device – by cybercrooks and without your knowledge! These are the usual steps:\n- 1. You go to a malicious webpage from your smartphone, by clicking on a link in an e-mail/SMS, when browsing.\n- 2. The webpage contains malware that exploits your mobile browser, enabling a connection between the mobile device and a cybercrook.\n- 3. The crook breaches your mobile security by sending commands to gather mobile data such as phone contacts, Skype contacts, login credentials etc., or even tracking your phone location.\nHow to avoid a mobile drive-by download\nWith the increasing number of smartphone users, this technique has become very popular among cybercrooks who want to breach their mobile security – which means, you’re more exposed than ever. What can you do to steer clear from it?\n- 1. If, while browsing the web you get a dubious pop-up screen that prompts you to click on it, don’t. If you do, and the pop-up starts downloading a file – stop it immediately.\n- 2. Be vigilant when browsing the web and pay attention to visual details. Also be suspicious of any unsolicited and/or alarming SMS/e-mail coming from your mobile network operator and even from your bank. If they ask you for personal details or to click on a link – it’s best you contact them to check the validity of the message.\n- 3. Keep your mobile operating system and applications up-to-date.\n- 4. Make sure you have proper mobile antivirus protection on your phone. A mobile antivirus app from a reputable security provider goes a long way in safeguarding your device. BullGuard Mobile Security 10 comes with an antivirus engine that provides real-time protection against malware, and additional mobile security features for overall mobile security.", "label": 1}
{"text": "Storage device manufacturer Plasmon has developed read-only back-up discs that allow companies to selectively destroy data while leaving the rest of the disc's contents intact.\nThe disc, designed to support regulatory compliance requirements, is able to retain a record to confirm that data has been destroyed, so managers can prove that the company has met its compliance requirements.\nClaus Egge, programme director, European storage research at analyst firm IDC, said the discs were an industry first and would be suitable for the pharmaceutical, medical and legal industries, which are required to protect personal data and destroy it after use.\nHe added that the Data Protection Act required, for example, certain call centres to destroy client records after use.\nThe disc is based on Plasmon's UDO (Ultra Density Optical) format. UDO is a phase-change optical storage system, which stores data by physically changing the state of the disc's recording layer between amorphous and crystalline. With Plasmon's media, data is selectively destroyed by changing the entire state of an area occupied by a file into the crystalline state. The supplier calls this \"data shredding\".\nEgge said, \"The UDO-compliant write-once media is an implementation of evolving Worm [write once, read many] technology. This media offers the ability to selectively destroy individual records as retention periods expire. The addition of such a finite yet static data protection capability is an important development.\n\"Enabling data to be retained for the correct length of time will provide data protection and compliance officers with the necessary tools to deal with deletion as well as retention. IDC recommends that this functionality be supported in all major storage applications.\"\nThe Plasmon disc will have a capacity of 30Gbytes, which is similar to the write-once and rewritable versions of UDO discs. Pricing will be somewhere between the two, at about £35 a disc.\nWhat is UDO?\nUDO (Ultra Density Optical) is an optical media storage disc format based on blue-laser technology similar to that used in the HD-DVD and Blu-Ray formats. UDO discs are encased in cartridges similar to Magneto Optical discs. This means IT managers can mix and match Magneto Optical and UDO drives in the same library.", "label": 1}
{"text": "For the first time, scientists at IBM Research have demonstrated that a relatively new memory technology, known as phase-change memory (PCM), can reliably store multiple data bits per cell over extended periods of time. This significant improvement advances the development of low-cost, faster and more durable memory applications for consumer devices, including mobile phones and cloud storage, as well as high-performance applications, such as enterprise data storage.\nWith a combination of speed, endurance, non-volatility and density, PCM can enable a paradigm shift for enterprise IT and storage systems within the next five years. Scientists have long been searching for a universal, non-volatile memory technology with far superior performance than flash - today's most ubiquitous non-volatile memory technology. The benefits of such a memory technology would allow computers and servers to boot instantaneously and significantly enhance the overall performance of IT systems. A promising contender is PCM that can write and retrieve data 100 times faster than flash, enable high storage capacities and not lose data when the power is turned off. Unlike flash, PCM is also very durable and can endure at least 10 million write cycles, compared to current enterprise-class flash at 30,000 cycles or consumer-class flash at 3,000 cycles. While 3,000 cycles will out live many consumer devices, 30,000 cycles are orders of magnitude too low to be suitable for enterprise applications (see chart for comparisons).\n\"As organizations and consumers increasingly embrace cloud-computing models and services, whereby most of the data is stored and processed in the cloud, ever more powerful and efficient, yet affordable storage technologies are needed,\" states Dr. Haris Pozidis, Manager of Memory and Probe Technologies at IBM Research - Zurich. \"By demonstrating a multi-bit phase-change memory technology which achieves for the first time reliability levels akin to those required for enterprise applications, we made a big step towards enabling practical memory devices based on multi-bit PCM.\"\nMulti-level Phase Change Memory Breakthrough\nTo achieve this breakthrough demonstration, IBM scientists in Zurich used advanced modulation coding techniques to mitigate the problem of short-term drift in multi-bit PCM, which causes the stored resistance levels to shift over time, which in turn creates read errors. Up to now, reliable retention of data has only been shown for single bit-per-cell PCM, whereas no such results on multi-bit PCM have been reported.\nPCM leverages the resistance change that occurs in the material - an alloy of various elements - when it changes its phase from crystalline - featuring low resistance - to amorphous - featuring high resistance - to store data bits. In a PCM cell, where a phase-change material is deposited between a top and a bottom electrode, phase change can controllably be induced by applying voltage or current pulses of different strengths. These heat up the material and when distinct temperature thresholds are reached cause the material to change from crystalline to amorphous or vice versa.\nIn addition, depending on the voltage, more or less material between the electrodes will undergo a phase change, which directly affects the cell's resistance. Scientists exploit that aspect to store not only one bit, but multiple bits per cell. In the present work, IBM scientists used four distinct resistance levels to store the bit combinations \"00\", \"01\" 10\" and \"11\".\nTo achieve the demonstrated reliability, crucial technical advancements in the \"read\" and \"write\" process were necessary. The scientists implemented an iterative \"write\" process to overcome deviations in the resistance due to inherent variability in the memory cells and the phase-change materials: \"We apply a voltage pulse based on the deviation from the desired level and then measure the resistance. If the desired level of resistance is not achieved, we apply another voltage pulse and measure again - until we achieve the exact level,\" explains Pozidis.\nDespite using the iterative process, the scientists achieved a worst-case write latency of about 10 microseconds, which represents a 100× performance increase over even the most advanced Flash memory on the market today.\nFor demonstrating reliable read-out of data bits, the scientists needed to tackle the problem of resistance drift. Because of structural relaxation of the atoms in the amorphous state, the resistance increases over time after the phase change, eventually causing errors in the read-out. To overcome that issue, the IBM scientists applied an advanced modulation coding technique that is inherently drift-tolerant. The modulation coding technique is based on the fact that, on average, the relative order of programmed cells with different resistance levels does not change due to drift.\nUsing that technique, the IBM scientists were able to mitigate drift and demonstrate long- term retention of bits stored in a subarray of 200,000 cells of their PCM test chip, fabricated in 90-nanometer CMOS technology. The PCM test chip was designed and fabricated by scientists and engineers located in Burlington, Vermont; Yorktown Heights, New York and in Zurich. This retention experiment has been under way for more than five months, indicating that multi-bit PCM can achieve a level of reliability that is suitable for practical applications.\nThe PCM research project at IBM Research - Zurich will continue to be studied at the recently opened Binnig and Rohrer Nanotechnology Center. The center, which is jointly operated by IBM and ETH Zurich as part of a strategic partnership in nanosciences, offers a cutting-edge infrastructure, including a large cleanroom for micro- and nanofabrication as well as six \"noise-free\" labs, especially shielded laboratories for highly sensitive experiments.\nFurther Reading: Read and find more RAM press releases at our RAM PR index page.\nDo you get our RSS feed? Get It!", "label": 1}
{"text": "What is Spam?\nSpam is unsolicited email on the Internet. It is a form of bulk mail from the sender’s point-of-view and often sent to a list gathered from subscribers to a discussion group or obtained by companies that specialize in creating email distribution lists. In much the same way that retailers and businesses use postal mailing lists to send potential customers catalogs and other information, an increasing number are using e-mail messages as a direct marketing tool. In general, it’s not considered good internet etiquette to send spam. It’s generally equivalent to unsolicited phone marketing calls except that the user pays for part of the message since everyone shares the cost of maintaining the Internet.\nEmail spoofing is the practice of changing from field of an email so that it looks like the email came from someone or somewhere else. Email spamming may be combined with email spoofing, so that it is very difficult to determine the actual originating email address of the sender. Some email-distributed viruses use spoofing, such the Klez or Sobig virus, take a random name from somewhere on the infected person’s computer and mail themselves out as if they were from that randomly chosen address. Recipients of these viruses are therefore misled as to the address from which they were sent, and may end up complaining to, or alerting the wrong person. As a result, users of uninfected computers may be wrongly informed that they have, and have been distributing a virus.\nEmail phishing is the act of sending an email to a user falsely claiming to be an established legitimate business in an attempt to scam the user into providing private information. The email usually directs the user to visit a website where they are asked to update personal information, such as, passwords and credit card, social security, and/or bank account numbers. This website is bogus and set up only to steal the user’s information. If you feel that you have received a phishing email, you should forward the email to the ITS Helpdesk at firstname.lastname@example.org .\nSome apparently unsolicited email is, in fact, email people agreed to receive when they registered with a site and a box was checked agreeing to receive postings about particular products or interests. This is known as both opt-in email and permission-based email.\nTips to Avoid Getting Spam:\n- Never post your real email address on a forum or bulletin board. Spammers use special programs which harvest these and use them to build spam lists. Once your email address has been caught in this way, you’ll never get off the spam lists.\n- Set up multiple email addresses. If you regularly sign up to a lot of web sites, which may sell email addresses as a source of revenue, consider having one email address just for this purpose, while keeping your other – real – email address private to friends and family.\n- When you register with an internet site, make sure you do not give them the right to sell your email address to spammers. (Watch for little checkboxes and make sure to remove any which are checked by default).\n- Use the email filters to reject spam with obvious catchphrases in it (debt consolidation, porn, sex, viagra, hot girls etc)\nDealing with Spam:\nIf you suspect a message is junk mail, treat it as such by deleting it — even without opening it. Common clues include information in the subject headings and unknown senders. Do take action to stop spam. Users can setup rules to filter the messages to stop spam messages and block spam sites.\nAll incoming email is now being filtered by Proofpoint Endpoint Security. Users will no longer need to setup a filter to move messages tagged as spam. For more inforamtion on Proofpoint and how it works please visit http://go.umflint.edu/proofpoint.", "label": 1}
{"text": "Available Data Indicate Growth in Prevalence and Cost\nGAO-02-424T, Feb 14, 2002\n- Accessible Text:\nIdentity theft involves \"stealing\" another person's personal identifying information, such as their Social Security Number (SSN), date of birth, or mother's maiden name, and using it to fraudulently establish credit, run up debt, or take over existing financial accounts. The prevalence and cost of identity theft seem to be increasing. Recently introduced bills seek to prevent identity theft and enforce laws prohibiting identity theft. Since May 1998, various actions--particularly passage of federal and state statutes--have been taken to address identity theft. Precise, statistical measurement of identity theft trends is difficult for several reasons. Federal law enforcement agencies lack information systems to track identity theft cases. Also, identity theft almost always accompanies white-collar or financial crimes, such as bank fraud, credit card or access device fraud, or the use of counterfeit financial instruments. Data sources, such as consumer complaints and hotline allegations, can be used as proxies for gauging the prevalence of identity theft. Law enforcement investigations and prosecutions of identity theft-related crimes, such as bank and credit card fraud, also provide data.", "label": 1}
{"text": "Mobile Clinic: How do you make mobile data secure?\nKeeping it safe\nEd Moore, OpenWeb Product Manager, Openwave Europe\nMobile data security is a many-headed Hydra; with a variety of potential issues to be addressed under the single banner. Mobile also covers a variety of potential access devices, from laptops down to phones and even internet cafes, all of which have to be addressed.\nSecuring data on laptops and phones\nAny device with more than just a contact list and browser should have security measures mandated. For non-sensitive work a password and rotation policy is sufficient, but for personal data records or sensitive business data then data encryption technology must be used as well.\nTracking services should also be considered; these will trace the device after being stolen so that remote deletion can be triggered or the unit retrieved.\nFinally, if a mobile is being used for collecting or generating primary data (as opposed to copying data from a centralised system) synchronisation/centralised backup software can be used too. This should minimise the possibility that valuable data can be lost through theft or accident.\nProtection against attack\nViruses, Trojans and Phishing attacks can all attack mobile devices and laptops or smartphones can be especially sensitive to these, as they can be taken outside of your corporate network, which may provide a degree of security at the network edge.\nAll devices should have anti-virus protection and ideally be configured to use a corporate (but external) security proxy for general internet access. This may not be possible in all cases, but will help give the most complete protection. The problem can be resolved in an alternative manner; by specifying standard phones for data access; with a closed platform it is much more difficult to suffer a meaningful attack.\nSecuring corporate communications\nAlways encrypt the traffic to a corporate network, SSL or IPSec encryption is common to all mobiles these days and there's no excuse not to make this a policy. Encryption can be used at a single application level or to secure the whole data pipe, but any application with automated log-on needs to be watched particularly carefully. Apply passwords and ensure these are used when establishing a connection, otherwise anyone can quickly gain access. A two-factor authentication service may be needed for added protection.\nStealing corporate secrets\nThere's always the potential for a staff member to use a mobile device to transport company secrets away from the office. Laptops have enormous storage capacity these days and usually CD burners and Wi-Fi connections too, to compound the problem. Logging and tracking software can help provide some security, but in reality this is just covering up the problem. Concentrate HR on keeping the staff happy instead!\nSimplify the problem; use standard handsets if at all possible with browser access to corporate applications. Don't store locally and don't enable viruses.\nStandardise wherever possible; same handsets, laptops, security software, and encryption technique. Proliferation always lessens effectiveness.\nConsider all angles; you'll end up with a more comprehensive policy because of it. ®", "label": 1}
{"text": "Malware removal is a tricky business. It often requires intimate knowledge of the inner workings of a particular piece of malcode: How it got on the computer in the first place; its attack mode; what it changes; where it resides. Malware removal is certainly not for the faint-of-heart.\nSince malware is a term that describes a broad variety of unwanted software, there are a multitude details to work out before removal can commence. Each virus, spyware or rootkit can have a completely different effect on a given computer system making removal that much more complicated. For example, adware might only manifest itself in Internet Explorer (IE) browser settings; a virus might infect an instant messaging (IM) application and send IMs to the buddy list; while a rootkit can hide itself at a computer's kernel level to avoid detection by the operating system (OS), applications and the user.\nTherefore, the first step in the malware removal process is identification and classification.\nAside from the basic classification terms, like viruses, worms, spyware, etc., you can classify malware on the basis of what's pertinent to administrators and users alike -- without needing to understand the precise technical definition of each term. For example, attack vector. How does a piece of malcode spread? Through email? Over IM? Does it disperse itself?\nWhen you understand how a piece of malware infected your computers in the first place, not only will that knowledge help you identify the particular malware strain, but it will also help prevent more attacks.\nAnother way to classify malware is by the flaw or vulnerability it exploits. Does the malware affect a particular application like Word or PowerPoint? Does it only affect a particular version of software, like an IE 6 VBscript flaw? These vulnerabilities affect client-level systems, but what if the malware affects a more critical server system like 2003's SQL slammer worm?\nThe potential severity of malware is another way to classify it. Can it be easily dispersed through the network? Will it affect server-level systems? Will it be confined to only desktop systems running unpatched Office 2003 applications? Antivirus and antispyware companies often classify threats based on the extent of the damage caused by the malware to a single system and the prevalence of the flaw or vulnerability across many systems.\nYou can further classify malware by the actions it takes once it has infected a system. What files does it change? Does it change registry settings? Does it implant itself in the OS startup file? Does it initiate Windows processes? If it does, that is often the key to finding out if you have a virus. A tool like Sysinternals Process Explorer can help identify processes that should not be running on a clean Windows computer.\nMalware removal tools\nA large number of tools out there are great at detecting malware -- and usually those same tools can prevent it from infecting a computer in the first place. But far fewer tools can completely remove an imbedded piece of malcode.\nFor removal, you often need to rely on tools that root out malware by scanning your system for anomalies like foreign processes, altered registry settings and corrupt files. Once the tool finds and identifies a piece of malware, there are usually manual instructions available for wiping its presence from a computer -- often that information comes from security companies or even blogs, user groups or independent security professionals.\nOf course, some malware is so insidious that it cannot be completely removed from an infected system. In those cases, the only recourse is to reinstall the OS. And that makes the subject of chapter three of this guide, prevention, that much more important.\nThis was first published in April 2007", "label": 1}
{"text": "As the popularity of these social sites grows, so do the risks of using them. Hackers, spammers, virus writers, identity thieves, and other criminals follow the traffic.\nRead these tips to help protect yourself when you use social networks.\n- Use caution when you click links that you receive in messages from your friends on your social website. Treat links in messages on these sites as you would links in e-mail messages.\n- Know what you’ve posted about yourself. A common way that hackers break into financial or other accounts is by clicking the “Forgot your password?” link on the account login page. To break into your account, they search for the answers to your security questions, such as your birthday, hometown, high school class, father’s middle name, on your social networking site. If the site allows, make up your own password questions, and don’t draw them from material anyone could find with a quick search.\n- Don’t trust that a message really is from whom it says it’s from. Hackers can break into accounts and send messages that look like they’re from your friends, but aren’t. If you suspect that a message is fraudulent, use an alternate method to contact your friend to find out. This includes invitations to join new social networks.\n- To avoid giving away e-mail addresses of your friends, do not allow social networking services to scan your e-mail address book. When you join a new social network, you might receive an offer to enter your e-mail address and password to find out if your contacts are on the network. The site might use this information to send e-mail messages to everyone in your contact list or even everyone you’ve ever sent an e-mail message to with that e-mail address. Social networking sites should explain that they’re going to do this, but some do not.\n- Type the address of your social networking site directly into your browser or use your personal bookmarks. If you click a link to your site through e-mail or another website, you might be entering your account name and password into a fake site where your personal information could be stolen.\n- Be selective about who you accept as a friend on a social network. Identity thieves might create fake profiles in order to get information from you.\n- Assume that everything you put on a social networking site is permanent. Even if you can delete your account, anyone on the Internet can easily print photos or text or save images and videos to a computer.\n- Be careful about installing extras on your site. Many social networking sites allow you to download third-party applications that let you do more with your personal page. Criminals sometimes use these applications to steal your personal information. To download and use third-party applications safely, take the same safety precautions that you take with any other program or file you download from the Web.\n- Think twice before you use social networking sites at work.\n- Talk to your kids about social networking.\nFounded in 1975, Microsoft (Nasdaq “MSFT”) is the worldwide leader in software, services and solutions that help people and businesses realize their full potential.", "label": 1}
{"text": "(DataBase Management System) Software that controls the organization, storage, retrieval, security and integrity of data in a database. It accepts requests from the application and instructs the operating system to transfer the appropriate data. The major DBMS vendors are Oracle, IBM, Microsoft and Sybase (see Oracle database, DB2, SQL Server and ASE). MySQL is a very popular open source product (see MySQL).|\nDBMSs may work with traditional programming languages (COBOL, C, etc.) or they may include their own programming language for application development.\nDBMSs let information systems be changed more easily as the organization's requirements change. New categories of data can be added to the database without disruption to the existing system. Adding a field to a record does not require changing any of the programs that do not use the data in that new field.\nMajor Features of a DBMS\nThe DBMS can prevent unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or a subset of it known as a \"subschema.\" For example, in an employee database, some users may be able to view salaries while others may view only work history and medical data.\nThe DBMS can ensure that no more than one user can update the same record at the same time. It can keep duplicate records out of the database; for example, no two customers with the same customer number can be entered.\nA DBMS provides a query language and report writer that lets users interactively interrogate the database. These essential components give users access to all management information as needed. See query language and report writer.\nInteractive Data Entry and Updating\nA DBMS typically provides a way to interactively enter and edit data, allowing you to manage your own files and databases. However, interactive operation does not leave an audit trail and does not provide the controls necessary in a large organization. These controls must be programmed into the data entry and update programs of the application.\nThis is a common misconception about using a desktop computer DBMS. Creating lists of data for a user's own record keeping is one thing. However, although complete information systems can be developed with such software, it cannot be done without understanding how transactions and files relate to each other in a business system (see Database Design below). In addition, some type of programming is required, whether at a graphical drag and drop level or by using traditional languages.\nWhen a DBMS is used, the details of the data structure are not stated in each application program. The program asks the DBMS for data by field name; for example, a coded equivalent of \"give me customer name and balance due\" would be sent to the DBMS. Without a DBMS, the programmer must reserve space for the full structure of the record in the program. Any change in data structure requires changing all application programs.\nA business information system is made up of subjects (customers, employees, vendors, etc.) and activities (orders, payments, purchases, etc.). Database design is the process of organizing this data into related record types. The DBMS that is chosen is the one that can support the organization's data structure while efficiently processing the transaction volume.\nOrganizations may use one kind of DBMS for daily transaction processing and then move the detail to another DBMS better suited for random inquiries and analysis.\nOverall systems design decisions are performed by data administrators and systems analysts. Detailed database design is performed by database administrators.\nHierarchical, Network & Relational\nInformation systems are made up of related files: customers and orders, vendors and purchases, etc. A key DBMS feature is its ability to manage these relationships.\nHierarchical databases link records like an organization chart. A record type can be owned by only one owner. In the following example, orders are owned by only one customer. Hierarchical structures were widely used with early mainframe systems; however, they are often restrictive in linking real-world structures.\nIn network databases, a record type can have multiple owners. In the example below, orders are owned by both customers and products, reflecting their natural relationship in business.\nRelational databases do not link records together physically, but the design of the records must provide a common field, such as account number, to allow for matching. Often, the fields used for matching are indexed in order to speed up the process.\nIn the following example, customers, orders and products are linked by comparing data fields and/or indexes when information from more than one record type is needed. This method is more flexible for ad hoc inquiries. Many hierarchical and network DBMSs also provide this capability.\nCertain information systems may have complex data structures not easily modeled by traditional data structures. An \"object database\" can be employed when hierarchical, network and relational structures are too restrictive. Object databases can easily handle many-to-many relationships.\nAll DBMSs provide some data validation; for example, they can reject invalid dates or alphabetic data entered into money fields. But most validation is left up to the application programs.\nIntelligent databases provide more validation; for example, table lookups can reject bad spelling or coding of items. Common algorithms can also be used such as one that computes sales tax for an order based on zip code.\nWhen validation is left up to each application program, one program could allow an item to be entered while another program rejects it. Data integrity is better served when data validation is done in only one place. Mainframe DBMSs were the first to become intelligent, and all the others followed suit.\nThis diagram shows the interaction between the DBMS with other system and application software running in memory.", "label": 1}
{"text": "Cloud Computing: Implementation, Management, and Security provides an understanding of what cloud computing really means, explores how disruptive it may become in the future, and examines its advantages and disadvantages. It gives business executives the knowledge necessary to make informed, educated decisions regarding cloud initiatives.\nThe authors first discuss the evolution of computing from a historical perspective, focusing primarily on advances that led to the development of cloud computing. They then survey some of the critical components that are necessary to make the cloud computing paradigm feasible. They also present various standards based on the use and implementation issues surrounding cloud computing and describe the infrastructure management that is maintained by cloud computing service providers. After addressing significant legal and philosophical issues, the book concludes with a hard look at successful cloud computing vendors.\nHelping to overcome the lack of understanding currently preventing even faster adoption of cloud computing, this book arms readers with guidance essential to make smart, strategic decisions on cloud initiatives.\nEvolution of Cloud Computing\nCommunications (HTTP, XMPP)\nData (XML, JSON)\nOffline (HTML 5)\nSecurity (OAuth, OpenID, TLS)\nSolution Stacks (LAMP)\nWeb Services (REST)\nPlanning for Capacity\nPlanning for Availability\nPlanning for Security\nArchitecting Marketable Solutions for Enterprise\nConsumer Specific Issues to Plan for\nCloud Vendors to Watch\nFuture Directions of Cloud Computing\nWho Is Leading the Pack?\nWhat Is at the Forefront of Cloud Computing?\nWhat Challenges Must Be Overcome with Adoption of Cloud Computing?\nHow Will Cloud Computing Blend with New Wireless Technologies?\nDay-to-Day Management Issues Running a Cloud Environment\nThree Key Elements: Ping, Power, and Pipe\nStructure of an Always-on Environment with Virtualization\nJohn W. Rittinghouse is Chief Software Architect and Co-founder of Hypersecurity LLC in Houston, Texas. He holds a Ph.D. in Psychology with emphasis in Natural Language Processing.\nJames F. Ransome is a Senior Director and the Chief Security Officer for the Cisco Collaborative Software Group (WebEx). He holds a Ph.D. in Information Systems specializing in Information Security.\n… This book is a compact and readable primer on the vocabulary and concepts behind the cloud computing phenomenon. … For those readers unfamiliar with basic virtualization software, the authors provide a brief tutorial using the popular (and free) VirtualBox product. … the book can serve as a brief but adequate introduction to cloud computing for those new to the topic …\n—Computing Reviews, November 2009", "label": 1}
{"text": "ecurity is a hot topic these days. It is as if developers and system designers are fighting a never ending war against those who desire to damage hardware, compromise system availability, steal data, and tarnish hard-earned client trust. And as if malicious threats weren't enough, we must also protect ourselves from unintentional\ndamages inflicted by accidental removal or modification of data.\nThe scope of this effort ranges from entire enterprise networks and the Internet itself down to a specific line of code that may handle the formatting of a string. For the benefit of this article, the entirety of this scope will be described as a \"system.\"\nSome tactics can be employed to secure a system without much analysis, such as implementing a firewall on the network, implementing logins to restrict system access, employing role-based security to control which aspects of the system a user can access, and encrypting sensitive data such as social security numbers. The question is: How can one be objectively confident when making the claim that their system is secure? The methodology commonly referred to as \"threat modeling\" organizes the review and analysis process to ensure the security of a system.\nThe sample system used in this article to illustrate the aspects of threat modeling is a simplified version of a web application. The public uses this system to browse a library of music CDs and request those items for short term lending, much like one that might be utilized for a public library.\nDefining Threat Modeling\nThreat modeling is a formal process that identifies assets and their security vulnerabilities, and analyzes and documents them. The output from this process is not a static document, but one that should be continually revised as new elements are introduced to a system or existing elements are modified.\nThere are several approaches to the threat modeling process. Some approaches may be better for large IT shops or enterprise-wide evaluation, while others are more suited for very small development shops or very limited-use systems. You should evaluate these approaches and modify the threat modeling methodology to the specific needs of your particular environment. This article presents the threat modeling methodology that I employ, which was originally inspired by the methodology presented by the Microsoft Application Consulting and Engineering Team, but contains some variations pulled from other sources.\nIt is said that a picture is worth a thousand words. It is also true that a well-crafted quote can encompass volumes of documents and articles. In the case of threat modeling, Sun Tzu, the sixth century B.C. author of \"The Art of War,\" best encompasses the threat modeling effort in the following quote: \"\nif you know your enemies and know yourself, you will fight without danger in battles\nAnother good piece of advice is to start early. Building threat modeling into a system during the development process is optimal, because the data entry and output points are defined during that stage, giving you the opportunity to evaluate the proposed foundation for potential vulnerabilities before any construction begins. Unfortunately, the optimal scenario is relatively rare. Threat modeling of an existing system and creating mitigations to identified vulnerabilities post-implementation offers a different set of challenges. Still, a late threat model is much better than no threat model at all.\nAssembling a Threat Modeling Team\nThe threat modeling process should have a designated person to facilitate the threat modeling process and assembling the documentation. System evaluation is not a one-person job; it typically involves many participants, such as:\n- System Architects and Developers: because they are the most intimately familiar with the structure and coding of the system.\n- Network Administrators: because they are most familiar with the environment in which the system operates.\n- End Users: because they have a grasp of how the system gets used on a daily basis.\n- Testers: to execute the findings and evaluate how any mitigation of identified vulnerabilities affects system operation.\n- Decision Makers (Managers): because they are the ones who will determine how the system is intended to be used as well as which vulnerabilities should be mitigated based upon their risk appetite.\nIn some development shops there may be persons who take on multiple roles; but the inclusion of other viewpoints, especially during the threat analysis portion of the process, is essential to identifying a system's vulnerabilities.\nHere are the steps that must be performed to fully understand a system:\n- Define the assets of the system\n- Define user entities\n- Define trust levels and boundaries\n- Identify input/output points of the system\n- Develop use case scenarios\n|A Note on Documentation: It is critical to document the results. For easy reference, you should document each element with the following key pieces of information:\nNote that this documentation contains important information regarding the system and—in the wrong hands—is itself a security vulnerability; therefore, keep it in a safe and restricted location in both electronic (soft copy) as well as printed (hard copy) format.\n- ID: This should be a unique identifier which can be referenced in other textural and graphical documentation.\n- Description: This will provide the details regarding the step in question.\n- Step Specific Details: This provides information that is specific to the step being evaluated. For example: Evaluating an asset should include the details regarding its consideration.", "label": 1}
{"text": "It started with a phone anchored to your car or your briefcase-\"walking-around\" communications that freed you from searching for a pay phone in order to talk outdoors.\nNow telecommunications has morphed into movies on your phone, banking on the fly, an office wherever you go. Communication isn't just about people talking to people. It's about things talking to each other.\nOn a smarter planet, almost anything can become digitally aware, instrumented and interconnected. We have the connections, processors, analytics and capabilities powerful enough for trillions of devices to talk to each other and improve the way the world works. Smart houses can be programmed remotely. Smart cars talk to home base. Smart phones can practically replace your wallet. Smart highways can regulate traffic flows.\nA typical U.S. 21-year-old has exchanged 250,000 e-mails, instant messages and phone text messages.\nA busy signal is not an option\nBut the deluge of data from the trillions of smart objects is creating an insatiable demand for bandwidth. The infrastructure has had to grow up and keep up, sometimes at great struggle when you consider that:\nThe deluge of data from the trillions of smart objects is creating an insatiable demand for bandwidth.\nThe growth in bandwidth means greater potential for online identity theft, stolen intellectual property and malicious attacks such as spam, which by many estimates accounts for about 80% of transmitted e-mail.\nRealising the potential of smarter telecommunications will require the infusion of new technologies and models into our systems to make it easier for devices to transmit and interpret data, provide more secure connections, and protect identities.\nTechnology to make our lives simpler\nIBM Research and Development Director and Chief Technologist, Glenn Wightwick, examines how the true value of mobile technology is in its potential to simplify our increasingly complex lives.\nHear Sir Paul Callaghan, New Zealander of the Year and the founding Director of the MacDiarmid Institute for Advanced Materials and Nanotechnology at Victoria University of Wellington, talk about ways to encourage the growth of technology, foster innovation in our universities and the role that private wealth can play in this field.\nMore than just talk\nA fisherman in India can use a mobile phone as he approaches the dock to check current prices across multiple marketplaces and get the best price for his catch, boosting his income by nearly 50%.\nA children's hospital in Australia reduces stress and confusion in the emergency room by replacing a loud overhead paging system with a hands-free, wireless voice network. And two college students in different cities can use their mobile phones to log onto Facebook and organise a party with a group of friends for their upcoming holiday break.\nDid you know?\nAT&T's ancestor, The Bell Company, proposed a wireless phone in 1915 but shelved the idea in favor of its wired service.\n1998 was a banner year for mobile commerce: The first purchase by cell phone was made (to a Coca-Cola machine), and a ring tone was the first downloaded content sale.\nAlmost 4 billion subscribers of cell phones were expected by 2008, representing 21% of the world's adult and child population.\nCreating smarter communications systems to handle increasingly demanding applications takes leading-edge information technology, forward-thinking business and industry expertise, and innovative research and development. IBM has joined forces with numerous telecommunications clients to make business smarter:\nReach out and touch someone-online\nPeople used to keep in touch with a call. Now they are using social networking sites such as Facebook and Twitter-dramatically cutting into telcos'share of communications services. But there are opportunities. Read the new report (PDF,324KB) The Changing Face of Communications.\nWe're here to help", "label": 1}
{"text": "Why is this? \"Pattern recognition\" is a frequent A.I. refrain, but computers can't learn to spot patterns they've never seen. The high-value targets in big data are invariably human: highly adaptive adversaries such as terrorists and cybercriminals whose ingenuity frustrates even the most advanced algorithms.\nYet even the nimblest fugitives leave clues, even patterns -- they're just buried in an expanding universe of data, a challenge that intensifies as we seek still more data, hoping it will yield more insight.\nAdaptive adversaries require adaptive responses, and this begins with asking questions rooted in human intuition. While technology can certainly be a force multiplier for good or evil, it's difficult to imagine a pure A.I. approach reverse-engineering the machinations of a terrorist mastermind.\nWhen U.S. intelligence tracked down Osama bin Laden, it was a function of brilliant, resourceful people asking questions and testing hypotheses using a variety of technologies.\nCybercriminals, as explored in my first TED talk, tend to target the allegedly weakest links in the network: people. Yet how weak is something that can learn in ways even the most robust automated systems can't?\nCyber security might always be an uphill, defensive struggle as techniques and technologies raise the stakes on both sides. Remember, though, that cyberwarfare is ultimately a human endeavor. Bot-nets, scripts and other automated tools play key roles, but they don't exist in a vacuum. This cuts both ways: Sooner or later, everyone makes mistakes, even evil genius types. That said, the enemy may well be two amateurs with a few weak laptops.\nAspiring good guys must be absolutely relentless in refining the intersection of brainpower and computing power, each of which is vulnerable in isolation.\nSometimes, the right combination of humans and technology can reshape the data landscape itself. In the aftermath of Superstorm Sandy, my company partnered with veterans' organization Team Rubicon to coordinate relief efforts in the Rockaways. It began with identifying the hardest-hit areas and greatest needs.\nSoon, as help poured in, the focus shifted to tracking projects, allocating manpower, and coordinating more than 10,000 volunteers in real time. Through rapid iteration, a group of determined people using low-friction technology had created a vast, self-regulating system. Each discrete data point was simple enough -- the status of a project, levels of need, locations of assets -- but in aggregate, the effect was transformative.\nWhile experience teaches that each approach has its caveats, we have every reason to be excited about the possibilities of human-computer symbiosis. Almost 50 years since the identification of Moore's Law, and 10 years since the human genome was first sequenced, humans and machines are beginning a new arc of re-imagining and discovery -- together.", "label": 1}
{"text": "Mental exhaustion from making repeated decisions can lead humans to avoid choices that require additional thinking, which often involves maintaining the status quo. This tendency may result in security and risk choices being influenced by extraneous variables that should be irrelevant to the decision.\nParole Hearings and Meals\nIn a paper titled Extraneous Factors in Judicial Decisions, the researchers found that judges were more likely to grant parole when the hearing was held shortly after a meal. More specifically,\n“The likelihood of a favorable ruling is greater at the very beginning of the work day or after a food break than later in the sequence of cases.”\nThe researchers concluded that “when judges make repeated rulings, they show an increased tendency to rule in favor of the status quo.” Though the behavior could be the result of lower blood glucose levels, researchers attributed the tendency primarily to mental depletion. A brain tired of making choices might shun additional workload by simply maintaining the status quo—which meant denying parole requests after hearing a certain number of cases.\nMaking Decisions Is Tiring\nAn earlier study titled Choice Fatigue: The Effect of Making Previous Choices on Decision Making explored the extent to which humans tire of making decisions. The researchers concluded that “decision outcomes are dependant on the number of previous decisions made.” More specifically,\n“Making more decisions prior to a particular decision increases the likelihood of abstention from the decision as well as the reliance on heuristics (such as choosing the status-quo) in decision-making.”\nThe researchers coined the term choice fatigue to describe the effects of mental exertion experienced after making repeated choices.\nPotential Information Security Implications\nInformation security professionals make choices on regular basis. These include:\n- Is the severity of the vulnerability too low to justify patching it?\n- Is the alert issued by an intrusion detection system a false positive?\n- Should a particular service be disabled when locking down a server?\n- Is a 14-character password sufficiently long for the situation?\n- Is the security policy document sufficiently descriptive?\nAfter numerous risk-related choices during the day, choice fatigue may lead to easier making decisions that eliminate the need for further mental processing, such as deeming the vulnerability irrelevant or labeling an alert a false positive. The individuals most likely to be affected by this may be those in operational roles that demand continued oversight of security events. Forensics specialists sifting through large amounts of data might also be affected by choice fatigue.\nSo, don’t let choice fatigue get you. Take a break now :-)\nFor more thoughts along these lines, see The Reason For All Information Security Woes… Sleep Deprivation.", "label": 1}
{"text": "Digital ants protect computer networks\nAs the nation’s electrical power grid becomes more interconnected through the Internet — from the nuclear power plant in California to transmission lines in Texas to the microwave in your kitchen — the chances of cyber attacks increase as well.\nProfessor of Computer Science Errin Fulp is training an army of “digital ants” to turn loose into the power grid to seek out computer viruses trying to wreak havoc on the system.\nIf the approach proves successful in safeguarding the power grid, it could have wide-ranging applications on protecting anything connected to SCADA (Supervisory Control and Data Acquisition) networks, computer systems that control everything from water and sewer management systems to mass transit systems to manufacturing systems.\nMore news about digital ants:\nFrom TG Daily: Digital ants check networks for viruses\nFrom Tech2: Virus protection takes inspiration from ants\nFrom InfoSecurity: Can digital ants protect computer networks?\nFrom Gather Technology: Researchers hope to use digital ant antivirus to protect the grid\nFrom International Business Times: Researchers working on digital ants to flush out virus in computer networks\nFulp is working this summer with scientists at Pacific Northwest National Laboratory (PNNL) in Richland, Wash., on the next steps in the digital ants technology, developed by PNNL and Wake Forest over the last several years. The approach is so promising that it was named one of the “ten technologies that have the power to change our lives,” by Scientific American magazine last year.\nThe power grid is probably more vulnerable to cyber attacks than security experts would like to admit, said Fulp, an expert in security and computer networks. As the grid becomes more and more interconnected, it offers hackers more points to enter the system; for instance, inserting a virus or computer worm into a low security site, such as in your home’s smart grid, to gain access to more secure systems up the line.\n“When that network connects to a power source, which connects to the smart grid, you have a jumping off point” for computer viruses, he said. “A cyber attack can have a real physical result of shutting off power to a city or a nuclear power plant.”\nThe digital ants technology could transform cyber security because it adapts rapidly to changing threats, said Fulp, who has received nearly $250,0000 in grants from PNNL/Battelle Memorial Institute for his ongoing research.\nUnlike traditional security approaches, which are static, digital ants wander through computer networks looking for threats such as computer worms, self-replicating programs designed to steal information or facilitate unauthorized use of computers. When a digital ant detects a threat, it summons an army of ants to converge at that location, drawing the attention of human operators to investigate.\n“The idea is to deploy thousands of different types of digital ants, each looking for evidence of a threat,” Fulp said. “As they move about the network, they leave digital trails modeled after the scent trails ants in nature use to guide other ants. Each time a digital ant identifies some evidence, it is programmed to leave behind a stronger scent. Stronger scent trails attract more ants, producing the swarm that marks a potential computer infection.”\nThe concept has proven successful in testing on a small scale, but will it still work when it’s scaled up to protect something as large and complex as the nation’s power grid? Fulp and two of his students — computer science graduate students Michael Crouse and Jacob White — are working this summer with scientists at PNNL and from the University of California at Davis to answer that question. But even using PNNL’s vast computer platforms, they can only rely on computer simulations to predict the ants’ “behavior” up to a point.\nThat’s where Kenneth Berenhaut, an associate professor of mathematics and Z. Smith Reynolds Faculty Fellow, comes in. Berenhaut — an expert in mathematical modeling and simulation — and graduate student Ross Hilton, will use modeling to help determine what will happen as the ants move about the smart grid from the hot water heater in your house to the electrical substation to the power plant.\nAmong the questions to be answered: How do the ants migrate across different computer platforms and systems operating at different speeds? How many ants should you have patrolling a system? How long do they live? How do the ants scale up to identify a threat and then ramp back down?\n“In nature, we know that ants defend against threats very successfully,” Fulp said. “They can ramp up their defense rapidly, and then resume routine behavior quickly after an intruder has been stopped. We’re trying to achieve that same framework in a computer system.”\nPNNL, a Department of Energy laboratory, conducts cutting-edge research in cyber security. Glenn Fink, a senior research scientist at PNNL, first came up with the idea of copying ant behavior for computer security. He was familiar with Fulp’s work developing faster computer scans using parallel processing — dividing computer data into batches like lines of shoppers going through grocery store checkouts, where each lane is focused on certain threats — and invited him to join the project several years ago.\nFulp and two of his students, Wes Featherstun (’08, MS ’10) and Brian Williams (’08, MS ’10), then graduate students in computer science, worked at PNNL during the summer of 2009. Fulp and Crouse worked there again last summer.", "label": 1}
{"text": "It all begins with a team of hackers that spy on a specific company and seek out data needed to hack into its system. Members of this team underhandedly make people cooperate with them through psychological tricks. Once they do, these intruders obtain data necessary (as usernames and passwords) to access company networks. Knowing that most business staff workers are kind and polite as well as trusting, hackers pretend they’re employees of the targeted enterprise while asking for simple favors. Rather than physically breaking into an enterprise’s system, they seek out information as a way to get unauthorized access to it. This practice is referred to as social engineering.\nAs you know, a chain is as strong as its weakest link. If security were a chain, its weakest link would be the natural human kindness to trust anybody based on his or her word alone. No matter how effective our firewalls and our antivirus and anti-spyware programs work, they can only do so much to deter intruders. Every business needs a security policy to prohibit “visitors” from entering secured areas of its buildings. Employees must be trained not to let in strangers or answer security-related questions over the phone.\nGaining Company Info\nJust like hackers, social engineers seek to gain confidential facts or unauthorized access as a means of finding out more about a targeted company. With such data, intruders can commit fraud, obtain network access, undergo industrial espionage, steal one’s identity, or simply raise havoc with the company’s network. Common targets of such malicious acts are telephone companies, answering services, prominent corporations, banks, military and government agencies, and hospitals. Still, any company, large or small can be a victim to social engineering.\nWhy is social engineering becoming widespread? Because asking people for passwords or other illicit access data is much simpler than technical computer hacking. Even those with a great degree of hacking expertise find it’s much simpler to make a phone call and ask one for his password.\nCompanies are attacked via social engineering on a physical basis. Sources of illicit info about an entity are sought in the workplace, through the phone system, from trash cans, and via online access. Hackers have been known to walk into offices pretending to be a consultant or janitor. Such a person will casually strut around the workplace and seek out papers with passwords on them or watch over employees’ shoulders as they log in. Once the intruder found such data, that person will leave the premises and enter into the company’s network from their home.\nHacking by Phone\nAnother popular form of social networking is done over the phone. A potential hacker will call a user and impersonate one who has authority or relevance as a means of getting data from the user. Often, a hacker may claim they’re calling from within the corporation and then will play tricks on its operator. Such a person will say something like, “Hello, I am your representative from AT&T and I will need some info from you to fix a problem with your account.” They may ask for one’s AT&T card number and PIN combination.\nOne of the most vulnerable places of social engineering within a company is its help desk. Its staff are trained to be friendly, but taught the minimum necessary to answer common inquiries. Most of its employees know little, if anything about the security of their employer and are also paid low wages. All they do is answer a caller’s questions and move onto the next caller. Hence, the help desk is a potential gold mine for hackers and a large security hole for the entity.\nYet another method called “shoulder surfing” is done at pay phones and ATMs, especially at large airports. People lurk around these machines and peek over users’ shoulders to obtain credit card and PINs. Users must be extra careful when using them.\nGoing Through Trash\nIllicit information is also obtained via dumpster diving. Social engineering is done by pulling out discarded documents and company materials as phone books, employee handbooks, memos, calendars, system manuals, and any other sensitive data printed on paper. Additional data can be found on user/password login lists, source code printouts, floppy disks, storage tapes, stationery, and discarded computer equipment.\nHow are these items useful to a hacker? Company phone books list the names and numbers of employees hackers can call and beguile. Organization charts reveal names and positions of a company’s staff. Employee handbooks give the hacker an idea of how secure the business is (or isn’t). Technical information found in system manuals and source code reveals sensitive data needed to unlock and access the network. Media such as disks, tapes, and hard drives may hold all kinds of data that will benefit a hacker. Stationery and memo forms serve as an authentic way to send employees malicious correspondence.\nRequesting Info Online\nWorking online is yet another form of social engineering. Some hackers send online-forms to be filled out by users and require the entry of a username and password, email address, or card number and PIN combination. With these forms are advertisements stating the user has won some sort of sweepstakes and all he needs to do is supply information to claim his prize. Also, people tend to use the same username/password pair for more than one account and once a hacker has these two pieces of data, he may access other sites that the user visits frequently. Some users respond through their corporate email addresses unknowingly letting the hacker know where they work. Yet other hackers will send correspondence via the US mail asking for info.\nYet, the oldest trick in social engineering is pretending to be the network administrator. Real network administrators already know the username/password combinations of every employee, even if one decides to change theirs on the spur of the moment. If there are concerns related to a company’s network, employees should talk with their networker face-to-face.\nSocial engineering is becoming increasingly popular among hackers. It is best to be alert at all times and never give information out over the phone, even if the voice sounds familiar. Never open up emails, especially attachments, from parties you don’t know. Shred all documents before throwing them in the trash and have all computer media and hardware physically destroyed before disposing of them. Remember, legitimate network staff and company reps will never call you and ask for passwords. If you’re unsure about a request made via the phone, arrange to meet the caller in person.\nAbout the Author: Publishnprosper publishes articles on numerous computer usage topics. In his articles you will find useful tips on maintaining your computer and keeping it virus-free. If you’re interested in purchasing antivirus software, you may find coupons on http://www.dailydeals4you.com, Kaspersky coupon codes, Bitdefender promo, etc.\nDo you have questions, comments, or suggestions? Feel free to post a comment!\nLiked this post? Make a PayPal Donation to keep us strong.", "label": 1}
{"text": "November 14, 1998 Lock-on-a-chip may close hackers out\nBy P. Weiss\nEngineers have crammed an electromechanical combination lock onto a computer chip that they say can shut out cybercrooks. The device erects a barrier to computer intrusions that is far more difficult to penetrate than security software, the only option available today, say the locks inventors.\nBecause security software does not physically isolate a system but monitors electronic codes, determined hackers on the Internet or a modem connection can keep trying passwords and other keys until they breach the defenses.\nThe new lock, however, accepts only one number among a million possibilities as its correct combination. If a remote troublemaker attempts a break-in with the wrong code just once, the device disconnects the computer from its network. When the lock closes, only someone physically present at the computer can reopen it.\nThe new lock, which employs concepts developed for protecting nuclear weapons, \"puts a physical barrier between an asset and a threat,\" says the devices designer, Frank J. Peter of Sandia National Laboratories in Albuquerque, N.M. \"And it absolutely, positively cant be circumvented in software.\"\nPeter and his colleagues have packed intricate machinery into the silicon device the size of a shirt button. Electrically driven shafts studded with microscopic teeth turn tiny gears to set the combination. If triggered by a bogus code, the mechanism throws a switch that interrupts the flow of electric current or light through the device, temporarily isolating the computer.\nSuch a drastic response may prove impractical except for restricted-use computer systems where a small number of users all know the code and someone is continuously on duty to reset machines, says Peter Mell of the National Institute of Standards and Technology in Gaithersburg, Md. Moreover, attackers can send trouble-causing electronic mail and other data without having to gain access to a computer by logging on. Hackers could also maliciously trigger the lock to deny use of computers to their owners, he notes.\nDuring the next 2 years, the inventors may consider such questions in preparation for commercializing the technology. Perhaps they will choose to allow more than one false start, for instance, since computer users who rely on remote log-ins may occasionally type the wrong password. They also hope to find a company to mass-produce the locks inexpensively via methods used by integrated-circuit makers.\nFrom Science News, Vol. 154, No. 20, November 14, 1998, p. 309. Copyright © 1998 by Science Service.\nSandia National Laboratories provides additional information about the lock at these websites: http://www.sandia.gov/media/hacker.htm and http://www.mdl.sandia.gov/micromachine/.\nNational Institute of Standards and Technology\nComputer Security Division\n100 Bureau Drive, Mailstop Code 8930\nGaithersburg, MD 20899-8930\nFrank J. Peter\nSandia National Laboratories\nP.O. Box 5800\nMailstop Code 0329\nAlbuquerque, NM 87185-0329\ncopyright 1998 ScienceService", "label": 1}
{"text": "Social Networking Best Practices\nFacebook, MySpace, LinkedIn, and other social networking sites make it easy for you to connect with others based on shared personal and/or professional interests. They help you exchange information about yourself via postings, pictures, videos, email, or instant messaging. Depending on how you set up your account, this information can be shared within a small community of friends or broadcast to the world.\nSocializing online encourages openness, but it also challenges us to think about how we define privacy and what we consider personal. Consider how parents, university officials, future and current employers, or worse, online predators, may interpret your profile. The tips below will help keep you and your information safe.\n1. Know how the site works before you join.\nSocial networking sites are each set-up differently and offer a range of options. Some allow you to post to a small group of users, while others allow anyone to view your personal postings. Look at the different features and think about what level of openness you really want. Consider whether setting viewing restrictions can help control who sees your information.\n2. Keep personal information to yourself.\nYour full name, Social Security number, address, phone number, bank or credit card account numbers (and that of others) do not belong on these sites. By posting them, you open yourself up to identity theft or stalkers.\n3. Information lasts forever.\nOnly post information you are comfortable with others seeing, including your professors, parents, current or future employers, coworkers, or the police. Even if you change your mind and delete what you posted, the information is still out there. Older versions may exist on someone else’s computer and social networking sites can never fully remove these files.\n4. Think before you share.\nPhotos, videos, stories, blogs can all be used to form opinions of you or can be shared with others. Before posting, consider who will see these and whether you can share them with a smaller audience. Be considerate when passing on photos of friends - ask whether they would want that information shared.", "label": 1}
{"text": "Short for Ad Hoc On-Demand Distance Vector, a routing protocol for ad hoc mobile networks with large numbers of mobile nodes. The protocol's algorithm creates routes between nodes only when the routes are requested by the source nodes, giving the network the flexibility to allow nodes to enter and leave the network at will. Routes remain active only as long as data packets are traveling along the paths from the source to the destination. When the source stops sending packets, the path will time out and close.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "A couple of days ago, I received an e-mail from Iran. It was sent by an analyst from the Iranian Computer Emergency Response Team, and it was informing me about a piece of malware their team had found infecting a variety of Iranian computers. This turned out to be Flame: the malware that has now been front-page news worldwide.\nWhen we went digging through our archive for related samples of malware, we were surprised to find that we already had samples of Flame, dating back to 2010 and 2011, that we were unaware we possessed. They had come through automated reporting mechanisms, but had never been flagged by the system as something we should examine closely. Researchers at other antivirus firms have found evidence that they received samples of the malware even earlier than this, indicating that the malware was older than 2010.\nWhat this means is that all of us had missed detecting this malware for two years, or more. That’s a spectacular failure for our company, and for the antivirus industry in general.\nIt wasn’t the first time this has happened, either. Stuxnet went undetected for more than a year after it was unleashed in the wild, and was only discovered after an antivirus firm in Belarus was called in to look at machines in Iran that were having problems. When researchers dug back through their archives for anything similar to Stuxnet, they found that a zero-day exploit that was used in Stuxnet had been used before with another piece of malware, but had not been noticed at the time. A related malware called DuQu also went undetected by antivirus firms for over a year.\nStuxnet, Duqu and Flame are not normal, everyday malware, of course. All three of them were most likely developed by a Western intelligence agency as part of covert operations that weren’t meant to be discovered. The fact that the malware evaded detection proves how well the attackers did their job. In the case of Stuxnet and DuQu, they used digitally signed components to make their malware appear to be trustworthy applications. And instead of trying to protect their code with custom packers and obfuscation engines—which might have drawn suspicion to them—they hid in plain sight. In the case of Flame, the attackers used SQLite, SSH, SSL and LUA libraries that made the code look more like a business database system than a piece of malware.\nSomeone might argue that it’s good we failed to find these pieces of code. Most of the infections occurred in politically turbulent areas of the world, in countries like Iran, Syria and Sudan. It’s not known exactly what Flame was used for, but it’s possible that if we had detected and blocked it earlier, we might have indirectly helped oppressive regimes in these countries thwart the efforts of foreign intelligence agencies to monitor them.\nBut that’s not the point. We want to detect malware, regardless of its source or purpose. Politics don’t even enter the discussion, nor should they. Any malware, even targeted, can get out of hand and cause “collateral damage” to machines that aren’t the intended victim. Stuxnet, for example, spread around the world via its USB worm functionality and infected more than 100,000 computers while seeking out its real target, computers operating the Natanz uranium enrichment facility in Iran. In short, it’s our job as an industry to protect computers against malware. That’s it.\nYet we failed to do that with Stuxnet and DuQu and Flame. This makes our customers nervous.\nThe truth is, consumer-grade antivirus products can’t protect against targeted malware created by well-resourced nation-states with bulging budgets. They can protect you against run-of-the-mill malware: banking trojans, keystroke loggers, and e-mail worms. But targeted attacks like these go to great lengths to avoid antivirus products on purpose. And the zero-day exploits used in these attacks are unknown to antivirus companies by definition. As far as we can tell, before releasing their malicious codes to attack victims, the attackers tested them against all of the relevant antivirus products on the market to make sure that the malware wouldn’t be detected. They have unlimited time to perfect their attacks. It’s not a fair war between the attackers and the defenders when the attackers have access to our weapons.\nAntivirus systems need to strike a balance between detecting all possible attacks without causing any false alarms. And while we try to improve on this all the time, there will never be a solution that is 100 percent perfect. The best available protection against serious targeted attacks requires a layered defense, with network intrusion detection systems, whitelisting against known malware and active monitoring of inbound and outbound traffic of an organization’s network.\nThis story does not end with Flame. It’s highly likely there are other similar attacks already underway that we haven’t detected yet. Put simply, attacks like these work.\nFlame was a failure for the antivirus industry. We really should have been able to do better. But we didn’t. We were out of our league, in our own game.", "label": 1}
{"text": "We are living in an age of unprecedented language creation. Between the explosion of languages on the JVM and the new native languages, we find ourselves with a happy surfeit of very interesting choices. These options are not just the toy creations of comp-sci undergraduates, but sophisticated products with extensive libraries and active communities. Where they tend to be weak, however, is in tooling. And unfortunately, for many language developers, tooling is a metaphor for the coding front end: They strive to create editor plugins to provide basic syntax assistance. The more important support for debugging is often consigned to the use of\nprintf-like statements to dump\ntrace statements and variables' contents to the console.\nWhite PapersMore >>\n- Informed CIO: SDN and Server Virtualization on a Collision Course\n- InformationWeek 2013 Strategic Security Survey\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Agile for Safety Critical Systems: Project Management Practices\nI have always found this substitution of\nprintf for debugging to be a profoundly wrong conflation of two concepts. Yet, because we've all had the experience of using\nprintf or its equivalents to help chase down bugs, we tend to go along with the proposal. Some well-known developers even proclaim their preference for\nThere are multiple aspects of\nprintf statements that make them very poor substitutes and, in fact, at times dangerous tools.\nLocation. Martin advises \"judiciously placed print statements.\" Well, if you're in a serious debugging mode, judiciously placing\nprintf is a very difficult thing to do. It implies some strong knowledge of the nature of the cause of the defect you're chasing. My experience is that, frequently, you get the first attempt at\nprintf wrong, and then must start to guess where else to place the statements. Sometimes, it's not even guessing: You need to put them at several upstream points to coarsely locate where a variable unexpectedly changes values. Finally, when you get the right location, you must then add new statements to track down why the variable is changing. It's a mess that brings me to the second point.\nTime cost. Every\nComplexity. While conceptually nothing is simpler than dumping a variable to the console, in fact, it's no trivial matter. This is particularly true of data structures, especially those containing pointers. Now, the\ndump statement is useful. Debuggers handle this transparently and allow you to walk lists and arrays with no difficulty.\nClean up. Congratulations, you found the bug! Now, it's time to clean up your\nIn almost every dimension, the dumping of variables to the console is an inferior alternative to using the debugger. It takes just as long, if not longer, to find defects, and the practice inserts detrimental artifacts into the codebase.\nWhen I hear developers say that they're happy debugging with", "label": 1}
{"text": "Growing Mobile Phone Use Hurts Energy Security, IEA Says\nWith increased mobile phone and computer use, says the International Energy Agency, comes increased energy use. Unplugging mobile devices once they're charged, and disconnecting a not-in-use charger from the wall, are just two ways to help, according to Nokia.\nBy 2010 there will be more than 3.5 billion mobile phone\nsubscribers, 1 billion personal computers and 2 billion televisions in\nuse around the world, according to the International Energy Agency\n(IEA), an energy policy advisor to 28 member countries.\nAs the numbers of these devices increase, so, too, does the demand for energy.\nPresenting a new IEA publication, \"Gadgets and Gigawatts\" in Paris on May 13, IEA Executive Director Nobuo Tanaka remarked that \"despite anticipated improvements in the efficiency of electronic devices, these savings are likely to be overshadowed by the rising demand for technology in OECD and non-OECD countries.\"\nThe OECD, or the Organization for Economic Co-Operation and Development, was established in 1961 and consists of 30 democratic member countries that discuss answers to common problems and coordinate domestic and international policies.\n\"Without new policies, the energy consumed by information and communications technologies as well as consumer electronics will double by 2022 and increase threefold by 2030 to 1,700 Terawatt hours (TWh). This will jeopardize efforts to increase energy security and reduce the emission of greenhouse gases,\" the IEA wrote in a statement on the book launch.\nIn \"Gadgets and Gigawatts,\" the IEA reports that electricity consumption from residential information and communications technologies, and from consumer electronics, can be cut by more than half through the use of available technologies and processes.\nNokia, the largest mobile device manufacturer in an industry of more than 4 billion users, according to Kirsi Sormunen, Nokia's vice president of environmental affairs, is among the many companies taking steps toward being an environmental steward - which she said has been an interest for Nokia since long before green became trendy.\n\"It's in Nokia's DNA,\" Sormunen told eWEEK. \"And I should know, I've been at Nokia for 28 years myself!\"\nWhile companies throughout the supply chain need to do their parts, Sormunen says there are simple steps end-users can take as well. For example, unplugging the charger from the wall when it's not in use.\nAccording to data from Nokia, the amount of energy lost when a charger is plugged in but not connected to a phone is equivalent to two-thirds of the energy used by a fully charged device.\nAnother energy-saving tip, particularly for those who tend to charge their devices overnight, is to unplug the charger and device as soon as the device is finished charging.\nIn a market of 4 billion devices, Sormunen says: \"There are 1 billion users using our devices. If just those people would unplug the charger, it would provide enough energy [to power] 100,000 homes.\"\nNokia additionally reports that if all 3 billion people using mobile phones around the world recycled one mobile phone a year - the presumption being that each of us has an old phone or two in a drawer - those devices could save 240,000 tons of raw material and reduce greenhouse gases by an amount equivalent to taking 4 million cars off the road.\nDecreasing the brightness of the phone's screen, turning off Bluetooth and WLAN capabilities when not in use, and turning off or disabling sounds on keypads are also ways to increase the energy efficiency of a mobile device.\nThe IEA's \"Gadgets and Gigawatts,\" in another environmentally friendly move, is additionally available in a PDF format.", "label": 1}
{"text": "A \"SYN Attack\"\nis a Denial of Service (DoS) attack that consumes all the resources on your machine, forcing you to reboot. Denials of Service attacks (attacks which incapacitate a server due to high traffic volume or ones that tie-up system resources enough that the server cannot respond to a legitimate connection request from a remote system) are easily achievable from internal resources or external connections via extranets and Internet. Enabling TCP SYN Cookie Protection will help to eliminate the problem.\nEdit the sysctl.conf file (vi /etc/sysctl.conf) and add the following line:\n# Enable TCP SYN Cookie Protection\nnet.ipv4.tcp_syncookies = 1\nOnce the configuration has been set, you must restart your network for the change to take effect.\nThe command to restart the network is the following:\nTo restart all network devices manually on your system, use the following command:\n[root:~ ]# /etc/rc.d/init.d/network restart", "label": 1}
{"text": "Firefox 16, a treat for developers http://t.co/cnd27CzT\nTop 5 security Myths about Linux; and their realities\nLinux, unfortunately has been long surrounded by myths. Despite the speedy adoption of Linux as mainstream operating systems for enterprises particularly, the common misconceptions about Linux seem to continue. The post enlists five traditional myths about Linux Security and attempts to debunk each; discussing real facts.\nThere exist mainly two schools of thoughts regarding security of Linux. One group that assumes ‘ Linux is Virus Proof’ and the other, advocating a completely contrary thought i.e. ‘Linux is more insecure (when compared to contenders), as it makes source code available to everyone’. Let’s investigate in detail.\nMyth 1: Linux is insecure, as it makes source code available to everyone.\nReality: While this is true that Linux makes Source code available to everyone to view and inspect; it is this open source nature that makes Linux superior to any proprietary OS in terms of security. As the source code is available to anyone, thousands of develops around the world scrutinize the source code for security pitfalls. Imagine, even at this very moment number of people are reading and making the code better. It is far more easier to spot and fix security issues on Linux than on any closed-source platform. Additionally, if any security vulnerability is found on closed source platform, it cannot be readily altered to make the software secure. On the contrary, in case of open source software, if any security hole is discovered patches are created as quickly as possible (usually within hours) therefore the security flaw doesn’t last for long enough to be exploited.\nWhen asked about the lack of viruses known for Linux platform, the proprietary camp claims that Linux is not very popular to have viruses. This comprises another common Myth. Interestingly, it’s not only the proprietary camp to believe that Linux lacks virus because of its minimal market share, alot of literature on the internet and in books we find this misconception.\nMyth 2: Linux lacks virus because it is not very popular.\nMany say that the purpose of virus writers is to bring massive destruction. As Linux does not run on as many computers as MS’s Windows does, virus writers only target Windows to damage more and more stations. While this might not be completely wrong, it’s not completely true too.\nReality: Linux might not run on many desktop computers, BUT it runs on most computers in very important places. All super computers run Linux. Many notable governments have approved policies moving governmental computers to Linux. Additionally there was a huge enterprise shift from Proprietary OS to Linux in last 2000s recession. That means Linux, too is a very charming opportunity for hackers; rather hackers would more likely to write virus for Linux than for Windows if they want to bring even more destruction (especially destruction in terms of quality then quantity!). Therefore, the myth can easily be ruled out. Another reason that the proprietary camp gives for lesser known viruses for Linux is that Linux is an advanced OS and can only be used by professions who know how to protect their systems.\nMyth3: Linux is for experts who know how to protect their system and therefore Linux does not get viruses and it generally thought as secure\nIt is also a common misconception that because Linux is for experts, they know well how to deal with viruses. On the other hand, Windows, as being a simpler system is usually used by even non-technical people who are naive enough to get virus and destroy the whole system.\nReality: The concept ‘ Linux is for experts’ is itself a myth and quiet out dated now. Linux is now one of the friendliest OS out there that can be used by novice and experts both. There are Linux based computers dedicated for elderly (heard of the Wow computer?). So to say that Linux is for experts is not true. Linux is for everyone. Consequently to say, the Linux doesn’t get virus because of its technically strong to defend OS is wrong.\nWhat makes Linux secure is neither its lack of popularity nor its technically strong user base. It is the strong architecture of Linux which makes it secure. On Linux systems users do not have “root” privileges; instead they possess lower-level accounts. As a result even if a Linux system is somehow compromised, the virus shall not have root access to bring about any major damage to the system. Windows supports exe files, a format in which virus are transmitted. Linux, on the other hand does not support .exe files. Linux uses configuration files in place of registry files hence closing this door for virus. For the Linux servers now, Linux servers employ several level of security. Linux servers are updated more often. To conclude, it’s the Linux architecture that is different from that of contending proprietary OS which makes it secure. That is to say if Linux is adopted in main stream desktop computing, I am sure that Linux will prove to be more strong and less incline to get virus than contending OS.\nDoes that mean Linux is virus free? This comprises of our third Myth.\nMyth 4: Linux is virus free\nReality: while Linux is very secure and superior to its proprietary counterparts, it’s not virus free. There are a number of viruses known for Linux. I have compiled popular known viruses in this post. It may be noted that all most all the viruses known for Linux are non-destructive in nature (but not non-existent)\nMyth 5: On Linux system you don’t need an Anti virus.\nReality: Yes indeed it’s very much true that when you are running Linux OS you are secure. Never the less one must realize that no OS is 100% secure. While this might not be very important for desktop/home users; enterprise sector which use Linux, may require anti-virus. Occasional scanning, backing up data and checking your system for malicious software does not bring harm to anyone. This does not mean you need to spend substantial amount of cash on expensive anti- virus softwares. Any free or open source and free antivirus would do justice to your security!\nLike us on Facebook\nThis week Top Posts\n- Top Things to do After Installing Ubuntu 13.04 ‘Raring Ringtail’ : Ubuntu 13.04 Raring Ringtail final is almost out. The final release it scheduled for release on Apri...0 comment(s) |\n- Howto: Upgrade to Ubuntu 13.04 Raring Ringtail from 12.04, 12,10 | Desktop & Server : Updated 05-04-2013: Ubuntu 13.04 Raring Ringtail will be released Soon, If you have ubuntu 12,10, 12...0 comment(s) |\n- Install lamp with 1 command in Ubuntu 12.10, 13.04 Raring Ringtail & LinuxMint13 : Updated: 10/09/2012 :LAMP (Linux, Apache, MySQL and PHP) is an open source Web development platform ...0 comment(s) |\n- Scan Your Home Network With Nmap : Who should read this article? Everyone who is interested in computer security and computer networkin...0 comment(s) |\n- How to use Remote Desktop in Ubuntu : Sometimes, we need to access our computer from other locations when we’re not at home and such. This...0 comment(s) |\n- Configure conky-Lua in Ubuntu (12.10 & 13.04 Raring Ringtail), Fedora, debian and LinuxMint | Howto Conky : Updated 05-04-2013: Conky is a free, light-weight system monitor for X, that displays any informatio...0 comment(s) |\n- Secure File from Removal in Linux and Unix\n- How to Install Nginx on FreeBSD 9.x\n- Create a Launcher in Ubuntu Using Bash\n- Scan Your Home Network With Nmap\n- Steganography- Hide Your Files Inside An Image in Linux\n- Unix/Linux File Recognition. Did You Know?\n- Migrate from MySQL to MariaDB in FreeBSD\n- Connect Your Android Galaxy Tablet to Ubuntu via USB\n- ElementaryOS Beta 1 and 2 Comparison and Review\n- Introduction to the Linux Command Line\nCopyright © 2008-2013 Unixmen.com .", "label": 1}
{"text": "Lesson 6 - Chapter Review\nThis is an ongoing series to dissect the PhreakNIC v3.0 code, which\nseen at http://www.phreaknic.org/phreaknic.txt.\nHello class, been studying your current events? PGP has been\nin the news\nrecently, so this is an excellent opportunity to learn how a PGP key is put\ntogether. Evidently PGP versions 5.5 and higher have a security\nvulnerability. If a malicious type could manipulate a PGP key in the public\nkey directory, they could decrypt the victim's encoded messages.\nHere are a couple links if you'd like to read more about it:\nOf course, hint-junkies that we are, we wonder, \"Hmmm, if PGP has\nhole, does that mean we could use it to crack the PGP message in the\nPhreakNIC v3.0 Code?\" Could there be a ray of light, a glimmer of hope?\nAlas though, our PhreakNIC Code message has been encoded with PGP v2.6.2, so\nit's still secure. Curses!\nGetting back to our review, let's go over what we've solved so far . . .\nThe PhreakNIC v3.0 Code can be broken down into five sections:\n(1) The first line of numbers\n(2) A few lines of \"poem\" gibberish\n(3) A rotated PGP message\n(4) A rotated UUencoded message\n(5) The last \"bkkbb\" line\nHere's what we've deciphered in each of those sections:\n(1) The first line: Hexadecimal numbers that translate to\nwhich when converted via ROT-13 decoding say:\n\"Nice start. Now\nit gets tough.\"\n(2) The gibberish after, a 9-line poem rotated via ROT-13.\nEach sentence an\nanagram, with some of the letters set off with () and  marks. But we\nhaven't solved all of it yet.\n(3) A short PGP message, again rotated by ROT-13. We've got\nproperly, but still don't know whether we need to make a key, or find one.\n(4) A short UUencoded message, rotated by ROT-13. Once unrotated,\ntweaked into the proper format, it decodes to a file called un-uu-me.txt.\nThat file turned out to contain a series of columns of 5-character blocks,\nwhich, when decoded, pointed to information about the CIA's Kryptos monument.\nAn interesting journey, but not relevant to the rest of the Code.\n(5) The last line, the \"bkkbb\" section. It's a representation\ncode, which translated to ASCII characters: \"end here\".\nSo, we've solved sections 1, 4, and 5. Which leaves section\n2 (the poem) and\nsection 3 (the PGP message).\nHow do we get into that PGP section? We've solved everything\nelse, and all\nthat's left is the poem, so something in that poem must either tell us how to\nBUILD a key, or else the poem tells us where to FIND a key.\nHow've you been doing on those anagrams? Here's what we found so far:\nThe earnes[t][se]crets sho(n)e.\n(O)ne hears sat[i]re. --> ??\nAhem - r(e)ally rag Satan. --> They are all anagrams.\n(A)(T)M of Hel(l). --> All of them.\nEvil nos[e]energy. --> Every single one.\nO, the (C)IA net lunacy. --> They contain a clue.\nObey luser ca[m]. --> ??\nP[h]one far-fe[t]ched[r]oot text[.] --> For the next part of the code.\nA data-[l]in[k] g[r](u)mbles on the cloud(.) --> ??\nAs for the letters in () and  marks:\n: t se i e m h t r . l k r\n(): n O e A T l C u .\nWhen we did a frequency distribution on the whole lot:\nThe most common letters E and T, followed by R and L. Well,\nE and T *are*\nthe most commonly-used letters in the English language, so, keeping in mind\nthat it's a small sample, it does suggest an english frequency distribution,\nso it's worth assuming that they're anagrams, too. Lots of letters there\nthough, so lots of possible words.\nWe're getting deeper into JonnyX's head, and closer to the end-game\nCode. But there's even more nifty state-of-the-art stuff ahead, and a *very*\ninteresting twist coming up. Not to mention even *more* bad poetry <grin>.\nNext installment: Digging deeper into the poem!\nSee you next time,\n\"I'm a gamer. It's what I am. It's what I do.\"", "label": 1}
{"text": "In this whitepaper, Yahoo engineers Konstantin Shvachko, Hairong Kuang, Sanjay Radia, and Robert Chansle look at HDFS, the file system component of Hadoop. While the interface to HDFS is patterned after the UNIX file system, faithfulness to standards was sacrificed in favor of improved application performance.\nAbstract—The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of HDFS and report on experience using HDFS to manage 25 petabytes of enterprise data at Yahoo!\nA tip of the hat goes to the new Systems We Make blog, who seek to chronicle the growing boom of distributed systems being built in both academia and industry.", "label": 1}
{"text": "Networks are messy. Although they can be made to look neat and tidy by holding all the gear in rack mounted cabinets with serious cable management makeovers, they are still comprised of small islands of hardware each running its own proprietary software and firmware, often on proprietary silicon. For home users this isn’t really an issue, but for large government and business networks things get complicated and convoluted quickly. Especially in the case of internal networks used by governments that need to be as locked down as possible, changing even one switch, server, or connected device on the network is a tedious (and expensive!) process of rewriting security rules on a each and every hardware device.\nEach hardware device (be it a switch, router, server, or firewall) operates as its own isolated island which requires individual configuration. Seeing the shortcomings of such a setup, researchers and startup companies like Nicira have started to develop open software control systems under a coined term of “software defined networking” (SDN). Stuart Miniman defines SDN as “a model for network control, based on the idea that network traffic flow can be made programmable at scale, thus enabling new dynamic models for traffic management.” Similar to the way virtualization can be used to host many (virtual) computers on one physical piece of hardware, these virtualized networks could allow companies to run multiple network slices off of a single physical network.\nThis is a level of control and programmability that is not currently possible due to network hardware vendors using proprietary software in all their devices (Cisco’s IOS for example). SDN takes the proprietary code out of the equation, and — using open software on all the routers, switches, firewalls, and other network devices — separates the data and control planes (the packets and the logic that determines what to do with those packets). The network hardware is then connected and mapped out in software, and network admins are able to manage the entire network from a software interface. They are also able to specialize their network and add new functionality by writing their own code and deploying it across the network.\nOne of the most important benefits of SDN is that commodity hardware can be used, instead of specialty hardware from specific manufacturers. Removing or relocating devices on the network would involve a few mouse clicks in a GUI rather than physically switching Ethernet cables and reconfiguring all the appropriate network devices. Martin Casado, CTO of Nicira (who is one of the companies developing SDN technologies) said that “we’re virtualizing away this physical fabric, and because now we have a virtual layer, you can do anything you want with it. Because of this virtualization, the network can be fashioned from any and all compatible hardware, and can be controlled, transformed, and secured from a software interface rather than from configuring each device individually.\nThere is talk around the web that SDN will spell the end for special network hardwar companies like Cisco as well as eliminate the jobs of network operators. While entirely possible, such an event is not going to happen overnight. Cisco is not likely to give up without a fight, and at this point it still has a chance to react and adapt to this new technology. The reduction in network operator IT positions is possible as well but this virtualization technology is going to open up its own field of study as well, which should lead to positions maintaining SDN. Especially while software defined networking is still a new technology, businesses are going to need their IT personnel.\nNetworking giant Cisco has recently responded to rumors of SDN killing its business by stating that some customers do not want programmable networks. Also, for those customers that do want the flexibility of SDN, it has funded and plans to acquire network startup company Insieme. Insieme is reportedly working on a line of programmable network switches that support OpenStack as the SDN abstraction layer. The CTO of Cisco has been quoted by Network World in stating “Networking is about to be reinvented and Cisco will do that reinvention of networking.”\nIn the end, the idea of a truly modular virtualized network that allows control from a software GUI is really cool. It is a big shift in networking to a programmable, open, and modular network controlled via software software that will make managing large scale networks much easier.", "label": 1}
{"text": "Security 101: E-mail Encryption with PGP and GPG\nPGP and GPG ensure e-mail stays between the sender and its intended recipient.\nWhen you send a cleartext, unencrypted e-mail, you are saying \"I don't care who reads the contents of this message, I don't care if someone possibly alters the contents, and I don't care if someone else pretends to be me.\"\nDoubtless it is not your intention to say these things, but it is an unfortunate fact of life that this is the result.\nOrdinary cleartext e-mails can be intercepted and read by anyone with access to the wires between you and your recipient. This could be snoopy sysadmins, or anyone who has successfully compromised a server, router or network. Sometimes getting onto a network is easy unsecured, poorly-secured and rogue wireless access points are big fat red welcome mats for all the wrong people.\nDid you know that inside jobs, just like in old-time industries like retail and manufacturing, represent the largest percentage of thefts and unauthorized snooping in computer networks? The numbers given vary, but it's safe to say it's a sizable majority.\nThe easiest and best way to secure your e-mail transmissions from end-to-end is to use Pretty Good Privacy (PGP) or its open source/free of cost sibling, Gnu Privacy Guard (GPG). PGP/GPG depend on encryption/decryption key pairs. You have a private key, which you guard zealously and never ever let anyone else get their hands on. Your public key can be distributed freely; many people even post their public keys on Web sites.\nThe way it works is genius-simple: Anyone who wants to send a message to you encrypts it with a copy of your public key. Then you decrypt it with your private key. Your message is completely protected in transit and immune to eavesdropping and altering.\nGPG works on any system on which it can be successfully compiled, which is most Linux and Unix systems. You may also compile and run it on Windows. Windows and Mac OS X users will probably want something a bit easier, such as GPG4Win and Mac GPG.\nPGP costs money and comes in many different flavors. It has support, as well as some nice management tools. PGP and GPG are completely compatible, and in fact share the same code base. So you can encrypt and decrypt messages freely between the two programs. It's the best of all worlds a very easy way to protect your e-mail with very strong encryption.\nThis article was first published on ServerWatch.com.", "label": 1}
{"text": "By: Logan Pierce, editor-in-chief\nIn the latest installment of the Great Issues Lecture Series, Linda Whaley, director, Health Information Technology Program, addressed students, faculty and staff regarding personal health information.\nOne thing Whaley considers both good and bad is the constant policy revisions that take place within the health care industry. “The changes sometimes make my job difficult,” Whaley said, “I’m constantly revising my slides. What I tell you today may be different next week.”\nTracking health information\nWhaley listed several things which are a part of personal health information, including hospital registration and admittance, doctor’s office visits, accessing urgent care clinics, and ambulance rides.\nMedical history goes beyond where you are treated. Physical exams, lab tests, medical imaging and other tests are also recorded.\nWhich begs the question, who has access to such personal information? A surprisingly large number of people, the most obvious being public, state and federal health agencies and health care providers.\nBeyond health care\nThird party payers, i.e. insurance companies, can access a client’s medical records to ensure that the paid procedures have been performed.\nLaw enforcement has a limited access to medical records. Other entities, such as lawyers, need the medical records of their clients if they’re suing as the result of an injury, or when filling out an application for life insurance.\nAnd, of course, individuals have the right to access their medical records. Care should be exercised when attempting to retrieve a hard copy. Depending on the amount of pages, printing fees could cost hundreds of dollars. To save money, individuals should select only those records relevant to their needs.\nAnother option is to request electronic copies of records. While not all facilities keep electronic medical records, government incentives are being pushed to increase these numbers. “Most physicians are migrating to electronic health records,” Whaley said, “$3.1 billion has gone to hospitals who adopt electronic health records.”\nThe benefits of digitally retrieving medical information include reduced paperwork, the rapid sharing of information, and the reduction of unnecessary tests.\n“Security is the downside to electronic health records,” Whaley said, “There’s lots of breaches.”\nThe Department of Health and Human Services’ (HHS) website has a page detailing large breaches of information; breaches which affect 500 or more individuals. Whaley referred to this as the “wall of shame.”\n“You can always get a wealth of information from government websites,” Whaley said, “Oklahoma has only four entries on the wall of shame.”\nOne of the most extreme breaches came from Blue Cross Blue Shield of Tennessee. They received a fine of $1.5 million from HHS after 57 unencrypted computer hard drives were stolen from a leased facility. The hard drives contained the names, social security numbers, dates of birth, diagnosis codes and health plan identification numbers of more than 1 million individuals.\nThe Secure Medical Records Transfer Network (SMRTNET) and their website, smrtnet.net, work to protect Oklahomans from medical identity theft, which is the fastest growing type of identity theft. Their network encompasses 25 hospitals and 60 clinics in Oklahoma, with more than 2,500 users.\n“New [government] guidelines are being enacted,” Whaley said, “Encryption is not a requirement, but it is highly encouraged.”\nOrganizations like SMRTNET are making strides to prevent identity theft, while striving to follow the Health Information Management (HIM) goal “to optimally achieve the accuracy, availability and protection of health information for all.”", "label": 1}
{"text": "The recent volcanic eruption at Eyjafjallajökull in Iceland, which caused major air travel disruptions across Europe due to the resulting ash cloud, is being exploited by cybercriminals to infect users. Searching for information or images related to the event poses an increased risk of leading to malicious pages.\nOn 14 April 2010, the Eyjafjallajökull volcano in Iceland erupted for the second time in 2010, leading to the formation of an ash cloud that is unusually rich in glass particles. The eruption is still on-going and experts claim the volcano might produce ash for weeks to come.\nBecause the ash plume has quickly spread across Europe, many countries were forced to completely or partially suspend air traffic over their territories. At the moment, all major European airports are closed down and thousands of travelers are stranded, in what might become the most severe air travel disruption in history.\nAs the event is affecting flights all over the world, it is understandable that a lot of people use the Internet to keep informed about new developments in real time. A quick look on Google Trends reveals that \"volcano iceland,\" \"uk airspace\" or \"flights canceled\" are amongst the hottest search topics in the USA at the moment.\nUnfortunately, cybercrooks are also paying attention to what people are searching for and waste no opportunity to exploit it to their advantage. By employing artificial page rank inflation techniques, collectively known as black hat search engine optimization (BHSEO), they succeed in pushing malicious links to the top pages of search results.\nAt the moment, a predictable search query such as \"Iceland volcano pictures\" produces malicious results beginning with the second page. These links take users to web pages displaying fake security alerts, that try to convince them to download and install fake antivirus programs on their computer.\nCalled scareware or roguware, such applications produce bogus reports about fictitious infections on the users' systems, in an attempt to convince them to pay for a fix. Such scams usually result in users losing their money and compromising their financial information.\nGoogle is making significant efforts to counter these attacks and tag the fake search results as malicious through its Safe Browsing service. However, as demonstrated by past experiences, this is an endless game of cat and mouse in which cybercriminals currently have the lead.\nBecause of this, Internet users are strongly advised to rely on additional forms of protection, such as capable antivirus programs or browser security extensions. Practicing extra caution when it comes to visiting links listed on Google search result pages is also a must - get your news only from trusted and reputable sources.", "label": 1}
{"text": "A botnet is a network of zombie computers controlled by a single entity. The term is a portmanteau of the phrase \"Robot Network\". Usually, the zombies in use of a botnet are compromised computers running the Microsoft Windows operating system that have been infected with some sort of malware. These computers communicate with other botnet machines via the Internet. Most botnets are distributed-design systems, with the botnet operator giving instructions to only a small number of machines. These machines then propagate the instructions to other compromised machines, usually via IRC. The distributed design prevents the discovery of the controlling computers. The anonymity that a botnet affords often helps the user avoid detection and possible prosecution.\nBotnets are effective in performing tasks that would be impossible given only a single computer, single IP address, or a single Internet connection. Originally, botnets were used for performing distributed denial of service attacks. However, most modern webservers have developed strategies to combat such DDoS attacks, making this use of a botnet ineffective. Additionally, many counter-DDoS strategies blacklist the IP addresses of attacking computers, thus exposing the botnet's machines. As the spam market has become profitable, and ISPs usually discontinue service to subscribers who send spam, botnets were found to be an effective resource for sending spam. Furthermore, many compromised computers contain address books of email addresses which can be incorporated into the list of addresses to send spam to. Zombies that are not actively sending spam at any point in time can be configured to scrape the web looking for new email addresses to spam, adding further value to the botnet.\nA secondary objective of the botnet is to find and compromise additional computers. While this is not considered a primary objective in and of itself, the expansion of the botnet via assimilation of new computers helps it perform the primary objectives more efficiently. Thus, this secondary objective is often the bulk of a botnet's tasks. Many computer networks, especially those using Microsoft Windows computers running the default settings, inherently trust other computers on the same network. Thus, a single compromised machine on such a network constitutes an attack vector against other machines on the network. Other secondary botnot objectives include website advertisement clicking, web browser toolbar installations, keylogging, and social bookmarking poll manipulation.\nSecurity Terminology Questions", "label": 1}
{"text": "Business Case for Open Standards\nBy Erik Sliman\nCreated April 30, 2002\nOpen standards begin when a collaboration of interested parties results in a consensus on specifications for implementing common requirements. They permit open access for anyone desiring to utilize the results in a way that enables conformity across implementations. While open standards describe openness in both the standards setting process as well as access to the specifications, industry de facto and government-led standardization alternatives are less open. The choice to use open standards over the alternatives can improve one's ability to realize common objectives.\nYou can optimize your options through the use of open standards, improving the choices that help you to reduce risk, implement durable solutions, obtain flexibility and benefit from quality. Since multiple vendors can support open standards, you can spread the risk out among them instead of on one proprietary vendor, reducing overall risk related to dependency on and support for the technology. This also leads to increased durability of options, as open standards are able to last longer than limited vendor solutions. Vendors come, and vendors go, but open standards, transcending them all, remain durable. With vendors competing to implement and help you use open standards, your vendor options are more flexible. In a market where accessibility to open standards are high, this leads to higher quality and lower pricing, key differentiators in an environment where conformity to open standards sets the foundation.\nThe more we use and deploy open standards, the greater our vendor independence. Open standards decrease the cost of changing vendors by decreasing the costly components of change, resulting in improved and increased vendor options.\nInteroperability results when components are able to work together to complete a process. Open standards, by helping to define component interfaces, increases interoperability. This leads to simpler, repeatable and quicker integration efforts.\nBy helping those involved in using open standards to use common terminology, communication is improved when organizing, planning and implementing open standards based technology.\nOpen standards help to consolidate competing standards, increasing the aggregate pool of resources available for using them without the cost inefficiencies of a single vendor de facto. For suppliers, this helps to consolidate a larger customer base. Instead of picking the portion of customers using the proprietary standards you are equipped to support, you can instead offer products and services to a larger consolidated base of users. For users, this pools vendors together, increasing competition and price pressures, yielding better quantity and quality of vendor options. This also results in consolidated pools of people skills. Instead of looking for specialists in the proprietary standard you use, you can choose among a larger base of consolidated specialists empowered to support multiple vendors using the same open standard.\nBy reducing costs, speeding time-to-market, and increasing market adoption and acceptance, products and services developed around open standards benefit from a higher Return on Investment (ROI). They benefit from lower barriers to market entry created through decreased customer risk with vendor selection as the association of support and durability with the individual vendor is transferred instead to the pool of vendors supporting open standards.\nObtaining the advantages of open standards begins by declaring it a high priority, considering it in all your options, including it in your planning, and improving your processes to use open standards. Initial steps you can take to lead your organization include opening dialog, increasing participation in open standards processes and raising awareness.\nOpen Standards Introduction\nOpen Standards is the concept of people working together openly to collaboratively develop solutions for addressing common requirements and goals.? Often they work together in committees through open standards organizations, such as the Internet Engineering Task Force (IETF) or the World Wide Web Consortium (W3C).?\nOpen standards permit everyone to utilize the resulting specification to build infrastructure and various solutions.? This creates the opportunity for unlimited vendors competing on the quality of their implementations and their ability to meet the diverse needs of the end-users in the markets utilizing the open standards.?\nFor standards requiring communication or interconnectivity, an open standard can help to ensure that the various implementations by the users can interoperate and integrate.? By using the Internet's TCP/IP communications protocol, for example, virtually any component on a network can talk to any other component, creating an infrastructure for collaborating and coordinating resources across the globe.?\nTo be sure, open standards are not the only means of obtaining standardization.? Whereas open standards exhibit openness in the collaborative efforts to create the standards, and access to the resulting specs and technology necessary to implement those specs, there are other types of standards such as industry de facto and government.?\nIndustry de facto standards often require the adoption of proprietary technology and may require the payment of licensing to a sole or few providers of that technology.?? People often use them because they are popular, increasing the user's ability to interoperate and collaborate others.? Where the benefits of standardization are high, de facto standards can be very difficult for competitors to unseat; yet, in the absence of open standards, continue to abound.?\nGovernment standards can be set through several means, including direct dictates in the form of laws, or mandates via regulatory bodies carrying the force of law.? Sometimes, government agencies may also lead efforts for voluntary compliance, and may even partner with private, public and commercial parties.? While open standards do not necessarily preclude government participation, nor do they require it, and should not be limited by it.?\nOpen standards bodies can include participation from government and industry.? Ideally, they are free to operate with the independence necessary to serve the principles and objectives set forth in their own charters.? Differentiating an ideal open standards body from similar constructs is the ability to permit participation while inhibiting dominance inherent in political, financial or market power.? Its goal is to balance the interests in order to support objectives while adhering to principles.?\nFor decision makers in charge of guiding and influencers able to impact an organization's technical direction, possibly by choosing vendors, products or technologies, it can quickly become challenging to sort out the options.? One needs not only to assess the degree of reliance on proprietary versus open standards each choice can bring, but the impact the decision will have on the organization.?\nAs one begins to take hold of the dynamics of these decisions, and how open standards can play a role, options can become more clear and simple, and commitments more resolute.? Increasing the transparency and understanding of open standards can not only help one realize better decisions, but can help obtain the reassurance that comes from discerning how open standards create improvements.?\nOptimizing options is about giving you more and better choices for accomplishing your goals.? Choices that help you to reduce risk, obtain durable solutions, acquire flexibility and benefit from quality optimize your path to success.? If open standards increase access to these options, then they are an empowering means to help you achieve a better end.?\nOpen Standards increase options that lower risk.? When selecting a proprietary solution, you are often putting your chips in one basket.? You risk that the vendor will be around for awhile, that they will choose to continue to support the technology you implemented, they will improve their product and their improvements will match the growth in your needs.? You also risk interoperability issues.? Will your suppliers, customer, partners and other related entities integrate well?\nOpen standards can reduce this risk in many areas.? Since, by definition, more than one supplier supports them, you spread your chips out among those implementing the standards.? This can increase the probability of long-term availability of support and continuous improvements, and can even open doors to those improvements being more applicable due to the increased representation of interests inherent with open standards.? With broad support and increased vendors behind it, it is easier to achieve interoperability needed to integrate your internal systems with each other, your suppliers, customers and partners.?\nOpen standards, such as the Structured Query Language (SQL), have proven to have higher durability over time than proprietary solutions.? Whereas individual vendors of proprietary solutions have an incentive to alter and phase out support for older technologies to solicit investment in upgrades even if costly upgrades are not the ideal growth strategy for your organization, open standards have demonstrated their resilience to this pressure.? Open standards last longer as they can be more reflective of the demands of the users, and are not subject to a single vendor's interests.?\nSQL is an example of an open standard demonstrating durability in a competitive market place.? Since SQL is used throughout the relational database industry by vendors such as Oracle, Microsoft and IBM, no single vendor has enough control to force you to replace it.? You can choose to continue to use SQL until something has proven to meet your requirements better.?\nOpen standards can continue to improve until you require something new. Since open standards can achieve a high user base through universal adoption, the drive is there to continue improvement so long as it is required.? Of course, if an open standard is ready to be replaced, then a new open standard can be created, opening the door to collaboration on migration and interoperability.?\nThe increased vendors available due open agreement on open standards gives you more flexible options.? In considering supplier options, one size usually does not fit all.? For a proven standard, there may be larger vendors available for those who require global support and higher reliability, while, for the same standard, there may be more localized vendors able to provide you with the implementation you need at a more appealing price, and possibly a more personalized service conducive to your growth needs.?\nIf multiple vendors implement a standard, this can decrease the cost of switching vendors compared to leaving or moving to a vendor of a proprietary solution.? Proprietary solutions are often incompatible with competing solutions, and can also require a high learning curve for the support specialists to make the switch.? Open standards can reduce the impact of change to your systems, your support staff, and other business assets.?\nFor example, using SQL can decrease the impact of switching from one relational database vendor to another.? However, producing code using proprietary super sets of SQL (e.g., Oracle's PL/SQL or Microsoft's Transact SQL) increases the cost of replacement.? Using n-tier architecture, business logic can be coded outside the database avoiding dependency on these supersets and, consequently, their vendors.? A simple decision about where to place logic can optimize options by decreasing the cost of replacing relational database vendors.? Due diligence leading to a better understanding of open standards can go a long way towards improving the effectiveness and efficiency of your IT infrastructure, operations and dependent solutions.\nOpen standards can also provide increased flexibility to your internal systems.? You can leverage interoperability options through open interfaces, giving you options you may not have considered otherwise.? Open source implementing open standards can also offer flexibility by competing with your vendors.?\nCoupled with durability, your flexibility is greater with open standards over the long haul, as technological progress tends to isolate proprietary solutions over time.? This was clear on the Internet when some early commercial Internet Service Providers (ISP) tried to implement proprietary connectivity to the Internet.? The early CompuServe and Prodigy networks are a memory today, while the Internet as a whole continues to grow.?\nQuality is the degree to which a product or service meets your requirements.? One way to measure quality is to measure defects, where a defect is anything other than complete satisfaction of your requirements.? Less defects translates to higher quality.? 100% free from defects would mean that your requirements were wholly met 100% of the time.\nIncreased competition increases quality.? Since the cost of switching vendors is decreased, they have a higher incentive to improve the metrics that impact your decisions, and quality is usually one of those metrics.?\nIncreased vendor competition also increases capacity to meet your requirements.? This capacity can be demonstrated in increased performance, scalability, features, security, or other means.? Since this increase can increase the ability to meet your requirements, you have higher quality selections available to you.?\nOpen standards are subject to the highest degree of peer review since the specs are available to everyone to view and scrutinize.? With open participation in the standard setting process, open standards also enjoy early peer review.? Widespread and early peer review increases early identification and resolution of potential problems, leading to higher quality results than closed proprietary solutions where the public may not be able to adequately determine quality.?\nCASE STUDY: Public peer review of open standards solutions has helped to increase the adoption of Public Key Infrastructure (PKI) solutions based on X.509 standards set by the IETF.? The acceptance of solutions for security business assets requires trust.? In areas of great complexity where it is infeasible for each prospective user to understand all the issues, yet the protection of valuable assets is at stake, open public peer review can offer reassurance where proprietary options might fall short.? The reassurance results from the perception that increased and early peer review can result in higher quality.?\nImprove Vendor Independence\nOne does not need to be in IT long to witness the reality and impact vendor dependence can have.? Many IT decisions have been made due in part to the potential costs of switching vendors, which, much of the time, is ruled infeasible.?\nDe facto industry standards encourage this dependence, reducing choice and competition.? If your customer requires that you transmit an artifact in a proprietary format, the cost to you of not supporting the proprietary solution could translate to lost revenue and profit.? Of course, it may not be your customer's fault.? They may be under the same pressure.? A de facto standard can be hard to break out of because it is like trying to solve the chicken and egg problem, only without a chicken or an egg.? Unless we all change to an alternate solution together, our ability to free our selves from vendor dependence can prove elusive.?\nOf course, not all vendor dependence is this strong or driven by customer requirements.? Sometimes, it is simply too costly to switch vendors due to proprietary technology.? You might, for instance, have a significant portion of your business code written in a proprietary language that is part of a vendor's product.? Switching vendors may require a costly ?rip-and-replace? rewrite.? Also, after the switch, the value of employee knowledge and expertise in that language you no longer use will drop, often requiring retraining or replacement of employees.?\nCASE STUDY:? Although there are plenty of vendors in the relational database market, many have created their own procedural language for creating complex application logic in the database server.? During the client/server era, where the only other alternative was putting all the application logic in the client, a lot of code was written in Oracle's PL/SQL, Microsoft's Transact SQL and other proprietary languages of vendor databases.? Although the n-tier architecture has decreased the reliance on these stored procedures by creating tiers between the front-end client and back-end database where logic can reside, in the absence of vendor independence objectives, the practice continues.? This means the cost of replacing one of one database vendor with another may include the cost of rewriting the server-side logic of the applications.?\nOpen standards help to reduce vendor dependence.? With increasing agreement by vendors on issues involving your business assets, the cost of switching vendors while preserving your business assets is reduced, leading to increased vendor-independence and lower barriers to choice.?\nIncrease Vendor Choice\nIn a market driven by open standards, the quantity and diversity of vendors and their ability to address your requirements can be substantial.? The quantity can grow to address decreasing barriers to entry since the ability to implement the standards is available to all.? The diversity is a result of vendors creating solutions to match the variety of requirements in a market subject to high competitiveness.?\nCASE STUDY: Internet Service Providers (ISP) utilizing open standards to deliver their services are an example of high quantity and diversity of vendor choice.\nPart of what enables this is the decreased cost of switching vendors.? Your ability to easily pick another vendor lowers the barriers to entry for the suppliers, as your current vendor is no longer as strong of a barrier to your competitors.?\nAs you replace proprietary dependency with open standards in potential solutions, risk is transferred from the owner of the single vendor technology to all the vendors supporting the open standards.? Since this offers a more durable option, your overall risk is decreased.? Additionally, a solution that can be more widely supported lowers the barriers to entry for other potential suppliers, giving them more cause to construct offerings crafted to satisfy your requirements.?\nThe combination of your greater accessibility to alternate vendors with the increased ability for them to be able to provide you with open solutions results in an increase in choice, as you are now able to select from a larger pool of supplier options.?\nDecrease Vendor Cost\nThe decreased cost of changing vendors and savings obtained from an increasingly competitive supplier market results in decreased vendor cost through open standards.? The increased competitiveness as open standards lowers barriers to entry in your supplier market also increases efficiencies resulting in lower overall costs throughout your vendor's market.?\nInteroperability is achieved when components are able to function together to share in the fulfillment of a process.? The components that interoperate can be of varying degrees of granularity from components within a single system that work together to create the processes within the system to components between systems tying customer, supplier, vendor, and other external processes into your business.?\nIn between systems you may also have middleware, which can have its own components with varying degrees of interoperability.?\nIncreasing interoperability increases your ability to connect and automate processes that transcend technologies, platforms, languages and customizations.?\nOpen standards and open architectures are continually improving to reduce the barriers to integration of disparate systems.?\nCASE STUDY:? Web services, a set of protocols based on open standards, are the most recent example of ways to increase interoperability options while decreasing costs of integration.? As these standards gained quick acceptance, it became clear that platforms that were previously too economically infeasible to even consider integrating now offer unprecedented synergy.?\nClearly, there are solutions that don't need every interoperability option.? Yet, increasing those options gives you more ability to optimize your use of integration.? Open standards can increase interoperability you need to produce synergy.?\nTwo people talking the same language is simple.? Talking through a translator is not as simple.? Writing a letter, having it translated, sending it, and waiting for a reply is not simple.?\nThe latter example demonstrates some of the techniques used to integrate systems without open standards.? The ability to collect information from one system, transform it into a format another system can understand, then find a way to get the new data correctly inserted into the new system can be a challenge.? One thing is clear, if the two systems could talk directly to each other, then the work would be simpler.?\nOpen standards have become a means of creating common ways all our systems can talk to each other.? Integration tools were quickly revamped to exploit the benefits of recent open standards such as SOAP, while system development platforms have likewise quickly added capability to use open standard protocols to include integration features to new and current systems.?\nThe concept using of ?plug and play? to integrate devices and computer components was born out of the demand for simple and quick integration.? Yet, a look at how it is implemented reveals that it is simply a standardization of integration specifications, automating the satisfaction of repeatable requirements.?\nOpen standards in interoperability issues helps to foster processes for quicker integration of components having standardized interfaces and increased automation of common requirements.?\nEncourage Repeatable Processes\nOpen standards are creating common ways of integrating systems, replacing many unique vendor solutions.? This is helping to foster repeatable integration processes for enterprises, and increasing repeatability throughout dependent industries.?\nOpen standards increase the availability of resources sharing the same processes.? For example, you have five specialists, each using tools that deploy different proprietary technology for achieving the goals, and methodologies developed around each solution, then one of the specialists is not a direct substitute for the other.?\nNow, if all five specialists use the same fundamental technology based on widely adopted open standards, then your ability to substitute one for the other is greater, increasing your pool of available specialists for a given solution one to five.? Specialists, likewise, are able to take advantage of learning efficiencies, as five schools of thought become one.?\nSubstitution increases the pool of knowledge matching your requirements and the ability of knowledge workers to find a need for their skills.? This benefits the technology efforts as a whole by creating the opportunity to increase repeatability.?\nIncrease Available Resources\nJust as using open standards based technology can increase the number of vendors able to address your needs, there are other resources that can increase, as specialization becomes more commonly focused around open standards.?\nCASE STUDY: The Unified Model Language (UML) is an example of an open standard accomplishing this.? By integrating three differing de facto object-oriented modeling standards into one open standard, modelers increased their ability to substitute each other, benefiting providers of modeling skills as well as consumers.? Even though there are many vendors of UML tools, repeatable methods of using UML have arisen permitting enterprises to select the UML tool that best balances their capacity requirements with cost, while choosing a repeatable process using UML transcending vendor implementations.?\nNot only does this increase the UML vendors to choose from in contrast to selecting one of the three primary modeling languages in the early 90s, it also combines the labor pool for the OOAD modeling category.? Whereas before you searched for specialists that supported the standard you selected to avoid learning and conflict costs, you can now simply look for someone who knows UML.?\nThe available labor pool for a project that has already selected specific a vendor's UML tool is increased by virtue of the increased substitutability of human resources that have experience with UML with other vendors.? Although there are differences in UML based toolsets, largely categorized around the bells and whistles not directly relating to UML itself, the use of UML decreases the learning curve from moving from one vendor tool to another in contrast to a change to a tool that uses a different modeling language, increasing substitutability of resources and repeatability of processes.?\nOpen standards can increase the quantity of all resource pools supplying knowledge or technology utilizing the specification by consolidating resources.?\nBesides automated communication improvements yielding improved interoperability, open standards simplifies and streamlines communication between people.?\nBy encouraging open dialog and participation from the outset, open standards encourage communications that leads to consensus.? The unified objective mindset of the contributors to the open standards process encourages adoption of common terminology used in the discussions before the specifications or processes are themselves concluded.\nThe common terms flow outside standards setting processes, advancing throughout industry and public discussions.? As the technology and standards are adopted, communication is increasingly streamlined, permitting educational and corporate institutions to apply the concepts and terminology.? Implementers and users of the standards can communicate more efficiently by using terminology predefined and visible to everyone interested.?\nThe streamlining of communications derived from common open dialog ensures higher productivity from users of open standards in contrast to operating with closed concepts.?\nIncrease Return on Investment (ROI)\nReturn on Investment (ROI) is the return an investment yields over a period of time, a financial metric for helping to determine and contrast the potential value of investments.? The higher the return you achieve with your investment, the greater the positive impact it can have on your bottom line.?\nThere are basically three ways to increase ROI.? The most obvious is to decrease cost.? Another is to increase benefits, or return.? Lastly, since the development of information systems cannot begin to yield a return until they are deployed in production, you can increase ROI by shortening the time it takes to enter production, speeding time-to-market.? This increases ROI by indirectly increasing return for the same period of time.? This may also yield competitive advantages increasing long-term return.?\nYou can decrease costs through the use of open standards, thereby increasing ROI.? Open standards can increase your vendor options, resulting in lower vendor costs.? Consolidation in other resources, such as training costs, can also decrease overall costs.?\nAs you demand quicker time-to-market, increased competition between vendors in an open standards market increases pressure to produce and pass on improvements and efficiencies.? Increased use of open standards increases the ability to share improvements across the industry, yielding improvements for all users.?\nBy helping to decrease cost and speed time-to-market through improved competition among suppliers and consolidation in other available resources, using open standards can help to increase ROI.\nIncrease Acceptance of Products and Services\nBuilding products and services using open standards improves market acceptance, since part of what you are offering, the implementation of open standards, has already been accepted.?\nIncreasing market acceptance by virtue of the choice to use open standards can decrease your barriers to market entry and growth.? In markets where highly proprietary solutions dominate, customers often choose larger vendors to reduce risk, often creating a market where a few are dominant, and barriers to entry are high.? Open standards lowers these barriers, opening markets to you as customers consider you an alternative to their current suppliers.?\nCustomer risk is lowered independent of the vendor chosen as risk is transferred from a single vendor to multiple vendors implementing the same open standards.? The decrease and transfer of risk increases the ability of the customer to consider more vendors.? This increases your accessibility to new customers as your products and services enjoy increased acceptance through the utilization of open standards.\nIncreasing the acceptance of the products and services through the adoption of open standards also means you will be competing for a faster growing market.? The increase in growth can create a business case turning even the most traditional proprietary players into advocates for open standards.? The ISP and website hosting markets are prime examples.?\nFor the consumption of products and services and the creation of internal solutions, using open standards can decrease your costs, speed time-to-market, expand available options and resources, improve communications, reduce risk and create more durable solutions.? Using open standards in the products and services you produce and internal applications directed towards such efforts offers these same benefits plus increased adoption and market acceptance of solutions and lower market barriers through decreased customer risk.? It also allows you to participate in faster growing markets.?\nObtaining these advantages begins with the decision to declare open standards among your highest priorities.? Decide to evaluate open standard options in all your considerations.? Address it in your planning.? Begin to build the process of understanding, contrasting and developing conclusions of how open standards can improve your decisions and impact your business.?\nRaising awareness, increasing participation and supporting dialog of open standards are all steps you can take to help your organization leverage the benefits of open standards.? If you open discussions on open standards, you might be surprised when the dialog lends itself to articulating the business case for open standards.?\nBuilt using Joshua Branch AS, J2EE and JBoss.\nFor questions or comments please contact the webmaster.\nExcept where otherwise noted, this site is\nlicensed under a Creative Commons License", "label": 1}
{"text": "01.Shopping without walls\nGeo-blocking prevents shoppers in some countries from accessing cheaper prices overseas through Internet Service Provider (ISP) restrictions.\nWe look at how international companies such as Amazon, Apple and Microsoft conduct geo-blocking, and offer some tips to circumvent the price discrimination.\nWhat is geo-blocking?\nThe internet is a borderless\nworld – news, shopping and\nsocial interaction with people\nfrom all over the world is at\nour fingertips. But some online retailers\nhaven’t yet embraced this fact, relying\ninstead on copyright and licensing\nrestrictions to vary prices around the\nworld – what’s known as “geo-blocking”.\nRestricting access to content based on geographic location is a popular strategy used by multinational tech giants so they can set different prices in different regions of the globe. The frustrating reality of geo-blocking is common for Australian consumers, who are often charged hefty mark-ups on products from companies such as Apple, Microsoft and Amazon, based on their IP address.\nWhile Amazon, Apple and Microsoft\nare among the main culprits, streaming\nservices such as Netflix and Hulu also\ndivide the globe into random segments,\nonly to grant access to those with a\ncertain IP address (the numerical\naddress that identifies your computer).\nin June this year\nfor a parliamentary\ninquiry into IT price\nbased on online prices of\nmore than 200 products,\nconsumers pay an\naverage of 50% more\nfor PC games, 34%\nmore for software,\n52% more for\niTunes music, 41%\nmore for computer\nhardware and a huge\n88% more for Wii games\nthan our US counterparts.\nAlthough these prices don’t take\ninto account the average 9.6% US sales\ntax (iTunes prices also don’t include\nAustralian GST), the mark-up remains\nFortunately for Australian consumers\nthere are other options that allow you to\nnavigate your way\nboundaries to access\nmore content and\n– see right.\nFor more information about shopping online, see Networking and internet.\nIs it legal?\nThe legality of\nis a grey\narea. Some copyright\nexperts claim those\nwho promote devices\nor programs that\nto infringe copyright\nare breaking the law.\nbelieves consumers who\ncircumvent measures used to\nprotect copyrighted content should be\nexempt from what could be construed\nas a breach of copyright simply because\nthey’re accessing products and services\nthat are being provided knowingly and\nwillingly by the copyright holder.\nIt is legal to use a virtual private\nnetwork (VPN) to protect\nyour online transactions from hackers,\nand there’s little definitive evidence as\nto whether other uses of a VPN breach\nIt’s also important to note that\ncircumventing geo-blocks may breach\nthe terms and conditions of the company\nyou’re buying from, and if discovered,\nyour account could be cancelled, losing\ncredit and access to your downloads.\nAccording to the ACCC, your rights\nwhen dealing with overseas-based\ncompanies to buy products may not\nbe protected by Australian law. While\nsome companies, such as Apple, have\ninternational warranties, others, such\nas Canon and Nintendo, say they refuse\nto recognise products purchased\ninternationally under domestic", "label": 1}
{"text": "U.K. surveillance proposal could reveal driving habits, sleep patterns — even infidelity, warn experts\nExplore This Story\nLONDON—British officials have given their word: “We won’t read your emails.”\nBut experts say that its proposed new surveillance program, unveiled last week as part of the government’s annual legislative program, will gather so much data that spooks won’t have to read your messages to guess what you’re up to.\nThe U.K. Home Office stresses that it is not seeking to read the content of every Britons’ communications, saying the data it was seeking “is NOT the content of any communication.” It is, however, seeking information on who’s sending the message, whom it’s sent to, where it’s sent from, and potentially other details including a message’s length and its format.\nThe government’s proposal is just a draft bill, so it could be modified or scrapped. But if passed in its current form, it would put a huge amount of personal data at the government’s disposal, which it could potentially use to deduce a startling amount about Britons’ private life — from sleep patterns to driving habits or even infidelity.\n“We’re really entering a whole new phase of analysis based on the data that we can collect,” said Gerald Kane, an information systems expert at Boston College. “There is quite a lot you can learn.”\nThe ocean of information is hard to fathom. Britons generate 4 billion hours of voice calls and 130 billion text messages annually, according to industry figures. In 2008 the BBC put the annual number of U.K.-linked emails at around 1 trillion. Then there are instant messaging services run by companies such as BlackBerry, Internet telephony services such as Skype, chat rooms, and in-game services liked those used by World of Warcraft.\nCommunications service providers, who would log the details of all that back-and-forth, believe that the government’s program would force them to process petabytes (1 quadrillion bytes) of information every day. It’s a mind-bogglingly large amount of data on the scale of every book, every movie, and every piece of music ever released.\nSo even without opening emails, how much can British spooks learn about who’s sending them?\nTHEY’LL SEE THE RED FLAGS\nDo you know how fast you were going?\nYour phone does.\nIf you sent a first text from London before stepping behind the wheel, and a second one from a service station outside Manchester only three hours later, authorities could infer that you broke the speed limit to cover the roughly 200 miles which separate the two.\nCrunching location data and communications patterns gives a remarkable rich view of a person’s lives — and their misadventures.\nKen Altshuler, of the American Academy of Matrimonial Lawyers, raves about the benefits which smartphones and social media have brought to savvy divorce attorneys. Lawyers don’t need sophisticated data mining software to spot evidence of infidelity or hints of hidden wealth when they review phone records or text traffic, he said.\n“One name, one phone number that’s not on our client’s radar, and our curiosity is piqued,” he said. The more the communication — a late-night text sent to a work colleague, an unexplained international phone call — is out of character, “the more of a red flag we see.”\nHOW DO YOU SLEEP?\nThe ebb and flow of electronic communication — that call to your mother just before bed, that early-morning email to your boss saying you’ll be late — frames our waking lives.\n“You can figure somebody’s sleep patterns, their weekly pattern of work,” said Tony Jebara, a Columbia University machine learning expert. In 2006, he helped found New York-based Sense Networks, which crunches phone data to do just that.\nJebara said that calls made from the same location between 9 and 5 are a good indication of where a person works; the frequency of email traffic to or from a person’s work account is a good hint of his or her work ethic; dramatic changes to a person’s electronic routine might suggest a promotion — or a redundancy.\n“You can quickly figure out when somebody lost their job,” Jebara said, adding: “Credit card companies have been interested in that for a while.”\nWHO’S THE BOSS\nDrill down, and communication can reveal remarkably rich information. For example, does office worker A answer office worker B’s missives within minutes of the message being sent? Does B often leave colleagues’ emails unanswered for hours on end? If so, B probably stands for “boss.”\nThat’s an example of what Jebara’s Columbia colleagues described as “automated social hierarchy detection,” a technique which can infer who gives the orders, who’s respected, and who’s ignored based purely on whose emails get answered and how quickly. In 2007 four of them analyzed traffic taken from the Enron Corporation’s email archive to correctly guess the seniority of several top-level managers.\nIntelligence agencies may not need such tools to untangle corporate flowcharts, but identifying ringleaders becomes more important when tracking a suspected terrorist cell.\n“If you piece together the chain of influence, then you can find the central authority,” he said. “You can figure that out without looking at the content.”\nWHO ARE YOU TALKING TO?\nSeeing how networks of people communicate isn’t just about finding your boss, it’s about figuring out who are your friends.\nPrograms already exist to determine the density of communications — something that can identify close groups of friends or family without even knowing who’s who. If one user is identified as suspicious, then the users closest to him or her might get a second look as well.\n“Let’s say we find out somebody in the U.K. is a terrorist,” said Kane. “You know exactly who he talks to on almost every channel, so BOOM you know his 10 closest contacts. Knowing that information not only allows you to go to his house, but allows you to go to their houses as well.”\nA SNOOP’S CHARTER?\nDetective work at the stroke of a key is clearly attractive to spy agencies. British officialdom has been pushing for the mass surveillance program for years, but civil libertarians are perturbed, branding the proposal a “snooper’s charter.”\nKane said that the surveillance regime had to be seen in the context of social networks such as Facebook and LinkedIn, where hundreds of millions of people were constantly volunteering information about themselves, their friends, their family and their colleagues.\n“There’s no sense in getting all Big Brother-ish that there are legitimate safeguards in place,” he said. “The bottom line is that we’re all leaving digital trails, everywhere, all the time. The whole concept of privacy is shifting daily.”\n- NEW Pet owner sues vets for pain and suffering over dog’s death\n- Police make second arrest in Tim Bosma murder investigation\n- Man hacked to death in London in suspected terror attack\n- 'The silence is deafening': Rob Ford stays mum on crack allegations\n- NEW A North Korean refugee’s tale of tragedy and bravery\n- Canada’s international reputation rising: Survey\n- As world gawks at Rob Ford scandal, Toronto police wait and watch\n- Boston bombings suspect's friend allegedly confessed to 2011 killings", "label": 1}
{"text": "Thirteen Ways Government Tracks Us\nTrue Activist— Privacy is eroding fast as technology offers government increasing ways to track and spy on citizens. The Washington Post reported there are 3,984 federal, state and local organizations working on domestic counterterrorism. Most collect information on people in the US. (Source)\nHere are thirteen examples of how some of the biggest government agencies and programs track people.\nOne. The National Security Agency (NSA) collects hundreds of millions of emails, texts and phone calls every day and has the ability to collect and sift through billions more. WIRED just reported NSA is building an immense new data center which will intercept, analyze and store even more electronic communications from satellites and cables across the nation and the world. Though NSA is not supposed to focus on US citizens, it does. (Source)\nTwo. The Federal Bureau of Investigation (FBI) National Security Branch Analysis Center (NSAC) has more than 1.5 billion government and private sector records about US citizens collected from commercial databases, government information, and criminal probes. (Source)\nThree. The American Civil Liberties Union and the New York Times recently reported that cellphones of private individuals in the US are being tracked without warrants by state and local law enforcement all across the country. With more than 300 million cellphones in the US connected to more than 200,000 cell phone towers, cellphone tracking software can pinpoint the location of a phone and document the places the cellphone user visits over the course of a day, week, month or longer. (Source)\nFour. More than 62 million people in the US have their fingerprints on file with the FBI, state and local governments. This system, called the Integrated Automated Fingerprint Identification System (IAFIS), shares information with 43 states and 5 federal agencies. This system conducts more than 168,000 checks each day. (Source)\nFive. Over 126 million people have their fingerprints, photographs and biographical information accessible on the US Department of Homeland Security Automated Biometric Identification System (IDENT). This system conducts about 250,000 biometric transactions each day. The goal of this system is to provide information for national security, law enforcement, immigration, intelligence and other Homeland Security Functions. (Source)\nSix. More than 110 million people have their visas and more than 90 million have their photographs entered into the US Department of State Consular Consolidated Database (CCD). This system grows by adding about 35,000 people a day. This system serves as a gateway to the Department of State Facial Recognition system, IDENT and IAFSIS. (Source)\nSeven. DNA profiles on more than 10 million people are available in the FBI coordinated Combined DNA index System (CODIS) National DNA Index. (Source)\nEight. Information on more than 2 million people is kept in the Intelligence Community Security Clearance Repository, commonly known as Scattered Castles. Most of the people in this database are employees of the Department of Defense (DOD) and other intelligence agencies. (Source)\nNine. The DOD also has an automated biometric identification system (ABIS) to support military operations overseas. This database incorporates fingerprint, palm print, face and iris matching on 6 million people and is adding 20,000 more people each day. (Source)\nTen. Information on over 740,000 people is included in the Terrorist Identities Datamart Environment (TIDE) of the National Counterterrorism Center. TIDE is the US government central repository of information on international terrorist identities. The government says that less than 2 percent of the people on file are US citizens or legal permanent residents. They were just given permission to keep their non-terrorism information on US citizens for a period of five years, up from 180 days. (Source)\nEleven. Tens of thousands of people are subjects of facial recognition software. The FBI has been working with North Carolina Department of Motor Vehicles and other state and local law enforcement on facial recognition software in a project called “Face Mask.” For example, the FBI has provided thousands of photos and names to the North Carolina DMV which runs those against their photos of North Carolina drivers. The Maricopa Arizona County Sheriff’s Office alone records 9,000 biometric mug shots a month. (Source)\nTwelve. The FBI operates the Nationwide Suspicious Activity Reporting Initiative (SAR) that collects and analyzes observations or reports of suspicious activities by local law enforcement. With over 160,000 suspicious activity files, SAR stores the profiles of tens of thousands of Americans and legal residents who are not accused of any crime but who are alleged to have acted suspiciously. (Source)\nThirteen. The FBI admits it has about 3,000 GPS tracking devices on cars of unsuspecting people in the US right now, even after the US Supreme Court decision authorizing these only after a warrant for probable cause has been issued. (Source)\nThe technology for tracking and identifying people is exploding as is the government appetite for it.\nSoon, police everywhere will be equipped with handheld devices to collect fingerprint, face, iris and even DNA information on the spot and have it instantly sent to national databases for comparison and storage.\nBloomberg News reports the newest surveillance products “can also secretly activate laptop webcams or microphones on mobile devices,” change the contents of written emails mid-transmission, and use voice recognition to scan phone networks. (Source)\nThe advanced technology of the war on terrorism, combined with deferential courts and legislators, have endangered both the right to privacy and the right of people to be free from government snooping and tracking. Only the people can stop this.", "label": 1}
{"text": "SRTP (Secure Real-Time Transport Protocol or Secure RTP) is an extension to RTP (Real-Time Transport Protocol) that incorporates enhanced security features. Like RTP, it is intended particularly for VoIP (Voice over IP) communications.\nSecuring VoIP Networks: Threats, Vulnerabilities and Countermeasures\nIn an excerpt from the book Securing VoIP Networks:...(SearchSecurity.com)\nExcerpt: Securing VoIP Networks: Threats, Vulnerabilities and Countermeasures\nAuthors Peter Thermos and Ari Takanen discuss t...(SearchCIO.com.au)\nSRTP was conceived and developed by communications experts from Cisco and Ericsson and was formally published in March 2004 by the Internet Engineering Task Force ( IETF ) as Request for Comments (RFC) 3711. SRTP uses encryption and authentication to minimize the risk of denial of service( DoS ) attacks. SRTP can achieve high throughput in diverse communications environments that include both hard-wired and wireless devices. Provisions are included that allow for future improvements and extensions.", "label": 1}
