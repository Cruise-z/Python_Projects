{"text": "A ‘English Tutorials’ kategória archívuma\nIn this Article I am endeavor to do a demonstration in HTML5 to be introduced data storage modul (Web Storage) of a client side. Naturally it will not change the World as it seems – since the “cloud” we know that it will -, but nevertheless it assures a great option which we could solve only with different tricks so far (e.g.: Cookie). But the Cookie had many disadvantage (limited size 4KB, traffic through the forwarding per request etc.). Well on the other hands the HTML5 Web Storage by the current definition can store 5MB data per source. Plenty of data can be stored here. It is important aswell that no unnecessary traffic will spring up because it is not sending data only if we ask. (by the way it is not done to make 5MB storages)\nThe Web Storage itself stores the data in a key/value pair form and we can search back with this in a later time when we need it. The type of the key is text while the type of the value can be anything. Let’s see the types of the storage:\n1. Session Storage\nThe data will be stored here until the end of the browsing Session. After that they will be deleted (this can redeem the cookies). As long as the data will not be important to us in a later time, or for users, it is worthwhile to use this solution due to saving of the resources.\n2. Local Storage\nIt is a different case like the previous. The data will be stored here and remains until we will not delete the key/value pairs or the user will not do this with his/her browser. Now You could ask why is this so good? Because e.g.: if a user opens a new window he/she can get the data or if he/she quits from his/her browser and re-enter, the data will be available. Tovább olvasom »\nGot an idea from You that would be good to deal with the text marking a little bit. So I thought we should see some examples for the innovations and for the text marking aswell.\nLet’s see the things we should know about according to the texts. Starting with the basics our texts should take into paragraph with the <p> element. Long ago there was an attribute called “align” but it was disused in HTML4 too neither HTML5 support this. Its use is very simple:\n<p>It is a new paragraph</p>\nThe next is the <q> element which serves to insert short cites in. Some of the browsers show this between apostrophe. It has only one attribute. With its help we can mark the source where we cite from.\nFor this purpose we can use the <blockquote> element too. We can show longer cites with this but i recommend the use of the <q> element because in the case of the latter the browers running new paragraphs pell-mell. Its use the same as the element of <q>:\n<q cite=\"http://www.magyarorszag.hu/\">http://html5.ugyesen.com/ - HTML5 webportal</q>\nMore of You have indicated, that the lists and the changes of the lists have been out of the articles so far. Now I would like to dissolve this gap. In my opinion there are less changes that happened according to HTML4.\nYou can make lists (ordered: (<ol> … <li>) or unordered (<ul>…<li>) or mixed lists (ordered and unordered) in a similar manner. So far we had opportunity to create lists in html aswell so let’s see an example for this:\nThe build-up of an unordered list:\n<ul> <li>Budapest</li> <li>Pécs</li> </ul>\nThe build-up of an ordered list:\n<ol> <li>Budapest</li> <li>Pécs</li> </ol>\nWhat realy Geolocation is? The Geolocation modul of HTML5 returns the geographical position of device (computer, tablet, mobil etc.) that displays the webpage. We can send this to Google Maps. The only flaw is that it is not defined what helps to determine this location. (built-in GPS, based by cell informations or by IP Address etc.) If the Technical Specification in the final version is going to determine this a little bit specifically then we are going to get a very useful and fast spread tool in our hands.\nUntil that it is worthwhile to deal with this as curiosity. Unfortunately if there is no GPS modul in the device it can be locate our position approximately with 35-50km accuracy based by my experience. But I have got 200km deviation too. Let’s start then.\nChecking the browser.\nFirst of all we are going to check that whether our browser supports the new device or not. The code below only queries that our browser capable to use geolocation or not. If not then it returns an error signal. If it is capable then returns a blank screen. Tovább olvasom »\nThe working source can be available here. What is My IP? I put this up here because many of you seek.\nBefore we start the geolocation let me make a little retrospection. In this article we are going to see how we queried the data of browsers and users in the past. Our best assistance was the “user agent”.\nThe user agent acts as a client in a network protocol used in communications within a client–server distributed computing system.\nMost frequently people use this in case of World Wide Web access applications (web browsers, web crawler etc.). The browers forwarding the “user agent” to the web server which describes the client hardware platform, the operating system, the browsers type and version and its language settings.\nBrowser information Tovább olvasom »", "label": 1}
{"text": "|Posted by Jipol27Juper on February 1, 2011 at 8:23 AM|\nA brand new Pc, free of defective components, will operate perfectly smooth. Even as many years go by, as much more programs are installed in your program, your computer running slow may not be noticeable. If all of a sudden your pc keeps on freezing up or you notice a sudden slowdown, it may be attacked corrupt content material.\nDespite the reality that this really is extremely typical issue amongst users, not many of us actually know what might be affecting the machine. The factors are numerous and diverse such as not enough space in the tough disk or not sufficient ram. Nevertheless, before obtaining a brand new tough disk or much more ram, you need to consider that occasionally registry mistakes could be those to blame.\nThere are lots of slow pc solutions, but when the issue has not but been recognized it could be hard to fix. A virus, or a minimum of a malignant one, gives away particular signs and symptoms including your computer freezing, programs not opening properly, actions becoming blocked towards other knowingly safe applications, random shutdowns, and sudden pc slowness. A broken computer, or one that seems to become damaged, can frequently be fixed if a virus will be the trigger. Occasionally, although, a virus has already carried out as well a lot harm to become repair or recovered.\nA technical term of a computer malware is really a piece of software program that will duplicate itself and infect a pc. Although numerous other malicious applications like malware and worms are often confused with becoming viruses, they are, in fact, not, though for the objective of this article, it's irrelevant. All of them need to power to place a computer in a worse condition. Viruses come in numerous various types, and there are just as many names connected to these viruses. A Trojan horse virus will get its name from the well-known poem made famous by Homer. The Trojan horse virus pretends to become a plan, or pretends to become capable of doing a certain desirable action, and (possibly additionally to performing what it's supposed to) steals files or harms the program.\nInside the PCs working system there is a registry that's essential for that great functioning of the machine. The cause is because the software package works by scanning keys and information bits that are essential in the procedure of loading information and making hardware function around the machine. Remember the essential stage to think about is the registry.\nWhen the registry shows reviews of errors and corrupt entries is when your Pc begins to work much more gradually. Be cautious simply because in the event the registry is reporting too numerous mistakes, you may find problems running applications. This kind of registry problems arises whenever you ameliorate applications as well as whenever you set up a new program as well. If your antivirus software has detected spyware and it has to remove it from your machine you may also expertise registry errors.\nThe best form of protection against viruses is prevention. Newer variations of Windows come having a plan called Windows Defender that protects against spyware but does not safeguard against viruses. There are plenty of web sites having a free antivirus trial so you can test out which antivirus software program you wish to buy. Some individuals also wish to purchase or try anti-spyware software online. This really is also perfectly acceptable. Download from highly rated web sites, and also you cannot go wrong. A crucial stage to keep in mind, although, is that two antivirus applications running in the exact same time isn't recommended. Two antivirus programs doesn't equivalent twice the protection. In fact, two antivirus applications will wind up fighting each other for priority, and then they'll each wind up not working properly.\nYou are able to get a registry cleaner plan on the internet. In fact you can access a scan and the possibility to repair little mistakes with out needing to buy the product. When you get it, you'll not be questioning \"why is my computer running slow ?\" actually again. I personally managed to clear up my pc by downloading higher high quality registry cleaner software program.", "label": 1}
{"text": "(NaturalNews) It's a concept that is anathema to most of today's military pilots: Fighter planes without a human being at the helm.\nYet, that's the next generation of strike fighters that are going to be produced by the United States, according to a number of analysts. In fact, the Navy already has its own version making test flights.\nThe X-47B, manufactured by Northrup Grumman, was unveiled by Navy officials this month as a pilotless, remote-controlled weapons platform that will ultimately be flying missions from the decks of American carriers. Officially known as the Unmanned Combat Air System, the drone-like strike fighter is currently undergoing flight tests at the Patuxent River Naval Air Station in Maryland. Eventually, officials say, the platform will carry weapons, though none are being placed on board the current test model.\nAccording to the manufacturer, the X-47B will make its first carrier landings.\n\"Under a contract awarded in 2007, the company designed, produced and is currently flight testing two X-47B aircraft. In 2013, these aircraft will be used to demonstrate the first carrier-based launches and recoveries by an autonomous, low-observable-relevant unmanned aircraft,\" Northrup Grumman said, adding that the aircraft will undergo aerial refueling testing the following year, in 2014.More testing on the horizon\nThe aircraft program has steadily matured. The X-47B's first successful test flight occurred Feb. 4, 2011, which consisted of a short flight of just 29 minutes, to a ceiling of 5,000 feet. Since then, follow-up testing has improved on the craft's capabilities and has demonstrated its potential.\nIn some of the latest flight tests that took place earlier this year, the aircraft\nclimbed to 15,000 feet and undertook \"multiple maneuvers that are essential for using an aircraft carrier as its base of operations including extending and retracting a tail hook needed to catch the carrier's arresting wires upon landing and 'touch-and-go\" landings,\" Forbes\nOfficials said part of the carrier tests would include so-called \"bolter\" runs, in which the tail hook fails to catch on the carrier deck and it must immediately take off again. The craft will also undergo wave-offs, in which the operator will have to abort a landing.\nsaid the goal of the X-47B program is to provide the military with an \"unmanned air system capable of providing persistent, penetrating surveillance, and penetrating strike capability in high threat areas.\" The aerial refueling element means the aircraft could stay aloft for extended periods, perhaps even taking on several pre-programmed missions, so long as conditions remained favorable and its weapons lasted.\nAlso, it's tailless design and special composite body makes the X-47B harder for radar to detect, adding a stealth element that will prove vital in covert operations especially.More than just military applications?\nWhat's more, the capability could expand into other aircraft markets.\n\"Even more exciting than the X-47B is the technology to fly aircraft with a laptop and a click of the mouse instead of a joystick and human pilot,\" said a report in Discovery News\nSuch technology exists even for cargo and commercial aircraft, experts say, but right now, the risk is too great.\n\"You could build one. The question is: Would you be allowed to operate it?\" John Hansford, director of the Center for International Air Transportation\nand a professor of aerospace engineering at the Massachusetts Institute of Technology\n, told the Web site.\n\"We already have the technology to take an existing commercial-scale airplane -- say an Airbus 320 or Boeing 777 -- and convert it to unmanned operations,\" he said. \"However, it's not clear yet that you could guarantee the safety of that to a level that would be acceptable for general public transport. If it has a problem, then it becomes a hazard to people on the ground.\"Sources:http://news.discovery.com/tech/navy-fighter-drone-120802.htmlhttp://www.forbes.comhttp://www.as.northropgrumman.com/products/nucasx47b/index.html\nHave comments on this article? Post them here:\npeople have commented on this article.", "label": 1}
{"text": "How to protect your PC\nBeing an Internet user you should know how necessary is to protect your PC from different malware, viruses and worms. Be sure to prevent is better than to cure.\nThe traditional method to provide you computer with additional protection\nUsually people try to use multiple signature scanners that include anti-viruses, anti-trojans, anti-spywares and anti-rootkits. Very often these tools cost too much and afford too little additional protection.\nAn up to date antivirus will find a lot of spyware while an anti-spyware program will also detect several Trojans, viruses and worms as well.\nYou should know that adding the “layer” of protection you will get not only a better protection but also several false positives. One of them is that you will suffer from long time load on your computer. It means that having good firewall together with an antivirus and antispyware tool will diminish returns.\nSometimes a specific malware that has penetrated your PC can disable all the layers of protection considering them useless.\nWell, how to prevent infection?\n- Keep your OS and MS Office completely updated. Check if your update settings are automatic.\n- If you use Firefox, Adobe products, Flash plug-ins and other useful software you should update them as well.\n- Choose the alternative software. Sometimes popular programs are worse than others because of high weight and its “popularity” among malware writers.\n- Be cautious while surfing. Avoid visiting web pages that offer serial numbers, keygens, AVG LinkScanner, etc. These free offers very often have hidden plug-ins that attend site security ratings.\n- While checking email never open the attachments from suspicious sources. Also don’t click on the links in email from unknown senders.\n- Download software from the websites you can trust. Install the program just when you are confident it doesn’t include infection.\n- Be sure that your firewall is turned on. You can use your Windows’ firewall or a firewall with outbound protection.\n- Disable AutoRun function.\nBasically even the above tips won’t guarantee 100% protection. Even a trusted source can be infected with malware. So you need more protection than a basic security service.\nProvide with a better protection\nTake care of your normal Windows environment. This is what you are using now, your default setup in Windows.\nThere are few ways to keep all malware away from your normal Windows account.\n- For your daily work use limited user account\n- High risk programs need to be run with limited rights\n- While testing high risk programs you should have a sandbox\n- Use policy restrictions while running high risk programs\nEach point has its advantages and disadvantages. That’s why you need to find all necessary information about it and to analyze them individually.\nAlso you can try on-demand scanning. It can be represented by antivirus scanner, key logger scanner or a rootkit detector. An on-demand scan is a scan when you initiate it manually.\nThis type of scanning helps you to use only computer power. Try anti-spyware scanner like Super Antispyware or Panda Antirootkit. These are free and very effective. Run them weekly or monthly. It will give additional protection to your antivirus program.\nFinally you should understand that day by day there appear new malware programs. Absolutely none of antimalware programs can provide you with 100% protection.\nChoose your security method and remember that an ounce of prevention is worth a pound of cure.\nHow to protect your PC\nTypes of Viruses\nMalware: A General Overview\nA Quick Analysis of a PC Virus\nProtecting Your PC from Spyware\nPreventing Macro Viruses\nWrite a comment\n- Required fields are marked with *.\nFree Antivirus Software\n- Free Antivirus Software\n- Free Online Virus Scan\n- Free Trojan Removers\n- Free Adware/Spyware Removers\n- Free Antivirus for Android\n- Free Antivirus for Mobile\n- Free Firewall\n- Free Rootkit Removers\n- Free Spam Filters\n- Free Advanced Spam Filters\n- Free HIPS (Host Intrusion Protection Software)\n- Free Antivirus for MAC\n- Free Antivirus for Linux", "label": 1}
{"text": "2010 Report: Public Health Preparedness\nSection 1: A National Snapshot of Public Health Preparedness Activities\nSurveillance and Epidemiology: Monitoring and Investigating Health Threats\nSurveillance and epidemiology are core public health functions that detect community health threats, investigate their sources and patterns of distribution, and monitor their impacts. These data are used to help in making decisions on actions meant to control or prevent disease or injury.\nSurveillance: Data for Monitoring Health Threats\nPublic health surveillance is the ongoing, systematic collection, analysis, and interpretation of health data, and the dissemination of this information to those who need to know. Surveillance data may describe health problem trends, detect epidemics, provide details about disease patterns, monitor changes in disease agents like viruses (through working with laboratorians), help determine the most effective mitigation strategies, and evaluate the effects of control and prevention measures.\nPublic health officials use different types of surveillance data as a basis for decision making to protect the public’s health. One of the first examples of a public health action stemming from the use of surveillance data likely occurred during the bubonic plague in the 14th century, when authorities boarded ships to prevent passengers with plague symptoms from coming ashore. Many early surveillance systems were based on identifying and reporting cases of disease.\nIn the United States, surveillance systems are a collaborative effort between CDC and its many partners in state, local and territorial health departments; public health and clinical laboratories; vital statistics offices; healthcare providers; clinics; and emergency departments. These surveillance systems resources helped support decision making by public health officials during the 2009 H1N1 influenza pandemic response (see boxes below and on next page).\nCurrent surveillance systems at the local, state, national, and international levels need to improve to meet the nation’s growing challenge to manage and integrate data from a variety of different sources, ensure that decision makers have access to the data, and exchange data with other federal agencies and with public health partners. In 2007, Homeland Security Presidential Directive 21 called for the development of a nationwide approach to enhance the United States’ ability to detect and respond to health-related threats. The National Biosurveillance Strategy for Human Health, an effort coordinated by CDC for the U.S. Department of Health and Human Services, provides a plan for building a nationwide, next-generation capability designed to generate timely, comprehensive, and accessible information for public health and clinical decision making.36 The Strategy established six priority areas: electronic health information exchange, electronic laboratory information exchange, unstructured data, integrated biosurveillance information, global disease detection and collaboration, and biosurveillance workforce.\nEpidemiology: Investigating Health Threats\nEpidemiologists – known as “disease detectives” – work closely with laboratorians to identify health threats, determine their patterns in a community, and estimate their effects. They might identify contaminated food causing illness, assess the number and locations of people injured and types of injuries resulting from a disaster, or determine causes of a sudden onset of fever in a community. Epidemiologists also work to minimize the negative effects of community health threats.\nDetection depends on accurate and complete surveillance data. Problems can arise if data are not available, especially for state and local health agencies. In particular, health problems may not be identified early and public health interventions (e.g., the provision of treatments or vaccines) may be delayed.\nEpidemiologists conduct targeted investigations and surveys that complement surveillance to validate and identify the causes and effects of a health event. Analyses of these data can produce criteria (e.g., specific symptoms) for determining whether a person should be counted as affected by the particular event, the characteristics of those affected (e.g., age, medication use, socioeconomic status), and the geographic extent of the event. Further studies help identify populations at increased risk for the disease or other health event.\n|Number of epidemiologists working in state health departments||2,498||2,193||12%|\n|Number of state health departments reporting substantial-to-full capacity in bioterrorism/emergency response||41||237||10%|\nSource: Council of State and Territorial Epidemiologists\nCDC epidemiological support to states and localities for FY 2008 included 26 Career Epidemiology Field Officers (CEFOs) located in states and localities supported through state Public Health Emergency Preparedness (PHEP) funding. CDC also deployed 71 field officers from its Epidemic Intelligence Service (EIS) to conduct 319 investigations in the same year. EIS is a two-year epidemiology training program modeled on a traditional medical fellowship. Officers in this program support states during responses to routine public health incidents and large-scale national emergencies. CEFOs are experienced, fulltime epidemiologists located in state and local public health departments to enhance and build epidemiologic capacity for public health preparedness and response.\nState epidemiological capacity continues to decline. A 2009 assessment37 by the Council of State and Territorial Epidemiologists reports that national epidemiological capacity has been eroding since 2004 (see Table 1). This trend contrasts with the significant increase in the number of epidemiologists that took place during 2001–2004, when emergency response and preparedness funds fueled rapid growth in the number of new and replacement epidemiologists in the public health workforce. The 2009 assessment also suggests that nearly 20% of current public health epidemiologists anticipate retiring or changing careers in the next 5 years and recommends that federal, state, and local agencies develop a strategy to address these projected downward trends and major gaps.\nAssessing Capabilities for Surveillance and Epidemiology\nCDC is developing performance measures related to surveillance and epidemiological capabilities. PHEP-funded states, localities, and U.S. insular areas will be required to report on measures that address the following:\n- Timely recognition of a potential health emergency through disease reports submitted to public health agencies\n- Ability to investigate an outbreak or exposure, summarize findings, and make improvements to the investigative process\n- Timeliness of initiating interventions to limit the spread of disease\nThe intent of these new measures is to demonstrate an ability to turn data into actionable information that supports decision making in a public health emergency. For more information on new performance measures, see the Moving Forward section.\n- Page last updated September 21, 2010\n- Page last reviewed September 21, 2010\n- Content source: Office of Public Health Preparedness and Response (OPHPR, formerly the Coordinating Office for Terrorism Preparedness and Emergency Response [COTPER])\nGet email updates\nTo receive email updates about this page, enter your email address:\n- Centers for Disease Control and Prevention\n1600 Clifton Rd\nAtlanta, GA 30333\nTTY: (888) 232-6348\n- Contact CDC-INFO", "label": 1}
{"text": "Sidebar Site Navigation\nWhat is it?\nIdentity theft happens when someone else uses your personal information to open credit accounts in your name. Since the accounts are in your name, you can be liable for any charges made to them.\nHow does it happen?\nIdentity thieves take personal information from you out of your mailbox, your garbage, off of canceled checks, etc. Accounts can be opened with your name and address or your social security number.\nHow do I know if I've been a victim?\nChecking your credit report regularly will keep you apprised of what accounts are being credited to you. While not every inaccuracy in your credit report is an indicator of identity theft*, keeping track of what is yours and what you don't recognize on your report will let you know if someone else is using your credit.\n*Sometimes inaccuracies can just be due to poor record keeping on the part of the credit bureau. Yes, it does happen. The author of this article had her credit merged with a random man by the credit bureau.\nWhat do I do if someone steals my identity?\nUnder the Fair and Accurate Credit Transactions Act (FACTA), credit bureaus are required to place a fraud alert in the file of a consumer who believes he or she has been a victim of identity theft. That person must request it. The fraud alert can last from 90 days to 7 years, depending on what you request. Once an alert has been placed on your file, no new accounts can be opened with your information while the fraud alert is active. That means no one can open a new account, not even you. Further, anytime anyone requests information about your credit, the bureau may block information and must inform the requester of the fraud alert.\nWhen you discover or become suspicious that you are or may be a victim of identity theft, contact the credit bureaus and let them know as soon as possible. Do this to avoid being liable for charges made on accounts opened in your name by a thief.\nYour credit is your reputation. Take good care of it. Guard it. While there are ways to fix problems with your credit report, monitoring it is a good way to prevent your credit from becoming a mess.\nFor more information concerning identity theft, how to prevent it, and how to handle it if it's happened to you, see:\nHow Safe Are You?\nWells Fargo Bank has a quiz on its website to test how safe you are from identity theft as it relates to your bank and credit card accounts. It can be found here:https://www.wellsfargo.com/privacy_security/fraud/protect/quiz/\nSome basics on keeping your identity safe:\n- DO NOT carry your social security card in your wallet. It should be stored at home, in a safe deposit box, anywhere else that is safe and less likely to be lost or stolen.\n- DO NOT give out your social security number. Don't use it as a password, a customer number, a PIN number, or any other way that would make it less secure and more open to prying eyes and ears.\n- DO NOT volunteer personal information over the phone to people whose identity you cannot verify.\n- DO NOT respond to e-mails from senders claiming to be your financial institution, asking you to click on a link and change your information.\n- DO shred bank statements, credit card receipts and statements, and anything else with your address and account numbers on it, rather than simply tossing them. Identity thieves are dumpster divers. They don't mind a little muck if it means a new life for them yours.\n- DO be aware of your financial institution's way of handling possible identity theft.\n- DO be aware of online payment systems' policies for handling customer accounts (i.e., PayPal never sends out e-mails that simply say, \"Dear Customer.\" They ALWAYS use your name. NEVER click on links in e-mails that don't address you by name from PayPal. Just one of many)\n- DO keep your credit card numbers and credit card companies' phone numbers in a file so you can call and report lost or stolen cards", "label": 1}
{"text": "What is Malware?Malicious software (malware) is the wide range of software applications developed with a malicious intent. The methods used for malware installation is unlike any other software installation you are accustomed to because malware is installed through devious means. People often use the terms virus and malware interchangeably. However, a virus is a type of malware. Other major malware types include:\nA virus contains malicious code that attaches itself to an application. When the infected application is executed, the virus is launched and will attempt to spread to other computers. A virus typically will not cause immediate damage as it needs time to replicate in order to infect other computers. Eventually, the virus will deliver its payload. The payload can cause significant damage such as deletion of critical system files, random reboots of your computer, and can corrupt hard drives and make them unbootable. Viruses are delivered to systems in a variety of ways. Email is the most common method for spreading viruses. For example, spammers will email viruses as attachments and will entice users to download and open the attachment, which in turn will execute the virus. Users can also transmit viruses by using infected USB flash drives. Most operating systems have Autorun enabled, which enable infected USB flash drives to execute the virus as soon as the device is plugged into the machine.\nTrojan horses trick users by posing as legitimate applications. For example, a Trojan horse may appear to be a game or a screensaver. A deceived user will download the application and the Trojan horse is released once the user executes the program.\nUnlike viruses and Trojan horses, worms do not need to be executed. Worms reside within memory and can travel throughout a network without depending on an infected computer application or interaction. Worms replicate themselves exponentially and can literally crash networks by consuming its bandwidth.\nSpyware is installed on a machine without the user’s awareness or consent. Spyware attempts to gather specific user information and send it to a third party. You can determine if your computer is infected with spyware if your Internet home page has suddenly changed, if your web browser redirects web searches, or if additional software has been installed on your machine. Another form of spyware is adware. Adware launches pop-up windows to display unwanted advertisements.\nA logic bomb is malicious code embedded within an application that executes based on certain events. The logic bomb lies dormant until that event occurs. The event may be when a specific date is reached or if an employee’s record is removed from an organization’s payroll information system.\nA rootkit is the combination of programs designed to infect your computer without being detected. Your antivirus application communicates with your operating system to identify threats. However, rootkits breaks down this communication process. Consequently, your antivirus software will think that everything is fine and will not report that your computer is infected.\nYou can find security tools that will protect your computer from the above threats. In most cases, one tool is not enough. You may need to use a combination of utilities to fully project your system. Understanding the major types of malware can help you make informed decisions about acquiring tools to project your computer.", "label": 1}
{"text": "I deal with a lot of customers who area worried about Windows password attacks. These days, the biggest fear is of pass-the-hash attacks, a topic I've written about many times in the past couple of years.\nOften, when customers voice concern about pass-the-hash attacks, they ask me about cached log-ons in Windows. They've heard about the vulnerability and have read one or more whitepapers about it. Even Microsoft recommends disabling cached log-ons.\n[ Brace yourself for IT's 9 biggest security threats. | Find out how to block the viruses, worms, and other malware that threaten your business. | Learn how to protect your systems with InfoWorld's Security Central newsletter. ]\nIn fact, cached Windows log-ons aren't a big risk at all. I'll tell you why in a minute, but first, let's review the basics.\nHow cached passwords work\nWhen a user successfully logs on to a Windows computer for the first time, Windows creates a local user profile folder to store desktop and other user-related settings. For domain users, Windows will store a cached log-on as well. With future log-ons, if the domain user attempts to log on to the same domain but the Windows user cannot successfully contact a domain controller, Windows will log on the user locally if the user submits the same password (or other authentication credentials) entered in the last successful domain log-on.\nA common use for cached log-ons is to serve traveling laptop users. When the laptop user is connected to the home domain network, log-ons are verified by the domain controller. But when the laptop is away from its home domain, the user can still log on and use Windows because of the cached information. The password (or authentication credential) used during travel must be identical to the one previously cached while on the home network. When away, the submitted password is verified against something called the cached log-on password verifier, which is a one-way function of the user's previously submitted password.\nA case of mistaken identity\nIn thinking about cached log-on verifiers, users often make the error of equating them to normal password hashes (such as LANManager or NT hashes) that computer hackers are always stealing, replaying, and cracking. Fortunately, they aren't the same. The mistaken assumption is reinforced by Microsoft's recommendation, as documented in the Microsoft Security Compliance Manager tool, that cached log-ons be disabled.\nThe default cached log-on setting (located in group policy objects at Computer Configuration/Windows Settings/Security Settings/Local Policies/Security Options/Interactive Logon: Number of Previous Logons to Cache) is usually around 10 cached log-ons. This default setting goes back to Windows NT 4.0, if not longer. Now, Microsoft recommends that cached log-ons be set to 0, which disables it.\nThe bad thing about disabling cached log-ons is that many computers could be difficult to log on to, or even to troubleshoot or repair, if the computer cannot reach a domain controller. Many computers, even ones that never leave the home network, suffer quick, transient network problems, which cached log-ons help overcome.\nThe confusion over the security risk of the cached log-on seems to ensnare lots of Windows security experts. I've read more than a few security papers that have characterized removing cached log-ons as a highly critical recommendation. I have seen respected computer security firms find cached log-on verifiers on their customer's networks and point them out as hacking vectors that need to be addressed immediately.", "label": 1}
{"text": "Trusted name resolution with DNSSEC\nChain of Trust\nSome Internet exploits target name resolution servers. DNSSEC uses cryptography to protect the name resolution service.\nSystem administrators and security consultants have devised elaborate strategies for protecting computer networks, but one very basic part of the Internet infrastructure is still surprisingly vulnerable: the name resolution system. Intruders have developed sophisticated techniques for spoofing DNS responses. Of course, the white hats have fought back with their own defensive maneuvers, but experts agree that a fundamentally different approach is necessary. The DNS Security Extensions (DNSSEC) system  offers a comprehensive solution for authentication and data integrity for DNS.\nDNSSEC adds cryptographic signatures to the legacy name resolution service. But a signature can't solve the problem alone (because an attacker can create a signature, too). DNSSEC also needs a method for authenticating the public key used in the asymmetric encryption, which means the system must provide its own form of Public Key Infrastructure (PKI).\nTo help DNSSEC succeed, two groups must make a contribution: Users can only benefit from the system if network managers provide servers that use DNSSEC responses to validate their users. Name server managers must sign their zones and integrate them with the chain of trust in the superordinate zones . The free ISC BIND name server, which many regard as being a DNS reference implementation, provides solutions for both these objectives .\nDNSSEC name server extends its zone file. Besides administrative information in the SOA record, it mainly contains RRs that support mapping of DNS names to IP addresses or vice versa. DNSSEC uses signatures to protect the RRs. To do so, the DNSSEC introduces another series of RRs, as listed in Table 1.\nBecause the DNS system typically resolves names through a hierarchical chain of interacting name servers, DNSSEC can only guarantee authenticity if it operates at all levels of the chain. A complete solution therefore requires the adoption of DNSSEC on a massive scale. So far, the Swedish .se domain is the only top-level domain signed with DNSSEC, but many organizations have started implementing and experimenting with DNSSEC at lower levels. In this article, I will look at trusted name resolution with DNSSEC.\nPublic Keys for DNS\nThe first thing you will need is a resolver that supports DNSSEC. Because most stub resolvers can't do this – and the one in libc is no exception – administrators on enterprise networks will need to install a name server and enable its DNSSEC functionality.\nNow, thanks to DNSSEC, when clients on the network ask the server for IP addresses, the name server is guaranteed to return reliable results. Of course, the hop between the client and the first server is not safeguarded and theoretically could be manipulated. If you are responsible for security on your network, you will need to decide on an individual basis whether to take this lapse seriously.\nThe DNSSEC resolver now checks to see whether the query is for a DNSSEC-secured zone. If the requested target is on a secure island, this is always true. The top nodes in these structures are referred to as Secure Entry Points (SEPs, see Figure 1). Admins must make these entries the top priority on the DNSSEC resolver. Thus, the list of SEPs is the functional equivalent of providing CA certificates to a web browser.\nDNSSEC uses the same access mechanisms as legacy DNS. Because the resolver only requests Resource Records (RRs) from a server, the system is downwardly compatible. Additional security is provided by a DNSSEC-enabled resolver validating the signatures in the RRs. If a response is not correctly signed, it is discarded.\nBecause the user is never tempted to use a potentially compromised response, this is a very secure approach. However, users must get used to the server responding with NXDOMAIN, which means \"this domain does not exist.\"\nIn contrast to this, PKI will pop up a window with web certificates in the same situation. The user can decide how to react to the invalid certificate; unfortunately, many users just ignore the warning.\nIf the response does not come from a secure island, the resolver will resort to legacy methods to resolve it and then return the response to the requesting client. Security admins should be aware that, if they use DNSSEC, the user will not be able to tell whether or not a response is authenticated by DNSSEC.\nIn the long term, the DNSSEC lobby seeks to have just a single SEP that points to the DNS root zone. A chain of trust links the signing key with all the zones below it in the hierarchy. This lets DNSSEC resolvers validate signatures. On the Internet today, this is not the case, in that it is still just interspersed with independent secure islands. Until the islands grow together, resolver administrators still need to manage multiple trusted keys as SEPs.\nRichard Stallman calls for the W3C to remain independent of vendor interests.\nThe new release supports nine architectures, 73 human languages, and zero non-Free components.\nFedora developers release the first alpha version of Fedora 19, known as Schrödinger’s Cat, for general testing. The final release is expected in July 2013.\nack is a grep-like, command-line tool that has been optimized for programmers to search large trees of source code.\nNew features in SUSE Studio 1.3 include enhanced cloud integration, VM platform support, and lifecycle management.\nThe Linux Foundation recently announced that the Xen Project is becoming a Linux Foundation Collaborative Project.\nOpen source version of LiveCode is now available for developing apps, games, and utilities for all major platforms.\nOpenDaylight is an open source software-defined networking project committed to furthering adoption of SDN and accelerating innovation in a vendor-neutral and open environment.\nThe new Gnome release includes privacy and sharing settings, allowing more user control over access to personal information.\nMozilla is collaborating with Samsung on a new web browser engine called Servo.", "label": 1}
{"text": "This article can also be found in the Premium Editorial Download \"Virtual Data Center: What is cloud computing, and what can it really do?.\"\nDownload it now to read this article plus other related content.\nCloud computing got a big boost in credibility recently when major vendors jumped on board. But\nlost in the swarm of announcements are questions about what cloud computing is and what it can\nMany data center managers envision cloud computing as the ability to pool resources, charge customers based on actual usage and tap into extra external capacity when needed. This view of cloud computing is becoming possible through a blend of technologies like virtualization, Software as a Service, and Web-based applications.\nBut to achieve this computing nirvana, there are several questions about how clouds will work—and how companies’ technology architectures will work with cloud architectures. How can data center managers tap into cloud computing? And should they? How will cloud computing affect data centers with more than 1,000 servers? Which architectural and technological decisions affect a company’s ability to use and exploit cloud computing?\nThese critical questions will likely arise repeatedly as data center managers begin to navigate vendor hype to uncover the realities of cloud computing as well as its possible benefits for their organizations.\nNuts and bolts of the cloud\nTo start, it’s important to know that there are external clouds—such as pooled resources provided by third parties like Amazon and Google—and internal clouds—such as pooled resources internal to a company. The interaction between external clouds and internal\nSome related considerations include the following:\n- How well does a cloud-computing scenario work for many of today’s noWeb-based applications, or does truly harnessing the cloud paradigm require that organizations “re-architect” several internal applications?\n- How does an organization manage network connectivity between its private internal cloud and external cloud resources?\n- How can organizations provision, configure and customize external cloud resources appropriately?\n- How do external cloud resources gain access to the internal data they require in order to operate?\n- For applications running in the external cloud, how much bandwidth is required so these applications can access the internal data they require?\n- How does an organization provide access control?\nExisting technologies—such as virtual private networks and data replication— can address some of\nthese issues. VPNs, for example, can provide connectivity between external clouds and private\nclouds. And many VPN solutions also provide access control lists, or ACLs, for traffic running\ninside the tunnel, giving organizations fine-grain control over the traffic that moves from a\nprivate cloud to an external cloud. This approach helps to ensure that only authorized external\ncloud resources are allowed to communicate with appropriate resources in the private cloud and only\nvia authorized ports and protocols.\nData replication technologies may be able to address the need for external cloud resources to access certain data sets in order to function correctly. Vendor-independent replication technologies—those that are not tied to a particular storage vendor’s hardware, for example—will be particularly useful in this case, offering organizations and service providers alike greater flexibility and compatibility.\nAt the same time, however, VPN technologies and data replication topologies must be coordinated between an organization and its service provider and, therefore, can create some degree of vendor lock-in. Successfully using these technologies to solve practical challenges of cloud computing will require IT organizations and their service providers to work together much more closely than ever before.\nAs a result, the tight coordination of such technologies doesn’t extend to the rest of a cloud-computing solution. These close ties between an organization and a service provider make it more difficult and more costly for organizations to switch cloud-computing providers, effectively reducing portability.\nAlso, as the ecosystem of virtualization hypervisors becomes increasingly competitive—with Citrix Systems Inc.’s XenServer and Microsoft’s Hyper-V poised to compete with the market leader VMware Inc.—there are other factors undermining portability. Given that virtualization typically plays a significant role in cloud-computing environments, particularly in private clouds, the interoperability of hypervisors from different platforms and guest virtual machines (VMs) is a key factor in portability and, by extension, the widespread adoption of cloud computing.\nThese factors introduce even more issues. For example, will organizations be able to make a VMware ESX-powered internal cloud work properly with a XenServer-powered external cloud, and vice versa? Will an organization that currently uses a VMware ESX-powered external cloud be able to switch to a XenServer-powered external cloud? Will service providers be able to mask that complexity for users?\nVirtualization vendors now tout interoperability, hoping to answer these questions, but users have yet to see significant progress on this front.\nThree major areas of interoperability that have yet to be addressed are VM definitions, virtual\nhard disks and para virtualized device drivers. Until efforts to address these areas bear results,\ndata center managers need to be wary of the claims of seamless scaling and fluidity that cloud\ncomputing supposedly offers. Leveraging cloud computing today may reap benefits for some\norganizations and some applications, as long as data center managers are fully aware of—and plan\nStumbling over cloud-computing compatibility\nWork is already being done to address the key compatibility issues: VM definitions, virtual hard disks and para virtualized device drivers. Some of these efforts, though, are still early in development. For example, on the VM definition or configuration front, the Open Virtualization Format (OVF)—also referred to as Open Virtual Machine Format—has been approved as a standard, yet broad support for the format is still lacking.\nVMware has the most complete implementation, while Citrix, Microsoft, Novell Inc. and others lag\nbehind. Organizations that want to leverage cloud computing should not count on using OVF to help\nprovide greater compatibility until all of the major vendors have shipped OVF support in their\nproducts. Note that some vendors have announced support for OVF, but that support has yet to be\ndelivered to users in the form of actual products. Furthermore, adoption of the standard doesn’t\nnecessarily resolve other key cross hypervisor compatibility issues.\nVirtual hard disk formats, in the form of VMware’s Virtual Machine Disk format and Microsoft’s VHD formats, pose another compatibility issue. The OVF specification supports both formats, and each vendor offers the ability to read or convert another provider’s format, but what about native read/write functionality?\nMicrosoft and Citrix each have a slight upper hand here, in that both natively support the VHD format, but VMware’s Virtual Machine Disk format is the market leader. Both camps have taken steps to make their virtual hard disk formats the default by opening up specifications to third-party developers, but neither format has emerged as the clear, de facto standard.\nThe use of hypervisor-specific para virtualized device drivers is another key compatibility\nissue that the virtualization industry has yet to address. All major virtualization providers use\npara virtualized device drivers to optimize performance of VMs running on their virtualization\nplatforms. VMware Tools, Microsoft’s enlightenments and Citrix’s Xen Tools are examples of para\nvirtualized device drivers. Again, by virtue of their interoperability and cross-licensing\nagreement, Microsoft and Citrix each have a slight advantage here, making it more likely that\nXenServer and Hyper-V VMs will be compatible in this realm.\nBut VMware still controls the lion’s share of the market. This dominance leaves customers without a clear standard on para virtualized device drivers in cross-virtual platform environments.\nSo how have the major vendors tried to address these key issues? It’s worth noting that the big three players in this area—VMware, Microsoft and Citrix— have taken different approaches to address the challenges for widespread adoption of cloud computing. Here is how each positions itself:\nVmware: Hoping to leverage its market leadership in the cloud-computing space, VMware’s\napproach lies in its vCloud initiative, which is based on its close partnership with service\nproviders, the use of virtual appliances and vApps, and the ubiquitous presence of the ESX\nhypervisor and supporting applications, in particular vCenter, formerly known as VirtualCenter.\nVMware intends to partner with several service providers that will use its software to build\nexternal clouds powered by the ESX or ESXi hypervisor and that are managed—or manageable —by\nTogether with virtual appliances and vApps, the OVF standard enables portability between these external and internal clouds. The vApps technology can be considered an extension of the OVF standard and can incorporate information about that application’s service-level agreement, disaster recovery requirements, security needs and other policy information. With vApps and the OVF, organizations could move applications from one “VMware-ready vCloud” to another relatively easily.\nAnd, because service providers offer ESX- or ESXi-based virtualization, it means that applications—in the form of vApps, virtual appliances or VMs with an OS and application installed—can be easily shared and transferred between internal and external cloud infrastructures. VMware has said that it plans to expose vCloud application programming interfaces (APIs) that enable even greater integration between internal cloud infrastructures and external cloud providers.\nIn that particular scenario, organizations would use VMware vCloud when they use VMware virtualization internally by “federating” a private cloud with an external VMware-ready vCloud service provider. Although the precise mechanics are yet unknown, the idea is that organizations could then move workloads from an internal cloud to an external one or spin up additional VMs at the external provider to handle additional load.\nCitrix: In some respects, Citrix’s answer to the cloud—Citrix Cloud Center (C3) —is similar to VMware’s. Naturally, Citrix XenServer is a key component of C3. Citrix will deliver a special version of XenServer—XenServer Cloud Edition— that incorporates all the functionality of traditional XenServer plus consumption based pricing so that service providers can charge based on metered resource usage.\nC3 joins XenServer Cloud Edition with NetScaler to provide policy-based application performance management. NetScaler integration will enable organizations to dynamically scale the number of VMs based on user demand to balance workloads across cloud environments or, in the event of failures or outages, to redirect traffic transparently. NetScaler also offloads some protocol and transaction processing from servers, providing greater scalability.\nWANScaler is another part of the package that provides acceleration and optimization of traffic between external and internal clouds. Citrix Workflow Studio aims to unify these different components. Like VMware vCloud, Citrix will offer this functionality to service providers. Citrix has focused less on the dynamic movement of workloads between internal and external clouds and more on application delivery via NetScaler and WANScaler, which gives C3 some advantages over vCloud.\nSimilar to how VMware-using organizations would take advantage of Vmware vCloud, organizations using XenServer —or potentially the open source Xen hypervisor—internally would partner with service providers using C3 to provide the ability to shift workload processing based on demand. C3’s integration with NetScaler enables the latter to become the vehicle by which workloads are shifted internally or externally or are load-balanced between the two based on business-driven policies. If demand dictates, NetScaler can also activate additional VMs. WANScaler optimizes traffic between internal and external clouds as workloads shift.\nMicrosoft: Windows Azure, Microsoft’s cloud-computing initiative, is quite different than the rest. Rather than relying on virtualization as a key building block, Microsoft has exploited its massive developer base and the leadership of .NET as a development platform to build a new cloud-computing environment. Microsoft touts Windows Azure as a “cloud services operating system” that is designed to provide “on-demand compute and storage to host, scale and manage Web applications on the Internet through Microsoft data centers.”\nAnd although VMware and Citrix tryto help service providers build their own clouds through the use of their virtualization software, Microsoft instead seeks to be its own service provider. External service providers won’t be able to buy Windows Azure, or the Azure Services Platform. These integrated components will be managed and maintained directly by Microsoft.\nThe other major differentiator of Windows Azure and the Azure Services Platform is that organizations seeking to host their applications in an Azure-powered cloud must port their applications over to Azure because unmodified applications won’t run on Azure. Although Microsoft said it will support third-party languages like Ruby, PHP and Python, the requirement that applications be ported to run on Azure suggests that applications won’t run elsewhere, even in a private cloud infrastructure. Naturally, Microsoft is not talking about merging internal and external clouds or about shifting workloads between clouds because none of that seems to be possible with its approach.\nUnlike organizations seeking to take advantage of VMware vCloud or C3, those that want to leverage Windows Azure will need to port their Web-based applications over to the Azure Services Platform, where it will run in data centers that are owned and managed by Microsoft. Within these data centers, Microsoft’s Azure Services Platform will be able to distribute workload processing across many different physical servers and add or remove processing capacity as needed.\nThere would be no shifting of workloads between clouds. Instead, the processing and hosting would occur within Microsoft’s cloud. In this sense, Microsoft is more of a competitor with other cloud-computing service providers than a provider of cloud-computing infrastructure.\nAs the dust settles in the cloud-computing market, the initiatives from the major vendors—VMware’s vCloud, Citrix’s Cloud Center (C3) and Windows’ Azure—are grand strategic visions that present different notions of a cloud architecture. What’s conspicuously absent, however, are key definitions, standards, compatibility, interoperability, security and privacy.\nVendors that have jumped into this market have yet to provide concrete, substantive answers on how these questions will be addressed. Until they do, the strategic vision of pervasive cloud computing will not likely see the explosive growth that many experts and industry pundits have predicted.\nSo what should data center managers do until then? How should they prepare? Data center managers need to recognize that cloud computing may benefit only a portion of their overall set of applications. Until the challenges around portability, compatibility and security are resolved, cloud computing involving external providers may need to be constrained to specific applications and/or specific user populations. As standards evolve and vendors increase their support for these standards, then data center managers can begin to look to cloud computing as a broader solution and can trust more of their applications to this new computing paradigm.\nAbout the Author\nScott Lowe is a senior engineer at ePlus Technology Inc., a provider of technology solutions based in Herndon, Va. Lowe’s experience in enterprise technologies includes storage area networks, server virtualization, directory services and interoperability. He has worked as the president and chief technology officer at Mercurion Systems and as the CTO of iO Systems.\nThis was first published in February 2009", "label": 1}
{"text": "Kids, you've heard of phone calls, right? Did you know that there's an app on your smartphone that lets you talk out loud to family and friends? Ask your grandparents about it.\nWe're being facetious, but it's true that the stereotype of a chatty teen or young adult spending hours talking on the phone is fading. Those interactions are being replaced by the image of a kid hunched over a handset, tapping out texts, emails, or Facebook messages.\nTwo new pieces of research highlight just how common that image has become.\nA British study conducted by independent media regulator Ofcom found that among 16- to 24-year-olds, phone calls are being superseded by texts or other e-messages. Per the research, 96 percent use some form of text-based communication -- either though social networks (73 percent) or through traditional texting (90 percent) -- on a daily basis. By comparison, only 67 percent of that age group talks on the phone daily. Overall, total time spent on the phone declined 5 percent for Britons of all ages, the first such drop since the 1990s, according to The Guardian.\nAnd new research from Pew finds similar trends among teens stateside. As NBC News explains, 63 percent of teens text every day, compared to only 39 percent making or taking cell phone calls daily. And it seems social networking (29 percent daily use) and instant messaging (22 percent) are increasingly taking up U.S. teens' time, too.\nTaken together, these studies appear to foreshadow a time in the not-so-distant future when text-based messages are the norm and phone calls are thought of as a quaint, nonessential way to get in touch.\nIn fact, that day may come sooner than you think, if the chief executive of one of the largest American phone carriers is to be believed. \"I'll be surprised if, in the next 24 months, we don't see people in the market place with data-only plans,\" AT&T CEO Randall Stephenson said at a conference in June. \"I just think that's inevitable.\"\nConsider it the beginning of the end of the phone call as we know it, with teens leading the trend.\nContact Your Phone\n<a href=\"http://www.pcmag.com/article2/0,2817,2363526,00.asp\"target=\"_blank\">PCMag</a> recommends using another phone to text your lost phone with a message offering a reward for the device, and you can always try calling it as well. If you don't have a phone handy, you can use a service like Skype, Google Voice or <a href=\"http://www.fonefindr.com/\"target=\"_blank\">fonefindr.com</a> to ping your phone. It can't hurt -- someone may have found your phone or maybe you'll find hear it ringing between the couch cushions.\nCall Your Carrier\nAfter you've called or texted your phone, retraced your steps, and shed a few tears in frustration over losing your precious device, you'll want to call your cellphone carrier immediately and tell them your phone has been lost or stolen. Ask them to suspend service (i.e. disable messaging and calls) on the device, because thieves could rack up thousands of dollars in international calls or app purchases. AT&T will even let you do this from your <a href=\"http://www.wireless.att.com/answer-center/main.jsp?t=solutionTab&solutionId=KB63935\"target=\"_blank\">account on the Web</a>.\nPassword Protect Your Phone\nWith all the messages, years of email, contacts, social networking accounts and other personal data stored on today's smartphones, we can't recommend password protecting your phone enough. Yes, it's a momentary frustration that requires you tap a few numbers every time you check your phone, but the extra security and peace of mind is worth the effort. While a thief could still wipe a password-protected device and there's always the possibility you just lost the phone for good, the alternative (going password-free) leaves not only your cellphone account but your bank, social networking, and e-mail accounts completely open. If your phone <em>was</em> stolen and you haven't locked it down, immediately change the passwords to your online accounts and alert any banks or services that you enabled on the phone.\nUse Remote Protection Apps\nMany remote security apps are now available for modern smartphones, and they offer everything from near real-time location tracking (often showing your phone's location on a map via a Web interface) and the ability to remote wipe your phone in case of theft to remote photo and data backup. There are many free options, and they take just a few minutes to install and set up. Your corporate BlackBerry can probably be wiped and tracked by your company's IT admins, and consumers can grab the free BlackBerry Protect from <a href=\"http://us.blackberry.com/apps-software/protect/\"target=\"_blank\">BlackBerry App World</a> for remote tracking and wiping. iPhone users should download the free '<a href=\"http://itunes.apple.com/us/app/find-my-iphone/id376101648?mt=8\"target=\"_blank\">Find My iPhone</a>' app Android users can grab the free <a href=\"http://preyproject.com/\"target=\"_blank\">Prey</a> app. Similarly, other third party solutions like <a href=\"http://www.mobiledefense.com/\"target=\"_blank\">Mobile Defense</a>, <a href=\"https://www.mylookout.com/\"target=\"_blank\">Lookout</a> can help secure your device.\nSave Your Phone's Unique ID\nTake a note of your phone's ESN, IMEI or MEID number (often found behind the battery or on the back of the iPhone near the FCC ID). This number will come in handy when reporting a lost or stolen phone to the police or to your cellphone provider.\nSchedule Regular Backups\nIt sounds obvious, but regularly back up your device to your computer to ensure that you don't lose essentials documents, purchases, apps and photos that are stored only on your phone. Even if you're forced to wipe your cellphone or if it's lost for good, you can often restore a factory fresh replacement to the last backup you've got, complete with apps, settings and documents. Depending on how much you use your phone, we recommend backing up between once a month and once a week.", "label": 1}
{"text": "Computer Forensics Schools and Education\n- Find a Computer Forensics School\n- Find Computer Forensics Education Requirements and Information\n- Find Computer Forensics Career Salary Information\nComputer crime is one of the fastest-growing types of crime in the world. With the Internet expanding, and email, social networks, ecommerce and texting so common, personal and corporate computers, cell phones and tablets, and other hand-held devices have become extremely vulnerable to attack. This has created an increased need for computer forensics analysts and investigators.\nWhat Do Computer Forensics Investigators Do?\nComputer forensics investigators are taught to combat crimes ranging from crimes against children to file system recovery on hacked or damaged computers. Computer forensics investigators—also known as a computer forensics specialists—recover data from digital media that may be used in criminal proceedings. Digital media refers to all methods of electronic data storage and transfer devices including computers, laptops, cell phones, PDAs and the documents, images, spreadsheets and other types of files stored on these devices. Once a computer forensics investigator retrieves the necessary information, they'll prepare detailed written reports on the collected data that may later be presented in court. Part of a computer forensics investigator's job is to testify in court regarding the information they recover and the methods they used to get that information.\nComputer forensics consulting firms and freelance computer forensic investigators are also hired by large corporations to test the security of their information systems. Computer forensic specialists may mimic how a malicious hacker might attempt to gain access to a corporation's computer network. But the best place to get the education you need is in computer forensics school.\nRequirements to Become a Computer Forensics Investigator\nComputer forensics is a relatively new field, so there have not been consistent requirements to become an analyst. Many individuals get their computer forensics skills by working in law enforcement or the military. Now that more colleges are offering computer forensics degrees and related information systems (security degrees/cyber crime degrees), education has become an important requirement to stay competitive in the industry. This includes continuing education once you've found a job to stay current in this rapidly changing field.\nComputer Forensics Education\nWe put together a collection of the skills you should look for in your computer forensics program to prepare you for a career in computer forensics. We consulted with leaders in the field of computer forensics and compiled their thoughts. Here's what they had to say:\nIndividuals should take courses in incident handling, investigation, management, protection, detection and reaction. They should study Internet crimes against people and children, learn about presenting digital evidence at trial, network security intrusion and detection, personal digital device forensics and advanced-file system recovery. Law and business are also critical to success in a computer forensics career.\nOne individual emphasized that a comprehensive knowledge of UNIX and NT is essential to retrieving deleted files and evidence of breaches in system security. We were also told that advanced knowledge of networking and routing has become increasingly important with the growth of the Internet and email.\nAll of the people we spoke with agreed that individuals with a desire to become computer forensics investigators should begin by earning a degree in computer forensics or a related degree such as information systems security or cyber crime.\nInformation systems security and computer forensics degrees are offered at the associate's, bachelor's and master's degree levels. An associate's degree along with a law enforcement internship is sometimes enough to be hired by a police department as a computer forensics investigator. Associate's also transition well into bachelor's degrees. Graduate degrees are usually 2-year programs and may advance your career and increase your salary in computer forensics. Some computer forensics careers require certifications such as, CISSP, CISM, CISA or CCSP.\nComputer Forensics Investigator Salary\nAccording to the U.S. Bureau of Labor Statistics' 2012-13 Occupational Outlook Handbook, the median national annual salary for information security analysts is $75,660. Actual salaries may vary greatly based on specialization within the field, location, years of experience and a variety of other factors. Freelancers and those working in consulting firms can earn even more and the BLS estimates that 17 percent of those analysts working are self-employed.\nRequest information from the accredited online schools below. The degree programs offered here may provide you with the skills to succeed as a computer forensics investigator.\nOnline Criminal Justice Schools\n- Doctor of Business Administration (DBA) - Computer and Information Security (Online)\n- PhD in Business Administration - Computer and Information Security (Online)\n- Master of Business Administration (MBA) - Computer and Information Security (Online)\n- Master of Science (M.S.) in Information Technology (Online)\n- BSIT/Information Systems Track - Information Security and Forensics (Online)\n- Associate's - Network Security\n- Bachelor's - Network Security\n- Bachelor of Information Technology - Digital Investigation (Online)\n- Bachelor of Information Technology - Information Assurance and Security (Online)\n- Master of Information Technology - Information Assurance and Security (Online)\n- Bachelor of Science in Information Technology - Security (Online)\n- Doctor of Computer Science in Digital Systems Security - Executive Format (Online)\n- Doctor of Computer Science in Information Assurance - Executive Format (Online)\n- Master of Science in Computer Science - Computer Systems Security (Online)\n- Master of Science in Information Technology - Security Management (Online)\n- Master of Science in Information Security - Technical Track (Online)", "label": 1}
{"text": "In the last article, you learned that a cryptosystem is used to protect the privacy, integrity, and authenticity of data as it traverses a network. In today's article, we'll see how the SSH cryptosystem provides these features.\nIf you're using at least FreeBSD version 4.0, your FreeBSD system uses OpensSSH and it is installed and ready to go. As the name implies, this is an open source implementation of the SSH cryptosystem. You can read more about it at the OpenSSH website.\nIn a previous article (see IP Packets Revealed), I demonstrated that the telnet utility can be used to login to a remote computer from another system. Once logged in, a user can do anything on that remote system as if he were physically sitting in front of it. That is, every keystroke is sent to the remote system and interpreted as if it had come from the keyboard attached to that remote system (even though that keyboard input first had to travel over a network). We also saw in that article that every single keystroke and response was sent in clear text, meaning that a sniffer could watch the entire session.\nAny SSH cryptosystem will allow a user to login to a remote system and work just as if he were physically there. However, before the user is given a login prompt, a key will be generated to encrypt and decrypt all of the data that will be passed between the two computers. That is, more is happening behind the scenes.\nSince SSH is used to access another computer, a user account must exist on the computer to be accessed. Additionally, the computer being accessed is known as the SSH server and must be running the SSH daemon; by default, this daemon listens on TCP port 22. The machine you are sitting at is known as the SSH client; it will contact the daemon on the other machine.\nYour FreeBSD system has default configurations that allow you to use SSH as is. I'll demonstrate the default configuration first, then move on to some changes you may wish to make to increase the security of SSH.\nI'll be using two computers. 10.0.0.1 will be the SSH daemon, the computer\nI wish to access, and 10.0.0.2 will be the SSH client, the computer I'm sitting\nat. On both systems, I have created a user account called \"genisis\". You'll\nnote that the cryptosystem is called OpenSSH. It uses a protocol usually\nwritten as uppercase SSH, and the commands you type,\nsshd, are written in lowercase. Also, you can use the\nssh command to access either an IP address or a hostname. In\nthis week's article, I'll purposefully use IP addresses. In the next\narticle I'll take a closer look at name resolution issues when using SSH.\nFirst, I need to check if the host keys have been created on the system that will be the server. At 10.0.0.1, I'll run this command:\nIf I get this output:\nmoduli ssh_host_dsa_key.pub ssh_host_rsa_key ssh_config ssh_host_key ssh_host_rsa_key.pub ssh_host_dsa_key ssh_host_key.pub sshd_config\nI have the necessary keys. However, if I instead get this output:\nmoduli ssh_config sshd_config\nthere aren't any host keys and I will need to generate them before I can start the SSH daemon. If I'm impatient and try to start the SSH daemon before creating the keys, it will refuse to start and I'll instead receive this error message:\nsshd Could not load host key: /etc/ssh/ssh_host_key Could not load host key: /etc/ssh/ssh_host_dsa_key Disabling protocol version 1. Could not load host key Disabling protocol version 2. Could not load host key sshd: no hostkeys available -- exiting.\nThere are several ways to generate those missing keys. If you are an\nadvanced user who is comfortable with reading startup scripts, search for\n/etc/rc.network to see which commands your\nFreeBSD system uses to generate the host keys. I'll instead demonstrate the\nresults of running that script. The easiest way to ensure the necessary keys\nare generated and that SSH starts whenever the system reboots is to add the\nfollowing line to\nOnce I've saved my changes, I'll type:\nWhen I get a prompt back, I'll press enter and then type the word exit. As my startup scripts are reinitialized, I see the following message:\nStarting final network daemons: creating ssh1 RSA host key Generating public/private rsa1 key pair. Your identification has been saved in /etc/ssh/ssh_host_key. Your public key has been saved in /etc/ ssh/ssh_host_key.pub. The key fingerprint is: 12:d9:3d:f3:95:92:0e:e7:6b:54:09:80:77:a0:3e:cf root@hostname creating ssh2 RSA host key Generating public/private rsa key pair. Your identification has been saved in /etc/ssh/ssh_host_rsa_key. Your public key has been saved in /etc/ssh/ssh_host_rsa_key.pub. The key fingerprint is: 4b:cf:7e:af:f1:a8:01:08:64:1b:c0:79:e3:a2:58:78 root@hostname creating ssh2 DSA host key Generating public/private dsa key pair. Your identification has been saved in /etc/ssh/ssh_host_dsa_key. Your public key has been saved in /etc/ssh/ssh_host_dsa_key.pub. The key fingerprint is: 22:69:d7:05:23:c6:db:d9:55:2a:20:a3:34:bd:f4:ef root@hostname\nLet's take a look at that output. You'll note that three separate key pairs were generated: one for rsa1, one for rsa, and one for dsa. You should recognize the RSA and DSA acronyms from the last article on cryptographic terms. But why so many key pairs? There are two versions of the SSH protocol, and OpenSSH supports them both. Not surprisingly, the rsa1 keypair is used by SSH version 1. You can see from the output that ssh2 (version 2) supports both RSA and DSA.\nPages: 1, 2", "label": 1}
{"text": "A new scheme in the UK aims to find the next wave of British computer security experts in a bid to tackle cybercrime.\nThe Cyber Security Challenge (CSC), which is based on a similar scheme already running in the US, is backed by a number of organisations including the Metropolitan Police and the Institute of Information Security Professionals.\nEntrants will be required to solve online games and challenges using eight key skills such as programming, digital forensics, network analysis and logical thinking.\nA Cyber Security Challenge is already running in the US\n\"We are increasingly dependent on networks and computer systems. The whole digital economy and society is structured around them,\" Judy Baker, director of the Cyber Security Challenge, told the BBC.\nBaker said those that show the most aptitude in the games will go through to a second stage, which is likely to include practical texts.\nThose that excel in these tests will be receive mentoring, training and scholarships to hone their skills.\n\"There's a real need for people with these skills and they can give great value back to the nation as a whole,\" Baker said highlighting that many firms have failing to recruit enough skilled member of staff to deal with computer security issues.\nCyber Security Challenge is expected to start this autumn and is open to those aged 16 and over.", "label": 1}
{"text": "1-18-2009 Virus spreads quickly\nA computer virus that may leave Microsoft Windows users vulnerable to digital hijacking is spreading through companies in the U.S., Europe and Asia, already infecting close to 9 million machines, according to a private online security firm.\nThough computer bugs have become a common affliction, Finland-based F-Secure says a virus it has been tracking for the past several weeks has surged more rapidly through corporate networks than anything they've seen in years.\nF-Secure's chief security adviser, Patrik Runald, said the virus's coding suggests a type of bug that alerts computer users to bogus infections on their machines and offers to help by selling them antivirus software.\nInstead, the virus is simply spreading to little effect, though it may still pose a threat to infected computers.\n\"The gang behind this worm haven't used it yet,\" F-Secure's chief research officer, Nikko Hypponen said by phone. \"But they could do anything they like with any of these machines at any time.\"\nMicrosoft issued a security update Tuesday to deal with the so-called \"Downadup\" or \"Conficker\" virus, which appears to be a new version of a bug that popped up in October.\nMost computers with Windows will automatically download Microsoft's security update, but Hypponen said the virus disables updates on infected machines.\nWhile the origin of the virus is a mystery, F-Secure's best guess is it came from Ukraine. Hypponen said it is coded to avoid computers there, which may indicate whoever wrote the virus was trying to avoid drawing attention from local authorities.", "label": 1}
{"text": "I'm looking for information on what NSA suggested for use in commercial systems in past times. 90's and early 2000's.\nI'm mainly interested in PKI and symmetric cyphers for SSL and file/disk encryption.\nNSA did not publicize their involvement in national standards. So, the exact role NSA played in algorithms and documents may be difficult to determine.\nIn 1987 the U.S. Congress passed the \"Computer Security Act\" which was intended to limit the role of the National Security Agency (NSA) in the development of civilian standards.. The act also authroized the U.S. government to develop standards for publicly available cryptography as most of the encryption up to this point was intended for military use.\nThe National Institute of Standards and Technology (NIST) had previously published FIPS 46 specifying The Data Encryption Standard in 1977. 1988 NIST issued FIPS 46-1 continuing to support DES. IN 1993 NIST published FIPS 46-2 which again supported DES. It wasn't until 1999 that NIST recommended using Tripple DES also known as 3DES.\nIn 1991 NIST published FIPS 186 The Digital Signature Standard (DSS). EPIC claims that the NSA actually produced the technology behind DSS. DSS became an official standard when approved by the U.S. Secretary of Commerce.\nIn 1994 NIST publishes FIPS 185 Escrowed Encryption Standard (EES) The most well know implementation of the standard was the Clipper Chip. EPIC describes Skipjack, the cryptographic algorithm used by ESS as 'developed by the National Security Agency' The Clipper Chip and ESS are failures whith little to no adoption. NIST also publishes FIPS 140-1 a standard for commercial development of cryptographic modules.\nIn 1995 NIST published FIPS 180 Secure Hash Standard (SHS) which describe the Secure Hash Algorithm (SHA-1). Wikipedia describes SHA-1 as being 'designed by the National Security Agency and published by the NIST'\nIn 1996 NIST publishes FIPS 186-1 a minor revision to FIPS 186 describing the Digital Signature Standard (DSS).\nIn 1997 NIST anounced the Advanced Encryption Standard competition. An open competition to select an algorithm to replace DES.\nIn 1999 NIST publishes FIPS 46-3 recommending Tripple DES (3DES) for new systems and the continued use of DES for legacy systems.\nIn 2001 NIST publishes FIPS 140-2 and makes revisions based on new technology and comments received from the vendor, tester, and user communities.\nIn 2002 NIST announced the winner of the AES competition and published FIPS 197 Advanced Encryption Standard (AES)\nNSA was undergoing a transformation on the subject question during the timeframe you are questioning.\nIn the previous two decades through the mid 90s NSA advocated for no strong privately controlled public encryption. This position surfaced with their clash with MIT over the work of the famed RSA crew Ron Rivest, Adi Shamir, and Leonard Adleman resulting in the rushed publishing of same in 1976. Federal funding for MIT was threatened during that dust up. That position continued through the next 15 years highlighted by the flare up with Phil Zimmermann and PGP which almost landed him in prison. By 1993 NSA was advocating the ‘Clipper Chip’ solution (using Skipjack) which created a back door key escrow for all public encryption. The pushback against the concept was great from both academia and the common computer enthusiast. That sets the stage for the period you question.\nTimes were changing as the Cold War ended, BBS-based personal computing was replaced by web browsing based on the Netscape browser with its PKI SSL solution, and with those changing times so changed NSA. By July 2000 NSA had gone so far as to partner with Network Associates, the owners of Zimmerman’s PGP at that point, to create a free open source operating system – SELinux. NSA by that point embraced publically available encryption as we know it today and provided hardening recommendations using same. You can find specifics at http://www.nsa.gov/ia/guidance/security_configuration_guides/archived_guides.shtml . Keep in mind that NSA was actually just joining the public using commercial standards of the day in the period you are questioning.", "label": 1}
{"text": "Let us guess: you have profiles on Facebook, twitter, MySpace, Foursquare, Reddit, Digg, Yelp, and the list goes on. You have separate email addresses for work, friends, spam, and some you can’t even remember. You’ve created countless accounts all across the web to track your online shopping orders, comment on blog posts, enter contests, share photos, and take quizzes.\nYou’ve reached a point where you can’t remember all of the sites on which you’re registered, let alone your password, so you’ve started using the same password (or a slight variation of it) on every site you visit. You’re hoping that you won’t fall victim to identity theft, or that spammers won’t figure out your go-to password.\nIf this sounds like you, we have good news and bad news for you.\nFirst the bad: each year, more than 15 million Americans fall prey to identity theft and fraud because of online security breaches. Maybe you’ve avoided it up until now, but odds are you won’t be so lucky in the future.\nNow the good: Abine’s PrivacySuite, a free browser-add on that runs in the background while you’re online, keeps track of all of your online accounts and passwords. It even generates random, encrypted passwords to make sure your accounts stay safe.\nPeople tend to make a few common mistakes regarding password security.\nFirst, we don’t create sufficiently safe passwords. The best passwords are easy for you to remember but hard for others to guess. Unfortunately, however, many of us worry more about remembering our passwords instead of making them secure.\nWhat makes a secure password?\nA combination of length, content, and how often you change it. In general, longer passwords with a wider variety of capitalization, letters, numbers, and symbols are the most secure, and the more often you change them, the better. The harder it is for others to guess, the safer it is. A few examples of notoriously bad passwords:\n- your first or last name\nOur second problem: we reuse our passwords everywhere.\nA 2003 survey found that 65% of us use the same password for different applications or services. We’re only human; we can’t keep hundreds of different username and password combinations in our heads at all times. But in our effort to try to keep things simple, we expose ourselves to a great deal of risk. Think about it: a spammer who discovers your password on, say, Facebook, can then access all the other sites where you use it: PayPal, your online banking site, your phone service, your email, and everywhere else.\nPrivacySuite takes care of both password security and complicated account management.\nIf you already use your browser to remember existing passwords and automatically fill in forms, PrivacySuite can import all of those passwords into one place. The next time you want to visit Facebook, for example, PrivacySuite can automatically fill your username and password and log you in, all in one click. You can also start fresh and have PrivacySuite start remembering your logins when you begin using it. With PrivacySuite, you’ll never have to memorize another username or password again.\nWhat about the passwords you’ve been constantly reusing? PrivacySuite lists all of your accounts and rates the strength of the passwords you use on them. A green circle next to your password means that it’s strong: it’s unique, difficult to crack, and you don’t use it often. Yellow means that you’ve reused it a few times, and red means that you reuse it often. With a quick glance, you’ll be able to see how all your passwords rank in terms of security.\nAnd if your passwords aren’t as strong as you’d like, you can use PrivacySuite to generate secure ones as you browse. Just right click in the password box, click “fill password,” and PrivacySuite creates an 8-character random password using mixed case and numbers and letters. Best of all, PrivacySuite then saves the password you just made so you’ll never have to keep track of it.\nPrivacySuite securely organizes your online accounts and stores your passwords in an encrypted form on your computer, keeping them safe from scammers, hackers, and advertisers. No other person or company can access your information, not even our servers.\nIf you want more control, organization, and security in your online life, try PrivacySuite today.\nA bit about us: Abine’s Privacy Suite and DeleteMe services help you stay private when you surf online, stay private when you enter your personal info into forms, and reclaim your privacy if you have info or accounts online you’d like removed. Many of these services are free or reasonably priced, and come directly from us at Abine, The Online Privacy Company.", "label": 1}
{"text": "In 1983, Americans watched as Matthew Broderick, armed with only a personal computer, brought the world to its knees. In the popular movie WarGames, Broderick played a young hacker who broke into the military’s electronic network and nearly started World War III. In recent years, as fear of terrorism continues to overwhelm rational threat assessment, the WarGames scenario looks a lot like what so-called cybersecurity experts and their federal government allies tout.\nThe problem with “cybersecurity,” says Jim Harper, director of information policy studies at the Cato Institute, is that we’re convincing ourselves that cyberspace is an endless sea of vulnerabilities that leave us weak and exposed. It’s not. Harper has emerged as the voice of reason among breathless news reports of “cyber attacks” and calls for Washington to take over security of the nation’s computing infrastructure. In his papers, congressional testimonies, and numerous media appearances, Harper emphasizes the need to better understand the nature of cyberspace, to appreciate the improvements in cybersecurity civil society is constantly generating, and to recognize the near impossibility that terrorists might inflict significant harm using computers.\n“It’s helpful to imagine ‘cyberspace’ as organized like the physical world,” Harper says. “Think of personal computers as people’s homes. Their attachments to the network analogize to driveways, which connect to roads and then highways. E-mails, financial files, and pictures are the personal possessions that could be stolen out of houses and private vehicles, leading to privacy loss.”\nCyberspace will be secured the way real space is. Computer owners, like homeowners and businesses, should be the first line of protection for their own property, Harper says. They should install the latest patches and place their systems behind firewalls. What the government wants — to come up with a national cybersecurity plan and force it upon network, data, and computer owners — is akin to cutting down crime in neighborhoods by stationing police officers in livingrooms and dictating what sorts of door locks and alarm systems must be in all new homes.\n“The analogy between cyberspace and real space shows that ‘cybersecurity’ is not a small universe of problems, but thousands of different problems that will be handled in thousands of different ways by millions of people,” Harper says. This analogy is particularly important when the topic shifts from broad “cybersecurity” to the narrower threat of “cyberterrorism.”\nThe popular view of such attacks, like WarGames, is nonsense, according to Harper. “With communications networks, computing infrastructure, and data stores under regular attack from a variety of quarters — and regularly strengthening to meet them — it is highly unlikely that terrorists can pull off a cybersecurity event disruptive enough to instill widespread fear of further disruption,” Harper says. If they could do it at all, taking down websites, interrupting financial networks, or knocking out power systems does not terrorize. In a 2009 speech about cybersecurity, President Obama spoke about “weapons of mass disruption,” a poor relation of the instruments that truly threaten violence and chaos.\nThe federal government plays a significant role in protecting Americans from genuine terrorism. And, even though the threat of cyberterrorism is dramatically overblown, the government can improve security in that area, too. But it should not do so through regulation, Harper says. Instead, it can take advantage of its position as a large purchaser of information technology and, through the market, guide technology producers to meet better security standards.\nThe politicians in Washington should realize that the easiest way to protect critical data and infrastructure is not to make it vulnerable in the first place. “Where security is truly at a premium,” Harper says, “the lion’s share of securing infrastructure against cyberattack can be achieved by the simple policy of fully decoupling it from the Internet.”\nHarper’s level-headedness is getting attention. The Obama White House cited a paper he wrote in the executive summary of its Cyberspace Policy Review. In it, Harper argued that updating tort law to allow those harmed by insecure computer products to recover damages from providers and manufacturers is a better path to true security than government regulation of the market. And he was called before the House Subcommittee on Technology and Innovation to testify about how the federal government should respond to cyberterrorist threats and how it should approach securing the nation’s informationtechnology infrastructure.\nHarper is adamantly clear that cybersecurity is important. While arguing that the federal government should not directly regulate computer security, he is careful not to downplay the need to secure our computer networks. But such security, like in the brick and- mortar world outside the Internet, is a matter of personal responsibility, business interest, and common sense.\nThat same common sense should lead us to recognize that cyberterrorism does not exist and that threat of cyberwarfare is minimal. Claims to the contrary result from technological illiteracy and the incentives of government officials and contractors that favor inflating threats. Cyberterrorism is “cyber–snake oil,” Harper says.", "label": 1}
{"text": "At all times, PostgreSQL maintains a write ahead log (WAL) in the pg_xlog/ subdirectory of the cluster's data directory. The log records every change made to the database's data files. This log exists primarily for crash-safety purposes: if the system crashes, the database can be restored to consistency by \"replaying\" the log entries made since the last checkpoint. However, the existence of the log makes it possible to use a third strategy for backing up databases: we can combine a file-system-level backup with backup of the WAL files. If recovery is needed, we restore the file system backup and then replay from the backed-up WAL files to bring the system to a current state. This approach is more complex to administer than either of the previous approaches, but it has some significant benefits:\nWe do not need a perfectly consistent file system backup as the starting point. Any internal inconsistency in the backup will be corrected by log replay (this is not significantly different from what happens during crash recovery). So we do not need a file system snapshot capability, just tar or a similar archiving tool.\nSince we can combine an indefinitely long sequence of WAL files for replay, continuous backup can be achieved simply by continuing to archive the WAL files. This is particularly valuable for large databases, where it might not be convenient to take a full backup frequently.\nIt is not necessary to replay the WAL entries all the way to the end. We could stop the replay at any point and have a consistent snapshot of the database as it was at that time. Thus, this technique supports point-in-time recovery: it is possible to restore the database to its state at any time since your base backup was taken.\nIf we continuously feed the series of WAL files to another machine that has been loaded with the same base backup file, we have a warm standby system: at any point we can bring up the second machine and it will have a nearly-current copy of the database.\nNote: pg_dump and pg_dumpall do not produce file-system-level backups and cannot be used as part of a continuous-archiving solution. Such dumps are logical and do not contain enough information to be used by WAL replay.\nAs with the plain file-system-backup technique, this method can only support restoration of an entire database cluster, not a subset. Also, it requires a lot of archival storage: the base backup might be bulky, and a busy system will generate many megabytes of WAL traffic that have to be archived. Still, it is the preferred backup technique in many situations where high reliability is needed.\nTo recover successfully using continuous archiving (also called \"online backup\" by many database vendors), you need a continuous sequence of archived WAL files that extends back at least as far as the start time of your backup. So to get started, you should set up and test your procedure for archiving WAL files before you take your first base backup. Accordingly, we first discuss the mechanics of archiving WAL files.\nIn an abstract sense, a running PostgreSQL system produces an indefinitely long sequence of WAL records. The system physically divides this sequence into WAL segment files, which are normally 16MB apiece (although the segment size can be altered when building PostgreSQL). The segment files are given numeric names that reflect their position in the abstract WAL sequence. When not using WAL archiving, the system normally creates just a few segment files and then \"recycles\" them by renaming no-longer-needed segment files to higher segment numbers. It's assumed that segment files whose contents precede the checkpoint-before-last are no longer of interest and can be recycled.\nWhen archiving WAL data, we need to capture the contents of each segment file once it is filled, and save that data somewhere before the segment file is recycled for reuse. Depending on the application and the available hardware, there could be many different ways of \"saving the data somewhere\": we could copy the segment files to an NFS-mounted directory on another machine, write them onto a tape drive (ensuring that you have a way of identifying the original name of each file), or batch them together and burn them onto CDs, or something else entirely. To provide the database administrator with flexibility, PostgreSQL tries not to make any assumptions about how the archiving will be done. Instead, PostgreSQL lets the administrator specify a shell command to be executed to copy a completed segment file to wherever it needs to go. The command could be as simple as a cp, or it could invoke a complex shell script — it's all up to you.\nTo enable WAL archiving, set the wal_level configuration parameter to archive (or hot_standby), archive_mode to on, and specify the shell command to use in the archive_command configuration parameter. In practice these settings will always be placed in the postgresql.conf file. In archive_command, %p is replaced by the path name of the file to archive, while %f is replaced by only the file name. (The path name is relative to the current working directory, i.e., the cluster's data directory.) Use %% if you need to embed an actual % character in the command. The simplest useful command is something like:\narchive_command = 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f' # Unix archive_command = 'copy \"%p\" \"C:\\\\server\\\\archivedir\\\\%f\"' # Windows\nwhich will copy archivable WAL segments to the directory /mnt/server/archivedir. (This is an example, not a recommendation, and might not work on all platforms.) After the %p and %f parameters have been replaced, the actual command executed might look like this:\ntest ! -f /mnt/server/archivedir/00000001000000A900000065 && cp pg_xlog/00000001000000A900000065 /mnt/server/archivedir/00000001000000A900000065\nA similar command will be generated for each new file to be archived.\nThe archive command will be executed under the ownership of the same user that the PostgreSQL server is running as. Since the series of WAL files being archived contains effectively everything in your database, you will want to be sure that the archived data is protected from prying eyes; for example, archive into a directory that does not have group or world read access.\nIt is important that the archive command return zero exit status if and only if it succeeds. Upon getting a zero result, PostgreSQL will assume that the file has been successfully archived, and will remove or recycle it. However, a nonzero status tells PostgreSQL that the file was not archived; it will try again periodically until it succeeds.\nThe archive command should generally be designed to refuse to overwrite any pre-existing archive file. This is an important safety feature to preserve the integrity of your archive in case of administrator error (such as sending the output of two different servers to the same archive directory).\nIt is advisable to test your proposed archive command to ensure that it indeed does not overwrite an existing file, and that it returns nonzero status in this case. The example command above for Unix ensures this by including a separate test step. On some Unix platforms, cp has switches such as -i that can be used to do the same thing less verbosely, but you should not rely on these without verifying that the right exit status is returned. (In particular, GNU cp will return status zero when -i is used and the target file already exists, which is not the desired behavior.)\nWhile designing your archiving setup, consider what will happen if the archive command fails repeatedly because some aspect requires operator intervention or the archive runs out of space. For example, this could occur if you write to tape without an autochanger; when the tape fills, nothing further can be archived until the tape is swapped. You should ensure that any error condition or request to a human operator is reported appropriately so that the situation can be resolved reasonably quickly. The pg_xlog/ directory will continue to fill with WAL segment files until the situation is resolved. (If the file system containing pg_xlog/ fills up, PostgreSQL will do a PANIC shutdown. No committed transactions will be lost, but the database will remain offline until you free some space.)\nThe speed of the archiving command is unimportant as long as it can keep up with the average rate at which your server generates WAL data. Normal operation continues even if the archiving process falls a little behind. If archiving falls significantly behind, this will increase the amount of data that would be lost in the event of a disaster. It will also mean that the pg_xlog/ directory will contain large numbers of not-yet-archived segment files, which could eventually exceed available disk space. You are advised to monitor the archiving process to ensure that it is working as you intend.\nIn writing your archive command, you should assume that the file names to be archived can be up to 64 characters long and can contain any combination of ASCII letters, digits, and dots. It is not necessary to preserve the original relative path (%p) but it is necessary to preserve the file name (%f).\nNote that although WAL archiving will allow you to restore any modifications made to the data in your PostgreSQL database, it will not restore changes made to configuration files (that is, postgresql.conf, pg_hba.conf and pg_ident.conf), since those are edited manually rather than through SQL operations. You might wish to keep the configuration files in a location that will be backed up by your regular file system backup procedures. See Section 18.2 for how to relocate the configuration files.\nThe archive command is only invoked on completed WAL segments. Hence, if your server generates only little WAL traffic (or has slack periods where it does so), there could be a long delay between the completion of a transaction and its safe recording in archive storage. To put a limit on how old unarchived data can be, you can set archive_timeout to force the server to switch to a new WAL segment file at least that often. Note that archived files that are archived early due to a forced switch are still the same length as completely full files. It is therefore unwise to set a very short archive_timeout — it will bloat your archive storage. archive_timeout settings of a minute or so are usually reasonable.\nAlso, you can force a segment switch manually with\npg_switch_xlog if you want to\nensure that a just-finished transaction is archived as soon as\npossible. Other utility functions related to WAL management are\nlisted in Table\nWhen wal_level is minimal some SQL commands are optimized to avoid WAL logging, as described in Section 14.4.7. If archiving or streaming replication were turned on during execution of one of these statements, WAL would not contain enough information for archive recovery. (Crash recovery is unaffected.) For this reason, wal_level can only be changed at server start. However, archive_command can be changed with a configuration file reload. If you wish to temporarily stop archiving, one way to do it is to set archive_command to the empty string (''). This will cause WAL files to accumulate in pg_xlog/ until a working archive_command is re-established.\nThe procedure for making a base backup is relatively simple:\nEnsure that WAL archiving is enabled and working.\nConnect to the database as a superuser and issue the command:\nwhere label is any string you\nwant to use to uniquely identify this backup operation.\n(One good practice is to use the full path where you intend\nto put the backup dump file.)\npg_start_backup creates a backup label file, called backup_label, in the cluster directory with\ninformation about your backup, including the start time and\nIt does not matter which database within the cluster you connect to to issue this command. You can ignore the result returned by the function; but if it reports an error, deal with that before proceeding.\npg_start_backup can take a long time to\nfinish. This is because it performs a checkpoint, and the\nI/O required for the checkpoint will be spread out over a\nsignificant period of time, by default half your\ninter-checkpoint interval (see the configuration parameter\nThis is usually what you want, because it minimizes the\nimpact on query processing. If you want to start the backup\nas soon as possible, use:\nSELECT pg_start_backup('label', true);\nThis forces the checkpoint to be done as quickly as possible.\nPerform the backup, using any convenient file-system-backup tool such as tar or cpio (not pg_dump or pg_dumpall). It is neither necessary nor desirable to stop normal operation of the database while you do this.\nAgain connect to the database as a superuser, and issue the command:\nThis terminates the backup mode and performs an automatic switch to the next WAL segment. The reason for the switch is to arrange for the last WAL segment file written during the backup interval to be ready to archive.\nOnce the WAL segment files active during the backup are\narchived, you are done. The file identified by\npg_stop_backup's result is the last\nsegment that is required to form a complete set of backup\nfiles. If archive_mode is enabled,\npg_stop_backup does not\nreturn until the last segment has been archived. Archiving\nof these files happens automatically since you have already\nconfigured archive_command. In\nmost cases this happens quickly, but you are advised to\nmonitor your archive system to ensure there are no delays.\nIf the archive process has fallen behind because of\nfailures of the archive command, it will keep retrying\nuntil the archive succeeds and the backup is complete. If\nyou wish to place a time limit on the execution of\npg_stop_backup, set an\nYou can also use the pg_basebackup tool to take the\nbackup, instead of manually copying the files. This tool will\ndo the equivalent of\npg_start_backup(), copy and\npg_stop_backup() steps automatically, and\ntransfers the backup over a regular PostgreSQL connection using the\nreplication protocol, instead of requiring file system level\naccess. pg_basebackup does not\ninterfere with file system level backups taken using\nSome file system backup tools emit warnings or errors if the files they are trying to copy change while the copy proceeds. When taking a base backup of an active database, this situation is normal and not an error. However, you need to ensure that you can distinguish complaints of this sort from real errors. For example, some versions of rsync return a separate exit code for \"vanished source files\", and you can write a driver script to accept this exit code as a non-error case. Also, some versions of GNU tar return an error code indistinguishable from a fatal error if a file was truncated while tar was copying it. Fortunately, GNU tar versions 1.16 and later exit with 1 if a file was changed during the backup, and 2 for other errors.\nIt is not necessary to be concerned about the amount of time\nand the start of the actual backup, nor between the end of the\npg_stop_backup; a few\nminutes' delay won't hurt anything. (However, if you normally\nrun the server with full_page_writes\ndisabled, you might notice a drop in performance between\npg_stop_backup, since full_page_writes is effectively forced on during\nbackup mode.) You must ensure that these steps are carried out\nin sequence, without any possible overlap, or you will\ninvalidate the backup.\nBe certain that your backup dump includes all of the files under the database cluster directory (e.g., /usr/local/pgsql/data). If you are using tablespaces that do not reside underneath this directory, be careful to include them as well (and be sure that your backup dump archives symbolic links as links, otherwise the restore will corrupt your tablespaces).\nYou can, however, omit from the backup dump the files within the cluster's pg_xlog/ subdirectory. This slight adjustment is worthwhile because it reduces the risk of mistakes when restoring. This is easy to arrange if pg_xlog/ is a symbolic link pointing to someplace outside the cluster directory, which is a common setup anyway for performance reasons. You might also want to exclude postmaster.pid and postmaster.opts, which record information about the running postmaster, not about the postmaster which will eventually use this backup. (These files can confuse pg_ctl.)\nTo make use of the backup, you will need to keep all the WAL\nsegment files generated during and after the file system\nbackup. To aid you in doing this, the\npg_stop_backup function creates a backup history file that is immediately stored\ninto the WAL archive area. This file is named after the first\nWAL segment file that you need for the file system backup. For\nexample, if the starting WAL file is 0000000100001234000055CD the backup history file\nwill be named something like 0000000100001234000055CD.007C9330.backup. (The\nsecond part of the file name stands for an exact position\nwithin the WAL file, and can ordinarily be ignored.) Once you\nhave safely archived the file system backup and the WAL segment\nfiles used during the backup (as specified in the backup\nhistory file), all archived WAL segments with names numerically\nless are no longer needed to recover the file system backup and\ncan be deleted. However, you should consider keeping several\nbackup sets to be absolutely certain that you can recover your\nThe backup history file is just a small text file. It\ncontains the label string you gave to\npg_start_backup, as well as the starting and\nending times and WAL segments of the backup. If you used the\nlabel to identify the associated dump file, then the archived\nhistory file is enough to tell you which dump file to\nSince you have to keep around all the archived WAL files back to your last base backup, the interval between base backups should usually be chosen based on how much storage you want to expend on archived WAL files. You should also consider how long you are prepared to spend recovering, if recovery should be necessary — the system will have to replay all those WAL segments, and that could take awhile if it has been a long time since the last base backup.\nIt's also worth noting that the\npg_start_backup function makes a file named\nbackup_label in the database cluster\ndirectory, which is removed by\npg_stop_backup. This file will of course be\narchived as a part of your backup dump file. The backup label\nfile includes the label string you gave to\npg_start_backup, as well as the time at which\npg_start_backup was run, and the\nname of the starting WAL file. In case of confusion it is\ntherefore possible to look inside a backup dump file and\ndetermine exactly which backup session the dump file came\nIt is also possible to make a backup dump while the server\nis stopped. In this case, you obviously cannot use\npg_stop_backup, and you will therefore be\nleft to your own devices to keep track of which backup dump is\nwhich and how far back the associated WAL files go. It is\ngenerally better to follow the continuous archiving procedure\nOkay, the worst has happened and you need to recover from your backup. Here is the procedure:\nStop the server, if it's running.\nIf you have the space to do so, copy the whole cluster data directory and any tablespaces to a temporary location in case you need them later. Note that this precaution will require that you have enough free space on your system to hold two copies of your existing database. If you do not have enough space, you should at least save the contents of the cluster's pg_xlog subdirectory, as it might contain logs which were not archived before the system went down.\nRemove all existing files and subdirectories under the cluster data directory and under the root directories of any tablespaces you are using.\nRestore the database files from your file system backup. Be sure that they are restored with the right ownership (the database system user, not root!) and with the right permissions. If you are using tablespaces, you should verify that the symbolic links in pg_tblspc/ were correctly restored.\nRemove any files present in pg_xlog/; these came from the file system backup and are therefore probably obsolete rather than current. If you didn't archive pg_xlog/ at all, then recreate it with proper permissions, being careful to ensure that you re-establish it as a symbolic link if you had it set up that way before.\nIf you have unarchived WAL segment files that you saved in step 2, copy them into pg_xlog/. (It is best to copy them, not move them, so you still have the unmodified files if a problem occurs and you have to start over.)\nCreate a recovery command file recovery.conf in the cluster data directory (see Chapter 26). You might also want to temporarily modify pg_hba.conf to prevent ordinary users from connecting until you are sure the recovery was successful.\nStart the server. The server will go into recovery mode and proceed to read through the archived WAL files it needs. Should the recovery be terminated because of an external error, the server can simply be restarted and it will continue recovery. Upon completion of the recovery process, the server will rename recovery.conf to recovery.done (to prevent accidentally re-entering recovery mode later) and then commence normal database operations.\nInspect the contents of the database to ensure you have recovered to the desired state. If not, return to step 1. If all is well, allow your users to connect by restoring pg_hba.conf to normal.\nThe key part of all this is to set up a recovery configuration file that describes how you want to recover and how far the recovery should run. You can use recovery.conf.sample (normally located in the installation's share/ directory) as a prototype. The one thing that you absolutely must specify in recovery.conf is the restore_command, which tells PostgreSQL how to retrieve archived WAL file segments. Like the archive_command, this is a shell command string. It can contain %f, which is replaced by the name of the desired log file, and %p, which is replaced by the path name to copy the log file to. (The path name is relative to the current working directory, i.e., the cluster's data directory.) Write %% if you need to embed an actual % character in the command. The simplest useful command is something like:\nrestore_command = 'cp /mnt/server/archivedir/%f %p'\nwhich will copy previously archived WAL segments from the directory /mnt/server/archivedir. Of course, you can use something much more complicated, perhaps even a shell script that requests the operator to mount an appropriate tape.\nIt is important that the command return nonzero exit status on failure. The command will be called requesting files that are not present in the archive; it must return nonzero when so asked. This is not an error condition. Not all of the requested files will be WAL segment files; you should also expect requests for files with a suffix of .backup or .history. Also be aware that the base name of the %p path will be different from %f; do not expect them to be interchangeable.\nWAL segments that cannot be found in the archive will be sought in pg_xlog/; this allows use of recent un-archived segments. However, segments that are available from the archive will be used in preference to files in pg_xlog/. The system will not overwrite the existing contents of pg_xlog/ when retrieving archived files.\nNormally, recovery will proceed through all available WAL segments, thereby restoring the database to the current point in time (or as close as possible given the available WAL segments). Therefore, a normal recovery will end with a \"file not found\" message, the exact text of the error message depending upon your choice of restore_command. You may also see an error message at the start of recovery for a file named something like 00000001.history. This is also normal and does not indicate a problem in simple recovery situations; see Section 24.3.4 for discussion.\nIf you want to recover to some previous point in time (say, right before the junior DBA dropped your main transaction table), just specify the required stopping point in recovery.conf. You can specify the stop point, known as the \"recovery target\", either by date/time, named restore point or by completion of a specific transaction ID. As of this writing only the date/time and named restore point options are very usable, since there are no tools to help you identify with any accuracy which transaction ID to use.\nNote: The stop point must be after the ending time of the base backup, i.e., the end time of\npg_stop_backup. You cannot use a base backup to recover to a time when that backup was in progress. (To recover to such a time, you must go back to your previous base backup and roll forward from there.)\nIf recovery finds corrupted WAL data, recovery will halt at that point and the server will not start. In such a case the recovery process could be re-run from the beginning, specifying a \"recovery target\" before the point of corruption so that recovery can complete normally. If recovery fails for an external reason, such as a system crash or if the WAL archive has become inaccessible, then the recovery can simply be restarted and it will restart almost from where it failed. Recovery restart works much like checkpointing in normal operation: the server periodically forces all its state to disk, and then updates the pg_control file to indicate that the already-processed WAL data need not be scanned again.\nThe ability to restore the database to a previous point in time creates some complexities that are akin to science-fiction stories about time travel and parallel universes. For example, in the original history of the database, suppose you dropped a critical table at 5:15PM on Tuesday evening, but didn't realize your mistake until Wednesday noon. Unfazed, you get out your backup, restore to the point-in-time 5:14PM Tuesday evening, and are up and running. In this history of the database universe, you never dropped the table. But suppose you later realize this wasn't such a great idea, and would like to return to sometime Wednesday morning in the original history. You won't be able to if, while your database was up-and-running, it overwrote some of the WAL segment files that led up to the time you now wish you could get back to. Thus, to avoid this, you need to distinguish the series of WAL records generated after you've done a point-in-time recovery from those that were generated in the original database history.\nTo deal with this problem, PostgreSQL has a notion of timelines. Whenever an archive recovery completes, a new timeline is created to identify the series of WAL records generated after that recovery. The timeline ID number is part of WAL segment file names so a new timeline does not overwrite the WAL data generated by previous timelines. It is in fact possible to archive many different timelines. While that might seem like a useless feature, it's often a lifesaver. Consider the situation where you aren't quite sure what point-in-time to recover to, and so have to do several point-in-time recoveries by trial and error until you find the best place to branch off from the old history. Without timelines this process would soon generate an unmanageable mess. With timelines, you can recover to any prior state, including states in timeline branches that you abandoned earlier.\nEvery time a new timeline is created, PostgreSQL creates a \"timeline history\" file that shows which timeline it branched off from and when. These history files are necessary to allow the system to pick the right WAL segment files when recovering from an archive that contains multiple timelines. Therefore, they are archived into the WAL archive area just like WAL segment files. The history files are just small text files, so it's cheap and appropriate to keep them around indefinitely (unlike the segment files which are large). You can, if you like, add comments to a history file to record your own notes about how and why this particular timeline was created. Such comments will be especially valuable when you have a thicket of different timelines as a result of experimentation.\nThe default behavior of recovery is to recover along the same timeline that was current when the base backup was taken. If you wish to recover into some child timeline (that is, you want to return to some state that was itself generated after a recovery attempt), you need to specify the target timeline ID in recovery.conf. You cannot recover into timelines that branched off earlier than the base backup.\nSome tips for configuring continuous archiving are given here.\nIt is possible to use PostgreSQL's backup facilities to produce standalone hot backups. These are backups that cannot be used for point-in-time recovery, yet are typically much faster to backup and restore than pg_dump dumps. (They are also much larger than pg_dump dumps, so in some cases the speed advantage might be negated.)\nTo prepare for standalone hot backups, set wal_level to archive (or hot_standby), archive_mode to on, and set up an archive_command that performs archiving only when a switch file exists. For example:\narchive_command = 'test ! -f /var/lib/pgsql/backup_in_progress || (test ! -f /var/lib/pgsql/archive/%f && cp %p /var/lib/pgsql/archive/%f)'\nThis command will perform archiving when /var/lib/pgsql/backup_in_progress exists, and otherwise silently return zero exit status (allowing PostgreSQL to recycle the unwanted WAL file).\nWith this preparation, a backup can be taken using a script like the following:\ntouch /var/lib/pgsql/backup_in_progress psql -c \"select pg_start_backup('hot_backup');\" tar -cf /var/lib/pgsql/backup.tar /var/lib/pgsql/data/ psql -c \"select pg_stop_backup();\" rm /var/lib/pgsql/backup_in_progress tar -rf /var/lib/pgsql/backup.tar /var/lib/pgsql/archive/\nThe switch file /var/lib/pgsql/backup_in_progress is created first, enabling archiving of completed WAL files to occur. After the backup the switch file is removed. Archived WAL files are then added to the backup so that both base backup and all required WAL files are part of the same tar file. Please remember to add error handling to your backup scripts.\nIf archive storage size is a concern, use pg_compresslog, http://pglesslog.projects.postgresql.org, to remove unnecessary full_page_writes and trailing space from the WAL files. You can then use gzip to further compress the output of pg_compresslog:\narchive_command = 'pg_compresslog %p - | gzip > /var/lib/pgsql/archive/%f'\nYou will then need to use gunzip and pg_decompresslog during recovery:\nrestore_command = 'gunzip < /mnt/server/archivedir/%f | pg_decompresslog - %p'\nMany people choose to use scripts to define their archive_command, so that their postgresql.conf entry looks very simple:\narchive_command = 'local_backup_script.sh \"%p\" \"%f\"'\nUsing a separate script file is advisable any time you want to use more than a single command in the archiving process. This allows all complexity to be managed within the script, which can be written in a popular scripting language such as bash or perl.\nExamples of requirements that might be solved within a script include:\nCopying data to secure off-site data storage\nBatching WAL files so that they are transferred every three hours, rather than one at a time\nInterfacing with other backup and recovery software\nInterfacing with monitoring software to report errors\nTip: When using an archive_command script, it's desirable to enable logging_collector. Any messages written to stderr from the script will then appear in the database server log, allowing complex configurations to be diagnosed easily if they fail.\nAt this writing, there are several limitations of the continuous archiving technique. These will probably be fixed in future releases:\nOperations on hash indexes are not presently WAL-logged, so replay will not update these indexes. This will mean that any new inserts will be ignored by the index, updated rows will apparently disappear and deleted rows will still retain pointers. In other words, if you modify a table with a hash index on it then you will get incorrect query results on a standby server. When recovery completes it is recommended that you manually REINDEX each such index after completing a recovery operation.\nIf a CREATE DATABASE command is executed while a base backup is being taken, and then the template database that the CREATE DATABASE copied is modified while the base backup is still in progress, it is possible that recovery will cause those modifications to be propagated into the created database as well. This is of course undesirable. To avoid this risk, it is best not to modify any template databases while taking a base backup.\nCREATE TABLESPACE commands are WAL-logged with the literal absolute path, and will therefore be replayed as tablespace creations with the same absolute path. This might be undesirable if the log is being replayed on a different machine. It can be dangerous even if the log is being replayed on the same machine, but into a new data directory: the replay will still overwrite the contents of the original tablespace. To avoid potential gotchas of this sort, the best practice is to take a new base backup after creating or dropping tablespaces.\nIt should also be noted that the default WAL format is fairly bulky since it includes many disk page snapshots. These page snapshots are designed to support crash recovery, since we might need to fix partially-written disk pages. Depending on your system hardware and software, the risk of partial writes might be small enough to ignore, in which case you can significantly reduce the total volume of archived logs by turning off page snapshots using the full_page_writes parameter. (Read the notes and warnings in Chapter 29 before you do so.) Turning off page snapshots does not prevent use of the logs for PITR operations. An area for future development is to compress archived WAL data by removing unnecessary page copies even when full_page_writes is on. In the meantime, administrators might wish to reduce the number of page snapshots included in WAL by increasing the checkpoint interval parameters as much as feasible.\nSome might find it helpful to use the following when using gzip and pg_compresslog:\nrestore_command = '[ -e /mnt/server/archivedir/%f ] && gunzip < /mnt/server/archivedir/%f | pg_decompresslog - %p'\nThis will correctly return non-zero for a missing file", "label": 1}
{"text": "An academic research paper by University of Pennsylvania researchers claims touch screen phones may be vulnerable to smudge attacks, a new form of security vulnerability based on the oily residue left on the screen. The researchers claim malicious attackers may be able to ascertain a certain amount of information, such as inferring a password used by the devices owner, left by the smudges left on a touch screen.\nThe researchers took photos of screens and used a program to analyze the photos closely. They found they could figure out the password over 90 percent of the time. The study used Android phones, which use a graphical pattern to allow users to unlock the phone. Phones included the Nexus 1.\nThe study also found that “pattern smudges,” which build up from writing the same password numerous times, are particularly recognizable.\nWhile it sounds somewhat plausible, I find it hard to believe that practical use of this vulnerability, assuming it is even an issue, will result in widespread exploits. The attackers would have to gain physical access to the device in order to make use of the exploit, and most bad guys prefer to do their dirty deeds from afar. This is not to necessarily downplay the issue but to speak towards the reality of the situation.\nIt should be worth watching to see if any true security issues ever come from this research. I applaud the University of Pennsylvania team for conducting some very exhaustive investigative work, and some very informative and interesting research, but the reality is this “vulnerability” is a non-issue right now.", "label": 1}
{"text": "Today's smartphones are much more than phones -- they are powerful, networked multimedia computers, and over the next 10 years they'll get far more advanced. As a result, mobility is transforming many day-to-day processes -- including how we sell, communicate, collaborate, train, and educate. The following are some key technological developments that will revolutionize the smartphone over the next decade.\nYour smartphone will have a 3-D display and a 3-D Web browser, and you won't need special glasses to view it. So instead of just viewing Web pages on your smartphone, you'll be able to go into environments (or stores or showrooms) and maneuver around in them, just as you do on devices like the Xbox. Alternatively, you'll be able to see things sticking out from the screen, again without the special glasses. So, the 3-D Web on your smartphone will be a game-changer for business.\nRather than have to remember numerous passwords, you will be able to access data and sites on your smartphone using multiple biometric authentications. Advanced screen resolution and sensors on the phone will make this possible.\nFor example, when you touch the screen, it will recognize you based on your fingerprint. In addition, your phone's front-facing camera will use facial recognition to identify you. Everyone's voice is unique, so voice recognition will also be part of the identification/security process.\nHow you handle the phone -- your keystrokes and touch/maneuver patterns -- are also unique. The number of biometrics used will depend on the level of security you want based on what you are doing. For example, if you're accessing your Facebook account, you may only want one biometric for authentication. However, if you're doing a high-level security activity (such as banking via your smart phone), you'll likely want to use multiple biometrics.\nYour smartphone will become your wallet. Credit cards are easy, but e-wallets are easier. Currently, Google has a mobile wallet that works with Citi MasterCard, and in the future it will work with other credit cards. It is secure and enables you to make payments with your smartphone.\nIn the near future, as every financial service firm gets into mobile payments, you will move very quickly from a leather wallet to a smartphone wallet. One example of an enabling technology is NFC -- near-field communications chips -- which are being built into smart phones as you read this article. They allow for secure and easy payment, so be ready for it.\nYour ultra intelligent agent will get smarter. The first ultra intelligent agent was Apple's Siri. As Siri-like agents advance, they will turn into personal assistants and will be able to search the Web for you and bring back focused, highly relevant information based on how long you have used your e-agent and how well it knows you.\nIn other words, your ultra intelligent agent will know your preferences, your likes, and your needs and will automatically compile, present, and share what's pertinent to you.\nAdditionally, your ultra intelligent agent will have a face when you are looking at the screen and a personality that you choose. You'll even see celebrities licensing the rights to their digital likeness and personality to be used as ultra intelligent agents.\nNo more screens\nSome of your smartphones will be screen-less. The traditional smartphone with a screen will not go away, but you will have an option for a screen-less smartphone. This will be a very popular and highly adopted smartphone because without the screen, you get rid of much of the need for a big battery. Think of the screen-less smartphone like the little piece of jewelry people wore on the old Star Trek TV show. The screen-less smartphone will be touch and voice activated. When you tap it, you'll be connected to your ultra intelligent agent, which is part of a super computer in the cloud. Whatever you need, your ultra intelligent agent will be able to verbally give you the information, such as turn-by-turn directions, reading your email to you and so on.\nYour smartphone will interface with smart surfaces. We are already seeing the beginning of using touch and voice-operated intelligent screens as tabletop computers that can access the internet. Simply by placing your smartphone on these surfaces, the two will link together. Additionally, your ultra intelligent agent will flow from your smartphone to the screen.\nThis is just a small sampling of what we'll see for future smartphone technology. All of these advancements are in their early stages today. So keep in mind that if it can be done, it will be done. The question is, who will be first?", "label": 1}
{"text": "Most Americans are aware that identity theft is a significant problem, and that it's important to take measures to protect your identity. What people might not know is their children may also be targets of identity theft before they even become old enough to own a credit card. The Federal Trade Commission has identified child identity theft as a growing problem and encourages parents to do what they can to minimize the risks to their children.\nThe most common way a criminal can steal or misuse the identity of a child is to get access to the child's Social Security number. The perpetrator then uses the Social Security number to open credit card accounts or loans, rent an apartment, sign up for utilities like cellphone service, or even apply for a job. Credit issuers often don't have a way to verify the age of the applicant, so if the criminal changes the age of the identity associated with your child, it's possible that the issuer may approve them for credit, according to the Identity Theft Resource Center.\nOnce an account has been established in your child's name, it's easier for criminals to establish subsequent accounts until this fraud is discovered. If your child's identity is stolen at an early age and the theft goes undiscovered until she reaches the age where she begins to establish her own credit, it can be very difficult to discover how the fraud first occurred.\nParents can take a number of steps to help prevent their children from becoming identity theft victims:\n- Store your children's Social Security cards in a safe place, such as a safety deposit box. Only give out your children's Social Security number when it's absolutely necessary, and provide alternate verification whenever possible.\n- Teach your children to never reveal personal information to anyone, no matter how trustworthy that person may seem. People close to the family are often found to be perpetrators in child identity theft cases.\n- If your child receives pre-approved credit card offers in the mail, you may want to check in with a credit reporting agency or Social Security. If you've been contacted by a collection agency regarding an account in your child's name, there's a possibility your child's identity was stolen.\n- Consider signing up your family members for a credit monitoring and identity protection solution.", "label": 1}
{"text": "Your user names, e-mail addresses and passwords are crucial for your internet security, so keep that in mind when you’re setting up an account on whatever site, forum or social media site you choose. The dangers out there in the online world are many: someone could try to trick you into revealing your personal data or downright steal it and use it to get into your bank account. And how about those pesky spam messages that clog up your inbox and waste your time?\nHere are a few internet security tips we’d like to share with you that will help you protect your online accounts from internet security threats such as hacking, phishing and identity theft:\n1. Use multiple addresses and make each one of them unique\nUse both numbers and letters when you create your e-mail address. This way you’ll save your address from spammers who use \"dictionary attacks\" to e-mail thousands of possible name combinations at large Internet Service Providers or e-mail services (ex: Hotmail, Yahoo), hoping to find valid addresses.\nYou should also have more than one e-mail address and use your second or “sacrifice” address to register to unknown websites, forums, and blogs or just to make online purchases.\n2. Create a user name that’s different from your e-mail address\nCreate a unique user name that is not associated with your e-mail address when you join websites like social networks or public forums. User names are accessible to anyone, so don't make it easy for internet crooks to guess your e-mail address.\n3. Mask your e-mail address when posting it online\nIf you need or want to share your address on a public website, you can mask it: just add a phrase or a character that people will know right away is not a part of your e-mail address. For example, if your address is “email@example.com”, you could mask it as “firstname.lastname@example.org”. This way spammers won’t pick up your address with their special software.\n4. Use strong passwords on all your accounts\nA strong password will never be guessed by someone else and that’s vital for your internet security, especially when you bank or shop online. Here are some hints:\n- Include letters, numbers and keyboard symbols (some of the symbols may be difficult to enter on foreign keyboards, so choose wisely)\n- Use at least 7 characters\n- Don’t use your username, your real name or your company’s name\nWhat makes a weak password? Any of the following, so think twice before resorting to them:\n- No password at all\n- A common dictionary word\n- Some piece of information about yourself that’s easy to guess from your online profile (your favorite sports team, your birthday, your spouse’s name)\n- The word “password”\n- One that you haven’t changed in the last few months\n5. Look after your passwords:\n- Never share your passwords with anyone. You never know how and where an internet security breach may appear from.\n- Don’t enter your password when others can see what you type in.\n- Have a unique password for banking sites, but don’t use the same one for different services.\n- Change your passwords every couple of months.\n- Don’t recycle your password for different accounts (for example password1, password2).\n- Don’t write passwords down, use memory tricks to remember them.\n- Never send your password by e-mail, as no serious company will ask you to do this.\n- Change your password immediately if you suspect someone else has figured it out.", "label": 1}
{"text": "Anyone can be a victim. Anybody who uses e-mail and has received a virus has been a victim of cybervandalism. Cybercrime—stalking, harassment, tampering, fraud, and theft of property or service—happens daily by way of the Internet.\nFrom left, Bill Oblitey and Mary Micco of the Computer Science Department and Dennis Giever of Criminology\nIf Dennis Giever had a credo, it might be an ounce of prevention is worth a pound of cure. A hackneyed admonition, perhaps, but one that might make the hacker drop in his tracks. He believes that it is the average citizen who will notice an act of terrorism or other crime by means of technology, and, therefore, blow the whistle. To notice it, he or she must recognize it.\nThe Criminology Department chairperson’s vision for an undergraduate minor in cybersecurity is based on prevention and public awareness; what makes it special is that it may be the first in the nation to be multidisciplinary, entailing courses in both computer science and criminology. It is meant for the average citizen, not the technology expert.\nGiever joined colleagues in the Computer Science Department, Mary Micco and William Oblitey, to write a proposal and receive a $250,000 grant from the National Science Foundation. The grant funds development of a minor program and allows IUP to offer workshops that might spur other educators to develop similar programs.\n“Our goal is to start the process of educating the masses,” said Giever. “The realization is that we have to get this information into classrooms everywhere.”\nWhile the official minor discipline is being developed by faculty members in both academic areas, two courses already are offered to IUP students. Criminology offers Cybersecurity and the Law, and Computer Science offers Cybersecurity Basics, according to Giever. Micco, Oblitey, and Giever oversaw three workshops during the summer meant to assist educators in other settings to develop their own programs; another workshop is planned. In addition, the Computer Science Department is developing an information assurance concentration, and certification and literacy programs are being considered.\n“We want to be proactive. The [experts] in the field today are reactive. If something happens, they have tons of expertise to fix and investigate a problem,” said Giever, referring to crimes such as product tampering, interruption of service, stalking, and murder. “We want to prevent these things from happening…. It becomes an issue of public awareness. We have a long way to go before the general public understands all of this,” Giever said. “A small circle of specialized IT professionals has traditionally been responsible for working with this type of activity. But, it’s time that not just they and law enforcement officials understand this. The office manager must understand. That’s why we need an interdisciplinary minor.”", "label": 1}
{"text": "Browser-hijacking malware talks to attackers using SPF email validation protocol\n- — 28 January, 2013 16:17\nA new Trojan program that displays rogue advertisements during browsing sessions uses a DNS-based email validation protocol called the Sender Policy Framework (SPF) in order to receive instructions from attackers without being detected, according to security researchers from Symantec.\nHowever, the most interesting aspect of this malware is the way in which it receives updated URLs from attackers to use in the rogue HTML script elements.\nThe malware periodically generates a domain name according to a predefined algorithm and makes an SPF lookup for it. Knowing in advance which domain will be generated, the attackers register it and configure its SPF record to contain IP (Internet Protocol) addresses or host names that will be used by the malware to construct new malicious URLs.\nSPF was designed to detect email spoofing and is implemented using the DNS (Domain Name System).\nA domain name owner can specify an SPF policy -- a number of IP addresses or host names that are allowed to send emails from that particular domain -- inside a DNS TXT or SPF record. Email servers can then perform SPF lookups via DNS in order to check that email messages appearing to have been sent from that domain actually came from an IP address authorized by the domain administrator.\nIf the sender IP address or host specified in an email's header is not listed in the SPF policy for the corresponding domain name then the email sender's address was probably spoofed.\nIn the case of Trojan.Spachanel, the SPF policy for the domain name is not used to validate emails, but to provide a new list of malicious host names to be used by the malware.\nUsing this technique, attackers can hide the malicious traffic from firewalls and other security products that might otherwise block direct connections to known malware command-and-control servers.\nThat's because in order to perform SPF lookups, the malware queries a trusted DNS server located on the local network or the Internet service provider's network. This server then queries other DNS servers up the chain until the request reaches the authoritative DNS server for the domain name, which responds with a TXT or SPF record containing the SPF policy.\n\"In some cases, specific domains are blocked by a local DNS server, but this malware generates a domain that is rarely filtered,\" Katsuki said.", "label": 1}
{"text": "NSF award for Dr. Carpenter\nNSF Award on Preventing Psychology Cyber-Attacks\nApproximately six million Americans are targets of identity theft each year. Many of the attacks on identity privacy use psychological influence strategies (\"psychological attacks\") to induce individuals to provide their private information. Although people are appropriately concerned about their privacy, they often unnecessarily disclose information that could be used to their disadvantage. Our studies have shown that people's privacy exposure behaviors may be severely affected by psychological attacks. Unfortunately, research from a psychological perspective to mitigate the attacks is scarce. This research identifies critical aspects of warnings for a sub-set of psychological cyber-attacks on privacy and provides guidelines for developing effective mitigations against other types of psychological cyber-attacks. We create computer-mediated countermeasures. We also ascertain the extent to which the warnings capture attention, are understood, are memorable, increase perceptions of risk, decrease trust, and lead to compliance under conditions of psychological attacks.\nThis research is a first investigation of whether theoretical models developed to reduce risky behaviors (e.g., health-related behaviors) can be extended to the domain of computer privacy. The research determines whether warnings can have significant impact on people?s decisions about disclosure of their private information. The effectiveness of our mitigation approach is tested on hand-held devices and web sites with the goal of increasing compliance with the warnings.\nThis research provides mitigation strategies for private information exposure and provides guidelines for software developers to use when designing privacy preserving software. Potentially, the results can be generalized to mitigate other current and future psychological privacy attacks. Research findings are disseminated in both social psychology and computer science. In addition, a website is developed to share the research results, the data sets, and the lessons learned, in order to raise the awareness of the importance of protecting identity information and mitigating psychological cyber-attacks.\n- Hits: 2225", "label": 1}
{"text": "Got this from IT at work. Use Caution with Search Engines\nNan and Sandy Sanders\nesanders at erols.com\nThu Nov 29 20:35:00 CST 2007\nUnlike the usual message of this type, this seems for real. Read the\narticles linked at the end.\nInformation Security Advisory: Use Caution with Search Engines\nA new threat has been discovered that affects the entire Internet.\nThe most widely used search engines; including Google, Yahoo, and\nMSN; contain links to malicious websites that appear near the top of\nsearch results. Seemingly legitimate searches may lead users to sites\nthat contain viruses, trojans, and other malicious code that can be\neasily transferred to the browser's computer.\nHow it Works\nAttackers have created enormous automated networks to spoof and scam\nsearch engines into placing their websites near the top of search\nresults. Unwary users assume that popular search engines only point\nto legitimate websites.\nMalicious iFrames, rootkits and fake codecs are being served up on\ntens of thousands of sites returned as results for searches for such\nthings as alternate router firmware or \"how to for Microsoft Excel,\"\n\"currency converter,\" \"americanexpress/activate,\" and \"knitted or\ncrocheted dachshund patterns.\"\nBy clicking on these sites, users may become infected by adware,\nviruses, or even rootkits and password stealers.\nThere's no absolute way to determine if a website contains malcode or\nnot. But some good practices include:\n- don't click on any link ending in \".cn\"\n- don't click on website names or descriptions that don't\n- don't accept any requests by websites to install drivers,\ncodecs, or any other application on your system\nThese links provide more technical information about the situation.\nMore information about the Tacos", "label": 1}
{"text": "How to Avoid Malware Online\nMalware (malicious software) is the collective term used for software that is designed with the intention of slowing down, appropriating or crippling a device or a network. Malware can also be tailored to covertly record information regarding your online activities and relay that information to its designers. This is illegal and usually done with the intention of offering the information as a cheap alternative to legitimate market research. It is also commonly used to steal private and banking information for the purposes of identity and currency theft.\nMalware comes in many shapes and sizes, all of which are undesirable and should be avoided wherever possible. Unfortunately this can be a tricky process, as knowing when and where Malware will strike is difficult and can be confusing to many users. Of course, Malware can always be removed after it has been installed, but as with most things of this nature prevention is better than cure.\nRegarding the prevention process there tends to be 2 prevailing but dichotomously opposed attitudes:\n- Anti-virus software is key. Grab the most powerful anti-virus program you can and you should be safe.\n- Anti-virus software is useless. It slows down your computer needlessly when all that was needed in the first place was a little common sense and caution on behalf of the user.\nOf course, as with most areas of fierce debate, the answer tends to lie somewhere between the two. Anti-virus software can indeed be helpful in protecting you from malware, but it’s important to not rely on it too heavily. Anti-virus software should be viewed as your safety net, or last-line of defence. There are many types of malware than can circumnavigate anti-virus software.\nThe argument that anti-virus software slows down a computer is also somewhat valid. While modern-day anti-virus programs are much lighter and require less of your system’s attention than older iterations, they can cause increased delays when starting up a computer or installing new software. Due to the lighter nature of today’s anti-virus software these delays are usually quite minimal in comparison to what their opponents claim, but the delays do still exist, nonetheless.\nAs such we advise merging the two ideologies. While most of the responsibility of avoiding malware can easily rest on the user, it’s still a good idea to be running some form of background protection, however minimal, in order to have a chance of catching anything that slips by.\nCommon Types of Malware\nFar and away the most well-known form of malware is the computer virus. A virus hides in pre-existing programs, applications or system files and is capable of replicating itself. A virus will usually try to spread itself to other computers once it has infected yours. This can be done over the internet, over a closed-network or by transmitting itself to a data transfer device such as a USB key.\nA worm is similar to a virus in that it can replicate itself, only it does not hide in pre-existing files but instead is a file unto itself. Worms are usually designed to destroy files, hinder networks and generally decrease computer efficiency. Some worms, such as the Blaster Worm from 2003, can actually prevent your computer from fully starting up before it shuts down again.\nTrojans are possibly the most dangerous form of malware from a social and personal-economic standpoint.\nA Trojan will find its way on to your computer using another file as a carrier. It rarely destroys files or affects computer performance. Rather, Trojans are generally intended to record user information, such as passwords or banking details, and relay this information to the developer.\nA botnet is not a piece of malware unto itself, but rather something that is created by malware. What happens here is that your computer is taken over by a botnet operator and used for their own purposes. This can be anything from increasing computer-power in order to perform brute-force hacks or to unleashing dedicated denial of service attacks on websites. Basically your computer is secretly turned in to an unwilling part of a large hive-mind of similarly enslaved computers, with one puppet-master pulling all the strings.\nThis is often not a conspicuous process and the puppet-master will go to great lengths to ensure that your computer’s new status as a zombie will not be noticed.\nSpyware, surprisingly enough, spies on you. This is generally done with the intention of gathering marketing data so that companies can more accurately advertise to you.\nAdware is similar, but actually contains the ads themselves. Adware is often installed on your computer legally, as it can be found in many user licence agreements. Agreeing to a user licence agreement can often mean you have given a company permission to install adware on your computer.\nSpyware and Adware can usually be removed with active system scans.\nModern Malware Penetration Techniques\nAs technology changes and online security systems advance so does malware and the methods that are employed to get it from its developer to your computer. Where once malware was predominantly passed around on USB drives, floppy discs or emails it’s now far more common to see more inconspicuous methods. Many victims of malware actually never realise that they’re a victim until real-world repercussions start rolling in.\nOne of the more common methods for the transferral of malware is to use a malicious or hacked website as a carrier. These websites will prompt you to download an innocent-looking package such as a video codec or browser plugin that is ‘required’ to view material on the website. Another method is to exploit browser security holes to install malware directly on to your computer without even asking.\nHowever, even prompted-downloads can be difficult to spot. This isn’t because you are somehow tricked in to clicking a download button without your knowledge, rather it is because reliable websites can be hacked and turned in to malware-dispensing tools. Even the BBC has had a couple of its websites turned in to these malware vendors in the past.\nPossibly the nastiest way that malware commonly proliferates by pretending to be ‘free’ anti-virus software. An alert will pop up in the user’s browser, warning them that a threat has been detected on their computer and that they have to download this new software now in order to eliminate it. The unwitting victim then dutifully downloads the package, allowing the real malware threat that was actually the download itself instant access to their system. Do not fall for this. Only pre-installed anti-virus programs should ever be installed.\nIf you get a pop-up from a program that is not already installed on your computer then ignore it and leave the website immediately. Don’t even click the ‘x’ box in the top right or left of the pop-up if you can avoid it, as that might be a cleverly hidden download button. You may also wish to contact the website to warn them that they have been hacked, but doing so may increase your risk and thus is up to you.\nDesktop PCs laptops running Windows are still the most vulnerable devices to malware. Apple Macs have become a larger target in recent years as well, but still get less attention from malware developers than anything running Windows. Android phones have also become a target, due to Android’s open-source nature and a user’s ability to download an app that has not been directly approved of by Google. Anything downloaded through the Google Play store (previously Android Market) should be safe. iPhones and iPads haven’t really had any problems, mostly thanks to Apple’s often strict control over the iOS ecosystem so that nothing that hasn’t passed Apple’s required tests isn’t made available on the App Store.\nThe key to staying safe from malware is to be alert. Be careful with small-time or dodgy-looking sites. Smaller websites usually have worse security methods in place and thus can be targeted more easily by malware developers. It’s also less common for maliciously-designed websites to look and act as professionally as a larger one, as malware developers often won’t have the kind of money that’s necessary to create a first-class web experience just to lure in unsuspecting prey. If a website looks bad or unprofessional then you might want to think twice about visiting there, let alone downloading any files.\nMost larger sites, especially those that support monetary transactions or store personal information, will use a more secure network. This can often be spotted easily, as the web address will begin with ‘https’ rather than the traditional ‘http’. Modern browsers and anti-virus packages will also often provide some kind of a marker, such as a green box or tick, to indicate that a website has been tested and is now a trusted source.\nAs far as anti-virus applications for Windows go there are some solid free options such as AVG, Avast, Avira and Microsoft’s Security Essentials. These programs provide a constant passive protection, as well as a more direct approach.\nIf your computer is acting sluggishly, or you believe you may have some malware, you can activate a scan that checks every file on your system. This is best to do overnight or while you’re out as it usually takes time to complete. Any threats that are detected will be quarantined until you decide what to do with them. The usual course of action is deletion. Scanning will not find every piece of malware out there, but it will detect and eliminate most of them. If you’re using a dedicated anti-adware program for this be careful, anti-adware packages are one of the more common fake ‘security services’ previously mentioned that end up being malware themselves. It’s probably best to use your pre-installed anti-virus software, if you have it.\nCurrently Mac users tend to not have to really worry about security software, as the prevailing majority of malware is still designed to target Windows machines.\nBasically we suggest that you remain alert and only use Anti-Virus software as a backup. The first and best defence against malware is to pay attention to what you’re doing and avoid online threats. Keep your eyes peeled and if you see something suspicious play it safe and just avoid it, rather than hoping your Anti-Virus package will protect you.", "label": 1}
{"text": "Cyber security software usage variations create vulnerabilities\nThere is certainly a difference between how cyber security software performs in a testing environment and how it performs in the real world. The many variables in real world usage patterns add an entirely new dimension to cyber security. Through my work at the Smart Grig Interoperability Panel (SGIP), I’ve come to believe that systems designers must consider the various means of inappropriate use or abuse capable by untrained users or nefarious individuals and provide appropriate testing for such usage at the outset.\nWhen we install conformant and interoperable products in the smart grid and achieve interconnectivity and information flow only a few experts need to know how to use the software. The software is most often a transparent service to the users. But when we are implementing a cyber secure system, we have to implement processes that ensure that the users of the system (who typically are process-oriented individuals and not technical experts) are using it in the proper manner and not opening holes that breach security. Many breaches in systems occur because the user either did not configure them so they would be appropriately secure or because they used them outside of the environment they were intended to function.\nExamples abound: Users did not select an appropriate password. Users did not use encryption on their laptop hard drive and it was stolen. That one should sound familiar, as it has occurred multiple times in organizations whose names you would immediately recognize. Users gave out their private security key or left a hardware token on their desk. Users added a device to their system which circumvented the organization’s security policy. Etc.\nTherefore, interoperability and conformance testing cannot be content to simply focus on testing of message boundary exchanges and data structure syntax or even the presence of proper cyber related algorithms in the software under testing. Going with the examples above, tests might incorporate scenarios of data-at-rest encryption or dual-factor authentication or other product specific tests. While poor user interaction can never be totally predicted and fully addressed, it must be considered in developing interoperability and conformance testing.\nSo, we must view cyber security as an integral part of the interoperability and conformance testing – performing testing for all of them in a coordinated manner. We must have input from security professionals, both on how the software should be used as well as how it may be used in the real world. Only by employing such a unified approach can we have confidence that our testing methodology is appropriately focused. For more information, see the Smart Grid Testing and Testing Certification Committee wiki page. What are your experiences with these testing and usage challenges? Let us know.\nRik Drummond, CEO Drummond Group Inc\n- An Accredited Test Lab and Certification Body by NAVLAP and ANSI\n- Chair emeritus DoE’s Grid Wise Architecture Council\n- Chair NIST Smart Grid Interoperability Panel’s Testing and Certification Committee", "label": 1}
{"text": "Protect Your Passwords from Theft\nPasswords are the keys to a person’s identity. However, it is more and more often the case that we hear of passwords and their corresponding usernames falling into malicious hands … causing financial loss, time loss, emotional distress, and worse.\nIn this day and age, you pretty much have to use the Internet and deal with passwords and security issues. You can take many steps to protect yourself from password theft and to minimize the damage caused if a password were to fall into the wrong hands.\nCommon Ways Passwords are Compromised\nIn order to protect your passwords, we need to have a good idea of what we are protecting them against. The most common ways that people’s passwords are discovered by others include:\n- Using “Insecure Connections” to web sites and Internet services. Malicious people in the same wifi hotspot or network as you can eavesdrop on your communications and easily discover your username, password, and any other information sent to or from your computer.\n- Companies that are hacked. Just like what happened recently with Sony’s Playstation Network (70 million accounts stolen including usernames, passwords, and perhaps other personal and financial information).\n- Passwords being guessed. Manual or automated attempts at guessing peoples passwords. Either people sitting down and trying to try passwords that they think you may use, or computers trying thousands or millions of common passwords until a match is found.\n- Company employee access to passwords. Many times, employees at companies (like Gmail) have full access to your passwords. They can, maliciously, save them and use them.\n- Scraps of paper. You wrote your password(s) down on a post-it note and someone saw it …\nHow to Protect Your Passwords\n1. Do not use “Insecure Connections”.\nIf you are connecting to a web site, be sure that the address in your browser’s address bar starts with “https://” and not “http:”. The “s” in “https” means “secured using SSL” and means that everything between you and that site is encrypted. However, if your browser gives you a warning that the site is “not trusted” or that there is some problem with the web sites “certificate”, you should NOT go there and login — someone may be trying to intercept your connection to glean your credentials!\nConnecting to other services, like email, chat, Facebook or Twitter, should also be made over SSL or TLS connections. If you want to use a service and they do not support secure connections, either do not use them, or use a username and password that is only for them (so if it gets discovered, it won’t impact anything else you are doing).\n2. Do not write your passwords on post it notes.\nLeaving your passwords written down and lying around is a great way to get yourself in trouble. Instead of the “post-it note” method of remembering passwords, it is best (if you can’t just remember them all in your head — but really, who can?) to store them in a secure database. I.e. keep all the usernames, passwords, and other pertinent information (like secret questions and answers) in a file or database or location that is itself encrypted — with one password, the only password your really have to remember (or maybe it is protected with a fingerprint reader … even better). With an encrypted password database, you can access all of your password data anytime, and no one else can get to them, even if they have access to your computer and all of your stuff.\nLuxSci provides one such solution in its WebAides suite — online Encrypted Password storage. Access your passwords securely from anywhere you have an online computer, and rest assured that the passwords are actually backed up and safe from disaster, misfortune, or compromise.\n3. Choose vendors that do not actually save your passwords in “plain text” anywhere.\nThe big problem with companies being hacked or having malicious employees is that databases of customer information get stolen. It is often the case, that companies have your passwords stored in “plain text” along with your username in their databases. I.e. if your password is “apple123″, and anyone looks in the database, they would see that clearly — and that is bad.\nAnother way to do things is for companies to store only “hashes” of passwords. A “hash” is a one-way mathematical function for turning “plain text” like “apple123″ into pretty unique gibberish like “$1$rjogGOYN$0p0j.DxKEBw0qKh4w1svU1″. They only store the gibberish (the hash) in their databases. In this way, they can still see if your password is correct by passing it through that math function and seeing if the result matches the gibberish. However, you can’t “go backwards” from the gibberish to the original password. If the database of a company that stores only hashes of passwords is stolen somehow, the passwords themselves are safe (well, mostly — see below).\nIf you can, you should choose to work with companies, like LuxSci, that never store plain text passwords anywhere.\n4. Choose good passwords!\nThis almost goes without saying, but if you don’t keep saying it, people won’t do it.\nIf you choose a simple (poor) password like “apple”, it is easily guessed by computer programs that try millions of common words, phrases, and commonly used passwords. How?\n- Some systems (unlike LuxSci’s) allow unlimited login attempts in a short period of time, even if they are all failing and all from the same place. This allows computer programs to quickly try all kinds of different passwords until one is found that works (the so-called “brute force” approach).\n- Also, if the gibberish (the hash) of a password is known, while you can’t “go backwards”, you can try all kinds of passwords and see if any of them “go forwards” and match the hash. If one does, it is the proper password.\nIf your password is simple, it can be quickly guessed by a computer in either of the above situations. If not, you are probably safe.\nWhat makes a good password? Doing a combinations of:\n- Using a phrase instead of a word: i.e. “let the games begin”\n- Using symbols and numbers and mixed case: i.e. “Let the 2011 Game$ begin!”\n- Keep it complex, but easily remembered.\n5. Use different passwords for different sites / accounts\nA big “no no” is to use the same password everywhere. Why? If it gets compromised in one place, then all of your accounts are vulnerable. The more places you use your password, the more vulnerable it becomes.\nOf course, the best thing to do is to use a different good password for each account you have. However, remembering all of these passwords quickly becomes cumbersome, even with a good password database. It is best if you can have different passwords for each account and create them in a way that makes them (a) strong, (b) easily remembered, and (c) you can’t easily guess one if you know another one.\nFor a good way to do this, see: Security Simplified, the Base+Suffix Method for Memorable Strong Passwords.\n6. Use Two-Factor Authentication when available and choose companies that support it!\nTwo Factor Authentication typically requires some kind of verification beyond your username and password in order to gain access to an account. I.e. if you have Two Factor Authentication enabled at LuxSci, when you login you will have a “token” (a short number) sent to either an alternate email address of your choice or to your mobile phone as a text messages. You have to access this token and enter it into the login page in order to complete the login process.\nTwo Factor Authentication protects your account against your password being stolen … as without access to the “second factor” (i.e. your phone), your account is still safe from intrusion.\nYou can also use a good OpenID to provide multi-factor authentication, if your account supports it.\n- How to Protect Yourself from Password Theft\n- Two Factor Authentication\n- DuoSecurity: Advanced Two-Factor Login for LuxSci’s Web Interface\n- How can I remember all these ##@! passwords?\n- Master Password Encryption in FireFox and Thunderbird", "label": 1}
{"text": "Peer-to-peer (P2P) File Sharing & Copyright Safety\nPeer-to-peer (P2P) file-sharing allows users to share files online through an informal network of computers running the same software. File-sharing can give you access to a wealth of information, but it also has a number of risks. You could download copyright-protected material, pornography, or viruses without meaning to. Or you could mistakenly allow other people to copy files you don't mean to share.\nIf you're considering P2P file-sharing:\n- Install file-sharing software carefully,\nso that you know what's being shared. Changes you make to the default settings of the \"save\" or \"shared\" folder might cause you to share folders and subfolders you don't want to share. Check the proper settings so that other users of the file-sharing network won't have access to your private files, folders, or sub-folders.\n- Use a security program from a vendor you know and trust;\nkeep that software and your operating system up-to-date. Some file-sharing software may install malware or adware, and some files may include unwanted content.\n- You may want to adjust the file-sharing program's controls\nso that it is not connected to the P2P network all the time. Some file-sharing programs automatically open every time you turn on your computer and continue to operate even when you \"close\" them.\n- Consider setting up separate user accounts,\nin addition to the administrator's account, if your computer has multiple users. Limiting rights on user accounts may help protect your computer from unwanted software and your data from unwelcome sharing.\n- Back up data\nyou don't want to lose in case of a computer crash, and use a password to protect any files that contain sensitive information.\nP2P File-Sharing: Evaluate the Risks\nEvery day, millions of computer users share files online. Whether it is music, games, or software, file-sharing can give people access to a wealth of information. To share files through a P2P network, you download special software that connects your computer to other computers running the same software. Millions of users could be connected to each other through this software at one time. The software often is free.\nSounds promising, right? Maybe, but make sure that you consider the trade-offs. OnGuard Online cautions that file-sharing can have a number of risks. For example, when you are connected to file-sharing programs, you may unknowingly allow others to copy private files — even giving access to entire folders and subfolders — you never intended to share. You may download material that is protected by copyright laws and find yourself mired in legal issues. You may download a virus or facilitate a security breach. Or you may unwittingly download pornography labeled as something else.\nTo secure the personal information stored on your computer, OnGuard Online suggests that you:\n- Install file-sharing software carefully\n- so that you know what's being shared. When you load a file-sharing application onto your computer, any changes you make to the P2P software's default settings during installation could cause serious problems. For example, if you change the defaults when you set up the \"shared\" or \"save\" folder, you may let other P2P users into any of your folders — and all its subfolders. You could inadvertently share information on your hard drive — like your tax returns, email messages, medical records, photos, or other personal documents — along with the files you want to share. And almost all P2P file-sharing applications will, by default, share the downloads in your \"save\" or \"download\" folder — unless you set it not to.\n- Use security software and keep it and your operating system up-to-date.\nSome file-sharing programs may install malware that monitors a user's computer use and then sends that data to third parties. Files you download may also hide malware, viruses, or other unwanted content. And when you install a P2P file-sharing application, you might be required to install \"adware\" that monitors your browsing habits and serves you advertising.\nMalware and adware can be difficult to detect and remove. Before you use any file-sharing program, get a security program that includes anti-virus and anti-spyware protection from a vendor you know and trust and make sure that your operating system is up to date. Set your security software and operating system to be updated regularly. Make sure your security software and firewall are running whenever your computer is connected to the Internet.\nDelete any software the security program detects that you don't want on your computer. And before you open or play any downloaded files, scan them with your security software to detect malware or viruses.\n- Close your connection\n- In some instances, closing the file-sharing program window does not actually close your connection to the network. That allows file-sharing to continue and could increase your security risk. If you have a high-speed or \"broadband\" connection to the Internet, you stay connected to the Internet unless you turn off the computer or disconnect your Internet service. These \"always on\" connections may allow others to copy your shared files at any time. To be sure your file-sharing program is closed, take the time to \"exit\" the program, rather than just clicking \"X\" or \"closing\" it. What's more, some file-sharing programs automatically open every time you turn on your computer. As a preventive measure, you may want to adjust the file-sharing program's controls to prevent the file-sharing program from automatically opening.\n- Create separate user accounts\n- If more than one person uses your computer, consider setting up separate user accounts, in addition to the administrator's account, and give those user accounts only limited rights. Since only a user with administrator rights can install software, this can help protect against software you don't want on your computer. It also can keep users from accessing other users' folders and subfolders, since users with limited rights generally don't have access to each other's information. Also use a password to protect your firewall and security software so no one else can disable them or grant themselves rights that you don't want them to have on your machine.\n- Back up sensitive documents\n- Back up files that you'd want to keep if your computer crashes. Store them on CDs, DVDs, or detachable drives that you keep in a safe place.\n- Talk with your family about file-sharing\n- If you're a parent, ask your children whether they've downloaded file-sharing software, and if they've exchanged games, videos, music, or other material. Talk to your kids about the security and other risks involved with file-sharing and how to install the software correctly, if they're going to use P2P file-sharing at all. If you're a teen or tween interested in file-sharing, talk with your parents before downloading software or exchanging files.\nFor more information about peer-to-peer file sharing and how it relates to copyright infringement, visit https://protect.iu.edu/cybersecurity/safeonline/filesharing/tutorial.\nSanctions for copyright infringement\nUnauthorized distribution of copyrighted material using Indiana University's information technology resources — including sharing copyrighted music, movies, and software through peer-to-peer applications like LimeWire, BitTorrent, etc. using Internet access provided by IU — is against the law and university policy. Unlawful file sharing may subject you to legal penalties, which can include any or all of the following:\n- Having to pay money to the copyright holder in a lawsuit — between $750 and $30,000 for each file, and up to $150,000 for each file if the infringement was willful\n- Having to pay the copyright holder's costs and attorney fees to bring the lawsuit\n- Criminal fines of up to $250,000, and up to 10 years' jail time — even if someone sharing files doesn't sell or charge for them\n- Seizure and destruction of infringing files\nAdditionally the university may impose sanctions, including loss of network access and disciplinary action. Visit https://protect.iu.edu/cybersecurity/safeonline/filesharing/procedure for further information about these sanctions or to learn how to avoid copyright infringement claims from music, movie, and software copyright holders.", "label": 1}
{"text": "by Dr. Scott Vanstone\nThe Practical Side of Public-Key Authentication\nThe authentication of the public keys used in a security protocol is one of the essential steps to ensuring the authenticity of the participants.\nYou may ask, “Why do you need to authenticate the public keys in a security protocol?” Without authentication, it may be possible for someone to insert themselves in a protocol and appear as a valid participant. This is the traditional man-in-the-middle attack. For example, assume Alice and Bob are using Diffie-Hellman (DH). If Eve inserts herself into the communications path and impersonates both Alice and Bob in the DH protocol, Alice and Bob will discover this only if they authenticate the public keys they receive from each other. This is because each will have received Eve’s public key during the exchange rather than each other’s authentic keys.\nPublic-key authentication schemes range from manual to fully automatic methods. Manual methods work well when a limited number of parties are involved; automated methods are generally more secure and cost effective for large distributed networks. Manual authentication usually involves an out-of-band verification process, such as telephonic verification, the use of pre-shared secrets, or public key signing “events” such as those held at IETF meetings.\nAs the number of users increases, it is no longer always practical to use a manual method – users may not know each other or secure communications must be established “on-the-fly”. A VPN device or a secure telephone may need to establish a secure session with a previously unknown (but authorized) party. For these applications where a manual setup process is too costly or time intensive, an automated method must be used. Automated methods will rely upon certificates; and as we’ve seen in this issue of Code and Cipher, there are many forms of certificates ranging from implicit to proprietary and X.509 explicit formats.\nWhen certificates are used, a Certificate Authority (CA) is required. However, it need not be complex or standalone. Again, depending on system criteria, the CA could be built into one device and issue certificates to the other communicating devices. For instance, a CA in a manufacturing environment may create and load a manufacturer’s certificate into each device before it is shipped. At the customer site, another device with a built-in CA will communicate with all other deployed devices, validate their manufacturer’s certificates, and then issue new customer-specific certificates to them. These certificates can be proprietary, if it’s a closed network, or X.509 for an open network. Both proprietary explicit and implicit certificates can be very lightweight. A public CA really only needs to be used when secure communications must be established between parties who have little to no other a priori knowledge of each other.\nObviously, this column is not a complete discussion of authentication methods or certificates. There are many alternatives available for performing the critical task of public key authentication. Security requirements, level of expertise and resources available all influence the final product. The use of a simple embedded CA issuing either implicit or explicit certificates can provide high security and great efficiency. Which authentication solution you select will depend on your specific application and its projected usage requirements.", "label": 1}
{"text": "A form of attack on a database-driven Web site in which the attacker executes unauthorized SQL commands by taking advantage of insecure code on a system connected to the Internet, bypassing the firewall. SQL injection attacks are used to steal information from a database from which the data would normally not be available and/or to gain access to an organization's host computers through the computer that is hosting the database. SQL injection attacks typically are easy to avoid by ensuring that a system has strong input validation.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "There have been so many password \"hacking\" stories lately, I thought I'd write this post so I can refer back to it. For added security, I've included the above image of Makise Kurisu, the scientist in my anime harem.\nCovering my behind\nCrypto is an exact science, so before I go any further I will make these clear.\n- When I say random, technically I mean pseudorandom. Algorithms are deterministic, and computer order and logic can't strictly speaking produce \"true\" randomness. Contemporary algorithms are an order of magnitude better than the BASIC RND() function of yore though.\n- When I say impossible and one way, I mean practically speaking. Our current algorithms would take the birth and death of several universes to brute force with current hardware, but that doesn't mean it's impossible. Just very very very very improbable!\nHow passwords are supposed to be stored\nWhen you create an account with a well designed, secure website, your chosen password is not stored anywhere. Instead, your password is put through a one way cryptographic hashing algorithm which converts it to random gibberish, along with some salt or random information only the web server knows.\nWhen you attempt to log into your site, the password you give is hashed and compared to the hash on file. If they're the same the server knows you have the right password.\nIt's a proven, tested technique and it works... provided everything is implemented properly. No doubt you've seen plenty of news stories suggesting sound security is harder than coming up with some snappy alliteration on a blog post.\nWhy go to the trouble?\nRather than storing a hash of a password, you could simply store the password and compare it when someone logs in. It's simpler, and a worryingly large number sites still do this.\nThe problem is, if the database is broken into, the malicious hacker has access to all your customer's passwords. People like conserving energy (politically correct way of saying lazy!), and are probably using those same passwords for all sorts of stuff including their banking sites, email, social networks and so on. You can see what a disaster this could be!\nIf you store them as hashes, all anyone ever sees is random gibberish... even the site owner!\nHow to tell\nShort of asking the site administrator, there are two main tells that a site is storing your passwords instead of a hash:\n- They're able to provide you with your password. This could happen when you first create your account and they send you a welcome email, or if you've said you've forgotten your password. A secure site should always direct you to a page to reset it, because they don't know your password either.\n- Hashes take any password length and adjust them to a uniform size (such as 128 bits). Not always, but often if a site puts a limit on your password length, it's because they're storing it as plaintext in their database.\nThere may have been (bad) excuses for these practices in the past, but not any more. If a site you access does either of these, it's time to question how important they are and whether they're worth risking your data and security over. Blunt, but true.\nIf you suspect a site you access is storing your password in plain text and you have no choice but to use them, complain, and make sure you pick something random and unique to that one site. If/when they get broken into, you'll be glad you did.", "label": 1}
{"text": "beware of clicking links in email or im messages\nPhishing occurs when a person attempts to steal personal information or install malicious software on your computer with the intention of stealing money from you. Cybercriminals can do this in a number of ways, all of which require some action on your part. They might email you, call you on the phone, post a link on your Facebook wall, or convince you to download something off a website. The best way to protect against phishing scams is to know the signs.\nSigns of phishing scams:\n- Incorrect Spelling and Grammar - Professional companies will not send out mass emails with spelling or grammar mistakes. If you find mistakes in an email, there is a good chance it is a scam.\n- Beware of Links - If an email seems suspicious, do not click on any links. Be especially suspicious of any truncated or shortened URL which then redirects you to the actual web site.\n- Threats - A common characteristic of spam emails are threats. For example, a typical phishing email might warn that your Hotmail account will be closed if you do not verify your personal information at a given address. The email is a scam intended on stealing your personal data.\n- Suspicious Facebook Posts - When a Facebook friend makes a post on your wall that seems uncharacteristic of that individual, be sure to avoid clicking on any links associated with the post. Often, spammers exploit contact lists and social media websites to virally spread their messages.\nKeep your computer safe. When in doubt, delete the email or message.\n- Learn more about staying safe or what to do if you’ve already given out personal information from the Anti-Phishing Work Group (APWG).\n- Learn about phishing scams at BC.\n- Test your knowledge by taking this phishing quiz.\n- Learn what to do, if you think your identity has been stolen from the FTC (Federal Trade Commission).", "label": 1}
{"text": "|Understanding VPN IPSec Tunnel Mode and IPSec Transport Mode - What's the Difference?|\n|Written by Administrator|\n|Sunday, 06 May 2012 04:14|\nIPSec’s protocol objective is to provide security services for IP packets such as encrypting sensitive data, authentication, protection against replay and data confidentiality.\nAs outlined in our IPSec protocol article, Encapsulating Security Payload (ESP) and Authentication Header (AH) are the two IPSec security protocols used to provide these security services. Analysing the ESP and AH protocols is out of this article’s scope, however you can turn to our IPSec article where you’ll find an in-depth analysis and packet diagrams to help make the concept clear.\nUnderstanding IPSec Modes –Tunnel Mode & Transport Mode\nIPSec can be configured to operate in two different modes, Tunnel and Transport mode. Use of each mode depends on the requirements and implementation of IPSec.\nIPSec Tunnel Mode\nIPSec tunnel mode is the default mode. With tunnel mode, the entire original IP packet is protected by IPSec. This means IPSec wraps the original packet, encrypts it, adds a new IP header and sends it to the other side of the VPN tunnel (IPSec peer).\nTunnel mode is most commonly used between gateways (Cisco routers or ASA firewalls), or at an end-station to a gateway, the gateway acting as a proxy for the hosts behind it.Tunnel mode is used to encrypt traffic between secure IPSec Gateways, for example two Cisco routers connected over the Internet via IPSec VPN. Configuration and setup of this topology is extensively covered in our Site-to-Site IPSec VPN article. In this example, each router acts as an IPSec Gateway for their LAN, providing secure connectivity to the remote network:\nAnother example of tunnel mode is an IPSec tunnel between a Cisco VPN Client and an IPSec Gateway (e.g ASA5510 or PIX Firewall). The client connects to the IPSec Gateway. Traffic from the client is encrypted, encapsulated inside a new IP packet and sent to the other end. Once decrypted by the firewall appliance, the client’s original IP packet is sent to the local network.\nIn tunnel mode, an IPSec header (AH or ESP header) is inserted between the IP header and the upper layer protocol. Between AH and ESP, ESP is most commonly used in IPSec VPN Tunnel configuration.\nThe packet diagram below illustrates IPSec Tunnel mode with ESP header:\nESP is identified in the New IP header with an IP protocol ID of 50.\nThe packet diagram below illustrates IPSec Tunnel mode with AH header:\nThe AH can be applied alone or together with the ESP, when IPSec is in tunnel mode. AH’s job is to protect the entire packet. The AH does not protect all of the fields in the New IP Header because some change in transit, and the sender cannot predict how they might change. The AH protects everything that does not change in transit. AH is identified in the New IP header with an IP protocol ID of 51.\nIPSec Transport Mode\nIPSec Transport mode is used for end-to-end communications, for example, for communication between a client and a server or between a workstation and a gateway (if the gateway is being treated as a host). A good example would be an encrypted Telnet or Remote Desktop session from a workstation to a server.\nTransport mode provides the protection of our data, also known as IP Payload, and consists of TCP/UDP header + Data, through an AH or ESP header. The payload is encapsulated by the IPSec headers and trailers. The original IP headers remain intact, except that the IP protocol field is changed to ESP (50) or AH (51), and the original protocol value is saved in the IPsec trailer to be restored when the packet is decrypted.\nIPSec transport mode is usually used when another tunneling protocol (like GRE) is used to first encapsulate the IP data packet, then IPSec is used to protect the GRE tunnel packets. IPSec protects the GRE tunnel traffic in transport mode.\nNotice that the original IP header at the front is the IP header from the original IP packet. Placing the sender’s IP header at the front (with minor changes to the protocol ID), proves that transport mode does not provide protection or encryption to the original IP header and ESP is identified in the New IP header with an IP protocol ID of 50.\nThe packet diagram below illustrates IPSec Transport mode with AH header:\nThe AH can be applied alone or together with the ESP when IPSec is in transport mode. AH’s job is to protect the entire packet, however, IPSec in transport mode does not create a new IP header in front of the packet but places a copy of the original with some minor changes to the protocol ID therefore not providing essential protection to the details contained in the IP header (Source IP, destination IP etc). AH is identified in the New IP header with an IP protocol ID of 51.\nIn both ESP and AH cases with IPSec Transport mode, the IP header is exposed.\n|Last Updated on Friday, 11 May 2012 11:21|", "label": 1}
{"text": "Security expert Craig Heffner from Seismic, a company specializing in security consulting, will be sharing the details of a security flaw that opens up many common household routers to a hack. The revelation will be part of the Black Hat Conference in Las Vegas at the end of the month. Black Hat is a gathering of technologists who are interested in security issues, some from the corporate world and some from the darker side of the issue. Heffner’s talk is entitled How to Hack Millions of Routers.â€\nAccording to Forbes, Heffner will release code that can be used to get into popular routers from Linksys, Dell, and Verizon FIOS or DSL. If a user visits a web site with the code, malicious hosts can gain access to information or send a browser to another site.\nThe way the hack works is extremely technical. If you want all the details check out the Forbes blog post. Simply put, it exploits the way Domain Name Systems (DNS) work. The DNS address is kind of like a web page’s phone number. When you type in Notebooks.com a request is sent to a computer connected to the Internet called a DNS server. It looks up the address Notebooks.com. The DNS server then gives the browser the right Internet Protocol address (IP address) so that it can find the actual computer containing the site’s web pages. An IP address is a series of four numbers ranging from 1 to 255. For example, where I live in NC Google’s IP address is 22.214.171.124. It changes based on your locality.\nEach web site can have more than one IP address. The trick is fool the router into giving up its address as if it were the secondary IP address for that site. Then the malicious code hidden in the site can gather access from the router like your login information as if your local network were part of that site. Forbes says this isn’t new, but has been patched repeatedly. However, Heffner has found a new way to exploit the system to gain access to most of the popular consumer routers. One of those that is vulnerable is the popular Linksys WRT54G routers.\nYou should go to the Forbes site and find out if your router has been tested. Towards the end of the post is a table listing some of the routers tested with for the vulnerability.\nTo secure your router do the following:\n- Change your password to a strong one. You do this by logging into the configuration page of your router, usually something like 192.168.1.1. Get specific instructions from your manufacturer’s website. Here is a site that will generate very strong passwords for you. The length should be set to at least 8 characters and include letters (both upper and lower case), numbers, and maybe even punctuation marks. Do not include words or names.\n- Go to your router’s support site and get the latest firmware and install it. This is different for each router. Some routers have a link in the router’s configuration page (see below).\n- Be careful which web sites you visit. Porn and pirated software pages are notorious for including this kind of code.\n“One comfort for users may be that Heffner’s method still requires the attacker to compromise the victim’s router after gaining access to his or her network. But that can be accomplished by using a vulnerability in the device’s software or by simply trying the default login password. Only a tiny fraction of users actually change their router’s login settings, says Heffner. ‘Routers are usually poorly configured and have vulnerabilities,” he says. “So the trick isn’t how to exploit the router. It’s how to get access to it.’” (Andy Greenberg, Forbes)\nSome may ask why would Heffner reveal this information? He believes it is the best way to force companies to update their software. As you notice from my router above, D-Link has not updated the firmware in a long time. Fortunately, most D-Link routers are not on the list of vulnerable routers.\nThe source for this was Dwight Silverman of the Houston Chronicle.", "label": 1}
{"text": "All Windows 2000 administrators want to allow the right people access to the right information. To do that, you must understand the most basic form of security -- permissions.\nMost network administrators are already familiar with the setting up of permissions to files/folders, so this article looks at the major concepts you should consider when applying permissions to files/folders. You need to do proper planning before you actually assign permissions.\nOne of the benefits of using Windows 2000 over Windows 98 or Me, for workstations as well as servers, is the ability to use file and folder permissions. To enable file and folder permissions, you need to use NTFS: they are not available on FAT. So when you upgrade to Windows 2000, if you are concerned about file/folder security, you must convert that FAT partition to NTFS. This is normally done during the upgrade process.\nUse caution when applying the deny permission, because the deny permission takes precedence over any allow permission. All other permission is cumulative or additive. For example, if a user has been assigned the \"Read\" permission to a file, but is also a member of a group that has been assigned the \"Write\" permission, the user's effective permission to the file is \"Write.\" If, on the other hand, a user has been assigned the \"Deny Write\" permission, then that user will not be able to write to the file or folder, even if he/she also belongs to a group that has been assigned\nTo properly assign permissions:\n- Calculate what permissions you are going to use for files/folders. Permissions for\nfiles/folders are \"least restrictive.\" For example, Paul is a user that has been assigned Read\npermission to a file. He also is a member of the shipping group that was assigned Full Control to\nthe same file. The result is that Paul's permission for the file will be Full Control, because the\n\"least restrictive\" permission will apply to users, and Full Control is less restrictive than Read.\n- Then perform separate calculations for shares using the \"least restrictive\" rule. For\nexample, the shipping folder is now shared. Paul is assigned change permission. The shipping group\n(of which Paul is a member) has been assigned Read Only permission. Based on the \"least\nrestrictive\" rule this user now has Change permission to the shared folder.\nPermission for files and shares are always additive or least restrictive.\nWhat would Paul's effective permission be? It is the combined permission for Paul when he accesses files and folders within the shared folder. This is calculated using the most restrictive rule. So because Paul is accessing the file (for which he has Full Control) through the shared folder (for which he has Change permission), then his effective permission (combined permission) would be Change since this is the most restrictive between the shared folder (Change) and the file permission (Full Control). Paul has Full Control for the file and Change permission for the share folder. Therefore Paul's effective permission is Change.\nAdesh Rampat has 10 years experience with network and IT administration. He is a member of the Association of Internet Professionals, the Institute for Network Professionals and the International Webmasters Association. He has also lectured extensively on a variety of topics.\nDid you like this tip? If so, (or if not) why not let us know. Send an email to us and sound off.\nThis was first published in September 2001", "label": 1}
{"text": "Creating and maintaining high safety standards of critical data are concerns for almost all of us, especially followers of online shopping and online banking. In this blog, we would be reading about some easy yet effective ways on how to prevent hacking attacks on PCs. Read on!\nIn today’s web-dominated world, almost every one of us makes use of PC and Internet to reduce time and efforts and staying close to comfort and convenience. Things are easy and safe till the time we come to know that critical information stored on the PC has been hacked. Things can be restored but it is always better to play it safe from the start itself. Let us read about computer hacking and find some easy ways to protect your privacy and data.\nBefore we start reading about ways to prevent hacking, let us read about computer hacking so that all of us can be on the same knowledge platform.\nComputer hacking is all about manipulating vulnerabilities of a computer by a hacker with an aim to invade privacy or steal or modify information. Most of us think that PCs at homes are safe but that is far from being true. Hacking can happen to any PC in this world and your PC is no exception.\nLet us now read about good ways to prevent hacking at the first place.\nTips to prevent Computer Hacking\n1. Install a good paid antivirus. You can install a free version to check its reliability but paid version has improved tools to prevent hacking and is therefore recommended. Moreover, update the antivirus on a daily basis and scan the PC, at least once a week\n2. Turn ON the Firewall and allow your PC to install all critical patches from Microsoft by activating Automatic Updates and Windows Firewall found under Control Panel-Security Center.\n3. Turn off sharing all your drives, especially where program files are usually stored, the C: / drive.\n4. Delete temporary internet files. Enter PREFETCH in the RUN box and delete by pressing SHIFT+DEL. Follow the same deletion process by typing %TEMP%, also type TEMP in the RUN box after clearing prefetch and %TEMP%. Go to start, type run, and type (prefetch, %temp%, and temp, one by one).\n5. Go to Control panel-Performance and Maintenance-System-Remote and UNCHECK the box “Allow remote invitations to be sent from this computer”, apply and then press OK. This will prevent hackers from gaining unauthorized access on your PC.\n6. Always scan a USB drive, floppy, attachment, and CD before opening its contents. This may take some time but it is always better to be safe\n7. Block pop-ups and do not click on misleading advertisements\n8. Never clicks on URLs that redirect you to other sites, especially those mischievously claiming to be from your bank or card issuing authority\n9. Do not disclose personal information by responding to emails suggesting that you just won a prize or lottery. If you have not participated, how come you won it? It is that simple\n10. Do not click or open emails or attachments from unknown persons\n11. Never install Kazaa, Napster, or new software from an unknown source\nFollow these simple tips and you can easily protect your PC and critical information from getting hacked.\nTags: computer hacking, Hacking, how to prevent hacking attacks, online banking, Online Shopping, prevent hacking, protect your PC, ways to prevent hacking", "label": 1}
{"text": "Number of oil spills continued to decrease in 2011\nPress release by SYKE and the Finnish Border Guard\nThe number of oil spills detected by Finnish authorities has continued to decrease. In 2011, the authorities observed 57 oil spills compared with closer to 70 in the previous two years. The authorities were informed of a total of 83 potential oil spills last year.\nA larger number of surveillance flight hours than in previous years\nAircraft operated by the Finnish Border Guard observed a total of 21 verified oil spills in the Finnish sea area. Helicopters observed eight oil spills and airplanes equipped with oil spill surveillance equipment observed 13 spills. In addition, surveillance airplanes observed three oil spills in the Swedish and two in the Estonian exclusive economic zones. The Estonian surveillance airplane verified three oil spills in the Finnish Exclusive Economic Zone, and one spill was observed by German surveillance airplane.\nOil spills detected by Finnish surveillance planes in years 1996-2011\nIn 2011, Finnish surveillance flights above sea areas exceeded the average level and amounted to 645 hours. The pollution per flight hour index, 0.03, was at a record low. This indicator offers strong support to the view that number of oil spills is decreasing in the northern Baltic Sea.\nSimilarly, the average volume of oil spills detected during surveillance flights has declined significantly in the past few years. The average volume of spills observed within the Finnish exclusive economic zone in 2011 was some 30 litres. In the three previous years the average volume of a spill has been more than 100 litres, and the average volume of spills detected e.g. in 2005 was 608 litres.\nIn addition to surveillance flights, the satellite based oil spill detection service CleanSeaNet (CSN) service of the European Maritime Safety Agency (EMSA) contributes significantly to the surveillance of marine oil spills. In 2010, Finnish authorities received 250 satellite images through the EMSA. Finnish Border Guard attempts to verify all oil spill indications.\nFinnish Border Guard investigates the oil pollution cases\nIn 2011, the Finnish Border Guard investigated nine cases to determine whether the conditions for imposing an administrative oil pollution fee were met. In six cases, an oil pollution fee was imposed. The fees varied from EUR 2,139 to EUR 17,112. Cases where no pollution fee was imposed were minor in terms of the volume and the environmental impact.\nInternational cooperation contributes to the reduction in spills in the Baltic Sea\nLast year, Finland organised SuperCEPCO Baltic 2011, a major pollution surveillance operation during which aircraft from five countries conducted surveillance over the northern Baltic Sea for a total of 68 hours. During the operation, one minor mineral oil spill was detected and two spills of other substances.\nThe results of the pollution surveillance operations together with national and international statistics show that thanks to closer international cooperation and an increased risk of getting caught, the number of oil spills has decreased. It would also seem that environmental awareness among shipping companies operating in the Baltic Sea has grown. Another contributor to the positive development is the HELCOM recommendation which states that all vessels in the Baltic Sea must dispose of any waste containing oil in collection points located in harbours.\nOil spill control\nKati Tahvonen, Research Engineer,\nFinnish Environment Institute (SYKE), tel. +358 400 148 754\nAdministrative oil pollution fees\nTom Lundell, Maritime Safety Expert,\nFinnish Border Guard, tel. +358 40 521 4685\nChief Editor for Web Services\nFinnish Environment Institute (SYKE), tel. +358 400 148 875", "label": 1}
{"text": "Using the Internet\nIn 2009 the Internet Crime Complaint Center (IC3), which acts in partnership with the National White Collar Crime Center and the FBI, received more than 336,000 complaints on its website and referred over 146,000 to law enforcement agencies for further consideration. The total loss from all of these cases was over $560 million. You may be at risk if you answer \"yes\" to any of the following questions:\n- Do you visit websites by clicking on links within an e-mail?\n- Do you reply to e-mails from persons or businesses you are not familiar with?\n- Have you received packages to hold or ship to someone you met on the Internet?\n- Have you been asked to cash checks and wire funds to someone you met on the Internet?\n- Would you cash checks or money orders received through an Internet transaction without first confirming their legitimacy?\n- Would you provide your personal banking information in response to an e-mail notification?\nThe following security tips will help you deal with dangerous matters associated with using the internet.\n- E-card Dangers\n- Illegitimate Websites\n- Safe Cyber Practices\n- Social Networking Dangers\n- Suspicious E-mails\nYou receive an e-mail saying \"A friend has sent you an e-card.\" The e-mail appears to be from a legitimate card company, but malware or a virus is downloaded into your computer when you click the link to see the card. You should delete the e-mail if you don't recognize the sender or if you are instructed to download an executable program to view the e-card. And make sure your computer has adequate anti-virus protection.\nAnd even if you recognize the sender your computer could be harmed if the incoming e-mail is phony and you click on a link to an e-card or open an attachment. This happened around Christmas time in December 2010 when employees of various government agencies received phony holiday messages that appeared to come from the White House.\nCybercriminals are now creating illegitimate websites that will receive high search-engine rankings and thus attract the attention of persons searching for information on a particular subject. Persons just visiting those sites risk having their computers infected with viruses. And if they click on any links in those sites they risk becoming a victim of identity theft and various scams, e.g., ones that claim you can make a lot of money for a small initial investment.\nTo avoid these problems users should:\n- Keep your computer's anti-virus system up to date with the latest firewalls and software.\n- Use caution clicking on links that claim to provide videos or information on hot topics in the current news, e.g., the earthquakes in Haiti and Chile. And be aware that the bad guys are now tricking Google into telling you that the link is a PDF file, which makes it look more authentic.\n- Do not click on links to other websites. Look up the address elsewhere and retype it into your browser.\n- If the link address is correct, before clicking on it check to see where you would actually go. You can do this by scrolling your mouse over the link and reading the address in the box that will pop up over the link. Do not click on the link if this address does not match the one in the link.\n- Use the tips provided above to counter phishing. Do the following to make sure a website is legitimate, especially if you are planning to make a purchase of a name brand product:\n- Check that the domain name is spelled correctly.\n- Check that the domain name ends in .com, .org, or .net. Those ending in .cn for China or .mn for Mongolia are likely to be fraudulent.\n- Call the phone number posted and talk to a live person.\nIn an e-mail scam known as \"phishing\" identity thieves fish for personal information by sending realistic-looking e-mail that asks recipients to go to a bogus website and provide personal information such as a credit card number or a Personal Identification Number (PIN). Legitimate banks and financial institutions don't send e-mails asking you to verify your account information. They already have it. The following are examples of scammers posing as the Internal Revenue Service (IRS), Federal Bureau of Investigation (FBI), Federal Deposit Insurance Corporation (FDIC), and the Centers for Disease Control and Prevention (CDC).\nEach year during tax preparation time there is a surge in the number of frauds by criminals posing as IRS officials to obtain personal information for identity theft. The IRS never sends out unsolicited e-mails or asks for detailed personal and financial information. Any such e-mail is a fraud. So are telephone calls from someone stating they are from the IRS. Go to the IRS website at www.irs.gov for information on the latest scams and instructions on how to protect yourself from suspicious e-mails or phishing schemes. The IRS also recommends forwarding the suspicious e-mail to it at firstname.lastname@example.org.\nFraudulent e-mails have also been sent out by criminals posing as FBI agents and officials. They give the appearance of legitimacy by using the FBI seal, letterhead, and pictures of the FBI Director. They may also claim to come from the FBI's domestic or overseas offices. Like the IRS, the FBI does not send out e-mails soliciting personal or financial information. For more information on this kind of fraud go to the FBI website at www.fbi.gov and click on New E-Scams and Warnings under Be Crime Smart.\nAnother agency that has become aware of fraudulent e-mails in its name is the FDIC. These ask recipients to \"visit the official FDIC website\" by clicking on a hyperlink that directs them to a fraudulent website that includes hyperlinks that open a \"personal FDIC insurance file\" to check on their deposit insurance coverage. Clicking on these links will download a file that contains malicious software to collect personal and confidential information.\nOn Dec. 2, 2009 the CDC issued a health alert warning people not to respond to an e-mail referencing a CDC-sponsored state vaccination program for the H1N1 (Swine Flu) contagion that requires registration on \"www.cdc.gov.\" People that click on this embedded link risk having a malicious code installed on their computer. Examples of this and other hoaxes and rumors can be seen at http://www.cdc.gov/hoaxes_rumors.html.\nUse the following tips to counter phishing:\n- Do not open any e-mail from an unknown sender.\n- Do not open any unexpected e-mail attachments.\n- Do not open any attachments that ask you to reset a password.\n- Do not click on website addresses in e-mails you get even if they look real. Retype them into your browser.\n- Do not click on links within e-mail messages purporting to come from your bank.\n- Do not double click on an Internet pop-up offering a link or provide personal information in response to an e-mail or Internet pop-up offer.\n- Use the latest versions of Internet browsers, e.g., Microsoft Internet Explorer 8, which is designed to prevent phishing attacks. Use Explorer in the \"protected mode,\" which restricts the installation of files without the user's consent, and set the \"Internet zone security\" to high. That disables some of Explorer's less-secure features. And set your operating system and browser software to automatically download and install security patches.\n- Make sure the website page you are entering sensitive information on is secure. You can tell it is secure when the address on the top of your screen where the Uniform Resource Locator (URL) is displayed begins with https:// rather than http://. You can also look for a closed padlock or an unbroken key on the bottom of your screen to indicate the page is secure. If the lock is open the site or the key is broken, the page is not secure. Note that on many websites only the order page will be secure.\n- Keep your computer up to date with the latest firewalls, and anti-virus and anti-spyware software. The latter counters programs that secretly record what you type and send the information to the thieves. They are often installed when you visit websites from links in e-mail. Use security software that updates automatically. Visit www.OnGuardOnline.gov for more information.\n- Do not buy \"anti-spyware\" software in response to unexpected pop-ups or e-mails, especially ones that claim to have scanned your computer and detected viruses known as malware, i.e., malicious software.\n- Do not respond in any way to a telephone or e-mail warning that your computer has a virus even if it appears to come from an anti-virus software provider like Microsoft, Norton, or McAfee. \"Helpful hackers\" use this ploy to get you to download their software to fix the virus or sell you computer monitoring or security services to give them remote access to your computer so they can steal your passwords, online accounts, and other personal information. If you already have anti-virus software on your computer you'll receive a security update or warning directly on your computer.\n- Contact your e-mail provider. Most keep track of scams. Send your provider the suspicious message header and complete text.\n- Use caution when entering personal information online.\nThere are presently two similar efforts by the U.S. Government to promote safer use of the Internet. The one by the FTC's Bureau of Consumer Protection is called Stop.Think.Click. The other, developed by a group representing industry, government, academia, and the nonprofit sector in 2009, and promoted by the Obama administration and the Department of Homeland Security, is called Stop.Think.Connect.\nStop.Think.Click defines seven practices for safer computing and provides tips on preventing identity theft, safe use of social networking sites, online shopping, Internet auctions, avoiding scams, and wireless security. It also provides a glossary of terms. The seven practices are:\n- Protecting your personal information\n- Knowing who you're dealing with\n- Using anti-virus and anti-spyware software, as well as a firewall\n- Setting up your operating system and web browser software properly, and updating them regularly\n- Protecting your passwords\n- Backing up your important files\n- Learning who to contact if something goes wrong online. Go to www.ftc.gov/bcp/edu/pubs/consumer/tech/tec15.pdf for information about these practices and tips.\nGo to www.ftc.gov/bcp/edu/pubs/consumer/tech/tec15.pdf for information about these practices and tips.\nStop.Think.Connect suggests that users do the following:\n- Stop. Before you use the Internet take time to understand the risks and learn how to spot potential problems\n- Think. Take a moment to be certain the path ahead is clear. Watch for warning signs and consider how your actions online could impact the safety of yourself and your family.\n- Connect. Enjoy the Internet with greater confidence, knowing you've taken the right steps to safeguard yourself and your computer.\nYou can learn how to become a partner in this effort by going to its website at www.stopthinkconnect.org. This site also contains the tips and advice for doing the following.\nKeeping a clean machine:\n- Have the latest security software, web browser, and operating system.\n- Use programs that automatically connect and update your security software.\n- Protect all devices that connect to the Internet from viruses and malware.\n- Use your security software to scan all USBs and other external devices before attaching them to your computer.\nProtecting your personal information:\n- Secure your accounts with protection beyond passwords that can verify your identity before you conduct business.\n- Make passwords long and strong with capital and lowercase letters, numbers, and symbols.\n- Use different passwords for every account.\n- Keep a list of your passwords stored in a safe place away from your computer.\n- Use privacy and security settings to limit who you share information with.\nConnecting with care:\n- Delete any suspicious e-mail, tweets, posts, and online advertising.\n- Limit the business you conduct from Wi-Fi hotspots and adjust your security settings to limit who can access your computer.\n- Use only secure websites when banking and shopping, i.e., ones with https:// or shttp:// in their addresses.\nBeing web wise:\n- Keep pace with new ways to stay safe online by checking trusted website for the latest information.\n- Think before you act when you are implored to act immediately, offered something that sounds too good to be true, or asked for personal information.\n- Back up your valuable information by making an electronic copy and storing it in a safe place.\nBeing a good online citizen:\n- Practice good online safety habits.\n- Post about others as you would have them post about you.\n- Report all types of cybercrime to you local law enforcement agency and other appropriate authorities.\nThis is phishing with text messages instead of e-mails. Beware of any messages that request personal information or give you a phone number to call. Before calling verify that the number matches the number of the named institution, e.g., your bank. And never give out personal information unless you have initiated the call.\nVirus creators, identity thieves, and spammers are increasingly targeting users of social networking sites in an effort to steal personal data and account passwords. One of the tactics they use to gain access to this information involves sending social networking users e-mails that appear to come from online friends. For example, some Facebook users have been receiving e-mails from their \"friends\" that claim to contain a video of them. When they click on it they download a virus that goes through their hard drives and installs malicious programs. The virus, known as Koobface, then sends itself to all the friends on the victim's Facebook profile. A new version of the virus also is affecting users of MySpace and other social networking sites. Cyber-criminals are tricking social networking users into downloading malicious software by creating fake profiles of friends, celebrities, and others. Security experts say that such attacks, which became widespread in 2008, are increasingly successful because more and more people are becoming comfortable with putting all kinds of personal information about themselves on social networking sites. They warn that users need to be very careful about what information they post because it can be used to steal their identities. Facebook users should become a fan of its security page at www.facebook.com/security, which has posts related to all sorts of security issues, tips, resources, and other information.\nTo avoid problems on social networks or anywhere in the Internet, users should:\n- Not to click on any links, videos, programs, etc. provided in messages, even if a “friend” encourages you to click on them.\n- Get program updates from the company's website, not through a provided link.\n- Customize your privacy so only your friends have access to the information you post.\n- Scan your computer regularly with an updated anti-virus program.\n- Be suspicious of anyone, even a \"friend,\" who asks for money over the Internet.\nDelete any suspicious e-mail without replying, especially the following:\n- Business opportunities to make money with little effort or cash outlay\n- Offers to sell lists of e-mail addresses or software\n- Chain letters involving money\n- Work-at-home schemes\n- Health and diet claims of scientific breakthroughs, miraculous cures, etc.\n- Get-rich-quick schemes\n- Free goods offered to fee-paying group members\n- Investments promising high rates of return with no risk\n- Kits to unscramble cable TV signals\n- Guaranteed loans or credit on easy terms\n- Credit repair schemes\n- Vacation prize promotions\n- Special offers that require a credit check and a small fee for verification expenses to be paid by a credit or debit card\n- Notices of prize or lottery winnings that require you to pay a fee to cover expenses You should also file a complaint with the IC3 at www.ic3.gov. Its website also includes tips to assist you avoiding a variety of Internet problems.\nIn another scam known as \"whaling\" fake e-mails have been sent to high-ranking executives to trick them into clicking on a link that takes them to a website that downloads software that secretly records keystrokes and sends data to a remote computer over the Internet. This lets the criminal capture passwords and other personal or corporate information, and gain control of the executive's computer. In one case fake subpoenas have been sent to executives commanding them to appear before a grand jury in a civil case. The link that offers a copy of the entire subpoena downloads the malicious software.", "label": 1}
{"text": "October is National Cyber Security Awareness Month; and in light of this, InHomelandSecurity is presenting a series of blogposts focusing on the security steps you can take to protect yourself from hacking, clickjacking, and other forms of cyberterrorism. Think about what you can do to make yourself more secure in your online world, and take a moment to read our offerings for this month of safety and security:\nMalicious URL’s in social networking are nothing new. Back in 2011, Time’s Techland blog reported in an independent study that 68% percent of Facebook users clicked on links sent to them. And why wouldn’t they? If a URL appears on your Facebook page or a friend sends you a private message on Twitter, it’s a link coming from someone you know. A friend.\nTechland’s study, though, reveals an inconvenient truth: 42% in this study admitted not knowing all their “Friends” on Facebook.\nBut that was 2011. We’ve learned a lot in a year, haven’t we?\nFast forward to September 24, 2012, where Sophos’ Naked Security blog reported new malware (software that installs itself on your computer without you knowing) is making the rounds using both Twitter and Facebook, and here’s how it works:\n- You usually get a direct message that reads “lol ur famous now” or “lol iz this u in this vid?” along with a link.\n- Regardless if you are logged into Facebook or not, you will be asked to log in to “verify” the link.\n- You will then be asked to load a “YouTube” update or third-party video application asking to access your Facebook account.\nOnce uploaded, the “update” installs a backdoor Trojan, software that replicates itself across network drives. Usually, these updates record your computer activity (websites visited, commands and passwords entered, etc.) and send data to a remote location.\nAll this happens because of a message. From a friend.\nBut there are precautions you can take with these attempts, and many of them involve common sense:\n- Do you know the sender? Do you often hear from them in this direct a fashion? If not, send a reply, asking if they did in fact send you a link.\n- Is the message poorly constructed? If it is something like “lol iz this u in this vid?” ask yourself if this is common for your friend? Do they usually spell “is” and “you” like this? A good sign it is a spam or a compromised account is the message itself is full of typos or poor sentence structure.\n- Remove and report SPAM on your Facebook wall. Make sure to remove it by moving your cursor over the “Edit/Remove” icon of the announcement, and selecting “Report/Mark as Spam” from the offered menu. (See image below)\n- Delete any Direct Message in Twitter if you suspect it is SPAM. On Twitter, if you suspect a private message as SPAM, reply to the friend and then delete the message. If it happens again, consider removing that user from your network.\n- Change your password if you believe you have been hacked. If you suspect that your Facebook or Twitter account has been compromised, change your password immediately. Do not use the same password for social networking as you use for other websites such as banking or eCommerce.\nSo what harm would it do if you just clicked on that link a “friend” sent you? Quite a bit actually. Following these preventative tips can still allow you to enjoy the benefits social networking while avoiding malware that could lead to identity theft and fraud. A mantra to follow when networking — think before you click. It’s a simple practice that can keep you safe and secure.\nAnd take a moment to consider that “friend” suddenly reaching out to you. A moment’s consideration can save you a healthy amount of headaches when trying to repair your digital footprint.", "label": 1}
{"text": "Since 2010 we’ve seen a new type of malware rapidly evolving and making the headlines in security news magazines around the world. Traditional Trojans, viruses, spyware and computer worms can be viewed as mere tools in petty theft crimes, in comparison with cyberwarfare weapons like Stuxnet.\nAlthough these malicious programs have affected the internet security of thousands of web users around the world, it seems that the Middle East is the preferred target of cyber-attackers. In late 2011 and the first half of 2012, security experts have been buzzing with news and discoveries of new malware strains used in attacks over the energy and banking sectors of countries in this region.\nNew standards for malware sophistication and scope\nMalware complexity has reached an all-time high and malware attacks can now be easily targeted at specific countries, companies or individuals. They can be used as weapons in cyber-warfare and hacktivism.\nHere’s an overview of the most sophisticated, recently discovered internet security threats:\nStuxnet. Discovered in June 2010, Stuxnet is a highly sophisticated computer worm developed to spy on and sabotage Iran’s nuclear program. Although the worm was supposed to remain secret and infect only computers in Iran’s infrastructure, an error in its code made it possible for it to go wild on the internet and replicate itself on computers and systems around the world. With a code 50 times as big as the typical computer worm, Stuxnet is the first such Windows-based malware discovered to spy on and subvert industrial systems.\nDuqu. Also a dangerous computer worm, Duqu was discovered in September 2011, spreading in the form of a Word document via e-mail. Since then, new, more targeted variants of it have been discovered in several countries around the world, including Iran. Its main capabilities are capturing keystrokes and stealing system information. Due to similarities in code, Duqu and Stuxnet are said to be related.\nFlame. Of an even bigger complexity than Stuxnet’s, the Flame malware was identified by internet security experts in May 2012. It was found on Windows computers belonging to governmental organizations, educational institutions and private individuals in Iran, Syria, Lebanon, Saudi Arabia and Egypt. Flame can spread via USB sticks or local networks, and record audio files, Skype conversations, keyboard activity, network traffic and more, but doesn’t actually damage systems. As such, it is believed to be more of a cyber-espionage tool.\nGauss. In July 2012, internet security experts found Gauss ravaging through Windows computers in the Middle East, mainly Lebanon. Showing similarities with Flame, this piece of malware is considered a cyber-espionage tool, as well. Its main capability is stealing cookies, browser history and login credentials for online banking and payment accounts, as well as for social networking and e-mail accounts.\nShamoon. In mid-August 2012, experts made public the existence of yet another possible cyber-weapon: Shamoon. However, this virus is not believed to be state-sponsored, but more of a tool used by hacktivists to protest against tyranny and oppression in the Middle East; the primary targets were state companies from the energy sector. Shamoon has computer data-wiping capabilities and can spread to computers of the same network, including those that are not connected to the internet.\nPrevention is better than cure. We can’t stop preaching about it\nWhile the heavily targeted region for these attacks was the Middle East, other countries have also been affected, including the US, India and European countries. And even if many of these attacks were aimed at sabotaging industrial activities, private individuals have also fallen victim. Which is why states, companies and individuals alike have to make sure they always have proper internet security in place. Now, surely, states and companies have experts to look after their internet security. But what can you do to look after yours?\nHere’s some internet security advice:\n- Always stay informed about new malware and online dangers. If you have at least one internet-connected device, then make sure you know all the threats you’re up against when you go online.\n- Keep your operating system and computer programs up to date, because software vulnerabilities can easily be exploited by malware and hackers. A Vulnerability Scanner, like the one in BullGuard Internet Security 2013, may come in handy to spot any outdated software and find updates for it.\n- Last, but not least, get proper antivirus protection for your computer, just like the one provided by BullGuard’s internet security software, to prevent all types of malware from infecting it. BullGuard Internet Security 2013 comes with a multi-layered protection system that virtually impenetrable and several other security features to keep you safe at all times.", "label": 1}
{"text": "Consumer Protection > Consumer News & Information > FDIC Consumer News\nFDIC Consumer News\nFraud Alert: Text Messages, Pop-Ups and Downloads to Avoid\nFDIC Consumer News has reported how criminals masquerading as legitimate businesses or government agencies have tricked consumers into divulging valuable personal information over the computer, phone or fax in order to drain bank accounts. Here are our latest tips for protecting against new schemes using electronic devices.\nThink twice before responding to “urgent” text messages. One recent scam involved a text message sent to cell phones and smartphones (a hand-held device to access the Internet and make calls) warning bank customers that their debit or credit card had been blocked for security reasons. The message urged users to call a hotline to unblock their card, but instead they reached an automated response system asking for their card number, personal identification number (PIN) and other information.\n\"Unfortunately, this was enough information for thieves to create counterfeit cards and commit fraud,\" said Michael Benardo, Chief of the FDIC's Cyber-Fraud and Financial Crimes Section.\nWhy are smartphone users now being targeted by scammers? \"Smartphone users almost always have their phone handy and tend to respond to calls and e-mails quickly, so the expectation is that many of them may not realize that a message is fake until it's too late,\" Benardo explained. \"Not only that, but fake Web sites are also harder to spot on a small screen.\"\nBe on guard against unexpected pop-up windows on Web sites, including your bank's. If after you're logged onto your bank's Web site — or on any Web site, for that matter — and you get an unexpected pop-up window asking for your name, account numbers and other personal information, that is likely a sign that a hacker has infected your PC with spyware and is trolling for enough information to commit identity theft and gain access to your bank account.\n\"It's normal for your bank to ask for your login ID and password when you first log in and to ask you to answer a 'challenge question' if you want to reset your password or start using a new computer,\" advised David M. Nelson, an FDIC fraud specialist. \"But your bank will not ask you — through a pop-up window — to type your name and information such as your date of birth, mother's maiden name, bank account and cell phone numbers. Banks only need that type of detailed personal information when the account is initially opened.\"\nBe suspicious of unsolicited offers to download games, programs and other attractive \"apps\" (applications) onto your smartphone. Those \"deals\" could contain malicious software directing you to fake Web sites or install spyware used to steal information that can lead to theft. \"You should consider using anti-virus software specifically designed for smartphones and other mobile devices,\" added Nelson.\nWhat are your best defenses against a variety of high-tech scams?\nFor additional tips on avoiding Internet fraud, visit www.onguardonline.gov.\nLast Updated 2/22/2011", "label": 1}
{"text": "These days, it’s hard to turn on the news or open a newspaper without seeing something about cybersecurity. President Obama calls for an immediate evaluation of U.S. cybersecurity initiatives. Rod Beckstrom, cybersecurity chief at the Department of Homeland Security (DHS), resigns amid turf battles with the National Security Administration (NSA). The Chinese government is accused of orchestrating cyber attacks on U.S. military networks. Congress is contemplating new legislation to expand government authority to manage Internet operations and other national cyber infrastructure. These headlines, coupled with criticism from all directions, has our leaders looking for the answer to the $64,000 question– is it truly possible for the government to a.) Share information freely enough to ensure national security, b.) Continuously defeat cyber attackers, and c.) Respect citizen privacy? All at the same time?\nA Call for Action\nBefore we throw our hands up in frustration, we ought to remember that cybersecurity needs to strike a balance between protecting citizens and enabling the collective business of government and industry – day in and day out. What we need is a solution to ease the natural – and very strong – tension between protecting sensitive data from the wrong hands and completely imprisoning mission-critical information for fear that it will be used inappropriately. The solution must also protect the network infrastructure supporting the data, while facilitating the sharing of the very information it protects.\nFederal agencies have been working to develop this solution for quite some time, and at its core is the practice of information assurance. Information assurance combines aspects of physical and cyber security protections, allowing for safe information sharing and collaboration across agencies. While restricting unauthorized information access, information assurance simultaneously enables protected access to the network that supports the flow of information.\nTo Share or Not to Share\nGiven the grave threats to our critical infrastructure, it is tempting to lock down buildings, networks and data, limiting access in efforts to mitigate risks. However, agencies must realize that information sharing is as important to our government’s security posture as both information and physical security. Intelligence must be shared to realize its value. From Social Security numbers and tax information to law enforcement data and classified national security intelligence, agencies must carefully determine which parties can access the information, and how. Through the enforcement of policies and procedures and the deployment of technology solutions – from CAC cards to secure ID tokens to iris scans and other tools – agencies have access to the power, the technology and the know-how to allow authorized individuals in and keep others out.\nPeriodically, public concern arises that agencies like the NSA have too much access to information. But there have been laws on the books with substantial penalties for the wrongful use of sensitive information long before we started saying, “cybersecurity.” When I worked with the U.S. Customs Service (later Customs and Border Protection), we frequently coordinated with Federal, state, tribal, and local public safety officials as well as numerous commercial trade organizations. Many times we were given access to very specific information that we could only use for an authorized purpose. After obtaining the information, I was civilly and criminally liable for protecting and appropriately using that information. So I made sure we used it only for its authorized intention. Information assurance policies function similarly – users are granted access to specific information for a specific mission. Once the mission is complete, access is restricted once again.\nProtecting the Network from Cyber Attack\nNetwork security is critical to information assurance. It isn’t just about keeping rogue agents out; effective network security also enables information sharing across, within, and among Federal agencies and important mission partners. Technology tools – and skilled professionals – are needed to defeat attackers that are intent on intruding to steal information or to disable the network itself. Systems analysts and software can monitor networks 24/7 for unusual patterns. In the case of a security breach, devices containing secure information can be completely locked down or, in some cases, open a trail leading directly to the cyber attacker.\nIt is possible for government agencies to realize cybersecurity as it was meant to be: a function that allows information sharing, protects data from unauthorized use, and protects citizen privacy. Leadership and commitment from the highest levels of government and industry are the answers. Only with visible and sustained focus from the top on properly funding and staffing information assurance will the cultural change and sustained investment in disciplined governance and defensive cyber technologies occur. Cybersecurity is fundamentally a people problem, not a technology problem. We know what to do; we need the will to do it. Accountability and trust are the behaviors that need to be institutionalized. We know how to do this at the micro-organizational level. We now need to commit to do it at the macro-level for the national and global cyberspace.", "label": 1}
{"text": "The Internet is widely used for research activities including data collection via electronic surveys, recruitment of research participants, and for interventional/observational activities. All uses present unique concerns for the investigator and for the IRB.\nProtection of human subjects is no less important when the research involves observation of online behavior. The IRB will make every effort to ensure individuals such as members of online cancer support-groups grant consent before having their discussions used for research purposes.\nWith the various uses the internet provides, there are challenges that may result pertaining to data quality. Issues surrounding social networking, posting images and videos of participants online, and recruitment and compensations can also be complex and therefore require the investigator to take extra precautions to ensure that privacy and confidentiality are not breached.\nRead More: Considerations and Recommendations Concerning Internet Research and Human Subjects Research Regulations (Produced by the HHS Secretary’s Advisory Committee on Human Research Protections (SACHRP)).\nOn this page:\nUsing the Internet as a Data Source\nResearch involving observation and reporting of online behavior is sometimes called data mining. The term data mining also refers to sorting through data to identify patterns and establish relationships.\nConsider the following:\n- Not all content on the internet is “public information.” Access is not a justification for collecting data without consent from the subject(s).\n- Most online groups do not require individuals to participate in discussions. After obtaining IRB approval and PRIOR to collecting ANY research data, permission must be sought from the list/group/community manager, and an announcement should be made to the list/group/community of the investigator’s intention to conduct research on the group.\n- Consent must always be obtained from subjects before attempting to collect private information. However, the investigator may request a waiver of informed consent. Concern that permissions will not be granted is not a justifiable reason for the IRB to waive consent.\n- Procedures must be in place to verify that research participants are adults.\n- Depending on the sensitivity of the research/data, clarity of disclosure, and confidentiality/anonymity of subjects, the IRB may require permission and/or informed consent to be obtained in addition to a community-wide announcement.\nUsing the Internet as a Research Tool\nThe internet can be used as a method of surveying subjects via direct email, web surveys, or other electronic instruments. The internet is a non secured medium meaning data in transit is vulnerable. The potential harm resulting from breach of privacy and/or confidentiality is accentuated if the research involves data that places subjects at risk of criminal or civil liability and/or could damage their financial standing, employability, insurability, or reputation.\nGuidance for Online Data Collection/Consent\n- A consent document for the internet should be written like a cover letter and should include all the elements of a regular signed consent, as appropriate. The signature line should read, “By completing the survey, you are agreeing to participate in the research.” Web based surveys should offer subjects the option to “Agree”/”Not Agree.” Online consent may not be appropriate for studies involving highly sensitive information.\n- For sensitive data transmission, the investigator should include a disclosure in the consent process, such as: “This research involves the transmission of data over the internet. Every reasonable effort has been taken to ensure the effective use of available technology however, confidentiality during online communication cannot be guaranteed.”\n- An alternative means for completing the survey should be offered where appropriate, such as printing the survey and mailing it in.\n- Survey instruments should be designed in such a way that allows participants to skip questions or provide a response such as “I choose not to answer.”\n- At the end of the survey, there should be one button to submit the data and another button to discard the data. The purpose of these buttons is to ensure that a subject may withdraw at any time and to help them understand that if they do withdraw, even after completing the survey, their data can be discarded prior to transmission to the researcher.\n- There are various protocols for transmitting data securely over the internet with SSL (Secure Sockets Layer) connections or Secure HTTP. Both SSL and S-HTTP can work interdependently or together. On an IRB application, the investigator must describe the technology chosen for implementation of the research and justify the plan based upon the sensitivity of the research.\nFor more information on online subject recruitment click here.\nChallenges of Internet Research: Data Quality\nSample Bias – Exclusion of Subjects\n- Internet samples make it problematic for researchers who attempt to generalize to broader groups.\n- Internet users vs. non-users vary on demographic, social, and psychological dimensions.\n- Dropout is an issue.\n- Longitudinal data collection is problematic online because email addresses and membership in online forums can quickly change.\nControl over Data-Collection Setting\n- Researchers can lose control over the environment in which the research is conducted when they conduct surveys or experiments online.\n- Behavioral monitoring and verification of subjects’ identities, age or gender present increased challenges.\n- Online subjects may simply invest less time and energy in the research task than those involved in a telephone survey or laboratory experiment.\nIssues in Social Networking Sites\n- Voluntary participation and identity disclosure is violated when researchers participate in discussion groups and bulletin boards and/or record and analyze text, but do not identify themselves as researchers (Engel & Schutt, 2010).\n- Posting patient protected health information is a violation of the Heath Insurance Portability and Accountability Act (HIPAA).\n- Posting pictures of patients (including those taken in international sites) is a potential violation of patient privacy.\n- The participants should know what information the researcher has/will collect; boundaries should be clear regarding what information will be gathered.\n- Knowing the researcher – if participants were to look at the researcher’s Facebook profile or conduct a “Google” search on her prior to the first study visit might this impact how they answer questions (Brooks & Churchill)?\nTo ensure that privacy is protected when using blogs for research:\n- Assess the blogger’s intent to be more or less private.\n- Ensure that the information used does not contain identifiable information. If a blogger uses a pseudonym used elsewhere on the internet, it may lead someone to information that can help identify the blogger.\n- To respond to higher levels of privacy, you may want to exclude certain content. Obtain consent from the blogger or mask certain details to minimize risk.\n- Work with the IRB to come up with a plan to help clarify how to calibrate privacy protections for blog material (i.e. exclude password-protected blogs).\nPosting Images or Videos of Participants Online\nPosting images or videos online can have ethical ramifications. It is good ethical practice to let the people identified in the picture know that you are photographing them and inform they of any plans to post online.\n- Online networks, such as PhotoVoice, have increased opportunities for artistic expression through participatory photography. Photo Voice employs participants to take images of their surroundings/neighborhoods as a way to advocate for social change.\n- Using images created of or by research participants can become complex as issues of consent, anonymity, and copyright come into play.\nTips for Photographing Subjects\n- Research participants may be actively involved in gathering data as they take photos to address different topics regarding social change.\n- Researchers should tell participants if they are required to report any photos revealing child or elder abuse or the likely prospect of harm that a subject may inflict on themselves or others.\n- Investigators must learn what methods of consent are acceptable to the IRB prior to photographing or otherwise recording subjects.\n- Researchers legally own the photos.\nWorking with Children Online/ Additional Security Considerations\n- Investigators communicating with children over the internet are subject to the Children’s Online Privacy Protection Act (COPPA) in addition to human subject regulations (45 Part 46 Subpart D). Investigators must not collect personal information from a minor without verifiable parental consent.\n- As appropriate, technology may be used to help screen out minors, such as programs that check for Internet Monitoring software or Adult Check systems.\n- The data file used for data analysis should be free of IP addresses or other electronic identifiers. If IP addresses are collected by the survey tool, the addresses should be deleted from the downloaded data file.\nRecruitment and Compensation on the Internet\nThe text and context of the recruitment message for any Human Subjects Research must be reviewed and approved by the IRB before the research begins. This includes posting to a blog or message board, mass e-mailings, and web pages created for recruitment of participants.\nTips for Compensating Anonymous Subjects\n- Consider using gift certificates from online retailers (and displaying the unique certificate redemption number to subjects after they complete the survey), in lieu of requiring identifiable information in order to mail out compensation.\n- Do not link compensation to contact information.\n- Use an intermediary service to manage your compensation.\n- Internet Research Ethics and IRBs (PowerPoint)\n- International Journal of Internet Research Ethics\n- Report on Conducting Research on the Internet (British Psychological Society)\n- “Internet Research, Internet Recruitment, Managing Data on the Internet” (Video)\n- VCU, Using the Internet to Conduct Research\n- IRB Challenge: Research on the Internet\n- The Board of Scientific Affairs (BSA) Advisory Group on Conducting Research on the Internet\n- Association of Internet Researchers “Ethical Decision-making and Internet Research”\n- Advisory Reports\n- Health and Human Services Secretary’s Advisory Committee on Human Research Protections (SACHRP).\n- The Board of Scientific Affairs (BSA) is the primary advisory body to the American Psychological Association. Their advisory report describes some benefits and challenges of conducting psychological research via the Internet and offers recommendations to both researchers and institutional review boards for dealing with them.\n- Ethical Decision-making and Internet Research: The Association of Internet Researchers (AoIR) ethics statement, developed by ethicists and researchers from 11 countries, articulates guiding questions for online research appropriate to the many disciplines—both within the social sciences and the humanities—that undertake such research.\nCases of Breach of Privacy\n- Harvard Researchers Accused of Breaching Students’ Privacy (July 29, 2011): some 1,700 Facebook profiles, downloaded from an entire class of students at an “anonymous” university, could reveal how friendships and interests evolve over time.\n- Large-scale Breach of Privacy Rules by New Zealand Post: A New Zealand Post survey that collected personal data to sell to marketing companies has been damned as a “systematic, large-scale breach” of privacy principles.", "label": 1}
{"text": "\"I can STEAL YOUR MONEY, your EMAIL or your IDENTITY. I can take control of your computer and use it to distribute spam, illegal pirated movies, or even CHILD PORNOGRAPHY. I could ruin your computer or your life.\"\nClick here to find out about confidence tricks, dangerous programs, how big the risk is.\n\"A good antivirus program will protect your computer without slowing it down, be easy to use, and have telephone support when you need it.\"\nClick here to find the best antivirus program for your computer.\n\"A properly protected computer is MUCH less likely to get infected by dangerous programs or viruses. Check your computer to make sure it's secure - or get an expert to do it for you.\"\nClick here to find out about computer security.\n\"You can avoid Internet risks by taking a few simple steps. Learn to recognise commong threats, warn your children, and THINK BEFORE YOU CLICK!\"\nClick here to find out how to stay one step ahead of the crooks.", "label": 1}
{"text": "What constitutes a strong password? An excellent question and something the industry seems to have difficulties figuring out at the moment. NIST, the National Institute of Standards and Technology, has a few words to say on the topic. Basically, password strength boils down to the number of bits of entropy that a password has.\nSo the next question is: How does one calculate the number of bits of entropy of a password? NIST has proposed the following rules:\n- The first byte counts as 4 bits.\n- The next 7 bytes count as 2 bits each.\n- The next 12 bytes count as 1.5 bits each.\n- Anything beyond that counts as 1 bit each.\n- Mixed case + non-alphanumeric = up to 6 extra bits.\nAfter thinking about this for a while and crunching some numbers, the NIST proposal seemed decent enough. Plus, implementing the algorithm in software is easy. Unlike a lot of programmers, I don't take algorithms like this at face value and just implement them blindly. I like to test their claims first and sometimes introduce my own ideas.\nDuring my research phase, I also ran across this xkcd web comic:\nWhile I don't generally care for xkcd comics, this one actually made me think. Is \"correcthorsebatterystaple\" actually 44 bits of entropy? I immediately said to myself \"no\" but, being a sucker for self-inflicted punishment, I went to check.\nModern security is best done by not \"handing out\" bits of entropy. Basically, you only want to say that something has \"at most 'x' bits of entropy\" if that something passes a number of tests.\nMy initial calculations of \"correcthorsebatterystaple\" against the NIST rules result in a maximum of 41 bits of entropy. So, xkcd handed out three undeserved bits. Three bits doesn't sound like a lot, but it is the difference between 550 years and 69 years. Also, this is a phrase using words from the dictionary and the letters of the phrase have a lot of repetition, so I modified the NIST algorithm to only count a multiplier of 75% of each repeat character (e.g. the first 'r' counts for 100% of the bits, the next 'r' counts only for 75% of the bits, etc). This drops the number of bits of entropy to 34.2. My own algorithm runs some more tests but the result still comes out to 34 bits. This is 10 bits fewer than the xkcd comic's claim for that strategy to selecting a password. Or, more simply put, roughly half a year at 1000 guesses/sec. Not 550 years.\nFor the \"Tr0ub4dor&3\" part of the comic, my same base algorithm gives me 22.1 bits, not 28 bits. Or roughly 1.2 hours at 1000 guesses/sec. However, the extra tests in my algorithm actually calculate it as having about 14 bits of entropy.\nOf course, the actual time it takes to guess the password is going to be somewhere between my theoretical time and xkcd's theoretical time. So, while on a surface level, xkcd seemed way off, the approach to selecting a good password with four random words isn't actually half bad and is a considerable improvement over today's passwords that users select. And we are all for anything that improves the passwords that users select...right?\nIf the computer generates dictionary-based passwords for the user, then that will eliminate the human equation. A human, following xkcd's rules, would likely select words of things that they can see, hear, and touch in their immediate vicinity - making it easier for a hacker to build a small attack dictionary. A quick glance around me and I get \"computerkeyboardvideogamenetflixmoviewikipedia\" - a great password from the algorithm's perspective except for the fact that I'm sitting at a computer with a keyboard, I love playing video games, I have a Netflix DVD movie in front of me, and I visited Wikipedia recently. So, even though I'm sure it has terrific entropy, it is a terrible password. Hence the need for a computer to generate dictionary-based passwords.\nOne thing I've noted with so-called \"password strength meters\" is that they are generally useless. The server-side doesn't enforce password strength requirements. Part of the problem is that no one seems to have come up with a solid algorithm (other than NIST) and no one has actually said, \"here is how you should use this password strength meter...\" This combination is useless to the average server-side programmer, so the only thing I've seen done is display the meter to the user and hope they make a strong password. Ha! As if that will ever happen.\nWhat should actually happen: Calculate the number of bits of entropy in a password using a good algorithm and then apply a minimum threshold. (And get rid of the silly password meter.) If the password exceeds the threshold, then the password is strong enough, otherwise the user has to try again.\nThis approach allows a web forum owner to choose a minimum threshold of 18 bits of entropy and an online bank to choose a minimum threshold of 40 bits of entropy (or more). Each industry requires different password strengths. A password strength meter, if you really need one, could then become useful for prevalidation against the threshold. After all, the user only cares to know the answer to the question, \"Will my password be strong enough so I won't have to resubmit this form?\"\nI'm still nitpicking at my algorithm, which is one of the reasons why it isn't being published (yet). So, don't get your knickers in a twist over my \"hand-waving\" claiming to have a solution and not playing nice in the kiddie pool and sharing said solution. The algorithm will be released in due time.\nAnother example: Google recently published an online safety guide on their homepage. This guide contains a YouTube video and other similar textual instructions on creating so-called strong passwords. The YouTube video shows \"Garden1ngF@n\" as a \"strong password\". For that password, my base algorithm gives 22.8 bits of entropy, but the extra tests portion of my algorithm calculate it as having around 16 bits of entropy. Yikes. Seems really broken to me.\nSo it looks like I'm onto something here. My algorithm is blasting apart even Google's recommendations for strong passwords. Woot!\nRead the next part in this three part series: Calculating Password Strength: Part II", "label": 1}
{"text": "Cyber-protest reflects cyber-warfare in its advantages over its physical counterparts; it is difficult for law enforcement to identify and prosecute the cyber-perpetrators. Cyber assaults in all forms are economical to conduct and the financial returns are overwhelming – causing potentially millions of dollars in actual and reputational damage with an attack like the one on Sony or STRATFOR (where payment information was compromised and published causing reputational damage) at a fraction of the cost.\nCyber-protest groups such as Anonymous have begun to affect the physical sphere. Anonymous were the organizers for the BART protests in San Francisco. Occupy Wall Street was the brainchild of the Adbusters protest group, with Anonymous becoming vocal promoters of OWS as the event grew close. Although the “Occupy” concept began in Spain and Greece, it has achieved global recognition under the Occupy brand. Now the Occupy Movement is seeking other forms of expression because the actual occupations have dwindled in numbers and media coverage has waned. Therefore, cyber-protest becomes more appealing.\nCyber-protest delivers all the same threats to companies that physical protest do: compromise of reputation; compromise of individual leaders and employees through doxing (the publishing of sensitive personal information on the internet); the compromise of physical infrastructure and assets (hackers can disrupt SCADA connected to the internet) or anything from the grid, from nuclear plants to electric turbines. As a result, if any of these components are attacked, the assault will have a significant effect on the financial interests of the company.\nCyber security has therefore taken on a whole new front. Not only must companies assess and manage the risks to their data centers, payment systems and finances, which tend to be better protected than the rest of the company, the penetration of the company’s e-mail systems, its records, its files and all its facilities must now be of concern. If Anonymous can hack the FBI’s e-mails and monitor telephone conversations, one must assume nothing is truly safe.\nWhat actions can companies take? Any company that has an active General Counsel will already have policies concerning what is written in e-mails, with good cause because of what occurs during legal proceedings. With the cyber threat, that is increased as an ongoing vulnerability. Making certain that physical and cyber systems are protected from being mutually compromised is also important. From the physical components of gates and guards through the IT systems to facilitate security, physical penetration is certainly viable at this stage, and there are some assaults that can only be carried out through physical penetration, including insider threats.\nCompanies MUST understand their protestor risk. Once the threat has been established, the means by which protests may materialize, be they by physical or cyber means, can then be assessed. Once a company fully understands the risk it faces from the protest community because of its own actions and counter-parties and those of its supply chain, then it can begin to understand the threats and the measures that can be put in place to manage those threats.\nAUTHOR’S UPDATE – February 15, 2012: Beginning Tuesday morning, Anonymous began attacking the websites of companies that sell less lethal weapons and technology, with the main focus apparently Combined Systems, Inc. When the press covers the use of CS gas in Bahrain, it is the logo of Combined Systems, Inc that is most often seen. This is an excellent example illustrating the point that one must understand the complete protester threat to a company as part of routine risk management, no matter how far from controversy one might believe their company to be. Once the exposure is understood, one can design one’s response to it. This requires understanding the supply chain and the political context.\nLAST 5 POST BY Sam Rosenfeld\n- Activist Groups Flocking to Environmental Issues, Direct Action Protests - February 20th, 2013\n- FBI/DHS Inaccuracy Could Lead to Police Over-Reaction - August 25th, 2012\n- Protest Groups Publish Police Home Addresses - August 21st, 2012\n- Worrying Signs From Tampa - Protest Management at the RNC - August 14th, 2012\n- Protesting is Cool This Summer - June 21st, 2012", "label": 1}
{"text": "The social web can only thrive if its participants are willing to share personal data, data about themselves, with each other. So, you have an account with some social network (Twitter, del.ico.us, LinkedIn, etc) in order to allow others to read your Tweets, peruse your presentations or, quite generally, find out who you are and what you do. With the advent of the semantic web, of systems that can make inferences on the basis of the data that are fed to them, this is all the more true. Individual users profit from the services that the web offers to them, often for free; the service providers profit, mainly from the advertisements that accompany their services. Although there are other business models, this is the prevailing one, it seems.\nSo far so good then. But what if service providers sell the data they have acquired in the course of their business to other providers; or worse even, what if these data end up in the hand of others because of clumsiness (a stolen USB stick, a lost laptop) or criminal intent (hacking servers, bribing personel)? Admittedly, you may decide to shut down your Facebook account or give up Twittering, but this freedom of choice is absent for many services. What about your loyalty card with your favourite grocery store, which not only registers your purchasing behaviour but also gives you access to sizeable discounts; or your public transportation travel pass, a system recently introduced in The Netherlands, which allows you to travel throughout the country with one card but registers routes and start and end times in its database; or a road use system installed in your car which helps prevent traffic congestions but does so by logging your car's GPS track data in its central database? In each of these examples - and many more can easily be given - data about a person are logged into a database and it is not transparent to the data providing individual what the associated privacy risks are.\nIn 1981 the states that jointly form the European Council signed a ‘Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data’. Among other things, it stipulates that no more data may be stored than needed for a particular, identified purpose, and that those data may not be kept for longer than strictly needed. The lack of transparency compels the individual to simply trust the database manager to abide by these rules. Experience teaches us that often this trust is misguided, even if we ignore cases of intentional theft and accidental loss of data. The issue of whom to trust with what data is a complex one. It touches upon the closely related questions of what data to collect and whom to allow to access them. The other day, I read a PhD thesis that sheds an interesting light on the first one of these questions (Harold J.W. van Heerde (2010) Privacy-aware data management by means of data degradation; making private data less sensitive over time. Universiteit Twente).\nIgnoring for now the possibility to grant differential access rights, someone can decide to make her particular personal data available or decide not to do so. A LinkedIn profile may contain a photo but need not. Something similar goes for the data that are collected through someone's public transport travel pass. If one uses the pass, route and time data will be collected and stored. Could a user still decide to remove or replace her photo, the storage of travel data is fully beyond her control. The point to note here is that the decisions are all-or-none decisions. Someone’s photo is there or it isn’t, travel data or logged or aren’t. There is no middle ground. Van Heerde shows that a sensible middle ground does exist. He introduces a limited retention principle, meaning that data degrade over time. So, the public transportation database may remain fully intact for a month to allow sending out bills. The data may subsequently be degraded to the level of the route and day of the week someone has travelled to allow sending out special offers. This level of detail is maintained, say, for a year. After one year only the cumulative frequency of use or routes per day of the week, decoupled from the individual, are still available. This still allows the statistical analysis of travel data, for planning purposes for instance. Data degradation allows for a more subtle marriage of the interests of the individual (new, better, cheaper services) with those of the service provider (a more efficient and effective business). Of course, there are all sorts of theoretical and practical problems to be dealt with. Van Heerde discusses many of them, he also suggests how to solve them. For me, the importance of his contribution is his description of how one may come one step closer to heeding the European Council's admonition only to store just enough data for just long enough. This is in the interest of both web service users (aren't we all) and web service providers.", "label": 1}
{"text": "[Editor's note: The Tyee is proud to co-publish with Rabble.ca a multi-part investigation of Maker Culture -- the do-it-yourself movement fast evolving in North America and beyond. This is episode four of 11, running Fridays.]\nIt's a wet Saturday afternoon at a hacker convention in an industrial section of Hamilton, Ontario. Treven Watson's Lucite badge is flashing: blue, green and red. The LED lights are controlled by a circuit in the laser-etched ID. That little bundle of electronics is about to be probed and reprogrammed by Watson and the three dozen other coders, anxious to make it do anything but alternate primary colours.\n\"There's a tradition in hacker conventions of making badges that can be expanded, can be hacked to do other things,\" said Watson.\nWatson is a member of the Hamilton hacker space think|haus. Attendees at the convention each got their own badge and spent hours seeing who could hack it best.\nHackers love figuring out systems like these badges, whether it's picking a lock, social engineering or hacking a computer.\nBeyond the thrill of the prank, what drives people to hack? \"I think it’s what drives us to be human,\" said Howard Rheingold, a writer, artist and teacher who coined the term \"virtual community.\"\n\"When we talk about technology, I think people often disconnect that from the fact that we are creatures that have hands with opposable thumbs and binocular vision and brains that have evolved because we coordinate our activities in manipulating the world.\n\"Our ancestors were rather small creatures and they were prey, how was it that we turned into the top predator in the food chain? It had to do with not only our ability to use our hands, but our ability to coordinate and communicate with each other.\"\nThe birth of digital hacking\nBy coordinating and communicating, early computer enthusiasts formed support systems. Hackers experimented with software and hardware, pushing the bounds of computers for the fun of it, and advancing computer capabilities along the way. One of the most notable of these was the Homebrew Computer Club (HCC) out of Silicon Valley in California.\nOut of the HCC came Steve Wozniak's Apple I, a hobby computer made to impress his friends. He handed out schematics and helped people set up their own at home. His college friend Steve Jobs convinced him to patent and sell the Apple I. This was Apple Inc.'s first product, and it was quickly followed by the Apple II, which was produced until the early '90s.\nThe personal computer revolution all but ended community hacking. Hackers quickly made careers as developers who couldn't share their secrets, or they would be scooped by a competitor.\nSecurity cracking, our modern idea of hacking, grew out of the '80s alongside personal computers.\nHACKING'S PHREAKY HISTORY\nMessenger boys became the first hackers when they were hired to work on telephone switchboards in the late 1860s. They quickly hacked the system. Dropped calls, intentionally crossed lines and insulted customers became too much. And in less than two years, the boys were flung off the switchboards. Docile young ladies were hired to take their places.\nAbout a century later hackers showed up again. Phreakers hacked phone systems for free long-distance calls. The switching systems to connect calls were automatic at the time, run by a series of signals and tones at different pitches.\nIn 1972, John Draper was a young Californian fascinated by technology. But when a blind friend discovered that whistles found in Cap'n Crunch cereal mimicked the signal to switch a call to an open internal line, Draper's life changed forever. He became Cap'n Crunch, the most famous of the phone phreaks. The discovery inspired Draper to create \"blue boxes,\" devices that could imitate different system signals while connected to a telephone.\nIn the mid-'70s Draper met the future co-founders of Apple Computers, Steve Jobs and Steve Wozniak. Draper showed Wozniak how to use a blue box in Wozniak's college dorm. To test it, they placed a call to the Vatican for free and asked to speak to the Pope. It was around four in the morning in Vatican City, and the Pope was sadly unavailable.\nAt the same time as the negative press on hacking, more people began using PCs. Connecting computers became a major goal, and early networks were developed -- ARPANET, Bulletin Board Systems, then web 1.0 and 2.0. People continued to appropriate technology and use it to connect to the world around them.\n\"'Appropriated' is a word that is compatible with 'hacked,'\" said Rheingold, and in the case of communications technology, \"people will take tools that are provided for other reasons and use them to communicate.\"\nBut the concept of hacking technology for the fun of it, and making things work the way you want them to, can still trump the desire to create new ways to communicate.\nFresh, homemade mobile innovation\n\"I was inspired by the movie Ferris Bueller's Day Off, where he's sick, he makes this call where he plays back puking sounds from his keyboard,\" says Tobias Weyland. \"Bueller inserts this diskette into his keyboard and pretends to be really sick, I've always wanted a thing like that.” Weyaland's a Nintendo DS homebrew game developer.\nHe finally got to fullfill his dream -- well, without the cybervomitting. The PhD computer science student at Aachen University in Germany always wanted a portable music tracker, so he programmed one. Nitro Tracker is one of the most popular homebrew applications for the Nintendo DS and allows users to create basic melodies that resemble the beeps and boops of old video games. Weyland is also part of an active community of homebrew developers and coders called Dorkbot.\nWeyland started playing the popular PC game Crayon Physics. He wanted to take it everywhere in his pocket, so he developed Pocket Physics. Drawings on the DS touch screen react to real world forces, like gravity. Crayon Physics has spawned an online community, where users can upload and share their creations. When Weyland runs into problems developing DS homebrew, he brings his applications to his local Dorkbot group, a worldwide group of makers and hackers who get together and share ideas and concepts.\nHomemade applications need help to work. Small cartridges, called flashcards, hack the DS and allows it to run unlicensed code, including pirated commercial game files. This gives the homebrew community a bad reputation, and Nintendo has shut down many flashcard retailers. Over the years, flashcards have evolved from clunky pieces of plastic to sleek devices that look like regular DS games. Micro SD cards fit inside them and allow data transfer from computer to flashcard.\nLucas Arts lead designer Jens Anderson developed the game Colors!, which allows users to create detailed art. Anderson worked around the DS hardware limitations to make his advanced image creation program. An online community sprang up, similar to Pocket Physics' following, which allows users to upload their artwork.\n\"The most surprising thing was clearly how well it was received within the professional digital concept art community,\" said Anderson.\nJeremy Smith of Vancouver, British Columbia, developed a DS version of Guitar Hero. Users tap onscreen notes and follow the tune of popular video game music. Smith collaborated with an artist to create the visual interface for his game.\n\"I'd always been interested in doing a music-slash-rhythm game,\" said Smith, who also programs user-generated iPhone applications.\nClosed platforms: why there isn't 'an app for that'\nThe iPhone revolutionized mobile communications by allowing individuals and software companies to develop apps for the platform. But Apple continues to frustrate app developers with a \"black box\" approval process that many find arbitary and slow. Now Google has opened the gates further for inexpensive application development on the open source Android mobile platform.\nAndroid, which runs on open source code, offers an app store, the Android Market, much like the iPhone's, but with one important difference -- Google's removed the approval process. Android’s open door policy has the hacker and programming communities' interest.\nMichael Both originally developed the GolfCard app for the iPhone, because it was the only touch screen handset capable of running his program. Google contacted Both when Android was released to tell him about their new operating system. \"Essentially, it was described to us as being just like the iPhone platform, minus the approval process, but with the stipulation that if the app was seen as inappropriate it would be removed from the store,\" he said.\nAart Bik is a Google software engineer who has applications available on the Android Market. \"I implemented a few board games just for fun and put them in the market in the hope that users would enjoy them. I expect that professional programs will replace them pretty soon, but I have been pleasantly surprised with the popularity of the applications so far,\" Bik said.\nMatt Liszt is a software developer at Glu, the company responsible for the mobile version of Call of Duty on Android. Glu has a long list of mobile games which were available before the iPhone. Liszt thinks that because Android is an open platform, it will help makers innovate. \"We are already seeing that most of the top apps on Google [Android] are from small developers,\" Liszt said.\nEric Burke built the State Capitals application for Android. He is outspoken about his passion for an iPhone alternative. \"Developers are annoyed by Apple's constant app store rejections. You don't have that same frustration with Android. I can publish an update to my app and it is available for download instantly. As more and more phones arrive, there will be more customers, so Android is becoming a viable market to make some money,\" Burke said. Like many hackers and makers, Burke wants the freedom to share an innovate the Android Market offers.\nA 'beat' to save the open web\nClosed mobile platforms, like the iPhone, don't just threaten application diversity. The Mozilla Foundation thinks they threaten the very foundations of a democratic Internet, as users continue to carry their digital lives in their pocket.\nFrank Hecker, director of grants and programs for the Mozilla Foundation, said the increase in mobile technology threatens the idea of an open web. Mobile devices are often closed systems with heavy applications restrictions.\n\"There's a real danger in moving to the mobile space that we're going to lose a lot of the ‘generativity'... of the Internet which has traditionally existed,\" said Hecker, referring to the revolution of web 2.0, which gave the Internet easy self-publication tools.\nThis generativity is what the grassroots movement called Drumbeat is hoping to protect.\nCreated in August 2009 by Chelsea Novak and executive director of the Mozilla Foundation, Mark Surman, Drumbeat is a community of people from knowledgeable hackers to casual web users, who feel that the Internet should be seen as a public utility. Mozilla is giving that community a space to meet, collaborate and receive support from the Foundation themselves.\n\"There are people out there who, we like to say, they make the web,\" said Novak, fundraising and communications manager for the Mozilla Foundation. \"Technology companies and software companies, they build the web, but people who make the web are people who blog and they do LOLcats... they create all this content and all this material that we use on the web.\n\"Because they're not necessarily 'building the web,' they may not realize that they have a say in the issues.\"\nThe Mozilla Foundation gives those users a say with Drumbeat.\n\"Mozilla's mission is to make sure that the Internet continues to be open and that it continues to be a place where people can innovate and create,\" said Surman. \"Drumbeat is a new effort to go beyond that and pursue that same objective, but beyond product.\"\nDrumbeat is still in its early stages, with new contributors joining the discussion as the movement grows. The first issues to tackle have yet to be identified, Novak said, but Surman sees the rise of the Internet cloud as an area to address. He said as users toss their personal data into the \"cloud,\" through hosting applications like Gmail or Facebook, they breeze by legal jargon in Terms of Service agreements without fully understanding where their information is going, who owns it and how it will be used.\n\"There really hasn't been either a conversation or really a set of products to figure out 'what [does] my kind of freedom and my control look like in those cloud apps?'\" said Surman.\nDrumbeat wants to inspire enthusiasm for the open web and get users, not the corporations, to make change. Surman said Drumbeat is about creating plug-ins and tools that enhance the openness and accessibility of the Internet, rather than asking for changes in proprietary software.\n\"We can go to Microsoft and say, 'Make IE6 [Internet Explorer] better,' but I'd rather we created a product that people want to use,\" said Surman. \"We're trying to say that anyone can pick up the tools and create the Internet. And I think we all do. So much of the Internet is shaped by us every day in terms of who makes the content. Drumbeat is very much about that.\"\nThe street finds uses for things\nBack at the hacker conference, attentions have shifted from the blinking badges to the set-up of a 3D printer from MakerBot Industries.\nJames Arlen, founder of think|haus, looks across the busy workspace to the half-built printer. \"William Gibson said this in the early- to mid-'80s. He said 'the street finds uses for things.' So whatever the original purpose was... whatever the marketer intended, might not be the way that it turned out. And that's where we are. So that was 20 years ago,\" he says. \"What's going to happen in another 20 years?\"", "label": 1}
{"text": "malwareArticle Free Pass\nmalware, in full malicious software, malicious computer program, or “malicious software,” such as viruses, trojans, spyware, and worms. Malware typically infects a personal computer (PC) through e-mail, Web sites, or attached hardware devices.\nMalware may be used to take over PCs, turning them into zombie computers that may form part of a “botnet” used to send out spam or perform denial of service attacks on Web sites. In addition, malware has been used to distribute pornography and unlicensed software. Owners of infected PCs often become aware of a problem only as their machines become progressively slower or they find unidentifiable software that cannot be removed.\nRootkits are one of the worst forms of malware. Their name comes from the fact that they infect the “root-level” of a computer’s hard drive, making them impossible to remove without completely erasing the drives. In efforts to curb copyright infringement, some computer software makers and music companies secretly install detection software on users’ machines. For example, it was revealed in 2005 that the Sony Corporation had been secretly installing rootkits as its music CDs were loaded into PCs. The rootkit was discovered because of the way that it collected information on users’ PCs and sent the data back to Sony. The revelation turned into a public relations disaster, which forced the company to abandon the practice. The practice of monitoring users’ data, with or without installing rootkits, continues in the software industry.\nThe evolution of malware reached a new milestone in 2010, when the Stuxnet worm proliferated on computers around the world. Characterized as “weaponized software” by security experts, Stuxnet exploited four separate vulnerabilities in the Windows operating system to achieve administrator-level control over specialized industrial networks created by Siemens AG. By attacking these supervisory control and data acquisition (SCADA) systems, Stuxnet was able to cause industrial processes to behave in a manner inconsistent with their original programming, thus crossing the line between cyberspace and the “real world.” While Stuxnet’s intended target remained a matter of debate, the worm demonstrated that SCADA systems, which provide the backbone for such critical infrastructure sites as nuclear power plants and electrical grid substations, could be subverted by malicious code.\nWhat made you want to look up \"malware\"? Please share what surprised you most...", "label": 1}
{"text": "The official announcement of every terrorist attack invariably concludes with a stock phrase, “Ghatna sthal ke nikat suraksha ke prabandh our kare kar diye gaye hain (security arrangements around the place of incident have been further strengthened).” However each incident is succeeded by another attack, to be followed by a similar announcement. Terror strikes at the place and time of its choosing. Yet there is a pattern and that pattern essentially lies in the behaviour of the terrorist and modus operandi of the parent organization.\nFuture attacks cannot be predicted, but past ones can be catalogued, stored and retrieved in near real-time. “Data archiving” and “data mining” are scientific tools and methologies, the former for gathering, sifting, hoarding and storehousing data, and the latter for displaying duly processed critical information to the decision-maker, whenever the need arises. Its hallmarks are virtuality and event-retrieval potential, and its purpose is to match, locate and track saboteurs, hijackers and terrorists.\nIn April 1999, Applied Systems Intelligence Inc was selected by the US Air Force to develop innovative information technology for a Global Information Base to “store global awareness information,” besides providing information services for dynamic planning and execution of operations. The software developed by the firm is called KARNAC, short for Knowledge-Aided Retrieval in Activity Context. It is highly versatile, and is anchored in a group of technologies and decision support and database management systems. It is designed to detect and identify impending terrorist operations and similar missions.\nIt is well known that Al Qaida terrorists and others of their ilk hunt for information on the Internet, often leaving valuable clues while surfing and communicating. Therefore it is logical to look for and pursue them in their haunt rather than go on hunting missions. Adam Pasik writes in “Sifting through Data to Detect New Attacks,” (infowar.com), “The problem is that intelligence and law-enforcement agencies are searching the world’s biggest haystack – untold exabytes, or quintillions of bytes of data stored on computers across the globe – to uncover a few dangerous needles.”\nAt the time of the September 11 attacks, there was a plethora of helpful scraps of information available e.g. e-mail intercepts, telephone calls, car rentals, airline reservations, financial transactions, casino winnings, Immigration records and much more. During the attack on our Parliament, the terrorists left behind pertinent information such as a laptop, which has reportedly been sent to Microsoft for analysis, and vital information about the terrorists’ hawala (money laundering) links and ISI connections garnered from cellular numbers called by the terrorists. Whereas security, intelligence and law-enforcement agencies work in tandem in the\nand other Western democracies with common databases, in\n, the right hand does not know what the left holds. Sharing information is the only way terrorists can be defeated at their own game and this sharing must occur within the security and law-enforcement agencies in the country, and also amongst all the countries fighting the global war against terrorism.\nCritical event detection, information retrieval and knowledge-based technologies, products and systems are available off-the-shelf, and are widely used in the commercial world. Banking fraud detection, promotional mailing, market research, supply chain management, tracking stolen credit cards, and antecedent check by credit companies are some of these applications. The potential market for these products is estimated to be several hundred million dollars. Indian software companies are aware of its potential and have ventured into writing some useful software applications. The software is not infallible, but that should not detract from its merits, which essentially lies in integration, automation and embedded security.\nThe technology can bring to focus artificial intelligence and virtual reality to search large data repositories, identify events of interest and compare templates. Elsewhere, much work has been done to acquire this capability. The rub lies in matching wits, in which the terrorists have an edge. Making events appear unrelated, random and seemingly innocuous is their strong point. Archived information can help in timely detection by piecing together the pattern, and sounding the alert based on past acts of terror. It could thereby preempt attack on a government or commercial facility.", "label": 1}
{"text": "The MySQL root password allows full access to the MySQL database and allows for all actions to be undertaken including creating new users, new databases, setting access rules and so on.\nLosing one can be a difficult issue to encounter. Luckily, resetting the root password is easy as long as you have sudo access to the Server.\nA common issue is confusing the Server root user with the MySQL root user.\nThe Server root user is the server's main user. The MySQL root user has complete control over MySQL only. The two 'root' users are not connected in any way.\nThe first thing to do is stop MySQL. If you are using Ubuntu or Debian the command is as follows:\nsudo /etc/init.d/mysql stop\nFor CentOS, Fedora, and RHEL the command is:\nsudo /etc/init.d/mysqld stop\nNext we need to start MySQL in safe mode - that is to say, we will start MySQL but skip the user privileges table. Again, note that you will need to have sudo access for these commands so you don't need to worry about any user being able to reset the MySQL root password:\nsudo mysqld_safe --skip-grant-tables &\nNote: The ampersand (&) at the end of the command is required.\nAll we need to do now is to log into MySQL and set the password.\nmysql -u root\nNote: No password is required at this stage as when we started MySQL we skipped the user privileges table.\nNext, instruct MySQL which database to use:\nEnter the new password for the root user as follows:\nupdate user set password=PASSWORD(\"mynewpassword\") where User='root';\nand finally, flush the privileges:\nNow the password has been reset, we need to restart MySQL by logging out:\nand simply stopping and starting MySQL.\nsudo /etc/init.d/mysql stop ... sudo /etc/init.d/mysql start\nsudo /etc/init.d/mysqld stop ... sudo /etc/init.d/mysql start\nTest the new password by logging in:\nmysql -u root -p\nYou will be prompted for your new password.\n© 2011-2013 Rackspace US, Inc.\nExcept where otherwise noted, content on this site is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License", "label": 1}
{"text": "One thing that won't change is that you can stay safe by showing basic vigilance: Keep your security software updated and run it regularly. Click only on links from trusted sources; the same goes for buying cellphone apps. Be smart about where and how you navigate in cyberspace.\nFive areas where scammers are likely to expend extra energy:\nRansomware. It begins when you open a malicious attachment, click on a link in a scammer's email or instant message, or visit scammer websites that promise such things as enticing videos or free prizes. Ransomware locks your computer, usually displaying a screen message that appears to be from a law enforcement agency. Pay us, you're told, and you'll get back control of your computer.\nOnce considered a niche scam, ransomware attacks exploded in 2012, hitting some 70,000 computers per month. About 3 percent of victims pay the ransom fee — thanks, in part, to cyber-criminals increasingly using online payment methods to collect, says cyber-security firm Symantec, which recently published a detailed report on this ruse. \"In 2013, attackers will use more professional ransom screens, up the emotional stakes to motivate their victims, and use methods that make it harder to recover once compromised,\" predicts Symantec's Kevin Haley.\nCloud-based botnets. For years, spammers have been distributing about 150 billion junk email messages per day with the covert help of the computers of everyday users — maybe even yours. To entice folks to watch videos on social networking websites, open email greeting cards and the like, spammers infect random computers with botnet malware that makes the machines secretly send out spam.\nIn 2013, predict Georgia Tech researchers, scammers will also turn their botnet schemes to what's known as \"the cloud,\" the global network of Internet-connected computers that store huge amounts of data, shuttle it around and offer data services. If you share your family photos online, for instance, you're using the cloud. As more and more companies put customer data and computing power on the cloud, there's an ever-growing collection of prized targets. \"One possible example is for attackers to use stolen credit card information to purchase cloud computing resources and create dangerous clusters of temporary virtual attack systems,\" say Georgia Tech researchers.", "label": 1}
{"text": "However, going totally wireless at home brings with it some possible problems as any new technology will do. Not the least of those concerns is security.\nGoing wireless means by definition that access to your computing resources and the internet is occurring without wires, through the air. And just as every computer in the house can access those digital signals, so can those outside the house and those who might not wish to use those signals properly.\nTherefore when planning your wireless network at home, some precautions and preventative measures should be observed so assure that your network at home is just as secure in a wireless mode as it was when you used cables and physical connections.\nThis purpose of this article is to help you understand the terminology of wireless security in the home setting as well as to develop a check list for key security oriented steps you should take when setting up and using your network.\nSome New Terminology\nThe wireless world has its own language and set of acronyms. So it’s appropriate before beginning our discussion of security to define some of the terms we need to understand to be effective at securing your home wireless network.\nSSID (Service Set Identifier) - This is the name of your network. All devices on the wireless network must use the same SSID to communicate with each other.\nWEP (Wired Equivalent Privacy) - A discipline that was integrated into the very earliest wireless standardization efforts that were put into place for the development of wireless technology. This protocol provides base level security standardization for all WI-FI vendors and systems that benefit from the OSI standardization effort. This standard, also called 802.11 is a default security level that is mandatory for all wireless products. WEP is either turned “on” or “off”. WEP was designed around the same security paradigms that were used in the wired network development time frame.\nWPA (Wi-Fi Protected Access) - A security protocol for the wireless technology industry that was developed to improve on the limitations of WEP.\nTKIP (Temporal Key Integrity Protocol) - TKIP is a more secure version of WEP which is required to utilize WPA for network security. TKIP encryption is stronger and more resilient than the WEP algorithm.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "gets is dangerousThis tip submitted by carl johnson on 2006-07-21 13:13:35. It has been viewed 9031 times.\nRating of 8.1 with 78 votes\nIf we use this code:\nchar string[ 100 ]; printf(\"ENTER SENTENCE: \"); gets(string);\nwe can introduce a bug or security vulnerability into our code!\nThe problem is that it allows someone to enter too much text and thereby overflow the buffer. There is no way for gets to know how big the string is supposed to be, so it will just read data until the user hits enter, even if it's way more than 100 characters. You can read more about the security risk of gets here. You can use fgets instead, which takes both a size for the string, ensuring there is no buffer overflow.\nIf you're interested in learning more about secure coding practices, check out this article on writing secure code.\nHelp your fellow programmers! Add a tip!", "label": 1}
{"text": "Aug. 4, 2009 A system that allows biometric data to be used to create a secret key for data encryption has been developed by researchers in South Africa. They describe details of the new technology in the International Journal of Electronic Security and Digital Forensics this month.\nIf a user, a web customer say, wishes to send a message or other data to another user, an online shop, over an unsecured network, the message must be encrypted to avoid interception of sensitive information such as passwords and credit card information.\nEncryption relies on authentication being symmetric to work. In other words, the user's password or PIN must match the password or PIN stored by the online shop to lock and unlock the data. This is because encryption systems use the password or PIN to produce, or seed, a random number that is used as the cipher for encrypting the data. If the passwords do not match exactly then the seed will be incorrect, the random number different and the decryption will fail.\nOne way to avoid users having to remember endless, complicated passwords is to use biometrics, including fingerprints, iris pattern, face recognition. However, biometrics is not a symmetric process. The initial recording of biometric data samples only a limited amount of the information, the pigment patter in one's iris, for instance. The unlocking process then compares the iris pattern, or other biometric \"token\", being presented for access with the sample stored in the database. If the match is close enough, the user can gain entry.\nThe reason for this asymmetry is that any biometric system takes only a digital sample of data from the fingerprint or iris, for instance. Moreover, even the legitimate user will not be able to present exactly the same biometric data repeatedly. The close enough aspect of biometrics does not make biometrics insecure, provided that the closeness is very precise, but it does mean that biometric tokens cannot be used to create a secret key for an encryption algorithm.\nBobby Tait and Basie von Solms of the University of Johannesburg, Gauteng, South Africa, explain how biometrics can nevertheless be used to make a consistent secret key for encryption.\nIn conventional encryption, if Alice wishes to send a secret message to Bill, then she must encrypt the message, whether it is an email or credit card details transmitted from her computer to the online shop. In order for the encryption algorithm to provide cipher text that is random, a secret key must be provided. Alice and Bill must share exact copies of their secret key for this to work.\nAside from the asymmetry in biometrics, this approach will not work because Alice and Bill cannot provide the same biometric token to encrypt and decrypt the message. Now, Tait and von Solms have used the so-called BioVault infrastructure to provide a safe and secure way for Alice and Bill to share biometric tokens and so use their fingerprints, iris pattern, or other biometric to encrypt and decrypt their data without their biometrics being intercepted.\nThe BioVault encryption system works as follows:\n- In phase 1, Alice identifies herself to the authentication server, and indicates that she wants to send an encrypted message to Bill and requests Bill's biometric key from the server.\n- In phase 2, the server retrieves a random biometric key from Bill's stored biometric keys.\n- In phase 3, Alice uses the biometric key to encrypt her message and sends it to Bill.\n- In phase 4, Bill receives the message sent by Alice, and decrypts the message by testing the biometric keys in his database against the received cipher text.\nThe fact that each biometric key (data) is unique means that the BioVault system can irrevocably identify and authenticate users through their biometric keys (data) and detect fraudulent use of biometric keys.\nTait adds that the same approach could also be used to digitally sign electronic documents, files, or software executables using biometrics. He will be presenting the team's results on this aspect of their work in the UK at the beginning of September. \"If passwords or tokens are used for authentication, only the password or token is proven as authentic - not the user that supplied the token or password,\" he explains, \"Biometrics authenticates the user directly - this was one of the drivers behind the BioVault development.\"\nOther social bookmarking and sharing tools:\n- BioVault: biometrically based encryption. Int. J. Electronic Security and Digital Forensics, 2009, 2, 269-279\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "You can create strong passwords that don’t make you memorize a cryptic string of letters, numbers, and punctuation symbols. Here are three techniques:\nUse a sentence. It’s easy to remember the first letters of the words in a sentence. For example, children have used this sentence to remember the names of the nine planets: My Very Excellent Mother Just Served Us Nine Pickles. You could use the first letters of those words to generate this strong 9-character password: m*Emjsu9p, where Venus (the morning or evening star) is represented by *, the letter for Earth is capitalized, and nine is a numeral. In practice, it’s best not to use such well-known sayings to generate acronyms.\nUse a pass phrase. Several words mixed with numbers and punctuation symbols is known as a pass phrase. For example: stitch9clock^handsapplausE. The longer the pass phrase, the more secure it is, though you’ll be limited by the maximum length the site allows.\nGrowing the haystack. Developed by security expert Steve Gibson, president of California-based Gibson Research, growing the haystack takes advantage of the ways hackers crack passwords. “The first thing they’ll try is the well-known dictionary of most common passwords,” Gibson says. “Then, if they know something about you, they will try to guess things from your life.”\nTo foil that part of the process, Gibson suggests starting with a phrase that’s short but not a common word. That forces the hacker to resort to the slower brute-force approach by trying every combination in existence, which is like looking for a needle in a haystack.\nOnce you’ve accomplished that, “the length of the password matters more than its absolute complexity,” Gibson says. In other words, make the haystack larger by padding the password with numerous easy-to-remember symbols. For example, the password “c - @T - - 9 - - -” is 10 characters long and is probably not in any dictionary, but it’s not very hard to remember.\nA caveat: Don’t use any of the above examples as actual passwords. Now that they have been widely published, hackers might add them to their dictionaries.\nCopyrighted 2011, Consumers Union of U.S., Inc. All Rights Reserved.\nConsumer Reports has no relationship with any advertisers on Yahoo!", "label": 1}
{"text": "This article can also be found in the Premium Editorial Download \"Information Security magazine: With SSL VPNs on the offense, will IPSec VPNs eventually be benched?.\"\nDownload it now to read this article plus other related content.\nInsecure RPCs can leave you wide open. Take steps to protect your network.\nRemote Procedure Calls (RPCs) are at the heart of client/server computing, from Windows to *nix, allowing networked devices to seamlessly call services and components from one another. They're also the source of numerous vulnerabilities and exploits.\nRPC is ubiquitous, and that's the dilemma: You can't simply turn it off. That said, you're not without security options. RPC isn't inherently insecure: Developers can write secure code using RPC, and there are alternatives. You can defend your networks against known RPC exploits.\nSince almost every system runs RPC services, it's an obvious target.\nRPC reduces the complexity of network programming by handling communication over UDP. The programmer writes client/server code with identical parameters and leaves the networking to the protocol, allowing the protocol to span multiple OSes and networks.\nMost RPC vulnerabilities are simply the result of sloppy coding. Poor error-checking leaves an app open to buffer-overflow exploits.\nThe consequences are familiar. In 2003, flaws in the RPC interface with DCOM opened Windows 2000/XP/2003 to buffer-overflow exploits and re-sulted in the LoveSan and Blaster worms.\nLinux had a similar vulnerability in its rpc.statd and glibc libraries, which led to the Ramen worm in 2000 and the Lion and Adore worms in 2001.\nFor the Defense\nFaulty code isn't likely to go away. Given this fact of life, rigorously apply these defensive strategies:\nPatch, patch, patch. Exploits continue to be created, and unpatched systems are the easiest to compromise.\nDeploy application firewalls. Traditional layer 3 and 4 firewalls are ineffective against RPC exploits because RPCs don't use a specific port. They use a port mapper--usually running on port 135 on Windows and port 111 on Unix--to tell the client program which port RPC is running. Blocking ports 135 and 111 would deny all RPC traffic, while blocking all UDP traffic would disable DNS. Firewalls that filter layer 7 traffic can detect application-based attacks, such as RPC exploits.\nDetect and prevent. Blocking suspicious traffic at the firewall isn't always possible. Craft custom IDS signatures that can trap these anomalous packets; the trick is to analyze them and look for their uniqueness. Be precise with the syntax so legitimate traffic doesn't trigger a false alarm.\nYour signatures need to be updated in a timely manner. You may have used an application for months or years without incident, but new vulnerabilities come to light all the time.\nIf Internet-facing apps are your company's lifeblood, invest in services to bulletproof your code.\nAlternatives to RPC are complex and require significant investment of time and resources:\nRPC over HTTPS forces authentication and \"hides\" RPC within a tunneling mechanism.\nObject Request Broker (ORB) is middleware that manages communication and data exchange be-tween distributed objects from different vendors. It's more secure than RPC because object communication details are hidden.\nMessage-Oriented Middleware (MOM) is a client/server infrastructure that allows applications to be distributed across heterogeneous platforms. It simplifies development by insulating the application developer from the details of the various OS and network interfaces. Application programming interfaces that extend across diverse platforms and networks are typically provided by the MOM.\nThis was first published in May 2005", "label": 1}
{"text": "Because our forum is being polluted with bad information.\nMyth #1: When you hash something, you get a unique result that no other file or string or password can have.\nWroonnnnggggg. Let's attack this one with simple logic. Let's say your hash is 32 characters long. Now let's say you hash every possible 33-character string there is. You will have strings with matching hashes, or \"collisions\". It's simple logic -- there are far more combinations of 33-character strings than there are of 32-character strings, because for every 32-character string that exists, you can tack on every possible character to the end and make a bunch of 33-character strings. So, just making up some example numbers, if there are 90,000 33-character strings and 20,000 32-character strings, some of those 33'ers MUST have the exactly the same 32-character hash. The goal of hashing algorithms is to make collisions as rare as possible, but it is impossible to write to a hashing algorithm that has no collisions.\nMyth #2: MD5 is insecure.\nWroonnnnggggg. MD5 is a less sophisticated (and therefore much faster) hashing algorithm than, say, SHA-256, but it is not insecure. An insecure hash would mean that the hash could be reversed -- or rather, that you could take a hash, and, using that and having no other information, produce a string that has the same hash. You cannot do that with MD5. In fact, the closest anyone has gotten to this is changing an existing, large file in a way that doesn't change the hash it already has. No one in the history of humankind has been able to produce a \"reverse\" MD5. This myth comes from the fact that MD5 is a common target of password-cracking attacks, which leads to our next myth...\nMyth #3: MD5 is less secure for password hashing than other algorithms like SHA.\nWroonnnnggggg. There are exactly three attacks that can be used to find out someone's password if you have the hash of that password:\n- Hash database lookup. You go to a super-large online database of short words and their hashes, plug in the hash, and see if a short word with that hash has ever been submitted before. A common prevention for this is to salt your passwords.\n- Brute force. You run through all the words of a dictionary, hashing each one, to see if the hash matches what you have on hand. If that doesn't work, you just start hashing every possible combination of 5, 6, 7, or 8-character words to find a match. This takes for effing ever and rarely produces a result, and can easily be prevented with a salt.\n- Rainbow tables. This is a method of hashing and re-hashing the data you have to find similarities in the hashes of other words, which can eventually lead to finding the password. Salts have minimal effect on these attacks.\nMyth #4: Sophisticated, super-long hashes like SHA-256 are harder to attack because they're longer.\nWroonnnnggggg. Let's face it: the biggest threat to hash cracking attacks is the rainbow tables method. It is by far the most efficient tradeoff between processing time and storage space, and often times can find a password in under a minute if you have enough chains. But rainbow tables are not magical. That's the impression most people have because it's easier to believe that than to learn how they work, but seriously, the rainbow table attack isn't hard to understand. I suggest reading up on it if you have a spare 15 minutes.\nSo if you know how rainbow tables work, you know that the biggest weakness they have is hash collisions -- which, you'll remember from above, means more than one string that produces the same hash. So password hashing security is a tradeoff: You want an algorithm that has reasonably few collisions so that no two passwords are likely to generate the same hash, but you also want one that produces enough collisions to potentially send a rainbow table into an endless loop that can't be cracked. SHA-256 is horrible for this, because it's too good a hashing algorithm. You're extremely unlikely to get any collisions at all when using SHA-256 for a password (even a salted one), so using that makes your passwords -- salted or not -- easier to crack. SHA-256 is awesome for hashing large files. Not so awesome for passwords.\nAt the same time, though, you don't want to use a measly 32 or 48-bit hash, because collisions are extremely likely with those. You want to find a happy medium, which is around 128 bits. What's a fast 128-bit hashing algorithm? MD5.\nMyth #5: SHA-1 is still better to use than MD5 because MD5 is more likely to be cracked.\nWroonnnnggggg. Again, you're being lulled into a false sense of security. Not only is SHA-1 160 bits (so you'll still get collisions, but fewer than MD5), hash databases and rainbow tables are just as easy and well-developed for SHA-1 as they are for MD5. This myth is one that is spread far and wide among developers who have never taken the time to research the facts. The fact that SHA produces a longer hash has little-to-no impact on the ability to store them in a database or produce rainbow chains with them. All it takes is a tiny bit more storage space, and that's true for any hashing algorithm in the world, whether it's 8 bits or 8 thousand bits. The length only helps for reducing collisions, which, past around 128 bits, doesn't help at all when you're hashing passwords rather than large files.\nMyth #6: Hashing with multiple algorithms is more secure!\nWroonnnnggggg. No. Just no. Come on, now you're just pulling stuff out of your ass. I've seen this before: sha1(md5(\"Password\")). That is ridiculous. You're feeding 128 bits into 160 bits, which is an easy easy crack. You can't make hashes more-hashy. You might add one more step to the process for someone cracking it, but it's going to end up with the same result. Don't guess at what's more secure, know what's more secure.\nMyth #7: Using a global salt AND a user salt is more secure than using just a user salt.\nThere was a thread recently in which folks supported the idea of using a global salt in addition to a user salt, and I dismissed it as pointless. I was met with some fierce opposition, claiming that it makes passwords more secure if a hacker should be able to steal a copy of your database but not your source code. This is true, however the amount of extra security this offers is minimal at best. Here's why:\nOut of our list of attacks on hashes that I wrote out earlier, there is only one attack that's made more difficult to crack by using a global salt, and that's the brute force attack -- the one that's already almost impossible to use successfully to begin with. Adding a global salt only makes this more-impossible-than-nearly-impossible. So I'll admit there is SOME benefit, but with the most common and most successful attack being rainbow tables, folks would be crazy to try a brute force attack anyway. They'd just rainbow table it, and the global salt won't make your password any more secure than a properly long user salt would. And hey, let's face it: If someone's able to steal a copy of your database, chances are that they can nab a copy of your source without too much trouble too.\nIf you're looking to protect against the case where someone gets a copy of your database, a far, far, far more effective solution would be to use symmetric encryption on your hashes. Choose a fast, simple symmetric encryption algorithm (RC4, Blowfish... your call), generate a key and store it somewhere in a configuration file. Use that to encrypt all your salted password hashes in the database. Then, when you pull them from the database, just decrypt them with that key when you read them. Now you have a hash that can't even be attacked with a rainbow table if someone happens to gain unauthorized access to either your database or your account on the server, and this is still effective if you distribute your software to the public. MUCH more effective than using a global salt.\nSo what are the best practices for password hashing?\nThe only two, good options for password hashing are MD5 and SHA-1, and you should let the language you're programming in dictate which one you use. For PHP (and most languages), MD5 is faster than SHA-1, so it's the better option. The key to making it secure is using a salt of the appropriate length. The sweet spot for securely storing a password that isn't susceptible to dictionary or brute force attacks AND is relatively safe from rainbow table attacks is to feed twice the number of bits of a hash into a new hash. So, for example, using MD5, you'd want to hash two MD5s. You can generate a 128-bit salt for this (which, for a lot of users, can take up some significant storage space), or you can generate a salt that's just a handful of characters long and hash that. My favorite method is this:\n$finalHash = md5(md5($salt) . md5($password))\nWhether you want to put the symmetric encryption layer on top of that is entirely up to you\nSo please, for the love of all that is holy, stop teaching these myths to other people! The world's programmers thank you :D", "label": 1}
{"text": "A perennial issue in Canadian privacy law is what to do about the USA Patriot Act. Just when we think we have things reasonably sorted out, the issues pop up again in a new context. This time it is cloud computing.\nWhat’s the USA Patriot Act?\nThe Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act (usually referred to as the “USA Patriot Act” or just the “Patriot Act”) is US legislation that was passed following the September 11, 2001 attacks on the World Trade Centre in New York City. Among other things, the Patriot Act made it easier for US law enforcement officials to intercept electronic communications and business records. One of the controversial measures was that officials were granted the power to issue a National Security Letter to electronic communication service providers requiring them to hand over information without informing the affected parties (in some cases without any judicial oversight).\nFor the purposes of this discussion of cloud computing, however, one of the most important provisions is section 215, which deals with access to business records. Section 215 repealed and re-enacted provisions of the Foreign Intelligence Surveillance Act (USA). Pursuant to section 215 of the Patriot Act, the FBI may apply to a federal judge for an order requiring the production of any tangible things (including books, records, papers, documents, and other items) for an investigation to protect against international terrorism or clandestine intelligence activities. US commentators agree that this definition covers electronic business records.\nWhat’s cloud computing?\nIn its most complete form, cloud computing involves outsourcing applications (e.g. email, customer relationship management, and accounting software), platforms (e.g. database architecture) and infrastructure (e.g. servers). All of these IT functions are offered as a service to organizations either independently or as a package. An organization’s data (e.g. its emails) may be stored in segregated servers or intermingled with the data of other organizations and segregated through the functionality of the service provider’s information technology. The organization accesses its data through Internet portals.\nWhere’s the Cloud?\nThe cloud isn’t in the sky. Data sent over the Internet in a cloud computing arrangement may be (and often will be) stored outside of Canada and may be intermingled with data from other organizations. In many cases, the cloud computing service provider may subcontract the storage of data to one or more organizations operating data centres. If these data centres are in the US, well, therein lies the rub. The data is going to be subject to the laws of the United States, including the Patriot Act. Actually, if the data is even accessible from the US or by an organization subject to the jurisdiction of the US, the data is likely to be subject to the laws of the United States.\nOkay, so the USA Patriot Act may apply, do I have a Canadian privacy problem?\nBut organizations aren’t prohibited from using US-based cloud services, if they are only operating in the private sector. Federal and provincial private sector privacy legislation does not prohibit the transfer of personal information to an organization in another jurisdiction for processing and storage, provided that:\n- The transfer does not entitle the receiving the personal information to use that information for purposes other than those for which individuals expressly or impliedly consented.\n- The transferring organization remains accountable for the protection of the personal information that has been transferred.\n- The organization receiving the personal information provides a comparable level of data security as would be required under Canadian law and the terms on which the collecting organization collected the information.\n- Disclosure is made to individuals. As a general rule, this disclosure to individuals should include notice that (1) their personal information will be transferred outside of Canada for processing and storage, (2) their personal information will be subject to the laws of the foreign jurisdiction and (3) the laws of the foreign jurisdiction may be different (and less protective) than those of Canada.\nThe transferring organizations will wish to consider obtaining meaningful contractual commitments to administrative, technological and physical security protections from the organization to which the personal information is being transferred. The transferring organizations will also wish to consider audit or other rights that would permit ongoing diligence of these security protections as well as the use being made of the personal information.\nThe Patriot Act provisions do not (on their own) mean that personal information will not be subject to a comparable level of security. An interesting survey and comparison of surveillance laws in Canada, the US, the UK and France was conducted by the Office of the Privacy Commissioner of Canada in 2009, which remains an important reference. Since 1990, Canada and the US have had Treaty on Mutual Legal Assistance in Criminal Matters in which each country has agreed to assist the other with the investigation, including seizure of records, of criminal activity. The Canadian Security and Intelligence Service Act (Canada) provides for secret warrants for the interception and seizure of, among other things, electronic data. The National Defence Act (Canada) permits the Minister of Defence (without judicial supervision) to authorize the Canadian Communications Security Establishment to intercept communications relating to foreign entities under certain circumstances. In addition, the Criminal Code (Canada) permits seizures of electronic data. The combination of this legislation has led the Office of the Privacy Commissioner of Canada to conclude in three decisions (here , here, and here) not only that Canadians are at risk of personal information being seized by Canadian governmental authorities (including without the knowledge of the target) but also that there is already a risk of that information being shared with US authorities. (This is not to say that reasonable people cannot still differ as to whether they wish to have their personal information stored outside of Canada.)\nBut if you are a public sector organization or contracting with a public sector organization in British Columbia or Nova Scotia (and probably Alberta), you need legal advice. Cloud-based services get a bit trickier when dealing with public sector organizations. British Columbia, Nova Scotia and Alberta each have legislation the prohibits or, in the case of Alberta, potentially prohibits the storage of data outside of Canada. In these cases, organizations would be prudent to obtain legal advice.", "label": 1}
{"text": "At the recent Chaos Communications Congress, Steven J. Murdoch, a researcher in the security group at the University of Cambridge, discussed how clock skew can be used to facilitate a digital attack against anonymity networks. Clock skew, the tendency for a computer’s clock to become less precise when heated, can reduce the efficacy of anonymizers, such as the Electronic Frontier Foundation’s Tor network.\nMurdoch explains, “When a crystal is manufactured, it has a clock skew, and it’s different for each crystal (throughout its) lifetime.” Tadayoshi Kohno, now an assistant professor in the Department of Computer Science and Engineering at the University of Washington, has shown that computers on the internet can be identified by their clock skews, by tracking the timestamps of each machine’s transmitted packets. Clock skew, however, yields up to only 64 separate identifiers, making it an incomplete confirmation tool.\nClock skew has long been a concern of engineers of synchronous network, as it causes the clock signal for system components to arrive at different times; however, Murdoch is the first to take advantage of this hardware fallibility. Murdoch attacked The Onion Router, Tor, an anonymizing network that allows unregistered users to access web sites without identifying themselves. Tor network encrypts web traffic, through multiple servers, creating layers of anonymizing packets, none of which may be decrypted by another node on the Tor network.\nMurdoch tested his digital attack by setting up a Tor network server and causing the server to warm up by executing intensive processes. The increase in system temperature caused minor changes in clock skew.\nTo understand how clock skew can be used to affect the security of anonymity networks, such as Tor, I think that we must first understand how Tor works. I suggest reviewing the audio recording or transcript of Steve Gibson and Leo Laporte’s Security Now! podcast. Episode 70 of this podcast explains in clear, lucid detail how the Tor network creates anonymity for web users.\nKohno’s theoretical work and Murdoch’s proof of concept attack does not bode well for network security systems, including the GPS and other national digital assets that require precise timings to function properly.\nCall for Comments\nWhat do you think? Leave your comments below.", "label": 1}
{"text": "Cell phones have come a long way in the last twenty years. Zach Morris’ brick from Saved By The Bell was a strictly utilitarian device, built for no reason other than making and answering phone calls. Today’s iPhones and Droids, by contrast, are full-fledged computers, capable of virtually anything a laptop or desktop PC can do. In many ways this is a step forward, but our phones now also share one bad similarity with our computers: exposure to security risks.\nHere are some of the most serious to watch out for:\nPhishing has been a major security threat to laptop and desktop users for at least the last decade. It typically works in the following manner: you receive an official-looking email from someone claiming to represent a major, well-known institution (such as the bank you use.) In this email, you are asked to provide your account information for a “security check” or other seemingly legitimate reason. You may even be directed to a website that looks very much like the real thing. Unfortunately, the entire process was nothing more than a cleverly crafted ruse designed to trick you into giving scammers your account details.\nThese same scams are now targeting mobile phone users as well. A 2010 article in the Wall Street Journal said that “the next generation of “phishing” scams, focused on mobile banking, has begun, and it has the potential to do much more damage than earlier versions.” Rather than tricking you into visiting a fraudulent website, scammers are now populating the web with fraudulent banking apps that carry out the same purpose.\nEvery few years, a worm virus slithers its way onto millions of computers around the world, inflicting financial damage and whipping the tech world into a panic until it finally dies out. Melissa, SoBig, ILoveYou and MSBlast were some of the bigger culprits of the last decade. Our phones have long been immune to these gigantic hassles but no longer. Inc.com tells the story of one nasty mobile worm that hit Asia and parts of the U.S as well:\n“The Sexy View worm, so dubbed because it sends a text inviting users to look at sexy pictures, targets some Nokia phones. If a hapless user tries to look at the pictures, it will take over the phone much the way a botnet takes over a computer, and then send itself to the entire contact list.”\nCloudmark CTO told Inc.com that it’s only a matter of time before mobile worms such as these become the widespread norm in the United States. “They [smartphones] can have a 1 gigahertz processor and hundreds of megabytes of RAM. So all the same types of attacks that could happen to a computer can happen to a smart phone.”\nMany of today’s smartphones have built-in GPS capabilities, allowing users to transmit their exact geographic coordinates to anyone they wish. Though this is certainly a handy feature to have, it carries the potential for misuse. Last February, ScienceDaily.com reported that because smartphones “run the same class of operating systems as desktop and laptop computers” all sorts of abuses are now possible – including GPS hijacking that lets unscrupulous people track the travels of a phone’s owner.\nToday, the web is filled with mobile apps that let you secretively “keep track of your untrustworthy boyfriend” or “always know where your wife is.” These same tools (and others) can just as easily be used by criminals or hackers.\nUnknown Privacy Settings\nThere is also a substantial security risk connected with not being aware of your phone’s privacy settings. Take Facebook’s iPhone app, for instance. Unbeknownst to many iPhone owners, this app will broadcast your exact location unless you deliberately turn that feature off. The same is true of any number of other apps, including FourSquare and AroundMe. True, this is not necessarily a risk in and of itself – but it could be. Someone determined to intercept data transmissions from your phone could very easily determine where you are if these features are left on.\nThat’s why it’s imperative for mobile phone users to be fully aware of location-based services and the risks they pose.\nIn 1999, having your cell phone stolen was an annoying inconvenience, but hardly a security risk. After all, what was the thief really getting his hands on: your contact list and (maybe) a few personal text messages? Surely nothing to be concerned about. Today, the theft of your mobile phone could be downright catastrophic. Depending on which apps you use, the thief could now have total, unrestricted access to your emails, bank accounts and investment portfolio.\nIn short, you could be in for a whole world of trouble. Luckily, most of these risks can be prevented. As Inc.com explains, the simple act of setting an access code on your phone that wipes your data after a certain number of wrong tries goes a long way.\n“SMS Of Death”\nOn December 30, 2010, CNN Tech discussed another serious mobile security risk: the “SMS of Death” Here’s how it works:\n“…many popular feature phones operating on GSM networks (the world’s most popular mobile network standard) are vulnerable to remote-controlled disabling or damage via the “SMS of Death.” This is according to a presentation by German researchers at this week’s Chaos Computer Club Congress in Berlin.”\nIn short, your entire SIM card can be corrupted just by receiving an SMS text message with a “damaging payload” in it. When this happens, your phone gets completely disconnected from the network. Worst of all, this particular security threat mostly targets lower-end phones, not the expensive smartphones. Researchers at the German conference “performed their tricks on handsets made by Nokia, LG, Samsung, Motorola, Sony Ericsson, and Micromax, a popular Indian cell-phone manufacturer” according to TechnologyReview.com.", "label": 1}
{"text": "Do not give sensitive information to anyone unless you are sure that they are indeed who they claim to be and that they should have access to the information.\nWhat is a social engineering attack?\nIn a social engineering attack, an attacker uses human interaction (social skills) to obtain or compromise information about an organization or its computer systems. An attacker may seem unassuming and respectable, possibly claiming to be a new employee, repair person, or researcher and even offering credentials to support that identity. However, by asking questions, he or she may be able to piece together enough information to infiltrate an organization's network. If an attacker is not able to gather enough information from one source, he or she may contact another source within the same organization and rely on the information from the first source to add to his or her credibility.\nWhat is a phishing attack?\nPhishing is a form of social engineering. Phishing attacks use email or malicious websites to solicit personal information by posing as a trustworthy organization. For example, an attacker may send email seemingly from a reputable credit card company or financial institution that requests account information, often suggesting that there is a problem. When users respond with the requested information, attackers can use it to gain access to the accounts.\nPhishing attacks may also appear to come from other types of organizations, such as charities. Attackers often take advantage of current events and certain times of the year, such as\n- natural disasters (e.g., Hurricane Katrina, Indonesian tsunami)\n- epidemics and health scares (e.g., H1N1)\n- economic concerns (e.g., IRS scams)\n- major political elections\nHow do you avoid being a victim?\n- Be suspicious of unsolicited phone calls, visits, or email messages from individuals asking about employees or other internal information. If an unknown individual claims to be from a legitimate organization, try to verify his or her identity directly with the company.\n- Do not provide personal information or information about your organization, including its structure or networks, unless you are certain of a person's authority to have the information.\n- Do not reveal personal or financial information in email, and do not respond to email solicitations for this information. This includes following links sent in email.\n- Don't send sensitive information over the Internet before checking a website's security (see Protecting Your Privacyfor more information).\n- Pay attention to the URL of a website. Malicious websites may look identical to a legitimate site, but the URL may use a variation in spelling or a different domain (e.g., .com vs. .net).\n- If you are unsure whether an email request is legitimate, try to verify it by contacting the company directly. Do not use contact information provided on a website connected to the request; instead, check previous statements for contact information. Information about known phishing attacks is also available online from groups such as the Anti-Phishing Working Group (http://www.antiphishing.org).\n- Install and maintain anti-virus software, firewalls, and email filters to reduce some of this traffic (see Understanding Firewalls, Understanding Anti-Virus Software, and Reducing Spam for more information).\n- Take advantage of any anti-phishing features offered by your email client and web browser.\nWhat do you do if you think you are a victim?\n- If you believe you might have revealed sensitive information about your organization, report it to the appropriate people within the organization, including network administrators. They can be alert for any suspicious or unusual activity.\n- If you believe your financial accounts may be compromised, contact your financial institution immediately and close any accounts that may have been compromised. Watch for any unexplainable charges to your account.\n- Immediately change any passwords you might have revealed. If you used the same password for multiple resources, make sure to change it for each account, and do not use that password in the future.\n- Watch for other signs of identity theft (see Preventing and Responding to Identity Theft for more information).\n- Consider reporting the attack to the police, and file a report with the Federal Trade Commission (http://www.ftc.gov/).\nAuthor: Mindi McDowell", "label": 1}
{"text": "- Use WinDbg for kernel debugging\n- Understand basic inner working of disk driver\n- Understand virtual hidden drive creation\n- Reverse engineering Max++ driver infection technique\n- Operating Systems\n- Assembly Language\n- Operating System Security\nThis tutorial continues the analysis presented in Tutorial 20. We reveal how Max++ uses a modified disk driver to handle I/O requests on the disk it created (its name is \"\\\\?\\C2CAD...\"). Recall that in section 4.2.3 we showed you Max++ creates a new IO device and hooks it to the malicious driver object, so that whenever an IO request is raised on this device the request will be forwarded to driver object 8112d550, as shown below. Pay attention to the value of MajorFunction (0xfae36bde), this is where IO requests are handled. Obtaining the module base address, we can easily calculate its offset: _+2BDE.\nkd> dt _DRIVER_OBJECT 8112d550\n+0x000 Type : 0n4\n+0x02c DriverInit : 0xfae4772b long +0\n+0x030 DriverStartIo : (null)\n+0x034 DriverUnload : (null)\n+0x038 MajorFunction :  0xfae56bde long +0\nTo replicate the experiments of this tutorial, you have to follow the instructions in Section 2 of Tutorial 20. In this tutorial, we perform analysis on the code of raspppoe.sys from _+2BDE (0x10002BDE)\n2. Lab Configuration\nIn general we will use the instructions of Section 2 of Tutorial 20. In the following we just remind you of several important steps in the configuration:\n(1) You need a separate image named \"Win_Notes\" to record and comment the code. You don't really need to run the malware on this instance, but just to record all your observations using the .udd file. To do this, you have to modify the control flow of IMM so that it does not crash on .sys files. See Section 2 of Tutorial 20 for details. Jump to 0x10002BDE to start the analysis.\n(2) The second \"Win_DEBUG\" image has to be run in the DEBUG mode and there should be a WinDbg hooked from the host system using COM part -- so here, we are doing kernel debugging.\n(3) Set a breakpoint \"bu _+2BDE\" in WinDbg to intercept the driver entry function.\n3. Background: Windows Driver Development\nOpferman provides an excellent introduction and sample code in . In the following, we summarize of the major points here.\n(1) Each driver has a driver entry function, its prototype is shown below:\nNTSTATUS DriverEntry(PDRIVER_OBJECT pDrv, PUNICODE_STRING reg)\nHere pDrv is a pointer to _DRIVER_OBJECT, and reg is a string that represents the registry entry where the driver could store information.\nAs we shown earlier in Tutorial 20, the DriverEntry function is located at _+372b.\n(2) Each driver may have a collection of 28 functions to handle different types of I/O requests (such as close handle, read, write etc.) The IRP Function code can be found at  (typical ones are IRP_MR_CREATE and IRP_MR_READ).\nYou might wonder, do we have to set breakpoints on all of the 28 functions? The answer is YES and NO. Look at the following dump (combined with the dump in section 1).\nkd> dd 8112d550\n8112d550 00a80004 81210030 00000002 fae54000\n8112d560 00008000 ffbd7d80 8112d5f8 001a001a\n8112d570 e1389208 8068fa90 00000000 fae5772b\n8112d580 00000000 00000000 fae56bde fae56bde\n8112d590 fae56bde fae56bde fae56bde fae56bde\n8112d5a0 fae56bde fae56bde fae56bde fae56bde\n8112d5b0 fae56bde fae56bde fae56bde fae56bde\n8112d5c0 fae56bde fae56bde fae56bde fae56bde\nAt offset 0x38 of the driver object (the starting of the major function array), all IRP handlers are set to one single function _+2BDE! The malware author tries to be lazy here, and it saves us a lot of job too. We can just concentrate on _+2BDE then!\nNow before we move on, we should know that each IRP handler function has the following prototype:\nNTSTATUS Handler(PDEVICE_OBJECT pDevice, PIRP pIRP)\nHere, the first parameter is a device object, and the second parameter represents the IRP request to handle.\nWhen we hit the _+2BDE handler, we could easily find out the contents of the two input parameters (device located at 8112d550 and irp located at 00070000) as below:\nkd> dd esp\nfafb73fc 81210030 8112d550 00070000 81210030\nfafb740c fafb7460 804e37f7 81210030 ffbbe7e8\nfafb741c 00000000 fb07c7a9 81210030 c000014f\nfafb742c 00000000 00000000 c3a408e0 00000000\nfafb743c 00000001 00000000 804e2490 fa047501\nfafb744c 00000000 fafb7450 fafb7450 804fb1a9\nfafb745c 00000000 fafb748c fb07ce80 81210030\nfafb746c fafb7484 ffb6fe10 81210030 ffb6fe10\nkd> dt _DEVICE_OBJECT 8112d550\n+0x000 Type : 0n4\n+0x002 Size : 0xa8\n+0x004 ReferenceCount : 0n-2128543696\n+0x008 DriverObject : 0x00000002 _DRIVER_OBJECT\n+0x00c NextDevice : 0xfae54000 _DEVICE_OBJECT\nkd> dt _IRP 00070000\n+0x000 Type : 0n193\n+0x002 Size : 0\n+0x004 MdlAddress : 0x00000100 _MDL\n4. Anatomy of Infected Disk Driver\nFigure 1 shows you the first part of the IRP handler function at _+2BDE.\n|Figure 1. Infected Disk Driver|\nAs shown in Figure 1, the control flow is a very simple decision procedure. First it takes out the PDEVICE_OBJECT pointer from EBP+8 (1st parameter) and compare it with a global variable stored at 100061B0 (see highlighted area). Clearly, the global variables stores the newly created infected device (for \\??\\C2CAD...). If it is not a request to \\??\\C2CAD, the flow jumps to 10002BFD (second highlighted area), which calls PoCallDriver to relay the request to low level (real) drivers to do the work; otherwise it calls a self-defined function handleIRPForVirtualVolume which performs the real operation to simulate the virtual disk.\nChallenge 1. Analyze the logic between 10002BFD and 10002C25 (highlighted area in Figure 1). Especially, explain the instructions at 0x10002C16 and 0x10002C19.\n5. Simulating the Virtual Disk Operations\nNow we will analyze the function handleIRPForVirtualVolume. It is located at _+292A. In this case, you need to set a breakpoint using \"bp _+292A\" in WinDbg. Figure 2 shows its major function body. Notice that you can easily infer from the context that EBX is an input parameter of the function, EBX points to the IRP request right now!\n|Figure 2. Function body of handleIRPForVirtualVolum|\nNow comes the interesting part. Look at Figure 2, at 0x1000293C EAX now has the \"MajorFunction\" of _IO_STACK_LOCATION (the value is one of the IRP_MJ_xxx types). Then there is a big switch case statement (see the highlighted area in Figure 2), which redirects the control flow to handle each of the different IRP requests such as READ, WRITE, etc.\nChallenge 2. Argue that the statement about \"0x1000293C EAX now has the \"MajorFunction\" (the value is one of the IRP_MJ_xxx types\" is true. You may need to find out the definition of IRP_MJ_xyz values.\nAs an example of how Max++ simulates the disk volume operation, we show how it handles the IRP_MJ_READ request. Figure 3 shows the handler code.\n|Figure 3. Simulate the Disk Operation on File|\nkd> dt _IO_STACK_LOCATION ff9c7fd8\n+0x000 MajorFunction : 0x3 ''\n+0x001 MinorFunction : 0 ''\n+0x002 Flags : 0x2 ''\n+0x003 Control : 0 ''\n+0x004 Parameters : __unnamed\n+0x014 DeviceObject : 0xffb746d8 _DEVICE_OBJECT\n+0x018 FileObject : (null)\n+0x01c CompletionRoutine : (null)\n+0x020 Context : (null)\nNow look at the first instruction LEA EAX, [ESI-24] in Figure 3. The purpose here is to move 0x24 bytes away (note the direction of stack) and the size of _IO_STACK_LOCATION (0x24). So EAX is now pointing to a new _IO_STACK_LOCATION instance. The next couple of instructions copy the first 9 words of the existing _IO_STACK_LOCATION to the new.\nThen at 0x10002B10 (look at the highlighted area of Figure 3), it assigns the value of ECX (from global variable at DS:[1000614C]) to offset 0x18 of the new _IO_STACK_LOCATION. Notice that 0x18 is the FileObject attribute (see above dump of _IO_STACK_LOCATION!). The following is the dump of the File Object pointed by ECX:\nkd> dt _FILE_OBJECT 811b25d0\n+0x000 Type : 0n5\n+0x002 Size : 0n112\n+0x02c Flags : 0x40040\n+0x030 FileName : _UNICODE_STRING \"\\WINDOWS\\system32\\config\\yknueenf.sav\"\n+0x038 CurrentByteOffset : _LARGE_INTEGER 0x0\nNow it's pretty clear that the READ operation on the disk volume is actually achieved by CONSTRUCTING A NEW _IO_STACK_LOCATION task on the \"*.sav\" file created by Max++ earlier!\nThe last interesting point is at 0x10002B17: Max++ hooks up a function for the CompleteRoutine (offset 0x1c of _IO_STACK_LOCATION), the intention is pretty clear: the data stored on the *.sav file is encrypted, and Max++ now decodes it when reading it out.\nWe've finished a very challenging and interesting analysis of a portion of the infected disk driver. Now it's your job to finish the rest:\nChallenge 3. What happens when FormatEx operation is performed on the virtual disk volume?\nChallenge 4. Analyze all the other IRP_MJ_ operations supported by the infected disk driver (hint: this could take considerable efforts).\n T. Opferman, \"Driver Development Introduction Part I\", available at http://codeproject.com\n MSDN, \"IRP Function Code\", available at", "label": 1}
{"text": "Tuesday, January 26, 2010 at 10:00 AM\nWebmaster Level: All\nIf you allow users to publish content on your website, from leaving comments to creating user profiles, you’ll likely see spammers attempt to take advantage of these mechanisms to generate traffic to their own sites. Having this spammy content on your site isn't fun for anyone. Users may be subjected to annoying advertisements directing them to low-quality or dangerous sites containing scams or malware. And you as a webmaster may be hosting content that violates a search engine's quality guidelines, which can harm your site's standing in search results.\nThere are ways to handle this abuse, such as moderating comments and reviewing new user accounts, but there is often so much spam created that it can become impossible to keep up with. Spam can easily get to this unmanageable level because most spam isn’t created manually by a human spammer. Instead, spammers use computer programs called “bots” to automatically fill out web forms to create spam, and these bots can generate spam much faster than a human can review it.\nTo level the playing field, you can take steps to make sure that only humans can interact with potentially spammable features of your website. One way to determine which of your visitors are human is by using a CAPTCHA , which stands for \"completely automated public Turing test to tell computers and humans apart.\" A typical CAPTCHA contains an image of distorted letters which humans can read, but are not easily understood by computers. Here's an example:\nYou can easily take advantage of this technology on your own site by using reCAPTCHA, a free service owned by Google. One unique aspect of reCAPTCHA is that data collected from the service is used to improve the process of scanning text, such as from books or newspapers. By using reCAPTCHA, you're not only protecting your site from spammers; you're helping to digitize the world's books.\nLuis Von Ahn, one reCAPTCHA's co-founders, gives more details about how the service works in the video below:", "label": 1}
{"text": "By Mark Huffman\n— The Internet has become more sophisticated over the years and so have the threats to users. Today, hackers are doing more than sending out infected spam emails -- they're exploiting the system's vulnerabilities to threaten consumers.\nExperts at Georgia Tech -- the Georgia Tech Information Security Center (GTISC) and the Georgia Tech Research Institute (GTRI) -- constantly work to stay one step ahead of the hackers. They say the coming year will pose some steep challenges.\nHere are some threats they say consumers should be aware of:\nThe ability to create vast, virtual computing resources will further persuade cyber criminals to look for ways to co-opt cloud-based infrastructure for their own ends. For example, attackers can use stolen credit card information to purchase cloud computing resources and create dangerous clusters of temporary virtual attack systems.\nSearch history poisoning\nCyber criminals will continue to manipulate search engine algorithms and other automated mechanisms that control what information you see when you do a search. Moving beyond typical search-engine poisoning, researchers believe that manipulating users’ search histories may be a next step in ways that attackers use legitimate resources for illegitimate gains.\nMobile browser and mobile wallet vulnerabilities\nThis, unfortunately, may be a fertile growth area for scammers. While only a very small number of U.S. mobile devices show signs of infection, the explosive proliferation of smartphones will continue to tempt attackers in exploiting user and technology-based vulnerabilities, particularly with the browser function and digital wallet apps.\nUnfortunately, your anti-virus software may prove less effective against emerging threats. The developers of malicious software will employ various methods to hinder malware detection, such as hardening their software with techniques similar to those employed in Digital Rights Management (DRM), and exploiting the wealth of new interfaces and novel features on mobile devices.\n\"Our adversaries, whether motivated by monetary gain, political/social ideology or otherwise, know no boundaries, making cyber security a global issue,” said Bo Rotoloni, director of GTRI’s Cyber Technology and Information Security Laboratory. “Our best defense on the growing cyber warfront is found in cooperative education and awareness, best-of-breed tools and robust policy developed collaboratively by industry, academia and government.”\nThe bottom line, say the Georgia Tech experts, is users must keep their guard up in the coming year.\nStory provided by ConsumerAffairs.", "label": 1}
{"text": "New answers tagged authorization\nThe 802.1x protocol is built on multiple steps. The supplicant (entity who wants to connect) identify the Access point by its SSID as it would do for any wireless network. Be noted that 802.1x also work on traditional wired networks. For what we know, this can be any hardware that provides this SSID, it can be changed, maybe spoofed. When you are connected ...\nTop 50 recent answers are included", "label": 1}
{"text": "Unencrypted WAP means all traffic over the wireless link can be read by anyone.\nWith an encrypted WAP, all traffic is encrypted on the radio link, but anyone with access to the WAP's WAN port can read the traffic even without the encryption key. With the WAP's key, for WiFi, you can read all the traffic on the radio link.\nThe secure way to use a shared wireless AP is by using end-to-end encryption; your traffic is encrypted before it is sent over the radio link and is not decrypted until it arrives at the destination. So, even with the WAP key or access to the WAP's WAN port, end-to-end encrypted traffic is safe.\nA common way to gain end-to-end encryption is to use an encrypted VPN. The traffic using the VPN between your machine and the VPN endpoint is encrypted, and so safe.\nOne complication. A VPN can use a technique called split-tunneling, which means that traffic not destined for the network at the VPN's other side doesn't use the VPN. And traffic that doesn't use the VPN isn't encrypted by the VPN, so if you use split tunneling, traffic not addressed to the other end of the VPN is not protected by the VPN.", "label": 1}
{"text": "Installing an SSL / TLS certificate on Windows Server 2008\nIn order to secure web traffic, SSL (Secure Socket Layer) is generally used as a first line encryption defense (you know, it makes the little padlock icon on your browser). SSL is also known as TLS (Transport Layer Security) which is kind of its newer name. Normally you access a site by navigating your browser to some place like: http://www.devtoolshed.com\nThis kind of communication between your browser and the web server sends information \"in the clear\" meaning that an attacker can read this traffic and if there is anything private like a credit card number, this can also be seen by an attacker. The \"http\" in the browser URL informs you that it is NOT secured by SSL.\nTherefore when sensitive information needs to be passed between your browser and a web server, many times SSL is used to encrypt (basic make the traffic into gibberish characters) that only the server and the browser have the ability to decrypt (decryption turns the gibberish back into readable information). When running under SSL, instead of using the \"http\" in front of your browser address, you will use \"https\" (the \"s\" stands for \"secure\"). For example, the URL above would change to: https://www.devtoolshed.com\nHow SSL Works\nThe way SSL works is somewhat complicated but at a high level (admittedly, this has been GREATLY simplified to make it easy for non-technical readers to understand so don’t hold it against me if there are things here that are not exact), you can understand it this way. Most popular browsers including Internet Explorer and Firefox ship with a list of \"trusted root certificates\". These certificates are publicly available \"passwords\" that are digitally signed by a CA (Certificate Authority). These CA’s are companies that have been generally agreed upon to be trusted by the Internet community in general. They sell SSL certificates. Some of the names of popular CA’s you may have heard of include VeriSign, Thawte, Entrust, and GoDaddy.\nThe process to obtain a certificate generally follows these steps. You generate a long \"password\" on your server called a CSR (Certificate Signing Request). You send this CSR to the CA to digitally sign it for you. The CA sends back your CSR digitally signed by their trusted root certificate. This becomes your SSL certificate. You then install this SSL certificate into your server. The following is a step by step guide to installing the certificate in Internet Information Services (IIS) 7 and Windows Server 2008.\nInstalling an SSL Certificate on Windows Server 2008\nClick on the Start menu, go to Administrative Tools, and click on Internet Information Services (IIS) Manager.\nClick on the name of the server in the Connections column on the left. Double-click on Server Certificates.\nOn the right side, choose Create Certificate Request to start the process of generating your CSR for your certificate.\nIn the Request Certificate dialog, fill in all of the fields and click Next.\nWhat do all of these fields mean?\nCommon name: This is the full domain name that your certificate will be securing. Certificates are bound to a specific domain so when creating your request, you must specify which domain this certificate will be securing. NOTE: domains and sub-domains are different so if you had mydomain1.devtoolshed.com and mydomain2.devtoolshed.com, you would need to purchase a certificate for both. Just because they are both using the domain devtoolshed.com, each sub-domain is treated separately.\nOrganization: The exact name of your company or organization as filed with the Government. When the CA background checks your organization to issue the certificate, they will check that this name exactly matches your organization’s name. That means if you have \"inc\" or \"LLC\" on the end of your name, make sure to put that in as well.\nOrganizational Unit: This is the division or group for which this certificate is being requested by. Most CA’s do not check this field so it mostly informational.\nCity / Locality: The city where your company or organization is located.\nState / Province: the state, province, or region where your company or organization is located. If possible, use the full name of the place instead of its abbreviation.\nCountry / Region: The country where your company or organization is located. This can be abbreviated with the two-letter ISO country code.\nChoose the Cryptographic Service Provider (you can leave this as the default in most cases). Then choose a Bit Length of 2048 or higher. Then click Next.\nEnter a name of a .txt file that you want to generate the CSR to. The file will be created so it does not need to exist yet. Then click Finish.\nNow that you have this CSR, you can open the .txt file that you just generated to find your signing request code that you must send to your CA to get it digitally signed. Depending on your CA you will need to provide this as well as other information and once the request is complete and you’ve paid for your certificate, you will usually receive it via email or web link to download. Download your certificate and you are now ready to install it back to your server.\nIn IIS, make sure you are back on the Server Certificates icon (double-clicked like you did in the previous steps). On the right side will be a new link Complete Certificate Request. Click this link to start the process of installing your certificate.\nUse the … button to browse to the certificate you received from the CA. This certificate file may have a \".cer\" extension in some cases. If so, make sure to click the drop down on the file picker dialog and choose \"all files *\" so that it shows up in your file view. Choose this file and then enter a friendly name (this is just a name you want to show up in the IIS list so you can tell what this certificate is for). You can put whatever you want to help you remember this certificate in the Friendly Name. Then click OK.\nYou will now see your certificate listed as a new certificate available to use. You can configure your site now to use this certificate for SSL traffic. There is more information here about configuring certificates and other details for IIS 7:\n- ASP.NET Charting Control 3.5 fix for \"Error executing child request for ChartImg.axd\"\n- Explanation of Cross Domain and Client Access Policy files for Silverlight\n- C# Free Component to Generate PDF - Convert HTML to PDF\n- Using Stored Procedures in the Entity Framework with Scalar Return Values\n- C# Download File with Progress Bar\n- Launch URL in Default Browser using C#\n- thank you for sharing\n1 day 4 hours ago\n- Great explanation and more questions\n2 days 7 hours ago\n- Insertion of illegal Element:\n4 weeks 4 days ago\n- Insertion of illegal Element: 32\n4 weeks 5 days ago\n- re \"But, this will NOT work.\"\n5 weeks 5 days ago\n- Unable to cast COM object of t\n5 weeks 5 days ago\n- Saved my life\n5 weeks 6 days ago\n8 weeks 5 days ago\n- good article\n9 weeks 6 days ago\n- windows 2008 server backups\n11 weeks 5 days ago", "label": 1}
{"text": "Network Caching Technologies\nAlthough the volume of Web traffic on the Internet is staggering, a large percentage of that traffic is redundant-multiple users at any given site request much of the same content. This means that a significant percentage of the WAN infrastructure carries the identical content (and identical requests for it) day after day. Eliminating a significant amount of recurring telecommunications charges offers an enormous savings opportunity for enterprise and service provider customers.\nWeb caching performs the local storage of Web content to serve these redundant user requests more quickly, without sending the requests and the resulting content over the WAN.\nNetwork caching is the technique of keeping frequently accessed information in a location close to the requester. A Web cache stores Web pages and content on a storage device that is physically or logically closer to the user-closer and faster than a Web lookup. By reducing the amount of traffic on WAN links and on overburdened Web servers, caching provides significant benefits to ISPs, enterprise networks, and end users. There are two key benefits:\n- Cost savings due to WAN bandwidth reduction - ISPs can place cache engines at strategic points on their networks to improve response times and lower the bandwidth demand on their backbones. ISPs can station cache engines at strategic WAN access points to serve Web requests from a local disk rather than from distant or overrun Web servers.\n- In enterprise networks, the dramatic reduction in bandwidth usage due to Web caching allows a lower-bandwidth (lower-cost) WAN link to serve the same user base. Alternatively, the organization can add users or add more services that use the freed bandwidth on the existing WAN link.\n- Improved productivity for end users - The response of a local Web cache is often three times faster than the download time for the same content over the WAN. End users see dramatic improvements in response times, and the implementation is completely transparent to them.\nOther benefits include:\n- Secure access control and monitoring - The cache engine provides network administrators with a simple, secure method to enforce a site-wide access policy through URL filtering.\n- Operational logging - Network administrators can learn which URLs receive hits, how many requests per second the cache is serving, what percentage of URLs are served from the cache, and other related operational statistics.\nHow Web Caching Works\nWeb caching works as follows:\n- A user accesses a Web page.\n- The network analyzes the request, and based on certain parameters, transparently redirects it to a local network cache.\n- If the cache does not have the Web page, it will make its own Web request to the original Web server.\n- The original Web server delivers the content to the cache, which delivers the content to the client while saving the content in its local storage. That content is now cached.\n- Later, another user requests the same Web page, and the network analyzes this request, and based on certain parameters, transparently redirects it to the local network cache.\nInstead of sending the request over the Internet and Intranet, the network cache locally fulfills the request. This process accelerates the delivery of content.\nThe important task of ensuring that data is up-to-date is addressed in a variety of ways, depending on the design of the system.\nThe Benefits of Localizing Traffic Patterns\nImplementing caching technology localizes traffic patterns and addresses network traffic overload problems in the following ways:\n- Content is delivered to users at accelerated rates.\n- WAN bandwidth usage is optimized.\n- Administrators can more easily monitor traffic.\nThe first step in creating a network-integrated cache engine is to ensure that the network supports traffic localization, which can be achieved by enabling content routing technology at the system-level, and setting specific parameters to optimize network traffic. Cisco IOS ® Web Cache Communication Protocol (WCCP) is one example of content routing technology that can be set to support traffic localization. Once the right network foundation is in place, network caches are added into strategic points within the existing network. By pairing software and hardware, Cisco creates a network-integrated cache engine. Network-integrated caches have at least the following three properties:\n- Managed like networking equipment, resulting in minimized operational costs\n- Designed like high-density networking hardware, resulting in better physical integration into the network infrastructure as network extensions and minimizing costs associated with leasing rack space\n- Transparently inserted into the network, resulting in minimized deployment and operational costs and greater content availability\nExisting Caching Solutions\nThe three most common types of caches on the market today are proxy servers, standalone caches, and browser-based caches.\nProxy servers are software applications that run on general-purpose hardware and operating systems. A proxy server is placed on hardware that is physically between a client application, such as a Web browser, and a Web server. The proxy acts as a gatekeeper that receives all packets destined for the Web server and examines each packet to determine if it can fulfill the requests itself; if not, it makes its own request to the Web server. Proxy servers can also be used to filter requests, for example, to prevent its employees from accessing a specific set of Web sites.\nUnfortunately, proxy servers are not optimized for caching, and do not scale under heavy network loads. In addition, because the proxy is in the path of all user traffic, two problems arise: all traffic is slowed to allow the proxy to examine each packet, and failure of the proxy software or hardware causes all users to lose network access. Expensive hardware is required to compensate for the low software performance and the lack of scalability of proxy servers.\nProxies also require configuration of each user's browser-a costly and unscalable management task for service providers and large enterprises. In addition, proxy servers that are arranged in a hierarchical fashion form an additional overlay network, contradicting any plans to strategically converge disparate networks into a single, unified network.\nIn response to the shortcomings of proxy servers, some vendors have created standalone caches. These caching-focused software applications and appliances are designed to improve performance by enhancing the caching software and eliminating other slow aspects of proxy server implementations. While this is a step in the right direction, these standalone caches are not network integrated, resulting in higher costs of ownership and making them less desirable for wide-scale deployment.\nBrowser-Based Client Caching\nInternet browser applications allow an individual user to cache Web pages (that is, images and HTML text) on his or her local hard disk. A user can configure the amount of disk space devoted to caching.\nFigure: Cache configuration window to configure the amount of disk space devoted to caching in Netscape Navigator shows the cache configuration window for Netscape Navigator.\nThis setup is useful in cases where a user accesses a site more than once. The first time the user views a Web site, that content is saved as files in a subdirectory on that computer's hard disk. The next time the user points to this Web site, the browser gets the content from the cache without accessing the network. The user notices that the elements of the page--especially larger Web graphics such as buttons, icons, and images appear much more quickly than they did the first time the page was opened.\nThis method serves this user well, but does not benefit other users on the same network who might access the same Web sites. In Figure: Benefits gained by a single node using browser caching, the fact that User A has cached a popular page has no effect on the download time of this page for Users B and C.\nFigure: Benefits gained by a single node using browser caching\nWCCP Network Caching\n- In 1997, Cisco developed WCCP, a router-cache protocol that localizes network traffic and provides \"network-intelligent\" load distribution across multiple network caches for maximized download performance and content availability.\n- The cache component of the Cisco caching solution comprises network-integrated caching solutions-the Cisco Cache Engine 500 Series. They are network-integrated because they:\n- Provide network management capabilities already available on traditional Cisco networking gear (such as Cisco IOS CLI and RADIUS support), resulting in minimized management and operational costs.\n- Are inherently designed and implemented as caching-specific networking hardware, rather than being standalone server platforms adapted as caches. Thus, the high-density Cisco Cache Engines physically integrate better into the network infrastructure as network extensions transparently insert into existing network infrastructures and adapt to unusual network conditions, resulting in minimized deployment and operational costs and greater content availability.\nThe cache engine was designed from the ground up as a loosely coupled, multinode network system optimized to provide robust shared network caching. The cache engine solution comprises the Web Cache Control Protocol (a standard feature of Cisco IOS software) and one or more Cisco cache engines that store the data in the local network.\nThe Web Cache Control Protocol defines the communication between the cache engine and the router. Using the Web Cache Control Protocol, the router directs only Web requests to the cache engine (rather than to the intended server). The router also determines cache engine availability, and redirects requests to new cache engines as they are added to an installation.\nThe Cisco cache engine is a single-purpose network appliance that stores and retrieves content using highly optimized caching and retrieval algorithms. (See the Figure: Cisco cache engine connected to a Cisco IOS router)\nFigure: Cisco cache engine connected to a Cisco IOS router\nTransparent Network Caching\nA cache engine transparently caches as follows:\n- A user requests a Web page from a browser.\n- The WCCP-enabled router analyzes the request, and based on TCP port number, determines if it should transparently redirect it to a cache engine.\n- If a cache engine does not have the requested content, it sets up a separate TCP connection to the end server to retrieve the content. The content returns to, and is stored on, the cache engine.\n- The cache engine sends the content to the client. Upon subsequent requests for the same content, the cache engine transparently fulfills the requests from its local storage.\nA cache engine transparently caches as shown in Figure: Transparent Network Caching:\nFigure: Transparent Network Caching\nBecause the WCCP router redirects packets destined for Web servers to a cache engine, the cache engine operates transparently to clients. Clients do not need to configure their browsers to point to a specific proxy server. This is a compelling feature for ISPs and large enterprises, for whom uniform browser configuration is expensive and difficult to manage. In addition, the cache engine operation is transparent to the network-the router operates entirely in its normal role for nonredirected traffic.\nBecause a Cisco Cache Engine is transparent to the client and to network operation, customers can easily place cache engines in several network locations in a hierarchical fashion. For example, if an ISP deploys a Cache Engine 590 at its main point of access to the Internet, all of its points of presence (POPs) benefit (Figure: Hierarchical Implementation of Cache Engines (ISP)). Client requests hit the Cisco Cache Engine 590 and are fulfilled from its storage. To further improve service to clients, ISPs can deploy the Cache Engine 590 or 570 at each POP. Then, when a client accesses the Internet, the request is first redirected to the POP cache. If the POP cache is unable to fulfill the request from local storage, it makes a normal Web request to the end server. Upstream, this request is redirected to the Cisco Cache Engine 590 at the main Internet access point. If the request is fulfilled by the Cisco Cache Engine 590, traffic on the main Internet access link is avoided, the origin Web servers experience lower demand, and the client experiences better network response times.\nFigure: Hierarchical Implementation of Cache Engines (ISP)\nEnterprise networks can apply this hierarchical-transparent architecture to benefit in the same way as shown in Figure: Hierarchical Implementation of Cache Engines (Enterprise):\nFigure: Hierarchical Implementation of Cache Engines (Enterprise)\nThe Cisco caching solution was designed to enable network administrators to easily cluster cache engines to scale high traffic loads. This design approach allows customers to linearly scale performance and cache storage as cache engines are added. For example, a single Cisco Cache Engine 590 can support a 45-Mbps WAN link and 144 GB of cache storage; adding a second Cisco Cache Engine 590 provides support for a 90-Mbps WAN link and 288 GB of cache storage. Up to 32 cache engines can be clustered together.\nThis linear scalability is achieved because of the manner in which WCCP-enabled routers redirect traffic to cache engines. WCCP-enabled routers perform a hashing function on the incoming request's destination IP address, mapping the request into one of 256 discrete buckets. Statistically, this hashing function distributes incoming requests evenly across all buckets. In addition, these buckets are evenly allocated among all cache engines in a cluster. WCCP-enabled routers ensure that a certain cache engine deterministically fulfills requests for a certain destination IP address on the Internet. Empirically, this distribution algorithm has consistently demonstrated even load distribution across a cache engine cluster. Most of the popular Web sites have multiple IP addresses, thus preventing uneven load distribution.\nWhen the customer adds a new cache engine to the cluster, the WCCP-enabled router detects the presence of the new cache engine and reallocates the 256 buckets to accommodate the additional cache engine. For example, the simplest installation using one router and one cache engine assigns all 256 buckets to the single cache engine. If a customer adds another cache engine, the WCCP-enabled router redirects packets to the two cache engines evenly-128 buckets are allocated to each cache engine. If the customer adds a third cache engine, the WCCP-enabled router assigns 85 or 86 buckets to each of the three cache engines.\nCustomers can hot-insert cache engines into a fully operating cache cluster. In this situation, the WCCP-enabled router automatically reallocates the buckets evenly among all cache cluster members, including the new cache engine. Because a new cache engine will not have any content, it will incur frequent cache misses until enough content has been populated in its local storage. To alleviate this cold startup problem, the new cache engine, for an initial period, sends a message to the other cache cluster members to see if they have the requested content. If they have the content, they will send it to the new cache engine. Once the new cache engine determines it has retrieved enough content from its peers (based on configurable numbers), it will handle cache misses by directly requesting the content from the end server rather than from its peers.\nFault Tolerance and Fail Safety\nIf any cache engine in a cache cluster fails, the cluster automatically heals itself. The WCCP-enabled router redistributes the failed cache engine's load evenly among the remaining cache engines. The cache cluster continues operation using one less cache engine, but operation is otherwise unaffected.\nThe Cisco network caching solution enables an WCCP-enabled, Multigroup Hot-Standby Router Protocol (MHSRP) router pair to share a cache engine cluster, creating a fully redundant caching system. This is referred to as WCCP multihoming. If the WCCP-enabled router fails, existing Cisco IOS fault tolerance and fail-safe mechanisms are applied. For example, a hot-standby router could dynamically take over operations, redirecting Web requests to the cache cluster.\nIf an entire cache cluster fails, the WCCP-enabled router automatically stops redirecting traffic to the cache cluster, sending clients' Web requests to the actual destination Web site in the traditional fashion. This loss of the entire cache cluster can appear to users as an increase in download time for Web content, but has no other significant effect. This designed-in, failsafe response is made possible because the cache cluster is not directly in line with clients' other network traffic.\nWCCP Multihome Router Support\nAs previously mentioned, the Cisco network caching solution enables a cache engine cluster to home to multiple WCCP-enabled routers for added redundancy. Thus, Web traffic from all of the WCCP home routers will be redirected to the cache cluster. For example, a cache engine cluster that is homing to both routers in a MHSRP router pair creates a fully redundant caching system, eliminating any single points of failure (Figure: Fully Redundant Cache Engine Cluster Configuration).\nFigure: Fully Redundant Cache Engine Cluster Configuration\nWith a sudden Web traffic surge, a cache engine cluster could become overloaded. To gracefully handle this overload situation, each cache engine detects when it is overloaded, refuses additional requests, and forwards them to the origin Web servers. The origin Web servers respond directly to the clients because the bypassed requests were not handled by a cache engine (Figure: Overload Bypass).\nFigure: Overload Bypass\nThe overloaded cache engine will resume accepting requests when it determines that it has the resources to do so without retriggering overload bypass in the near future. The overload bypass on/off triggers are automatically determined by CPU and file system load. In the extreme situation that the cache engine becomes so overloaded that it is unable to respond to the basic WCCP status check messages from its home router, the WCCP home router will remove the cache engine from the cluster and reallocate its buckets.\nThus, overload bypass ensures that a cache engine cluster does not introduce abnormal latencies and maintains network availability even under unusually high traffic conditions.\nDynamic Client Bypass\nSome Web sites require clients to be authenticated using the client's IP address. However, when a network cache is inserted between a client and a Web server, the Web server only sees the cache's IP address and not the client's IP address.\nTo overcome this issue and similar situations, the Cisco Cache Engine has a dynamic client bypass feature that effectively allows clients, under certain conditions, to bypass cache engines and directly connect to origin Web servers. The result is that a Cisco Cache Engine can preserve existing source IP authentication models and pass through server error messages to clients. Because the cache engine dynamically adapts to these situations, less management is required to ensure cache transparency.\nDynamic Client Bypass Function\nIn Figure: Dynamic Client Bypass, a client issues a Web request, which is redirected to a cache engine. If the cache engine does not have the content, it will try to fetch the content from the origin Web server.\nFigure: Dynamic Client Bypass\nIn Figure: Dynamic Client Bypass, if the server responds to the cache engine with certain HTTP error return codes (such as 401-Unauthorized request, 403-Forbidden, or 503-Service Unavailable), the cache engine will invoke the dynamic client bypass feature. The cache engine will dynamically store a client IP-destination IP address bypass pair, so that future packets with this IP address pair will bypass the cache engine. The cache engine sends an automatic HTTP retry message to the client's browser.\nFigure: Dynamic Client Bypass\nIn Figure: Dynamic Client Bypass, when the client's browser automatically issues a reload, the request will be redirected to the cache engine. However, when the bypass table is checked and the request matches one of the table entries, the cache engine will refuse the request and send it directly to the origin Web server. Thus, the origin Web server will see the client's IP address, authenticate the client, and respond directly to the client.\nFigure: Dynamic Client Bypass\nReverse Proxy Caching\nCache engines are frequently deployed nearby clients to ensure faster network response time and minimal WAN bandwidth usage. Thus, the caches are caching the clients' most frequently accessed content. In addition, cache engines can also be deployed in front of Web server farms to increase the server farm capacity and improve Web site performance. This configuration is called reverse proxy caching because the cache engines are only caching content from the servers for whom they are acting as a front-end.\nThis feature is particularly important when cache engines are acting as a front-end for server farms in which certain content is dramatically more popular than other content on the servers. Using reverse-proxy caching allows administrators to prevent a small number high-demand URLs from impacting overall server performance. Better yet, this means the high-demand URLs do not have to be identified, manually replicated, or independently managed from the bulk of the URLs on the servers.\nReverse Proxy Caching Function\nIn Figure: Reverse Proxy Caching, each cache engine homes to WCCP-enabled routers/switches that are supporting server farms. When an incoming Web request reaches an WCCP-enabled router, the router performs a hashing function on the incoming request's source IP address and port number, mapping the request into one of 256 discrete buckets. Statistically, this hashing function distributes incoming requests evenly across all buckets. In addition, these buckets are evenly allocated among all cache engines in a cluster.\nBecause the hashing function is based on source IP address and port number instead of destination IP address, a given Web object could be stored in multiple cache engines in a cluster. By spreading popular content across a cache cluster, reverse proxy caching allows multiple cache engines to service requests for very popular content. Thus, additional cache engines can be added to a cluster to incrementally scale the performance of a popular site and decrease content download latency.\nNote that hashing on a destination IP address could also do the reverse-proxy caching. But in this case, all requests would have the same destination IP address and would be redirected to one cache engine. If you do not need to scale beyond one cache engine act as a front-end to a server farm, then this method is sufficient.\nFigure: Reverse Proxy Caching\nEnsuring Fresh Content\nA requirement for any caching system is the ability to ensure that users see the same content from a network cache as they would from the Web. Every Web page comprises several Web objects and each Web object has its own caching parameters, determined by content authors and HTTP standards (see the \"HTTP Caching Standards\" section). Thus, even a Web page with real-time objects typically has many other objects that are cacheable. Rotating ad banners and Common Gateway Interface (CGI)-generated responses are examples of objects that are typically noncacheable. Toolbars, navigation bars, GIFs, and JPEGs are examples of objects that are typically cacheable. Thus, for a given Web page, only a few dynamic objects need to be retrieved from the end server, while static objects can be fulfilled locally.\nCisco Cache Engine products deliver fresh content by obeying the HTTP caching standards and by enabling cache administrators to have control over when content should be refreshed from origin Web servers.\nHTTP Caching Standards\nHTTP 1.0 and 1.1 are caching standards, which specify caching parameters for each object on a Web page.\nHTTP 1.0 allows content authors to enable a \"Pragma: no cache\" header field for any object that should not be cached and allows authors to enable content to be cached indefinitely.\nHTTP 1.1 allows content authors to specify how long content is to be cached. For each object on a Web page, content authors can choose among the following caching attributes:\n- OK to cache (the default setting)\n- Explicit expiration date\nHTTP 1.1 has a freshness revalidation mechanism called If-Modified-Since (IMS) to ensure that cached data is up to date. A cache engine will send a lightweight IMS request to the end Web server when the cache engine receives requests for cached content that has expired or IMS requests from clients where the cached content is more than a configured percentage of its maximum age. If the object has not been modified on the end server since the object was cached, the end server will return a lightweight message indicating that the cache engine can deliver its cached copy to clients. If the object has been modified on the end server since the object was cached, the end server will return this information to the cache engine. If the case of the client issuing an IMS request, and the content is less than a configured percentage of its maximum age, the cache will serve the content without checking if it is fresh.\nCache Engine Content Freshness Controls\nAdministrators can control the freshness of Web objects in a cache engine by configuring a parameter called the freshness factor, which determines how fast or slow content expires. When an object is stored in the cache, its time-to-live (TTL) value is calculated using the following formula: TTL value = (Current date - last modified date) * Configurable freshness factor\nWhen an object expires, based on its TTL value, the cache engine will issue an IMS request the next time the object is requested (see \"HTTP Caching Standards\" section for a description of the IMS process).\nIf an administrator wants to adopt a conservative freshness policy, he or she can set the freshness factor to a small value (such as 0.05), so that objects expire more quickly. But the disadvantage to this approach is that IMS requests will be issued more frequently, consuming extra bandwidth. If an administrator wants to adopt a liberal freshness policy, the fresh factor can be set to a larger value, so that objects will expire more slowly and the IMS bandwidth overhead will be smaller.\nBrowser Freshness Controls\nFinally, clients can always explicitly refresh content at any time by using the browser's reload/refresh button.\nThe reload/refresh command is a browser-triggered command to request a data refresh. A reload/refresh will issue a series of IMS requests asking for only data that has changed.\nThe shift+reload/shift+refresh command is an extension of the reload/refresh command. In correctly implemented browsers, this command always triggers a \"pragma: no cache\" rather than an IMS request. As a result, cache engines are bypassed and the end server directly fulfills all content.\nMuch of the traffic on the Web is redundant, meaning that users in the same location often access the same content over and over. Eliminating a significant portion of recurring telecommunications offers huge savings to enterprise and service providers.\nCaching is the technique of keeping frequently accessed information in a location close to the requester. The two key benefits are:\n- Improved usability\nImplementing caching technology in a network accelerates content delivery, optimizes WAN bandwidth, and enables content monitoring.\nCisco has created a network-integrated cache engine by pairing system-level software and hardware.\nQ - On what concept is network caching based?\nA - Based on the assumption that users access the same content over and over.\nQ - What are two secondary benefits of implementing caching technology?\nA - 1. Secure access and control.\n2. Operational logging-administrators can log how many hits sites receive.\nQ - Provide a brief description of network-integrated caching technology.\nA - Network-integrated caching technology combines system-level software and hardware. Network-integrated caches must be managed like network equipment, designed like high-density hardware, and transparently inserted into the network.\nQ - How do Cisco cache engines ensure that web pages are kept up to date?\nA - By obeying HTTP caching standards that dictate which elements on a page can be cached and which cannot. Those that are not are retrieved from the source every time they are accessed.\nQ - Name an object that can be saved in cache memory, and one that cannot.\nA - Saved in cache: rotating banners, GIFs and JPEGs, toolbars, navigation bars. Noncacheable: CGI-generated responses.", "label": 1}
{"text": "- Confidentiality: Making sure people cannot acquire information they should not (keeping secrets)\n- Integrity: Making sure people cannot change information they should not (protecting data)\n- Availability: Making sure people cannot stop the computer from doing its job.\nComputer security involves telling computers what they are not to do. This makes computer security unique because most programming makes computers do things. Security takes much of a computers power.\nBasic computer security methods (in approximate order of strength) can be:\n- Limit access to computers to \"safe\" users.\n- Peripherals which block any \"unsafe\" activity.\n- Firewall and antivirus software.\nOther pages [change]", "label": 1}
{"text": "Anders Persson MCS-2007:18, pp. 31. TEK/avd. för interaktion och systemdesign, 2007.\nOnline banking and e-commerce applications have good protection against attacks directed direct towards their computer systems. This, the attacker has considered and instead use “social engineering” attacks, such as phishing to gain access to the information inside   . Phishing is a growing problem that many different companies are trying to develop a working protection against. The number of new phishing-sites per month increased by 1363 % between January 2005 and October 2006, from 2560 to 37 444 attacks  . Today there are several different antiphishing applications as well as implemented methods to prevent attacks, but it’s not certain they giving enough protection. In this paper we plan to investigate the concept of phishing to better understand the threat it provides. We will analyse 252 different phishing attacks and examine a number of existing antiphishing applications to see if there are possibilities to improve the different protection methods to improve the accuracy of such tools.", "label": 1}
{"text": "(ARA) – Have you ever casually surfed the Web, answered a friendly chat or responded to a curious email only to have it lead to major computer trouble? With virus, spam and phishing technology more sophisticated than ever, computer threats can be hidden in devious places. Are you making common computing mistakes without even knowing it?\nAccording to a 2012 Pew Internet & American Life Project survey, 58 percent of American adults have a desktop computer and 61 percent have a laptop. With all that computer power out there, it’s important to understand how to protect your at-home PC.\nHere are common mistakes that can affect computer speed and safety, from the experts at USTechSupport whose family of products include MYCLEANPC and MAXMYSPEED:\nMistake: Enjoying “free” software and movies from your buddy.\nDownloading pirated software is not only illegal; it can cause significant damage to your computer. The “free” software and media your buddy gave you can do more harm than good to your computer because it may be riddled with malicious viruses and malware, making your PC susceptible to attack. Remember, it’s better to buy than borrow when it comes to software and media.\nMistake: Clicking on enticing pop-ups.\nPop-ups caught your attention? Think before you click. Pop-ups that offer free goods, deals on products and even conversation with beautiful people can be alluring. But, do you know where that click will take you? Clicking on suspicious pop-ups can lead you down a rabbit-hole of even more unwanted pop-ups and spam. Take the time to research the subject yourself, rather than clicking on the first questionable advertisement.\nMistake: Leaving multiple files open.\nYou’re an expert at multitasking, meaning you need to constantly access many files. But leaving multiple files open in different applications can put a significant strain in your system. Try to keep only necessary resources active and see how much faster your machine responds.\nMistake: Not being proactive with computer maintenance.\nComputer issues arise frequently, even for the most savvy computer user. That’s why taking a proactive approach is best so your computer remains secure and fast. You can get a free diagnosis of issues that may be affecting your PC’s performance by visiting www.mycleanpc.com. You can easily fix common issues before they become costly (and timely) problems.\nMistake: Responding to an email with an “incredible opportunity.”\nEveryone has received them – that email investment opportunity that seems too good to ignore. The reality is, many scammers prey on trusting individuals or those who are enticed by get-rich-quick schemes. These scammers may even complete an initial transaction, only to later wipe out all your accounts. Never provide personal information, including banking information or your Social Security number, to anyone over email.\nMistake: Visiting adult websites.\n“Triple X” can also mean triple the issues. Some sites harbor more than just adult material, they can create a domino-effect of pop-ups, forcing your PC to a grinding halt as it deals with the incoming viruses that drain the system’s resources. Avoiding suspicious sites is part of keeping your computer running at its best.\nIf you’ve made some of these mistakes in the past, don’t worry. Many people are tricked each day. By learning from these useful tips and suggestions, you’ll keep your PC running fast and issue-free.", "label": 1}
{"text": "System Smart Security Description\nSystem Smart Security is a rogue security program that borrows the interface and attack techniques of similar rogue security programs. Rogue security programs in the System Smart Security family are known to create fake infection warnings and system errors, hijack web browsers and block applications and executable files. System Smart Security may look like a normal security program but is incapable of finding or removing threats from your computer. You should remove System Smart Security by using an anti-malware program, as soon as you can.\nThe Litany of System Smart Security’s Fake Alerts\nSystem Smart Security and similar threats are distributed by Trojans that attack computers through browser security exploits. Other rogue security programs that are closely related to System Smart Security include Security Essentials, Internet Security, Internet Security 2011, Security Essentials 2011 and Internet Security 2010. These rogue security programs use a similar interface, and attack your PC in the same ways, although security software that can detect a System Smart Security clone may still be unable to detect System Smart Security.\nAfter System Smart Security is installed, you’ll notice that System Smart Security runs whenever Windows starts. System Smart Security may even remain active as a memory process even if you try to shut System Smart Security down. This lets System Smart Security create pop-up errors like the following, whenever System Smart Security wants:\nContinue working in unprotected mode is very dangerous. Viruses can damage your confidential data and work on your computer. Click here to protect your computer.\nSecurity Essentials Ultimate Pack software detects programs that may compromise your privacy and harm your systems. It is highly recommended you scan your PC right now. Click here to start.\nYour computer is being attacked from a remote machine !\nBlock Internet access to your computer to prevent system infection.\nCritical System Warning! Your system is probably infected with a version of Trojan-Spy.HTML.Visafraud.a.\nThese fake alerts don’t detect real threats on your PC, since System Smart Security can only create false positives. Following their instructions may redirect you to malicious websites like System Smart Security’s homepage that attempt to steal your credit card information, or attack your PC with other threats.\nOther System Smart Security Perils to Keep Your Eyes Peeled For\nSystem Smart Security may also engage in other attacks in an attempt to fool you into believing that your PC is much more dysfunctional than it really is. The two primary and more serious System Smart Security attacks are:\n- Browser hijacks that change your homepage, redirect you to harmful websites or block you from visiting helpful websites. Hijacks by System Smart Security may also create fake errors that make it look like a website is unsafe or use links that redirect you to malicious sites.\n- System Smart Security may also block applications, most notably programs related to security or system maintenance. Windows Task Manager, MSConfig and similar default programs may be blocked, as well as well-known anti-virus scanners.\nRemoving System Smart Security will solve all of these issues, but improperly deleting System Smart Security can harm your Internet connectivity and other aspects of your PC. To remove System Smart Security with no side effects, consider using a good anti-malware program to scan your entire system once System Smart Security has been shut down.\nSystem Smart Security Automatic Detection Tool (Recommended)\nIs your PC infected with System Smart Security? To safely & quickly detect System Smart Security, we highly recommend you run the malware scanner listed below.\nDownload SpyHunter's* Malware Scanner to detect System Smart Security What happens if System Smart Security does not let you open SpyHunter or blocks the Internet?\nFile System Modifications\n- The following files were created in the system:\n# File Name 1 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\ 2 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].dll 3 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].exe 4 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].mof 5 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].ocx 6 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS]\\ 7 %UserProfile%\\Application Data\\System Smart Security\\ 8 %UserProfile%\\Application Data\\System Smart Security\\cookies.sqlite 9 %UserProfile%\\Application Data\\System Smart Security\\Instructions.ini\nPosted: June 7, 2011 | By SpywareRemove\nThreat Level: 10/10\nRate this article:", "label": 1}
{"text": "Information compiled by the GradSchools.com team - last updated October 2010\nStudying In the field\nIn addition to an undergraduate degree in a field such as accounting or business, some forensic accountants have backgrounds in law enforcement or criminal justice. A few schools offer accounting degrees with an emphasis in forensic accounting. For people already in the accounting field, the Association of Certified Fraud Examiners (ACFE) offers a certification exam. Entry-level forensic accountants typically earn between $30,000 and $60,000. Forensic accountants who have worked in the field for several years can make six figures.\nJob opportunities In the field\nThe field of forensic accounting is a specialty area of accounting that has to do with lawsuits or legal disputes. Webster’s dictionary defines the word “forensic” as “belonging to, used in, or suitable to courts of judicature or to public discussion and debate.” A forensic accountant might investigate white-collar crimes such as fraud or analyze financial information in a personal injury case. Sometimes forensic accountants, also called forensic auditors or investigative auditors, need to be expert witnesses at trials.\nAll of the Big Four accounting firms have forensic accounting departments. In addition, some smaller firms, such as Boston-based Feeley & Driscoll, offer forensic accounting services. International forensic accounting firm MD&D has 32 offices in the United States, the UK, Canada, Australia and Singapore. Police departments, government agencies, insurance companies and other businesses also hire forensic accountants.\nThe Bureau of Labor Statistics (BLS) expects the demand for all accountants, including forensic accountants, to increase. The BLS explains, “Increased focus on and numbers of financial crimes such as embezzlement, bribery, and securities fraud will increase the demand for forensic accountants to detect illegal financial activity by individuals, companies, and organized crime rings. Computer technology has made these crimes easier to commit, and they are on the rise. At the same time, the development of new computer software and electronic surveillance technology has made tracking down financial criminals easier, thus increasing the ease, and likelihood of, discovery. As success rates of investigations grow, demand for forensic accountants will increase.”\nCheck out: Accounting Graduate Programs\nPhoto by alancleaver_2000", "label": 1}
{"text": "Pádraic Brady: PHP Security: Default Vulnerabilities, Security Omissions & Framing Programmer\nOdd though it may seem, this principle explains some of PHP's greatest security weaknesses. PHP does not explicitly use Secure By Design as a guiding principle when executing features. I'm sure its in the back of developers' minds just as I'm sure it has influenced many if their design decisions, however there are issues when you consider how PHP has influenced the security practices of PHP programmers. The result of not following Secure By Design is that all applications and libraries written in PHP can inherit a number of security vulnerabilities, hereafter referred to as \"By-Default Vulnerabilities\".\nHe focuses on what he sees as a responsibility of those creating the language to either default to a more secure architecture or provide information as to why their choices could cause problems. In the extended version of the post, he talks about some specific issues that the language has including SSL/TLS misconfiguration, openings for XML entity injection attacks and limited native filtering for cross-site scripting.", "label": 1}
{"text": "Friday, June 17, 2011\nThe shield uses two antennas, one to transmit the jamming signal and the other to relay authenticated programming commands to the implant. (Source: MIT)\nMedical implants today receive wirelessly transmitted instructions from physicians regarding how to dispense their therapy, opening them to cyber-attacks that could potentially be fatal. However, a novel shield technology could secure access to the implants by virtue of an add-on medallion worn by the patient.\"\nEven though there have yet to be any reported cases of cyber-attacks on people with medical implants, such as pacemakers, researchers are intent on heading off the possibility with a shielding technology that works even with existing implants.\nSomeday soon Hollywood will be basing a major film on the premise that a hacker gains control of an important person's medical implant, either manipulating them by adjusting, say, their blood sugar with an insulin implant, or even assassinate them by stopping their heart with their own pacemaker. That is precisely the real-world scenario that Massachusetts Institute of Technology (MIT) professor Dina Katabi and University of Massachusetts-Amherst (UMass) professor Kevin Fu want to \"head off at the pass,\" to use the Hollywood colloquialism from old Westerns (where the bad guy alway wore a black hat).\nThe stakes are enormous. Millions of citizens worldwide already have approved medical implants and more than 300,000 more receive pacemakers, defibrillators, drug pumps, brain \"stimulators\" and the like every year. Many of these implants have wireless connections that allow doctors to monitors their performance and fine-tune their therapeutic benefits. Communication with them is carefully encoded so that stray radio signals do not unintentionally modify their programming; however, hackers today already possess the skills to circumvent these safety measures, prompting Katabi and Fu to collaborate on a solution before the problem materializes.\nThe smarter solution, according to the team, is what it calls a \"shield\" which is worn like a medallion. The shield constantly emits a jamming signal on the precise frequency at which the implant receives its wireless instructions from an external programmer, usually at the doctor's office. However, this is no dumb jamming signal that just blankets the patient in white noise, which could actually endanger the patient if it randomly changed the implant's programming. Instead, it emits a carefully encrypted signal that still allows authenticated programming to get through but which foils any hacker who does not possess the encryption key.\nPosted by R. Colin Johnson at 7:00 PM", "label": 1}
{"text": "IN DEPTH: BEGINNER'S GUIDE TO COMPUTER SECURITY\nHow safe is your computer?\nCBC News Online | Feb. 18, 2005\nSAFE PRACTICES | »TOP TIPS\nSafe practices checklist\nThe five top tips are tools to help protect your computer. They won't be much help if you reply to spam e-mail or use weak passwords. Even with a fully updated anti-virus program and firewall, an intruder with your passwords can gain access to your system.\nHere are some safe practices to layer your defence against online threats.\n\"Computers have passwords, and passwords are the keys to the kingdom. With this access they (intruders) could do anything you could and if motivated, even more.\"\nRyan Purita, security consultant.\n- Use unique passwords that you can remember. Use at least eight characters and include numbers and symbols. Make it difficult for programs that are specially written to crack your password.\nDon't use words you can find in the dictionary, or obvious things like the name of your child, your pet's name or your month of birth. Use a password that is easy to remember, so you don't have to write it down\nA 2003 Symantec survey of 700 Canadians found one out of every four respondents use family or pet's name as a password. Sixty-nine per cent memorized their passwords, but 24 per cent wrote their passwords down.\n- Be cautious with e-mail. Don't open e-mails and attachments from an unknown source. Make sure your e-mail program isn't set to automatically download attachments. Report spam to your internet service provider.\nWatch those virus warnings passed on by well-intentioned friends and family. It might be a hoax perpetuated by chain-letters. Verify the information with trusted sources. Rosaleen Citron, CEO of security firm White Hat Inc., recommends Sans.org and Anti-Phishing.org.\n- Scan downloaded files. Even if you've made sure that the file is from a trusted source, always scan for viruses before opening it.\n|AOL Canada March 2004 study\nOf 2000 Canadians surveyed:|\n· 89 per cent reported they were\nusing anti-virus protection.\n· 56 per cent were using firewall protection.\n·42 per cent had spam filtering.\n· 35 applied anti-pop-up software.\n· 6 per cent indicated they were not using any of the above.\n- Watch for unsecured shares: Turn off software features you don't use such as printer sharing and file sharing. These are available for easy access between computers on a network. This ability to share files can be used to infect your computer with a virus or allow an intruder to look at the files on your computer.\nIf you do have file sharing turned on, know what programs are using it. If you need to share files between computers, Ryan Purita, a security consultant, suggests that users set passwords to accounts and give only those accounts access: \"Never share your entire drive; rather, share folders which contain the files you want to share. Do not expose shares to the internet. Always use a firewall -- it will prevent anyone from accessing your computer via shares.\"\n- Secure your browser. Turn off features that allow automatic downloads, and turn on your browser's built-in security features. Get a blocker to stop those pop-up banners, and don't click on links in those pop-ups. Tod Maffin, CBC's technology columnist, points out most people don't read what's in the pop-ups before accepting them.\nHackers often target popular browsers such as Microsoft's Internet Explorer so\nyou might want to consider using alternative web browsers such as Firefox or\nOpera, suggests Maffin. There's no guarantee your computer will be safe, but you can avoid those\nthreats designed especially for Internet Explorer.\nIf you do use Internet Explorer, change the internet options default setting so that\nIE has to ask your permission before downloading files or running ActiveX\nControls, which are mini-programs often exploited by hackers.\n- Make backups of important files onto separate disks. If your computer does become infected, you'll have a clean copy of your files.\n- Turn your computer off or disconnect from the network between uses. Disconnecting your computer from the internet when you're not online, or shutting down the computer, lessens the chance that an intruder will be able to access your system.\nFollowing the top tips and safe practices should minimize your computer's exposure to online risks. But what if you think your computer's already been infected? What steps should you take?|\nRead some of our experts' advice.\nNEXT: PROTECT YOUR PERSONAL INFORMATION", "label": 1}
{"text": "When you're born, you're given a name which not only has meaning for you and your family, it also establishes your identity. Unfortunately, your name and identity are equally important to criminals who seek to take advantage of your name and steal your identity.\nIdentity theft is when someone wrongfully obtains and uses another person’s information in a fraudulent or deceptive manner. The personal information is typically used for financial gain. In fact, identity theft is the nation's fastest growing crime, according to the Identity Theft Resource Center. A recent study by the center showed seven million Americans become victims every year.\nWays thieves can steal your name and personal information:\nEven if the thief is caught, victims often spend a lot of time and money clearing their name. If your identity is stolen, you can expect to spend an average of 600 hours over the next few years clearing your name, and an average of $1,400 in out-of-pocket expenses.\nIdentity theft can affect your financial security for years to come\nThe residual financial effects of identity theft can be long-lasting. Identity theft can have a significant impact on your plans to save and invest in your family’s financial security. Money you have earned for saving or investments, such as your retirement or your child’s education fund, may end up paying for these collateral costs:\nIn addition to the financial strain, identity theft can also leave emotional scars. Victims have often reported the same mental conditions which afflict victims of physical assault. Common feelings include shame and embarrassment.\nSteps you can take to avoid becoming a victim:\nProtect your financial future\nWe offer two types of protection:\nGuidance from a trained professional\nYour name is one of your most valuable assets. Contact me to protect you and your family’s financial security from the threat of identity theft.\nFor product and service information, read our full disclaimer.", "label": 1}
{"text": "Systems exposed to the internet are heavily challenged to keep the bad\nguys out, and keeping up with the latest security patches is not always\neasy. So, the wise admin will attempt to institute systemic steps\nto limit the damage should a compromise occur, and one excellent\nmethod is the use of a chroot() jail.\nA chroot jail presents a dramatically restricted view of the filesystem to an\napplication, and usually far fewer system privileges, and this all intends\nto limit the damage should the application go awry or be subverted by the\nThis document touches on how chroot works and discusses some best\npractices that developers and administrators can use to make their\ninstallations more secure.\nBackground on chroot\nThe chroot system call changes the root directory\nof the current and all child processes to the given path, and this is\nnearly always some restricted subdirectory below the real root of the\nfilesystem. This new path is seen entirely as \"/\" by the process,\nand we refer to this restricted environment as the \"jail\". It's not\npossible to escape this jail except in very limited circumstances.\nThe chroot system call is found in all versions of UNIX that\nwe know of, and it serves to create a temporary root directory for\na running process, and it's a way of taking a limited hierarchy\nof a filesystem (say, /chroot/named) and making this the\ntop of the directory tree as seen by the application.\nHow to break out of jail\nThere are well-known techniques used to escape from jail, but the most\ncommon one requires root privileges inside the jail. The idea is for the\nprogram to do a chroot to a subdirectory, leaving the current\ndirectory outside the jail.\nWe'll add more notes on ways to break out of a jail - which is meant\nmore to show what must be protected against than it is as a how-to\nfor jailbreakers -- but we've found a good article on chroot in general\n- Use mknod to create a raw disk device, thereby doing\npretty much anything you like to the system.\n- Use mknod to create /dev/mem and modify kernel memory\n- Find a carelessly-left hard link that leads outside the\njail (though symbolic links don't escape jail, hard\n- Use ptrace to trace a process living outside the jail.\nWe may be able to modify this program to do our bad stuff on our behalf.\nAlmost all jail breaking requires root privileges.\nGeneral chroot principles\nWe have presented these in no particular order, and no one site will\nuse them all. In particular, some tips apply to developers at the source\ncode level, while others apply to administrators trying to jail an\nMany of these points may end up being overly petty in practice, in\nthat there are only so many layers of defense that a workable system\ncan use, but we'll present all we can think of and let you pick and\nchoose. An overriding principle is \"What if the bad guy somehow does\nX? How can we limit our exposure\".\nOur general concern is mostly about remote buffer overflows, and\nthis can give the bad guy complete control over our CPU: all our\nsteps are designed to limit the damage should this unfortunate\n- Run in the jail as a non-root user\nA chroot jail is not\nimpervious to escape, but it not easy and requires root permission in\nthe jail itself, so we must take steps to limit this possibility. By\nrunning the jail as a non-root user, it's as secure as we know how to\nmake it. It may be necessary for the daemon to launch as root in order\nto do a few tasks that require these permissions (say, binding to a\nlow-numbered port), but the program must \"give up\" its root permissions\nafter doing so.\nWe believe that this single factor is the most important one\nin setting up a jail properly.\n- \"Give up\" permissions correctly\nWe've seen situations where\non some operating systems, a program can jump back and forth between\na non-root user and root by use of a \"saved\" uid, and this has been\nexploited by the bad guy who get root.\nThe details of how to do this correctly are much more tricky when\nOS differences are taken into account: the variants are setresuid()\nseteuid(), setreuid(), and setuid() — it's likely\nthat this does not exhaust the options. The right one depends on the OS\nThe best resource by far we've found on this is the outstanding\nUsenix 2002 paper Setuid Demystified,\nby Hao Chen, David Wagner, and Drew Dean: it is precisely on point, and we'll\ndirect the reader to section 5.2 \"Comparison among Uid-setting System Calls\".\n- Explicitly chdir into the jail\n- The chroot call itself does not change the working directory, so if\nthe new root is below the current directory, the application can\nstill have access outside resources.\nThe application should explicitly change to a directory within the\njail before running chroot:\nsetXXuid(nonroot); // give up root permissions correctly.\nThis closes a trivial escape route from the jail (but we'll note that you\nmust use the proper setuid-esqe calls as noted in the previous item).\n- Keep as little in the jail as possible\n- This limits what\ncan be compromised should a vulnerability be discovered. Often this\nrequires development support to do some \"preloading\" of non-jailed\nfiles before the chroot operation itself is performed (we'll touch\non this a bit more later). But we're quite ruthless in removing things\nfrom the jail when possible.\n- Limit non-jail running of jailed binaries\n- For systems that\ndo not have a command-line option for running chroot, the only alternative\nis to create a wrapper program. This wrapper will perform the key chroot\noperation, give up root permission, and then execute the jailed binary.\nThe wrapper must be run as root (only chroot can perform this\noperation), but the wrapper itself must not be found in the jail.\nOtherwise an intruder could quietly compromise the wrapper, and\nthe next time the system is launched, the intruder's program would\nbe run as root in a non-jailed environment. This is complete\n- Have root own as many jailed files as possible\n- This limits the\nability of the intruder to make changes should a compromise occur.\nOur feeling is that the most likely cause of penetration will be\nthe buffer overflow exploit in which the intruder executes arbitrary\ncode in environment, and for files that the jailed system need not\never write to, making them readonly and owned by root means that\nthe penetration can't chmod the file before writing to it. This\nrule applies to directories as well.\n- Drastically limit all permissions of files and directories\nfeeling is that if a permission bit is not required, it should not\nbe set. For instance, the jailed \"/dev/\" directory should be of\nmode d--x--x--x with owner = root. Even though the only thing\nin the directory is /dev/null, forbidding searching of a directory\nstrikes us as prudent practice across the board when it's known to work.\n- Create a permissions-setting script\n- When first setting\nup the jail, many of the permission-related knobs are tweaked by hand\nas we gradually tighten things up, looking for things to break (at\nwhich point the knob is eased back a bit). This research is intricate,\nand the knowledge gained really ought to be represented in source code\nWe typically create a small shell script — living outside the jail\n— that sets the owner, group, and permissions mode on every file in the\njailed environment. It always starts with a few recursive change-everything\noptions to hardcode everything to very tight permissions, then relaxes\nthe settings on the files that can tolerate this. It's important to include\ndocumentation in the script on why particular permissions are relaxed,\nas well as describing why certain files are found in the jail in the first\nOnce this script is created, we typically make all of our\npermissions-related changed here and then re-run the script to\nmake them take effect. This is the only way that we can be sure\nthat our script matches the running environment.\nA great side benefit of the permission script is that it serves as\ndocumentation to the next person setting up a similar environment.\nA sample permission script that we use for one of our projects\n(running BIND in a chroot jail). The specific details aren't\nreally important, but this gives an idea\n# by default, root owns /everything/ and only root can write\n# but directories have to be executable too.\nchown -R root.named .\nfind . -print | xargs chmod u=rw,og=r # *all* files\nfind . -type d -print | xargs chmod u=rwx,og=rx # directories\n# the \"secondaries\" directory is where we park files from\n# master nameservers, and named needs to be able to update\n# these files and create new ones.\nfind conf/secondaries -type f -print | xargs chown named.named\nfind conf/secondaries -type f -print | xargs chmod ug=r,o=\nchown root.named conf/secondaries\nchmod ug=rwx,o= conf/secondaries\n# the var/run business is for the PID file\nchown root.root var\nchmod u=rwx,og=x var\nchown root.named var/run\nchmod ug=rwx,o=rx var/run\n- Try to do the chroot operation inside the daemon itself\n- ... rather than rely on the explicit chroot command (this requires\nsource code modifications). A daemon that has its own internal chroot\ncan often park the executable located outside the jail: this is a big\nwin because an intruder is not able to ever infect the binary directly.\nBut the more immediate benefit is that shared libraries and other startup\nfiles can be automatically loaded from the full system and need not be\nlocated inside the jail. This not only makes the system safer — less\nexposure to the outside — but also makes it easier to set up.\nIn many cases, even configuration files can be loaded from outside the\njail, though this won't usually work if the daemon includes any kind of\n\"reread config files\" option.\n- Preload dynamically loaded objects\nFor developers adding chroot\nsupport to programs, consider operations that require access to full-system\nresources and perform them before closing the jail door. These steps are\noften not entirely obvious at first and require some trial and error,\nbut we've found several that qualify.\nMany systems load nameservice resolver clients dynamically at runtime,\nand they are not included in the shared objects bound to the executables.\nWe have found that simply calling gethostbyname one time before the\njail door is closed will load all the appropriate libraries required, so\nthat later nameservice requests are handled properly:\nWe believe that syslogging operations fall in this category too, as many\nsystems uses UNIX domain sockets for this and require access to the socket\nthat syslogd is listening on. We've not done the modifications required\nfor syslog support and cannot offer any specific suggestions. We believe\nthat Solaris -- with its use of \"doors\" -- is an added complication.\nFor daemons that permit cmdline parameters to select the runtime users\nand group (after giving up root), the mapping of name to UID and GID must\nbe done before the chroot operation so that the system-wide /etc/passwd\nand related files are used, not the one inside the jail. See the\nnext section for the rationale.\nThis bit of C code shows the idea of how the user lookup should be performed\nseparately from the user ID changing:\nif ( geteuid() == 0 )\nstruct passwd *userent = 0;\nif ( (run_as_user != 0) && (userent = getpwnam(run_as_user)) == 0 )\n/* ERROR */\nchroot( working_dir );\nif ( userent )\nsetXXuid(userent); // use the proper call!\n- Avoid using the jailed /etc/passwd file\n- ...particularly for\nname to UID mapping used to determine the runtime user ID of the daemon.\nThe mapping involves scanning the passwd file for the given name\n(say, named) and finding the user ID associated with it. If the\nbad guy somehow manages to compromise the jailed passwd file, it's\npossible that the UID for the runtime user could be changed to zero,\nwhich is root. This will take effect the next time the daemon restarts.\nThe bad guy shouldn't be able to compromise this file in the first place,\nbecause it should not be writable by the running user, but it's not out\nof the question that the daemon could somehow retain a writable file\ndescriptor that the buffer overflow could use to modify the file: we\nbelieve we have seen this happen before. As is so common, a bug in one\narea of the system can have surprising impacts on security.\n- Close file descriptors aggressively before chrooting\n- We don't\nwish to leave handles open to non-jailed resources because these can all\nbe exploited by those living inside the jail. Some file descriptors are\nrequired (day, to the syslog daemon), but developers should make a point\nto close anything that is not strictly required.\n- Link config files from the outside\nSome systems (such as BIND)\nshare the configuration file between the jailed daemon and other utilities\nthat are run from user mode. In this case, the config file simply must\nlive inside the jail so that the daemon can access it, but the other utils\nfrom user mode still need to access this file. Rather than rebuild these\nutilities to use the special path (say, /chroot/named/etc/named.conf),\ninstead go to the \"regular\" place for this file and create a symbolic\nlink from the outside to the inside of the jail:\n# ln -s /chroot/named/etc/named.conf /etc/named.conf\nThis allows most of the tools to operate \"normally\", though one has\nto be a little more careful that users editing /etc/named.conf\nrealize that they're affecting a jailed system.\nThis doesn't go the \"other\" direction, though it's not always obvious\nat first. Symbolic links from inside the jail to the outside will\nwork for the administrator but will not work for the system running\ninside the jail.", "label": 1}
{"text": "What is Big Data?\nBig Data describes the process of extracting actionable intelligence from disparate, and often times non-traditional, data sources. These data sources may include structured data such as databases, sensor, click stream and location data, as well as unstructured data like email, HTML, social data and images. The actionable data may be represented visually (e.g. in a graph), but it is often distilled down to a structured format, which is then stored in a database for further manipulation.\nThe sheer size of data being collected is more than traditional compute infrastructures can handle; exceeding the capacities of databases, storage, networks and everything in between. Extracting actionable intelligence from BigData requires handling large amounts of disparate data and processing it very quickly. Finally, the data inputs and the actionable intelligence must be correct; the data must be consistent and clean. As the saying goes, garbage in, garbage out. All of these demands are overwhelming traditional computing infrastructure. IBM describes these new demands across four dimensions: Volume, Velocity, Variety and Veracity. I would add Richly Linked Data to this list—processing Big Data uncovers rich relationships between that data—except I cannot think of a “V” word that says richly linked. To deal with the onslaught of Big Data, companies are turning to new tools and new business processes.\nBig Data Tools\nAs Big Data overwhelms traditional databases, storage and more, companies are looking to exploit new tools like Hadoop, SSD, database virtualization, storage virtualization, network virtualization, and more. The reality is that you want to avoid single device bottlenecks, since they inhibit scaling. Hadoop uses map-reduce to spread analytical processing across armies of commodity servers. SSD, while expensive per GB of data capacity, provides the performance necessary to keep up with the velocity of Big Data. Virtualization of the database, storage and networking provides the elasticity and agility needed to scale to address Big Data demands, while delivering a consistent quality of service. These are just some of the tools being brought to bear on the Big Data challenge.\nBig Data Business Processes\nThe benefits of Big Data are quite tantalizing. Big Data can be used to improve efficiency and the predictive capabilities in everything from health care to oil drilling. Once businesses get a taste of Big Data, their appetite becomes insatiable. This has spawned new business processes to meet the rising demand. Moving to the cloud is one such business process enabling Big Data. Cloud enables you to process your Big Data using say 1,000 machines for just an hour, paying only for the time you use them. This makes Big Data processing cost-effective in terms of both operational expenses (OpEx) and capital expenses (CapEx). Another interesting business process that is becoming popular is cloud-bursting. Cloud-bursting means running the core process on your own machines, but allowing overflow compute demands to run on a public cloud, typically for a short period of time. Creative companies will use these and other innovative business processes to deal with the growing demands of Big Data.\nWhat Role do Databases Play in Big Data?\nBig Data begets Bigger Data. The more a company recognizes the transformative role of Big Data, the more data they seek to capture and utilize. As a result, more companies are capturing more data. This includes everything from web analytics and click stream data to expanding their database schema to capture more transactional information. The more you utilize Big Data, the more data you seek to collect.\nDatabases are broken into two classes: analytical and transactional. Transactional databases capture structured information and maintain the relationships between that information. Transactional data is one feedstock for Big Data. Analytical databases then sift through the structured and unstructured data to extract actionable intelligence. Often times, this actionable intelligence is then stored back in a transactional database.\nHow are Transactional Databases Handling Big Data?\nBig Data requires decentralization. Because of the volume and velocity of data being processed, centralization is anathema to Big Data. The networking, storage and compute must be decentralized or they will not scale. However, centralization is a core tenant of SQL databases. Traditional databases tightly link computation, caching and storage in a single machine in order to deliver optimal performance. There are two approaches to scaling SQL databases in order to handle Big Data—namely sharding and shared-data clustering.\nOne approach to decentralizing transactional databases is sharding. If you have an existing schema, sharding removes the relations between tables and then stores those various tables in separate databases. This forces the application layer to maintain, and in some cases reconstruct, those relationships. One common approach to sharding is to split customers across multiple databases. For example, you might have customers 1-10,000 in one database, then 10,001-20,000 in another database and so on.\nSharding is one way to scale your data handling needs, but it is very inflexible, it doesn’t adhere to the Big Data principle of agility. A sharded database cannot add new data sources, and new ways of processing that data, on the fly. Sharding creates a rigid structure that necessitates a painful re-sharding each time you modify or expand the data or relationships between the data.\nShared-data database clusters, as provided by ScaleDB and Oracle RAC®, deliver the agility required to handle Big Data. Unlike sharded databases, shared-data clusters support elastic scaling. If your database requires more compute, you can add compute nodes. If your database is I/O bound, you can add storage nodes.\nIn keeping with the Big Data principle of distributing the workload, shared-data clusters parallelize some processing across smart storage nodes, further eliminating bottlenecks, and allowing you to scale to address your Big Data needs.\nUnlike sharded databases, shared-data clusters maintain the flexibility to add new tables and relationships on the fly. This flexibility is imperative, in order to keep up with the ever changing data sources and data relationships driven by Big Data.\nHow Can You Prepare for Big Data?\nThe most important first step in preparing for Big Data is to consider scale, parallelization, and agility. These issues must be considered when choosing your computing tools and your business processes. Maintain agility or flexibility, because your data and your processing needs will change and that change may be rapid and disruptive. Scale and parallelization go hand-in-hand. The only way you can scale to handle Big Data, is by leveraging parallelization. This means you must distribute processing, data and networking so as to avoid bottlenecks.\nThese same principles aplpy to your business processes. This may involve exploiting elastic cloud computing either directly or through cloud bursting. Consider that, as you plan your infrastructure and your schemas today, things will change relatively quickly. Big Data begets Bigger Data, so prepare for future scale and agility today.\nFor more information about Big Data and how databases are adapting to the demands of Big Data, see our Big Data White Paper.", "label": 1}
{"text": "What are secure connections?\nSecure connections are designed to protect data sent between two computers via the Internet. Secure connections should:\n- Mask confidential data from third parties\n- Verify the identification of the party with whom information is being exchanged\n- Protect information from being viewed or modified by a third party\nFig. 1. Access to an MS Exchange Server mailbox via a secure connection\nThere are several ways to secure data transmission, and they all involve the use of data encryption and special keys used to read the information. The keys (also known as certificates) are usually stored in a dedicated database – a certificate archive – and are accessible to authorized users.\n- Data encryption. This method involves masking information (emails, for example) from third parties and sender verification. This method, however, does not verify the authenticity of the two computers involved in the exchange of information. In order to create an encrypted message and have two recipients read it, the recipients must have the appropriate program installed (such as PGP, GPG or S/MIME). Most encrypted data is transferred via email.\nFig. 2. Encrypting data using PGP\n- Encrypting a transfer channel. This method involves concealing the entire contents of the network connection and verifying the authenticity of all computers participating in the network connection. However in most cases, the data itself, as opposed to the first method, is not verified. For example, sender verification of an email received via an encrypted channel is not possible. These encryption protocols are called SSL and TLS.\nFig. 3. Secure connection settings in Outlook Express\nSupport for an encrypted transfer channel is currently provided by the vast majority of Internet applications: email servers and client programs, web servers and browsers, as well as a number of proprietary network applications, such as banking systems used to manage accounts and make payments online. The simplicity of this method is obvious to developers: a standard data transfer protocol can be implemented within an established secure network connection, making any necessary modifications to network ready applications minor. This is how well-known protocols function:\n- HTTPS (normally HTTP – the main Internet protocol which is encrypted using SSL/TLS)\n- POPS (normally POP3 –the main protocol for receiving email, and encrypted using SSL/TLS)\n- SMPTPS (normally SMTP – the main protocol for sending email, and encrypted using SSL/TLS)\n- MAPS (normally IMAP4 – a common protocol for receiving email, and encrypted using SSL/TLS)\n- NNTPS (normally NNTP – a common protocol for reading news and encrypted using SSL/TLS)\nSome network services are offered exclusively via an encrypted connection, such as the popular Gmail.\nThis article examines encrypted transfer channels, or so-called secure connections.\nDifferent types of protection against network threats\nNetwork connections are used to transmit both useful information but also malicious data, which can pose a threat to computers. Typical examples of malicious data include most contemporary threats: hacker attacks, Trojans, email worms and exploits which target web application vulnerabilities.\nThe following types of programs and application packages can be used to protect against network traffic threats:\n- Checks every network connection on the local computer in accordance with designated rules: the connection will either be permitted or denied.\n- Can detect (but not delete) Trojans when they attempt to transmit harvested confidential data to a third party.\n- Cannot detect viruses, regardless of the type of connection.\nFig. 4. Firewall rules for an application\n- Protection against network attacks (IDS: Intrusion detection system):\n- Scans for, and is capable of blocking attacks for which there is a signature with in an established network connection regardless of protocol;\n- Can detect viruses, but not delete them from common HDLC protocols such as HTTP and POP3. When a virus is detected in an email received via POP3, the only possible action is to terminate the network connection. This does not guarantee, among other things, protection against the virus detected in the email. When the user attempts to get other emails from the server, the infected email will cause the victim machine to disconnect from the mail server;\n- Cannot detect viruses within an encrypted connection.\nFig. 5. Blocking a network attack\n- Antivirus solutions (email and web):\n- Can detect and neutralize viruses included in the database during sending and receiving data via a known HDLC protocol.\n- Cannot detect viruses within an encrypted connection.\nFig. 6. Detecting a virus in a downloaded file\nThe danger of secure connections\nAs stated above, both useful and malicious information can be transmitted via network connections. Standard solutions protect computers against threats present in standard network connections, but aren’t able to counter threats present in secure connections. Verifying the contents of a secure connection is impossible by virtue of its secure nature, as demonstrated by the different types of protection listed above. As a result, malicious data within secure channels can cause a significant amount of damage, and sometimes more than if it were to be transmitted via a standard, non-secure connection.\nThe fact that it’s easy to encrypt a network channel and the fact that in most cases there will be no verification of who created the file results in a contradictory situation: a “secure connection” to a server provides the user with a feeling of security, but does not guarantee that the connection will be free from malicious data.\nThe dangers inherent in “secure connections” are particularly apparent now as such threats are becoming more and more widespread. After developers ensured SSL/TLS support for all popular web applications, a number of servers on the Internet began to offer their services via SSL/ TLS: together with major banking sites, all the big-name email services and partner sites opened access exclusively via secure connection. The qualifications of administrators of such servers is often barely enough for them to configure a secure server connection correctly.\nThe situation is exacerbated by the fact that an attack on a computer can be carried out remotely – for example, by simply placing a malicious file on a server which can be reached only via a secure connection.\nA few examples can be found below.\nGmail and viruses\nThe popular email service Gmail offers access to its services exclusively via secure connection. It is known that Gmail servers use an antivirus program. Now let’s consider some hypothetical situations:\n- A virus writer sends his virus to a Gmail subscriber.\n- Gmail’s antivirus doesn’t detect the virus, because the antivirus database update has been delayed.\n- After a certain time the user downloads the infected email from a local computer, because the Gmail antivirus has been optimized, resulting in emails being scanned only once they reach the inbox, and not when they are transmitted to the user.\n- The antivirus program on the local computer, which has already updated its database to include the relevant signature, does not detect the virus since the network connection was encrypted in line with Gmail requirements, and the email antivirus was not able to scan the email.\n- The file antivirus detects the virus in the email database and indicates that the entire email database should be deleted, since it is often impossible to disinfect an email database.\n- Result: the user will lose all his correspondence.\nWeb servers and viruses\nAn equally interesting example: a malicious user can upload a malicious file to a web server and then attract Internet users to visit that server. If the virus is placed on a regular HTTP server, a computer with antivirus software will not be in any danger. However if the virus is placed on an HTTPS server the situation is a little more complicated:\n- A virus writer can use a vulnerability to access files stored on a server (e.g. the case of the Valuehost servers, run by a Russian provider) and can replace files with the virus.\n- A user opens a familiar website with a standard browser using HTTPS. The web antivirus cannot read the data in the encrypted connection and cannot prevent infected files from being downloaded.\n- Instead of a normal web page, the browser loads a virus which exploits a browser vulnerability. The virus will instantly execute its code within the browser. The file antivirus cannot block the execution of the malicious code, because the infected file is processed by the file antivirus only after it has been saved to disk i.e. in this case after the malicious code has been executed.\n- Result: the computer is infected.\nIn order to check data transferred via a secure connection, most antivirus developers offer plug-ins for web applications. This approach has its pluses and its minuses:\n- The data stream between client and server is not affected\n- The data stream cannot be accessed by third parties\n- It’s impossible to create a plug-in for certain applications. One key example: Outlook Express, the most common email program.\n- There are limitations on using plug-ins, for example MS Outlook.\nFig. 7. An antivirus plug-in for Microsoft Office Outlook\nAn alternative to using plug-ins is checking traffic using a man-in-the-middle method, which overcomes the negative aspects of plug-in architecture. Although it does have its drawbacks, antivirus vendors have been forced to implement this approach in order to protect their users.\nThis method is an attack on the essence of SSL/TLS, since it intercepts the secure connection, substitutes the original certificate and establishes two secure connections: between the application and the proxy antivirus, and again between the proxy antivirus and the remote computer.\nFig. 8. A standard secure connection\nFig. 9. A secure connection being scanned\n- Connections can be scanned for any client application.\n- Connection can be scanned for viruses under any known protocol.\n- In addition to antivirus scanning, the proxy can conduct all other data operations, scanning for phishing, spam, etc.\n- The data stream cannot be viewed by a third party unless s/he conducts a man-in-the-middle attack.\n- The data stream between client and server is modified. As a result:\n- Web applications cannot verify the authenticity of a server;\n- A server cannot verify the authenticity of a client;\n- If the proxy does not carry out its own verification, a second man-in-the-middle attack (between proxy and server) could be conducted. This could be done by a malicious user in order to read and modify data.\nIn practice, traffic scanning does not present any real danger to the user. Scanning is conducted on the local machine; the user can be asked to make choices, and all remote certificates can be verified by antivirus software and certificate archives, just as is done by web applications.\nThe drawbacks of the man-in-the-middle method are more than compensated for. The computer will be totally protection against threats on all types of network connections.\nKaspersky Internet Security\nKaspersky Internet Security includes solutions that verify both types of secured connections:\n- Plug-ins for web applications:\n- MS Outlook,\n- IE ScriptChecker\n- Verification of secured connections in traffic using man-in-the-middle method:\n- Kaspersky Internet Security informs the user of all actions:\n- Notifies the user about server certificate substitutions\n- Verifies certificates received from a server in the Windows certificate archives in exactly the same way as web applications\n- The final stage of the man-in-the-middle method is not included. Registering a substitute certificate in the archives of trusted certificates has to be conducted by the user\n- Kaspersky Internet Security provides the option to disable the checking of certain connections (configuration options: applications / servers / ports.) This solves any questions which could arise about the correct functioning of services which check the authenticity of the client.\n- Kaspersky Internet Security checks all possible parameters within secure connections:\n- The web antivirus component detects viruses in browser traffic\n- The email antivirus component detects viruses in email traffic\n- The anti-phishing component detects fake websites and links to these sites\n- The antibanner component blocks pop-ups\n- The antispam component blocks unwanted correspondence\nFig. 10. Detection of the eicar test file within a secure browser connection\nSecure connections are designed to protect data against modification and theft. However, today, secure connections do not provide real protection against network attacks, and are therefore not as secure as they may seem.\nInterestingly, the term secure connection may mislead users by creating a false sense of security. The situation is further exacerbated by the fact that standard security solutions cannot perform within secure channels.\nSpecial methods have to be used in order to provide total protection against network threats. The simplest and most obvious solution is to use a plug-in for web browsers. Unfortunately, plug-ins are not universal, and many applications do not support them or impose too many restrictions on their functionality. Another solution found by antivirus manufacturers involves traffic verification.\nThe dangers of secure connections should not be underestimated. When you make important decisions about your computer’s security, make sure that your antivirus solution provides real protection against all network threats.", "label": 1}
{"text": "MalwareBy Gina on November 18, 2010 | Malware\nNovember is the month of hackers that designed bunch of rogue anti-spyware programs for different Operating Systems. They are spread all over the web and confuse computer users because the main goal of theirs is to trick users into believing that computer is severely compromised. Fake AV is designed to pilfer money from unwary users. They download and install itself automatically without user’s knowledge and consent. Read more.By Gina on October 19, 2010 | Malware\nA mistrust seed in Kaspersky is sowed. Few comments in Kaspersky Lab forum state that the site of this major computer security company is compromised by cybercriminals. It seems like hackers try to spread fake security software.Fake AV malware are designed to fool users into thinking that they are legitimate antivirus applications. As such, they usually pretend to scan systems prevent certain applications from executing, display warning messages, and connect to adult sites. Read more.By Gina on September 29, 2010 | Malware\nStuxnet worm is one of the most dangerous worms ever. It is able to infiltrate itself in a computer even after it has been already cleaned from the machine. Worm usually targets computers that are used in nuclear plants and other industrial facilities.Stuxnet has proven it is a piece of headache for the security researchers and analysts because it could affect four flaws that were undiscovered and unpatched. Read more.By Gina on August 30, 2010 | Malware\nAccording to Panda’s report, 25% of worm based malware spreads through the USB drives. Even more, most of viruses are designed to spread via USB drives. Security Company confirms that cybercriminals are very persistent and put a lot of efforts to make user’s life impossible. 25% of latest created malware are configured to enter the system through portable storage devices, usually USB drives. Read more.By Luciana on August 11, 2010 | Malware\nIf there's the Android OS on your phone and your bills started to skyrocket, you may have the first Android trojan. The incredibly popular OS made by Google couldn't be left out by cyber criminals. What's the hype about and how can you avoid the mess?The first trojan for Android Smartphones is called Trojan-SMS.AndroidOS.FakePlayer-A. It poses as a video player and it has to be installed manually. Read more.", "label": 1}
{"text": "Keep Passwords Strong, Secret, and Safe\nIn early 2009 more than 30 high-profile accounts on social-messaging site Twitter were compromised, including those of President Barack Obama and Britney Spears. A weak password on a Twitter employee's computer caused the security breach—a hacker used dictionary attack software, which systematically tries all words in the program's \"dictionary,\" beginning with commonly used ones such as names and places, until it discovers a computer's password or exhausts its list.\nThis hacker's program discovered the Twitter employee's password and used administrative tools on the computer to reset passwords on the high-profile accounts. Then, in an online forum, the hacker offered anyone access to the accounts upon request.\nHow could the Twitter employee have foiled the dictionary attack? By creating a robust password and guarding it from unauthorized access. Dictionary attacks are only one way unscrupulous people steal passwords and commit malicious acts on unsuspecting consumers, and the consequences can be far more serious than having people open your Twitter account. (Although sending fake messages as President Obama could be quite serious, fortunately the scam was discovered before that happened.)\nThe point is, it's vital that you keep your computer's content secure by creating strong passwords, keeping them secret, and keeping track of them. A compromised password could lead to identity theft or other dire consequences. A criminal could use your information to apply for credit cards or mortgages, or to make online purchases or other transactions.\nCreate strong passwords\nThe first rule of thumb is to use a different password for each of your accounts. It may be easier to keep track of just one password, but if a crook discovers that one password, he or she can access all of your accounts. This tip has been well publicized, but the Accenture consultancy's survey of 800 U.S. and U.K. consumers revealed that 88% use just one, universal password.\nThe second key to a robust password is to make it lengthy. According to a Microsoft spokesperson, each character you add to your password increases the protection it affords many times over. At a minimum, your passwords should be eight digits long, and 14 digits or more is ideal.\nA compromised password could lead to identity theft or other dire consequences.\nUsing the greatest variety of characters possible in your passwords—letters, numbers, symbols—makes them harder to guess or uncover with malicious software. Microsoft's spokesperson says the fewer types of characters you use, the longer your password needs to be—if you use only letters and numbers make it 15 characters long.\nConsider using words and phrases you can remember, but that others wouldn't guess. You can use the first letter of each word in a sentence, plus some numbers, mix upper- and lowercase, and include some misspellings and symbols. Here's one example: \"I went to Hawaii in August 2009 with Bob,\" becomes \"iWThI082009wB.\" Include a few symbols and it's \"!WT*h;I082009w%B:.\" (The exclamation point substitutes for \"I\" and the randomly selected symbols bracket \"Hawaii\" and \"Bob.\") Who would ever guess that one? You can also substitute numbers for letters: \"hate\" becomes \"h8.\"\nAfter creating your password, you can test its strength with one of the \"password checkers\" available online such as Microsoft's Password checker and The Password Meter. If your password tests as weak, make it more complex.\nSome password don'ts include:\nKeep passwords secret\nOf course, the strongest password is useless if you share it with others, so guard yours closely. Don't reveal your passwords to family or friends. Children, particularly, may unwittingly pass them on to others, Microsoft's spokesperson reminds.\nYou shouldn't type passwords into public computers, such as those at libraries or in hotel lobbies. Even if you instruct the computer not to save the password, there could be malicious software on the computer that records your keystrokes for a criminal's use.\nAlso, you shouldn't send passwords via e-mail—it isn't a secure delivery channel—and you shouldn't enter a password if requested to do so via an e-mail.\nIf you see suspicious activity, notify the authorities and contact your credit union for help.\nDon't store a list of your passwords on your computer—that would be a goldmine to a crook. Microsoft's spokesperson says it's safer to record your passwords on paper, and then hide the paper where others won't find it. Make sure it's a location you'll remember, though. What about between the pages of a book on your shelf? Another idea is to store the word file on a thumb drive and hide the thumb drive, says Ian Forkash, an information technology manager for the Credit Union National Association in Madison, Wis.\nIf you add encryption software to your computer, which codes information for privacy, you can store passwords there. Some versions of the software are available at no charge, such as a limited version of RoboForm for Windows. There's a fee for more comprehensive programs, such as Symantec's Endpoint Security.\nKeep track of passwords\nSo, how do you remember your many passwords? Your secret list is one way, of course. And using a familiar phrase when creating the passwords, as described above, is another.\nConsumer Reports suggests developing a couple of basic passwords you can memorize, and then adding different prefixes or suffixes to them for different accounts or Web sites, or scattering different symbols throughout.\nThen, on your password list, you can write down just the add-ons and where they appear in the password. For example, if you add an asterisk as the second character in the password for one account, on your list you can just write: 2*.\nDon't store a list of your passwords on your computer—that would be a goldmine to a crook.\nVince, who lives in Louisiana, uses a consistent approach to make his passwords memorable. \"I use a combination of the Web site's name, along with recognizable information,\" he says. \"For Yahoo, my password could be the first three letters of Yahoo, the first three letters of my pet's name, and the number of my birth month. So, my password for Yahoo might be: yahspo04. This way my password is always different, but still is easy enough to remember.\" Vince was one of several Home & Family Finance Resource Center's What's Your Story respondents.\nStephanie, from West Virginia, has another approach. \"I have a good memory for numbers and things such as passwords, so I can typically remember many of them. But when I first change my password, I enter it in my rolodex as a code,\" she recounts. \"Say my user name is 'username,' I would put down 'un.' If my password is 'password1,' I would put down 'pw1.' If I enter a year behind a password like 'password2009,' I would write down 'pw yr full.' Full means I've used a four-digit number instead of two.\" (Of course, Stephanie would want to use a combination of various characters rather than words that appear in dictionaries.)\nWhen it comes to password storage, Catherine, from California, has a creative method. She uses a set of small index cards, hole-punched at the corner and attached to a metal ring made for organizing papers. \"Every time I sign up on a new Web site I write its name on a card, along with the user name and password and other relevant information,\" she says.\nShe stores the cards in a safe place that she can remember. \"The cards are small enough to drop in my bag, and easy enough to hide from prying eyes,\" she says. \"It works very well for me.\"\nPaul, from New Mexico, stores his online. \"I use the Secure Login add-on available for the Firefox Web browser,\" he explains. \"It uses one master password to give you automatic access to an encrypted database containing all your individual passwords.\"\nTake action if someone gets your password\nIf, despite your best efforts, your password is compromised—possibly through a security breach at a business—don't panic. Monitor all the information you protect with that password, such as online shopping accounts or investment accounts, and request free copies of your credit reports from the national credit bureaus.\nUsing a variety of characters in passwords—letters, numbers, symbols—makes them harder to guess or uncover with software.\nIf you see suspicious activity in any of these places, notify the authorities and contact your credit union for help. If you're a victim of identity theft, the Federal Trade Commission's Web site includes information about what steps to take. But remember, the stronger your passwords, the less likely this is to happen.\nHome & Family Finance® Resource Center", "label": 1}
{"text": "Data protection and identity theft\nThe Data Protection Act controls how your personal information is used by corporations or the government. Its rules require everyone who collects data to follow strict rules, and to keep your information safe. This page explains how it works.\nProtecting your information\nThe Data Protection Act's rulesare quite complex, but at the heart of it are eight common sense rules known as the 'data protection principles'.\nThese principles require any organisation, corporation or governmental body that collectspersonal information to handle it safely. Anyone collecting personal information must:\n- fairly and lawfully process it\n- process it onlyfor limited, specifically statedpurposes\n- use the information in a way that is adequate, relevant and not excessive\n- use the information accurately\n- keep the information on file no longer than absolutely necessary\n- process the information in accordance with your legal rights\n- keep the informationsecure\n- never transferthe information outside the UK without adequate protection\nAll organisations collecting and using personal information are legally required to comply with these principles.\nThe law provides stronger protection for more sensitive information - such as your ethnic background, political opinions, religious beliefs, health, sexual life or any criminal history. It is enforced by an independent information commissioner, who can take action against any company or governmental body that fails to protect your information, or that abuses its right to collect and hold that information.\nFinding out who knows what about you\nThe Data Protection Act gives you the right to find out what information about you the government and other organisations store. This is known as the 'right of subject access'. If you submit your request in writing, they are legally required to provide you with a copy of all the information they hold about you.\nSome agencies or corporations may charge a fee for providing the information, but they are only allowed to charge up to 10 for digital information, or 50 for printed (i.e. non-electronic) medical records. Finding out what information about you credit reference agencies hold costs 2.\nStopping direct marketing\nSome people resent the way companies and government agencies contact them directly by phone, post or even fax. You have the right to stop these direct marketing campaigns from using your personal information to contact you.\nAll you have to do is register your details with one of the 'preference services', which allow you to opt out of direct marketing altogether.\nThe links below offer more information about how you can opt out\nThis content is subject to Crown Copyright", "label": 1}
{"text": "Protecting Our Ports\nData devices that plug into computers make many jobs easier, but they can expose networks to attacks.\nAll it takes is one thumb drive or other external data device plugged into a computer to jeopardize the security of information on federal networks. Army officials learned that lesson the hard way in November 2008, when a removable storage device plugged into a computer's Universal Serial Bus port introduced a worm that spewed malicious code across the network. The Defense Department has remained mum on the specifics of the attack, but hackers have used similar types of malware to take control of computers remotely and steal files.\nNow other agencies are trying to find ways to protect their data without sacrificing productivity. External storage devices that plug into a USB port have become ubiquitous in federal government. Employees use thumb drives and handheld computers to transfer files that are too large to e-mail or send over a network, or store documents while working remotely without network access. Military members in the field use flash drives when scarce bandwidth makes it difficult to access critical information on the network.\nThese devices enable employees to do their jobs, but also jeopardize network security.\n\"It's a threat-that's been proven,\" says Pat Howard, chief information security officer at the Nuclear Regulatory Commission. \"It's tough to make the system smart enough to identify what is or is not safe. But you can't say, 'No, you can't do this,' without offering some alternative for meeting business requirements.\" NRC inspectors, for example, often use flash drives when conducting field work.\nTypically, when one talks about the security of removable computer devices, it's in the context of a data breach: An employee downloads from the network sensitive files that are then exposed to unauthorized users, lost or stolen. But that isn't the only risk. Worms and viruses can spread through removable components as easily as through the Internet, and federal cybersecurity requirements don't properly address that risk.\nIn the Army's case, the virus was an AutoRun worm, which installs a file on a thumb drive or other device that is plugged into an infected computer and triggers the Microsoft operating system to execute the worm when the thumb drive is plugged into another computer. Viruses are slightly different, because they require a user to click on an executable file to infect a system. The program then infiltrates the network, as was the case at Army, says Jim Russell, vice president for the public sector at security software company Symantec.\n\"Failure to properly configure [security software] hurts the ability to cleanse the data coming into the network,\" he says. \"With the explosion of these types of devices, the endpoint has become far tougher to manage.\" A 2007 Office of Management and Budget directive provides some guidance for locking down networks by requiring agencies to use a standard set of security settings for the Microsoft Windows operating system.\nBut every infrastructure is different, whether it is for collecting tax information from citizens or sharing intelligence on terrorist suspects, and security policies must address all risks.\nAs of mid-February, the Defense Department still had a temporary ban on removable storage devices. But the USB port is essential for many employees, especially those who spend time in the field.\nThe best strategy for minimizing risk is a combination of tight security policy and multiple layers of protection for the computer network and the removable device.\nFew agencies cover all those bases.\n\"Everyone has a flash drive hanging from around their necks, and there's the capacity for a lot of data to disappear or malware to find its way onto computers-even when the flash drive has been authorized,\" Howard says.\n\"Nothing is certain. Additional controls have to be put in place.\"\nNRC requires all agency files downloaded to a flash drive to be encrypted, and forbids employees from downloading sensitive files to personal storage devices. Long-term plans include technologies that will prevent the download of such files, but for now, Howard has to rely on people to comply and accept the risk that comes with what he calls the \"human element.\"\nTechnology managers must ensure that antivirus and anti-malware software is installed, current and properly configured on all computers.\n\"If you keep patches and antivirus up to date, that's one step to making sure the machines you're working with are a first line of defense,\" says Lou Magnotti, chief information officer at the U.S. House of Representatives.\nAs an alternative to flash drives, House members can use a \"secure vault,\" Magnotti says, that encrypts and stores sensitive documents, such as draft bills and minutes from closed committee meetings, on a network drive that can be accessed remotely. He also is considering purchasing encrypted thumb drives.\nThe interagency Data-at-Rest Tiger Team, which was formed to lead data encryption policy and acquisition efforts, is weighing whether to incorporate anti-malware protection into blanket purchase agreements, says Dave Hollis, director of the tiger team and cyberspace programs for Defense's Information Assurance program. Anti-malware would enable technologists to prevent malicious programs from launching.\n\"Locking all doors and hardening the targets is critically important,\" says Christopher Painter, deputy assistant director of the FBI's cyber division. \"But everyone recognizes that no matter how well you do that, there will be persistent attackers that will get into systems. . . . It's easier to play offense, because you can focus on one hole to get through. In defense, you need to protect everything.\"", "label": 1}
{"text": "Simple Smartphone Safety Tips for Kids\nmobilesecurity.com [London, UK] It’s back to school time again, and despite a natural reluctance to return to the classroom, pupils are keen to catch up with friends and share their news from the summer break. Marian Merritt, Norton Internet Safety Advocate, offers some essential tips for parents who might be sweetening the deal by getting their kids new cell phones or even a first cell phone as part of the school preparations.\n1. Set a password on the phone to lock the keypad and screen when not in use.\n2. Set up parental and emergency contacts on the phone, and show your child how to access them.\n3. Review school cell phone policy with your child.\n4. Discuss not clicking links or replying to unknown callers or text messages.\n5. Set rules for selecting, purchasing new apps and games.\nA smartphone can be a lifeline to safety, a gaming device and an educational tool, and we all have a responsibility to make sure children understand the right way to use these devices. Read all ten tips on Marian’s full article on the Ask Marian page at Norton.com, and find time to sit down and discuss the topic with your children. Let’s all help youngsters understand that smartphones can be great fun when they pay attention to a few simple rules.", "label": 1}
{"text": "Us Online v2 is activity-based learning (K-10) about the safe, ethical and responsible use of digital technologies … interactive learning plus teacher resources about cyber-bullying, privacy and identity fraud, networking and gaming, using the web for research, making and posting content, tagging photos, copyright and sharing, security and passwords, viruses and malware, file-sharing and more.\nNo Bullying Here consists of two modules, each with activity-based learning about bullying, rights, and respect – one for Lower Primary (K-3) and one for Upper Primary (4-6) … with interactive learning and fully resourced Teacher Centres that explore the issues of cyber-bullying, verbal, physical and social bullying.\n- Multiple Intelligence Theory\n- Roar recommendations to Cyber-Safety Inquiry\n- The internet is one giant job resume\n- Tackling the seedy cyber-underbelly\n- Should there be limits on students’ screen time?\n- Did You Know 4.0 [VIDEO]\n- Millenials will make ‘sharing’ a lifelong habit, says Pew study\n- Roar Showcase [VIDEO]\n- Next Generation Learning [VIDEO]", "label": 1}
{"text": "In order to prevent the exposure of confidential data, consider the following measures: securing your computer, monitoring the major identity information sources, preventing unauthorized exposure of your personal information. It is also important to receive frequently updated detailed information on the latest risks, scams, and prevention measures.\nPlatform Windows 95/98/ME\nOperating Systems Windows 95/98/ME,Windows NT/2000,WindowsCE,Windows XP,Windows NT/2000/2003/SBS2003,Windows Vista\nSystem Requirements MS Excel\nDate added 27 Aug 2007\nLast Updated 24 Jan 2011\nTags identity theft risks metrics,identity theft risks scorecard,identity theft risks balanced scorecard,identity theft risks kpi,identity theft risks performance,identity theft risks measure,identity thef", "label": 1}
{"text": "Part 1 – PC Security and Common Sense\nThis article is part one of a two part series on computer security. Part two will feature network security, online security, and encryption.\nIn the good ‘ol days of the Internet, programmers who wrote viruses used to do it for the mischievous sense of accomplishment and respect of their hacker-culture peers. These days, however, viruses and malware are big business for organized crime. What this means for you is that viruses are no longer a nuisance, they are meant to steal valuable information without you ever knowing it. What to do to stop the attacks? Security for your home or office computer network is one of those topics that can go from the very basic to the infinitely complex. For 99% of us, though, a few simple strategies will secure your computer and its data against 99% of the threats you’ll run across.\nYour PC is the destination for all the viruses, malware, keyloggers, trojans, rootkits and any number of other malicious software. The best defense against these threats is AntiVirus software from a reputable vendor. There are several great vendors that offer free versions of their Anti-Virus software. These free versions are only for home use (not office) and may lack some functionality such as scheduled scans or advanced settings, but they use the exact same scanning system as their paid-for counterparts.\nAt MAR’s office we use a product called Vipre from Sunbelt Software. This software is a comprehensive and inexpensive alternative to many of the more well-known vendors out there: http://www.sunbeltsoftware.com/home-home-office/vipre/\nSimilarly, keeping your Windows, Mac or Linux operating system up to date is critical because these updates often block security holes that viruses use to infect your computer. Macs are not necessarily safer than PCs when it comes to viruses, they are just less of a target because they represent less of the market for stolen data. As Mac’s presence grows, so will the number of people making malicious programs to infect the Mac OS. By keeping updated on the latest updates you can protect many of the hidden entrances to your computer.\nAll the security software in the world won’t help you if you leave the front door open. Similarly, an ounce of skepticism when online will do more for your computer security than any antivirus software on the market. A few tips:\nNever open email attachments from unknown senders. A big danger comes around holidays when people start sending emails to “view the attached holiday card”. Criminals know this too, and send viruses as email attachments inviting you to watch the latest Valentines e-card. Similarly, if you receive an email inviting you to view an online birthday card, and it’s not your birthday, be very suspicious.\nBeware of phishing. Phishing is a scam where an email pretends to be from a legitimate source (like your bank, ebay, Paypal, etc) but is actually from a scam website made to look like the legitimate destination. These phishing sites will ask you to “login to verify” some type of information. What they are really doing is recording the username and password to your REAL bank website. Keep in mind that all banks are aware of this scam and will never ask you to “login to verify” or “login to update” anything using links in an email. If you suspect an email is legitimate the safest way to approach it is to open a new browser (Internet Explorer, Firefox, etc) and type in the address of the site you want to visit. Never use a link in an email message to any sensitive website because it’s very difficult to see where you’re actually going to end up. By typing in the address for BankOfAmerica.com you can rest assured you will end up at the actual BoA website.\nBeware of “Fake” Antivirus and other free software. A scourge of the Internet is pop-up ads that warn you of a virus on your computer, and then invite you to download a free utility to clean out the infection. Quite often these programs actually install viruses on your PC instead of clean them. One of the most notable examples of this is the “Antivirus 2009” virus which sports graphics and layout very similar to Windows. It runs fake scans on your computer, shows you fake infections, and then downloads real viruses to your PC. The best way to avoid these maladies is to never use a pop-up ad to visit a website or purchase a product because you can’t be sure of the source of the pop-up.\nA real-life equivalent might be walking down the street when a complete stranger asks you if you want a free gold watch. All you have to do is walk with this stranger into a dark alley to receive your prize. Would you do it?\nOther free software such as games, screensavers, and search toolbars often contain adware, which is a less-malicious form of software meant to show you pop-ups even when you aren’t browsing the Internet. This software can sometimes be a doorway to other more unsavory programs, so be very cautious about the source of your next screensaver of puppy pictures.\nLike I said at the beginning, computer security is one of those topics you can follow to an extreme degree. Many specialists devote their lives to securing large company networks against those who devote their lives to breaking in. You have advantages on your side, though. As an end user you are not likely to be the target of a serious hacker; your relative anonymity will protect you to a certain degree. What you should worry about are the automated programs designed to trick you into letting them inside. Luckily these programs are not yet as savvy as live criminals at the digital con game. Using just a few of the techniques I’ve outlined can go a long way toward keeping you, and your most personal data, safe.\nThis article is part one of a two part series on computer security. The state of Massachusetts is currently reviewing regulations that would enforce strict new requirements on data security and the privacy of client data at many businesses across the state. The final requirements of the law, however, are still in flux. The MAR is watching the proposed regulations closely and will provide tools and resources to help you and your business comply. In the meantime, good security practices should be a part of everything you do online whether at home or in the office.", "label": 1}
{"text": "What is a limited user account?\nA limited user account in Windows gives specified users the ability to only utilize certain programs and functions on their computers. People with limited user accounts are also unable to download or delete certain applications on their computer or while online.\nThere are a number of reasons and benefits for setting up limited user accounts, including:\nIncreased security. Even with firewall and anti-virus protection, harmful malware can still find its way onto a computer. This is especially true if users are downloading programs such as active x or visiting sites that install spyware while surfing the net. With the limited access limited user accounts provide, the likelihood of malware on the computer is much lower.\nAdded protection. Because users with a limited user account are unable to delete or add applications and programs, computer owners can have the confidence of knowing the computer will remain undefiled.\nWhat can you do with a limited user account?\nLimited user accounts still allow users to do pretty much everything needed to run their computer and complete day-to-day tasks. Some of the things users can still do, even with a limited user account, include:\nUse programs like Microsoft Word, Excel, and Power Point.\nUse programs that allow users to listen to music or edit photographs\nSurf the Internet and send and receive emails\nChange the passwords and pictures on the account\nWhat can you not do with a limited user account?\nThere are a number of things, as the name suggests, that users who are on a limited user account can’t do. Some of these things include:\nInstall software or hardware. New software and hardware programs must be installed by an administrator on a limited user’s account.\nChange the name or account type. Users with a limited user account on Windows are unable to change their name. In addition, they can’t change the account type (such as removing the limited user account status).\nDownload certain applications from the Internet. Limited user account users are unable to download specific Internet applications and programs. This helps protect the computer and system from malware.\nSetting up a limited user account\nYou can set up as many limited user accounts as you need to for your employees or family members. To set up a limited user account, follow these steps. Note: You must be an administrator or have administrator rights in order to set up limited user accounts.\n1. In Windows, click Start, and then select the Control Panel option.\n2. Click on User Accounts. A number of selections will come up. Select Pick a Task, then Create a new account.\n3. The Action menu will come up. Select New User.\n4. Type in the user’s name, then click Next.\n5. Under Pick an account type, select Limited User, and then click Create account.\n6. Your user will be able to select his or her own password and pictures.\nLimited user accounts are helpful for employers and are a good way to protect your computer, information, and system from the threat of being hacked or from malware being installed on your computers. If you have problems or questions setting up you limited user accounts, the Windows website is very helpful.", "label": 1}
{"text": "By David Keaton,\nThe CERT Secure Coding Program\nBuffer overflows—an all too common problem that occurs when a program tries to store more data in a buffer, or temporary storage area, than it was intended to hold—can cause security vulnerabilities. In fact, buffer overflows led to the creation of the CERT program, starting with the infamous 1988 “Morris Worm” incident in which a buffer overflow allowed a worm entry into a large number of UNIX systems. For the past several years, the CERT Secure Coding team has contributed to a major revision of the International Organization for Standardization (ISO) and International Electrotechnical Commission (IEC) standard for the C programming language. Our efforts have focused on introducing much-needed enhancements to C and its standard library to address security issues, such as buffer overflows. These security enhancements include (conditional) support for bounds-checking interfaces, (conditional) support for analyzability, static assertions, “no-return” functions, support for opening files for exclusive access, and the removal of the insecure gets() function. This blog posting explores two of the changes—bounds-checking interfaces and analyzability—from the December 2011 revision of the C programming language standard, which is known informally as C11 (each revision of the standard cancels and replaces the previous one, so there is only one C standard at a time).\nI work on the CERT Secure Coding team, where I’ve made technical contributions to the definition of the new C features for addressing security. I’ve also chaired Task Group PL22.11 (programming language C) of the International Committee for Information Technology Standards (INCITS), representing the United States. Working with SEI colleagues Robert C. Seacord and David Svoboda, I helped develop, refine, and introduce many of the security enhancements to this major ISO standard revision.\nBounds Checking Interfaces\nUntil the latest update of the C standard, its security features had been limited to the snprintf() function, which was introduced in 1999 and whose implementations have some quirks. Previous iterations of the C library contained functions that did not perform automatic bounds checking. Instead, C library implementations assume programmers provide output character arrays that are large enough to hold the result and return a notification of failure if they were not large enough.\nThe C standard now includes a library that provides extensions that can help mitigate security vulnerabilities, including bounds-checking interfaces. For example, the strcpy() copy function in previous versions of the standard C library did not check the bounds of the array into which it was copied. A buffer overflow will occur, therefore, if a programmer uses strcpy() to copy a larger string into a small array and does not explicitly check the bounds of the array prior to making the call to strcpy().\nOne remedy to the strcpy() problem is to use the strncpy() function, which provides bounds, but won’t terminate the string with a null character (whose value is 0) if there’s insufficient space. Situations like this create a vulnerability because data can be written past the end of the array, overwriting other data and program structures. This buffer overflow vulnerability can be (and has been) misused to run arbitrary code with the permissions of the defective program. If the programmer writes runtime checks to verify lengths before calling library functions, then those runtime checks frequently duplicate work done inside the library functions, which discover string lengths as a side effect of doing their job. The new bounds-checking interface provides strcpy_s(), a more secure string copy function that not only checks the bounds of the array that it is copying into, but also ensures that the string is terminated by a null character.\nAnother aspect of the C programming language we focused on in C11 is analyzability, which deals with so-called “undefined” behavior. Undefined behavior arises when a programmer uses a nonportable or erroneous program construct or erroneous data for which the C standard does not impose a requirement. The C standard includes several areas of the C language with undefined behavior because behavior of those areas depends on compiler implementation details. An example is signed integer overflow. Different hardware behaves differently on signed integer overflow, so trying to make the language mandate one method of dealing with it would negatively affect performance on some systems because the standard behavior would not match what the hardware does.\nThere are many areas in which the standard makes accommodations for various kinds of hardware, and they are all lumped together into the undefined behavior category. Since the C standard doesn’t constrain how a compiler implements undefined behavior, it could conceivably do anything, such as cause the machine to halt and catch fire, though compiler writers who do this might not find many professional programming customers!\nWe examined this issue and realized that in practice, there are two categories of undefined behavior:\n- behavior for which we really cannot say what will happen, such as storing data outside the bounds of an object, and\n- behavior where the implementation really should do something reasonable, such as signed integer overflow\nWe created the Analyzability Annex in C11, in which we labeled the former behavior \"critical undefined behavior,\" indicating that the consequences could be serious. The latter category we called \"bounded undefined behavior,\" because we can say with certainty that nothing unpredictable should be allowed to happen as a result.\nThe category of critical undefined behavior is a small subset of undefined behavior, which means that most undefined behavior becomes bounded. We didn't have to change the spirit of the C language to do this, because all we did was specify that bounded undefined behavior is not allowed to store data outside the bounds of an object. In the example of signed integer overflow, this means the compiler runtime implementation could choose to return some reasonable result, cause a trap that terminates the program, or simply print a message and move on. As long as it does not perform an out-of-bounds store, anything is permissible.\nThe bounding of undefined behavior allows analysis tools to know that a C program will not have unpredictable behavior except in a very small set of circumstances, which is why we called it the Analyzability Annex.\nOther Areas of Research\nWhile our work to date has focused on the ISO C standard and helping programmers prevent critical undefined behaviors, the CERT secure coding team has also been working on the CERT C Secure Coding Standard, which contains a set of rules and guidelines to help programmers code securely. Those guidelines, which will be the subject of an upcoming blog post, leverage our work on the ISO standard to help programmers avoid undefined behavior, as well as behavior that programmers might not have expected when writing their code.\nThe CERT C Secure Coding Standard also serves as a foundation for the Source Code Analysis Lab (SCALe), which is our software auditing service that can be used to find vulnerabilities and weaknesses in any codebase. SCALe uses a suite of static analysis and dynamic analysis tools to find vulnerabilities in a codebase, based on the patterns and guidelines defined in the CERT C Secure Coding Standard.\nFor more information about the new ISO standard for the C programming language, please visit\nThe C standard is available for purchase in the ANSI Web Store.\nFor more information about the work of the CERT Secure Coding Team, please visit\nFor more information on the CERT Source Code Analysis Lab (SCALe), please visit", "label": 1}
{"text": "Lifehacker's tech-savvy readers are the first people on speed-dial when it's time to heal an infected PC, but how much do you really know about viruses, spyware, scareware, trojans, and worms? Here's a helpful guide to understanding all the different types of malware.\nThe point of today's lesson, of course, is to help you teach your friends and family more about the different types of malware, and debunk a few of the common myths about viruses. Who knows, maybe you'll learn a thing or two as well.\nWhat is Malware?\nThe word Malware is short for malicious software, and is a general term used to describe all of the viruses, worms, spyware, and pretty much anything that is specifically designed to cause harm to your PC or steal your information.\nViruses Wreak Havoc On Your Files\nThe term computer virus is often used interchangeably with malware, though the two don't actually have the same meaning. In the strictest sense, a virus is a program that copies itself and infects a PC, spreading from one file to another, and then from one PC to another when the files are copied or shared. Image by Joffley\nMost viruses attach themselves to executable files, but some can target a master boot record, autorun scripts, MS Office macros, or even in some cases, arbitrary files. Many of these viruses, like CIH, are designed to render your PC completely inoperable, while others simply delete or corrupt your files—the general point is that a virus is designed to cause havoc and break stuff.\nYou can protect yourself from viruses by making certain your antivirus application is always updated with the latest definitions and avoiding suspicious looking files coming through email or otherwise. Pay special attention to the filename—if the file is supposed to be an mp3, and the name ends in .mp3.exe, you're dealing with a virus.\nSpyware Steals Your Information\nSpyware is any software installed on your PC that collects your information without your knowledge, and sends that information back to the creator so they can use your personal information in some nefarious way. This could include keylogging to learn your passwords, watching your searching habits, changing out your browser home and search pages, adding obnoxious browser toolbars, or just stealing your passwords and credit card numbers.\nSince spyware is primarily meant to make money at your expense, it doesn't usually kill your PC—in fact, many people have spyware running without even realizing it, but generally those that have one spyware application installed also have a dozen more. Once you've got that many pieces of software spying on you, your PC is going to become slow.\nWhat many people don't realize about spyware is that not every antivirus software is designed to catch spyware. You should check with the vendor to make sure the application you are using to protect you from malware is actually checking for spyware as well. If you come across a PC that is already heavily infected, run a combination of MalwareBytes and SuperAntiSpyware to clean it thoroughly.\nScareware Holds Your PC for Ransom\nScareware is a relatively new type of attack, where a user is tricked into downloading what appears to be an antivirus application, which then proceeds to tell you that your PC is infected with hundreds of viruses, and can only be cleaned if you pay for a full license. Of course, these scareware applications are nothing more than malware that hold your PC hostage until you pay the ransom—in most cases, you can't uninstall them or even use the PC.\nIf you manage to come across a PC infected with one of these, your best bet is to Google the name of the virus and find specific instructions on how to remove it, but the steps are usually the same—run a combination of MalwareBytes, SuperAntiSpyware, and maybe ComboFix if you need to.\nFor more on scareware, including a full walk-through of how a PC actually gets infected in the first place, check out the guide I wrote on removing Internet Security 2010 and other fake antivirus malware.\nTrojan Horses Install a Backdoor\nTrojan horses are applications that look like they are doing something innocuous, but secretly have malicious code that does something else. In many cases, trojans will create a backdoor that allows your PC to be remotely controlled, either directly or as part of a botnet—a network of computers also infected with a trojan or other malicious software. The major difference between a virus and a trojan is that trojans don't replicate themselves—they must be installed by an unwitting user. Image by otzberg\nOnce your PC has been infected with the trojan, it can be used for any number of nefarious purposes, like a denial of service (DoS) attack against a web site, a proxy server for concealing attacks, or even worse—for sending out buckets of spam. Protection against trojans works the same way as viruses—make sure that your antivirus application is up to date, don't open suspicious attachments, and think long and hard before you try and use a downloaded crack for Photoshop—that's one of malware authors' favorite spots to hide a trojan.\nWorms Infect Through the Network\nComputer worms use the network to send copies of themselves to other PCs, usually utilizing a security hole to travel from one host to the next, often automatically without user intervention. Because they can spread so rapidly across a network, infecting every PC in their path, they tend to be the most well-known type of malware, although many users still mistakenly refer to them as viruses. Image by me and the sysop\nSome of the most famous worms include the ILOVEYOU worm, transmitted as an email attachment, which cost businesses upwards of 5.5 billion dollars in damage. The Code Red worm defaced 359,000 web sites, SQL Slammer slowed down the entire internet for a brief period of time, and the Blaster worm would force your PC to reboot repeatedly.\nBecause worms often exploit a network vulnerability, they are the one type of malware that can be partially prevented by making sure your firewall is enabled and locked down—you'll still need an updated antivirus software, of course.", "label": 1}
{"text": "An Australian-led research team said Thursday they had made a technological breakthrough in the race for a quantum supercomputer that could revolutionise data encryption and medicine.\nEngineers make quantum devices at the Australian National Fabrication Facility at the University of New South Wales in Sydney in this undated photo. The Australian-led research team said they had made a technological breakthrough in the race for a quantum supercomputer that could revolutionise data encryption and medicine.\nEngineers from Sydney's University of New South Wales said they had created the first working quantum bit or qubit -- the fundamental unit of a quantum supercomputer -- with the findings published in the latest edition of Nature.\nLead researcher Andrew Dzurak said the team used a microwave field to gain unprecedented control over en electron bound to a single phosphorous atom that was implanted in a silicon transistor device.\nThey were able to both write and read information using the electron's spin, or magnetic orientation, which Dzurak said was a \"key advance towards realising a silicon quantum computer based on single atoms\".\n\"This is a remarkable scientific achievement, governing nature at its most fundamental level, and has profound implications for quantum computing,\" Dzurak said.\nQuantum computing, the next generation in information technology, harnesses the power of atoms and molecules to perform calculations and store data, with the potential to be millions of times more powerful than the most advanced modern computers.\nDzurak's research partner Andrea Morello said quantum computers, which could run one million parallel computations at once compared with a desktop PC's single-computation capacity, could do things that were currently impossible.\n\"These include data-intensive problems, such as cracking modern encryption codes, searching databases, and modelling biological molecules and drugs,\" he said.\nMorello said the study was significant because it was the first time silicon had been used -- a well understood and easily accessed material.\n\"Our technology is fundamentally the same as is already being used in countless everyday electronic devices, and that's a trillion-dollar industry,\" he said.\nThe next step is to combine qubit pairs into a \"logic gate\", which would be the basic processing unit of a quantum computer, a fully functioning model of which is likely still to be five to 10 years off.\nThe research is being funded by the Australian government, the US Army, the New South Wales state government, the University of New South Wales and the University of Melbourne.\nLatest stories in this category:\n- 'Kill Mittal' game capitalises on French workers' struggle\n- Facebook joins Web freedom group\n- Solar plane aims for new world distance record\n- Sony board examines hedge fund spin-off plan\n- Risky behaviour starts young on social media: survey\n- Teens share more online, see privacy issues: study\n- China arrests 13 over protest 'rumours'\n- Sprint lifts bid for Clearwire in broadband battle", "label": 1}
{"text": "What is a service-oriented architecture?\nFor completeness we include two different definitions, one from W3C: “A set of components which can be invoked, and whose interface descriptions can be published and discovered.”\nAnd a second from LooselyCoupled: “A system for linking resources on demand. In an SOA, resources are made available to other participants in the network as independent services that are accessed in a standardized way. This provides for more flexible loose coupling of resources than in traditional systems architectures.”\nWhat are Web Services?\nFor completeness we include two different definitions, one from W3C: “A Web service is a software system designed to support interoperable machine-to-machine interaction over a network. It has an interface described in a machine-processable format (specifically WSDL). Other systems interact with the Web service in a manner prescribed by its description using SOAP, typically conveyed using HTTP with an XML serialization in conjunction with other Web-related standards.”\nAnd a second from LooselyCoupled: “Automated resources accessed via the Internet. Web services are software-powered resources or functional components whose capabilities can be accessed at an internet URI. Standards-based web services use XML to interact with each other, which allows them to link up on demand using loose coupling.”\nWhat is Web Services Management?\nWeb Services Management is a title used by the Gartner group to describe a market for solutions that facilitate the deployment of Web services. The term has become very broad and encompasses a wide range of different capabilities, implemented to varying degrees by a number of vendors.\nAt a minimum, Web Services Management solutions provide service performance and availability monitoring, often extending to provide service level agreement (SLA) monitoring.\nSome solutions build on monitoring to provide management and enforcement of service level agreements. While others focus on Web Services Security management and enforcement.\nSOA Software offers comprehensive monitoring and management (including very advanced identity-based SLA contracts, the strongest Web Services Security solution on the market, and extends the concept of Web Services Management with a powerful SOA Enablement solution.\nThe OASIS standard WS-Security is defined by LooselyCoupled as a Standards framework for secure web services, based on SOAP. WS-Security defines additional headers that can be added to a SOAP message to implement integrity and confidentiality in web services applications. It provides a foundation for further security specifications that are under development, including WS-Policy, WS-Trust and WS-Federation. Originally put forward by IBM, Microsoft and Verisign, WS-Security became the responsibility of the OASIS e-business standards body in July 2002.\nAs a market, Web Services Security refers the set of technology solutions that enhance security, including authentication, authorization, privacy, non-repudiation and auditing, for Web services. These solutions are available in many forms ranging from XML Firewall appliances through enterprise software solutions from many different vendors.\nSOA Software offers a best-of-breed enterprise software solution for Web Services Security. SOA Software ’s advanced software delivers performance that exceeds that of many of the XML firewall appliance solutions. It also delivers much richer security from network edge to core.\nService oriented architecture enablement, or as Zapthink discusses, the SOA Implementation Framework, is an emerging technology concept that goes beyond Web Services Management to unlock the value of Web services. The promise of Web services is to enable the agile enterprise through service reuse within a service oriented architecture.\nWithout an SOA enablement solution, much of this promise falls by the wayside as developers are unable to comply with changing security and management policy and cannot keep track of changing service interfaces and locations.\nSOA Software’s industry-leading Service Manager delivers a comprehensive SOA enablement solution that offers all the capabilities of traditional Web Services Management solutions and adds:\n- Dynamic discovery and real-time implementation of service requirements for security:\n- Message auditing\n- Dynamic discovery of, and binding to, service location\n- Powerful load-balancing and high-availability\n- Real-time monitoring and enforcement of identity-based service level agreement contracts\n- An adaptive, self-healing network of services\nIn short, the Service Manager fully abstracts service and application developers from any required knowledge of central management and security policy.\nWhat is the difference between ESB, XML Firewall and Web Services Management providers?\nAt a high level there is very little difference. SOA Software believes that the distinction between these terms, and the terms themselves are transitory. To clarify, the terms exist as a result of different market sectors approaching the common problem of Web Services Management, or SOA Enablement; the EAI companies created ESB to highlight their value as a messaging system while the hardware vendors invented the XML Firewall due to the market’s familiarity with the traditional firewall. As we move forward, SOA Enablement will exist as a ubiquitous fabric that exists to abstract multiple transports, platforms and deployment scenarios.\nFrom www.searchwebservices.com: “Firewalls have long been a mainstay of corporate security - but when it comes to Web services, they may well provide no security at all, because they can only filter at the packet level, and can't examine the contents of messages. Considering that Web services traffic may account for 25 percent of all enterprise traffic by 2006 according to the ZapThink Web services consulting group, that is a serious problem for any business looking to use Web services.\nXML firewalls promise to protect corporations against the unique dangers and intrusions posed by Web services. These firewalls can examine SOAP headers and XML tags, and based on what they find, distinguish legitimate from unauthorized content.”\nMost XML Firewalls are implemented as hardware/software appliances that package Web services intermediary software with a rack mountable server.\nAn intermediary is a server (software or hardware – see XML Firewall) that sits between a web service consumer and provider endpoint. In the case of Web Services Management intermediaries, the intermediary provides varying degrees of security and monitoring functions.\n“A SOAP intermediary is both a SOAP receiver and a SOAP sender and is targetable from within a SOAP message. It processes the SOAP header blocks targeted at it and acts to forward a SOAP message towards an ultimate SOAP receiver.”\nSOA Software’s Management Point is a powerful, extremely high performance software appliance providing rich Web Services Management, Web Services Security and SOA enablement functionality.\nA Service Level Agreement (SLA) provides advanced monitoring capabilities for services and operations to ensure that they meet pre-defined operational requirements.\nSOA Software’s Service Manager implements very rich and powerful SLA monitoring with unique enterprise-class features. The distributed data collection combined with centralized analysis employed by the Service Manager ensures comprehensive, accurate performance monitoring. The Service Manager defines SLA policies that can then be applied by reference or copy to an operation or service. This provides the flexibility to be able to define central performance and availability monitoring policies that, when changed, will affect all services or operations to which they the policies have been applied.\nSLA policies can be defined for many criteria including, throughput, response time, availability, number of errors, etc.\nA contract is an agreement of a set of terms between various parties. The Service Manager uses contracts for various high-value functions. It implements both access contracts and SLA contracts.\nAn access contract is used to define highly granular rule about how a particular user, group or role and can access a service or operation. It can be used to control how many times, how frequently and at what times a user may access a particular operation. For example, the system could only allow a user to use a particular service 10 times per minute during business hours, but unlimited outside those hours. Or a user may only be allowed to use a service 100 times before being denied access.\nAn SLA contract closely models a real-world SLA by monitoring the performance of a service or operation as seen by a particular user, group or role. This allows the creation and monitoring of agreements for different user groups for the same services. For example one group of users may need a contractual commitment that a particular operation will always respond in less than 50ms to its messages, while another may want to guarantee that it will always be able to get more than 400 messages per second through a particular service.\nThese identity-based contracts are a unique feature of the Service Manager, made possible by its tight integration with identity management solutions.\nWhat is the difference between monitoring and management?\nMonitoring is the process of collecting and reporting on data. In the case of Web Services Management, monitoring typically refers to the collection and charting of performance and availability data, and in some cases security (access) data.\nManagement adds enforcement to monitoring. In Web Services Management, enforcement normally refers to security or network enforcement. Security enforcement is the process of authenticating users and making authorization decisions about the users' right to access a resource. Network enforcement is less common and should involve combining content-based routing and message throughput throttling with SLA monitoring.\nThe Service Manager is the only Web Services Management and SOA enablement solution that implements an adaptive infrastructure leveraging this concept of network enforcement.\nWhy do I need Web services management?\nThe promise of Web services is to enable the agile enterprise through service reuse within a service oriented architecture. Without an SOA enablement, or Web Services Management solution, much of this promise fails as developers are unable to comply with changing security and management policy and cannot keep track of changing service interfaces and locations.\nSpecifically, you need SOA Enablement and Web Services Management to:\n- Ensure that application developers are abstracted from service endpoint and infrastructure policy requirements\n- Provide comprehensive end-to-end security\n- Guarantee that services perform to contractually agreed, or policy defined availability and performance metrics.\nWhen should I think about using a Web Services Management system?\nThis is a “how long is a piece of string question”. Depending on the criticality and value of deployed Web services some organization should implement SOA Enablement and Web Services Management before conceiving their first Web services. Other organizations may be comfortable with insecure, unmanaged services for a long period. There is no clear rule of thumb, other than the obvious statement that without Web Services Management and SOA Enablement Web services will not be secure and will likely not live up to application developers performance and availability requirements.\nHow does Web Services Management fit into my existing infrastructure?\nThe Service Manager is completely non-intrusive. It operates using standalone and agent based intermediaries to ensure that messages are authenticated, routed and authorized appropriately. It uses powerful SLA and contract management technologies to dynamically adjust the network to ensure performance and availability without ever requiring a developer to be aware of the fabric.\nHow does Web Services Management Security fit in with my existing security and policy systems?\nThe Service Manager can implement its own user and policy store (commonly used to manage application identities), and/or it can tightly integrate with existing 3rd party identity and policy management systems extend their reach into Web services.\nHow does Web Services Management integrate with existing applications?\nThe Web Services Management solution should integrate transparently with existing client and server applications in order to abstract much of the complexity of security and message delivery and simplify the development task. The Web Services Management solution can be deployed as a proxy that intercepts the Web service calls without any changes to the application code. On Java and .NET applications, the agent can also be deployed with no changes to the application code by making a few simple declarative changes to the environment.\nHow does Web Services Management integrate with new applications?\nThe Web Services Management solution offers a great deal to developers of new applications by providing a fabric that abstracts much of the complexity of security and message delivery and simplifies the development task. Making use of the Web Services Management solution can be done during development or added later as described above.\nHow does Web Services Management & Web Services Security fit into my Netegrity environment?\nWeb Services Security solution will inevitably need to authenticate users and roles and make authorization decisions about granting access to services and operations. It is essential that the Web Services Management and Security solution is able to integrate with an existing identity-management infrastructure for authentication and most authorization decisions.\nThe Service Manager offers the closest integration with Netegrity in the industry. It can either integrate at an intermediary level, or via it’s powerful built-in Policy Manager. When integrating at the Policy Manager it can leverage identity for security and management tasks. See contracts.\nHow do I manage B2B communication?\nB2B communication brings a number of interesting challenges to the SOA, including the requirement to manage Service Level Agreement and provisioning contracts. In addition to this, you need to manage the routing of external requests through your DMZ to your internal applications. A good WSM solution will provide both the means to effectively and transparently route transactions as well as the means to manage the business agreements (SLAs and provisioning contracts) that you have set up with your partners.\nHow do I secure B2B communication?\nB2B communication raises two important security concerns. Firstly the transactions may be occurring over the Internet, resulting in an increased security risk. Secondly, the partner identities and their access rights need to be closely managed. Your WSM solution should therefore provide all the features of an XML firewall, such as:\n- High performance\n- Schema validation\n- Attack prevention\n- Authentication and authorization\n- Centralized policy management\nAdditionally, the WSM solution should be capable of associating partner identities with their provisioning contracts and Service Level Agreements\nDoes Web Services Management provide orchestration?\nBefore answering this question it is important to first describe the concept of orchestration.\nFrom a Hewlett Packard White Paper “Web Services Orchestration - A Review of Emerging Technologies, Tools, and Standards”:\n“The industry has used a number of terms to describe how components can be connected together to build complex business processes. Workflow and document management systems have existed as a means to handle the routing of work between various resources in an IT organization. These resources might include people, systems, or applications, and typically involve some human intervention. Business process management systems (BPMS) have also been used to enable a business to build a tops-down process design model, consisting of various integration activities (e.g., integration to a legacy system). BPMS systems would typically cover the full lifecycle of a business process, including the modeling, executing, monitoring, management, and optimization tasks. With the introduction of web services, terms such as “web services composition” and “web services flow” were used to describe the composition of web services in a process flow. More recently, the terms orchestration and choreography have been used to describe this. Orchestration describes how web services can interact with each other at the message level, including the business logic and execution order of the interactions. These interactions may span applications and/or organizations, and result in a longlived, transactional, multi-step process model. Choreography tracks the sequence of messages that may involve multiple parties and multiple sources, including customers, suppliers, and partners.\nChoreography is typically associated with the public message exchanges that occur between multiple web services, rather than a specific business process that is executed by a single party. There is an important distinction between web services orchestration and choreography. Orchestration refers to an executable business process that may interact with both internal and external web services. For orchestration, the process is always controlled from the perspective of one of the business parties. Choreography is more collaborative in nature, in which each party involved in the process describes the part they play in the interaction. Many of the standards that will be discussed in this paper initially focused on either orchestration or choreography. However, recent enhancements and standards convergence has somewhat blurred this distinction. In this paper, the term web services orchestration will be used to describe the creation of business processes, either executable or collaborative, that utilize web services.”\nWhile some Web Services Management solutions may provide Orchestration and Choreography functions, these would more typically be provided by a Business Process Management solution.\nIs Web Services Management only important if I have a Heterogeneous environment?\nNo, SOA Enablement and Web Service Management adds considerable value to any environment. The concept of abstracting developers from security and management policy requirements in the network and at the service endpoints is independent of development platform. Just because consumer and endpoint applications are both implemented using .NET, or BEA doesn’t mean that they automatically understand each other, and can automatically adapt to changes.\nSOA Software’s Web Services Management solution ensures the performance and availability of services using powerful failover and load balancing technologies combined with industry-leading service level agreement management and monitoring. Essentially, the Web Services Management fabric will detect impending failures or performance problems and will make appropriate routing and throttling decisions to ensure that service levels are maintained for high value or importance transactions.\nWhat is needed to deploy Web Services Management?\nDepending on the Web Services Management vendor, deployment will usually involve some central policy server(s) and software and distributed intermediaries. The intermediaries may be hardware/software appliances, standalone servers running specialized software, or a “agent” deployed with the Web service itself.\nAgain, depending on the vendor, the Web Services Management solution should not be intrusive.\nWhat is the fabric?\nThe fabric is a representation of the Web Services Management and SOA enablement infrastructure. It provides a visual concept that facilitates understanding of what Web Services Management is and does.\nDo I need to change my applications to use Web Services Management?\nDepending on the Web Services Management vendor, the solution should be completely non-intrusive.\nThe Services Manager delivers a fully non-intrusive comprehensive Web Services Management and SOA enablement fabric.\nWhat are the performance implications of Web Services Management?\nThis completely depends on the Web Services Management vendor and the architecture of the complete solution. The functions of Web Services Management; security, monitoring, enforcement, enablement, all need to be done somewhere in an SOA. A well-architected solution will externalize these functions from the applications to ensure consistent application of policy.\nThe Service Manager is an extremely high performance solution. In monitor mode, the Management Point operates at zero-latency (any added latency is not measurable). In intermediary mode where is it enforcing management and security policy it has been tested under heavy load and demonstrated sub millisecond latencies. To put this into perspective, most Web services themselves will operate with 100-200 millisecond response times, some taking several seconds to respond. In this environment, the Web Services Management fabric is increasing latency by less than 1/10th of a percent.\nFurthermore, a well-architected Web Services Management solution will constantly monitor performance and will increase the perceived performance of the Web services network through intelligent routing.\nDynamic binding is the process whereby a Web service consumer discovers the location (and in some cases the policy requirements) of a Web services immediately prior to invocation and connects to it based on this up-to-date information.\nDynamic binding is essential for the functioning of an agile enterprise. Without dynamic binding service consumers will use hard-coded endpoint information and will fail in the event of any change being made to the service endpoint.\nHow can I make my Web services secure?\nThere are many approaches to securing Web services. The Service Manager implements one of the most secure and flexible approaches by deploying agent-based intermediaries with each Web service, and forcing all messages to pass through the intermediary for authentication and authorization.\nHow can I make my Web services reliable?\nThe Service Manager’s approach to Web Services Management delivers powerful failover and load-balancing technologies to ensure service availability. As the solution begins to detect performance or availability problems it will automatically adjust traffic to ensure that high-priority messages are delivered and alert administrators to impending problems.\nHow can I make my Web services transparent?\nThe Service Manager implements powerful dynamic discovery capabilities to fully abstract consumer applications from any knowledge of service endpoint location, or fabric policy.\nHow do I expose services on Mainframe and AS/400 systems?\nExposing services on Mainframe and AS/400 systems is not the problem, there are many technologies and companies that do just that. The challenge is to do it in a way that ensures security and protects the mainframe and AS/400 systems from denial-of-service attacks.\nThe SOA Software Mainframe and AS/400 solution package delivers a powerful combination of professional services expertise and product to create secure managed Web services from mission critical Mainframe and AS/400 systems. It integrates enterprise identity-management systems such as Netegrity SiteMinder or IBM Tivoli Access Manager with Mainframe security solutions like ACF/2 and RAC/F. It delivers powerful service level agreement and contract management capabilities combined with comprehensive message throughput and routing controls to prevent denial-of-service attacks.\nWhy is policy-based management important?\nThe number of service relationships in an organization will quickly grow beyond its ability to manage and secure the services individually. To handle this, the practices and standards of the organization should be defined and stored centrally as policies. These policies can then be easily managed and applied to the distributed groups of services.\nPolicy-based management is critical if your enterprise intends to define central policies for security, performance and availability and then implement and enforce these policies at a service and application level.\nThe concept of policy-based management allows central definition of security, availability and performance requirements in a single location (the Policy Definition Point – PDP), with these definition being automatically implemented and enforced at distribute Policy Enforcement Points – PEPs. This dramatically reduces the cost of securing and managing a large scale Web services deployment.\nThe Service Manager is the industry’s first comprehensive, central policy-based management and security solution.\nManagement and Security Policy can be defined at many levels. At a high level, it is the rules defined by the enterprise for managing and securing applications and transactions. At a more granular level it is the meta-data used to describe these business policies and their enforcement.\nWhat is the difference between definition, enforcement and enablement?\nDefinition is the process of defining policies for security and management.\nEnforcement is the process of enforcing these policies as described above.\nEnablement goes beyond both of these to provide a mechanism for automatically allowing applications to comply with Policy.\nSOA Software is the only SOA enablement vendor with products that dynamically adapt to the changing infrastructure to fully abstract application developers from management and security policy. The Gateway and Management Point products provide the core of this enablement capability.\nWhy is it important to externalize policy?\nThe number of service relationships in an organization will quickly grow beyond its ability to manage and secure the services individually. To handle this, the practices and standards of the organization should be defined and stored centrally as policies. These policies can then be easily managed and applied to the distributed groups of services.\nExternalized Policy-based management is critical if your enterprise intends to define central policies for security, performance and availability and then implement and enforce these policies at a service and application level.\nWhat is the importance of the Web services standards?\nWeb services standards ratified by organization such as OASIS and the IETF are critical for the long term adoption of Web services. The basic building blocks of Web services, XML, SOAP, WSDL and UDDI allow applications to be built from loosely coupled services. Without further standards describing security, reliability, transaction support and other advanced capabilities, Web services will fail to deliver the real promise of a service oriented architecture.\nTo this end, standards like: WS-Security, WS-Federation, WS-Trust, WS-Reliability, WS-Transactions, WS-Correlation, WS-DistributedManagement and many others are fundamental to the success of Web services.\nWeb services security standards include, but are not limited to:\nWS-Security, Security Assertion Markup Language (SAML), XML-Encryption, XML-Signature, WS-Trust, WS-Federation, and WS-Policy (this is broader than security, but has strong security implications).\nWhat are the management standards?\nWeb services management standards include, but are not limited to:\nWS-Distributed Management, WS-Reliable Messaging, WS-Correlation, WS-Orchestration, WS-Meta-Data, and WS-Policy.\nWhat is WS-I?\nWS-I is the Web Services Interoperability organization. SOA Software is a member of WS-I.\nFrom the WS-I web site:\n“WS-I is an open, industry organization chartered to promote Web services interoperability across platforms, operating systems, and programming languages. The organization works across the industry and standards organizations to respond to customer needs by providing guidance, best practices, and resources for developing Web services solutions.\nWS-I was formed specifically for the creation, promotion, or support of Generic Protocols for Interoperable exchange of messages between services. Generic Protocols are protocols that are independent of any specific action indicated by the message beyond actions necessary for the secure, reliable, or efficient delivery of messages; \"Interoperable\" means suitable for and capable of being implemented in a neutral manner on multiple operating systems and in multiple programming languages.”\nOASIS (www.oasis-open.org) is the primary standards body focused on developing and ratifying Web services standards. SOA Software is a member of OASIS, tracking Web Services Management, Web Services Security and SOA Enablement standards.\nFrom the OASIS Web site:\n“OASIS is a not-for-profit, international consortium that drives the development, convergence and adoption of e-business standards. Members themselves set the OASIS technical agenda, using a lightweight, open process expressly designed to promote industry consensus and unite disparate efforts. OASIS produces worldwide standards for security, Web services, conformance, business transactions, supply chain, public sector, and interoperability within and between marketplaces.\nOASIS has more than 3,000 participants representing over 600 organizations and individual members in 100 countries around the world. The Consortium hosts two of the most widely respected information portals on XML and Web services standards, xml.CoverPages.org and XML.org. OASIS Member Sections include UDDI, CGM Open, LegalXML and PKI.”\nUDDI is one of the three foundations of Web services. It provides a registry of services that can be used both to allow application developers to find appropriate services, and as a meta-data store that can allow the fabric to abstract developers from service and fabric location and policy requirements.\nFrom www.developer.com: “(Universal Description, Discovery, and Integration)—An XML-based lookup service for locating Web Services in an Internet scenario.”\nSOAP is one of the three foundations of Web services. Arguably, for an application to be called a Web service, it must expose its interfaces as SOAP APIs.\nFrom www.developer.com: “(Simple Object Access Protocol)—A lightweight, XML-based messaging protocol that contains an envelope, header, and body, designed to exchange information in a decentralized, distributed environment.”\nWSDL is one of the three foundations of Web services. It provides a standard way of defining the interfaces and APIs implemented by a service.\nFrom www.developer.com: “(Web Services Definition Language)—An XML-based language used to give a description about the Web Services available in a UDDI.”\nThe www.developer.com definition is somewhat misleading, because it is not necessary for a service to be published in a UDDI registry for it to have a WSDL document.\nWhat is SAML?\nSAML (Security Assertions Markup Language) provides a basic framework for federated authentication and authorization. Essentially SAML allows a user (person or application) to authenticate once against a server that validates the identity. Once authenticated the server will issue an authentication assertion to the user (the server can also generate an authorization assertion that grants privileges to the user), the user can pass this (these) assertion(s) on to other application that can then verify that the user is who they say they are, without having any prior knowledge of the user. This would be most useful in partnership environments, where an enterprise can rely on its partners to authenticate their own users. Unfortunately there are some outstanding challenges that SAML must address before it can be widely used in this type of environment:\n- Chained trust – A SAML assertion is signed by its issuing authority, but there is no model for attaching a trust chain, i.e. signature of an authority that can vouch for the issuing authority\n- Token interoperability – SAML is often used as a simple container for passing proprietary credentials. A good example is Netegrity TransactionMinder that generates a SAML assertion containing just a Siteminder ID. This renders different SAML implementations non-interoperable\n- Standards battles – Liberty Alliance and a group led by Microsoft and IBM are battling over specific federation models. Without an effective federation standard SAML is rendered impotent.\nWhy is SOA Software’s SAML implementation unique and valuable? The following text is the formal description of SAML taken directly from the OASIS published standard.\nThe Security Assertion Markup Language (SAML) is an XML-based framework for exchanging security information. This security information is expressed in the form of assertions about subjects, where a subject is an entity (either human or computer) that has an identity in some security domain. A typical example of a subject is a person, identified by his or her email address in a particular Internet DNS domain.\nAssertions can convey information about authentication acts that were previously performed by subjects, attributes of subjects, and authorization decisions about whether subjects are allowed to access certain resources. A single assertion might contain several different internal statements about authentication, authorization, and attributes.\nAssertions are issued by SAML authorities, namely, authentication authorities, attribute authorities, and policy decision points. SAML defines a protocol by which clients can request assertions from SAML authorities and get a response from them. This protocol, consisting of XML-based request and response message formats, can be bound to many different underlying communications and transport protocols; SAML currently defines one binding, to SOAP over HTTP. SAML authorities can use various sources of information, such as external policy stores and assertions that were received as input in requests, in creating their responses. Thus, while clients always consume assertions, SAML authorities can be both producers and consumers of assertions.\nOne major design goal for SAML is Single Sign-On (SSO), the ability of a user to authenticate in one domain and use resources in other domains without re-authenticating. However, SAML can be used in various configurations to support additional scenarios as well. Several profiles of SAML have been defined that support different styles of SSO, as well as the securing of SOAP payloads.\nWS-Distributed Management (WSDM) is an OASIS technical committee (TC) tasked with creating a standard for the management of distributed Web services.\nFrom www.oasis-open.org: “The purpose of this TC is to define web services management, including using web services architecture and technology to manage distributed resources. This TC will also develop the model of a web service as a manageable resource.”", "label": 1}
{"text": "A Sophos researcher stirred up the Mac masses this week when he reported that 20 percent of Mac computers carry Windows malware. The good news is that even though Macs are capable of harboring Windows-targeting viruses and Trojans, those machines can't be harmed by the malware in all but exceptional cases. The bad news, though, is that Mac users can still spread that malware to Windows machines in a number of ways.\nSophos senior technology consultant Graham Cluley reported earlier this week on a Sophos study that found that one in five Macs carries one or more instances of Windows malware and that one in 36 Macs are infected with Mac malware.\nSome critics of Cluley's article have taken issue with his view that \"although most of the malware we're currently seeing on Macs is designed to infect Windows, you should still be a responsible member of society and ensure that you're keeping your Mac squeaky clean.\"\nAgain, Windows malware won't hurt a Mac, but a Mac user can inadvertently pass along that malware to a colleague's or friend's Windows machine in a number of ways. Cluely provided InfoWorld with the following examples:\n- Forwarding malware-infected emails to Windows-using friends and colleagues\n- Sharing files with Windows colleagues and friends (using USB sticks, Dropbox, or the like)\n- If Web development is done on a Mac, infected files (be they executable or HTML/JS infections) can end up being transferred to a Web server and shared with the world\nWhat's more, Mac machines aren't entirely immune to Windows malware if they're, say, running Parallels. \"When you run Parallels, or any virtual machine software that runs a full copy of Windows, it's just like you're running Windows when you're in that VM, and all the same rules apply,\" InfoWorld security expert Roger Grimes said via email.\nUnless you run Windows on your Mac, the notion of loading resource-intensive antivirus software simply for the sake of protecting a peer or friend's Windows machine may not sit well. Bill Cole, a system admin, thoughtfully weighed in on the subject in his blog:\nAs both Cole and Cluley noted, the emergence of Mac malware like Flashback points to the fact that Macs are becoming increasingly targeted by malware as the Mac platform continues to gain popularity. \"Clearly, the Windows malware on Macs isn't as big a problem as Mac malware actually running on Macs, but the fact that some of the Windows malware we found on Macs was five years old underlines that many Mac users simply aren't taking security seriously at all,\" Cluely told InfoWorld.\nIn other words, it would behoove Mac users to start taking necessary precaution to better protect their machines, just as it would suit vendors (hey, how about Apple?) to develop the sort of security software that Mac users will want to use. Mac malware will only increase, and down the road, we might start seeing instances of malware capable of infecting both Macs and Windows.\n\"There are very, very few examples of malware that have payloads that work on both Mac and Windows. The ones that do exist aren't common in the wild,\" said Grimes. \"As our Web standards become more standard (with Web services, HTML5, and so on), we can expect payloads to become cross-platform, because the bad guy can at least infect and exploit within the hosting browser environment. I expect a future headline within a year or two to announce the arrival of popular cross-platform malware.\"\nThis story, \"Why Mac users should care about Windows malware,\" was originally published at InfoWorld.com. Get the first word on what the important tech news really means with the InfoWorld Tech Watch blog. For the latest developments in business technology news, follow InfoWorld.com on Twitter.", "label": 1}
{"text": "Oracle just launched Oracle Global Secure Desktop 4.7. It is a\ndesktop virtualization product based upon Oracle's Oracle VM, access\nvirtualization and application virtualization technology. It is designed\nto offer Oracle's customers Web-based access to their Windows, Linux,\nUNIX, and both IBM System i and System z applications. This approach\nallows applications and data to be safely tucked away in the customer's\ndatacenter, reduces the cost and complexity of desktop system\nmanagement, and, Oracle hope's, will beat out similar product offerings\nfrom Citrix, Microsoft and VMware.\nWhat is desktop virtualization?\nAlthough I've run though this examination before, Oracle's Global Secure Desktop launch suggests that it would be good time to consider desktop virtualization once again. Desktop virtualization, as a catch phrase, means different things to different suppliers. For the most part, desktop virtualization is the use of one or more of four different virtualization technologies to create an artificial desktop computing environment. If we examine offerings coming from Citrix, Microsoft and VMware, all of the following technologies are included.\nThe four virtualization technologies in use include:\n- Access Virtualization — hardware and software technology that allows nearly any device to access any application without either having to know too much about the other. The application sees a device it’s used to working with. The device sees an application it knows how to display. In some cases, special purpose hardware is used on each side of the network connection to increase performance, allow many users to share a single client system or allow a single individual to see multiple displays.\n- Application Virtualization — software technology allowing applications to run on many different operating systems and hardware platforms. This usually means that the application has been written to use an application framework. It also means that applications running on the same system that do not use this framework do not get the benefits of application virtualization. More advanced forms of this technology offer the ability to restart an application in case of a failure, start another instance of an application if the application is not meeting service level objectives, or provide workload balancing among multiple instances of an application to archive high levels of scalability. Some really sophisticated approaches to application virtualization can do this magical feat without requiring that the application be re-architected or rewritten using some special application framework.\n- Processing Virtualization — hardware and software technology that hides physical hardware configuration from system services, operating systems or applications. This type of Virtualization technology can make one system appear to be many or many systems appear to be a single computing resource to achieve goals ranging from raw performance, high levels of scalability, reliability/availability, agility or consolidation of multiple environments onto a single system.\n- Management of virtualized environments — In the case of desktop virtualization, this means the management of a combination of some of the following: virtual machine software, operating system, application frameworks, applications, database manager, user personalization and/or user data to create a secure, reliabile, movable artificial client system or environment.\nHow does Oracle describe Oracle Global Desktop 4.7?\nOracle Secure Global Desktop 4.7 delivers a richer application experience by providing:\n- Multi-monitor support: Can increase productivity in organizations such as contact centers by allowing users to run multiple applications on different physical monitors at the same time.\n- Bi-directional audio: Expanding on the existing support for audio output for Windows applications, Oracle Secure Global Desktop now supports microphones and other audio input devices. This enables the use of dictation, conferencing, training, and other applications requiring audio interaction.\n- Enhanced Linux and UNIX graphics display: Oracle Secure Global Desktop now supports improved performance for 3-D applications utilizing OpenGL 1.3 graphics extensions. This provides a richer user experience for customers in Federal Government, Healthcare, Education and other industries where the regular use of graphically intense applications is becoming more common.\n- Oracle Secure Global Desktop 4.7 provides optimal out-of-the-box security through pre-configured security settings, eliminating the need for additional effort by administrators. This helps ensure consistency for large enterprise deployments.\n- Oracle Secure Global Desktop 4.7 adds support for the latest Internet browsers and server OS platforms including Internet Explorer 9, Chrome and the latest Firefox ESR browsers, and the Oracle Linux 6 and Oracle Solaris 11 operating systems.\nIf you are an Oracle customer, this form of desktop virtualization will be attractive. It is tightly integrated into the Oracle virtualization strategy and, in all likelihood, will be easier to manage and install. Is this offering better than similar technology being offered by Citrix, Microsoft and VMware. That is subject to debate.\nWhat is clear is that Oracle has developed a template for its Oracle VM product that should make installation and initial use a pretty painless process.\nIf you are not an Oracle customer, the requirement for having one of the following platforms in your IT infrastructure could be a show stopper:\n- Oracle Linux 5.7, 5.8, 6.2 or 6.3\n- Oracle Solaris 11 and Oracle Solaris 11 Trusted Extensions (x86 and SPARC)\n- Oracle Solaris 10 and Oracle Solaris 10 Trusted Extensions (x86 and SPARC)\nIf your organization' IT infrastructure doesn't include one of these operating systems, other offerings would be a better choice.", "label": 1}
{"text": "Android Paternity Test App Developed by UC Irvine Computer Scientists\nUniversity of California, Irvine, computer scientists have developed a genomic app that conducts on-the-spot paternity tests and holds potential for personalized medicine.\nThe software platform, or personal genomic toolkit, is called GenoDroid, and the actual Android app is named Pater Noster, which means \"our father\" in Latin.\nGenoDroid uses advanced encryption techniques to preserve the privacy of people's DNA.\n\"It doesn't do magic,\" Gene Tsudik, UC Irvine professor of computer science told eWEEK. \"It just shows that today it's practical to run privacy-preserving genomic applications [and] operations, on modern smartphones—these ubiquitous personal devices.\"\nTsudik leads a group of faculty and students and visitors in applied cryptography, computer/network security and privacy as part of Security and Privacy Research Outfit (SPROUT) at UC Irvine.\nHe designed the smartphone app along with Emiliano De Cristofaro of Xerox's Palo Alto Research Center and a UC Irvine doctoral program graduate; UC Irvine Ph.D. candidate Sky Faber and Paolo Gasti, assistant professor at the New York Institute of Technology and a former UC Irvine postdoctoral researcher.\nDNA extracted from skin, hair or body fluids holds clues to genetic dispositions such as diseases, personality, eye color, hair color and height, Tsudik noted.\nMost of the genomic data would be storage on a PC or a laptop, said Tsudik.\nThe scientists tested the the app with publicly available genomic data. It can determine in less than a second whether one person is the father of another.\n\"What we do is we extract certain information from the DNA that is necessary to run a paternity test, so you don't actually need the entire genome to run a paternity test,\" he explained.\n\"The paternity test app compares the lengths of specific DNA segments from two individuals to determine how many of them match in the two samples,\" said Tsudik.\nWith the growing options for genomic sequencing, maintaining privacy of the data is essential, and promoting and protecting the privacy of a person's DNA is the main goal of the application, he said.\nCryptographic and encryption techniques protect the data during the paternity test on the app, according to Tsudik. A test algorithm decrypts and compares the DNA.\nThe app's \"double-blind\" technique only indicates a match or no match and doesn't reveal any other details about the DNA.\n\"Privacy of genomic information is really, really important,\" he said. \"It is possible to get privacy and still do these kinds of genomic operations.\"\nIf DNA falls into the wrong hands and various parties, such as an employer or car insurance company, find out about a person's temper, for example, it could be detrimental, Tsudik suggested.\nCurrently the app is limited to a quick paternity test, but its functionality will be expanded when DNA digitalization become commonplace.\n\"We are working on extending it to privacy-preserving maternity and more general ancestry tests,\" said Tsudik. Eventually, it could determine the likelihood of being born with an illness such as Down syndrome and be able to help biologists customize cancer-fighting drugs, he said.", "label": 1}
