{"text": "You can help your child become a responsible, ethical digital citizen with healthy online relationships. To do that, you’ll use the same successful parenting skills that you’re already using at home. Resilient digital citizens recognize and seek out the 3Cs—appropriate contact, content, and conduct—in all digital settings (e.g., iPods,instant messaging, chat, computer games, game consoles, cell phones, text messaging, webcams). To help you teach your children to safely and ethically use their digital devices, iKeepSafe has created the following programs:\nIt’s your identity. Defend it. Identity thieves and cyber-criminals are continually finding new ways to take advantage of those who are unprepared and unprotected—including online and through your home computer. It’s never been more important to protect your privacy, your credit, your money, and those you care about most.\niDefend® provides you with the 7 key areas of protection you need to defend yourself against today’s identity thieves and cyber-criminals. No other service gives you this level of protection – period.\nThe Faux Paw books and animated DVD series will captivate the attention of your young children and illustrate the important principles you desperately want to teach them about the safe and responsible use of technology.\nDigital Literacy Tour workshops are interactive discussions helping students learn, through hands-on scenario activities, how to steer clear of cyber tricks and be responsible digital citizens. Each workshop contains a resource booklet for both educators and students that can be downloaded in PDF form, presentations to accompany the lesson and animated videos to help frame the conversation.\nDesigned to teach parents how to help their teens strengthen their privacy and safety on Facebook, the guide features important topics such as risks involved in social networking, how to parent Facebook users, managing reputation in the digital age, managing your privacy on Facebook, reporting problems and more. The guide will also be translated into other languages such as Arabic and distributed internationally\niKeepSafe Generation Safe™ helps K-12 schools comprehensively navigate and embrace the digital environment. It includes a comprehensive suite of professional development, self assessment and incident response tools. It helps schools know how to best integrate technology into whole school initiatives to minimize liability and enhance classroom experiences.\nProject PRO is a partnership between the American School Counselor Association (ASCA), AT&T and iKeepSafe that has created an interactive program promoting the importance of security and online reputation to students nationwide.\nRead more about the digital citizenship topics students need to understand to become full, resilient digital citizens by clicking HERE.\niKeepCurrent Generation Safe News Feed is a weekly email newsletter using current events and news stories to build digital citizenship public awareness content, curricula and professional development . The units are tied to ALA and ISTE standards.", "label": 1}
{"text": "Protecting Yourself Against Viruses\nGuarding your computer against digital invaders\nYour computer can fall victim to many destructive events:\npower surges, coffee spills, a failed hard drive or worse. But your computer is\nalso susceptible to a digital invader called a virus.\nA virus is a program that attaches itself to another program and spreads\nfrom one file to another, causing varying degrees of damage. You may not even\nnotice some viruses, but malicious ones can erase your data files, corrupt your\napplications, cause your computer to crash, and in certain cases, render your\nhard drive completely useless.\nViruses can be transmitted via email attachments, so monitor your in-box for\nsuspicious messages. If you don't know the person who sent you a message, don't\nopen any attachment that came with it.\nYou can't get a virus from simply opening an email message, but your email\nclient may be configured to automatically open attachments, in which case you\nshould disable that feature. Be especially aware of attachments with the\nsuffixes .exe or .com. If you activate this type of virus, it can attack\nexecutable files, overwrite code and cause irrevocable damage.\nBeyond keeping a watchful eye on your incoming email, you should also be\ncareful about using removable media, especially from unknown sources. Floppy\ndisks, Zip disks and CD-ROMs can also transmit viruses.\nWithout a doubt, the best way to protect yourself against viruses is to\ninstall antivirus software. These utilities will scan for many types of viruses\nand keep watch over your system files, boot files and data files.\nSet your virus program to run a basic startup scan every time you turn on\nyour computer and a full system scan every few weeks. Most antivirus utilities\nlet you either set an automatic schedule for a full scan or do it manually. If\nthe utility finds a virus, it alerts you and tries to disinfect the file. If\nthe file can't be disinfected, you'll probably have to delete it.\nIt's also important to download updates to your virus software so that it\nwill recognize and protect you against the latest viruses. Keeping your\nantivirus software up to date greatly reduces the chances that you'll have to\ndelete any files.", "label": 1}
{"text": "Source: Security Focus\nLinux Kernel Hardening\nby Anton Chuvakin, Ph.D.\nlast updated January 23, 2002\nThis article will cover the issues of Linux hardening, with a specific focus on kernel hardening and its use on production systems. Several kernel-hardening approaches and their usability will be analyzed.\nIs Linux secure? The question is much less useful, than 'Is Linux \"securable\"?' The answer to the latter is a definite yes. Being securable means that Linux can be made more secure (to whatever degree necessary) by applying a clearly defined sequence of steps that always produces the same result, and that can be automated and applied to systems that have been in operation for a long time. It would be ideal to be able to make securing systems understandable by regular system administrators who donít have formal security training. However, the last requirement might be pushing it a bit, since security will likely always require expertise.\nLinux can be made more secure by hardening the system. It is beyond the scope of this article to discuss system hardening; however, there are a number of system hardening resources available, such as:\nThere are also utilities available, such as Bastille linux. The latter automate the hardening process with detailed explanations on each step. Hardened Linux distributions such as EnGarde Linux and Immunix are also available. Typical steps that are taken during the system hardening include:\n- Minimizing installed software\n- Patching the system\n- Securing filesystem permissions and S*ID binaries\n- Improving login and user security\n- Setting some physical and boot security controls\n- Securing the daemons via network access controls\n- Increasing logging and audit information\n- Configuring vendor supplied security software (IDS, host firewall)\nIt is curious to note that hardening is not just a matter of fixing bad defaults the vendors throw at users. It is believed that vendors ship systems with mostly open default setting based on customer feedback. Thus hardening should be viewed not as \"fighting the evil vendor\", but rather as optimizing the system based on local business and security needs.\nHardening is also a great example of defense in depth. Such a Linux system will be much harder to crack and utilize for nefarious purposes. There are examples of Linux servers running for years without a successful penetration and with no firewall. Their reliability is due to a professionally hardened OS.\nHowever, system hardening appears to be lacking in several aspects. For example, buggy SUID programs and network application will still give the attacker root and user access. If attacker gets \"root\", there is positively no way to stop them from anything on a normal Linux system. In addition, basic Unix access controls will not stop authorized system users from doing various bad things (port scanning, accessing unauthorized resources, running password crackers or banned network applications), which cannot be prohibited using Ďaccess controlí without rendering the system unusable. And while hardening, improved logging, audit and intrusion detection will complicate rootkit deployment by attackers, kernel-level rootkits can easily overcome those preventive measures.\nTo combat these threats, kernel hardening is needed. Kernel hardening can be defined as enabling additional kernel-level security mechanisms to improve the security of the system, while keeping system close to traditional Linux. What are some approaches to kernel hardening? Current Linux kernel security can be tightened a bit without adding any new features or patches. One can compile the kernel with no module support (in this case, most kernel rootkits cannot function) and some security-related kernel options can be turned on.\nThe full article can be wieved here.", "label": 1}
{"text": "Ads on the web have become essential tools for companies to promote their products, and for people to learn about bargains. But they’ve also caught the attention of cybercriminals who increasingly use them as virus and spyware-spreading channels. Their goal? Damage your data, steal your personal details or even control your computer remotely. This is when useful ads go malicious and harmful, and are referred to by specialists as “malvertisements”.\nThere are two common methods used by cybercriminals to spread viruses and other malware through ads on the Internet:\nOne entails criminals acting as trustworthy companies. They place a series of “clean” ads on trusted sites that host third-party ads, and leave them running for some time to gain a “good reputation”. Then, they attack – they insert a virus or spyware in the code behind the ad, and after a mass virus infection is produced, they remove the virus. In this case, because the ad network infrastructure is very complex with many linked connections between ads and click-through destinations, the criminals’ identity can hardly be traced.\nAnother common way for criminals to turn legitimate ads into malicious ads is by hacking trusted sites and injecting viruses into banner ads. Examples of trustworthy sites that have been hacked and used by cybercriminals to insert viruses in the ads are The London Stock Exchange and The New York Times. Usually, the next day – after the harm’s been done – they’re gone. These types of malvertisements can take the form of Google ads, pop-ups, antivirus notifications or even software upgrades.\nWhat can I do to avoid virus infections contracted from malvertising?\nKnow the exact type of the file! This is one of the most efficient and yet simple solutions: set your Windows to show the complete file name. This way you will be able to avoid most of the infections masked as ads, pictures or email attachments. For example, if you receive a picture which is named Cute_Kitten but the complete file name is Cute_kitten.exe, that's not a picture for sure. To enable this option, go to Control Panel ->Folder Options ->View ->uncheck the \"hide extensions for known file types\" box, then click \"Apply\" and \"OK\" buttons.\nDon’t be too trusting! If, say, a random pop-up appears on your screen saying you’re the one hundredth visitor and you won something huge (free), chances are that’s a malicious ad, and the only thing you can win by clicking it is a virus. Also, do not trust pop-up online surveys. Long story short, avoid such ads.\nUpdate, update, update! Out-dated software on your computer (browsers and other applications installed on your PC) makes you more vulnerable to hackers and viruses. And due to the fast evolution of malvertising methods, it’s always best to have a vulnerability scanner to check your system for out-of-date software and update it.\nBe extra careful during weekends! Malvertising campaigns are usually triggered over weekends, when IT resources are low and attacks are less likely to be noticed. Make sure you have effective antivirus protection that includes “safe browsing” functionality, so that with each site you visit, you’re notified whether it’s safe to access it or not. BullGuard Antivirus contains a feature like that.\nPrevent, rather than cure! While you can’t always figure out which ads are, in fact, malvertisements, you can lower the chances of getting infected by installing comprehensive internet security software. BullGuard Internet Security 12 is, in this respect, a great solution to all internet security problems – including malicious ads that run amok –, as it comes with the broadest selection of internet security features on the market and 24/7 free support .", "label": 1}
{"text": "SMTP-based email has long been considered insecure, and for good reason. The basic protocol doesn't include encryption, authentication\nAlthough SMTP itself is a fairly simple protocol, the idea of extending SMTP has been around for a long time. The mechanism to extend SMTP is a general one, and many different extensions have been defined to extend and stretch the capabilities of one of the Internet's oldest protocols.\nStart with TLS\nOne of the extensions within SMTP is the addition of the TLS (Transport Layer Security) encryption and authentication protocol. When a client and server that support TLS talk to each other, they can encrypt the data channel and thus guard against eavesdroppers.\nTLS is the IETF-standardized version of the SSLv3 protocol, which is widely used across the Internet. All popular Web browsers support SSL and TLS. SSL is the protocol that is negotiated when you use an \"https:\" URL. The differences between SSLv3 and TLS are not important, and most SMTP servers also support clients that want to talk SSLv3 instead of TLS. In this article, I'll only refer to TLS to simplify the discussion.\nWith TLS, the server side of the transaction sends down a digital certificate that is used to prove the server's identity. Optionally, the SMTP client can send up a digital certificate to prove the client's identity. Once the server's certificate is sent down, the client creates an encryption key, encrypts the key using the certificate of the server and ships the encrypted key up to the server. The client and server then start up an encrypted channel, and everything from that point forward is protected against eavesdroppers. This is how encryption works on the Internet with https: Web pages, and this is also the way it can work if you've enabled TLS support in your SMTP email server. (I am glossing over a lot of the potential variations in TLS that are allowed, but the cases that I'm describing represent 99% of the TLS use on the Internet today.)\nUsing TLS with your SMTP mail server is generally a simple matter. All modern email servers fully support TLS and have for many years. More importantly, TLS and SMTP are extremely interoperable. My company has been using TLS on our mail server since early 1999. Although we used to run into the occasional domain our mail server couldn't send out to, this hasn't happened in several years. In fact, almost all of the problems we encountered in TLS interoperability were caused by defective firewalls with poorly written SMTP protective code. Very old versions of WatchGuard's Firebox and Cisco's PIX had this problem, for example.\nHow to use TLS\nTo make use of TLS with your mail server, you've got to do two things: turn the feature on and get a digital certificate. How to enable TLS is beyond the scope of this article, but if you search for TLS or STARTTLS (the name of the SMTP service extension that enables TLS) in your mail server documentation, you'll probably find it very quickly. Getting a digital certificate is a little harder. In fact, this is probably why most people haven't turned on TLS -- they get to this step and freeze up. Fortunately, it's become a lot easier to get a digital certificate than it used to be. You can give Verisign a couple of hundred dollars and wait a week or so, but there are many options for getting an inexpensive digital certificate signed by a well-recognized certification authority, such as RegisterFly, within a few minutes.\nIn fact, you don't have to pay for a digital certificate to run TLS in your mail server. For testing purposes, and perhaps even for production, you can use a self-signed certificate. Your SMTP server might even have a built-in command to generate a private key and matching digital certificate. CAcert will also generate signed certificates for you for free.\nWith TLS enabled, all of your email traffic from your company's SMTP mail server to external TLS-enabled SMTP mail servers will be encrypted, from start to finish. If you are using a POP or IMAP email client that supports TLS -- and all modern ones do -- when you send mail from your client to the mail server, it'll be encrypted.\nAlthough TLS includes server and client identity, these are fairly vague concepts when it comes to SMTP-over-TLS. The binding between a server's identity and the identity in the digital certificate is a loose one. There is no clear and obvious standard for mapping the identity I want to talk to with the identity in the certificate. In addition, it's not clear to the SMTP client or server what action to take if the digital certificate doesn't seem to match. On the Web, a dialog box pops up and the user makes the decision whether or not to accept the certificate. A client and server have no one to ask when things don't look right.\nThe result of the TLS transaction is perfectly fine encryption, but rather weak authentication. If you don't match the server certificate to the identity you think you're sending to, you're susceptible to a man-in-the-middle attack. You could be sending encrypted traffic, but not to your intended recipient. Since we're accustomed to SMTP mail being forwarded in an uncontrolled manner through a number of different relays, all we're really doing is adding encryption against casual eavesdroppers. Not a huge benefit, but at virtually no cost.\nAll of this comes down to TLS not being the ultimate answer for email encryption. But like any good security system, it's a question of layers. Throw TLS on, and you're no worse off then you were before; in fact, you'll discover that about 10% of your email is encrypted. For an investment of a few hours of time, you're adding another layer of security.\nThere are some cases where TLS is critical. If you are supporting any sort of Internet, SMTP, POP and/or IMAP service, then TLS encryption on these services is a security requirement. Otherwise, you're sending passwords out in the clear when you authenticate people coming in to your mail service. Many companies are turning to SSL VPN appliances from companies such as Juniper and Nokia to front-end their SMTP, POP and IMAP services with TLS encryption.\nSophisticated mail systems often can be configured to be \"pickier\" about TLS services when talking to trusted partners. For example, if you've got a company that you often send commercially-sensitive information to (health care providers and insurance companies are good examples), you can use a Message Transfer Agent (MTA) that actually does make sure that the digital certificates match and that you're talking to who you think you are. Even if you don't have that kind of requirement, though, enabling TLS will improve your overall email security.\nJoel Snyder is a senior partner at Opus One, a consulting firm in Tucson, Ariz. He sent his first network email in 1980, and has been designing and implementing enterprise email systems ever since. He is partially to blame for the X.400 messaging standards and has been trying to atone for them ever since. Let us know what you think about this tip; email email@example.com.\nThis was first published in April 2005", "label": 1}
{"text": "Static source code analysis for bug finding (\"static analysis\" for short) is the process of detecting bugs via an automated tool that analyzes source code without executing it. The idea goes back at least to Lint, which was invented at Bell Labs in the 1970s, but static analysis has undergone a revolution in effectiveness and usability in the last decade. The initial focus of static analysis tools was on the C and C++ programming languages. Such tools are particularly necessary given C/C++'s notorious flexibility and susceptibility to low-level bugs. More recently, tools have flourished for Java and/or Web applications; these are needed because of the prevalence of easily exploitable network vulnerabilities. When using such tools, it is all too easy to deploy them in a way that looks good superficially, but misses important defects, shows many false positives, and brings the tool into disrepute. This article is a guide to the process of deploying a static analysis tool in a large organization while avoiding the worst organizational and technical pitfalls.\nLeading commercial static analysis tools with which I am familiar include Coverity, Fortify (now owned by Hewlett-Packard), and Klocwork. Klocwork and Coverity both initially focused on C/C++, although they came from opposite origins: Klocwork from the telephone equipment company Nortel, and Coverity from Stanford University. Fortify's initial focus was on security for Web applications in languages such as Java and PHP. All three companies are now encroaching on each others' territories, but it remains to be seen how well they will do outside of their core competencies.\nAn excellent, free, but limited, academic static Java byte code analysis tool is FindBugs. Its lack of an integrated database for defect suppression makes its large-scale use difficult in sizable organizations, but its use by individual developers within the Eclipse development environment can be extremely valuable. Similarly, recent versions of Apple's Xcode and Microsoft's Visual Studio development environments contain integrated static analysis tools for C/C++. These are useful for finding relatively shallow bugs while an individual developer is writing code; their short feedback loop bypasses the difficulties of broader deployment of tools that perform deeper analysis. A longer list of tools is provided in Figure 1 (which is taken from \"Magic Quadrant for Static Application Security Testing,\" by Gartner Inc.), albeit with a strong bias towards security and adherence to Gartner's strategy recommendations.\nThere is no general-purpose introductory textbook on the subject; the best general introduction is a short article by Dawson Engler, the inventor of Coverity, et al. Two of the leaders at Fortify have written an introductory textbook, but it focuses primarily on their tool and on security, and skimps on key static analysis concepts. There is a rigorous academic textbook on the more general concept of static analysis, but it preceded the revolution in static analysis for bug finding.\nGetting Started: The Politics\nThe first question to ask before deciding to do static analysis in an organization is not what tool to buy, nor even whether you should do static analysis at all. It's \"why?\"\nIf your purpose is genuinely to help find bugs and get them fixed, then your organizational and political approach must be different from the more usual, albeit unadmitted, case: producing metrics and procedures that will make management look good. (Fixing bugs should actually be your second goal: An even higher goal is preventing bugs in the first place by making your developers learn from their mistakes. This also contraindicates outsourcing the evaluation and fixing of defects, tempting though that may be.)\nPolitical Issues to Settle in Advance\nGet buy-in from your testing/quality assurance department. They must support the project and will have authority over quality-related issues, even if they inconvenience the other stakeholders. Quality has a much smaller constituency than the schedule or the smooth running of internal procedures, but it must be the final arbiter for crucial quality-related decisions (see chapter 22 of Joel On Software for more on this topic).\nGive some thought to what part of the organization, if any, should be in charge of running the tool once it's set up. If your organization has a tools team, it might seem the obvious owner, but this does need careful consideration. Static analysis for bug finding is probably not your organization's core competency, and you will need to worry about the Iron Law of Bureaucracy: Your tools team's institutional interest will be in the smooth running of the tool, not in the messy changes necessary for finding bugs. Even if you're reluctant to outsource the rest of the process, administration and configuration may be more flexible if done by external players rather than an internal team with its own interests, habits, and procedures. It may also be more productive to hire an expensive consultant for a few hours, rather than a lesser-paid internal resource full-time; an external resource may be more flexible and less prone to establishing an entrenched bureaucracy.\nThe conventional wisdom is that getting most developers to use a static analysis tool requires a high-ranking management champion to preach its benefits, ensure that the tool is used, and keep the focus on finding bugs and getting them fixed. The flip side to this is that any attempt to herd cats (or to get programmers to adhere to best practices) will cause a backlash. Your tool must withstand scrutiny from developers looking for excuses to stop using it.\nGet buy-in from engineering that they will make time in the schedule to review and fix bugs found, even if they are disinclined to do so, which they will be once they see the first false positive. (Or even the first false false positive; more on this later.) Ensure that it's not the least-effective engineers whose time is allotted for reviewing and fixing static analysis bugs (more on this momentarily). You'll also need agreement from the security team that sales personnel will get access to your real source code; more on that is also to follow.\nSmart Programmers Add More Value and Subtract Less\nHandling static analysis defects is not something to economize on. Writing code is hard, finding bugs in professional code should be hard, and evaluating possible mistakes in alleged bugs is even harder. Learning to evaluate static analysis defects, even in a developer's own code, requires training and supervision. It is necessary to tread delicately around the polite pretense that the code owner is an infallible authority on the behavior of that code. Misunderstandings about the actual behavior of unsigned integers and assertions are, for instance, regrettably common in my experience.", "label": 1}
{"text": "Security (IT Security) means protecting information and information\nsystems from unauthorized access, use, disclosure, disruption,\nmodification, or destruction.\nThe main protection priorities are the confidentiality, integrity\nand availability of information.\nGovernments, military, corporates, financial institutions, hospitals,\nand private businesses amass a great deal of confidential information\nabout their employees, customers, products, research, financial\nstatus and privacy. These informations must be protected by intruders\nand unauthorized accesses.\nHacker is generic term for a computer criminal, often with a specific\nspecialty in computer intrusion.\nHacking is breaking into computer systems, frequently with intentions\nto alter or modify existing settings. Sometimes malicious in nature,\nthese break-ins may cause damage or disruption to computer systems\nor networks. People with malevolent intent are often referred\nto as \"crackers\" as in \"cracking\" into computers.\nTheir main attack techniques are: Exploit, Buffer Overflow, Shellcode,\nCracking, Backdoor, Port Scanning, Sniffing, Keylogging, Spoofing,\nTrojans, Viruses, Spyware, Malware DOS and Browser CMD.\nThe main instruments of defense are: anti-virus softwares, antispyware,\nfirewalls, encryption, cryptography, authentication techniques,\nbackups, honey pots, Intrusion Detection System (IDS), Network\nIntrusion Detection System (NIDS), etc.\nEGI Security's Network Counterespionage\nequipment has a wide range of applications form the professional\nto the novelty uses as well as Hardware and Software Tactic Solutions\nand Countermeasures for private, corporate and governmental institutions.\nEGI Security guarantees quality and\nreliability in the Products and the proposed Solutions.", "label": 1}
{"text": "There are so many passwords in our daily life such as those for file encryption, Email and ICQ account, computer login, credit card and deposit book etc.\nIt’s a common occurrence that you forget one of your passwords one day.\nNow with \"Password Management\", you can manage all your passwords by just remembering one password, or even remember no password at all by using an authorized disk or a file as the password.\nWith \"Password Management\", you can select a password and paste it into password input box during encryption. You can also use \"Copy Password\" to copy a password into clipboard and then paste it into other applications. All passwords are completely safe since they are encrypted before saving.\nNever lose the password to enter \"Password Management\". Keep safe the authorized disk and backup the password file with \"Backup Information Files\".\nTo use \"Password Management\", first fill out the \"Caption\", \"Password\" and \"Commentary\" in the \"Edit Column\" and then click \"Append\" button.\nIf you have modified any information above, remember to click \"Modify\". Click \"Delete\" to erase an item. Before exit, click \"Save\" first. By clicking \"Save as a file\" button, you can save the password records as a .txt file which is convenient to modify or print. Click \"Change Password\" button, and you can change the password to enter \"Password Management\".", "label": 1}
{"text": "HTTPS Security Encryption Flaws Found\nThe flaw exists in the RC4 encryption algorithm that's often used to help secure the SSL/TLS communications that underpin secure (HTTPS) Web pages. The flaw was first disclosed last week by University of Illinois at Chicago professor Dan Bernstein at the Fast Software Encryption conference in Singapore, in a talk titled \"Failures of secret-key cryptography\" that's based on research he conducted with researchers from University of London's Royal Holloway and the Eindhoven University of Technology in the Netherlands.\n- Get Actionable Insight with Security Intelligence for Mainframe Environments\n- Getting a Grip on Mobile Malware\n- Gartner Magic Quadrant for Secure Email Gateways\n- Protecting Sensitive Data In and Around an Oracle Database\n\"The transport layer security (TLS) protocol aims to provide confidentiality and integrity of data in transit across untrusted networks like the Internet,\" according to the group's research presentation. \"It is widely used to secure Web traffic and e-commerce transactions on the Internet.\"\n[ Are hackers hacking for fun or for profit? Celeb Data Breach Traced To Credit Reporting Site. ]\nBut RC4, the researchers found, isn't sufficiently random, and with enough time and effort, an attacker could recover some plaintext from a communication secured using TLS and RC4. \"We have found a new attack against TLS that allows an attacker to recover a limited amount of plaintext from a TLS connection when RC4 encryption is used,\" they said. \"The attacks arise from statistical flaws in the keystream generated by the RC4 algorithm, which become apparent in TLS ciphertexts when the same plaintext is repeatedly encrypted at a fixed location across many TLS sessions.\"\nThe vulnerability has wide-ranging repercussions, given current RC4 use. \"Around 50% of all TLS traffic is currently protected using the RC4 algorithm,\" they said. \"It has become increasingly popular because of recent attacks on CBC-mode encryption on TLS, and is now recommended by many commentators.\" Those CBC-mode encryption attacks have included padding oracle attacks, the BEAST attack against browsers and the Lucky 13 attack that was first disclosed last month.\nSome cryptography experts have moved to reassure Internet users that they're in no immediate danger from the RC4 vulnerabilities. \"While interesting, the attacks don't represent an immediate practical threat to users of SSL/TLS (including online banking, e-commerce, social networking, etc.),\" said Symantec technical director Rick Andrews in a blog posted to the Certificate Authority Security Council website. \"Such attacks require an attacker to run malicious software on a user's computer, which would connect to a particular website and send the same message over and over again many times. In fact, if the attacker's software could send the same message over and over 10 times per second, it would still take more than three years for the attack to succeed.\"\nStill, once easily exploitable vulnerabilities have been discovered in an encryption algorithm, it's only a matter of time before more rapid and effective attack techniques get discovered. Furthermore, other researchers -- working at intelligence agencies, for example -- could have already discovered these vulnerabilities and put them to use.\n\"RC4 shouldn't be around,\" said Paul Ducklin, head of technology for Sophos in the Asia Pacific region, in a blog post. \"Experts have recommended avoiding it completely, at least for any newly written applications, for several years. But replacing or banning RC4 in existing cryptographic implementations is a much trickier problem.\"\nWhat's the solution? \"The most effective countermeasure against our attack is to stop using RC4 in TLS,\" according to the researchers. \"There are other, less-effective countermeasures against our attacks and we are working with a number of TLS software developers to prepare patches and security advisories.\"\nInstead of using RC4, the researchers strongly recommend switching to AEAD cipher suites such as AES-GCM, which are supported in TLS 1.2, which hasn't yet been widely adopted. Another approach, however, could be to use a CBC-mode cipher suite that's been patched against the BEAST and Lucky 13 attacks, and they said many versions of TLS 1.0 and 1.1 do now have such patches.\nSymantec's Andrews also emphasized that the discovery of vulnerabilities in RC4 doesn't reveal weaknesses in SSL/TLS. \"The designers of the SSL/TLS protocol anticipated that algorithms would become weaker over time, so the protocol was designed to support the easy addition of new algorithms,\" he said. \"Hence a weakness in one algorithm does not mean that SSL/TLS is broken. Newer, stronger algorithms have already been developed and incorporated into the latest implementations of SSL/TLS. What's needed now is for users of Web server and browser software to update to the newest versions to minimize or eliminate the use of weakened algorithms.\"", "label": 1}
{"text": "Before \"Cablegate\" (the Wikileaks diplomatic cables scandal), those of us who are relatively ignorant about the internet (non-geeks in other words) had never heard the term DDOS, or if we had, we thought it was some kind of software like Windows DOS. But in fact, DDOS attacks have been striking terror into the hearts of IT specialists in the major companies for over 10 years now, and they severely disrupted Wikileaks in late 2010. DDOS is a more radical and damaging version of a DOS attack: the acronym DOS means \"Denial of Service\". The idea of a DOS is to render a website inaccessible to its visitors. Either the site is blocked altogether, or it is severely slowed down. The pirate orchestrating the attack has a number of ways of paralysing a targeted website: he can cut the power supply to the server, though this is rare. The technique most often used is to inundate the target site with requests so that it becomes saturated. This involves thousands of computers attempting to download the same page of the target website at the same time. Once the number of requests exceeds the capacity of the server to handle them, this is enough to immobilise the website.\nDDOS is the acronym for “Distributed Denial of Service”, in other words a DOS on a larger scale.\nIn a DDOS attack, the pirate (known as the Master) starts by inflitrating people’s computers (maybe including yours or mine) so that they become his “slaves”, which he takes control of and instructs to attack the target or victim: the website in question. In fact, if your computer is badly protected it could well be used as a slave (also known as a zombie or demon) to take part in an attack without your knowing anything about it. If a pirate chooses your machine as a zombie, you haven’t heard the last of it. Many pirates \"rent out\" their network of zombies to other pirates preparing DDOS attacks. It is therefore possible for you to be implicated in several of these attacks.\nWhile it is easy to trace the perpetrator of a DOS attack – it’s the IP address (their computer identification) that gives them away — it is more difficult to track down all the IP addresses of thousands of zombies! As a preventive measure, instead of using just one server, it’s better to choose a configuration based on a number of servers, so that, if one of them is attacked, your website will still be accessible, even if it’s slowed down. Some people advocate using a buffer server designed to filter requests and “neutralise” any malevolent ones. A good firewall can reduce the risk of a DDOS attack, but it can’t eliminate it altogether.\nIf your website suffers repeated attacks, it is quite likely that the server on which it runs will just abandon you to your fate, in order to safeguard its other customer websites and ensure that they, too, are not brought down by the attack. It might decide to block your IP address, in which case you will have to find a different server.\nIn practice, if your website is the victim of repeated DDOS attacks, you will have to change your IP address or your server regularly, in the hope that the pirates will eventually get bored. Otherwise, you can set up \"mirror sites\", which provide an \"alias\" for the website you are trying to protect. That way, your visitors can always access the data on your website. This is the solution Wikileaks chose, with more than 700 mirror sites being set up. That should give the DDOS pirates something to think about!", "label": 1}
{"text": "Number Of Teenage Hackers Increasing\nExperts are concerned over the increasing numbers of teenagers dabbling in hi-tech crime.\nTeenagers swapping credit card numbers, phishing kits and hacking tips populate many net forums, computer security professionals say.\nBut the poor technical skills of many young hackers means they are very likely to get caught and arrested. Youth workers added that any teenager getting a criminal record would be putting their future at risk.\nChris Boyd, director of malware research at FaceTime Security, said he sees kids of 11 and 12 sharing credit card details and asking for hacks.\nTeens often get involved in low-level crime by looking for exploits and cracks for their favorite computer games. Communities and forums spring up where people start to swap malicious programs, knowledge and sometimes stolen data.\nOthers search for exploits and virus code that can be run against the social networking sites popular with many young people. They then try to peddle or use the details or accounts they net in this way.\nBoyd has spent a lot of time tracking down the creators of many of the nuisance programs written to exploit users of social networking sites and he said the culprit was often a teenager.\nFrom such virus and nuisance programs many progress to outright criminal practices such as using phishing kits to create and run their own scams.\n\"Some are quite crude, some are clever and some are stupid,\" Boyd said.\nBut most teenagers’ attempts to make money from cyber scams result in getting caught because of their poor technical skills.\n\"They do not even know enough to get a simple phishing or attack tool right,\" said Kevin Hogan, a senior manager Symantec Security Response.\n\"We have seen phishing sites that have broken images because the link, rather than reference the original webpage, is referencing a file on the C: drive that is not there,\" he said.\nMany teenagers manage to cripple their own PCs by infecting them with viruses they have written, Symantec researchers said.\n“Many of the young criminal hackers were undermined by their desire to win recognition for their exploits,” said Chris Boyd from FaceTime.\n“They are obsessed with making videos of what they are doing.”\nMany post videos of what they have done to sites such as YouTube and sign on with the same alias used to hack a site, run a phishing attack or write a web exploit.\nSome make it easy for computer security experts to track them down when they share photos or other details of their life on other sites.\nBoyd shut down one wanna-be hacker named YoGangsta50 and made the teenager promise to never get involved in petty hi-tech crime again.\nReformed teenage hacker Mathew Bevan said it was no surprise that young people were indulging in online crime.\n\"It’s about the thrill and power to prove they are somebody,\" he said. That also explains why they stuck with an alias or online identity even though it was compromised, he added.\nHe said what most of them do it to get fame within their peer group. \"They spend months or years developing who they are and their status. They do not want to give that up freely.\"\nTeenagers needed to appreciate the risks they take by falling into hi-tech crime, said Graham Robb, a board member of the Youth Justice Board.\n\"If they get a criminal record it stays with them,\" he said. \"A Criminal Record Bureau check will throw that up and it could prevent access to jobs.\"\nHe also said young people needed to appreciate the impact of actions carried out via the net and a computer.\n\"Are they going to be able to live with the fact that they caused harm to other people?\" he said. \"They do not think there is someone losing their money or their savings from what they are doing.\nOn The Net:", "label": 1}
{"text": "Redesign Enables NASA Site to Handle Traffic Surge, TragedyThe space shuttle Columbia disintegrated on entry Feb. 1. NASA's Web site received 72 million hits that day -- less than 24 hours after its revamp. By month's end, NASA.gov had attracted an unprecedented 512 million hits.\nDespite the enormous surge in traffic, not once did the site have problems, NASA officials said.\n\"NASA would not have been able to handle the volume of traffic were it not for overhauled technical infrastructure and information architecture,\" said Tyler Niess, account director at Calgary, Alberta-based Critical Mass, the interactive agency that handles the NASA account along with eTouch, Fremont, CA.\nFebruary's traffic volume was more than the previous five years combined. Perhaps the closest online interest NASA.gov received to the Columbia disaster was when NASA landed the Mars Pathfinder probe in July 1997, when it received 750 million hits over the probe's six-month mission.\nOf course, it helps that NASA is a government agency with the ability to install unlimited bandwidth. Still, many other government sites have buckled under traffic spikes or technical glitches.\nThere are lessons here for retailers and marketers. One is the efficient use of the Internet as a communications tool in times of crisis. Another is the technology preparedness when consumer interest is expected to peak, in this case, Columbia's descent to Earth.\nSo what happened when the Columbia disaster unfolded?\nA team at Critical Mass and eTouch assembled and put together recommendations for NASA less than an hour after the tragedy. A multimedia introduction on NASA.gov was replaced with the image of a U.S. flag at half-staff, and the tone changed from celebratory to mourning.\nAnother far more important addition was a microsite that included a schedule of events, biographies of the seven crew members and the ability to upload directions for video and photographs. The microsite was designed to handle information requests, serving as one of the most invaluable information portals in the crisis management chain at NASA.\nA few factors helped officials meet the demands created by the Columbia tragedy. NASA had, for the first time, outsourced site hosting. Next, it took advantage of its different in-place systems to conduct searches and balance the query load. Finally, NASA redesigned the site architecture to make it flexible enough to quickly add a new section that did not break the navigational conventions.\nDirect marketers, online retailers and even news sites in the aftermath of major events can learn from NASA's online experience. Retail sites undergo similar stress during the Thanksgiving and Christmas holiday shopping season.\nNASA had the foresight to erect load, traffic and peak bandwidth requirements that seemed outlandish.\n\"The information architecture and the stripped-down content delivery system were critical,\" Niess said. \"So, when planning for anything special or for anything unexpected, you have to maximize load times and accessibility.\"\nNASA has faced tighter budgets and diminished public interest in its activities. Last year, however, the E-Government Initiative became law, and government agencies were challenged to use the Internet to meet public needs as the private sector does. Encouraged, NASA decided to accelerate its awareness and advocacy by making its site a public outreach asset. NASA.gov now is the portal for 4 million pages of information from 2,922 disparate NASA sites.\nThis new philosophy will be put to test with the next Mars Exploration Rover Mission slated for takeoff this summer and a January landing. This mission is expected to generate 10 times the traffic as the previous Pathfinder spacecraft in 1997, a number running into billions of hits.\nCritical Mass will not delve into the specific features expected on the site with the new Mars probe. But the shop does disclose the efforts are going to be unprecedented.\nIn essence, NASA is in the midst of an online rebranding. As a government agency, it is aware that it needs to be more accessible to the public. More importantly, the site is the agency's only public interface. There is no NASA magazine or newsletter, and all communications are conducted online and via press conferences.\nBefore Critical Mass' online retooling -- it took only three weeks to prep NASA.gov for Columbia's return -- the site was aimed primarily at scientists. Now the site has a broader appeal.\n\"We think the site is unusual because it starts with user needs and modifies internal processes to meet those needs,\" Niess said. \"It is unprecedented for government agencies to think this way.\"", "label": 1}
{"text": "On September 17th, 2011, Natasha Singer wrote for the New York Times about the National Strategy for Trusted Identities in Cyberspace (NSTIC). Comparing NSTIC to a digital driver's license, Singer explained how NSTIC would make it so people have a simpler, safer way to prove who they are online with more than a flimsy password. To do so, consumers would choose among trusted third parties — such as banks, technology companies or cellphone service providers — that verify certain personal information about them and issue them secure credentials to use in online transactions. The system would allow Internet users to use the same secure credential on many Web sites; people could have their identity authenticator automatically confirm that they are old enough to sign up for Pandora without having to share their birthdate with Pandora.\nHowever, authentication proponents and privacy advocates disagree about whether Internet IDs like NSTIC would actually heighten consumer protection. Privacy advocates argue that identity verification online could make consumers more vulnerable because authentication companies would become \"honey pots for hackers.\" Lillie Coney, the associate director of the Electronic Privacy Information Center, noted that “You can have one key that opens every lock for everything you might need online in your daily life, or, would you rather have a key ring that would allow you to open some things but not others?”\nHowever, Jeremy Grant (senior executive adviser for identity management at the National Institute of Standards and Technology) noted that no system is invulnerable. Privacy concerns aside, better online identity authentication would improve the current situation where people use the same passwords for their e-mail, banking, and social network accounts. Mr. Grant went on to compare weak security to flimsly locks on bathroom doors: “If we can get everyone to use a strong deadbolt instead of a flimsy bathroom door lock, you significantly improve the kind of security we have.”\nThe source article can be found here.", "label": 1}
{"text": "The Browser Takes All\nGoogle's new computer throws out everything but the Web.\n- Friday, December 10, 2010\n- By Tom Simonite\nThis week, Google unveiled a computer like no other: the Cr-48, a notebook that relies on the Web for all its software applications. Yet the Web search giant thinks the notebook can compete with computers that run all kinds of installed software.\nThe matte black Cr-48 won't be sold to the public, but thousands are being sent to consumers and businesses who have volunteered to test it. It introduces a new kind of operating system, called Chrome OS, that turns to the Web for almost everything. Google is pitching Chrome OS as its vision for a new form of computing—one that shifts the data, functionality and almost everything else you would expect from your desktop computer into the cloud. Chrome OS will get its biggest test when Acer and Samsung start selling notebook computers customized to run the software in mid-2011.\nGoogle's Chrome OS vision is perhaps best understood by examining the differences between Chrome OS and the operating systems commonly used today, says Sundar Pichai, the vice president of product management for Chrome OS (and the related Chrome Web browser). Those differences come from a single design decision about the relationship between a person and his computer, Pichai says.\n\"Operating systems today are centered on the idea that applications can be trusted to modify the system, and that users can be trusted to install applications that are trustworthy,\" he says, \"it turns out those are bad assumptions.\"\nIn contrast, Chrome OS assumes that applications and users can't be trusted. And it has just one application: the browser. \"There's a cascade of things that happen when you make this core assumption,\" says Linus Upson, a Google VP of engineering working on the project, from making it easier to protect against malware, to reducing the need for users to act as administrator for their own system.\nChrome OS—based on a pared-down version of the Linux operating system—automatically downloads and installs its own updates. Any data downloaded in the course of using the Web is kept carefully in a secure place, separate from the OS.\nGoogle still needs to prove that the simplicity of Chrome OS doesn't undo its usefulness. To this end, it has built a Web \"app store\" to encourage developers to create Web-based software that will match the diversity and functionality of the applications that can be installed on the hard drive of a Windows or Mac computer. These apps are basically advanced websites that offer similar functionality to desktop apps software.\nUsers of Chrome OS—as well as the Chrome browser on a conventional computer—can search or browse the Chrome Web Store and with a single click install apps. The store has far fewer software applications than are available for a conventional machine. But some Chrome apps can compete with more traditional, desktop applications, for example a Photoshop-like image editor, Aviary.\nPichai says the fact the app store takes payments—either one off or subscriptions—should stimulate the creation of apps that otherwise wouldn't exist because developers couldn't make them profitable. \"I wouldn't find a random game on a website and give them my credit card details to pay $3.99. It's not worth the time or the risk.\"\nSomewhat surprisingly, given Google's claimed commitment to the open Web, Google's app store is not compatible with other Web browsers. But it is possible to easily modify apps developed for Chrome's store for other \"modern\" browsers, says Pichai, since they use HTML5 and other web standards designed to enable advanced functionality, including working while offline. The latest versions of Internet Explorer, and other browsers, support those standards. However some features of Chrome apps remain exclusive to Chrome, such as 3-D effects that tap into a machine's graphics processor. \"We need to make sure that apps can do everything that apps can do on the desktop today,\" Pichai explains. He expects other browsers to catch up as HTML5 and other new Web standards become more common.", "label": 1}
{"text": "How cloud storage could catch up with big data\n- By John Moore\n- Apr 17, 2012\nCloud computing has managed to make the world’s already colossal appetite for data storage even more voracious.\nLast year, IDC, an IT market research firm, cited public cloud-based service providers, from Amazon Web Services to YouTube, as the most significant drivers of storage consumption in the past three years. The government sector contributes as well: IDC noted that the private clouds of government and research sites compare in scope and complexity to their public cloud counterparts.\nThe so-called big data problem has surfaced in the past two years to rank among the primary IT challenges. Technologies such as the Apache Hadoop distributed computing framework and NoSQL databases have emerged to take on the challenge of very large — and unwieldy — datasets.\nAnd now another technology, already at work behind the scenes, could grow in importance in the coming years. Erasure coding has been around since the 1980s, but until recently its use in storage circles has mainly been confined to single storage boxes as a way to boost reliability more efficiently.\nNow erasure coding is moving into distributed storage. Its application becomes trickier here, but industry executives and storage researchers believe erasure coding — particularly in conjunction with increasingly popular techniques such as object-based storage — will play a growing role in cloud storage. Potential government adopters include Energy Department labs and other agencies with vast data stores.\nWhy it matters\nWhen it comes to storage, everything is getting bigger, whether it’s an individual disk, a storage system or a cloud-based repository. Erasure coding, an error-correcting algorithm, plays a role across this range of ever-growing storage platforms.\nVendors most commonly use erasure coding to boost the resiliency and performance of their Redundant Array of Independent Disks (RAID) storage systems, said Bob Monahan, director of management information systems at DRC, a consulting and IT services firm.\nBut it’s the use of erasure coding as an alternative to data replication that is attracting new interest in this storage mechanism. In many traditional cases, redundancy is achieved by replicating data from primary storage devices to target arrays at the data center or an off-site location. Mirroring data in that way provides protection but also consumes lots of storage, particularly when organizations make multiple copies of data for greater redundancy. The approach becomes particularly unwieldy for organizations that deal with petabytes or more of data.\nErasure coding offers an alternative way to achieve redundancy while using less storage space, said Russ Kennedy, vice president of product strategy, marketing and customer solutions at storage vendor Cleversafe, which uses erasure codes in its object-based storage solutions.\nOrganizations that rely on replication might make three or four copies of data — one copy at another location then a copy of the copy to be safe and so on. In comparison, the overhead to make a sufficiently fault-tolerant copy with erasure coding is less than double the size of the original volume, Kennedy said.\nJean-Luc Chatelain, executive vice president of strategy and technology at DataDirect Networks, said financial concerns are driving interest in erasure coding among customers who don’t want to replicate data two or three times. DataDirect takes advantage of erasure coding in its RAID system, file storage offerings and Web Object Scaler product for cloud storage.\nThe prospect of saving space and money hasn’t been lost on the cloud community. The major providers are on their way to adopting erasure coding, said James Plank, a professor in the Department of Electrical Engineering and Computer Science at the University of Tennessee. His research focuses on erasure codes in storage applications.\n“Pretty much every cloud installation you can think of is either using erasure coding or converting to erasure coding,” he said, citing Amazon, Google and Microsoft as examples. “They are using erasure coding for fault tolerance because the disk space savings is huge.”\nThere’s a bandwidth benefit as well. “While the big savings today would come from reduced capacity requirements, the big win, from my standpoint, is the two- or threefold reduction in bandwidth [compared to what is] used during replication,” said Galen Shipman, group leader of the Technology Integration group at Oak Ridge National Laboratory’s National Center for Computational Sciences.\nErasure coding might have implications for the nascent cloud, but the technology has been around the storage block a few times. In a storage setting, the technique encodes data into fragments from which the original data can be reconstructed.\nFor example, erasure coding is the underlying technology of Cleversafe’s dispersed storage method, which takes a data object (think of a file with self-describing metadata) and chunks it into segments. Each segment is encrypted and cut into 16 slices and dispersed across an organization’s network to reside on different hard drives and servers. If the organization has access to only 10 of the slices — because of disk failures, for instance — the original data can still be put back together, Kennedy said.\nNumerous experts see erasure coding paired with object-based storage as a good option for achieving more fault-tolerant repositories with petabytes and even exabytes of capacity.\nGovernment clouds and data centers have yet to jump on erasure coding, apart from agencies using RAID storage devices that embed the technique.\n“It is less well understood and therefore less mature in commercially available solutions,” Monahan said. “As it becomes more mature, the use cases for when it is more appropriate will drive implementation scenarios.”\nPerformance is another limitation. Shank Shome, a storage engineer at Agilex Technologies, said the impact of erasure coding on storage performance has yet to be fully explored. He added that reading the data back from an erasure-coded system is generally fast, but the real performance cost lies in writing the data to storage.\n“If the data is generally static with very few rewrites, such as media files and archive logs, creating and distributing the data is a one-time cost,” Shome said. “If the data is very dynamic, the erasure codes have to be re-created and the resulting data blocks redistributed.”\nErasure coding also runs into problems with high-performance computing. One complication arises when data is being written simultaneously from many sources and at a high rate, said Robert Ross, a computer scientist at DOE’s Argonne National Laboratory and a senior fellow at the University of Chicago’s Computation Institute. That activity requires a level of coordination that isn’t easy with current approaches.\nIn general, storage experts believe erasure coding faces the biggest obstacle in frequently accessed “hot data.” Accordingly, they believe a key initial use case lies in protecting data that has cooled enough to move to long-term storage.\nMonahan said the benefits of erasure coding are “higher local availability at a lower cost and highly available dispersed archival systems that are an order of magnitude less expensive than traditional systems.”\nThe trick is knowing when to use replication to get data out of a system quickly and when to use erasure coding to create more economical, resilient long-term storage, Ross said.\n“Both have important roles moving forward in high-performance computing,” he added.\nThe Oak Ridge lab is now exploring the use of erasure coding for the Oak Ridge Leadership Computing Facility. That facility already uses RAID 6 systems from DataDirect Networks. Shipman said erasure coding could play a significant role in two distributed storage systems: a Lustre parallel distributed file system and the large-scale archival High Performance Storage System, which uses replication for data integrity and resiliency.\n“Erasure coding will likely emerge as a viable alternative to replication due to savings in the media and bandwidth consumed for replication,” Shipman said.\nHe acknowledged the computational demands of the more advanced erasure-coding techniques but said ongoing research on algorithms aims to minimize that cost.\nNext steps: Updating the storage toolbox\nAs data storage needs continue to grow and cloud-based models introduce new options for distributed systems, agencies should constantly re-evaluate their storage strategies. Specifically, they should:\n- Monitor current storage options. Erasure coding might not be at the top of your agenda today, but if your storage growth is outpacing your budget, it probably makes sense to add the technology into the mix of current or near-term future options.\n- Assess likely use cases. Beyond data archiving, erasure coding could prove useful for maintaining and protecting large quantities of sensor-derived data. For example, Cleversafe recently signed GeoEye, a provider of high-resolution satellite imagery, as a customer.", "label": 1}
{"text": "Cross-Site Scripting attacks are a type of injection problem, in which malicious scripts are injected into the otherwise benign and trusted web sites. Cross-site scripting (XSS) attacks occur when an attacker uses a web application to send malicious code, generally in the form of a browser side script, to a different end user. Flaws that allow these attacks to succeed are quite widespread and occur anywhere a web application uses input from a user in the output it generates without validating or encoding it.\nAn attacker can use XSS to send a malicious script to an unsuspecting user. The end user’s browser has no way to know that the script should not be trusted, and will execute the script. Because it thinks the script came from a trusted source, the malicious script can access any cookies, session tokens, or other sensitive information retained by your browser and used with that site. These scripts can even rewrite the content of the HTML page.\nMore information: Wikipedia.", "label": 1}
{"text": "Recent events such as hurricanes Katrina and Rita, the 911 event, the attack on the USS Cole, and the Northeast U.S. blackout have demonstrated our vulnerability to disasters and our need to find methods that provide some degree of tolerance for large cyberspace systems in the presence of disasters. Disaster Tolerance in computing and communications systems refers to the ability of infrastructure, software, IT systems, communications infrastructure and business or organizational processes that depend on these systems, to maintain functionality throughout the occurrence of a disaster. The goal of Disaster Tolerance is to provide an ability to continue uninterrupted operations, despite the occurrence of a disaster that would normally interrupt organizational operations; where critical business functions and technologies continue operations, as opposed to resuming them.\n- Faculty: Theodore Manikas, Stephen Szygenda, Mitch Thornton\n- Students: Poramate Ongsakorn\nHardware Security and Electronic Design Automation\nThe mission of the Electronic Design Automation (EDA) laboratory is to create and design new techniques for the capture of system specifications and to automatically synthesize, verify, and test the resulting system. EDA laboratory personnel work on projects related to conventional electronic and emerging quantum and nano-based systems. An emphasis on the application of fundamental knowledge in discrete mathematics, algorithms, and system design principles is the underlying philosophy behind research projects.\n- Faculty: Jennifer Dworak, Theodore Manikas, Mitch Thornton\n- Students: Saurabh Gupta, David Kebo Houngninou, Xi Shen, Abhijit Sunil, Fanchen Zhang, Adam Zygmontowicz\nThe mission of the Cyber Security Lab is to nurture education, research and development of security technologies for systems ranging from the physical layer to the application layer. In that spirit, our projects range from border and transportation security to application layer security against phishing attacks. Over the past 10 years, research in the Cyber Security Lab has provided the basis for Security Engineering curriculum in the Computer Science and Engineering Department at SMU's Lyle School of Engineering.\n- Faculty: Tyler Moore, Suku Nair\n- Students: Bilal Alqudah, Will Bengtson, Ala' Eshmawi\nEconomics puts the challenges facing information security into perspective better than a purely technical approach does. Systems often fail because the organizations that defend them do not bear the full costs of failure. In order to solve the problems of growing vulnerability and increasing crime, solutions must coherently allocate responsibilities and liabilities so that the parties in a position to fix problems have an incentive to do so. This requires a technical comprehension of security threats combined with an economic perspective to uncover the strategies employed by attackers and defenders.\nThe security economics lab conducts research measuring various forms cybercrime in order to improve our understanding of how attackers and defenders behave. We emphasize empirical analysis of security incidents that can be directly observed, driven by the belief that security failures must be studied from the concrete, not the hypothetical. We also attempt to quantify the costs and benefits of security mechanisms where possible.\nWe collaborate with researchers at institutions across the US and internationally, including Carnegie Mellon University, Penn State, the University of New Mexico, the University of Cambridge, and the University of Münster. For more information and publications, see http://lyle.smu.edu/~tylerm/eis.html.\n- Faculty: Tyler Moore\n- Students: Marie Vasek, Jake Drew", "label": 1}
{"text": "Enabling Secure SSH Terminal Connections From Roaming Smartphones\nThe Secure Shell, or SSH, is a popular program that lets computer users log onto remote machines. Software developers use it for large collaborative projects, students use it to work from university servers, customers of commercial cloud-computing services use it access their accounts, and system administrators use it to manage computers on their networks.\nFirst released in 1995, SSH was designed for an Internet consisting of stationary machines, and it hasn't evolved with the mobile Internet. Among other problems, it can't handle roaming: If you close your laptop at the office and reopen it at home, your SSH session will have died; the same goes for an SSH session on a tablet computer that switches from a Wi-Fi connection to the cellular network.\nAt the Usenix Annual Technical Conference in Boston this month, researchers at MIT's Computer Science and Artificial Intelligence Laboratory presented a paper describing a new remote-login program called Mosh, for mobile shell, which solves many of SSH's problems. The researchers also believe that the communication scheme underlying Mosh could improve the performance of a host of other mobile applications.\nEven before they presented the paper, they made Mosh freely available on a number of different websites; it's now been downloaded at least 70,000 times. \"That's from the ones that we're able to track,\" says Keith Winstein, a graduate student in MIT's Department of Electrical Engineering and Computer Science and lead developer of Mosh.\nBesides roaming, another of the problems that Mosh addresses is the delayed \"echoing\" of keystrokes in SSH. During a standard SSH session, when a user strikes a key on the keyboard, nothing appears onscreen until information about the keystroke travels to the remote machine, which performs a computation and sends back the result. That's because, in many applications commonly run through SSH, keystrokes don't necessarily correspond directly to displayed symbols: In an email program, for instance, the \"N\" key might call up the next email; similarly, when a user enters a password, it shouldn't appear onscreen.\nMosh has an algorithm running in the background that deduces when keystrokes should be displayed and when they shouldn't. Until the remote computer confirms Mosh's predictions, the characters onscreen are underlined. \"I have never seen it display anything wrong,\" says Hari Balakrishnan, a professor in the Department of Electrical Engineering and Computer Science and Winstein's coauthor on the Usenix paper.\nThe reason Mosh handles roaming so much better than SSH does is that it abandons the Transmission Control Protocol, or TCP -- the framework that governs almost all the traffic in today's Internet.\n\"TCP has some wonderful ideas embedded in it -- congestion control, ways of doing reliability and so forth,\" Balakrishnan says. \"But it has this one big, big problem: It provides a reliable, in-order byte-stream abstraction between two fixed endpoints. If you were to pick the worst possible abstraction for the mobile world, it would be that.\"\nWith mobile applications, Balakrishnan explains, it's not as crucial that every byte of information be displayed in exactly the order in which it was sent. If you've lost connectivity while using the map application on a smartphone, for instance, when the network comes back up, you probably want an accurate map of your immediate surroundings; you don't want to wait while the phone reloads data about where you were when the network went down.\nWinstein and Balakrishnan developed their own communications protocol, which they call SSP, for state synchronization protocol. SSP, Balakrishnan says, works more like the protocols that govern videoconferencing, where getting timely data about the most recent state of the application is more important than getting exhaustive data about previous states.\nMosh is already proving itself useful: At his computer in his office, Balakrishnan pulls up the connection log for one of the servers in MIT's Athena network; a third of the people logged into it are using Mosh. But in ongoing research, Winstein and Balakrishnan are investigating how SSP can be improved and extended so that other applications can use it as well.\n\"We have sort of a broader agenda here,\" Winstein says. \"Mosh is a gracefully mobile application. But there's a lot of even more popular network applications that have the same problems, like Gmail, or Google Chat, or Skype. None of these programs gracefully handle mobility, even though they're intended for mobile devices.\"", "label": 1}
{"text": "Many people use their computers for months or years without ever knowing it's infected with a virus. An infected computer runs slowly and and the overall user ...\nUse these guidelines to protect your computer system from viruses.\nRegister now to access 7 million high quality study materials (What's Course Hero?) Course Hero is the premier ...\n... or simply keeping up ... AVG Free Edition has the presence of all necessary functions to protect your computer from viruses ... AVG Anti-Virus FREE Edition is ...\nBest Computer Protection - 5 Tips to Keeping Your PC Virus and Spyware Free EzineArticles.com.\nComputer Viruses- Protect computer against viruses ... It's happened to the best of us, it's happened to the worst of us. And when infected, it feels like your world ...\ngroovyPost 10 Step Security Guide to Keeping your Computer Virus Free and Your Data Safe!\nBattling Computer Viruses. As a computer user, you face a major challenge in keeping your computer free from destructive viruses. A virus is a program or piece of ...\nThe 3 Keys To Keeping Your Computer Network Virus-Free! To keep your computer virus-free, here are 3 key strategies from managed IT services provider, Cartish ...\nKeep your computer clean, quick and virus free with The FixMeStick® Virus Removal Device for $34 (reg. $64.99). Free shipping!\nHow do I remove a computer virus? If your computer is infected with a ... The scanner is a free online service that helps you identify and remove ... Keep in touch ...\nKeep your Computer free from Viruses, Trojans, Spyware and Malware - HelpWithWindows.com - News\nBy Preston Gralla, TechWeb From the moment you turn on your PC until the moment you turn it off, it's under assault. Hackers try to break into it; viruses,\nKeeping your computer virus-free is an active, ongoing job. You will need to update your virus definitions, run regularly scheduled scans of your computer, ...\nHere are some simple ways you can keep your computer safe: Use Anti-Virus Software; Don't Open Junk Mail; ... im jus about 2 start using the free antiviruses im so exited.\nKeep Your PC Clean With a Free Virus Cleaning Program. Article about Free Computer Virus Cleaning Programs. It's Easy To Find Computer Virus Cleaning Programs that are Free.\nAndroid phones are not unlike your typical computer, it can do many of the same things such as browsing the web, or playing games. But just like any typical computer ...\nThe following programs will help you keep your computer clean and running fast. Defraggler. ... but the anti virus protection is not free and has to be added.\n... viruses are able to cross the firewall and end up on your computer anyway. A virus ... , it's important to keep your virus ... Don't install \"free ...", "label": 1}
{"text": "Glossary What is a virus, trojan, spyware, malware or other badware\nThe technical terminology used in virus alerts and descriptions can be confusing. The glossary below contains definitions for some of the most common terms with the top ones linked just below.\nA legitimate, non-replicating program designed to display ads to the end-user, often based on monitoring of browsing habits. Often adware contains spyware in order for the program to know which advertisements to display based on the current user’s preference. Adware displays ads often in exchange for the right to use a program free of charge (a variation on the shareware concept).\nA program that opens secret access to systems, and is often used to bypass system security. A Backdoor program does not infect other host files, but nearly all Backdoor programs make low-level operating system modifications (i.e. it makes changes to the registry). Backdoors usually hitch a ride in on trojans. Once they are in place and they have executed, they hide themselves while opening a port on your computer to allow others in. Some backdoors are placed by hackers once they gain access allowing themselves easier entrance later, or if their original entryway is blocked.\nA virus which uses multiple infection techniques. This may include the exploitation of various program vulnerabilities, incorporation of trojan behavior, file infection routines, Internet propagation routines, network share propagation routines, and spreading without any human intervention.\nA trojan that, upon execution, logs every keystroke or activity in a system. Although they are similar to third-party parenting/monitoring software, some keyloggers actually employ the same techniques as parenting/monitoring software to gather valuable data such as usernames, passwords, and personal information from unsuspecting users.\nA “macro” is a saved set of instructions that users may create or edit to automate tasks within certain applications or systems. A Macro Virus is a malicious macro that a user may execute inadvertently and that may cause damage or replicate itself. Some macros replicate, while others infect documents. Unlike other virus types, macro viruses aren’t specific to an operating system and spread with ease via email attachments, floppy disks, Web downloads, file transfers, and cooperative applications. Macro viruses are typically written in Visual Basic and are relatively easy to create. They can infect at different points during a file’s use (for example, when a file is opened, saved, closed, or deleted).\nMalware (Malicious Software)\nPrograms that are intentionally designed to perform some unauthorized (and often harmful or undesirable) act such as viruses, worms, and trojans.\nA virus that contains a special routine that changes parts of the virus code with each replication to evade detection by antivirus software.\nA software program that monitors a user’s computing habits and personal information and sends this information to third parties without the user’s authorization or knowledge.\nTrojan (Trojan Horse)\nA program or a part of program code that performs unexpected or unauthorized, often malicious, actions. The main difference between a trojan and a virus is the Trojan’s inability to replicate. Trojans cause damage, unexpected system behavior, and compromise the security of systems, but do not replicate. If a malicious program replicates, then it should be classified as a virus. A Trojan, coined from Greek mythology’s Trojan Horse, typically comes in good packaging but has some hidden malicious intent within its code. When a Trojan is executed users will likely experience unwanted system errors, problems in operation, and sometimes loss of valuable data.\nA program or a part of program code that replicates – that is, “infects” another program, boot sector, partition sector, or document that supports macros, by inserting itself or attaching itself to that medium. Most viruses only replicate, though, many do a large amount of damage as well.\nA self-contained program (or set of programs) that is able to spread functional copies of itself or its segments to other computer systems. The propagation usually takes place via network connections or email attachments. The worm may do damage and compromise the security of the computer. It may arrive in the form of a joke program or software of some sort.", "label": 1}
{"text": "Uncertain State Of Cyber War\nJust what does \"cyber warfare\" mean? We're still figuring out tactics and capabilities.\nMilitary agencies worldwide are right in the middle of figuring out the tactics and capabilities that will be critical in any future cyber war. So far, any conflicts are playing out behind the scenes, with only the rare accusation or public request for technology giving a glimpse into what offensive attacks between countries might look like.\nEven what counts as \"cyber warfare\" remains an open question. Many cite as the first-known example of such operations the distributed denial-of-service (DDoS) takedowns and hijacking of government and business websites in the country of Georgia in 2008, at the same time as Russian military operations on the ground.\nMore Government Insights\n- Demystifying Big Data: A Practical Guide to Transforming the Business of Government\n- Single Source of Truth for Managing Critical Assets Application Consolidation across Public Sector Organizations\n- Continuous monitoring for government agencies\n- Strategy Guide to Security Information Management in Government\n- Research: Federal IT Priorities: Focus On The Foundation\n- Research: Federal Government Cybersecurity Survey\nBut there's scant proof that the Russian government launched or sponsored online attacks against Georgia, according to many security experts, including Robert David Graham, CEO of Errata Security. \"There's no evidence the cyber attacks were by the Russian government, or that they were anything more than normal 'citizen hacktivism,'\" he said in a blog post. It's notable that this supposed first-ever cyber war served no clear military purpose. Attackers compromised informational government websites, not critical infrastructure systems or military networks.\nTo be fair, even the would-be practitioners of cyber warfare -- namely, the U.S. military -- are themselves soliciting input on what offensive computer system attacks might look like, either on their own or in conjunction with physical operations and kinetic attacks.\nLast year, for example, the Defense Advanced Research Projects Agency (issued a call to tech vendors for \"cyberspace warfare operations\" capabilities, as part of what Darpa dubs Plan X. Darpa seeks a broad range of capabilities, from a scripted counterresponse to a cyber attack to IT infrastructure that could be hardened to withstand attacks.\nSimilarly, the Air Force Life Cycle Management Center last year called on contractors to submit concept papers for \"cyberspace warfare operations\" capabilities, including \"cyberspace warfare attack\" and \"cyberspace warfare support.\"\nCapabilities on the Air Force wish list include \"employing unique characteristics resulting in the adversary entering conflicts in a degraded state.\" In other words, why blow up an enemy's tank if you can instead somehow infect and kill the tank's electrical system?\nWho else is bolstering their cyber war capabilities? Iran is a strong candidate, and in April 2012, the VP of the American Foreign Policy Council, Ilan Berman, told a U.S. House committee that Iran has been boosting its cyber warfare resources in the wake of online attacks against the country. The attacks include Stuxnet, malware blamed in 2010 for trying to attack power plant infrastructure. U.S. officials have accused the Iranian government of sponsoring DDoS attacks against U.S. banks. China has reportedly mobilized its own cyber army, and Russia last year launched a recruitment drive to find the country's best hacking minds, seeking people versed in \"methods and means of bypassing antivirus software, firewalls, as well as in security tools of operating systems,\" the newspaper Pravda reported.\nBut while governments don't face the same legal problems that companies do when considering offensive attacks, they do face the same major intelligence challenge: accurately tracing an attack's true origin, a process known as attribution. While small-time cybercriminals may leave tracks, government-backed professionals will go to great lengths to hide what they're doing -- or perhaps, pin blame on another enemy.", "label": 1}
{"text": "This blog article is reposted in part, with permission, from the SANS Ouch! Newsletter.\n[Editor's Note: (Wyman) This month we present an overview of why and how the Bad Guys do it, what it's called, and what you can do to protect your computer.]\nBlackhats. Hackers who use their skills for explicitly criminal or other malicious ends, such as writing malware (malicious software) to steal\ncredit card numbers and banking data or by phishing; a.k.a. the Bad Guys.\nPhishing. The practice of sending out fake email messages that look as if they come from a trusted person or institution-usually a bank-in\norder to trick people into handing over confidential information. The emails often direct you to a website that looks like that of the real\nfinancial institution. But it is a fake and has been rigged to collect your personal information, such as passwords, credit card numbers and\nbank account numbers, and transmit them to the Bad Guys.\nMan-in-the-middle. An attack in which a criminal hacker intercepts information sent between your computer and the website of your financial\ninstitution and then uses that information to impersonate you in cyberspace. The hacker is able to defeat even very sophisticated\nsecurity measures and gain access to your account.\nBotnet. Botnets consist of large numbers of hijacked computers that are under the remote control of a criminal or a criminal organization. The\nhijacked computers-a.k.a. “zombies” or “bots” (short for “robots”) -are recruited using viruses spread by email or drive-by downloads. Worms are used to find and recruit additional computers. The biggest botnets consist of thousands and even millions of computers, most often\nunprotected home computers.\nVirus. A malicious program that usually requires some action on the part of a user in order to infect a computer; for example, opening an\ninfected attachment or clicking on a link in a rigged email may trigger a virus to infect your computer.\nDrive-by Download. A kind of malware that installs itself automatically when you visit a booby-trapped website. Symptoms of a drive-by download include: your homepage has been changed, unwanted toolbars have been added, and unfamiliar bookmarks appear in your browser.\nWorm. Self-replicating malware that, for instance, hunts down unprotected computers and recruits them for criminal or other malicious\npurposes. Unlike a virus, worms do not require any action on your part in order to infect your computer.\nFake Anti-Virus. Fake anti-virus software purports to be a helpful program than can find and remove malware, but in fact it is malware–the\nvery thing that it’s supposed to eliminate. After taking over your computer, it pretends to do security scans, tells you it has found\nmalware, and then asks you to pay to have the non-existent malware removed. Whether or not you pay, fake anti-virus is likely to install\nWhitehats. Hackers who use their skills for positive ends, and often for thwarting blackhats. Many whitehats are security professionals who spend their time identifying and fixing vulnerabilities in software that blackhats seek to exploit for criminal or other malicious purposes.\nSecurity suite. A set of software applications designed to protect your computer that consists of anti-virus, anti-malware and a personal\nAnti-virus and anti-malware. Helpful software applications that scan your computer for certain patterns of infection. The patterns they scan\nfor are the signatures, or definitions, of known forms of malware. Since Bad Guys are creating new forms of malware continuously, it is important that you keep your anti-virus and anti-malware definitions updated. See\nthe “Patches and Updates” section below.\nPersonal firewall. Software that monitors incoming and outgoing traffic on your computer and checks for suspicious patterns indicating the\npresence of malware or other malicious activity. A personal firewall alerts you to these threats and attempts to block them. Like anti-virus\nand anti-malware software, personal firewalls require frequent updates to provide effective protection.\nUpdates. Security software relies on frequent updates in order to be able to counteract previously undetected forms of malware. Consequently, your computer may suffer a “window of vulnerability” between the time a new form of malware is identified and the time when your security software can block it or remove the infection. Set your security software to update automatically.\nPatches. Operating systems, like Windows and OS X, and software applications, such as Internet Explorer and Firefox, may be found to contain security flaws or holes that make your computer vulnerable to attack. Their makers release patches to plug the holes. The fastest and surest way to get these installed quickly is to use auto-updating via the Internet. Some software applications require manual updating. See the “Patches and Updates” section below.\nBlack Tuesday a.k.a. Patch Tuesday. On the second Tuesday of each month Microsoft releases security patches for Windows, Internet Explorer, Office and its other software products. You can have these installed automatically using Microsoft Update. See the “Patches and Updates” section below.\nAuto-updating. A software tool built into Windows (“Microsoft Update”) and OS X (“Auto Update”) and many other applications which can download and install important security updates and patches for software installed on your computer automatically. See the “Patches and Updates” section below.", "label": 1}
{"text": "Citywire printed articles sponsored by:\nView the article online at http://citywire.co.uk/money/article/a599570\nRisk and return: how to strike the balance in your portfolio\nMike Deverell of Equilibrium Asset Management explains how finding the right level of diversification can reduce the riskiness of your portfolio.\nInvesting can be a risky business. Risk and return are highly correlated; the greater the return you want to make, the more risk you need to take to have a chance of getting it.\nIt is therefore vital that you understand what risks are inherent in any investment you make. Only once you understand the risks can you decide if the potential return is worth it. There is no point taking more risk than is required to meet a given return.\nRisk and return: the theory\nSay there are two stocks, company A and company B. Both are expected to return around 10% growth to investors. However, company A has a much more volatile share price than company B and a greater risk of loss. Given the choice, most investors would invest in company B, which offers similar upside but with less risk.\nFor an investor to buy company A, they would want to see a much greater potential return to justify the extra risk they are taking.\nSo what different types of risk do you need to take into account, and can you do anything to reduce your risk?\n- Stock-specific risk: This is the risk inherent in an individual company. If you invested in just one stock, that individual company could underperform its peers (or even go bust) due to poor management, poor products, or just plain old bad luck.\n- Sector-specific risk: This is the danger that an entire sector could underperform the market. For example, the UK banking sector has underperformed the FTSE over the past few years because of the financial crisis.\n- Market risk: Both stock specific and sector risk can be diversified away by choosing enough different companies and sectors. You are then left with market risk, the risk that the market could fall. Remembering that risk and return are correlated, we could rename this 'market opportunity', the potential that the market will rise.\nThere is some debate as to how many positions are required to diversify away stock- or sector-specific risk. It is generally thought that at least 25 to 30 individual stocks are needed to diversify away most of the specific risk.\nThe simplest way of diversifying this away is to use funds, particularly index tracking funds.\nOnce you start looking overseas for opportunities, other risks come into play.\n- Currency risk: Say you invest in Japan and your investment goes up by 10% in local currency terms. However, the Yen weakens by 15%. You’ve lost money, despite your apparently great stock picking! Some funds avoid this risk by currency hedging, but this increases the cost of investing.\n- Geographic risk: Some countries by virtue of simple geography are riskier to invest in than others. Last year’s Japanese earthquake and tsunami is an obvious example of how an economy and a market can be affected by natural disaster.\n- Political risk: This is the risk that government policy will have an adverse effect on your investment. This has historically been most prevalent in emerging market investing. For example, if you invest in China you would probably want an additional return compared to investing in the UK, due to the inherent political risk.\nUnfortunately, political risk now seems to be unavoidable in any market and is currently the main driver of price movements of virtually all assets. As the eurozone debt crisis and the implications for our financial system continue, this seems unlikely to change soon.\nConstructing a portfolio\nTo recap, risk and return are intrinsically linked, but some risks can be diversified away. By diversifying correctly, you can increase your potential return and reduce your risk.\nAs well as diversifying away specific risks in stocks, you can also diversify away some of the market risk of equities by investing in other asset classes, such as bonds and property. The asset allocation of a portfolio is the key driver of returns.\nGetting the mix of a portfolio right is difficult. It is possible to overdiversify, as once you get past a certain point each additional position makes a much smaller difference to your risk.\nMore about this:\nMore from us\n- Why passive funds beat active management\n- Asset allocation: where bonds fit in to the big picture\n- Sharpen your asset-allocation skills to profit from the volatility\n- Equilibrium Asset Management\nTools from Citywire Money\nFrom the Forums\nWeekly email from The Lolly\nGet simple, easy ways to make more from your money. Just enter your email address below\nAn error occured while subscribing your email. Please try again later.\nThank you for registering for your weekly newsletter from The Lolly.\nKeep an eye out for us in your inbox, and please add firstname.lastname@example.org to your safe senders list so we don't get junked.", "label": 1}
{"text": "Navy delves deeper into undersea robotics\nBy the end of the decade, the Navy plans to deploy squadrons of unmanned underwater robots to survey the ocean. But there are a lot of challenges operating underwater, and the robots will require a great deal of autonomy to carry out search and mapping missions.\nThat’s the goal of the Adaptive Networks for Threat and Intrusion Detection or Termination (ANTIDOTE) program. Funded by the Office of Naval Research (ONR), ANTIDOTE’s team of scientists from the Massachusetts Institute of Technology and the University of Southern California is developing software-based methods for large teams of robots to perform more sophisticated missions autonomously in dynamic, time-critical environments and with limited communications.\nA major part of the program focuses on autonomous planning and replanning methods, said Marc Steinberg, ANTIDOTE’s program officer at ONR.\nEnergy lab’s microscopic robots assemble selves, can move larger objects\nAndroid phones to be ‘brains’ of space station robots\nThe underlying theory behind ANTIDOTE was for persistent surveillance of dynamic environments, regardless of the vehicle type carrying out the mission, Steinberg said. For example, some successful simulation experiments have been conducted with unmanned air systems.\nUndersea vehicles have very limited communications compared with systems that operate above ground, Steinberg said. This drives a need for autonomy because the robot subs can’t rely on a human operator.\nAdditionally, there are unique challenges in navigation, mobility and sensing underwater. For example, the undersea glider robots in ANTIDOTE's experiments use changes in buoyancy for propulsion, rather than an active device such as a propeller. This enables them to have an extended endurance, but it also requires that gliders move up and down in depth in a saw-tooth-like pattern, which has a big impact on how to do autonomous planning to maximize the value of the scientific data being collected.\n“The sea experiments were a great way to examine how some promising theoretical results would work in a real-world situation of practical value to scientists,” Steinberg said. Prior theoretical work had looked at how autonomous vehicles can best perform persistent surveillance in a dynamic environment.\nIn the sea tests, the new software was used to generate paths for the underwater gliders to collect oceanographic data. The method takes into account both user priorities and ocean currents in determining these paths. The experiments, in southern California and in Monterey Bay, Calif., involved a glider using this new capability and a reference glider that followed a more traditional fixed path.\nResults of the experiment showed that the vehicle using the new method executed two to four times as many sampling profiles in areas of high interest when compared against the unmodified reference glider, while maintaining an overall time constraint for the completion of each circuit of the path, ANTIDOTE researchers said in a statement.\nOverall, the results validate that the theoretical results can be of value in solving real-world surveillance problems with autonomous systems, Steinberg said.\nThe ANTIDOTE program is near the end of its third year. After that, Steinberg said that it is up to ONR leadership to decide whether to fund it for an additional two years.\n“As a fundamental research program, the main products are new theory and methods,\" he said. \"Some of these are being implemented in software and will be available to other researchers via open architectures for robots.”\nHenry Kenyon is a contributing writer for Defense Systems.", "label": 1}
{"text": "updated Aug 18, 2008 8:55 pm | 6,384 views\nRevision as of 19:50, 24 July 2007\nSpyware is defined as a program that secretly monitors your actions on your computer. Any data collection program that gathers information about you and relays it to advertisers and/or other interested parties falls under this Internet jargon.\nSpyware is any software that employs a user's Internet connection in the background (the so-called \"backchannel\") without their knowledge or explicit permission.\nIn order to not be considered spyware, silent background use of an Internet \"backchannel\" connection must be preceded by a complete and truthful disclosure of proposed backchannel usage, followed by the receipt of explicit and informed consent for such use.\nAny software communicating across the Internet without these key elements is guilty of information theft and is properly and rightfully termed: Spyware.\nThe effects of spyware are varied and depend a lot on your system. The most common effects include:\nThe list could go on and on but I think you get the idea. So, do not just assume it is a virus when your system crashes, behaves strangely, or acts erratically.\nHere are the main players in the defense against Spyware (in no particular order):\nSpybot (Freeware), AdAware (comes in a variety of flavours; all with increasing levels of defense, control and cost), Pest Patrol (again, like Adaware it has a variety of Flavours), Spy Sweeper, Ewido, and A2Squared.\nSpyware is software that gathers information about your Web-surfing habits for marketing purposes. Spyware \"piggybacks\" on programs you choose to download. Tucked away in the fine print of user agreements for many \"free\" downloads and services is a stipulation that the company will use spyware to monitor your web habits for business research purposes.\nSpyware takes up memory and space on your computer. It can slow down your machine, transmit information without your knowledge, and lead to general computer malfunction. One of the most widely-used Web browsers, Internet Explorer is especially susceptible to spyware-related problems. You may choose to keep certain spyware programs on your computer in exchange for the free services that accompany them, but you should be aware of how that might affect your computer.", "label": 1}
{"text": "Once an attacker has physical access to the computer, he almost certainly has access to the data on it, writes Security Supersite Editor Larry Seltzer. If so, the OS doesn't really matter.\nVery often well hear reports about a serious security vulnerability. We look into it, and theres a catch: In order to execute the attack, physical access to the computer is necessary.\nYou can safely ignore these alleged vulnerabilities: Without physical security, no system is secure.\nIf I can open the computer, I can remove the hard disk, put it in as the second drive in another computer and read the contents of the disk. Bye-bye, security. But its not usually necessary to open the box. I can boot the system off a floppy disk or CD-ROM and read the hard disk that way. Given such access, there are commercial and free tools available\nthat can reset the Administrator password on the installation of Windows NT, Windows 2000 or Windows XP - gaining access to a Win9x system is even easier. (The existence of these tools is a good\nthing; administrators need to be able to access systems where the passwords are forgotten or changed for malicious purposes.)\nBut even thats not necessary; if you can boot off the floppy or CD, you can install a second copy of Windows on the hard disk and run that to analyze data on it.\nThis point is very important when considering whether attacks represent vulnerabilities in the computers operating system: If I boot the system off the floppy or CD-ROM, the operating system on the hard disk is not running. Its just a bunch of files.\nYour only potential protection when physical security is breached is to use an encrypted file system, such as Windows 2000 Pro and Windows XP Pros EFS. (See this article\non the SecurityFocus Web site for a good explanation of encrypting file systems.) No operating system (to my knowledge) employs such a file system by default.\nThe most recent such case of significance was an allegation by a famous writer that one could break into a Windows XP system by booting off a Windows 2000 CD and running the Recovery Console. The Recovery Console is a special console mode OS used to repair Windows 2000 and Windows XP. You run it by installing it to the hard disk and booting into it, or booting it directly off the Windows installation CD. See this Microsoft Knowledge Base article\nfor a description of the Recovery Console, and this one\nfor a description of the Windows XP Recovery Console.", "label": 1}
{"text": "MS10-047 is not categorized as virus, worm, Trojan or backdoor. It is a group of important vulnerabilities in the Windows Kernel on Windows 2008/Vista/XP computers, which allows to gain local privilege escalation and to launch denial of service attacks.\nThe kernel is the core of the operating system and provides basic services for all other parts of the operating system.\nIf exploited successfully, MS10-047 allows to gain unauthorized privileges on a computer or network. An example of privilege elevation would be an unprivileged user who could manage to be added to the Administrator's group. In such case, the hacker could take complete control of the system: create, modify or delete files, install programs, create new user accounts, etc. It could also cause the system to stop responding until it is restarted.\nMS10-047 is usually exploited by running a specially crafted program in the vulnerable computer. In order to do so, a hacker must be able to log on locally to the system.\nIf you have a Windows 2008/Vista/XP computer, it is recommended to download and apply the security patch for this vulnerability. Click here to access the web page for downloading the patch.\nBear in mind that this security patch replaces a previous one, called MS10-021.", "label": 1}
{"text": "In the course of a busy day, you may write a\ncheck at the grocery store, charge tickets to a ball game, rent a\ncar, mail your tax returns, change service providers for your\ncell phone, or apply for a credit card. Chances are you don't\ngive these everyday transactions a second thought. But an\nidentity thief does.\nIdentity theft is a serious crime. Identity\ntheft is a crime in which an imposter obtains key pieces of\ninformation such as Social Security and driver's license numbers\nand uses it for their own personal gain. People whose identities\nhave been stolen can spend months or years and thousands of\ndollars cleaning up the mess the thieves have made of a good name\nand credit record. In the meantime, victims of identity theft may\nlose job opportunities, be refused loans for education, housing,\nor cars, and even get arrested for crimes they didn't commit.\nHumiliation, anger, and frustration are among the feelings\nvictims experience as they navigate the process of rescuing their\nThere are four types of identity theft crime:\n- Financial ID Theft This type of\ncase typically focuses on your name and Social Security\nnumber (SSN). This person may apply for telephone\nservice, credit cards or loans, buy merchandise, lease\ncars or apartments.\n- Criminal ID Theft The imposter in\nthis crime provides the victim's information instead of\nhis or her own when stopped by law enforcement.\nEventually when the warrant for arrest is issued it is in\nthe name of the person issued the citation- yours.\n- Identity Cloning In this crime the\nimposter uses the victim's information to establish a new\nlife. They work and live as you. Examples: Illegal\naliens, criminals avoiding warrants, people hiding from\nabusive situations or becoming a \"new person\"\nto leave behind a poor work and financial history.\n- Business or Commercial Identity Theft\nBusinesses are also victims of identity theft.\nTypically the perpetrator gets credit cards or checking\naccounts in the name of the business. The business finds\nout when unhappy suppliers send collection notices or\ntheir business rating score is affected.\nNo matter what type of identity theft is involved, the result\nis a long and sometimes arduous road to recovery. As in all\ncrimes, preventing the crime from occurring in the first place is\nIdentity theft is a complex problem. You will\nnot be able to work on clearing your name as fast as you'd like.\nCompanies move slowly, partly to protect you. Most imposters are\nnever found, let alone arrested or convicted. This is often not\nthe fault of law enforcement, but rather the nature of the crime.\nSo, work with the police, help them out when you can, but let\nthem investigate. Work on clearing your name and getting your\nlife back to normal.\nthieves get your personal information\n»How identity thieves use your personal\n» Steps to Take When Identity Theft Happens\n» Chart of Action\n» Tips to Protect Yourself\n» File a Police Report\n» What You Can Do\n» Download Identity Theft Coach", "label": 1}
{"text": "2 Tips for a Secure Password\nWe were surprised to learn that some of the leading sites (LinkedIn, Dropbox) got hacked recently. The problem is that most of us have one or two passwords we use across multiple websites. This can cause a significant problem when a hacker discovers one of these passwords and gains access to virtually all the user’s accounts. Fortunately, there are two simple steps to creating an uncrackable password.\n1. Create an Acronym as Your Base Password Think of a sentence, something like “I like walking in the park on a sunny day”, or a refrain from your favorite song like “Billie Jean is not my lover, she’s just a girl who claims that I am the one” and take the first letters of the words. In the latter case, it would be BJINMLSJAGWCTIATO - nearly impossible to crack, but super easy for you to remember.\n2. Modify for Each Website Create a rule, where you append the base password with a variation based on the name of the site. It might be the first vowel, repeated twice, followed by the second consonant of the site’s name. So for Yahoo Mail, it would be AAH. For Dropbox it would be OOD. Or something like that. Now you have 1 set of rules, which are very easy for you to remember, but virtually impossible to crack. Best part, if any of the sites get hacked, your password will be completely safe.\nNow that you secured your email, it’s time to try SaneBox!", "label": 1}
{"text": "Making sense of vast amounts of data is made easier through processor improvements, faster networks and a growing amount of cloud storage capacity, but there’s another factor that’s accelerating the ability to sift through information: user communities. At the Structure Big Data event on Wednesday, Alfred Spector, a VP of Research and Special Initiatives at Google, illustrated how to combine low-level user data with the massive information stores and cloud computing services offered by his company.\nPerhaps the most prominent example is Google’s geographic data used both in both the Google Maps and Earth products. The company harvests global information to create useful products in their own right, but each can be supplemented through localized user data. A modern data management web app makes it easy for Google to host, manage, allow collaboration and publication of data tables or personalized maps. For example, Google Maps data combined with information from hospitals and doctors can easily show which nearby health-care providers have flu vaccines available.\nMaking large amounts of data usable and modifiable by end users has the potential to create solutions that Google hasn’t envisioned yet. But what it has done is allowed for what Spector calls a “hybrid intelligence” because users and computers are doing more together than either could do individually. Scientists that track global warming may only have access to limited datasets which show only a small picture of the overall situation. Google Earth, however, can augment its base data with sensor information from various satellites and datapoints, providing a more holistic view of global warming.\nThis user community and data combination approach is leading to smarter machines as well. The voice search features offered by Google are becoming more accurate due to speech recognition data provided by users. In effect, the speech service is training itself because it’s learning from all of the incoming data.\nJust as they can with Google Maps data, end users can leverage these smarter machines as well. Spector said that a spam-killing blog moderator could be created by end users if they train the system with both good blog posts and spam comments. Those inputs, combined with Google’s prediction APIs and Python scripts, would effectively create an intelligent automated moderator that could continuously improve its own performance.", "label": 1}
{"text": "What is identity theft?\nBasically, identity theft involves someone taking your personal information without your knowledge to commit fraud or theft. According to the Federal Trade Commission (FTC) identity theft costs Americans billions of dollars every year. It is estimated that as many as 9 million Americans have their identity stolen each year. Victims can spend hundreds of dollars and countless hours trying to repair their credit and good name. The latest trend involves thieves taking advantage of the current economic situation by targeting job seekers, by establishing fake online job sites.\nThe FTC recommends a deter, detect, and defend approach to protect yourself from identity theft. You can deter identity theft through safeguarding your information. Detect identity theft by monitoring your financial accounts and billing statements regularly.\nDefend yourself by following the following steps should you suspect a problem in order to minimize the damage:\n1. Place a “Fraud Alert” on your credit reports and review the reports carefully. The three nationwide consumer reporting companies have toll-free numbers and can place a 90-day Fraud Alert on your credit report:\nExperian: 1-888-EXPERIAN (397-3742)\nA call to any one of the three companies is sufficient and entitles you to free copies of your credit report once the fraud alert is placed.\n2. Close all accounts that have been opened fraudulently or any existing accounts that have been tampered with. Notify your bank to flag your accounts and to contact you should there be any unusual activity. Keep a record of your conversations regarding your accounts, including the date, time, and the name of the person you spoke with. Also, keep copies of documents regarding the theft.\n3. Contact your local police. Obtain a copy of the police report.\n4. Contact your nearest U.S. Postal Inspection Service office.\n5. Contact the Social Security Administration’s Fraud Hot line at 1-800-269-0271.\n6. Contact the Department of Motor Vehicles to find out if another license was issued in your name. If so, request a new license number and fill out a complaint form for the DMV to begin the fraud investigation process.\n7. Report the identity theft to the FTC which helps law enforcement across the country in the investigations. Call 1-877-ID-THEFT (438-4338) to report the theft.\nIf, after following all the above steps, you feel you need an investigator for follow-up investigation, or consultation, we are there to help.\nCall Toll Free for More Information and a FREE Consultation!", "label": 1}
{"text": "Asudhak, don't feel bad if this is a bit confusing. Inventing asymmetric cryptography was a huge advance in Mathematics. It seems very counter-intuitive if not down right impossible when one first encounters it.\nWhen a client (often a web browser) and a server (often a web browser) want to establish a secure communications channel they perform what is called a 'key exchange'.\nThe public key that the server provides to the client program contains nothing secret. It's only function is to encrypt information.\nThe client generates a one time secret password that only the web browser knows. The client then uses the server's public key to encrypt that one time use secret password. The public key can only encrypt, the public key can not decrypt!\nThe client can safely transmit this encrypted secret password to the server. Any man-in-the-middle who might intercept this key exchange will gain no useful information since he almost certainly can't decrypt that one time use secret generated by the client and encrypted with the server's public key.\nThe server, and only the server has the corresponding private key. The server's private key can only be used to decrypt. The server's private key is never transmitted to anybody!\nThe server uses the private key to decrypt the one time secret password that was generated by the client (web browser).\nThe client and the server now both know a secret that nobody else knows!\nUsing this secret they can encrypt their subsequent conversations using any traditional symmetric encryption algorithm with a high degree of confidence that the channel is secure.\nIn addition, the client has a store of 'certificates' that contain the public keys of organizations that it trusts. The actual TLS key exchanges will fail if the server doesn't present a digital document called a certificate that contains a hash value encrypted with the trusted organization's private key. The client can use this hash and the trusted public key to know that this server is considered trustworthy.", "label": 1}
{"text": "Put a somewhat less descriptive, but more conceptual way, basically you want to provide two different means to get to the same key. This is the idea of having a data key, typically unique to a record, or perhaps to all of a user's records, depending on security needs. You then encrypt that key with a key derived from their password and a key derived by some other piece of information. It could be an alternate thing that they know or it could be something that your server knows. This can either be symmetric cryptography, or for greater security, the information your server knows can use a public key for a private key that is not held on the server.\nThen if the user ever loses there password and is thus unable to access the data key, the alternate encryption of it can be decrypted to retrieve the key. In order of security, symmetrically storing the key on the server is least secure as if both the server and DB are compromised, the encryption is rendered useless. The user information might be a little better, but for it to be easily rememberable, it will also likely be easily researchable or guessable, which is insecure even if the server isn't compromised. The asymmetric option where the server doesn't have access to the information necessary for a reset (because it only knows how to encrypt the recovery version of the data key is the most secure, but it is also the most difficult from a usability standpoint as the decryption then has to either be done a) by hand or b) by a secondary, highly secured server, preferably holding the private key in a TPM (trusted platform module) or some other secure hardware keystore.\nEither way though, the basic principal is the same. You always make the key unrecoverable without the secret, you just store it multiple times with different secrets.", "label": 1}
{"text": "Cloud Computing Overview\nThe cloud computing engine is a natural extension of the Internet. One of the terrific advantages is the transition to the point where there are no major software upgrade releases; cloud is about building software capability that is continuously improved. It is about hosting software on an Internet platform that works, where the user does not have to worry about the platform. Major software releases are rare on the cloud. Software test and development are an ongoing process and software upgrades are released as appropriate, but certainly on a weekly basis.\nCloud software exposes syntax and applications to users across the board for all different kinds of applications. In a sense, cloud computing is so powerful that we can think of it as a black hole that depends on the creativity of the provider. Cloud initiatives are bound only by the user’s imagination. The quantity of data and the quality of analytics leave the possibility of innovation at every users desktop, laptop, netbook, tablet, smart phone, and Internet accessible device.\nCloud is in a sense another name for self-service computing. In this respect it is the opposite of the old batch oriented mainframe computers. It is a new, fleet footed, sure way for users to independently define and automate tasks in real time, using their own integration syntax and their own ability to create content modules that are meaningful. No more waiting one year for IT to prepare a mailing list that only IT can change, no more running tasks in batch. In the cloud, everything happens using open systems in real time.\nCloud computing provides a consolidated working environment where collaboration is possible and encouraged. Systems are dense. Systems use 80% less energy and transform systems management, creating automated process to replace what previously has taken hundreds of technicians. Hundreds of technicians that have been responsible for managing individual servers can be replaced with six technicians able to run a virtualized system, achieving significant savings in operations costs Running virtualized workloads on consolidated platforms is called modernization. This virtualized, software managed cloud computing environment depends on hypervisors and software systems that streamline workload deployment.\nSo, from the users perspective the cloud is an altogether new and different approach to computing, a utility like service where the machine is always on, always available, and intuitive to use. But, from the IT administrators perspective, the advent of cloud computing brings some of the old along with the new. The old mainframe workload manger has been revitalized, achieved new capabilities, and been given an industry transformational status, given new life under a new, more powerful cover, the IBM zEnterprise 196. The era of hybrid computing has been ushered in under the name of cloud computing.\nMore and more, the cloud is used to implement enterprise applications. Customization, optimization, security, privacy, availability, and reliability are key to keeping automated process producing revenue consistently. Modular systems have become key, some are built with some application SOA services orientation, and some to support Web applications based self-service.\nPrepackaged, self-contained, purpose-built service delivery platforms combine the best of hardware, software and services to quickly accelerate the creation of service platforms for all types of workload.\nOver the next few months I will be sharing with you my thoughts on cloud computing, across topics like the business case for cloud computing, Infrastructure as a Service, Software a a Service, Platform as a Service, and Process as a Service all in the context of cloud virtualized systems. And I will be passing along some insights from some IBM cloud experts, as they continue to grow their enterprise cloud capabilities, most recently showcased on December 1. https://events.unisfair.com/rt/ibm~cloudlaunch Come back often and stay well-informed about cloud computing.and x86", "label": 1}
{"text": "Quality of Service for Web Services-Demystification, Limitations, and Best Practices, Page 2\nWeb Services Accessibility\nAccessibility defines whether the Web Service is capable of serving the client's request. High accessibility of Web Services can be achieved by building highly scalable systems.\nBuilding scalable systems are expensive, and this may cause smaller companies to defer this requirement. Also, this becomes an infrastructure issue for companies that deploy Web Services within their enterprise.\n- Service pooling\n- Load balancing (Scalability)\nWeb Services Availability\nAvailability defines whether the Web Service is ready for immediate consumption. Associated with availability is Time-to-Repair (TTR). TTR represents the time it takes to repair the Web Service.\nBuilding fault-tolerant systems for highly available Web Services is expensive. As companies roll out Web Services, the ability to manage this diverse, dynamic, distributed environment will become critical. Questions such as the following arise:\n- Has one of my key servers become unavailable?\n- Is a system being overly burdened?\n- Why are requests taking so long?\n- Web Service Management\n- Web Service Clustering\nWeb Services Interoperability\nThe fundamental goal of interoperability in Web Services is to cross the lines between the development environments used to implement services so that developers using those services don't have to think about which programming language or operating system the services are hosted on.\nMost of the Web Services specifications are defined under standards bodies. As these activities are under way, there seems to be a delay in the implementations. Vendors partly implement the specification in their products due to the competitive nature of this market. This results in poor interoperability.\n- Key to enabling seamless Web Services interoperability is the ability of one Web Services framework to consume the WSDL documents generated by other frameworks.\n- Web Services-Interoperability (WS-I) Profiles.\nThe Basic Profile defines how a selected set of specified Web Services technologies, such as messaging and discovery, should be used together in an interoperable manner.\nWeb Services Security\nWith the increase in the use of Web Services, which are delivered over the public Internet, there is growing concern towards security. Security for Web Services means providing non-repudiation and confidentiality by authorizing the parties involved, encrypting messages, and providing access control. The Web Service provider may apply different approaches and levels of providing security policy depending on the service requestor.\nSOAP is a de-facto messaging standard for Web Services; inherently, it does not support many security features. Some of the Web Services-enabled applications also require role-based security features, which expose different functionalities, depending on user credentials. Underlying technologies used by Web Services currently do not support these features.\nThe security-related issues in Web Service must be dealt with greater vigor, as it will build confidence among users. The following measures can be used while architecting the secure Web Services:\n- Use of XML Encryption.\n- Use of XML Key Management Specification.\n- Use of Private WANs, Web Service Network, and VPNs.\n- P3P (Platform for Privacy Preferences) is an emerging standard for specifying privacy preferences for a user while using Web Services.\n- Use of security assertions.\nConclusionQoS for Web Services is about bringing business value to service providers by guaranteeing a competitive edge through their ease of adoption and implementation. With these collections of best practices for the design and implementation of Web Services, one can think of Web Services as a perfect replacement for traditional integration problems that are being faced by the enterprises today. We will be analyzing each of these proposed best practices in forthcoming articles.\nAbout the Authors\nRajesh Sumra is a senior software engineer in HP's Wireless Solutions Lab. He has worked with the espeak project for more than a year and was involved in developing UDDI Server functionalities for the HP's UDDI Server. Currently, he is involved with designing and developing a Web Services-based framework for the mobile infrastructure. Rajesh holds a Masters degree in Information Technology from IIIT, Bangalore. He can be reached at firstname.lastname@example.org.\nArulazi D has been designing and building Java-based applications and SDK for more than three years. He was also involved in the API development of UDDI4j project (http://uddi4j.org). He works with Hewlett-Packard (ISO), where he is involved in the development of an open-service framework for mobile infrastructures. He holds a Master of Computer Applications degree from the PSG College of Technology, Coimbatore. He can be reached at email@example.com.", "label": 1}
{"text": "(ARA) – The app world is booming and today there are more than 1 million mobile apps available for download through online stores run by companies like Apple and Google. Many apps are available free of charge and collect user data for advertising purposes, raising the question: What is the true cost of these “free” apps?\nSmartphones today collect and store a wealth of personal information because they’re always “on,” and typically go wherever their users go. Consumers store extensive contact information, calendar data, and personal videos and photos on these devices. Modern smartphones may also contain GPS technology capable of collecting precise data about the phone’s movement and location in near real-time.\n“Personal data collection online has been happening for years on traditional PCs,” says Babel. “The difference today is that these ‘computers’ now sit in our pockets in the form of smartphones, and are capable of collecting more types of data, in greater quantities, than ever before. It’s a far more complex ecosystem and it can be difficult for consumers to understand what’s happening with their data. ”\nUnwelcome data collection on smartphones can lead to unwanted and intrusive advertising, and increase the risk of data breaches as companies build ever-larger databases of personal information profiling consumers. Before you click that next free download, TRUSTe recommends taking these steps to protect your privacy:\nSet app and smartphone privacy settings\nMany apps contain privacy settings that can control behaviors like what information the app collects, how it interacts with other apps or a user’s contacts, and how it communicates with and alerts the app user about its background activity. In some cases, these settings may have their own section under a “privacy” tab within the app, but more often than not these privacy settings are found alongside standard settings within the app, like volume levels or sound effects.\n“We commissioned a Harris Interactive survey and found that nearly three quarters of the population worries about their privacy when using mobile apps,” says Babel. “App developers not only have a responsibility to provide consumers with mobile-appropriate privacy disclosures, but also meaningful choices about how their data is collected and used.”\nThe settings tab of your smartphone operating system (like iOS for Apple devices) may also contain important privacy choices, allowing you to control the types of personal information that apps may collect from the device. Depending on your device, these settings may also provide you with granular privacy control over apps, preventing one app, for example, from collecting GPS data while allowing other apps to collect this data.", "label": 1}
{"text": "Schneier on Security\nA blog covering security and security technology.\n« Power and the Internet |\n| Jared Diamond on Common Risks »\nJanuary 31, 2013\nThe Eavesdropping System in Your Computer\nDan Farmer has an interesting paper (long version here; short version here) discussing the Baseboard Management Controller on your computer's motherboard:\nThe BMC is an embedded computer found on most server motherboards made in the last 10 or 15 years. Often running Linux, the BMC's CPU, memory, storage, and network run independently. It runs Intel's IPMI out-of-band systems management protocol alongside network services (web, telnet, VNC, SMTP, etc.) to help manage, debug, monitor, reboot, and roll out servers, virtual systems, and supercomputers. Vendors frequently add features and rebrand OEM'd BMCs: Dell has iDRAC, Hewlett Packard iLO, IBM calls theirs IMM2, etc. It is popular because it helps raise efficiency and lower costs associated with availability, personnel, scaling, power, cooling, and more.\nTo do its magic, the BMC has near complete control over the server's hardware: the IPMI specification says that it can have \"full access to system memory and I/O space.\" Designed to operate when the bits hit the fan, it continues to run even if the server is powered down. Activity on the BMC is essentially invisible unless you have a good hardware hacker on your side or have cracked root on the embedded operating system.\nWhat's the problem?\nServers are usually managed in large groups, which may have thousands or even hundreds of thousands of computers. Each group typically has one or two reusable and closely guarded passwords; if you know the password, you control all the servers in the group. Passwords can remain unchanged for a long time -- often years -- not only because it is very difficult to manage or modify, but also due to the near impossibility of auditing or verifying change. And due to the spec, the password is stored in clear text on the BMC.\nIPMI network traffic is usually restricted to a VLAN or management network, but if an attacker has management access to a server she'll be able to communicate to its BMC and possibly unprotected private networks. If the BMC itself is compromised, it is possible to recover the IPMI password as well. In that bleak event all bets and gloves are off.\nBMC vulnerabilities are difficult to manage since they are so low level and vendor pervasive. At times, problems originate in the OEM firmware, not the server vendor, adding uncertainty as to what is actually at risk. You can't apply fixes yourself since BMCs will only run signed and proprietary flash images. I found an undocumented way of gaining root shell access on a major vendor's BMC and another giving out-of-the box root shell via SSH. Who knows what's on other BMCs, and who is putting what where? I'll note that most BMCs are designed or manufactured in China.\nBasically, it's a perfect spying platform. You can't control it. You can't patch it. It can completely control your computer's hardware and software. And its purpose is remote monitoring.\nAt the very least, we need to be able to look into these devices and see what's running on them.\nI'm amazed we haven't seen any talk about this before now.\nEDITED TO ADD (1/31): Correction -- these chips are on server motherboards, not on PCs or other consumer devices.\nPosted on January 31, 2013 at 1:28 PM\n• 44 Comments\nTo receive these entries once a month by e-mail, sign up for the Crypto-Gram Newsletter.\nHmm. How are those BMCs accessed? Do they have their own IP? Take over some port from the OS? Or wait for some secret protocol? Have their own port and connection?\nIf someone 20 or 30 years ago had written a science fiction story about something like this happening in the future, they would have been laughed at. Nobody could ever be so stupid as to allow a situation like this to happen! Yet here we are.\nThe conclusion that I've reached is that humans, for all their self-advertised intelligence, are basically stupid beasts who do whatever seems convenient and easy at the moment. They have no ability to envision future possibilities in any real sense, and will not change their behavior to avoid disaster. Instead, they adapt to the consequences when the time comes.\n@EPh - BMC has its own IP address. Ethernet port can be dedicated or shared with OS.\nOn my MacBook:\nbash-3.2# networksetup -showBMCSettings\nUnable to determine if BMC is supported - error 0xFFFEF92D.\n** Error: BMC is not supported on this device.\nI work with these facilities quite a bit as a server administrator. It's not entirely true that these are unable to be patched.\nWorking with Sun(now Oracle), HP, Dell, IBM server hardware, we've had to patch and in fact did patch these controllers consistently, most often due to bugs, or secondly to pick up new features that we wanted to use to help us with either performance (Patches usually also contain BIOS firmware upgrades) or to help keep them managed efficiently.\nFor the big guys at least, they are able to be patched, but admittedly, it can be a pain in the butt, and I don't know how many actually do it outside of my own practices, but they are certainly possible to be patched to fix any bugs they might be found to contain. I'm sure this varies by hardware vendor, or perhaps age of systems, so there is some risk there too.\nAnton Yuzhaninov has it right. And there are a few things you can do to mitigate this risk.\na. don't plug in the management port if you don't want to use it.\nb. restrict access to the VLAN (or physical switch) that you connect it to if you do connect it.\nc. restrict access to the IP addresses you assign to them if they are connected.\nAfter that, if someone gets access to them you'll have to fall back on strong passwords and staying current with the patches. Fortunately, the patches are usually easy to apply and do not require rebooting the server since they are are on a sub-system of that server.\nEPh: They have their own ethernet port on the box. Smart money is to put them on their own (unrouted) VLAN and behind a firewall.\n@Kryai - as with other closed source products you are depend on vendor. If vendor don't want to ship new BMC firmware version after some bug in code is reported, you servers will be vulnerable.\n@EPh: BMCs may have a dedicated ethernet port or share a main system port, depending on a particular system's configuration. They're assigned an IP address, usually in private / nonrouteable space (10.0..0/8, 172.16.0.0/12, or 192.168.0.0/16) that's accessible only within the datacenter LAN for an entity. However access may be forwarded outside (say, to the office LAN where admins are located), or made available through a bastion host or port-forwarding to specific network ranges or IPs.\nYou're going to find BMCs of some sort on virtually all server-grade hardware (and few admins would accept hardware that doesn't offer such functionality because of the utility of the remote management provided). Typical uses are to provide a \"failsafe\" serial-console access to a system, and allow hard/soft reboots. Vendor extensions to IPMI (iDRAC, iLOM, etc.) often rely on additional technologies such as Java (what could possibly go wrong). And there is often a Web interface to at least some functionality. IPMI will generally offer SNMP traps (monitoring facilities), which is a protocol with its own host of security concerns.\nIn addition to BMCs there are other \"under the OS\" systems with similar concerns. Virtualization systems such as Xen (used by Amazon for its AWS / EC2 services), VMWare (used by many organizations to virtualize systems and services for managment), and others (VirtualBox, Parallels, KVM, qemu, ...). Boot systems including particularly EUFI, but also bootloaders which are themselves increasingly small operating systems themselves. The guys who sweat security and trust really sweat this stuff.\nIn addition to BMC on server boards, many laptops now have Intel's AMT which serves a similar purpose. In my experience it's always disabled by default, but it seems like it would be subject to the same security concerns.\nIt's nothing new really. We've deployed many servers with these functions, and best practice is to have them in their own private & secure VLAN without the ability to connect outwards to anything.\nBasic measures, just like protecting ssh and root access to the server OS.\nThis isn't a new concern. On an individual scale it's akin to having the TPM (Trusted Platform Module) or NIC firmware compromised.\nIn 2010 whitepapers/security presentations were done on all three threat vectors.\nWhat's odd is not much has been said since.\nOf note is that I once found an attempt to infect a Broadcom chipset via it's ASF - In the Wild.\nThat short version really is short...\nIn addition to the points that Brandioch Conner noted, checking your log files regularly would help to identify a pending or possible compromise (i.e. HP servers have a logger that tracks who logged or attempted to log into what they call iLO (integrated lights out), the ip, username etc.).\nI'm less familiar with Dell but have used their equivalent iDRAC (no idea offhand what that stands for) on the handful of Dells we run but it's similar too.\nFor the truly paranoid, you could perform a packet capture for traffic destined to the mgmt ip earlier in the stream and log it elsewhere to protect against missing an attacker erasing their tracks (or to correlate logs for integrity, etc. :)\nI was gonna say - I *wish* my desktop had IPMI! I would have uses for that.\nBut no. While it CAN share a NIC with with OS (and Supermicro's do by default, which is very naughty of them especially since the default password for the just-grabbed-a-DHCP-address interface is \"ADMIN/ADMIN\"), that's configurable, and most of the time accessing IPMI means plugging a new wire into the management port. If you run that to your shared LAN switch, then sure, you've opened the IPMI interface to everyone on the LAN - but the solution is *don't do that*. If it's physically connected only to a physically secure network, then you're fine unless the attacker physically has your server. And if the attacker physically has your server, you're already screwed.\nDell DRAC ~ Dell Remote Access Controller. The DRAC comes in several levels; the systems I maintain have the lowest level version and have their network support disabled, which is typically over a NIC shared with the OS. We run FreeBSD which, by default, doesn't support IPMI, and run the servers in a mode that prevents kernel modules from being loaded once the system is in multi-user. In theory this would prevent the IPMI support modules from being loaded. Also, in theory, communism works.\nI've recently concluded that IPMI gives us some additional monitoring capabilities that are useful (e.g., determining system temperature, fan RPMs, etc.), but do not trust the network stack on these devices to be fully hardened and am allowing IPMI access only by root locally on the system. This seems to be a reasonable tradeoff between usability (being able to monitor system health) and security (exposing IPMI capabilities to root).\nBiggest problem: some BMCs seem to default to RFC1918 addresses and ARP out periodically, even when their network connectivity is supposedly disabled. Not routing this traffic internally helps mitigate this brain-damaged behavior.\nThis is the same kind of exposure that network equipment management interfaces have and is mitigated through much the same techniques by segmenting the management traffic so it's not accessible by users. I think this is a threat model that is pretty well understood intuitively and would require some kind of willful misconfiguration to be a problem in most cases.\nActually some \"desktop\" systems do have BMC chips in them.. it all depends if they are enterprise systems or not. [I have seen laptops respond to BMC scans.. I think it was a class of Dell but it might have been a whitebox laptop.] Because the BMC sits before the OS on the ethernet bus you can send it all kinds of things that you think your local firewall blocks but doesn't.. this allows for script kiddies to have fun at various times.. [they do it for a short time and then go away.] There was a \"bug\" in one set of BMC where even if you had set its IP address to something unreachable if you sent the proper Xmas tree packet to the main system it would cause the BMC to reset itself and ask for a DHCP address which you could then probe for and get to.\nCorrection -- these chips are on server motherboards, not on PCs or other consumer devices.\n... so far as we know ...\nIt is all a little late to the party... we have been talking about this quite a lot, there have been talks about AMT (Intel's IPMI-equivalent) and simply nobody cared.\nIt is far more fashionable to talk about browser exploits than it is to look at hardware.\nHow about Charlie Miller's Mac battery firmware hack? Or the PCI hacks (amongst others) by John Heasman? eEye's work in about Tigon2 backdoors which was pretty much at the same time as my own on Broadcom NICs? Andrea Barisani and Daniele Bianco on AMT?\nThat was all 2007 vintage and I don't think we're done yet (I'm not for sure).\nIt is my opinion this scheme of functionality has some amount of economic origins, stemming from 24x7 systems not necessarily staffed appropriately.\nThat is to say, an on-call admin using this function can remotely access an otherwise unresponsive system and potentially resolve issue(s). Thus negating the requirement for on-site staff during \"off-hours\".\ncalvin? hobbes' computer isn't working any more...\n>these chips are on server motherboards, not on PCs or other consumer devices.\nYes they are, they're built into Intel's vPro chipsets, intended for business users. Note that if you want to detect them you can't access them from the same machine the device is in because it performs (primitive) access-control filtering to prevent that (supposedly done for \"security\" reasons to prevent a local priv-esc by the end user, but it also means you can't easily check whether your own machine has this enabled or not).\nPeople who say \"just put the IPMI on its own private network\" didn't read the paper, where I explicitly address that. If you compromise the server you can change and talk to the network interface to compromise the BMC. You can also hop networks once that's done and also have complete control of the server. Plus you can get the IPMI password from the BMC from memory or files. Any server that's compromised has to be viewed with extreme suspicion as to the integrity of the BMC. This is true for physical access and other methods as well - do you de-provision your server by shredding the BMC and where it stores the passwords?\nRE: patching - again, read the paper. It's not that you can't patch them, its that you can't use *your* patches - a vulnerability found cannot be addressed until the vendor gets around to getting you a fix (if it works at all.) In addition with the heavy use of OEMs (also noted in paper) there are a handful of vendors who supply the major servers means that a problem in the firmware is likely to mean a cross *server vendor* problem that transcends your typical bug. (I'm sorry if conclusions were drawn without context; I put caveats and such on my page that tries to provide context.)\nThis isn't theoretical, I've gotten root on BMCs, recovered passwords, and try to provide further details in the paper.\nI welcome responses (I'll try to check here, flying cross country in the AM.)\nI think every point I see in the comments were explicitly addressed in the paper (if not, me know!) I try to illustrate that it is categorically not the same set of problems as it always was thought to be. If I fail feel free to let me know, but I'd ask folks to read my perhaps laborious but hopefully telling arguments that I try to supply with ample support and details before dismissing my claims.\nThe one pager is meant as a teaser to the larger one - one of primary points I try to drive home is that it's a confluence of a *lot* of different points that individually don't matter, but when taken as a whole is (I claim) a much larger toxic mess. I simply couldn't crush all the details into a page, but wanted to have something one (if convinced or even worried) could hand to a perhaps less technical but business savvy person for a different response.\nIt also doesn't matter if some of your servers in an IPMI group are \"safe\" (whatever that means) - if *ANY* are compromised your entire group has the ability to be compromised - and while the BMC has complete and utter control of the server you simply cannot view any activity on the BMC at all.\nWhen I find a backdoor that allows shell access to the BMC from a major vendor (details TBD; I'm try to let them patch it before releasing details) I find it more than troubling - these things are designed for remote control and managing of servers at a very low level - I think it's utter folly to allow this to continue.\nMany thanks for bruce for putting the pointers here, and the discussion post-post.\n@ dan farmer\n\"I think every point I see in the comments were explicitly addressed in the paper (if not, me know!)\"\nMostly seem to be after a quick read of the HTML paper. Great work on this. I've always suspected the management computers were a security risk. When asked about them for high security networks, I gave people three options:\n1. Disable the port physically & use trusted software on the machine to gather statistics.\n2. Put a little gateway between the management computer and the network that only allows authenticated traffic.\n3. If you trust the networking gear, use it to restrict and monitor access to them.\nI don't trust Cisco et al, hence option 2 existing. However, options 1 and 2 may be impractical for groups with very large numbers of servers. Their default will be option 3. Always tradeoffs...\nRe \"Correction -- these chips are on server motherboards\"\nThat's actually not correct. This functionality is present in modern \"business class\" notebook chipsets from Intel; for example, QM67 which can be found in e.g. Lenovo T420.\nThe technology is called AMT, or Active Management Technology. (Also, Wikipedia has a nice summary which is better than Intel's own).\nThere have been a number of BMC vulnerabilities in the past, for instance:\nfor HP iLO3/iLO4.\nIt's a fairly well understood risk in the datacentre worlds, and is why many larger companies are segmenting and controlling the networks these console ports are connected to.\nUseful things to know:\n* The vendors are fairly responsive to critical vulnerabilities.\n* They almost always have a default password (either a vendor default, or the serial number of the machine).\n* You can always disable the functionality in the BIOS (though I'm not sure whether this disables power to the BMC chip itself).\n@q: Mr Farmer's paper does mention AMT, but it seems it is distinct from IPMI:\n\"Intel launched a similar effort for personal computers called Active Management Technology ( AMT) that shares many features with IPMI, but while hazardous I don't personally view it to be as threatening as IPMI.\"\nOne of the 'additional reading' entries has an analysis on AMT specifically, which on reading doesn't exactly fill me with confidence.\nI'm keen to know more about AMT's vulnerabilities, for several reasons:\n* There are many more consumer devices.\n* Consumer devices definitely don't have the dedicated management port & infrastructure that has been discussed here so far.\n* Consumers aren't going to know how to turn it off, even if it can be turned off.\n* Consumers definitely aren't going to manage it, which means default configuration every time.\n* They can even be accessed via wireless.\nNow if you'll excuse me, I'm going to see if my most recent PC, which I know has AMT, can have it turned off...\n@Jeff H: I did a talk at Breakpoint about AMT/ME stuff that might be interesting to you. The short story is that while it does have its share of issues it's much more mature than IPMI and Intel took its security very seriously, especially in later versions. For example, it supports SSL and certificate-based/Kerberos authentication, remote boot/KVM requires user consent and so on. Here's a nice post outlining some of the details on how it's configured: http://www.symantec.com/connect/articles/...\nEverytime that I update the firmware on a server whether it is IBM, Dell, or HP I always have a new firmware that said vendor has provided fixes for. I think we are bit addicted to the conspiracy theories aren't we? News Flash!! All this crap is built in China. In fact, I don't know of a single vendor that doesn't have a major portion of their production coming right from our friendly communists across the Pacific. This is another false alarm from a conspiracy theorist.\n\"If you compromise the server you can change and talk to the network interface to compromise the BMC.\"\nBut in order to get to there you have to:\na. get onto the server network\nb. exploit a vulnerability in a service that gives you root/admin access that is running on a server that is on the server network.\nc. then you can get access to the BMC.\nBut once you have \"b\" you have lots of options for compromising other systems.\n\"Often running Linux, the BMC's CPU, memory, storage, and network run independently.\"\nIf it's running Linux, and you can't get access to the Linux source code as specifically modified for the BMC on your server's motherboard in order to check for vulnerabilities, your server manufacturer's committing software piracy. Read the GPL and know your rights.\nHmm I'm a little late to this party...\nAnd firstly to those who are saying this is old news etc, yes whilst that is true, it takes time to compile the information test etc, so please Don't Shoot the Messanger. Firstly it's not polite, secondly it's a significant disincentive for others to come forward with similar information.\nNow as to this \"computer within a computer\" in one way or another all PC's have had another computer in them since day one (in the keyboard). Some systems have had limited state machines set up bits of hardware. Almost all standalone modems had a 6502 or equivalent 8bit CPU built in and many hard drive controlers had microcontrolers or bitslice processors built in as have all hard drives in recent times. Likewise most peripherals including every real USB device and as others have noted in bateries and other unexpected but perhaps unsurprising places. And they will continue to appear in more and more places as time goes on and their price drops to cents or less in chips (many real time clock chips are now actually baby microcontrolers).\nBoth Nick P, RobertT, myself and others have repeatedly said over many years, from the security perspective peripherals are as much if not more of a danger to system security as malware. Primaraly because not only do they run \"beneath the OS\" in most cases they run \"beneath the CPU\" and thus control what the Main CPU does or does not see.\nAs a simple rule of thumb anything that runs beneath the Main CPU cannot be audited by the Main CPU thus any kind of nasty can be on there, and more importantly it can access anything the Main CPU can either directly or by getting the Main CPU to do it. Thus it will always be able to work around the \"don't plug in the maintanence port\" as will any command and control messages sent to it from any other connected system...\nWhilst we might not like this there is little we can actually do about it as we will almost certainly get less attention than the big company wish to have less people do more work. That is their stated aim is to reduce costs by (supposadly) making those lucky few who still have jobs \"more efficient\".\nNow as I'm in the habit of repeatedly saying you have the general case of \"Efficiency -v- Security\". That is unless you realy realy know what you are doing at all levels then making a system more efficient makes it less secure. The problem is nobody these days knows enough at all levels to know what they are doing so our systems become more insecure with time.\nNow as I also say with regular monotony \"technology is agnostic to it's use\" like a knife it cares not if it cuts you food or your throat, you however do. In the same way in times befor the safety razor you trusted your barber not to \"Sweeny Tod you\". One way you built up such trust was to go to the barber with a friend untill you both got to know him, then on going on your own you would by way of conversation let the barber know that immediatly after you had been shaved you were meeting a friend who knew you were there. Likewise you almost always let your friends and family know you were going to the barbers and they knew from experiance exactly which one it was. Thus the barber if he had any sense would know you had marked him, so if you disappeared your friends and family would know where to point the finger.\nWe call this process \"building up trust\" unfortunatly it does not always work, that is past behaviour is no indicator of future behaviour and Con artists rely on abusing trust because they have planned their exit strategy so they are not there to have fingerrs pointed at them.\nAnd that's tthe point when it comes to all types of cyber-crime the perpetrator generaly aranges so that they are not there to have the finger pointed at them, or be safely in another safe jurisdiction when the authorities come knocking.\nFor instance Stuxnet and the code signing keys, how did the malware writers get hold of them, and are the people who stole them still around to have fingers pointed and their collars felt? unlikely (unless they were blackmailed etc).\nI've always disliked code signing because it is not a security mechanism just an at best attestation method. All it says is that on such and such a date a body of code was hashed, and digitaly signed. Nothing else, thus steal the key, factor it or add malware upstream of signing or find a hash collision the result will be the same properly signed code... not audited code, not tested code, not bug free code or even secure code just signed code...\nThus there is a myth that has been proved repeatedly wrong that \"signed code is good code\" it's not.\nThe advantage of code signing is that finding hash collisions, factoring or stealing signing keys and getting code into the developers database should be at best very difficult problems.\nBut are they? Unfortunatly in many cases they are not. I've been on a walk through of an organisations development process where in many respects they had gone to a lot of trouble to be secure in how they did their code signing via automated processes. Unfortunatly on a little anaylasis it all rested on knowing the name of a senior member of the developer or test teams that had admin rights over the code repository and their remote login password...\nPublicaly available information gave the names and thus their predictable usernames and the organisations remote access server was vulnerable to having malware put on it so finding out the passwords via a bit of malware was not going to be difficult... And in one case the password was fairly easily crackable even though it followed the usual rules for security on passwords.\nSecurity involving humans is hard because by and large we trust other people and we can be persuaded to turn by various human failings.\nWhilst eliminating many humans from the loop by technical measures is possible you cann't make the systems \"perfectly secure\" and thus ultimatly there is atleast one human (the admin) kept in the loop, making it less secure etc.\nThe other solution is of course issolation or air gapping the systems entirely, but again as I worked out and Stuxnet later showed humans breach the air gap as a simple matter of getting their job done. But as others have noted over and over again computers in general are only as of as much use as the other computers they are connected to. Thus to get not just some but most jobs done requires connectivity.\nIs there a solution? well no because perfect security does not exist, but there are mitigations. The first is \"Eternal Vigilance\" that is you realy have to not only monitor and store what comes in and goes out your door. You have to know exactly what is on your systems and where, and have easy but effective ways to verify whats there. You further have to profile the behaviour of the systtems and humans that use them. And these systems are not efficient or easy to use...\nAt the end of the day \"you pay your money and make your choice\" and currently those in walnut corridor are chosing short term small gain over longterm stability and more secure income...\nI think most people who run lots of servers are very familiar with this. Administration of many machines is involves many trade-offs. These things exist to make machines much easier to remote manage they are the equivalent to the serial consoles unix machines might have attached to a modem pool in the old days.\nI think the thing that surprises security people here is that most large computing rooms have a gooey center behind the hard shell. I think this is the real problem. Once an attacker in inside there is little defense against an attacker who understands the 'enterprise crap' they could hop to any other machine.\nThe problem is not limited to DRAC/Lights-out systems, but its essentially the same for: backup agents, KVMs, SANs (iSCSI, FC, etc...), and \"cluster stuff\" often are designed with the idea that traffic can only come from a special network on which each node is trusted or forgery is impossible.\nThe problems here are:\n1) Security is too fixated on stopping threats from breaching the outer layer and not enough focus on people hopping between enclaves or even acknowledging the size of the perimeter of the crust vs the volume of gooey center.\n2) Often service architects forget these things are there because they often have no control over it. The \"systems folks\" just put it there. Its not a choice if it is used, just which bad product is used.\nIt sounds like technology making a full circle again. In the \"old days\" of mainframes and large minicomputers, they typically had a \"front-end\" or \"console\" processor. It would be responsible for loading the initial bootstrap code into memory, debugging, and stuff like that, by being able to access the main computer's memory and having its (own) disk drive and tty.\nYou can easily tell whether your system has one of these things by watching the BIOS messages on the (console) display when you power the system up. If it's there, it will make itself obvious. We've got a couple of PowerEdge servers at work that have these features. They're not enabled, but they still cause 30+ seconds of delays at firmware boot time. (The RAID controller causes an *additional* 30+ seconds of delays, and there's other stuff too. All of this is before the software boot loader starts. Server hardware takes a lot longer to boot up than consumer hardware.)\n@Jonadab: \"If it's there, it will make itself obvious.\"\nNope. Before reading this thread, I would have interpreted \"Network IPMI enabled\" as an obscure feature, possibly related to bios trying to boot from a variant of ISCSI, thus under my radar.\nThis is quite an eye opener.. Somewhat reminds me of purpose build \"back-doors\" in Chinese grey kit!\nThe desktop version of this is Intel's AMT. This is sold to medium and large enterprises as a desktop management solution.\nThe BMC on the systems I use has all sorts of things other than IPMI 2.0 included. It has a web server embedded along with a proprietary interface running on another port. There is no documentation on this OS (although it can be seen to be linux based). The vendor seems to fix bugs in the BMC software every couple of months. More recent systems do seem to let you turn off the network interfaces for this other junk.\nI have asked the vendor for their security evaluation of the BMC and they are unable to provide it. This vendor has at least one major design problem with the BMC software.\nMy lab has a couple of older HP/Compaq 1U rack-mounted servers with iLO. They've got separate Ethernet ports, get their own IP addresses, and we've done very little with them, but they look like they'd be useful if we were running a server farm. You can at least talk to the machine and decide whether it's up or down.\nBack when the VAX 11/780 was still cutting-edge, it had a PDP-11-on-a-chip for booting, and an 8\" floppy disk, and there were drivers for 4.1BSD that could access the disk. Somebody sent us some data on 8\" DEC floppies, and after some thought we decided it was ok to use the boot floppy drive to read them; worked ok. Traditionally you'd use a DECwriter paper terminal on the PDP console to manage the system, though eventually we shifted over to CRTs. (Hint: Don't play Rogue on the console; the ^P gets interpreted as a request to talk to the microcontroller, which asks if you want to reboot the system. But at least we never put a modem on that port.)\nRecent intel chipsets are full of Intel Management Engine (this appears to be mandatory on all new Intel chipsets), vPRO, AMT and other Intel technologies herein referred to as \"intel embedded rootkit\" from now on\nHow can you disable Intel AMT and related technologies on your motherboard, can you simply de-solder the chip that contains the intel embedded rootkit ARC processor (and firmware, private memory etc)\nI am seriously thinking of desoldering the intel embedded rootkit chip on my new motherboard... Could this introduce any unforeseen problems?\nSchneier.com is a personal website. Opinions expressed are not necessarily those of BT.", "label": 1}
{"text": "Frequently Asked Questions - Security & Policies\n1) How do I protect myself from computer viruses?\n- Install anti-virus software on your computer (Students - please click on this link for further information)\n- Update your virus definitions regularly\n- New virus definitions are released almost every day. By updating your virus definitions the risks of becoming infected is greatly reduced\n- Use good judgment when opening strange or unexpected email attachments and/or files\n- Never open an email attachment from someone you don’t know.\n- It is a good practice to check with a known user if you receive an attachment from them that you were not expecting. (Don’t assume that it is legit!)\n- The type of attachment can also be a tip that something is not right. If you get an email attachment that has two periods in it i.e. .txt.doc, .xls.exe, or any combination of file extensions, DO NOT OPEN IT!!! To find out the real name of an attachment, right click on it and choose “properties”. If the file has an .exe, .vbs, .com, .cmd, .pif or .lnk extension, do not open it UNLESS you were expecting it or it was sent by a known (trusted) user AND you have confirmed that they meant to send it to you.\n- Backup your data\n- The original file that has become infected and/or was destroyed can be restored if you have it backed up.\n2) What should I know about securing my personal computer?\n- The following computer security tips are recommended best practices:\n- Use strong passwords. Choose passwords that are difficult or impossible to guess but easy to remember. Give different passwords to all accounts. See Choosing Good Passwords for additional help.\n- Make regular backups of critical data. Backups should be made at least once each day. Larger organizations should perform a full backup weekly and an incremental backup every day. At least once a month the backup should be verified. (In other words restore something from the backup.)\n- Use virus protection software. That means three things:\n- having it on your computer in the first place\n- checking daily for new virus signature updates\n- actually scanning all the files in your computer periodically (once a week).\n- Use a personal firewall as a gatekeeper between your computer and the Internet. Firewalls can be either hardware or software. In most instances for home use the software firewall should be sufficient. Firewalls are very important for computers that access the Internet via DSL and cable modem connections, but they are also valuable for those who still use dial-up.\n- Do not keep computers online when not in use. Either shut them off or physically disconnect them from the Internet connection.\n- Do not open email attachments from strangers, regardless of how enticing the subject line or attachment may seem. Be suspicious of an unexpected email attachment from someone you do know because it may have been sent without that person’s knowledge from an infected machine.\n- Regularly download security patches from you software vendors. These include but are not limited to your OS (operating system) and office products.\n- Do not use older OS’s such as Windows 95 or 98, there are a great many vulnerabilities in these operating systems and Microsoft does not support them anymore, which means you cannot get fixes and updates for them.\n- Be wise about cookies. Some web sites require that your computer accept cookies before allowing access, but these little programs can reveal a great deal of information about you. Compromise is the key, disable cookies and only enable them when necessary to visit a web site you really need to see.\n- If you use Windows and share files with other Windows users (remember this is against UVA-Wise policy and could result in denial of network privileges), be sure your computer’s permission settings require them to enter a username and password before gaining access. Without this safeguard practically anyone can tamper with your disk drive (with or without your knowledge).\n3) How do I know if my computer has been compromised?\n- If your computer and/or programs running on it are behaving unexpectedly or out of the ordinary.\n- An indicator that your computer may be infected and/or is under attack is if the computer’s speed suddenly becomes very slow and sluggish. Your awareness of this performance change is important. It is recommended that you use antivirus software, keep the definitions up-to-date, and scan your computer frequently so that you may be advised of infections and attacks. (Please note that the best antivirus software will not catch 100% of all viruses/attacks. You may want to use more than one method of identifying malicious activity such as Spybot, Adaware, etc…A word of caution, don’t go overboard.)\n- One way to identify suspicious behavior on your computer is to look for files and/or programs that you did not install.\n- If a program runs or opens by itself (but it didn’t use to do so), you may be infected with a Trojan horse.\n- If you think that your computer has been compromised get assistance immediately\n- Faculty and Staff should get in contact with the Technical Assistance Center (TAC) in 110 Darden or at extension 4509.\n- Students may either call TAC at extension 4509 or seek outside assistance. (If your computer is compromised and it is identified during a routine scan of the network you risk having your port disabled and a possible reconnection fee. See the Student Computing Handbook for more information.)\n4) Can I connect my game system or play PC games on the College network?\nThe Office of information Technology does not explicitly prohibit the use of campus network resources for student gaming purposes; however we do not actively support (ie. fix problems) gaming across the network and/or the Internet. For network security, requested changes to our network system to support gaming will not be accommodated. In the future, if gaming causes a problem for other users on our network, UVa-Wise reserves the right to block this gaming traffic without notice.\n5) What should I know about creating a good password?\n- Literally thousands of computers are compromised each year due to weak or non-existent passwords. The following is a list of some of the things not to do:\n- Write down a password on a sticky note or piece of paper and place it near your computer. (This includes the center drawer in your desk, the sliding shelf in your desk, the monitor, under the keyboard, etc.)\n- Use a word found in the dictionary. That includes foreign dictionaries.\n- Use a word from a dictionary followed by a couple of numbers.\n- Use the names of spouses, children, friends, enemies, relatives, pets, or other common items.\n- Use dates such as anniversaries, birthdays, christenings, etc.\n- Share you password with someone (anyone) else\n- Use the same password for more than one account, and for an extended period of time.\n- Use the default password provided by the vendor.\n- Why would this be a problem?\n- Passwords are one of the first lines of defense in the protection of computer systems. Most computer users don’t recognize the importance of using strong passwords, especially when they can be very complicated and hard to remember. In fact, the more complicated and hard to remember the password is the better the protection. One of the first things that a hacker will attempt to do against a system is to run a program that will attempt to guess the correct password. These programs can be very simple or very sophisticated. Most of the programs begin with the simple things like words from a dictionary and not just English dictionaries; they usually include dictionaries from several different languages. For information on how to create a good, strong password see Choosing a Good Password.\n- Understanding human weaknesses and/or failings makes a hackers job that much easier. One of our major weaknesses is the reluctance to remember several long and/or difficult passwords. Hence the likelihood that the same password will be use for several accounts is very high. It is also very likely that the password will be used for a long period of time, allowing the hacker a greater length of time to access the system. Any password can be cracked given enough time; therefore passwords should be changed at least every 60 days.\n6) How do I know if I am on a “secure” Web page?\n- There are a couple of things you can look for to ensure that you are on a “secure” web page.\n- Look for a closed padlock symbol in the lower right corner of the Internet Explorer 4.0 or greater window or in the lower left corner of the Netscape 4.0 or greater window.\n- If there is an s on the end of the “http” (making it https) in the address line. Such as https://ibank.amsouth.com/\nNever give personal information on a Web site that you cannot verify is secure and even then proceed with caution. Identity theft is rampant and we don’t want you to be the next victim. Protect yourself and what you have worked to achieve.\n7) What campus policies, procedures and/or guidelines should I be aware of?\n- Most of our existing policies, procedures and/or guidelines can be found on this web site under the Computing Policies and Guidelines section and under the Secure Computing section.\n- Be aware that work is ongoing to create and update our policies, procedures and guidelines and the most up-to-date information can be found on our web pages.\n8) What constitutes harassing or inappropriate e-mail, and what can I do about it?\n- Examples of inappropriate e-mail include but are not limited to, SPAM, pyramid schemes, mass-mailings, marketing one or more products or services, and chain letters. Harassing e-mail messages include messages that offend, intimidate or threaten an individual or group.\n- These should be reported immediately to email@example.com.\n9) How do spammers get my name and how can I protect myself?\nFree services. Many Web sites carry paid advertising as a way to generate revenue. But many web-based services also require that you register, by supplying your name and e-mail address, before you can use their “free” services. Selling the information they collect is part of their business plan. And guess who buys that information? (The correct answer is “spammers”).\nNewsgroups. Think twice before posting to a newsgroup. Spammers often release information-gathering programs called “bots” to collect the names and e-mail addresses of people who post to specific newsgroups. Bots can get this information from both recent and old posts. And, since many newsgroups are special-interest communities, spammers can learn what you’re interested in—which makes you a better target for spam.\nHow to protect yourself:\nNever reply to a spammer. Replying to spam—no matter how good the offer sounds—will guarantee that you get more spam, because you’ve shown yourself as susceptible. Also ignore any offer to “click here to be removed from our list.” All your request does is tell the spammer the message arrived and that a live person is reading the mail at that address. Any response increases your value to list-sellers.\nUse filters. Every e-mail program has some sort of built-in filtering system. Check your client’s online help section for info on setting up filters. Filters aren’t perfect, though, because you have to enter the spammer’s e-mail address, and the addresses change often and are commonly disguised. Another good use for filters: blocking messages from one person who keeps sending you unwanted (but not spam) messages.\nHow to complain\nBe sure to include the expanded header when you forward a message. The expanded header identifies every computer that handled the message before it arrived at your in-box. We need this information to determine the origin of the message. Every e-mail client has its own way to expand headers; click the online help section to learn more.\nIn Eudora, for example, select the message by double-clicking on it in the inbox, then click on the button that says “blah blah blah” to expand the header.\n10) How can I automatically delete/clear private data when exiting Mozilla Firefox?\nTo automatically clear private data in Mozilla Firefox:\n1. Open Firefox.\n2. Select Tools from the toolbar.\n3. Select Options from the pull-down menu.\n4. Select the Privacy Tab.\n5. Click on the checkbox, to put a check mark, under Private Data section: “Always clear my private data when I close Firefox”.\n6. Click on the Settings… box.\n7. Make sure that all of the checkboxes are selected with checks.\n8. Click OK.\n9. Click OK.\n10. Every time you close Firefox you will prompted to “Clear Private Data Now”.", "label": 1}
{"text": "We need passwords for just about everything anymore. A fear my next toaster will require me to sign in and agree to terms before I can toast a bagel.\nHere are a few tips to keep yourself protected:\n1) Don’t reuse passwords.\nIt’s true, keeping track of all those passwords is tough. At a bare minimum, you probably have online accounts with Facebook, Google, your bank, your email, and your website admin. And many of you will also have Flickr, Twitter, Pinterest, Amazon, eBay, LinkedIn, Spotify, Foursquare, etc. My personal password manager keeps track of more than 300 logins.\nBut if you use the same password across multiple accounts, that means the weakness of one service becomes a weakness for all the services you use. Suppose you have a really strong password like\nle8'a6[Nwva7Y)lq/RSy that you use everywhere. If just one of your accounts gets hacked, then it is only a matter of time before the hacker uses that to gain access to your other accounts.\n2) Don’t use common passwords.\nIf you can find your password in the dictionary, don’t use it. Those passwords are the easiest to guess. Remember, we’re not worried about a person sitting at a computer trying these passwords one-by-one, we’re worried about bot-attacks which can try thousands of passwords per second.\nIf your password is one of these 25 most common passwords, don’t use it, and change it immediately: password, 123456, 12345678, abc123, qwerty, monkey, letmein, dragon, 111111, baseball, iloveyou, trustno1, 1234567, sunshine, master, 123123, welcome, shadow, ashley, football, jesus, michael, ninja, mustang, password1\n(More information about that list)\nYou should also make sure that your password isn’t your username, real name, email address, or some combination thereof. Children’s and pets’ names should be avoided too.\n3) Try a pass-phrase\nWe have been conditioned to not use spaces in our passwords (I’ll admit that I often don’t), but this is a great way to use a strong password that is easy to remember.\n4) “Retire” old passwords\nIf a password has been in use for a while, it might be time to retire it. In case a site was compromised, changing your password regularly will help ensure that the password that someone else has is out-of-date by the time they try to use it.\n5) Find a system\nYour system might be to find a tool like 1Password or LastPass to keep track of your various passwords (as well as storing other secure information). Or you might want to use some sort of naming convention to make it easier to remember your passwords (for example, having a base password like “myDogHas3Legs” and prefix it for the site like “facebook-myDogHas3Legs”).\nThe important thing is to pick whatever method works best for you.\nReady to change your password?\nHere’s how to change your inndx.com password:\n6) Bonus: Watch out for those security questions!\nA good password is worthless if a hacker can reset it by answering a security question or two. You wouldn’t give your password out, but sometimes we don’t think twice about leaking information like where you were born, your first pet’s name, or the street you grew up on. So be mindful that security questions are a second point of entry, and should be just as difficult to get past as your password.", "label": 1}
{"text": "Virtual machine live migration is a virtualization process that moves a virtual machine (VM) from one physical host server to another. It moves the memory and state of a VM without shutting down the application,\nThe process captures the complete memory space occupied by the VM—along with the exact state of all the processor registers currently operating on the VM—then sends that content across a TCP/IP link to memory space on another server. Processor registers are then loaded, and the newly moved VM can pick up its operation without missing a step.\nMost VM live migrations occur between similar hypervisors, so the migrated VM retains its name and other unique identifiers. Even though the VM is on a different server, it's the exact same machine as far as the users are concerned.\nLive migration is a key benefit of virtualization, allowing workloads to move in real time as server or data center conditions change. Consider the impact on business continuity: A virtual server scheduled for maintenance can migrate its workloads to a spare server or to other servers that have extra computing capacity. Once the maintenance is complete and the server returns to service, these workloads can all migrate back to the original server without disruption.\nLive migration helps server consolidation by allowing IT administrators to balance workloads across data center servers, ensuring that each server is used efficiently without being overtaxed. Live migration helps with disaster recovery too because VMs can just as easily be moved from one site to another, relying on spare servers at a remote site to receive and operate the migrated VMs.\nAll of the major virtualization software platforms include VM live migration tools. These include VMware VMotion (part of vSphere), Microsoft Live Migration (part of Hyper-V R2) and Citrix Systems XenServer live migration.\nMigration tools typically allow administrators to prioritize the movement of each VM so that failover and failback processes occur in a predictable and repeatable manner. Mission-critical VMs usually take priority and are often moved to spare servers with ample computing resources.\nSecondary VMs can be addressed next, although the migration software may be left to move noncritical VMs automatically based on the computing resources on each available server. Migration audits allow administrators to locate VMs and track their movements to refine and optimize ongoing migration behaviors.\nLive migration works between almost all virtual host servers, but it's important to test migration behaviors between servers with various processor manufacturers. Processors from Intel and AMD both include extensions that provide hardware assistance for virtualization tasks, including migration. However, Intel VT and AMD-V processors use different architectures to facilitate migration, and moving VMs between Intel and AMD-based servers may result in unexpectedly poor migration performance.\nThis was first published in October 2009", "label": 1}
{"text": "Article written on 26 October 2010\nDuring the European Security and Information System congress, the CNIL released a guide regarding the security of personal data. This guide aims at helping security managers to respect the law « Data Processing, Data Files and Individual Liberties » and to ensure the security of personal data. The present article is a summary of the recommendations of this guide.\nContext and presentation\nThere are more and more personal data manipulated, and threats affecting information systems are in parallel increasing (see on this topic Cert-IST 2009 annual report on the vulnerabilities and attacks). During all their lifecycle, personal data must therefore be protected against the loss of confidentiality, the loss of integrity, the usurpation or the simple loss.\nOrganisation of the guide\nThe CNIL guide is made of 17 datasheets allowing security managers to evaluate the level of security of personal data in their organisation.\nThese sheets are divided into three sections mentioning the elementary precautions for data security, the things to avoid and a third section enabling the reader to go further on the topic dealt in the sheet. The themes developed are as follows: risk management, user authentication, accreditation management and user awareness, workstation security, mobile equipment security, backups and activity continuity, maintenance, traceability and incident handling, office security, internal network security, server and application security, externalisation, storing, exchange of information with other organisations, computer development, anonymisation and encryption.\nThe following examples give an idea of the sheets presented in this guide.\nSheet n°1: Which risks ?\nThis first sheet allows the persons responsible for the data handling to take the necessary measures to protect these data from the possible risks they encounter.\nThe elementary precaution is to formalize the risks in a complete document, which will have to be kept up to date regularly. This document must gather the personal data and the associated treatments, by identifying the supports on which these treatments rely. The possible impacts on private life will have to be identified, as well as risks and threats, in order to set up the appropriate security measures.\nThree things must in particular be avoided, managing a risk study alone, performing a too much detailed study and choosing inappropriate measures.\nSeveral orientations enable the reader to go further, for instance the implementation of a security budget, the use of a method such as EBIOS, the formation of the persons in charge of the risk analysis or the realisation of a security audit.\nSheet n°5: How to secure mobile devices?\nThis sheet deals with the protection of data manipulated by mobile computers and phones, USB keys and any other mobile device. The risks related to these devices have indeed been mentioned in the Cert-IST 2009 annual report quoted above, it is therefore essential to secure personal data manipulated by these devices.\nAs an elementary precaution, the guide recommends to encrypt store spaces either at hardware level, or at software level, or to use file encryption or at last to create encrypted containers.\nThe thing to avoid is keeping personal data in these mobile devices when travelling abroad. This guide reminds the advices published by ANSSI in the document named « Passport advice to travellers ». The section « To go further » recommends to lock the device after some time of inactivity, as well as to use a fingerprint reader.\nSheet n°8: Traceability and incident handling\nAnother interesting example for personal data is the one of logging the actions performed on a system. This is indeed crucial in case of investigation on incident (i.e. unauthorised access to personal data or fraudulent use of these data).\nThe elementary precaution recommended by the CNIL is to set up a reliable logging system, allowing to record accesses, errors, and security events on a period of time that does not exceed six months.\nThe CNIL recommends, in the section « things to avoid », not to use these data for other things than the good use of the information system.\nThe section « To go further » gives recommendations on the synchronisation of information systems and the treatment of security vulnerabilities that may affect these systems.\nSheet n°15: Computer developments\nThe last example that we will take is the protection of personal data during the development of applications.\nIn the section « Elementary precautions », the CNIL reminds the basic principles in term of security for developments, which are the use of a development environment distinct of the production environment and the integration of security since the conception of applications. These principles have been known for a long time, but are still often neglected.\nThe thing to avoid is to use real personal data for development, or in this case to impersonate these data.\nTo go further in its advices regarding developments, the CNIL recommends to reduce the personal data collected, to use a format compatible with the time of conservation of these data, to integrate access control to these data during development and to avoid free text areas (or then with a mention regarding access rights to the information entered).\nAt the end of this guide, a questionnaire allows computer managers to evaluate the security level of the personal data in their organisation.\nThe CNIL president (Alex TÜRK) also mentions that this guide is probably not perfect and is either too much or not enough detailed depending on the reader profile, but also indicates that a more precise document is under elaboration.", "label": 1}
{"text": "A VPN (virtual private network) encrypts and tunnels all Internet traffic between yourself and another computer. This computer might belong to a commercial VPN service, your organization, or a trusted contact.\nBecause VPN services tunnel all Internet traffic, they can be used for e-mail, instant messaging, Voice over IP (VoIP) and any other Internet service in addition to Web browsing, making everything that travels through the tunnel unreadable to anyone along the way.\nIf the tunnel ends outside the area where the Internet is being restricted, this can be an effective method of circumvention, since the filtering entity/server sees only encrypted data, and has no way of knowing what data is passing through the tunnel. It has the additional effect of making all your different kinds of traffic look similar to an eavesdropper.\nSince many international companies use VPN technology to allow employees who need access to sensitive financial or other information to access the companies' computer systems from home or other remote locations over the Internet, VPN technology is less likely to be blocked than the technologies used only for circumvention purposes.\nIt is important to note that the data is only encrypted as far as the end of the tunnel, and then travels unencrypted to its final destination. If, for example, you set up a tunnel to a commercial VPN provider, and then request the Web page http://news.bbc.co.uk through the tunnel, the data will be encrypted from your computer to the VPN provider's computer at the other end, but from there it will be unencrypted to the servers run by the BBC, just like normal Internet traffic. This means that the VPN provider, the BBC and anyone with control over a system between these two servers, will, in theory, be able to see what data you sent or have requested.\nUsing VPN services\nVPN services might or might not require installation of client-side software (many rely on existing VPN support in Windows, Mac OS or GNU/Linux and so need no extra client software).\nUsing a VPN service requires you to trust the owners of the service, but provides a simple and convenient method of bypassing Internet filtering, for free or for a monthly fee generally between 5 and 10 US dollars, depending on the service. Free services are often either ad-supported, or limit the bandwidth and/or the maximum traffic allowed over a given period.\nPopular free VPN services:\n- Hotspot Shield, https://hotspotshield.com\nAccording to a 2010 report from the Berkman Center, Hotspot Shield is overwhelmingly the most popular VPN service. For more details on how to get and use Hotspot Shield, read the \"Hotspot Shield\" chapter of this manual.\n- UltraVPN, http://www.ultravpn.fr\n- FreeVPN, http://www.thefreevpn.com\n- CyberGhost, http://cyberghostvpn.com\n- Air VPN, https://airvpn.org\nAirVPN offers free accounts without bandwidth or traffic restrictions and without ads for activists by request.\n- Vpnod, http://www.vpnod.com\n- VpnSteel, http://www.vpnsteel.com\n- Loki Network Project, http://www.projectloki.com\n- ItsHidden, http://itshidden.com\nExamples of paid VPN services include Anonymizer, GhostSurf, XeroBank, HotSpotVPN, WiTopia, VPN Swiss, Steganos, Hamachi LogMeIn, Relakks, Skydur, iPig, iVPN.net, FindNot, Dold, UnblockVPN and SecureIX.\nVPN standards and encryption\nThere are a number of different standards for setting up VPN networks, including IPSec, SSL/TLS and PPTP, that vary in terms of complexity, the level of security they provide, and which operating systems they are available for. Naturally, there are also many different implementations of each standard within software that have various other features.\n- While PPTP is known to use weaker encryption than either IPSec or SSL/TLS, it may still be useful for bypassing Internet blocking, and the client software is conveniently built into most versions of Microsoft Windows.\n- SSL/TLS-based VPN systems are relatively simple to configure, and provide a solid level of security.\n- IPSec runs at the Internet level, responsible for packet transfer in the Internet architecture, while the others run at the Application level. This makes IPsec more flexible, as it can be used for protecting all the higher level protocols, but also difficult to set up.\nSet up your own VPN service\nAs an alternative to paying for commercial VPN services, users with contacts in unrestricted locations may have these contacts download and install software that sets up a private VPN service. This requires a much higher level of technical knowledge, but it will be free. Also the private nature of such a setup means it is less likely to be blocked than a commercial service that has been available for a long time. One of the most widely used free and open source programs available for setting up this kind of private VPN is OpenVPN (http://openvpn.net), which can be installed on Linux, MacOS, Windows and many other operating systems.\nTo understand how to set up an OpenVPN system, read the \"Using OpenVPN\" chapter in this manual.\nA VPN provides encrypted transfer of your data, so it is one of the safest ways to bypass Internet censorship. Once configured, it is easy and transparent to use.\nVPNs are best suited for technically capable users who require secure circumvention services for more than just web traffic and who access the Internet from their own computer where they can install additional software. VPNs are an excellent resource for users in censored locations who do not have trusted contacts in non-filtered locations. VPN technology is a common business application that is not likely to be blocked.\nDisadvantages and Risks\nSome commercial VPNs (especially the free ones) are publicly known and may be filtered. They normally cannot be used in public access locations where users cannot install software, such as Internet cafés or libraries. Use of VPNs may require a higher level of technical expertise than other circumvention methods.\nA network operator can detect that a VPN is being used and determine who the VPN provider is. The network operator should not be able to view the communications sent over the VPN unless the VPN is set up incorrectly.\nThe VPN operator (much like a proxy operator) can see what you're doing unless you use some additional encryption for your communications, like HTTPS for Web traffic; without additional encryption, you have to trust the VPN or tunnel operator not to abuse this access.", "label": 1}
{"text": "In computing, a denial-of-service attack (DoS attack) or distributed denial-of-service attack (DDoS attack) is an attempt to make a machine or network resource unavailable to its intended users. Although the means to carry out, motives for, and targets of a DoS attack may vary, it generally consists of efforts to temporarily or indefinitely interrupt or suspend services of a host connected to the Internet.\nPerpetrators of DoS attacks typically target sites or services hosted on high-profile web servers such as banks, credit card payment gateways, and even root nameservers. This technique has now seen extensive use in certain games, used by server owners, or disgruntled competitors on games such as Minecraft. The term is generally used relating to computer networks, but is not limited to this field; for example, it is also used in reference to CPU resource management.\nOne common method of attack involves saturating the target machine with external communications requests, so much so that it cannot respond to legitimate traffic, or responds so slowly as to be rendered essentially unavailable. Such attacks usually lead to a server overload. In general terms, DoS attacks are implemented by either forcing the targeted computer(s) to reset, or consuming its resources so that it can no longer provide its intended service or obstructing the communication media between the intended users and the victim so that they can no longer communicate adequately.\nDenial-of-service attacks are considered violations of the Internet Architecture Board's Internet proper use policy, and also violate the acceptable use policies of virtually all Internet service providers. They also commonly constitute violations of the laws of individual nations.\nSymptoms and manifestations \nThe United States Computer Emergency Readiness Team (US-CERT) defines symptoms of denial-of-service attacks to include:\n- Unusually slow network performance (opening files or accessing web sites)\n- Unavailability of a particular web site\n- Inability to access any web site\n- Dramatic increase in the number of spam emails received—(this type of DoS attack is considered an e-mail bomb)\n- Disconnection of a wireless or wired internet connection\nDenial-of-service attacks can also lead to problems in the network 'branches' around the actual computer being attacked. For example, the bandwidth of a router between the Internet and a LAN may be consumed by an attack, compromising not only the intended computer, but also the entire network.\nIf the attack is conducted on a sufficiently large scale, entire geographical regions of Internet connectivity can be compromised without the attacker's knowledge or intent by incorrectly configured or flimsy network infrastructure equipment.\nMethods of attack \nA denial-of-service attack is characterized by an explicit attempt by attackers to prevent legitimate users of a service from using that service. There are two general forms of DoS attacks: those that crash services and those that flood services.\nA DoS attack can be perpetrated in a number of ways. The five basic types of attack are:\n- Consumption of computational resources, such as bandwidth, disk space, or processor time.\n- Disruption of configuration information, such as routing information.\n- Disruption of state information, such as unsolicited resetting of TCP sessions.\n- Disruption of physical network components.\n- Obstructing the communication media between the intended users and the victim so that they can no longer communicate adequately.\n- Max out the processor's usage, preventing any work from occurring.\n- Trigger errors in the microcode of the machine.\n- Trigger errors in the sequencing of instructions, so as to force the computer into an unstable state or lock-up.\n- Exploit errors in the operating system, causing resource starvation and/or thrashing, i.e. to use up all available facilities so no real work can be accomplished or it can crash the system itself\n- Crash the operating system itself.\nIn most cases DoS attacks involve forging of IP sender addresses (IP address spoofing) so that the location of the attacking machines cannot easily be identified and to prevent filtering of the packets based on the source address.\nICMP flood \nA smurf attack is one particular variant of a flooding DoS attack on the public Internet. It relies on misconfigured network devices that allow packets to be sent to all computer hosts on a particular network via the broadcast address of the network, rather than a specific machine. The network then serves as a smurf amplifier. In such an attack, the perpetrators will send large numbers of IP packets with the source address faked to appear to be the address of the victim. The network's bandwidth is quickly used up, preventing legitimate packets from getting through to their destination. To combat denial of service attacks on the Internet, services like the Smurf Amplifier Registry have given network service providers the ability to identify misconfigured networks and to take appropriate action such as filtering.\nPing flood is based on sending the victim an overwhelming number of ping packets, usually using the \"ping\" command from unix-like hosts (the -t flag on Windows systems is much less capable of overwhelming a target, also the -l (size) flag does not allow sent packet size greater than 65500 in Windows). It is very simple to launch, the primary requirement being access to greater bandwidth than the victim.\nPing of death is based on sending the victim a malformed ping packet, which might lead to a system crash.\n(S)SYN flood \nA SYN flood occurs when a host sends a flood of TCP/SYN packets, often with a forged sender address. Each of these packets is handled like a connection request, causing the server to spawn a half-open connection, by sending back a TCP/SYN-ACK packet (Acknowledge), and waiting for a packet in response from the sender address (response to the ACK Packet). However, because the sender address is forged, the response never comes. These half-open connections saturate the number of available connections the server is able to make, keeping it from responding to legitimate requests until after the attack ends.\nTeardrop attacks \nA teardrop attack involves sending mangled IP fragments with overlapping, over-sized payloads to the target machine. This can crash various operating systems because of a bug in their TCP/IP fragmentation re-assembly code. Windows 3.1x, Windows 95 and Windows NT operating systems, as well as versions of Linux prior to versions 2.0.32 and 2.1.63 are vulnerable to this attack.\nLow-rate Denial-of-Service attacks \nThe Low-rate DoS (LDoS) attack exploits TCP’s slow-time-scale dynamics of retransmission time-out (RTO) mechanisms to reduce TCP throughput. Basically, an attacker can cause a TCP flow to repeatedly enter a RTO state by sending high-rate, but short-duration bursts, and repeating periodically at slower RTO time-scales. The TCP throughput at the attacked node will be significantly reduced while the attacker will have low average rate making it difficult to be detected.\nPeer-to-peer attacks \nAttackers have found a way to exploit a number of bugs in peer-to-peer servers to initiate DDoS attacks. The most aggressive of these peer-to-peer-DDoS attacks exploits DC++. Peer-to-peer attacks are different from regular botnet-based attacks. With peer-to-peer there is no botnet and the attacker does not have to communicate with the clients it subverts. Instead, the attacker acts as a \"puppet master,\" instructing clients of large peer-to-peer file sharing hubs to disconnect from their peer-to-peer network and to connect to the victim's website instead. As a result, several thousand computers may aggressively try to connect to a target website. While a typical web server can handle a few hundred connections per second before performance begins to degrade, most web servers fail almost instantly under five or six thousand connections per second. With a moderately large peer-to-peer attack, a site could potentially be hit with up to 750,000 connections in short order. The targeted web server will be plugged up by the incoming connections.\nWhile peer-to-peer attacks are easy to identify with signatures, the large number of IP addresses that need to be blocked (often over 250,000 during the course of a large-scale attack) means that this type of attack can overwhelm mitigation defenses. Even if a mitigation device can keep blocking IP addresses, there are other problems to consider. For instance, there is a brief moment where the connection is opened on the server side before the signature itself comes through. Only once the connection is opened to the server can the identifying signature be sent and detected, and the connection torn down. Even tearing down connections takes server resources and can harm the server.\nThis method of attack can be prevented by specifying in the peer-to-peer protocol which ports are allowed or not. If port 80 is not allowed, the possibilities for attack on websites can be very limited.\nAsymmetry of resource utilization in starvation attacks \nAn attack which is successful in consuming resources on the victim computer must be either:\n- carried out by an attacker with greater resources, by either:\n- controlling a computer with greater computation power or, more commonly, large network bandwidth\n- controlling a large number of computers and directing them to attack as a group. A DDOS attack is the primary example of this.\n- taking advantage of a property of the operating system or applications on the victim system which enables an attack consuming vastly more of the victim's resources than the attacker's (an asymmetric attack). Smurf attack, SYN flood, Sockstress and NAPTHA are all asymmetric attacks.\nAn attack may utilize a combination of these methods in order to magnify its power.\nPermanent denial-of-service attacks \nA permanent denial-of-service (PDoS), also known loosely as phlashing, is an attack that damages a system so badly that it requires replacement or reinstallation of hardware. Unlike the distributed denial-of-service attack, a PDoS attack exploits security flaws which allow remote administration on the management interfaces of the victim's hardware, such as routers, printers, or other networking hardware. The attacker uses these vulnerabilities to replace a device's firmware with a modified, corrupt, or defective firmware image—a process which when done legitimately is known as flashing. This therefore \"bricks\" the device, rendering it unusable for its original purpose until it can be repaired or replaced.\nThe PDoS is a pure hardware targeted attack which can be much faster and requires fewer resources than using a botnet in a DDoS attack. Because of these features, and the potential and high probability of security exploits on Network Enabled Embedded Devices (NEEDs), this technique has come to the attention of numerous hacker communities.\nPhlashDance is a tool created by Rich Smith (an employee of Hewlett-Packard's Systems Security Lab) used to detect and demonstrate PDoS vulnerabilities at the 2008 EUSecWest Applied Security Conference in London.\nApplication-level floods \nOther kinds of DoS rely primarily on brute force, flooding the target with an overwhelming flux of packets, oversaturating its connection bandwidth or depleting the target's system resources. Bandwidth-saturating floods rely on the attacker having higher bandwidth available than the victim; a common way of achieving this today is via Distributed Denial of Service, employing a botnet. Other floods may use specific packet types or connection requests to saturate finite resources by, for example, occupying the maximum number of open connections or filling the victim's disk space with logs.\nA \"banana attack\" is another particular type of DoS. It involves redirecting outgoing messages from the client back onto the client, preventing outside access, as well as flooding the client with the sent packets.\nAn attacker with shell-level access to a victim's computer may slow it until it is unusable or crash it by using a fork bomb.\nA Nuke is an old denial-of-service attack against computer networks consisting of fragmented or otherwise invalid ICMP packets sent to the target, achieved by using a modified ping utility to repeatedly send this corrupt data, thus slowing down the affected computer until it comes to a complete stop.\nA specific example of a nuke attack that gained some prominence is the WinNuke, which exploited the vulnerability in the NetBIOS handler in Windows 95. A string of out-of-band data was sent to TCP port 139 of the victim's machine, causing it to lock up and display a Blue Screen of Death (BSOD).\nOWASP HTTP Post Denial of Service Tool \nFrom the authority of web application security OWASP Foundation the OWASP HTTP Post Tool completes the request headers phase however it sends the request body (post payload) very slowly (e.g. - 1 byte/110sec). When you consider that, by default, Apache will accept a request body of up to 2GB in size, you can can see how effective this attack can be.\nR-U-Dead-Yet? (RUDY) \nThis attack is one of many web application DoS tools available to directly attack web applications by starvation of available sessions on the web server. Much like Slowloris, RUDY keeps sessions at halt using never-ending POST transmissions and sending an arbitrarily large content-length header value.\nSlow Read attack \nSlow Read attack sends legitimate application layer requests but reads responses very slowly, thus trying to exhaust the server's connection pool. Slow reading is achieved by advertising very small number for the TCP Receive Window size and at the same time by emptying clients' TCP receive buffer slowly. That naturally ensures a very low data flow rate.\nDistributed attack \nA distributed denial of service attack (DDoS) occurs when multiple systems flood the bandwidth or resources of a targeted system, usually one or more web servers. This is the result of multiple compromised systems (for example a botnet) flooding the targeted system(s) with traffic. When a server is overloaded with connections, new connections can no longer be accepted.\nMalware can carry DDoS attack mechanisms; one of the better-known examples of this was MyDoom. Its DoS mechanism was triggered on a specific date and time. This type of DDoS involved hardcoding the target IP address prior to release of the malware and no further interaction was necessary to launch the attack.\nA system may also be compromised with a trojan, allowing the attacker to download a zombie agent (or the trojan may contain one). Attackers can also break into systems using automated tools that exploit flaws in programs that listen for connections from remote hosts. This scenario primarily concerns systems acting as servers on the web.\nStacheldraht is a classic example of a DDoS tool. It utilizes a layered structure where the attacker uses a client program to connect to handlers, which are compromised systems that issue commands to the zombie agents, which in turn facilitate the DDoS attack. Agents are compromised via the handlers by the attacker, using automated routines to exploit vulnerabilities in programs that accept remote connections running on the targeted remote hosts. Each handler can control up to a thousand agents.\nThese collections of systems compromisers are known as botnets. DDoS tools like Stacheldraht still use classic DoS attack methods centered on IP spoofing and amplification like smurf attacks and fraggle attacks (these are also known as bandwidth consumption attacks). SYN floods (also known as resource starvation attacks) may also be used. Newer tools can use DNS servers for DoS purposes. See next section.\nSimple attacks such as SYN floods may appear with a wide range of source IP addresses, giving the appearance of a well distributed DoS. These flood attacks do not require completion of the TCP three way handshake and attempt to exhaust the destination SYN queue or the server bandwidth. Because the source IP addresses can be trivially spoofed, an attack could come from a limited set of sources, or may even originate from a single host. Stack enhancements such as syn cookies may be effective mitigation against SYN queue flooding, however complete bandwidth exhaustion may require involvement.[further explanation needed]\nUnlike MyDoom's DDoS mechanism, botnets can be turned against any IP address. Script kiddies use them to deny the availability of well known websites to legitimate users. More sophisticated attackers use DDoS tools for the purposes of extortion – even against their business rivals.\nIf an attacker mounts an attack from a single host it would be classified as a DoS attack. In fact, any attack against availability would be classed as a Denial of Service attack. On the other hand, if an attacker uses many systems to simultaneously launch attacks against a remote host, this would be classified as a DDoS attack.\nThe major advantages to an attacker of using a distributed denial-of-service attack are that: multiple machines can generate more attack traffic than one machine, multiple attack machines are harder to turn off than one attack machine, and that the behavior of each attack machine can be stealthier, making it harder to track and shut down. These attacker advantages cause challenges for defense mechanisms. For example, merely purchasing more incoming bandwidth than the current volume of the attack might not help, because the attacker might be able to simply add more attack machines.\nIn some cases a machine may become part of a DDoS attack with the owner's consent. An example of this is the 2010 DDoS attack against major credit card companies by supporters of WikiLeaks. In cases such as this, supporters of a movement (in this case, those opposing the arrest of WikiLeaks founder Julian Assange) choose to download and run DDoS software.\nReflected / Spoofed attack \nA distributed reflected denial of service attack (DRDoS) involves sending forged requests of some type to a very large number of computers that will reply to the requests. Using Internet Protocol address spoofing, the source address is set to that of the targeted victim, which means all the replies will go to (and flood) the target.\nICMP Echo Request attacks (Smurf Attack) can be considered one form of reflected attack, as the flooding host(s) send Echo Requests to the broadcast addresses of mis-configured networks, thereby enticing many hosts to send Echo Reply packets to the victim. Some early DDoS programs implemented a distributed form of this attack.\nMany services can be exploited to act as reflectors, some harder to block than others. DNS amplification attacks involve a new mechanism that increased the amplification effect, using a much larger list of DNS servers than seen earlier.\nTelephony denial of service \nAccording to the US Federal Bureau of Investigation, TDoS has appeared as part of various fraudulent schemes:\n- A scammer contacts the victim's banker or broker, impersonating the victim to request a funds transfer. The banker's attempt to contact the victim for verification of the transfer fails as the victim's telephone lines are being flooded with thousands of bogus calls, rendering the victim unreachable.\n- A scammer contacts consumers with a bogus claim to collect an outstanding payday loan for thousands of dollars. When the consumer objects, the scammer retaliates by flooding the victim's employer with thousands of automated calls. In some cases, displayed caller ID is spoofed to impersonate police or law enforcement agencies.\n- A scammer contacts consumers with a bogus debt collection demand and threatens to send police; when the victim balks, the scammer floods local police numbers with calls on which caller ID is spoofed to display the victims number. Police soon arrive at the victim's residence attempting to find the origin of the calls.\nTelephony denial of service can exist even without Internet telephony. In the 2002 New Hampshire Senate election phone jamming scandal, telemarketers were used to flood political opponents with spurious calls to jam phone banks on election day. Widespread publication of a number can also flood it with enough calls to render it unusable, as happened with multiple +1-area code-867-5309 subscribers inundated by hundreds of misdialed calls daily in response to a popular song 867-5309/Jenny.\nTDoS differs from other telephone harassment (such as prank calls and obscene phone calls) by the number of calls originated; by occupying lines continuously with repeated automated calls, the victim is prevented from making or receiving both routine and emergency telephone calls.\nUnintentional denial of service \nThis describes a situation where a website ends up denied, not due to a deliberate attack by a single individual or group of individuals, but simply due to a sudden enormous spike in popularity. This can happen when an extremely popular website posts a prominent link to a second, less well-prepared site, for example, as part of a news story. The result is that a significant proportion of the primary site's regular users – potentially hundreds of thousands of people – click that link in the space of a few hours, having the same effect on the target website as a DDoS attack. A VIPDoS is the same, but specifically when the link was posted by a celebrity.\nWhen Michael Jackson died in 2009, websites such as Google and Twitter slowed down or even crashed. Many sites' servers thought the requests were from a virus or spyware trying to cause a Denial of Service attack, warning users that their queries looked like \"automated requests from a computer virus or spyware application\".\nNews sites and link sites – sites whose primary function is to provide links to interesting content elsewhere on the Internet – are most likely to cause this phenomenon. The canonical example is the Slashdot effect when receiving traffic from Slashdot. Sites such as Reddit, Digg, the Drudge Report, Fark, Something Awful, and the webcomic Penny Arcade have their own corresponding \"effects\", known as \"the Digg effect\", being \"drudged\", \"farking\", \"goonrushing\" and \"wanging\"; respectively.\nRouters have also been known to create unintentional DoS attacks, as both D-Link and Netgear routers have created NTP vandalism by flooding NTP servers without respecting the restrictions of client types or geographical limitations.\nSimilar unintentional denials of service can also occur via other media, e.g. when a URL is mentioned on television. If a server is being indexed by Google or another search engine during peak periods of activity, or does not have a lot of available bandwidth while being indexed, it can also experience the effects of a DoS attack.\nLegal action has been taken in at least one such case. In 2006, Universal Tube & Rollform Equipment Corporation sued YouTube: massive numbers of would-be youtube.com users accidentally typed the tube company's URL, utube.com. As a result, the tube company ended up having to spend large amounts of money on upgrading their bandwidth.\nDenial-of-Service Level II \nThe goal of DoS L2 (possibly DDoS) attack is to cause a launching of a defense mechanism which blocks the network segment from which the attack originated. In case of distributed attack or IP header modification (that depends on the kind of security behavior) it will fully block the attacked network from Internet, but without system crash.\nPerforming DoS-attacks \nA wide array of programs are used to launch DoS-attacks. Most of these programs are completely focused on performing DoS-attacks, while others are also true Packet injectors, thus able to perform other tasks as well. Such tools are intended for benign use, but they can also be utilized in launching attacks on victim networks.\nDefensive responses to Denial of Service attacks typically involves the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate. A list of prevention and response tools is provided below:\nFirewalls can be set up to have simple rules such to allow or deny protocols, ports or IP addresses. In the case of a simple attack coming from a small number of unusual IP addresses for instance, one could put up a simple rule to drop all incoming traffic from those attackers.\nMore complex attacks will however be hard to block with simple rules: for example, if there is an ongoing attack on port 80 (web service), it is not possible to drop all incoming traffic on this port because doing so will prevent the server from serving legitimate traffic. Additionally, firewalls may be too deep in the network hierarchy. Routers may be affected before the traffic gets to the firewall. Nonetheless, firewalls can effectively prevent users from launching simple flooding type attacks from machines behind the firewall.\nSome stateful firewalls, like OpenBSD's pf(4) packet filter, can act as a proxy for connections: the handshake is validated (with the client) instead of simply forwarding the packet to the destination. It is available for other BSDs as well. In that context, it is called \"synproxy\".\nMost switches have some rate-limiting and ACL capability. Some switches provide automatic and/or system-wide rate limiting, traffic shaping, delayed binding (TCP splicing), deep packet inspection and Bogon filtering (bogus IP filtering) to detect and remediate denial of service attacks through automatic rate filtering and WAN Link failover and balancing.\nThese schemes will work as long as the DoS attacks are something that can be prevented by using them. For example SYN flood can be prevented using delayed binding or TCP splicing. Similarly content based DoS may be prevented using deep packet inspection. Attacks originating from dark addresses or going to dark addresses can be prevented using Bogon filtering. Automatic rate filtering can work as long as you have set rate-thresholds correctly and granularly. Wan-link failover will work as long as both links have DoS/DDoS prevention mechanism.\nSimilar to switches, routers have some rate-limiting and ACL capability. They, too, are manually set. Most routers can be easily overwhelmed under a DoS attack. Cisco IOS has features that prevent flooding, i.e. example settings.\nApplication front end hardware \nApplication front end hardware is intelligent hardware placed on the network before traffic reaches the servers. It can be used on networks in conjunction with routers and switches. Application front end hardware analyzes data packets as they enter the system, and then identifies them as priority, regular, or dangerous. There are more than 25 bandwidth management vendors.\nIPS based prevention \nIntrusion-prevention systems (IPS) are effective if the attacks have signatures associated with them. However, the trend among the attacks is to have legitimate content but bad intent. Intrusion-prevention systems which work on content recognition cannot block behavior-based DoS attacks.\nAn ASIC based IPS may detect and block denial of service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.\nA rate-based IPS (RBIPS) must analyze traffic granularly and continuously monitor the traffic pattern and determine if there is traffic anomaly. It must let the legitimate traffic flow while blocking the DoS attack traffic.\nDDS based defense \nMore focused on the problem than IPS, a DoS Defense System (DDS) is able to block connection-based DoS attacks and those with legitimate content but bad intent. A DDS can also address both protocol attacks (such as Teardrop and Ping of death) and rate-based attacks (such as ICMP floods and SYN floods).\nLike IPS, a purpose-built system, such as the well-known Radware DefensePro, can detect and block denial of service attacks at much nearer line speed than a software based system.\nBlackholing and sinkholing \nWith blackholing, all the traffic to the attacked DNS or IP address is sent to a \"black hole\" (null interface or a non-existent server). To be more efficient and avoid affecting network connectivity, it can be managed by the ISP.\nSinkholing routes traffic to a valid IP address which analyzes traffic and rejects bad packets. Sinkholing is not efficient for most severe attacks.\nClean pipes \nAll traffic is passed through a \"cleaning center\" or a \"scrubbing center\" via various methods such as proxies, tunnels or even direct circuits, which separates \"bad\" traffic (DDoS and also other common internet attacks) and only sends good traffic beyond to the server. The provider needs central connectivity to the Internet to manage this kind of service unless they happen to be located within the same facility as the \"cleaning center\" or \"scrubbing center\".\nSide effects of DoS attacks \nIn computer network security, backscatter is a side-effect of a spoofed denial-of-service attack. In this kind of attack, the attacker spoofs (or forges) the source address in IP packets sent to the victim. In general, the victim machine cannot distinguish between the spoofed packets and legitimate packets, so the victim responds to the spoofed packets as it normally would. These response packets are known as backscatter.\nIf the attacker is spoofing source addresses randomly, the backscatter response packets from the victim will be sent back to random destinations. This effect can be used by network telescopes as indirect evidence of such attacks.\nThe term \"backscatter analysis\" refers to observing backscatter packets arriving at a statistically significant portion of the IP address space to determine characteristics of DoS attacks and victims.\n|This section requires expansion. (January 2011)|\nIn the US, denial-of-service attacks can considered a serious federal crime under the Computer Fraud and Abuse Act with penalties that include years of imprisonment. Many other countries have similar laws.\nThe US situation is under court ruling with a case in California.\nSee also \n- Billion laughs\n- Black fax\n- Industrial espionage\n- Intrusion-detection system\n- Network intrusion detection system\n- Regular expression Denial of Service\n- Virtual sit-in\n- Wireless signal jammer\nNotes and references \n- Shabtai, A.; Fledel, Y.; Kanonov, U.; Elovici, Y.; Dolev, S.; Glezer, C. (March–April 2010). \"Google Android: A Comprehensive Security Assessment\". IEEE Security & Privacy Magazine 8 (2): 35–44. doi:10.1109/MSP.2010.2.\n- Mindi McDowell (2007). \"Cyber Security Tip ST04-015\". United States Computer Emergency Readiness Team. Retrieved May 2, 2008.\n- \"Types of DDoS Attacks\". 2001. Retrieved May 2, 2008.\n- \"RFC 4987 – TCP SYN Flooding Attacks and Common Mitigations\". Tools.ietf.org. Retrieved 2011-12-02.\n- \"CERT Advisory CA-1997-28 IP Denial-of-Service Attacks\". CERT. 1998. Retrieved May 2, 2008.\n- \"Windows 7, Vista exposed to 'teardrop attack'\". ZDNet. Retrieved 2011-12-02.\n- \"Microsoft Security Advisory (975497): Vulnerabilities in SMB Could Allow Remote Code Execution\". Microsoft.com. Retrieved 2011-12-02.\n- Zhang, C.; Yin, J.; Cai, Z.; Chen, W. (May 2010). \"RRED: Robust RED algorithm to counter low-rate denial-of-service attacks\". IEEE Communications Letters 14 (5): 489–491. doi:10.1109/LCOMM.2010.05.091407.\n- Leyden, John (2008-05-21). \"Phlashing attack thrashes embedded systems\". theregister.co.uk. Retrieved 2009-03-07.\n- \"Permanent Denial-of-Service Attack Sabotages Hardware\". Dark Reading. 2008. Retrieved May 19, 2008.\n- \"EUSecWest Applied Security Conference: London, U.K.\". EUSecWest. 2008. Archived from the original on 2009-02-01.\n- \"The \"stacheldraht\" distributed denial of service attack tool\". Retrieved 2011-12-02.\n- Phillip Boyle (2000). \"SANS Institute – Intrusion Detection FAQ: Distributed Denial of Service Attack Tools: n/a\". SANS Institute. Retrieved May 2, 2008.\n- Leyden, John (2004-09-23). \"US credit card firm fights DDoS attack\". Theregister.co.uk. Retrieved 2011-12-02.\n- Paxson, Vern (2001), An Analysis of Using Reflectors for Distributed Denial-of-Service Attacks\n- Vaughn, Randal and Evron, Gadi (2006), DNS Amplification Attacks\n- Shiels, Maggie (2009-06-26). \"Web slows after Jackson's death\". BBC News.\n- \"Google Discussiegroepen\". Google.com. Retrieved 2012-02-11.\n- \"YouTube sued by sound-alike site\". BBC News. 2006-11-02.\n- Loukas, G.; Oke, G. (September 2010) [August 2009]. \"Protection Against Denial of Service Attacks: A Survey\". Comput. J. 53 (7): 1020–1037. doi:10.1093/comjnl/bxp078.\n- Froutan, Paul (June 24, 2004). \"How to defend against DDoS attacks\". Computerworld. Retrieved May 15, 2010.\n- \"Some IoS tips for Internet Service (Providers)\" (Mehmet Suzen)\n- Patrikakis, C.; Masikos, M.; Zouraraki, O. (December 2004). \"Distributed Denial of Service Attacks\". The Internet Protocol Journal 7 (4): 13–35.\n- \"DDoS Mitigation via Regional Cleaning Centers (Jan 2004)\" (PDF). Retrieved 2011-12-02.\n- \"VeriSign Rolls Out DDoS Monitoring Service\". Darkreading.com. Retrieved 2011-12-02.\n- \"DDoS: A Threat That's More Common Than You Think\". Tatacommunications.com. 2011-09-07. Retrieved 2011-12-02.\n- \"AT&T Internet Protect Distributed Denial of Service Defense\". 2012-10-16.\n- An educational animation describing such backscatter can be found on the animations page maintained by the Cooperative Association for Internet Data Analysis.\n- U.K. outlaws denial-of-service attacks, November 10, 2006, By Tom Espiner – CNET News\n- \"United States Code: Title 18,1030. Fraud and related activity in connection with computers | LII / Legal Information Institute\". Law.cornell.edu. 2010-06-28. Retrieved 2012-02-11.\n- DDOS Attack: crime or virtual sit-in?, October 6, 2011, by RT.COM\n- \"Anonymous DDoS Petition: Group Calls On White House To Recognize Distributed Denial Of Service As Protest\". 2013-01-12.\nFurther reading \n- \"Distributed Denial of Service Attacks Against Independent Media and Human Rights Sites\". The Berkman Center for Internet & Society at Harvard University. December 2010. Archived from the original on 2011-05-01. Retrieved 2011-03-02.\n- \"DDOS Public Media Reports\". Harvard. Archived from the original on 2011-05-01.\n||This article's use of external links may not follow Wikipedia's policies or guidelines. (November 2012)|\n- RFC 4732 Internet Denial-of-Service Considerations\n- Radware Global Security Report  GlobalApplicationNetSecurityReport_HP\n- W3C The World Wide Web Security FAQ\n- Understanding and surviving DDoS attacks\n- cert.org CERT's Guide to DoS attacks. (historic document)\n- ATLAS Summary Report – Real-time global report of DDoS attacks.\n- linuxsecurity.com An article on preventing DDoS attacks.\n- Is Your PC a Zombie?, About.com.\n- Report: Distributed Denial of Service Attacks Against Independent Media and Human Rights Sites Berkman Center for Internet and Society Report on DDOS\n- News on DDoS Latest DDoS news and techniques\n- Mitigating Slow HTTP Denial of Service", "label": 1}
{"text": "[Dogbert] took a look at the security that goes into BIOS passwords on many laptops. He starts off with a little background about how the systems work. People are bound to forget their passwords, so when you enter a wrong one three times in a row you get a message similar to the one above that locks you out until all power is removed from the system (then you get three more tries). But check out that five-digit number in the picture. That’s a checksum of the password. Some BIOS versions display it automatically, some require you to hold down a certain key during POST, but it’s the pivotal data needed to crack the password.\n[Dogbert's] post doesn’t go into verbose detail about the algorithms he uses to brute force the passwords. But he has posted the Python scripts he uses to do so. Learning how to generate the passwords based on the checksum is as simple as studying the code, which is often the best way to learn.", "label": 1}
{"text": "A rootkit typically patches the kernel or other software libraries to alter the behavior of the operating system. Once this is happening, you cannot trust anything that the operating system tells you.\nFor example; a simple change to the\ndir program could hide the existence of malicious files from a user, but this is easily detectable by many anti-virus packages as the alteration of an executable is something that can be noticed. If however, the malware alters the mechanisms by which userland programs query the file system, by patching the kernel itself, any user-space program can be tricked into thinking that the executable has not been altered.\nOnce malware has started altering the behavior of the system calls/kernel api, it can hide any activity effectively, including network interactions.\nAll of this only applies if you are monitoring the infected machine locally. If you have firewall logs or some other remote method of monitoring the infected machine, this information can be trusted (the network connections still have to exist, but they can be hidden from the infected OS).", "label": 1}
{"text": "- Language Tips\nFlame, one of the most complex computer viruses ever discovered, has been detected in China and could potentially cause widespread damage - including information leakage - to company and government networks as well as individual computers, experts warned.\n\"According to our analysis, the virus was designed mainly to target governments, firms, schools and scientific institutions,\" said Liu Siyu, director of the research and development section of Rising International Software, a Chinese Internet security company.\n\"However, the technology it used could be adopted by other lower-level Trojan viruses and cause damage to the networks we use in our daily lives,\" he said.\nThe company issued a notice on its website last week, calling on companies to take all necessary measures to protect themselves from the virus.\n\"We first intercepted this virus on Wednesday and have not received any report of damage caused by it yet,\" said Liu.\nInitial analysis has revealed the complexity of the virus. It contains many components, each with a different function that can integrate with others to cause complex harm to the infected network, Liu said.\n\"The total size of the virus package is nearly 20 megabytes, while a normal virus is less than one megabyte.\"\nAccording to Liu, the virus could even record sound and video stored in the infected computer and steal the information.\n\"It is arguably the most complex virus discovered,\" said Hungary-based Laboratory of Cryptography and System Security in a 64-page technical report released on Thursday.\nFlame has very advanced functionality to steal information and to propagate, and covers all major intelligence gathering possibilities, including monitoring keystrokes, screens, microphones, storage devices, networks, WiFi, Bluetooth, USB and system processes, according to the report.\nLiu said Rising has upgraded its anti-virus software, which is capable of eliminating the virus. It also offered a free anti-virus software that anyone can download, he said.\nThe lab's report said Flame first appeared in Europe in December 2007, but it \"may have been active for five to eight years\".\n\"The result of our technical analysis supports the hypotheses that sKyWlper (Flame) was developed by a government agency of a nation with significant budget and effort, and it may be related to cyber warfare activities,\" the report said.\nAccording to a report by Iran's Kayhan daily on Thursday, which was quoted by Xinhua New Agency, Iranian cyber experts have detected and contained Flame, which it called an Israeli spy virus.\nFlame has targeted Iran's oil industry, the report said, adding that, however, Iranian experts have been able to detect and contain it.\nThe report said that the malware was different from other viruses and was more destructive than Stuxnet.\nIran announced in October 2010 that it had detected and thwarted the Stuxnet virus aimed at infecting the country's nuclear plant system.\nAccording to the Iranian intelligence service, Stuxnet had infected 30,000 IP addresses in the country.", "label": 1}
{"text": "VMware vSphere For Dummies\nWith virtualization, a single server can host dozens or hundreds of virtual machines running a variety of operating systems, and even hook them together in a virtual network or cloud infrastructure. This practical guide shows you how to create a virtual system using the VMware VSphere environment. You'll find all the information you need to understand, design, and deploy one—without getting overwhelmed with technical detail. And once you’re up and running, this book is the perfect reference for maintenance and troubleshooting issues.\n- Introduces you to virtualization and VMware’s virtualization/cloud computing technology, the most recent version is VMware vSphere Shows you how to design a vSphere environment\n- Covers installation, deployment, management, maintenance, and troubleshooting\n- Provides what IT managers and system administrators need to roll out their first virtualized or cloud infrastructure, or to get up to speed on VMware’s technology\nGet up and running on the cloud with VMware vSphere For Dummies!", "label": 1}
{"text": "Those of us who interact with or manage the results from penetration testing teams all (hopefully!) understand the ramifications when a XSS vulnerability is found.\nWe may even all understand the differences between a reflected XSS vulnerability and a persistent (stored) XSS vulnerability.\nWhat about those higher up the food chain? Do those who interact with the executives within an organisation fully understand the risks from a XSS vulnerability? Do they paint a realistic picture to those who are ultimately responsible for said website of just what is possible?\nA reflected XSS vulnerability is when ‘code’ is injected into a website in such a way so as to deliver a payload or to produce a result on the end users browser. Reflected XSS vulnerabilities are delivered to a victim via various means such as an email causing the user to click on a malicious URL which in itself normally contains the malicious ‘code’.\nA persistent XSS vulnerability is one in which the ‘code’ is actually injected into the website itself, and remains for multiple users to be attacked by. For example, placing XSS code within the database that a forum uses would mean anyone who viewed that specific forum or thread would be affected by said code. The URL used to access this forum would not appear malicious…\nIn this post I’d like to provide some examples of what is possible with a reflected XSS vulnerability, it is in no way an exhaustive list. I created a purposefully weak and simple application that prints (or executes) the text placed in the relevant fields. It uses the GET method which means the code is visible within the browsers address bar…\nAs can be seen the application is a simple form asking for a Name and CustomerID which are then printed on the next page\nNotice that the URL contains now the ‘code’ for an alert, and its being executed without restriction.\nTime for some fun… Any one remember Rick Astley?\nFrom a PR point of view, an XSS can be very embarrassing. Executed in a certain manner and it could be used to launch a variety of ‘inappropriate’ popup windows which would appear to be from the ‘corporate’ website, it could equally be used to redirect any users accessing the specific URL to a company’s main competition.\nOne last example is the embedding of new forms into websites so as to try and steal users legitimate credentials. Now it could be said that vigilant users would see something wrong with the URL, but what about if it was hidden behind a ShortURL? How many of your users would fall for this in that scenario?", "label": 1}
{"text": "'End of passwords' predictions are premature - Cambridge boffin\nNice fresh well-salted hash will keep them healthy\nAdvances in the power of computers won't automatically make passwords obsolete, according to a top computer science researcher.\nJoseph Bonneau, a postgrad researcher at Cambridge University, looked into the perceived wisdom that runs along these lines: \"Since computers are getting exponentially faster, yet the human brain is constant, then password crackers will eventually beat human memory.\"\nRemarks such as this are often made when the latest advances in increasingly powerful graphics processors for password cracking or similar stories hit the news. Bonneau doesn't dispute that password cracking is getting faster or that easily guessable or reused passwords are toast. Instead he disputes the idea that well thought out, complex passwords stored using a sufficiently robust hash function with proper salting have had their day.\nA hash function is a mathematical process that takes a \"message\" and forms a message digest or hash from it. Storing plain text passwords as part of an online authentication system is an obviously bad idea. If a website is broken into and the passwords are lifted then even well thought out passwords are exposed.\nInstead websites need to store password hashes, protected by salting, in order to prevent brute force attacks using rainbow tables.\nA password hash is computationally easy to create but working out the corresponding password from a hash ought to be nearly impossible, given a correctly implemented hash function. Rainbow tables circumvent this snag by creating a large data set of hashes from nearly every possible password. Faster number-crunching chips make it possible to derive and run through an increasing volume of possible passwords, increasing the potency of such brute force attacks.\nBonneau argues however that this points towards an arms race necessitating the development of better hashing algorithms rather than an inexorable move towards the end of days for passwords.\n\"Password cracking is certainly getting faster,\" Bonneau explains. \"In my thesis I charted 20 years of password cracking improvements and found an increase of about 1,000 in the number of guesses per second per unit cost that could be achieved, almost exactly a Moore’s Law-style doubling every two years.\n\"The good news though is that password hash functions can (and should) co-evolve to get proportionately costlier to evaluate over time. This is a classic arms race and keeping pace simply requires regularly increasing the number of iterations in a password hash. We can even improve against password cracking over time using memory-bound functions, because memory speeds aren’t increasing nearly as quickly and are harder to attack using parallelism,\" he adds.\nBonneau cautions against complacency: hashing passwords isn't going to get any more efficient over time and older algorithms will need to be replaced by more complex successors. As well as the brute force problem, hashing algorithms can come under increasing pressure from new types of cryptanalysis.\n\"Moore’s Law has indeed broken MD5 as a password hash and no serious application should still use it. Human memory isn’t more of a problem today than it used to be though. The problem is that we’ve chosen to let password verification become too cheap,\" Bonneau argued.\nBooneau's remarks come days after Deloitte Canada warned that the password was doomed. It predicted more than 90 per cent of user-generated passwords will be vulnerable to hacking during the course of 2013.\n“Passwords containing at least eight characters, one number, mixed-case letters and non-alphanumeric symbols were once believed to be robust. But these can be easily cracked with the emergence of advanced hardware and software,” Duncan Stewart, director, Deloitte Canada Research said. Deloitte Canada made the point while arguing for more widespread use of two-factor authentication using either tokens or mobile phone technology. Password vaults, secured by two-factor authentication, can play a role in driving the wider use of more complex passwords that users don't necessarily have to remember, the management consultancy argues, adding that disaster beckons for continued use of current password choices.\n\"In a recent study of six million actual user-generated passwords, the 10,000 most common passwords would have accessed 98.1 percent of all accounts,\" Deloitte Canada adds.\nEasily guessable passwords are arguably a lesser problem than password re-use. The average user has 26 password-protected accounts, but only five different passwords across those accounts, according to a recent study by credit reference agency Experian.\nDeloitte Canada's prognosis on password problems can can be read on page 11 of a larger report on tech trends here (PDF). ®", "label": 1}
{"text": "Enforcing data integrity ensures the quality of the data in the database. For example, if an employee is entered with an employee_id value of 123, the database should not allow another employee to have an ID with the same value. If you have an employee_rating column intended to have values ranging from 1 to 5, the database should not accept a value of 6. If the table has a dept_id column that stores the department number for the employee, the database should allow only values that are valid for the department numbers in the company.\nTwo important steps in planning tables are to identify valid values for a column and to decide how to enforce the integrity of the data in the column. Data integrity falls into these categories:\n- Entity integrity\n- Domain integrity\n- Referential integrity\n- User-defined integrity\nEntity integrity defines a row as a unique entity for a particular table. Entity integrity enforces the integrity of the identifier column(s) or the primary key of a table (through indexes, UNIQUE constraints, PRIMARY KEY constraints, or IDENTITY properties).\nDomain integrity is the validity of entries for a given column. You can enforce domain integrity by restricting the type (through data types), the format (through CHECK constraints and rules), or the range of possible values (through FOREIGN KEY constraints, CHECK constraints, DEFAULT definitions, NOT NULL definitions, and rules).\nReferential integrity preserves the defined relationships between tables when records are entered or deleted. In Microsoft® SQL Server™ 2000, referential integrity is based on relationships between foreign keys and primary keys or between foreign keys and unique keys (through FOREIGN KEY and CHECK constraints). Referential integrity ensures that key values are consistent across tables. Such consistency requires that there be no references to nonexistent values and that if a key value changes, all references to it change consistently throughout the database.\nWhen you enforce referential integrity, SQL Server prevents users from:\n- Adding records to a related table if there is no associated record in the primary table.\n- Changing values in a primary table that result in orphaned records in a related table.\n- Deleting records from a primary table if there are matching related records.\nFor example, with the sales and titles tables in the pubs database, referential integrity is based on the relationship between the foreign key (title_id) in the sales table and the primary key (title_id) in the titles table.\nUser-defined integrity allows you to define specific business rules that do not fall into one of the other integrity categories. All of the integrity categories support user-defined integrity (all column- and table-level constraints in CREATE TABLE, stored procedures, and triggers).", "label": 1}
{"text": "Why a Surveillance Society Clock?\nSurveillance is an urgent issue. That isn't always obvious amid the constant blur of new technologies and one-day privacy stories, but when you step back it is clear we are at a crucial moment for the future of privacy and freedom, in danger of tipping into a genuine surveillance society completely alien to American values. That is why the ACLU has made this new Surveillance Clock – to dramatize the urgent situation we face.\nMake a Difference\nYour support helps the ACLU defend privacy rights and a broad range of civil liberties.\nAmazing new technologies enter our lives at such a steady pace that we have gotten used to constant change – change that often comes to us wrapped in the promise (and often the reality) of pleasing new conveniences and efficiencies. Yet the dark side of new technologies is usually slower to emerge – and often builds in the shadows, without an advertising budget or corporate cheerleader to thrust it into public view.\nIt doesn't require some apocalyptic vision of American democracy being replaced by dictatorship to worry about a surveillance society. There is a lot of room for the United States to become a meaner, less open and less just place without any radical change in government. All that's required is the continuation of trends that have continued unimpeded in recent years:\n- Powerful new technologies\n- Weakening privacy laws\n- The \"War on Terror\"\n- Courts that are letting privacy rights slip away\n- A president who thinks he can ignore laws against warrantless spying on citizens\n- Big corporations willing to become extensions of the surveillance state\nThe Surveillance Clock symbolizes the potential for a dark future where our every move, our every transaction, our every communication, and eventually our every thought, is recorded, compiled, and stored away, ready to be examined and used against us by the authorities whenever they want.\nThe Surveillance Society Clock was inspired by the \"Doomsday Clock\" created in 1947 by the Bulletin of the Atomic Scientists to warn about the potential for nuclear war. Today we face the prospect of the complete loss of our privacy. In that way, the Surveillance Society Clock is a fitting sign of the times we're now living in.\nBut, as dire as things have gotten, it's not too late - there is still time to save our privacy. Doomsayers who say \"it doesn't matter, we've already lost all our privacy\" are wrong. In America we still enjoy many protections despite everything that is happening – a reflection of the wisdom of our founders and the strength of our traditions. But to keep those traditions alive, our generation will have to work harder. We need modern privacy laws and new technologies that enhance our privacy rather than destroy it.\nWe hope that our clock will help to remind people of the emergency we face, and spur them to take action on our Web page.\nGo to www.aclu.org/clock", "label": 1}
{"text": "This blog was originally posted here: Windows 8: The right way to Read & Write Files in WinRT\nAlso, check out our Windows Runtime (WinRT) sponsored section.\nWindows 8: The right way to Read & Write Files in WinRT\nWindows 8 Metro development leverages WinRT; and, in WinRT, there are new namespaces – and namespace constriction in the .Net Framework. What you think you know, you may not.\nMSDN: In some cases, a type that you used in a .NET Framework desktop app doesn't exist within the .NET APIs for Metro style apps. Instead, you can use a type from the Windows Runtime. For example, the System. IO. IsolatedStorage. IsolatedStorageSettings class isn't included in the .NET APIs for Metro style apps, but the Windows.Storage.ApplicationDataContainer class provides similar behavior for storing app settings. Examples of common changes you might have to make are included in the section Converting your existing .NET Framework code.\nRead Isolated Storage\nEvery Metro application has three folders. A Local folder, a Roaming folder and a Temp folder. Each is accessed the same way. Local is meant to store assets in a local, application-specific folder.\nMSDN: You can access files in the local app data store using the \"ms-appdata:///local/\" protocol. To access files in the app package, use Windows. ApplicationModel. Package. Current. InstalledLocation.\nTo request that Windows index your app data for search, create a folder named \"indexed\" under this folder and store the files that you want indexed there. Windows indexes the file content and metadata (properties) in this \"indexed\" folder and all its subfolders.\nRoaming is meant to store assets that should be synchronized with any other desktop where the current user has the same application installed.\nMSDN: The sync engine has restrictions on the file name conventions that you must follow to ensure the items in the roaming folder can roam. Be sure that your file and folder names do not contain leading whitespace. The sync engine may limit the total size of settings and files that can roam. You can access files in the roaming app data store using the \"ms-appdata:///roaming/\" protocol.\n<img src=\"ms-appdata:///roaming/myFile.png\" alt=\"\" />\nTemp is a throw-away location that will be cleaned, potentially, every time the application is launched.\nMSDN: You can access files in the temporary app data store using the \"ms-appdata:///temp/\" protocol.\nHere’s how you use them:\nGet the code here.\nThe code above is a simple Unit Test demonstrating the core functionality of writing and reading to Isolated Storage. You might notice that there is no mention of Isolated Storage in the code or namespaces (like there is in the Windows Phone API). Just know that all of this takes place in Isolated Storage, and for the same reason – to compartmentalize your application and it’s ability to break the user’s machine.\nRead Project Files\nHere’s a fun one. What if you have a resource (a file) in your project that you want to read? Lots of time this is for sample data or settings or something. It could be an XML file, a JSON file, or something else. Can you do it? Of course.\nAdd the file to your project. Note: since this is your file, you will need to deal with the type. Somewhere else you can learn how to deserialize JSON and XML.\nChange your file’s Build Action to Content. And, change Copy to Output Directory to Copy Always. This will ensure the file itself ships with your application. If it doesn’t, you wont have a file to read!\nRead your project file like this:\nGet the code here.\nThe code above is a simple Unit Test demonstrating how to read a file that is included in your project’s folder structure. The two most important parts is the unique path and Installed Location folder. Pay close attention. The correct path will include your project name (mine is Metro.Helpers.Tests).\nRead Local files w/a Picker\nHere’s a great one. You want to read a file in the Documents Library? Let the user select the file using a picker, and take it from there! Let’s do it.\nJust Do It\nThere’s nothing special you have to do in order to use a file picker. No changes to the AppXManifest, I mean. The reason is, using a File Picker puts the user in charge. Only the user can pick a file. And so, the picker itself is sort of its own Capabilities declaration and consent.\nGet the code here.\nIn the code above we initialize the FileOpenPicker (just like we have always done in .Net). We invoke the picker using PickSingleFileAsync() where we get a StorageFile (just like all the techniques above) and we go from there. I added a MessageBox (aka MessageDialog) to show some details. Clearly in your application you will do something else.\nRead Local files w/o a Picker\nWhat if you want to read a file without using the File Picker. Can you do that? You bet. But, it takes more effort because you need to update your applications AppXManifest to request the Document Library Access capability.\nBut wait there’s more.\nSee that red X on the Capabilities tab title? That tells you that something is not right. The manifest designer is pretty cool. What’s left?\nYou also need to update your AppXManifest by declaring what file type(s) you want to access. Then, even with access to the folders, you only have access to a limited set of file types. (in case you wondered *.* is not allowed)\nNote: Accessing the file system without user interaction is dangerous for the user. These extra steps are not meant to make your life (the developer) easier. It is meant to make the user’s experience easier and more safe.\nSo, in my case I will only want access to TXT files. The Declarations tab can be complex – to learn more about it, look here. I set a new file type (.txt) and let it role from there.\nWhen the user installs your application, they will be promoted to consent to the capabilities your application requests. Its capabilities are constrained by the manifest. And, your app’s capabilities are reviewed by Microsoft store curators.\nNow, get that file!\nYou have probably noticed with all the samples in this article that I have to write and read in order to have a reliable test. This one is no different. This will create the HelloWorld.txt file and read it. For added fun, I also will delete the file at the end of the method so your folder is not polluted.\nGet the code here.\nThe only reason the code above works is because we have declared the capability to read TXT files from the Documents Library folder in the AppXManifest file. Reading the file is easy because, once you get it, it’s just a simple WinRT StorageFile.\nPretty simple really, eh?\nSome Interesting StorageFile Methods\nI might take a moment to talk about StorageFolder, too. One of the most common requests I get is to iterate files and folders on user’s system. You really can’t – if what you mean is to start at c:\\. Try to iterate through c:\\ and you get this:\nYou can, however, iterate the files in a Library (Documents, Photos, Music, Videos, and even Home Group) folder – if you have requested this capability in the manifest. It is important to note that the files returned for a folder will be automatically filtered to the file types you declare in your manifest. (Did I already mention *.* cannot be declared?) Let me restate that as a developer you have intentional restrictions like this that ultimately improve the user’s experience and safety.\nRead those files people. Whatever your reason, they are there for you to get them. Yes, the sandbox of a Metro application prevents access to files and resources outside user’s Libraries. But in about 2 seconds you can appreciate this decision. We are approaching a brave new world.\nNow, should your application REQUIRE such access (that is otherwise restricted), you might consider the choice between desktop and metro applications – or consider a clever alternative; we all know you are a clever developer, keen at problem solving. You can do it!\nBest of luck!\nJerry Nixon is a Microsoft Developer Evangelist in Colorado. He has been developing and designing on the Microsoft platform for 15 years. He speaks at universities, events and groups on Kinect, XAML, Windows Phone, and Windows 8. Most of Jerry’s days are spent teaching his three daughters Star Trek character backstories and episode plots.", "label": 1}
{"text": "DNSSEC: Security for Essential Network Services - Page 3\nHow DNSSEC Works\nFrom our discussion so far, it is clear that DNS has some major security issues that urgently need to be addressed. The Internet and security engineering communities have responded to the threats by developing DNSSEC, a new secure DNS protocol, which addresses the data integrity and source-spoofing issues by means of a public key distribution. Interestingly, the extensions do not protect against buffer overruns or DDoS types of attack, nor do they provide confidentiality -- another major issue.\nTo maintain as much backwards compatibility as possible, the DNSSEC protocol requires only minor changes to the DNS protocol. DNSSEC has added four additional record types (SIG, KEY, DS, and NXT) and two new message header bits (CD and AD). Because the UDP protocol has a packet size limit of 512 bits, DNSSEC requires the use of EDNS0 extensions that override the limitation so that larger key sizes can be accommodated.\nThe DNSSEC implementation uses the familiar public/private key system. The site administrator generates a key pair for the secured domain. The private key is generally kept on the domain's primary master name server, and the public key is published in the domain in a KEY record. The administrator signs the domain's data record to verify its authenticity and adds a SIG record, which contains the signature for each domain record. The administrator submits the public KEY to the administrator of the domain's parent to sign with proof that he is the administrator of that domain. The parent domain's administrator signs the domain's public KEY and returns it. Unfortunately, a major unresolved issue is that nobody has really determined key authentication and verification methodologies. How keys are configured initially and how they are updated has yet to be determined as well.\nDNSSEC solves many of the worst DNS security problems. It is based on generally known technology and is backwards compatible with the existing DNS infrastructure. It is completely transparent to the user population and downstream administrators if they choose not to implement the extensions. While it does require installation of BIND 9 or later, you should upgrade to BIND 9 for many other beneficial reasons.\nSo why has DNSSEC not been widely adopted by the Internet community to date? After all, increased security of such a vital service should be an important priority for the maintenance of the Internet. Unfortunately, the implementation of DNSSEC is problematic because of the large increase in the computational load it puts on the servers, the hierarchical model of trust, the lack of tools to support the additional administrative overhead, the need for a higher level of time synchronization between the servers, and most critically, DNSSEC by itself does not begin to solve all the known DNS security vulnerabilities.\nIncreased Computational Load\nDNSSEC significantly increases the size of DNS response packets, which drastically increases the computational load on the DNS servers and also increases the query response time. Just the process of verifying signed resource records is computationally intensive, particularly if you choose larger key sizes. The DNSSEC standard allows up to 1024 bit keys. Adding digital signatures to a domain increases each record size 5-7 times, which puts a burden on upstream name servers.\nHierarchical Trust Model\nLike DNS itself, DNSSEC's trust model is almost totally hierarchical. Any compromise in the chain between the root servers and a target machine can damage DNSSEC's ability to protect the integrity of the data owned by that downstream system.\nLack of Management Tools\nDNSSEC is an order of magnitude more complex than DNS. Since the system is relatively new, there are few tools to help with the cumbersome task of maintaining a signed domain. Serious problems can occur with configuration errors and expired keys, and monitoring and log analysis tools are virtually non-existent. Debugging the errors by hand can be time consuming and difficult.\nForces Stricter Time Synchronization\nDNSSEC requires at least some time synchronization between the primary and secondary name servers. This is problematic because NTP (Network Time Protocol) itself is insecure, which opens up the possibility of DoS attacks based on invalid times.", "label": 1}
{"text": "In the past, I've written about \"phishing.\" Basically, it's a way for unscrupulous thieves to steal your identity. They send you an e-mail that includes a link to a bogus site that asks you to type in your personal information. Keeping yourself safe from phishing is simple: never, ever click a link in your e-mail that asks for any personal information. If you are a PayPal or eBay member, for example, and you get an e-mail that seems to be from them, don't click the link in the e-mail. Take the three extra seconds to open up a new browser window and type in www.paypal.com or www.ebay.com directly into the address bar.\nAvoiding this form of identity theft is easy, however, there's a new type of attack that's more complex. A term called \"pharming\" describes a new way to trick you out of providing personal information. Pharming is another name for something that's been around for a while called \"domain spoofing.\" Instead of sending an e-mail, pharmers attack a fundamental piece of the Internet called domain name servers (DNS).\nTo understand pharming, you need understand a bit about DNS. Basically, the Internet is really made up of numbers, not names, to describe the location of Web sites. So a site called www.mywebsite.com might really be 188.8.131.52. Domain name servers sit out there, and by accessing large databases of sites, they translate the text you type into the numbers the Internet needs to take you to the site you requested. Unfortunately, DNS is a weak link because a number of years ago, hackers figured out how to \"poison\" DNS and change the records for certain sites. They pretend to have authority to change the destination of a Web address. If they do this to an information site, it's really not a big deal as far as identity theft is concerned. If they do it to a banking site, it becomes a really big deal.\nThe scary reality of pharming is that even if you were to type in www.mybank.com into your browser's address bar, you could be taken to a site that looks like mybank.com, but really is not. However, by paying attention you can keep yourself safe. Any reputable banking or ecommerce site has a security certificate (or SSL certificate) from an authority such as Verisign or Thawte. That's what gives you the little lock icon or https:// in the address bar. A pharmed site won't have a valid certificate.\nSo you want to make sure your Web browser checks for a valid SSL certificate. To do that, you need to set some options. In Internet Explorer, choose Tools|Internet Options. In the Advanced tab, look under the Security section. Add check marks next to: Check for publisher's certificate revocation, Check for server certificate revocation, Use SSL 3.0, and Warn about invalid site certificates.\nSure, people are working on making DNS more secure. But the criminals are working just as hard on ways to defeat new security. So when you surf, always pay attention. If something looks a little \"off\" with a site, it may be, so exercise caution before providing any important information.", "label": 1}
{"text": "Nov 18, 2011 11:45 AM, By Mark Mayfield\nIs it ready for AV control?\nThe definition of cloud computing has, until recently, been as translucent as the gaseous cluster of water vapor molecules after which it is named.\nTo help add shape to the issue, the National Institute of Standards and Technology (NIST) released a draft document in January 2011, titled “The NIST Definition of Cloud Computing.” It begins with the definition: “Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.”\nAs part of its definition, NIST also defines three service models, including Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). Saas is the capability to use the provider’s applications running on a cloud infrastructure, where the applications are accessible from various client devices through a thin client interface such as a web browser (e.g., web-based email). Platform as a Service (PaaS) refers to the capability to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider. Cloud Infrastructure as a Service (IaaS) allows the capability to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components (e.g., host firewalls).\nIn the IT world, cloud computing is here today, and most experts predict significant expansion. Gartner is projecting rapid growth in public cloud services worldwide, with revenue growing from $68.3 billion in 2010 to $102.1 billion by 2012 and $180 billion by 2015. Somewhat more conservatively, IDC predicts that public cloud IT spending will grow from $21.5 billion in 2010 to $72.9 billion in 2015. While Gartner focuses on revenue, which allows for the inclusion of new business model growth, both firms expect the cloud market to grow at more than five times the rate of traditional IT products.\nBut is AV going to the cloud? It depends on whom you ask. Many would say that it already has. Any time you access music, video or other AV content that’s hosted on a server that you don’t own, that’s cloud AV access. Cloud AV is already well entrenched in the consumer AV world. Do you use Netflix? That’s cloud-based AV access. So is YouTube.\nApple’s iCloud allows users to stream images and other types of media to other devices, primarily manufactured from Apple. And Amazon’s Cloud Player is all about storage and streaming of music—all you do is “reserve” as much cloud storage as you need.\nBut what about cloud-based AV control for out-of-the-home applications? If the current trend of consumer technologies migrating to commercial applications continues, it’s probably already on its way.\n“Today, I can control devices in my home today over the cloud, using my iPhone or iPad,” says Dave Sobel, CEO of Fairfax, Va.-based Evolve Technologies. “As commercial AV moves closer to the IT model, it’s only logical that this type of control will extend to AV systems in the workplace.” Sobel cites figures from CompTIA, which projects that 20 percent of businesses will have fully cloud-based IT services by the end of 2012. It’s no big stretch to envision that commercial AV devices and systems—already considered part of the IT infrastructure—aren’t far behind.\nNot everyone agrees with Sobel’s assessment, including Steve Greenblatt, president of independent programming firm Control Concepts. “At this point, I think it’s pretty far off,” he says. “A lot of people had been thinking, for years, that you wouldn’t need anything more than a computer in a room to control an AV system, but AV systems have really gotten a lot more complicated than that. I think cloud-based control would be some time in the future.”\nOne of the problems with the idea of cloud-based AV control is that, for many AV devices, you still need a dedicated control processor to perform basic functions, like projector on/off, audio system volume levels, or camera pan/tilt/zoom. Serial commands delivered by IR or RS-232 and simple contact closure signal is still the most common way to control many AV products. But most control processors today are software-configurable, so it’s logical that as these devices become more like IT appliances, the software that drives control functions could be accessed via the cloud.\nAMX has announced a cloud-based systems configuration tool that allows AV technicians or IT professionals to easily configure an AMX system by using a step-by-step, wizard-based approach. Rapid Project Maker (RPM) is stored on AMX servers, so users never have to worry about “who owns the code” or what happens if an on-premise system should fail. It’s always there, “in the cloud”; no additional software is required. Once configuration of an AV control system is complete, the code is downloaded to the on-premise controller, and it’s ready to go. But just as configuration moves to the cloud, is it feasible that the control processor itself could disappear as an on-premises piece of hardware, and become a cloud-based IaaS function?\nAcceptable Use Policy blog comments powered by Disqus", "label": 1}
{"text": "(1) (Solid State Lighting) See LED lighting.|\n(2) (Secure Sockets Layer) The leading security protocol on the Internet. Developed by Netscape, SSL is widely used to do two things: to validate the identity of a Web site and to create an encrypted connection for sending credit card and other personal data. Look for a lock icon at the top or bottom of your browser when you order merchandise on the Web. If the lock is closed, you are on a secure SSL or TLS connection (see TLS).\nHTTPS and Port Number 443\nAn SSL session is started by sending a request to the Web server with an HTTPS prefix in the URL, which causes port number 443 to be placed into the packets. Port 443 is the number assigned to the SSL application on the server (see well-known port).\nAfter the two sides acknowledge each other, the browser sends the server a list of algorithms it supports, and the server responds with its choice and a signed digital certificate. From an internal list of certificate authorities (CAs) and their public keys, the browser uses the appropriate public key to validate the signed certificate. Both sides also send each other random numbers. For more details on certificates, see digital certificate.\nData for Secret Keys Is Passed\nThe browser extracts the public key of the Web site from the server's certificate and uses it to encrypt a pre-master key and send it to the server. At each end, the client and server independently use the pre-master key and random numbers passed earlier to generate the secret keys used to encrypt and decrypt the rest of the session. See TLS, server-gated cryptography, security protocol and public key cryptography.\nThese steps take place to negotiate an SSL session before any user data are transmitted. Steps 5 and 6 verify the integrity of the handshake, ensuring that nobody tampered with any messages. These checksums are called \"message authentication codes\" (see", "label": 1}
{"text": "Cloud computing is a growing trend in information technology as organizations look for ways to save money and add flexibility to their operations. Cloud computing, while still an evolving service, provides on-demand network access to a shared pool of computing resources such as networks, servers, storage and applications. The pooling of resources allows the provider to rapidly scale to meet changing customer demands. The service is typically provided through a large data center. Cloud computing can be divided into three types: Software as Service, Platform as Service, and Infrastructure as Service.\n- Software as a Service (SaaS): Provides ready for use web-based applications such as email that are maintained centrally by a provider (e.g., Gmail, Salesforce.com).\n- Platform as a Service (PaaS): Provides programming languages and tools that can be used by application developers to create and deploy applications on the web.\n- Infrastructure as a Service (IaaS): Provides computing resources, such as virtualized servers and storage, whose usage is rented from a provider (e.g., Amazon EC2, Windows Azure).\nIn addition, cloud computing can be private, available for a single organization/group of users, open to the public, or some combination of these models.1\nThe growth in cloud computing is fueled by economies of scale. Cloud computing allows users to pay for what they need, when they need it.\nThere are security and privacy concerns that must be considered before moving to cloud computing, including the following:\n- Vendor Security: Cloud computing customers rely on providers to implement appropriate security measures to protect the confidentiality, integrity, and availability of data. Be wary of providers who are reluctant to share details of their security architecture/practices with customers.\n- Isolation/Segregation: Users access cloud computing resources via a virtual machine hosted on an unknown physical machine2. The physical machine may be shared with other users. Providers must ensure that multiple customers do not interfere with each other, maliciously or unintentionally.\n- Data Location: Providers may have data centers located in other countries. Be sure your vendor contract stipulates any restrictions you may have on the physical location of where your data is stored.\n- Management Interface: Customers access the cloud management interface via the Internet, thus increasing exposure to potential attack.\n- Reputation Sharing: Bad behavior by one cloud customer may impact others using the cloud. For example a customer engaging in spamming may cause a common cloud IP address to be blacklisted.\n- Provider Viability: What happens to your organization’s applications and data in the event that the provider goes out of business?\n- Compliance: Placement of data in the cloud does not eliminate an organization’s need to meet legal and regulatory requirements such as PCI or HIPAA. Organizations will need timely assistance from cloud computing providers to fulfill investigation/audit requirements.\nOrganizations should fully research the risks and benefits of cloud computing before moving to that environment. It is critical that security requirements are addressed in contractual agreements in advance. In addition, there are steps organizations should take when using cloud computing:\n- Data Classification: Consider the sensitivity of your data before making a decision of whether or not to put it in the cloud.\n- Encryption: Encrypt sensitive data before placing it in the cloud.\n- Authentication: Consider requiring multifactor authentication for access to cloud computing resources.\n- Vulnerability Assessment: Include a requirement for a security review or vulnerability assessment as part of the service level agreement with the provider.\n- Monitor: Require close monitoring of cloud computing resources by providers for unauthorized activity.\n- Backup: Ensure that your backup data is not comingled with other customers.\n- Notification: Require providers to provide timely notification of any potential data security breach.", "label": 1}
{"text": "Using a new grid computing system, radiologists, physicians and pediatric oncologists at 40 hospitals all over North America are now quickly and securely exchanging high-resolution medical images.\nOne hoped-for result will be that the doctors of young cancer patients will know more quickly whose treatment is not working and be able to change course. Others include making second opinions from specialists anywhere easily available; and quicker, closer monitoring of ongoing clinical research and diagnostic practice.\n\"We have broken the medical image communication barrier,\" says Stephan Erberich, a computer scientist who is the Director of Functional Imaging and Biomedical Informatics at Childrens Hospital Los Angeles and a faculty member of both the USC Keck School of Medicine and the USC Viterbi School of Engineering.\nHe will demonstrate the Globus MEDICUS system at the upcoming annual meeting of the Radiological Society of North America (RSNA) in Chicago every day from Sunday Nov. 26 through Thursday Nov. 30.\nThe Globus MEDICUS project makes pediatric cancer researchers and the medical imaging profession at large the latest in the rapidly growing number of scientific and professional communities using Globus open-source grid collaboration software developed at the USC Viterbi School of Engineering's Information Sciences Institute (ISI) and Argonne National Laboratories (ANL).\nCarl Kesselman and Ann Chevernak of ISI, who worked with Erberich in creating MEDICUS, built the system basing themselves directly upon earlier work by the Digital Imaging and Communication In Media (DICOM) standards committee.\nDICOM created a uniform electronic format for medical images, one that allow the whole range of commercial imaging devices -- X-ray, MRI, and CT -- to display and manage images from any other.\nBut DICOM's potential for transparent exchange between collaborating researchers, and physicians has so far not been realized, because of technological, administrative, and security challenges of confidential patient data, according to Erberich.\nAs a result, access to the interchangeable data was limited to the hospital where the images are acquired -- not even available to a patient's point-of-care facility, if different, unless physically carried there.\n\"Today if you leave the hospital, you either leave your digitized images behind or you have to carry them on a CDROM,\" said Erberich. \"This is not the 21st century healthcare we need in a networked society. All kinds of other fields, from banking to air travel now rely on instant information exchange and decision making online. We should be able expect the same level of sophistication in healthcare.\"\nThat day has now arrived, says the scientist. Using the DICOM Grid Interface Service (DGIS) DICOM records at medical facility anywhere are now easily accessible and exchangeable over Grid-secured Internet connections.\nThe MEDICUS project began when Erberich approached ISI grid experts Kesselman and Chervenak asking them \"to translate DICOM into Grid,\" as Erberich described it.\nKesselman had, as part of the Globus project previously helped more than a dozen scientific communities ranging from high-energy physicists to earthquake simulating engineers and geologists share instruments and data, securely and easily.\nHe immediately saw that the need was a perfect fit for Globus open-source Grid solution. \"There had to be new code developed to handle the medical-specific things like DICOM translation and patient confidentiality assurance,\" Kesselman said, \"but the cool thing is this leverages all of the existing underlying Globus technology that we use in so many other projects.\"\nIn creating key grid components for MEDICUS, ISI research scientist Chervenak and Kesselman, who is director of the center for grid technologies at ISI and a research associate professor of computer science in the USC Viterbi School of Engineering worked with Manasee Bhandekar, a computer engineer at the USC Alfred E. Mann Institute. ISI researchers Robert Schuler, Shishir Bharathi and Gaurang Mehta also made significant contributions.\nErberich developed the DICOM to Grid interface and led the inter-disciplinary collaboration between the engineering and clinical teams, working with Childrens Hospital radiologist-in-chief and Chairman Marvin D. Nelson.\nThe system has been in place since September, and as Nelson describes it, \"it's totally transparent. Each facility is now connected to the Grid, using its own interface -- you only have to one interface at the hospital, and that serves the whole hospital, reusing the hospital's capital investment in DICOM visualization devices.\"\nThe cost of installing a DGIS node is \"trivial,\" said Erberich: on the order of $1000 for a Grid gateway, attached to a high-bandwidth net connection. The gateway provides two-way access to the Grid, allowing upload of local images (after de-identification) and also continuing access to a catalog of archived DICOM records. \"The nice thing, \" said Nelson, \"if a researcher has authorization for a specific record in the catalog, it can be downloaded for use on her own image display.\"\nOne dramatic change in practice will be the ease of review. Researchers can look at observations made anywhere on the grid without leaving their offices.\n\"We store the images here in the Data Center, \" said Erberich, \"but the people who have been assigned to review images, can review them from virtually anywhere.\"\n\"Before\" he continued \"when we were documenting a research study, it meant that radiologists would have to physically come to a single facility and look through a file cabinet full of physical images. Now, radiologists all over the planet can look at the images at their leisure in their own offices, on their own favorite commercial medical imaging system.\"\nOne critical advantage of this is elimination of backlogs reviewing images, with potentially life-saving results for patients in studies. \"We'll probably have a more timely review of scans,\" said Robert C. Seeger, M.D., of the Saban Research Institute of Childrens Hospital Los Angeles, a specialist in neuroblastoma who is part of one of the research groups now using the system.\nBesides the 13-institution New Approaches in Neuroblastoma Therapy group (NANT.org) that Seeger is part of, the 27-member Children's Oncology Group (CURESEARCH.org) is now active.\nBoth the doctors and the computer scientists involved expect this number to skyrocket in coming years, because the entry cost is so low and the possibilities are only beginning to be tapped. Other advantages include:\nGreatly increased ease of radiological consultation and study. Any radiologist practicing on rare or unusual conditions can now see only see the small fraction of the total cases that present in one place. Now, \"he could sit in Boston and potentially review every single case, from anywhere in the country,\" says Seeger.\nImaging research. Scientists studying new techniques will be able to exchange samples instantly. And \"we can develop expertise not just for reading, but also processing images,\" said Erberich.\nDrug development. New techniques depend on imaging experimental animals, typically mice, using bioluminescent markers. Analysis of large bodies of such images requires great computing power. Grid techniques can both share images and the computing power necessary to extract their meaning.\nThe Globus Alliance is a community of organizations and individuals developing fundamental technologies behind the \"Grid,\" which lets people share computing power, databases, instruments, and other on-line tools securely across corporate, institutional, and geographic boundaries without sacrificing local autonomy.\nGrid computing work has been named one of \"Ten Technologies that Will Change the World\" by M.I.T. Technology Review, and has received a \"Top 100\" award as well as a \"Most Promising New Technology\" honor from R&D Magazine.\nThe Globus MEDICUS project was supported by the Children's Oncology Group Phase-I Consortium, NIH (grant UO1-BA97452), and the NANT Cancer Foundation.\nAAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert! system.", "label": 1}
{"text": "Sandia computer scientists successfully boot one million Linux kernels as virtual machines\nLIVERMORE, Calif. - Computer scientists at Sandia National Laboratories in Livermore, Calif., have for the first time successfully demonstrated the ability to run more than a million Linux kernels as virtual machines.\n(Media-Newswire.com) - LIVERMORE, Calif. — Computer scientists at Sandia National Laboratories in Livermore, Calif., have for the first time successfully demonstrated the ability to run more than a million Linux kernels as virtual machines.\nThe achievement will allow cyber security researchers to more effectively observe behavior found in malicious botnets, or networks of infected machines that can operate on the scale of a million nodes. Botnets, said Sandia’s Ron Minnich, are often difficult to analyze since they are geographically spread all over the world.\nSandia scientists used virtual machine ( VM ) technology and the power of its Thunderbird supercomputing cluster for the demonstration.\nRunning a high volume of VMs on one supercomputer — at a similar scale as a botnet — would allow cyber researchers to watch how botnets work and explore ways to stop them in their tracks. “We can get control at a level we never had before,” said Minnich.\nPreviously, Minnich said, researchers had only been able to run up to 20,000 kernels concurrently ( a “kernel” is the central component of most computer operating systems ). The more kernels that can be run at once, he said, the more effective cyber security professionals can be in combating the global botnet problem. “Eventually, we would like to be able to emulate the computer network of a small nation, or even one as large as the United States, in order to ‘virtualize’ and monitor a cyber attack,” he said.\nA related use for millions to tens of millions of operating systems, Sandia’s researchers suggest, is to construct high-fidelity models of parts of the Internet.\n“The sheer size of the Internet makes it very difficult to understand in even a limited way,” said Minnich. “Many phenomena occurring on the Internet are poorly understood, because we lack the ability to model it adequately. By running actual operating system instances to represent nodes on the Internet, we will be able not just to simulate the functioning of the Internet at the network level, but to emulate Internet functionality.”\nA virtual machine, originally defined by researchers Gerald J. Popek and Robert P. Goldberg as “an efficient, isolated duplicate of a real machine,” is essentially a set of software programs running on one computer that, collectively, acts like a separate, complete unit. “You fire it up and it looks like a full computer,” said Sandia’s Don Rudish. Within the virtual machine, one can then start up an operating system kernel, so “at some point you have this little world inside the virtual machine that looks just like a full machine, running a full operating system, browsers and other software, but it’s all contained within the real machine.”\nThe Sandia research, two years in the making, was funded by the Department of Energy’s Office of Science, the National Nuclear Security Administration’s ( NNSA ) Advanced Simulation and Computing ( ASC ) program and by internal Sandia funding.\nTo complete the project, Sandia utilized its Albuquerque-based 4,480-node Dell high-performance computer cluster, known as Thunderbird. To arrive at the one million Linux kernel figure, Sandia’s researchers ran one kernel in each of 250 VMs and coupled those with the 4,480 physical machines on Thunderbird. Dell and IBM both made key technical contributions to the experiments, as did a team at Sandia’s Albuquerque site that maintains Thunderbird and prepared it for the project.\nThe capability to run a high number of operating system instances inside of virtual machines on a high performance computing ( HPC ) cluster can also be used to model even larger HPC machines with millions to tens of millions of nodes that will be developed in the future, said Minnich. The successful Sandia demonstration, he asserts, means that development of operating systems, configuration and management tools, and even software for scientific computation can begin now before the hardware technology to build such machines is mature.\n“Development of this software will take years, and the scientific community cannot afford to wait to begin the process until the hardware is ready,” said Minnich. “Urgent problems such as modeling climate change, developing new medicines, and research into more efficient production of energy demand ever-increasing computational resources. Furthermore, virtualization will play an increasingly important role in the deployment of large-scale systems, enabling multiple operating systems on a single platform and application-specific operating systems.”\nSandia’s researchers plan to take their newfound capability to the next level.\n“It has been estimated that we will need 100 million CPUs ( central processing units ) by 2018 in order to build a computer that will run at the speeds we want,” said Minnich. “This approach we’ve demonstrated is a good way to get us started on finding ways to program a machine with that many CPUs.” Continued research, he said, will help computer scientists to come up with ways to manage and control such vast quantities, “so that when we have a computer with 100 million CPUs we can actually use it.”\nSandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin company, for the U.S. Department of Energy’s National Nuclear Security Administration. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major R&D responsibilities in national security, energy and environmental technologies, and economic competitiveness.\nSandia news media contact: Mike Janes, email@example.com ( 925 ) 294-2447\nThis story was released on 2009-08-03. Please make sure to visit the official company or organization web site to learn more about the original release date. See our disclaimer for additional information.", "label": 1}
{"text": "The Distributed Checksum Clearinghouses or DCC is an anti-spam content filter that runs on a variety of operating systems. The counts can be used by SMTP servers and mail user agents to detect and reject or filter spam or unsolicited bulk mail. DCC servers exchange or \"flood\" common checksums. The checksums include values that are constant across common variations in bulk messages, including \"personalizations.\"\nThere are graphs of recently detected spam. Those graphs suggest the effectiveness of the system. For example, if you assume that 80% of all mail is spam and those graphs indicate that DCC finds 70% of mail is spam, then DCC detects 88% of spam.\nclick for more graphs\nThe idea of DCC is that if mail recipients could compare the mail they receive, they could recognize unsolicited bulk mail. A DCC server totals reports of checksums of messages from clients and answers queries about the total counts for checksums of mail messages. A DCC client reports the checksums for a mail message to a server and is told the total number of recipients of mail with each checksum. If one of the totals is higher than a threshold set by the client and according to local whitelists the message is unsolicited, the DCC client can log, discard, or reject the message.\nBecause simplistic checksums of spam would not be effective, the main DCC checksums are fuzzy and ignore aspects of messages. The fuzzy checksums are changed as spam evolves. Since DCC started being used in late 2000, the fuzzy checksums have been modified several times.\nUnless used with isolated DCC servers and so losing much of its power, DCC causes some additional network traffic. However, the client-server interaction for a mail message consists of exchanging a single pair of UDP/IP datagrams of about 150 bytes. That is often less than the several pairs of UDP/IP datagrams required for a single DNS query. SMTP servers make DNS queries to check the envelope Mail_From value and often several more. As with the Domain Name System, DCC servers should be placed near active clients to reduce DCC network costs. DCC servers exchange or flood reports of checksums, but only the checksums of bulk mail.\nDo not send comments or questions about your \"DCC listing\" to any address at Rhyolite Software unless an SMTP server operated by by Rhyolite Software LLC rejected your mail. Contact instead the operators of the system that rejected your mail.\nDCC does not \"list\" domain names or IP addresses, but detects bulk mail messages. Domain names, IP addresses, and so forth are \"listed\" independently. by DCC users. If DCC users want to receive your bulk mail, they must whitelist it by adding your IP address, SMTP envelope sender, RFC 2369 SMTP List-* headers, or other characteristics of your mail to their whiteclnt files. Do not send \"please remove my address\" requests unless you want your domain name, mailbox, or IP address added to a blacklist.\nA separate facility called DCC Reputations supported by the commercial verson of the DCC software does automatically compute the reputations for sending bulk mail. However, it makes no sense to ask for IP addresses to be removed from the distributed DCC Reputation database. A reputation for sending lots of bulk mail expires automatically a week to 30 days after the last bulk email reported by a DCC Reputation client mail system.\nSpam is unsolicited bulk mail, and only mail targets can say whether a message is solicited. A virtue of DCC and DCC Reputations spam filtering is that mail targets decide whether they have subscribed to bulk mail or want to hear from senders with DCC Reputations for sending bulk mail. The opinions of bulk mail senders about whether their messages are spam are irrelevant.\nThe current version of the DCC source is version 1.3.145, May 16, 2013. It is available at dcc-servers.net and Rhyolite Software. It is usually best to update an existing installation with the /var/dcc/libexec/updatedcc script. Some previous versions are available.\nThe variations of version 1.2.74 redistributed by some organizations is very old; it dates from May, 2005. Many problems have been fixed and improvements made since that version was released. Some of the problems in that old version cause problems for the public DCC servers. DCC clients of that version and older can be expected to stop working with the public DCC servers in coming months when the version of the DCC client-server protocol that they use is finally disabled on the public DCC servers.\nThe non-commercial DCC software is distributed under a license that is free only to organizations that do not sell filtering devices or services except to their own users and that participate in the global DCC network. ISPs that use DCC to filter mail for their own users are intended to be covered by the free license. You can redistribute unchanged copies of the free source, but you may not redistribute modified, \"fixed,\" or \"improved\" versions of the source or binaries. You also can't call it your own or blame anyone for the results of using it.\nOrganizations that do not qualify for the free license are welcome to inquire about licensing the commercial version of the DCC software by email to firstname.lastname@example.org or via the form. The commercial DCC version supports DCC Reputations.\nPlease note that contrary to obsolete web pages you might find with search engines, Rhyolite Software is currently the exclusive source of commercial DCC software. No other organizations can sell or market DCC software except as part of their own products.\nSelling the bandwidth and, most important, human system administration work of the public DCC servers to third parties has always been wrong. Sellers of products, \"appliances,\" or managed mail services must contract for or provide their own DCC servers, as well as obtain a commercial license for the DCC software.\nIncorrectly configured firewalls are the a common causes of problems of DCC client using the public DCC servers. Your firewalls must allow responses to requests from dccproc or dccifd on your system to come from UDP port 6277 at the public servers.\nAnother common cause of DCC client problems is the use of ancient versions redistributed by some organizations including Linux packagers. Those versions can try so hard to get answers that they triggers the denial-of-service (DoS) defenses in the public DCC servers. See a discussion of problems associated with old versions of the DCC software.\nExcessive requests are a third common cause. The public DCC servers have various defenses against DoS attacks including rate limiting or delaying responses based on the maximum of the requests made today and a recent daily average. When the delays would reach 4 seconds, the public servers completely ignore additional requests. If your mail system processes more than 100,000 messages per day, you should use your own, probably private DCC server connected to the global network of DCC servers.\nIf the public DCC servers not working for you, your firewalls allow UDP port 6277, and you are not sending an excessive number of requests, then the cause might be excessive or objectionable DCC operations that have been received from your network. See the blacklist of DCC clients used by the public DCC servers.\nEach of the several parts of DCC have its own man page including:\nThere are also\nThe code seems to be compatible with flavors of UNIX-like systems. See the list of systems in the installation instructions. The long range plan is to port the DCC client code widely, including to common personal computer operating systems.\nA useful anti-spam scheme is more than just code, and that is particularly true of the Distributed Checksum Clearinghouses, DCC, which are based sharing information about bulk mail If you do not run your own DCC server, you need to point your DCC client to someone else's server. The DCC client code does the right thing when it cannot contact any of the servers it knows about; it quickly passes the mail without worrying about its bulkiness. Given more than one server, the DCC client code uses the fastest or closest.\nWhen using someone else's server, you must either contact them for a DCC client-ID and corresponding password.\nPublic DCC servers for anonymous DCC clients handling fewer than 100,000 mail messages per day are provided by people and organizations in the following list. The default contents of /var/dcc/map file point to these servers.\n|DelMarVa OnLine||Sven Willenberger|\n|INFN (National Institute for Nuclear Physics) - Bari||Domenico Diacono|\n|INFN (National Institute for Nuclear Physics) - Turin||Alberto D'Ambrosio|\n|INAF IASF (National Institute for Astrophysics)-Palermo-Italy||Giacomo Fazio|\n|Peregrine Computer Consultants Corporation||Kevin A. McGrail|\n|Quonix Networks||John Von Essen|\n|Sonic,net, Inc.||Kelsey Cummings|\n|Tilastokeskus - Statistikcentralen||--|\n|Universitšt Trier||Horst Scheuermann|\n|Vienna University of Economics and Business Administration||Franz Schaefer|\nThe IP addresses of the public DCC servers define the DNS names dcc1.dcc-servers.net, dcc2.dcc-servers.net, dcc3.dcc-servers.net, dcc4.dcc-servers.net, and dcc5.dcc-servers.net. Use them by adding those names to your /var/dcc/map file with cdcc \"add dcc1.dcc-servers.net\" and so forth. The names are automatically installed when the DCC programs are installed with the ./configure script and Makefile in the source. See the installation instructions.\nNote well that it has been wrong to take and resell the bandwidth and, most important, human system administration work of the public DCC servers to third parties. Blunt words for that include theft and stealing. Vendors of \"spam appliances\" or services including DCC such as \"managed email\" must provide DCC servers of their own or contract for DCC services from others. They must also buy a license for the commercial version of the DCC software.\nThe effectiveness of DCC filtering increases with checksums \"flooded\" or exchanged with other DCC servers. The spam filtering results of violating the free license by not connecting a local, private server to the global network of DCC servers may be disappointing.\nMail systems that handle more than 100,000 mail messages per day should have a local DCC server so that processing incoming mail is not delayed by the time required for the UDP packets used by the DCC client protocol to cross the Internet. Organizations that deal with more than 500,000 mail messages per day benefit from two or more local DCC servers to ensure that at least one local DCC server is available despite system maintenance. Organizations that deal with fewer than 100,000 mail messages per day use less bandwidth of their own and of the servers in the global network by using the public servers.\nThe first step in configuring a DCC server to flood checksums is agreeing on the server-IDs of all participating servers. There is a private list of the DCC servers, server-IDs and so forth in the global network of DCC servers at //www.rhyolite.com/dcc/private/. It is readable only by server operators. Contact Vernon Schryver at email@example.com for server-IDs. Subscriptions to the DCC-servers mailing list are available only to operators of servers in the global network.\nThe DCC source includes a script named /var/dcc/libexec/fetch-testmsg-whitelist intended to be invoked by cron to periodically fetch new copies.\nThere are also mailing lists for DCC server operators and public DCC server operators, but they are closed except to operators.\nThe DCC FAQ also answers questions about the resources needed by a DCC server.\nTechnical questions or comments can be sent to Rhyolite Software. More extensive assistance can also be hired from Rhyolite Software.\nDCC Reputations are a distinct mechanism based on and contributing to DCC data. In part to minimize abuse by anonymous users, DCC Reputations are available only in the commercial version of the DCC software.\nDCC is based on an idea of Paul Vixie and on fuzzy body matching to reject spam on a corporate firewall operated by Vernon Schryver starting in 1997. The DCC software was designed and written at Rhyolite Software starting in 2000. It has been used in production since the winter of 2000/2001.\nContact Vernon Schryver at firstname.lastname@example.org or use the form.", "label": 1}
{"text": "Click on any phrase to play the video at that point.Close\nThe idea behind the Stuxnet computer worm is actually quite simple. We don't want Iran to get the bomb. Their major asset for developing nuclear weapons is the Natanz uranium enrichment facility. The gray boxes that you see, these are real-time control systems. Now if we manage to compromise these systems that control drive speeds and valves, we can actually cause a lot of problems with the centrifuge. The gray boxes don't run Windows software; they are a completely different technology. But if we manage to place a good Windows virus on a notebook that is used by a maintenance engineer to configure this gray box, then we are in business. And this is the plot behind Stuxnet.\nSo we start with a Windows dropper. The payload goes onto the gray box, damages the centrifuge, and the Iranian nuclear program is delayed -- mission accomplished. That's easy, huh? I want to tell you how we found that out. When we started our research on Stuxnet six months ago, it was completely unknown what the purpose of this thing was. The only thing that was known is it's very, very complex on the Windows part, the dropper part, used multiple zero-day vulnerabilities. And it seemed to want to do something with these gray boxes, these real-time control systems. So that got our attention, and we started a lab project where we infected our environment with Stuxnet and checked this thing out. And then some very funny things happened. Stuxnet behaved like a lab rat that didn't like our cheese -- sniffed, but didn't want to eat. Didn't make sense to me. And after we experimented with different flavors of cheese, I realized, well, this is a directed attack. It's completely directed. The dropper is prowling actively on the gray box if a specific configuration is found, and even if the actual program code that it's trying to infect is actually running on that target. And if not, Stuxnet does nothing.\nSo that really got my attention, and we started to work on this nearly around the clock, because I thought, \"Well, we don't know what the target is. It could be, let's say for example, a U.S. power plant, or a chemical plant in Germany. So we better find out what the target is soon.\" So we extracted and decompiled the attack code, and we discovered that it's structured in two digital bombs -- a smaller one and a bigger one. And we also saw that they are very professionally engineered by people who obviously had all insider information. They knew all the bits and bites that they had to attack. They probably even know the shoe size of the operator. So they know everything.\nAnd if you have heard that the dropper of Stuxnet is complex and high-tech, let me tell you this: the payload is rocket science. It's way above everything that we have ever seen before. Here you see a sample of this actual attack code. We are talking about -- around about 15,000 lines of code. Looks pretty much like old-style assembly language. And I want to tell you how we were able to make sense out of this code. So what we were looking for is, first of all, system function calls, because we know what they do.\nAnd then we were looking for timers and data structures and trying to relate them to the real world -- to potential real world targets. So we do need target theories that we can prove or disprove. In order to get target theories, we remember that it's definitely hardcore sabotage, it must be a high-value target and it is most likely located in Iran, because that's where most of the infections had been reported. Now you don't find several thousand targets in that area. It basically boils down to the Bushehr nuclear power plant and to the Natanz fuel enrichment plant.\nSo I told my assistant, \"Get me a list of all centrifuge and power plant experts from our client base.\" And I phoned them up and picked their brain in an effort to match their expertise with what we found in code and data. And that worked pretty well. So we were able to associate the small digital warhead with the rotor control. The rotor is that moving part within the centrifuge, that black object that you see. And if you manipulate the speed of this rotor, you are actually able to crack the rotor and eventually even have the centrifuge explode. What we also saw is that the goal of the attack was really to do it slowly and creepy -- obviously in an effort to drive maintenance engineers crazy, that they would not be able to figure this out quickly.\nThe big digital warhead -- we had a shot at this by looking very closely at data and data structures. So for example, the number 164 really stands out in that code; you can't overlook it. I started to research scientific literature on how these centrifuges are actually built in Natanz and found they are structured in what is called a cascade, and each cascade holds 164 centrifuges. So that made sense, that was a match.\nAnd it even got better. These centrifuges in Iran are subdivided into 15, what is called, stages. And guess what we found in the attack code? An almost identical structure. So again, that was a real good match. And this gave us very high confidence for what we were looking at. Now don't get me wrong here, it didn't go like this. These results have been obtained over several weeks of really hard labor. And we often went into just a dead end and had to recover.\nAnyway, so we figured out that both digital warheads were actually aiming at one and the same target, but from different angles. The small warhead is taking one cascade, and spinning up the rotors and slowing them down, and the big warhead is talking to six cascades and manipulating valves. So in all, we are very confident that we have actually determined what the target is. It is Natanz, and it is only Natanz. So we don't have to worry that other targets might be hit by Stuxnet.\nHere's some very cool stuff that we saw -- really knocked my socks off. Down there is the gray box, and on the top you see the centrifuges. Now what this thing does is it intercepts the input values from sensors -- so for example, from pressure sensors and vibration sensors -- and it provides legitimate program code, which is still running during the attack, with fake input data. And as a matter of fact, this fake input data is actually prerecorded by Stuxnet. So it's just like from the Hollywood movies where during the heist, the observation camera is fed with prerecorded video. That's cool, huh?\nThe idea here is obviously not only to fool the operators in the control room. It actually is much more dangerous and aggressive. The idea is to circumvent a digital safety system. We need digital safety systems where a human operator could not act quick enough. So for example, in a power plant, when your big steam turbine gets too over speed, you must open relief valves within a millisecond. Obviously, this cannot be done by a human operator. So this is where we need digital safety systems. And when they are compromised, then real bad things can happen. Your plant can blow up. And neither your operators nor your safety system will notice it. That's scary.\nBut it gets worse. And this is very important, what I'm going to say. Think about this: this attack is generic. It doesn't have anything to do, in specifics, with centrifuges, with uranium enrichment. So it would work as well, for example, in a power plant or in an automobile factory. It is generic. And you don't have -- as an attacker -- you don't have to deliver this payload by a USB stick, as we saw it in the case of Stuxnet. You could also use conventional worm technology for spreading. Just spread it as wide as possible. And if you do that, what you end up with is a cyber weapon of mass destruction. That's the consequence that we have to face. So unfortunately, the biggest number of targets for such attacks are not in the Middle East. They're in the United States and Europe and in Japan. So all of the green areas, these are your target-rich environments. We have to face the consequences, and we better start to prepare right now.\nRalph Langner: Okay, you really want to hear that? Yeah. Okay. My opinion is that the Mossad is involved, but that the leading force is not Israel. So the leading force behind that is the cyber superpower. There is only one, and that's the United States -- fortunately, fortunately. Because otherwise, our problems would even be bigger.\nYou can share this video by copying this HTML to your clipboard and pasting into your blog or web page.\nneed to get the latest Flash player.\nGot an idea, question, or debate inspired by this talk? Start a TED Conversation.\nWhen first discovered in 2010, the Stuxnet computer worm posed a baffling puzzle. Beyond its sophistication loomed a more troubling mystery: its purpose. Ralph Langner and team helped crack the code that revealed this digital warhead's final target. In a fascinating look inside cyber-forensics, he explains how -- and makes a bold (and, it turns out, correct) guess at its shocking origins.\nRalph Langner is a German control system security consultant. He has received worldwide recognition for his analysis of the Stuxnet malware. Full bio »", "label": 1}
{"text": "Ten students, working for ABC News, visited nuclear reactors on 25 college campuses and found many gaping security holes at many of them, prompting a federal investigation. Here's what the team found at MIT.\nReactor Name: MIT Nuclear Reactor Laboratory\nFuel: Highly-enriched uranium, possession limit 40 kg.\nPower Level: 5 MW\nBegan Operating: 1958\nLocation: In a highly populated area just off Massachusetts Avenue, the heavily traveled main artery that runs through Cambridge. The dense area includes campus buildings, pharmaceutical laboratories, shops and restaurants.\nSecurity Obervations: Two armed guards. No metal detectors. No searches. Tour available with advance request and interview. Multiple forms of identification requested and photocopied before tour. Backpacks allowed inside the complex, though not inside the reactor building. Wallets permitted on reactor tour.\nWhat We Found: Detailed information (including labeled diagrams and photographs of the reactor core and its full operation schedule) was easily located on the Internet. Even more information was available using campus computer terminals available to the public at the MIT library, where the Fellows found detailed floor plans of the reactor.\nThe Fellows scheduled a tour by e-mail and, after a brief interview with a few staff members, toured the reactor.\nAn ABC News producer parked a large Ryder truck next to the reactor facility and was not questioned or challenged.\nUniversity Reaction: In a written statement, Denise Brehm, senior communications officer, said given the small size of the reactor facility, it is not a likely target for terrorism.\nBrehm said an independent study assessing the impact of possible terrorist acts against the reactor concluded that in all likely scenarios the core of the reactor would not be breached and radiation would not be released. According to Brehm, the study also determined that a large truck bomb within even a few feet of the reactor building would not breach the containment of the reactor's core. The core is fully enclosed in a radiation-shielded structure consisting of several feet of concrete and other materials, which itself is housed within the containment building, \"all of which would impossible to breach at one time,\" Brehm said.\nTours are by appointment only and names, addresses and identification are run through a security review prior to the tour, Brehm said, adding that visitors are not allowed to bring bags or cameras into the reactor building, but must leave them in the administrative offices.\n\"MIT moved its reactor floor plans and exterior diagrams from its Web site following the 9/11 terrorist attacks,\" according to Brehm. Posting of the operating schedule does not pose a security threat because it does not indicate \"when MIT is conducting sensitive operations, such as a refueling.\"\n\"Fresh fuel is not stored in the facility and is never present in large enough quantities to create a nuclear weapon,\" Brehm said.\nAdditional Comment: The federal official responsible for security at the nation's campus reactors told ABC News that he was not happy to see the wide availability of detailed information on the Internet. \"That's something I'd want us to pursue, and we will,\" said Roy Zimmerman, director of the Office of Nuclear Security and Incident Response for the Nuclear Regulatory Commission.", "label": 1}
{"text": "As defenses against network DDOS attacks improve, hackers find a new target\nPart of GCN's series on DOS attacks.\nDenial of service attacks, which traditionally have bombarded networks with an overwhelming number of requests, are getting more efficient. And as these attacks mature, it's more important than ever that agencies understand the kind of attack they're facing so they can mount an effective defense.\nDenial of service is a descriptive term rather than a technical one: It describes the goal of the attack rather than the tools or techniques used. Although there are a variety of ways to carry out the attacks, they fall into two broad categories -- network and application.\nNetwork DOS attacks can be fairly simple brute-force affairs, flooding servers with high volumes of requests or packets to overwhelm the resources. In general, the way to counter them is to maintain enough bandwidth and computing power to withstand the flood, but this might be impractical in a well-orchestrated attack that can generate hundreds or thousands of times the agency's usual traffic levels. Or agencies can identify the malicious packets and block them before they hit their servers, which is best done as close to the source of the attack as possible.\nTo date, network DOS attacks probably remain the most common, but as defenses against them improve, \"we are seeing more attacks move up the stack to Layer 7 application attacks,\" said Rob Rachwald, directory of security strategy at Imperva. Application attacks do not rely on a flood of packets, but use specially formed — or malformed — queries and requests that servers have to deal with slowly until the number of available connections or the processing capacity is exhausted.\nApplication attacks can require less firepower than a network attack and can focus on a specific application or process rather than an IP address or range of addresses, making them more efficient.\nBoth types of attack often are strengthened by using multiple sources to deliver malicious traffic, a technique called distributed denial-of-service, or DDOS. Distributed attacks not only can deliver more firepower, but they can more easily hide by spreading out the source of the malicious traffic, making it more difficult to block. Botnets — networks of compromised computers often managed by a criminal enterprise — traditionally have powered this distribution, but hacktivist organizations also have encouraged volunteers to participate in attacks with easy-to-use tools. More recently, the rise of virtual computing has opened new avenues for distributed attacks.\n\"Now what we’re seeing is compromised cloud-hosting structures,\" said Fran Trentley, senior service line director for Akamai Technologies’ public sector business. Even more than botnets, cloud computing gives attackers access to large amounts of processing power and the ability to quickly move through large IP address spaces to hide their activities. This tactic \"makes it extremely challenging to fight,\" he said.\nAccording to a recent Prolexic report on observed DDOS activity in the fourth quarter of 2012, the majority of attacks targeted infrastructure (layers 3 and 4 of the OSI Model) by a wide margin, with application layer attacks accounting for just 25 percent. But Imperva’s Rachwald said attack tools for Web applications appear to be a growth area in the underground economy. \"There is something going on when black hats start developing tools,\" he said.\nOne such tool that has gained attention in the past year is the Low Orbit Ion Cannon (LOIC), apparently used by Anonymous in its January 2012 Operation MegaUpload attacks that targeted government and entertainment industry sites.\nBoth network and application layer attacks have traits in common. It is the motive — denial of service — that defines them, not malware. They exploit a network or a server’s finite resources rather than its vulnerabilities, so it is difficult to defend against them by patching or updating software and hardware, although hardening systems can help. Operating systems and applications can be configured to disable services and applications not required for their missions; blacklists can be used to block traffic from known malicious sites; and service screening at edge routers can help to decrease loads from unwanted or improper traffic.\nBut while these steps can help reduce the attack surface, attacks still are possible and can quickly overwhelm resources. And although a denial-of-service attack usually does not damage systems or steal information, neither are the attacking infrastructures affected by the defense; the attackers remain capable of launching another attack as soon as the guard is lowered.\nPREVIOUS: Surviving denial-of-service? You need outside help to keep from going under.\nNEXT: How to mitigate and defend against DOS attacks", "label": 1}
{"text": "Worms, viruses, Trojan horses, and spyware: BEWARE!\nThe National Science Center, or NSC, is now training kids to stay safe from cyber attack malware when they’re surfing the web or using email and cell phones. A new online game called Cyber Swarm Defenders is targeted to 6th-8th grade students and is also appropriate for younger students.\nThe game is part of the NSC’s newest Cyber Ops education outreach program. The NSC is a public-private partnership between the U.S. Army and NSC, Inc., that uses its resources to stimulate and increase science, technology, engineering, and mathematics, known as STEM, proficiency in U.S. students, especially those in grades 4-9.\n“Anything we can do to make the young students of our country understand the cyber threat and get them excited about STEM technologies has a big payoff,” said Ron Ross, chairman of the NSC.\n“Educating students about cyber security threats and how to counteract them is imperative,” said Mike Krieger, the Army deputy chief information officer, who serves as the secretary of the Army’s proponent for the NSC. He also serves as the co-chairperson for the NSC’s Partnership Executive Committee, which provides overall direction and oversight for the NSC.\nCyber Swarm Defenders is deployed through the social networking site, which was built for children ages 13 and under. Kid-safe requirements are built in, including a parental control feature. This tower-defense strategy game integrates cyber security education and “learn to earn” mini-exercises. Students earn points, badges and game coins as they strengthen their defenses to advance through the game levels.\n“Installing the game on a social network site allows us to reach a variety of students and an existing community of users,” said Krieger.\nTo access the game from the NSC’s website and click on the Cyber Swarm banner button. Or, go directly to this site. To play, participants must first register on jabbersmack–which is not accessible on some older versions of browsers.\n“Our additional focus on cyber threats also significantly enhances the value proposition of the NSC Partnership,” Ross said.\nCreated by Congress in 1985, the NSC ‘s outreach programs include online teacher tools, two 18-wheeler Mobile Discovery Center vans, Junior ROTC STEM Outreach activities, and Cyber Ops. In addition to the new game, the Cyber Ops program links to a Malware Comic Book and Malware Mystery game that are also appropriate for older students.\nBy Margaret McBride, CIO/G-6\nDisclaimer: The appearance of hyperlinks does not constitute endorsement by the Department of Defense of this website or the information, products or services contained therein. For other than authorized activities such as military exchanges and Morale, Welfare and Recreation sites, the Department of Defense does not exercise any editorial control over the information you may find at these locations. Such links are provided consistent with the stated purpose of this DoD website.", "label": 1}
{"text": "You never know when malware can sneak up on you.\nNow that you can browse the web and check your e-mails anywhere, at any time, from your smartphone, you have more control over your actions. But acting on rapid mode might make you less attentive to visual details in your search results, e-mails etc. Also, the mobile screen, because of its small size, cannot comprise all the elements you’re used to see on a PC screen. Even though this may seem like simplifying things, it actually makes it more difficult to spot virus activity. And thus, cybercrooks’ mobile security attacks and scams are more successful. Even those initially designed for PC, which you might otherwise easily recognize on the “big screen”.\nThis is the case with drive-by downloads. Cybercrooks have figured a way to adapt them to the mobile environment and now the risks of falling victim to them are significantly higher. More so if you don’t have proper mobile antivirus protection.\nWhat’s the deal with drive-by downloads?\nThe drive-by download technique has been used in computer infections for some time now. It basically refers to downloads of files that you don’t know are taking place – often spyware, a Trojan or some other form of malware.\nHow does it work? – by exploiting vulnerabilities in web browsers, additional browser software or lowered security settings.\nHow can you trigger it? – by visiting a compromised website, viewing an e-mail or by clicking on a misleading pop-up window. In some cases, users who want to download, say a browser add-on they’ve seen on a not-so-reputable website, may end up installing the add-on and a sneaky piece of malware, too.\nDrive-by downloads versus mobile security\nOn smartphones, especially those with little or no mobile antivirus protection, drive-by downloads work pretty much the same way. But there have been cases where the user triggered a drive-by download by clicking on a malicious link in a text message – this being part of the whole “adapting to mobile devices” idea. Here are two scenarios that paint a clearer picture of how drive-by downloads can compromise your mobile security:\n- You browse the web on your smartphone. You go to a webpage and suddenly, a small window, looking like the one that usually appears when someone calls you, pops up on your screen. You click on that window to answer the alleged call, and a file starts downloading to your phone. Without a doubt that’s malware compromising your mobile security. The same could happen with an ad suddenly popping up on your screen.\n- You receive an SMS supposedly from your mobile network operator urging you to click on a link it provides. Once you click on it, you go to a website which exploits your mobile browser and silently plants a Trojan on your smartphone. The malware gives cybercrooks remote access to your device, which, clearly, is a dangerous threat to your mobile security. Such links can also be embedded in phishing e-mails.\nThe most common mobile drive-by downloads are those exploiting mobile browser vulnerabilities. They enable crooks to remotely run commands within the phone’s operating system and change the way it works. It’s similar to rooting or jailbreaking the device – by cybercrooks and without your knowledge! These are the usual steps:\n- 1. You go to a malicious webpage from your smartphone, by clicking on a link in an e-mail/SMS, when browsing.\n- 2. The webpage contains malware that exploits your mobile browser, enabling a connection between the mobile device and a cybercrook.\n- 3. The crook breaches your mobile security by sending commands to gather mobile data such as phone contacts, Skype contacts, login credentials etc., or even tracking your phone location.\nHow to avoid a mobile drive-by download\nWith the increasing number of smartphone users, this technique has become very popular among cybercrooks who want to breach their mobile security – which means, you’re more exposed than ever. What can you do to steer clear from it?\n- 1. If, while browsing the web you get a dubious pop-up screen that prompts you to click on it, don’t. If you do, and the pop-up starts downloading a file – stop it immediately.\n- 2. Be vigilant when browsing the web and pay attention to visual details. Also be suspicious of any unsolicited and/or alarming SMS/e-mail coming from your mobile network operator and even from your bank. If they ask you for personal details or to click on a link – it’s best you contact them to check the validity of the message.\n- 3. Keep your mobile operating system and applications up-to-date.\n- 4. Make sure you have proper mobile antivirus protection on your phone. A mobile antivirus app from a reputable security provider goes a long way in safeguarding your device. BullGuard Mobile Security 10 comes with an antivirus engine that provides real-time protection against malware, and additional mobile security features for overall mobile security.", "label": 1}
{"text": "Storage device manufacturer Plasmon has developed read-only back-up discs that allow companies to selectively destroy data while leaving the rest of the disc's contents intact.\nThe disc, designed to support regulatory compliance requirements, is able to retain a record to confirm that data has been destroyed, so managers can prove that the company has met its compliance requirements.\nClaus Egge, programme director, European storage research at analyst firm IDC, said the discs were an industry first and would be suitable for the pharmaceutical, medical and legal industries, which are required to protect personal data and destroy it after use.\nHe added that the Data Protection Act required, for example, certain call centres to destroy client records after use.\nThe disc is based on Plasmon's UDO (Ultra Density Optical) format. UDO is a phase-change optical storage system, which stores data by physically changing the state of the disc's recording layer between amorphous and crystalline. With Plasmon's media, data is selectively destroyed by changing the entire state of an area occupied by a file into the crystalline state. The supplier calls this \"data shredding\".\nEgge said, \"The UDO-compliant write-once media is an implementation of evolving Worm [write once, read many] technology. This media offers the ability to selectively destroy individual records as retention periods expire. The addition of such a finite yet static data protection capability is an important development.\n\"Enabling data to be retained for the correct length of time will provide data protection and compliance officers with the necessary tools to deal with deletion as well as retention. IDC recommends that this functionality be supported in all major storage applications.\"\nThe Plasmon disc will have a capacity of 30Gbytes, which is similar to the write-once and rewritable versions of UDO discs. Pricing will be somewhere between the two, at about £35 a disc.\nWhat is UDO?\nUDO (Ultra Density Optical) is an optical media storage disc format based on blue-laser technology similar to that used in the HD-DVD and Blu-Ray formats. UDO discs are encased in cartridges similar to Magneto Optical discs. This means IT managers can mix and match Magneto Optical and UDO drives in the same library.", "label": 1}
{"text": "For the first time, scientists at IBM Research have demonstrated that a relatively new memory technology, known as phase-change memory (PCM), can reliably store multiple data bits per cell over extended periods of time. This significant improvement advances the development of low-cost, faster and more durable memory applications for consumer devices, including mobile phones and cloud storage, as well as high-performance applications, such as enterprise data storage.\nWith a combination of speed, endurance, non-volatility and density, PCM can enable a paradigm shift for enterprise IT and storage systems within the next five years. Scientists have long been searching for a universal, non-volatile memory technology with far superior performance than flash - today's most ubiquitous non-volatile memory technology. The benefits of such a memory technology would allow computers and servers to boot instantaneously and significantly enhance the overall performance of IT systems. A promising contender is PCM that can write and retrieve data 100 times faster than flash, enable high storage capacities and not lose data when the power is turned off. Unlike flash, PCM is also very durable and can endure at least 10 million write cycles, compared to current enterprise-class flash at 30,000 cycles or consumer-class flash at 3,000 cycles. While 3,000 cycles will out live many consumer devices, 30,000 cycles are orders of magnitude too low to be suitable for enterprise applications (see chart for comparisons).\n\"As organizations and consumers increasingly embrace cloud-computing models and services, whereby most of the data is stored and processed in the cloud, ever more powerful and efficient, yet affordable storage technologies are needed,\" states Dr. Haris Pozidis, Manager of Memory and Probe Technologies at IBM Research - Zurich. \"By demonstrating a multi-bit phase-change memory technology which achieves for the first time reliability levels akin to those required for enterprise applications, we made a big step towards enabling practical memory devices based on multi-bit PCM.\"\nMulti-level Phase Change Memory Breakthrough\nTo achieve this breakthrough demonstration, IBM scientists in Zurich used advanced modulation coding techniques to mitigate the problem of short-term drift in multi-bit PCM, which causes the stored resistance levels to shift over time, which in turn creates read errors. Up to now, reliable retention of data has only been shown for single bit-per-cell PCM, whereas no such results on multi-bit PCM have been reported.\nPCM leverages the resistance change that occurs in the material - an alloy of various elements - when it changes its phase from crystalline - featuring low resistance - to amorphous - featuring high resistance - to store data bits. In a PCM cell, where a phase-change material is deposited between a top and a bottom electrode, phase change can controllably be induced by applying voltage or current pulses of different strengths. These heat up the material and when distinct temperature thresholds are reached cause the material to change from crystalline to amorphous or vice versa.\nIn addition, depending on the voltage, more or less material between the electrodes will undergo a phase change, which directly affects the cell's resistance. Scientists exploit that aspect to store not only one bit, but multiple bits per cell. In the present work, IBM scientists used four distinct resistance levels to store the bit combinations \"00\", \"01\" 10\" and \"11\".\nTo achieve the demonstrated reliability, crucial technical advancements in the \"read\" and \"write\" process were necessary. The scientists implemented an iterative \"write\" process to overcome deviations in the resistance due to inherent variability in the memory cells and the phase-change materials: \"We apply a voltage pulse based on the deviation from the desired level and then measure the resistance. If the desired level of resistance is not achieved, we apply another voltage pulse and measure again - until we achieve the exact level,\" explains Pozidis.\nDespite using the iterative process, the scientists achieved a worst-case write latency of about 10 microseconds, which represents a 100× performance increase over even the most advanced Flash memory on the market today.\nFor demonstrating reliable read-out of data bits, the scientists needed to tackle the problem of resistance drift. Because of structural relaxation of the atoms in the amorphous state, the resistance increases over time after the phase change, eventually causing errors in the read-out. To overcome that issue, the IBM scientists applied an advanced modulation coding technique that is inherently drift-tolerant. The modulation coding technique is based on the fact that, on average, the relative order of programmed cells with different resistance levels does not change due to drift.\nUsing that technique, the IBM scientists were able to mitigate drift and demonstrate long- term retention of bits stored in a subarray of 200,000 cells of their PCM test chip, fabricated in 90-nanometer CMOS technology. The PCM test chip was designed and fabricated by scientists and engineers located in Burlington, Vermont; Yorktown Heights, New York and in Zurich. This retention experiment has been under way for more than five months, indicating that multi-bit PCM can achieve a level of reliability that is suitable for practical applications.\nThe PCM research project at IBM Research - Zurich will continue to be studied at the recently opened Binnig and Rohrer Nanotechnology Center. The center, which is jointly operated by IBM and ETH Zurich as part of a strategic partnership in nanosciences, offers a cutting-edge infrastructure, including a large cleanroom for micro- and nanofabrication as well as six \"noise-free\" labs, especially shielded laboratories for highly sensitive experiments.\nFurther Reading: Read and find more RAM press releases at our RAM PR index page.\nDo you get our RSS feed? Get It!", "label": 1}
{"text": "What is Spam?\nSpam is unsolicited email on the Internet. It is a form of bulk mail from the sender’s point-of-view and often sent to a list gathered from subscribers to a discussion group or obtained by companies that specialize in creating email distribution lists. In much the same way that retailers and businesses use postal mailing lists to send potential customers catalogs and other information, an increasing number are using e-mail messages as a direct marketing tool. In general, it’s not considered good internet etiquette to send spam. It’s generally equivalent to unsolicited phone marketing calls except that the user pays for part of the message since everyone shares the cost of maintaining the Internet.\nEmail spoofing is the practice of changing from field of an email so that it looks like the email came from someone or somewhere else. Email spamming may be combined with email spoofing, so that it is very difficult to determine the actual originating email address of the sender. Some email-distributed viruses use spoofing, such the Klez or Sobig virus, take a random name from somewhere on the infected person’s computer and mail themselves out as if they were from that randomly chosen address. Recipients of these viruses are therefore misled as to the address from which they were sent, and may end up complaining to, or alerting the wrong person. As a result, users of uninfected computers may be wrongly informed that they have, and have been distributing a virus.\nEmail phishing is the act of sending an email to a user falsely claiming to be an established legitimate business in an attempt to scam the user into providing private information. The email usually directs the user to visit a website where they are asked to update personal information, such as, passwords and credit card, social security, and/or bank account numbers. This website is bogus and set up only to steal the user’s information. If you feel that you have received a phishing email, you should forward the email to the ITS Helpdesk at firstname.lastname@example.org .\nSome apparently unsolicited email is, in fact, email people agreed to receive when they registered with a site and a box was checked agreeing to receive postings about particular products or interests. This is known as both opt-in email and permission-based email.\nTips to Avoid Getting Spam:\n- Never post your real email address on a forum or bulletin board. Spammers use special programs which harvest these and use them to build spam lists. Once your email address has been caught in this way, you’ll never get off the spam lists.\n- Set up multiple email addresses. If you regularly sign up to a lot of web sites, which may sell email addresses as a source of revenue, consider having one email address just for this purpose, while keeping your other – real – email address private to friends and family.\n- When you register with an internet site, make sure you do not give them the right to sell your email address to spammers. (Watch for little checkboxes and make sure to remove any which are checked by default).\n- Use the email filters to reject spam with obvious catchphrases in it (debt consolidation, porn, sex, viagra, hot girls etc)\nDealing with Spam:\nIf you suspect a message is junk mail, treat it as such by deleting it — even without opening it. Common clues include information in the subject headings and unknown senders. Do take action to stop spam. Users can setup rules to filter the messages to stop spam messages and block spam sites.\nAll incoming email is now being filtered by Proofpoint Endpoint Security. Users will no longer need to setup a filter to move messages tagged as spam. For more inforamtion on Proofpoint and how it works please visit http://go.umflint.edu/proofpoint.", "label": 1}
{"text": "Available Data Indicate Growth in Prevalence and Cost\nGAO-02-424T, Feb 14, 2002\n- Accessible Text:\nIdentity theft involves \"stealing\" another person's personal identifying information, such as their Social Security Number (SSN), date of birth, or mother's maiden name, and using it to fraudulently establish credit, run up debt, or take over existing financial accounts. The prevalence and cost of identity theft seem to be increasing. Recently introduced bills seek to prevent identity theft and enforce laws prohibiting identity theft. Since May 1998, various actions--particularly passage of federal and state statutes--have been taken to address identity theft. Precise, statistical measurement of identity theft trends is difficult for several reasons. Federal law enforcement agencies lack information systems to track identity theft cases. Also, identity theft almost always accompanies white-collar or financial crimes, such as bank fraud, credit card or access device fraud, or the use of counterfeit financial instruments. Data sources, such as consumer complaints and hotline allegations, can be used as proxies for gauging the prevalence of identity theft. Law enforcement investigations and prosecutions of identity theft-related crimes, such as bank and credit card fraud, also provide data.", "label": 1}
{"text": "Mobile Clinic: How do you make mobile data secure?\nKeeping it safe\nEd Moore, OpenWeb Product Manager, Openwave Europe\nMobile data security is a many-headed Hydra; with a variety of potential issues to be addressed under the single banner. Mobile also covers a variety of potential access devices, from laptops down to phones and even internet cafes, all of which have to be addressed.\nSecuring data on laptops and phones\nAny device with more than just a contact list and browser should have security measures mandated. For non-sensitive work a password and rotation policy is sufficient, but for personal data records or sensitive business data then data encryption technology must be used as well.\nTracking services should also be considered; these will trace the device after being stolen so that remote deletion can be triggered or the unit retrieved.\nFinally, if a mobile is being used for collecting or generating primary data (as opposed to copying data from a centralised system) synchronisation/centralised backup software can be used too. This should minimise the possibility that valuable data can be lost through theft or accident.\nProtection against attack\nViruses, Trojans and Phishing attacks can all attack mobile devices and laptops or smartphones can be especially sensitive to these, as they can be taken outside of your corporate network, which may provide a degree of security at the network edge.\nAll devices should have anti-virus protection and ideally be configured to use a corporate (but external) security proxy for general internet access. This may not be possible in all cases, but will help give the most complete protection. The problem can be resolved in an alternative manner; by specifying standard phones for data access; with a closed platform it is much more difficult to suffer a meaningful attack.\nSecuring corporate communications\nAlways encrypt the traffic to a corporate network, SSL or IPSec encryption is common to all mobiles these days and there's no excuse not to make this a policy. Encryption can be used at a single application level or to secure the whole data pipe, but any application with automated log-on needs to be watched particularly carefully. Apply passwords and ensure these are used when establishing a connection, otherwise anyone can quickly gain access. A two-factor authentication service may be needed for added protection.\nStealing corporate secrets\nThere's always the potential for a staff member to use a mobile device to transport company secrets away from the office. Laptops have enormous storage capacity these days and usually CD burners and Wi-Fi connections too, to compound the problem. Logging and tracking software can help provide some security, but in reality this is just covering up the problem. Concentrate HR on keeping the staff happy instead!\nSimplify the problem; use standard handsets if at all possible with browser access to corporate applications. Don't store locally and don't enable viruses.\nStandardise wherever possible; same handsets, laptops, security software, and encryption technique. Proliferation always lessens effectiveness.\nConsider all angles; you'll end up with a more comprehensive policy because of it. ®", "label": 1}
{"text": "Malware removal is a tricky business. It often requires intimate knowledge of the inner workings of a particular piece of malcode: How it got on the computer in the first place; its attack mode; what it changes; where it resides. Malware removal is certainly not for the faint-of-heart.\nSince malware is a term that describes a broad variety of unwanted software, there are a multitude details to work out before removal can commence. Each virus, spyware or rootkit can have a completely different effect on a given computer system making removal that much more complicated. For example, adware might only manifest itself in Internet Explorer (IE) browser settings; a virus might infect an instant messaging (IM) application and send IMs to the buddy list; while a rootkit can hide itself at a computer's kernel level to avoid detection by the operating system (OS), applications and the user.\nTherefore, the first step in the malware removal process is identification and classification.\nAside from the basic classification terms, like viruses, worms, spyware, etc., you can classify malware on the basis of what's pertinent to administrators and users alike -- without needing to understand the precise technical definition of each term. For example, attack vector. How does a piece of malcode spread? Through email? Over IM? Does it disperse itself?\nWhen you understand how a piece of malware infected your computers in the first place, not only will that knowledge help you identify the particular malware strain, but it will also help prevent more attacks.\nAnother way to classify malware is by the flaw or vulnerability it exploits. Does the malware affect a particular application like Word or PowerPoint? Does it only affect a particular version of software, like an IE 6 VBscript flaw? These vulnerabilities affect client-level systems, but what if the malware affects a more critical server system like 2003's SQL slammer worm?\nThe potential severity of malware is another way to classify it. Can it be easily dispersed through the network? Will it affect server-level systems? Will it be confined to only desktop systems running unpatched Office 2003 applications? Antivirus and antispyware companies often classify threats based on the extent of the damage caused by the malware to a single system and the prevalence of the flaw or vulnerability across many systems.\nYou can further classify malware by the actions it takes once it has infected a system. What files does it change? Does it change registry settings? Does it implant itself in the OS startup file? Does it initiate Windows processes? If it does, that is often the key to finding out if you have a virus. A tool like Sysinternals Process Explorer can help identify processes that should not be running on a clean Windows computer.\nMalware removal tools\nA large number of tools out there are great at detecting malware -- and usually those same tools can prevent it from infecting a computer in the first place. But far fewer tools can completely remove an imbedded piece of malcode.\nFor removal, you often need to rely on tools that root out malware by scanning your system for anomalies like foreign processes, altered registry settings and corrupt files. Once the tool finds and identifies a piece of malware, there are usually manual instructions available for wiping its presence from a computer -- often that information comes from security companies or even blogs, user groups or independent security professionals.\nOf course, some malware is so insidious that it cannot be completely removed from an infected system. In those cases, the only recourse is to reinstall the OS. And that makes the subject of chapter three of this guide, prevention, that much more important.\nThis was first published in April 2007", "label": 1}
{"text": "As the popularity of these social sites grows, so do the risks of using them. Hackers, spammers, virus writers, identity thieves, and other criminals follow the traffic.\nRead these tips to help protect yourself when you use social networks.\n- Use caution when you click links that you receive in messages from your friends on your social website. Treat links in messages on these sites as you would links in e-mail messages.\n- Know what you’ve posted about yourself. A common way that hackers break into financial or other accounts is by clicking the “Forgot your password?” link on the account login page. To break into your account, they search for the answers to your security questions, such as your birthday, hometown, high school class, father’s middle name, on your social networking site. If the site allows, make up your own password questions, and don’t draw them from material anyone could find with a quick search.\n- Don’t trust that a message really is from whom it says it’s from. Hackers can break into accounts and send messages that look like they’re from your friends, but aren’t. If you suspect that a message is fraudulent, use an alternate method to contact your friend to find out. This includes invitations to join new social networks.\n- To avoid giving away e-mail addresses of your friends, do not allow social networking services to scan your e-mail address book. When you join a new social network, you might receive an offer to enter your e-mail address and password to find out if your contacts are on the network. The site might use this information to send e-mail messages to everyone in your contact list or even everyone you’ve ever sent an e-mail message to with that e-mail address. Social networking sites should explain that they’re going to do this, but some do not.\n- Type the address of your social networking site directly into your browser or use your personal bookmarks. If you click a link to your site through e-mail or another website, you might be entering your account name and password into a fake site where your personal information could be stolen.\n- Be selective about who you accept as a friend on a social network. Identity thieves might create fake profiles in order to get information from you.\n- Assume that everything you put on a social networking site is permanent. Even if you can delete your account, anyone on the Internet can easily print photos or text or save images and videos to a computer.\n- Be careful about installing extras on your site. Many social networking sites allow you to download third-party applications that let you do more with your personal page. Criminals sometimes use these applications to steal your personal information. To download and use third-party applications safely, take the same safety precautions that you take with any other program or file you download from the Web.\n- Think twice before you use social networking sites at work.\n- Talk to your kids about social networking.\nFounded in 1975, Microsoft (Nasdaq “MSFT”) is the worldwide leader in software, services and solutions that help people and businesses realize their full potential.", "label": 1}
{"text": "(DataBase Management System) Software that controls the organization, storage, retrieval, security and integrity of data in a database. It accepts requests from the application and instructs the operating system to transfer the appropriate data. The major DBMS vendors are Oracle, IBM, Microsoft and Sybase (see Oracle database, DB2, SQL Server and ASE). MySQL is a very popular open source product (see MySQL).|\nDBMSs may work with traditional programming languages (COBOL, C, etc.) or they may include their own programming language for application development.\nDBMSs let information systems be changed more easily as the organization's requirements change. New categories of data can be added to the database without disruption to the existing system. Adding a field to a record does not require changing any of the programs that do not use the data in that new field.\nMajor Features of a DBMS\nThe DBMS can prevent unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or a subset of it known as a \"subschema.\" For example, in an employee database, some users may be able to view salaries while others may view only work history and medical data.\nThe DBMS can ensure that no more than one user can update the same record at the same time. It can keep duplicate records out of the database; for example, no two customers with the same customer number can be entered.\nA DBMS provides a query language and report writer that lets users interactively interrogate the database. These essential components give users access to all management information as needed. See query language and report writer.\nInteractive Data Entry and Updating\nA DBMS typically provides a way to interactively enter and edit data, allowing you to manage your own files and databases. However, interactive operation does not leave an audit trail and does not provide the controls necessary in a large organization. These controls must be programmed into the data entry and update programs of the application.\nThis is a common misconception about using a desktop computer DBMS. Creating lists of data for a user's own record keeping is one thing. However, although complete information systems can be developed with such software, it cannot be done without understanding how transactions and files relate to each other in a business system (see Database Design below). In addition, some type of programming is required, whether at a graphical drag and drop level or by using traditional languages.\nWhen a DBMS is used, the details of the data structure are not stated in each application program. The program asks the DBMS for data by field name; for example, a coded equivalent of \"give me customer name and balance due\" would be sent to the DBMS. Without a DBMS, the programmer must reserve space for the full structure of the record in the program. Any change in data structure requires changing all application programs.\nA business information system is made up of subjects (customers, employees, vendors, etc.) and activities (orders, payments, purchases, etc.). Database design is the process of organizing this data into related record types. The DBMS that is chosen is the one that can support the organization's data structure while efficiently processing the transaction volume.\nOrganizations may use one kind of DBMS for daily transaction processing and then move the detail to another DBMS better suited for random inquiries and analysis.\nOverall systems design decisions are performed by data administrators and systems analysts. Detailed database design is performed by database administrators.\nHierarchical, Network & Relational\nInformation systems are made up of related files: customers and orders, vendors and purchases, etc. A key DBMS feature is its ability to manage these relationships.\nHierarchical databases link records like an organization chart. A record type can be owned by only one owner. In the following example, orders are owned by only one customer. Hierarchical structures were widely used with early mainframe systems; however, they are often restrictive in linking real-world structures.\nIn network databases, a record type can have multiple owners. In the example below, orders are owned by both customers and products, reflecting their natural relationship in business.\nRelational databases do not link records together physically, but the design of the records must provide a common field, such as account number, to allow for matching. Often, the fields used for matching are indexed in order to speed up the process.\nIn the following example, customers, orders and products are linked by comparing data fields and/or indexes when information from more than one record type is needed. This method is more flexible for ad hoc inquiries. Many hierarchical and network DBMSs also provide this capability.\nCertain information systems may have complex data structures not easily modeled by traditional data structures. An \"object database\" can be employed when hierarchical, network and relational structures are too restrictive. Object databases can easily handle many-to-many relationships.\nAll DBMSs provide some data validation; for example, they can reject invalid dates or alphabetic data entered into money fields. But most validation is left up to the application programs.\nIntelligent databases provide more validation; for example, table lookups can reject bad spelling or coding of items. Common algorithms can also be used such as one that computes sales tax for an order based on zip code.\nWhen validation is left up to each application program, one program could allow an item to be entered while another program rejects it. Data integrity is better served when data validation is done in only one place. Mainframe DBMSs were the first to become intelligent, and all the others followed suit.\nThis diagram shows the interaction between the DBMS with other system and application software running in memory.", "label": 1}
{"text": "Cloud Computing: Implementation, Management, and Security provides an understanding of what cloud computing really means, explores how disruptive it may become in the future, and examines its advantages and disadvantages. It gives business executives the knowledge necessary to make informed, educated decisions regarding cloud initiatives.\nThe authors first discuss the evolution of computing from a historical perspective, focusing primarily on advances that led to the development of cloud computing. They then survey some of the critical components that are necessary to make the cloud computing paradigm feasible. They also present various standards based on the use and implementation issues surrounding cloud computing and describe the infrastructure management that is maintained by cloud computing service providers. After addressing significant legal and philosophical issues, the book concludes with a hard look at successful cloud computing vendors.\nHelping to overcome the lack of understanding currently preventing even faster adoption of cloud computing, this book arms readers with guidance essential to make smart, strategic decisions on cloud initiatives.\nEvolution of Cloud Computing\nCommunications (HTTP, XMPP)\nData (XML, JSON)\nOffline (HTML 5)\nSecurity (OAuth, OpenID, TLS)\nSolution Stacks (LAMP)\nWeb Services (REST)\nPlanning for Capacity\nPlanning for Availability\nPlanning for Security\nArchitecting Marketable Solutions for Enterprise\nConsumer Specific Issues to Plan for\nCloud Vendors to Watch\nFuture Directions of Cloud Computing\nWho Is Leading the Pack?\nWhat Is at the Forefront of Cloud Computing?\nWhat Challenges Must Be Overcome with Adoption of Cloud Computing?\nHow Will Cloud Computing Blend with New Wireless Technologies?\nDay-to-Day Management Issues Running a Cloud Environment\nThree Key Elements: Ping, Power, and Pipe\nStructure of an Always-on Environment with Virtualization\nJohn W. Rittinghouse is Chief Software Architect and Co-founder of Hypersecurity LLC in Houston, Texas. He holds a Ph.D. in Psychology with emphasis in Natural Language Processing.\nJames F. Ransome is a Senior Director and the Chief Security Officer for the Cisco Collaborative Software Group (WebEx). He holds a Ph.D. in Information Systems specializing in Information Security.\n… This book is a compact and readable primer on the vocabulary and concepts behind the cloud computing phenomenon. … For those readers unfamiliar with basic virtualization software, the authors provide a brief tutorial using the popular (and free) VirtualBox product. … the book can serve as a brief but adequate introduction to cloud computing for those new to the topic …\n—Computing Reviews, November 2009", "label": 1}
{"text": "ecurity is a hot topic these days. It is as if developers and system designers are fighting a never ending war against those who desire to damage hardware, compromise system availability, steal data, and tarnish hard-earned client trust. And as if malicious threats weren't enough, we must also protect ourselves from unintentional\ndamages inflicted by accidental removal or modification of data.\nThe scope of this effort ranges from entire enterprise networks and the Internet itself down to a specific line of code that may handle the formatting of a string. For the benefit of this article, the entirety of this scope will be described as a \"system.\"\nSome tactics can be employed to secure a system without much analysis, such as implementing a firewall on the network, implementing logins to restrict system access, employing role-based security to control which aspects of the system a user can access, and encrypting sensitive data such as social security numbers. The question is: How can one be objectively confident when making the claim that their system is secure? The methodology commonly referred to as \"threat modeling\" organizes the review and analysis process to ensure the security of a system.\nThe sample system used in this article to illustrate the aspects of threat modeling is a simplified version of a web application. The public uses this system to browse a library of music CDs and request those items for short term lending, much like one that might be utilized for a public library.\nDefining Threat Modeling\nThreat modeling is a formal process that identifies assets and their security vulnerabilities, and analyzes and documents them. The output from this process is not a static document, but one that should be continually revised as new elements are introduced to a system or existing elements are modified.\nThere are several approaches to the threat modeling process. Some approaches may be better for large IT shops or enterprise-wide evaluation, while others are more suited for very small development shops or very limited-use systems. You should evaluate these approaches and modify the threat modeling methodology to the specific needs of your particular environment. This article presents the threat modeling methodology that I employ, which was originally inspired by the methodology presented by the Microsoft Application Consulting and Engineering Team, but contains some variations pulled from other sources.\nIt is said that a picture is worth a thousand words. It is also true that a well-crafted quote can encompass volumes of documents and articles. In the case of threat modeling, Sun Tzu, the sixth century B.C. author of \"The Art of War,\" best encompasses the threat modeling effort in the following quote: \"\nif you know your enemies and know yourself, you will fight without danger in battles\nAnother good piece of advice is to start early. Building threat modeling into a system during the development process is optimal, because the data entry and output points are defined during that stage, giving you the opportunity to evaluate the proposed foundation for potential vulnerabilities before any construction begins. Unfortunately, the optimal scenario is relatively rare. Threat modeling of an existing system and creating mitigations to identified vulnerabilities post-implementation offers a different set of challenges. Still, a late threat model is much better than no threat model at all.\nAssembling a Threat Modeling Team\nThe threat modeling process should have a designated person to facilitate the threat modeling process and assembling the documentation. System evaluation is not a one-person job; it typically involves many participants, such as:\n- System Architects and Developers: because they are the most intimately familiar with the structure and coding of the system.\n- Network Administrators: because they are most familiar with the environment in which the system operates.\n- End Users: because they have a grasp of how the system gets used on a daily basis.\n- Testers: to execute the findings and evaluate how any mitigation of identified vulnerabilities affects system operation.\n- Decision Makers (Managers): because they are the ones who will determine how the system is intended to be used as well as which vulnerabilities should be mitigated based upon their risk appetite.\nIn some development shops there may be persons who take on multiple roles; but the inclusion of other viewpoints, especially during the threat analysis portion of the process, is essential to identifying a system's vulnerabilities.\nHere are the steps that must be performed to fully understand a system:\n- Define the assets of the system\n- Define user entities\n- Define trust levels and boundaries\n- Identify input/output points of the system\n- Develop use case scenarios\n|A Note on Documentation: It is critical to document the results. For easy reference, you should document each element with the following key pieces of information:\nNote that this documentation contains important information regarding the system and—in the wrong hands—is itself a security vulnerability; therefore, keep it in a safe and restricted location in both electronic (soft copy) as well as printed (hard copy) format.\n- ID: This should be a unique identifier which can be referenced in other textural and graphical documentation.\n- Description: This will provide the details regarding the step in question.\n- Step Specific Details: This provides information that is specific to the step being evaluated. For example: Evaluating an asset should include the details regarding its consideration.", "label": 1}
{"text": "It started with a phone anchored to your car or your briefcase-\"walking-around\" communications that freed you from searching for a pay phone in order to talk outdoors.\nNow telecommunications has morphed into movies on your phone, banking on the fly, an office wherever you go. Communication isn't just about people talking to people. It's about things talking to each other.\nOn a smarter planet, almost anything can become digitally aware, instrumented and interconnected. We have the connections, processors, analytics and capabilities powerful enough for trillions of devices to talk to each other and improve the way the world works. Smart houses can be programmed remotely. Smart cars talk to home base. Smart phones can practically replace your wallet. Smart highways can regulate traffic flows.\nA typical U.S. 21-year-old has exchanged 250,000 e-mails, instant messages and phone text messages.\nA busy signal is not an option\nBut the deluge of data from the trillions of smart objects is creating an insatiable demand for bandwidth. The infrastructure has had to grow up and keep up, sometimes at great struggle when you consider that:\nThe deluge of data from the trillions of smart objects is creating an insatiable demand for bandwidth.\nThe growth in bandwidth means greater potential for online identity theft, stolen intellectual property and malicious attacks such as spam, which by many estimates accounts for about 80% of transmitted e-mail.\nRealising the potential of smarter telecommunications will require the infusion of new technologies and models into our systems to make it easier for devices to transmit and interpret data, provide more secure connections, and protect identities.\nTechnology to make our lives simpler\nIBM Research and Development Director and Chief Technologist, Glenn Wightwick, examines how the true value of mobile technology is in its potential to simplify our increasingly complex lives.\nHear Sir Paul Callaghan, New Zealander of the Year and the founding Director of the MacDiarmid Institute for Advanced Materials and Nanotechnology at Victoria University of Wellington, talk about ways to encourage the growth of technology, foster innovation in our universities and the role that private wealth can play in this field.\nMore than just talk\nA fisherman in India can use a mobile phone as he approaches the dock to check current prices across multiple marketplaces and get the best price for his catch, boosting his income by nearly 50%.\nA children's hospital in Australia reduces stress and confusion in the emergency room by replacing a loud overhead paging system with a hands-free, wireless voice network. And two college students in different cities can use their mobile phones to log onto Facebook and organise a party with a group of friends for their upcoming holiday break.\nDid you know?\nAT&T's ancestor, The Bell Company, proposed a wireless phone in 1915 but shelved the idea in favor of its wired service.\n1998 was a banner year for mobile commerce: The first purchase by cell phone was made (to a Coca-Cola machine), and a ring tone was the first downloaded content sale.\nAlmost 4 billion subscribers of cell phones were expected by 2008, representing 21% of the world's adult and child population.\nCreating smarter communications systems to handle increasingly demanding applications takes leading-edge information technology, forward-thinking business and industry expertise, and innovative research and development. IBM has joined forces with numerous telecommunications clients to make business smarter:\nReach out and touch someone-online\nPeople used to keep in touch with a call. Now they are using social networking sites such as Facebook and Twitter-dramatically cutting into telcos'share of communications services. But there are opportunities. Read the new report (PDF,324KB) The Changing Face of Communications.\nWe're here to help", "label": 1}
{"text": "Why is this? \"Pattern recognition\" is a frequent A.I. refrain, but computers can't learn to spot patterns they've never seen. The high-value targets in big data are invariably human: highly adaptive adversaries such as terrorists and cybercriminals whose ingenuity frustrates even the most advanced algorithms.\nYet even the nimblest fugitives leave clues, even patterns -- they're just buried in an expanding universe of data, a challenge that intensifies as we seek still more data, hoping it will yield more insight.\nAdaptive adversaries require adaptive responses, and this begins with asking questions rooted in human intuition. While technology can certainly be a force multiplier for good or evil, it's difficult to imagine a pure A.I. approach reverse-engineering the machinations of a terrorist mastermind.\nWhen U.S. intelligence tracked down Osama bin Laden, it was a function of brilliant, resourceful people asking questions and testing hypotheses using a variety of technologies.\nCybercriminals, as explored in my first TED talk, tend to target the allegedly weakest links in the network: people. Yet how weak is something that can learn in ways even the most robust automated systems can't?\nCyber security might always be an uphill, defensive struggle as techniques and technologies raise the stakes on both sides. Remember, though, that cyberwarfare is ultimately a human endeavor. Bot-nets, scripts and other automated tools play key roles, but they don't exist in a vacuum. This cuts both ways: Sooner or later, everyone makes mistakes, even evil genius types. That said, the enemy may well be two amateurs with a few weak laptops.\nAspiring good guys must be absolutely relentless in refining the intersection of brainpower and computing power, each of which is vulnerable in isolation.\nSometimes, the right combination of humans and technology can reshape the data landscape itself. In the aftermath of Superstorm Sandy, my company partnered with veterans' organization Team Rubicon to coordinate relief efforts in the Rockaways. It began with identifying the hardest-hit areas and greatest needs.\nSoon, as help poured in, the focus shifted to tracking projects, allocating manpower, and coordinating more than 10,000 volunteers in real time. Through rapid iteration, a group of determined people using low-friction technology had created a vast, self-regulating system. Each discrete data point was simple enough -- the status of a project, levels of need, locations of assets -- but in aggregate, the effect was transformative.\nWhile experience teaches that each approach has its caveats, we have every reason to be excited about the possibilities of human-computer symbiosis. Almost 50 years since the identification of Moore's Law, and 10 years since the human genome was first sequenced, humans and machines are beginning a new arc of re-imagining and discovery -- together.", "label": 1}
{"text": "Mental exhaustion from making repeated decisions can lead humans to avoid choices that require additional thinking, which often involves maintaining the status quo. This tendency may result in security and risk choices being influenced by extraneous variables that should be irrelevant to the decision.\nParole Hearings and Meals\nIn a paper titled Extraneous Factors in Judicial Decisions, the researchers found that judges were more likely to grant parole when the hearing was held shortly after a meal. More specifically,\n“The likelihood of a favorable ruling is greater at the very beginning of the work day or after a food break than later in the sequence of cases.”\nThe researchers concluded that “when judges make repeated rulings, they show an increased tendency to rule in favor of the status quo.” Though the behavior could be the result of lower blood glucose levels, researchers attributed the tendency primarily to mental depletion. A brain tired of making choices might shun additional workload by simply maintaining the status quo—which meant denying parole requests after hearing a certain number of cases.\nMaking Decisions Is Tiring\nAn earlier study titled Choice Fatigue: The Effect of Making Previous Choices on Decision Making explored the extent to which humans tire of making decisions. The researchers concluded that “decision outcomes are dependant on the number of previous decisions made.” More specifically,\n“Making more decisions prior to a particular decision increases the likelihood of abstention from the decision as well as the reliance on heuristics (such as choosing the status-quo) in decision-making.”\nThe researchers coined the term choice fatigue to describe the effects of mental exertion experienced after making repeated choices.\nPotential Information Security Implications\nInformation security professionals make choices on regular basis. These include:\n- Is the severity of the vulnerability too low to justify patching it?\n- Is the alert issued by an intrusion detection system a false positive?\n- Should a particular service be disabled when locking down a server?\n- Is a 14-character password sufficiently long for the situation?\n- Is the security policy document sufficiently descriptive?\nAfter numerous risk-related choices during the day, choice fatigue may lead to easier making decisions that eliminate the need for further mental processing, such as deeming the vulnerability irrelevant or labeling an alert a false positive. The individuals most likely to be affected by this may be those in operational roles that demand continued oversight of security events. Forensics specialists sifting through large amounts of data might also be affected by choice fatigue.\nSo, don’t let choice fatigue get you. Take a break now :-)\nFor more thoughts along these lines, see The Reason For All Information Security Woes… Sleep Deprivation.", "label": 1}
{"text": "Digital ants protect computer networks\nAs the nation’s electrical power grid becomes more interconnected through the Internet — from the nuclear power plant in California to transmission lines in Texas to the microwave in your kitchen — the chances of cyber attacks increase as well.\nProfessor of Computer Science Errin Fulp is training an army of “digital ants” to turn loose into the power grid to seek out computer viruses trying to wreak havoc on the system.\nIf the approach proves successful in safeguarding the power grid, it could have wide-ranging applications on protecting anything connected to SCADA (Supervisory Control and Data Acquisition) networks, computer systems that control everything from water and sewer management systems to mass transit systems to manufacturing systems.\nMore news about digital ants:\nFrom TG Daily: Digital ants check networks for viruses\nFrom Tech2: Virus protection takes inspiration from ants\nFrom InfoSecurity: Can digital ants protect computer networks?\nFrom Gather Technology: Researchers hope to use digital ant antivirus to protect the grid\nFrom International Business Times: Researchers working on digital ants to flush out virus in computer networks\nFulp is working this summer with scientists at Pacific Northwest National Laboratory (PNNL) in Richland, Wash., on the next steps in the digital ants technology, developed by PNNL and Wake Forest over the last several years. The approach is so promising that it was named one of the “ten technologies that have the power to change our lives,” by Scientific American magazine last year.\nThe power grid is probably more vulnerable to cyber attacks than security experts would like to admit, said Fulp, an expert in security and computer networks. As the grid becomes more and more interconnected, it offers hackers more points to enter the system; for instance, inserting a virus or computer worm into a low security site, such as in your home’s smart grid, to gain access to more secure systems up the line.\n“When that network connects to a power source, which connects to the smart grid, you have a jumping off point” for computer viruses, he said. “A cyber attack can have a real physical result of shutting off power to a city or a nuclear power plant.”\nThe digital ants technology could transform cyber security because it adapts rapidly to changing threats, said Fulp, who has received nearly $250,0000 in grants from PNNL/Battelle Memorial Institute for his ongoing research.\nUnlike traditional security approaches, which are static, digital ants wander through computer networks looking for threats such as computer worms, self-replicating programs designed to steal information or facilitate unauthorized use of computers. When a digital ant detects a threat, it summons an army of ants to converge at that location, drawing the attention of human operators to investigate.\n“The idea is to deploy thousands of different types of digital ants, each looking for evidence of a threat,” Fulp said. “As they move about the network, they leave digital trails modeled after the scent trails ants in nature use to guide other ants. Each time a digital ant identifies some evidence, it is programmed to leave behind a stronger scent. Stronger scent trails attract more ants, producing the swarm that marks a potential computer infection.”\nThe concept has proven successful in testing on a small scale, but will it still work when it’s scaled up to protect something as large and complex as the nation’s power grid? Fulp and two of his students — computer science graduate students Michael Crouse and Jacob White — are working this summer with scientists at PNNL and from the University of California at Davis to answer that question. But even using PNNL’s vast computer platforms, they can only rely on computer simulations to predict the ants’ “behavior” up to a point.\nThat’s where Kenneth Berenhaut, an associate professor of mathematics and Z. Smith Reynolds Faculty Fellow, comes in. Berenhaut — an expert in mathematical modeling and simulation — and graduate student Ross Hilton, will use modeling to help determine what will happen as the ants move about the smart grid from the hot water heater in your house to the electrical substation to the power plant.\nAmong the questions to be answered: How do the ants migrate across different computer platforms and systems operating at different speeds? How many ants should you have patrolling a system? How long do they live? How do the ants scale up to identify a threat and then ramp back down?\n“In nature, we know that ants defend against threats very successfully,” Fulp said. “They can ramp up their defense rapidly, and then resume routine behavior quickly after an intruder has been stopped. We’re trying to achieve that same framework in a computer system.”\nPNNL, a Department of Energy laboratory, conducts cutting-edge research in cyber security. Glenn Fink, a senior research scientist at PNNL, first came up with the idea of copying ant behavior for computer security. He was familiar with Fulp’s work developing faster computer scans using parallel processing — dividing computer data into batches like lines of shoppers going through grocery store checkouts, where each lane is focused on certain threats — and invited him to join the project several years ago.\nFulp and two of his students, Wes Featherstun (’08, MS ’10) and Brian Williams (’08, MS ’10), then graduate students in computer science, worked at PNNL during the summer of 2009. Fulp and Crouse worked there again last summer.", "label": 1}
{"text": "It all begins with a team of hackers that spy on a specific company and seek out data needed to hack into its system. Members of this team underhandedly make people cooperate with them through psychological tricks. Once they do, these intruders obtain data necessary (as usernames and passwords) to access company networks. Knowing that most business staff workers are kind and polite as well as trusting, hackers pretend they’re employees of the targeted enterprise while asking for simple favors. Rather than physically breaking into an enterprise’s system, they seek out information as a way to get unauthorized access to it. This practice is referred to as social engineering.\nAs you know, a chain is as strong as its weakest link. If security were a chain, its weakest link would be the natural human kindness to trust anybody based on his or her word alone. No matter how effective our firewalls and our antivirus and anti-spyware programs work, they can only do so much to deter intruders. Every business needs a security policy to prohibit “visitors” from entering secured areas of its buildings. Employees must be trained not to let in strangers or answer security-related questions over the phone.\nGaining Company Info\nJust like hackers, social engineers seek to gain confidential facts or unauthorized access as a means of finding out more about a targeted company. With such data, intruders can commit fraud, obtain network access, undergo industrial espionage, steal one’s identity, or simply raise havoc with the company’s network. Common targets of such malicious acts are telephone companies, answering services, prominent corporations, banks, military and government agencies, and hospitals. Still, any company, large or small can be a victim to social engineering.\nWhy is social engineering becoming widespread? Because asking people for passwords or other illicit access data is much simpler than technical computer hacking. Even those with a great degree of hacking expertise find it’s much simpler to make a phone call and ask one for his password.\nCompanies are attacked via social engineering on a physical basis. Sources of illicit info about an entity are sought in the workplace, through the phone system, from trash cans, and via online access. Hackers have been known to walk into offices pretending to be a consultant or janitor. Such a person will casually strut around the workplace and seek out papers with passwords on them or watch over employees’ shoulders as they log in. Once the intruder found such data, that person will leave the premises and enter into the company’s network from their home.\nHacking by Phone\nAnother popular form of social networking is done over the phone. A potential hacker will call a user and impersonate one who has authority or relevance as a means of getting data from the user. Often, a hacker may claim they’re calling from within the corporation and then will play tricks on its operator. Such a person will say something like, “Hello, I am your representative from AT&T and I will need some info from you to fix a problem with your account.” They may ask for one’s AT&T card number and PIN combination.\nOne of the most vulnerable places of social engineering within a company is its help desk. Its staff are trained to be friendly, but taught the minimum necessary to answer common inquiries. Most of its employees know little, if anything about the security of their employer and are also paid low wages. All they do is answer a caller’s questions and move onto the next caller. Hence, the help desk is a potential gold mine for hackers and a large security hole for the entity.\nYet another method called “shoulder surfing” is done at pay phones and ATMs, especially at large airports. People lurk around these machines and peek over users’ shoulders to obtain credit card and PINs. Users must be extra careful when using them.\nGoing Through Trash\nIllicit information is also obtained via dumpster diving. Social engineering is done by pulling out discarded documents and company materials as phone books, employee handbooks, memos, calendars, system manuals, and any other sensitive data printed on paper. Additional data can be found on user/password login lists, source code printouts, floppy disks, storage tapes, stationery, and discarded computer equipment.\nHow are these items useful to a hacker? Company phone books list the names and numbers of employees hackers can call and beguile. Organization charts reveal names and positions of a company’s staff. Employee handbooks give the hacker an idea of how secure the business is (or isn’t). Technical information found in system manuals and source code reveals sensitive data needed to unlock and access the network. Media such as disks, tapes, and hard drives may hold all kinds of data that will benefit a hacker. Stationery and memo forms serve as an authentic way to send employees malicious correspondence.\nRequesting Info Online\nWorking online is yet another form of social engineering. Some hackers send online-forms to be filled out by users and require the entry of a username and password, email address, or card number and PIN combination. With these forms are advertisements stating the user has won some sort of sweepstakes and all he needs to do is supply information to claim his prize. Also, people tend to use the same username/password pair for more than one account and once a hacker has these two pieces of data, he may access other sites that the user visits frequently. Some users respond through their corporate email addresses unknowingly letting the hacker know where they work. Yet other hackers will send correspondence via the US mail asking for info.\nYet, the oldest trick in social engineering is pretending to be the network administrator. Real network administrators already know the username/password combinations of every employee, even if one decides to change theirs on the spur of the moment. If there are concerns related to a company’s network, employees should talk with their networker face-to-face.\nSocial engineering is becoming increasingly popular among hackers. It is best to be alert at all times and never give information out over the phone, even if the voice sounds familiar. Never open up emails, especially attachments, from parties you don’t know. Shred all documents before throwing them in the trash and have all computer media and hardware physically destroyed before disposing of them. Remember, legitimate network staff and company reps will never call you and ask for passwords. If you’re unsure about a request made via the phone, arrange to meet the caller in person.\nAbout the Author: Publishnprosper publishes articles on numerous computer usage topics. In his articles you will find useful tips on maintaining your computer and keeping it virus-free. If you’re interested in purchasing antivirus software, you may find coupons on http://www.dailydeals4you.com, Kaspersky coupon codes, Bitdefender promo, etc.\nDo you have questions, comments, or suggestions? Feel free to post a comment!\nLiked this post? Make a PayPal Donation to keep us strong.", "label": 1}
{"text": "November 14, 1998 Lock-on-a-chip may close hackers out\nBy P. Weiss\nEngineers have crammed an electromechanical combination lock onto a computer chip that they say can shut out cybercrooks. The device erects a barrier to computer intrusions that is far more difficult to penetrate than security software, the only option available today, say the locks inventors.\nBecause security software does not physically isolate a system but monitors electronic codes, determined hackers on the Internet or a modem connection can keep trying passwords and other keys until they breach the defenses.\nThe new lock, however, accepts only one number among a million possibilities as its correct combination. If a remote troublemaker attempts a break-in with the wrong code just once, the device disconnects the computer from its network. When the lock closes, only someone physically present at the computer can reopen it.\nThe new lock, which employs concepts developed for protecting nuclear weapons, \"puts a physical barrier between an asset and a threat,\" says the devices designer, Frank J. Peter of Sandia National Laboratories in Albuquerque, N.M. \"And it absolutely, positively cant be circumvented in software.\"\nPeter and his colleagues have packed intricate machinery into the silicon device the size of a shirt button. Electrically driven shafts studded with microscopic teeth turn tiny gears to set the combination. If triggered by a bogus code, the mechanism throws a switch that interrupts the flow of electric current or light through the device, temporarily isolating the computer.\nSuch a drastic response may prove impractical except for restricted-use computer systems where a small number of users all know the code and someone is continuously on duty to reset machines, says Peter Mell of the National Institute of Standards and Technology in Gaithersburg, Md. Moreover, attackers can send trouble-causing electronic mail and other data without having to gain access to a computer by logging on. Hackers could also maliciously trigger the lock to deny use of computers to their owners, he notes.\nDuring the next 2 years, the inventors may consider such questions in preparation for commercializing the technology. Perhaps they will choose to allow more than one false start, for instance, since computer users who rely on remote log-ins may occasionally type the wrong password. They also hope to find a company to mass-produce the locks inexpensively via methods used by integrated-circuit makers.\nFrom Science News, Vol. 154, No. 20, November 14, 1998, p. 309. Copyright © 1998 by Science Service.\nSandia National Laboratories provides additional information about the lock at these websites: http://www.sandia.gov/media/hacker.htm and http://www.mdl.sandia.gov/micromachine/.\nNational Institute of Standards and Technology\nComputer Security Division\n100 Bureau Drive, Mailstop Code 8930\nGaithersburg, MD 20899-8930\nFrank J. Peter\nSandia National Laboratories\nP.O. Box 5800\nMailstop Code 0329\nAlbuquerque, NM 87185-0329\ncopyright 1998 ScienceService", "label": 1}
{"text": "Social Networking Best Practices\nFacebook, MySpace, LinkedIn, and other social networking sites make it easy for you to connect with others based on shared personal and/or professional interests. They help you exchange information about yourself via postings, pictures, videos, email, or instant messaging. Depending on how you set up your account, this information can be shared within a small community of friends or broadcast to the world.\nSocializing online encourages openness, but it also challenges us to think about how we define privacy and what we consider personal. Consider how parents, university officials, future and current employers, or worse, online predators, may interpret your profile. The tips below will help keep you and your information safe.\n1. Know how the site works before you join.\nSocial networking sites are each set-up differently and offer a range of options. Some allow you to post to a small group of users, while others allow anyone to view your personal postings. Look at the different features and think about what level of openness you really want. Consider whether setting viewing restrictions can help control who sees your information.\n2. Keep personal information to yourself.\nYour full name, Social Security number, address, phone number, bank or credit card account numbers (and that of others) do not belong on these sites. By posting them, you open yourself up to identity theft or stalkers.\n3. Information lasts forever.\nOnly post information you are comfortable with others seeing, including your professors, parents, current or future employers, coworkers, or the police. Even if you change your mind and delete what you posted, the information is still out there. Older versions may exist on someone else’s computer and social networking sites can never fully remove these files.\n4. Think before you share.\nPhotos, videos, stories, blogs can all be used to form opinions of you or can be shared with others. Before posting, consider who will see these and whether you can share them with a smaller audience. Be considerate when passing on photos of friends - ask whether they would want that information shared.", "label": 1}
{"text": "Short for Ad Hoc On-Demand Distance Vector, a routing protocol for ad hoc mobile networks with large numbers of mobile nodes. The protocol's algorithm creates routes between nodes only when the routes are requested by the source nodes, giving the network the flexibility to allow nodes to enter and leave the network at will. Routes remain active only as long as data packets are traveling along the paths from the source to the destination. When the source stops sending packets, the path will time out and close.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "A couple of days ago, I received an e-mail from Iran. It was sent by an analyst from the Iranian Computer Emergency Response Team, and it was informing me about a piece of malware their team had found infecting a variety of Iranian computers. This turned out to be Flame: the malware that has now been front-page news worldwide.\nWhen we went digging through our archive for related samples of malware, we were surprised to find that we already had samples of Flame, dating back to 2010 and 2011, that we were unaware we possessed. They had come through automated reporting mechanisms, but had never been flagged by the system as something we should examine closely. Researchers at other antivirus firms have found evidence that they received samples of the malware even earlier than this, indicating that the malware was older than 2010.\nWhat this means is that all of us had missed detecting this malware for two years, or more. That’s a spectacular failure for our company, and for the antivirus industry in general.\nIt wasn’t the first time this has happened, either. Stuxnet went undetected for more than a year after it was unleashed in the wild, and was only discovered after an antivirus firm in Belarus was called in to look at machines in Iran that were having problems. When researchers dug back through their archives for anything similar to Stuxnet, they found that a zero-day exploit that was used in Stuxnet had been used before with another piece of malware, but had not been noticed at the time. A related malware called DuQu also went undetected by antivirus firms for over a year.\nStuxnet, Duqu and Flame are not normal, everyday malware, of course. All three of them were most likely developed by a Western intelligence agency as part of covert operations that weren’t meant to be discovered. The fact that the malware evaded detection proves how well the attackers did their job. In the case of Stuxnet and DuQu, they used digitally signed components to make their malware appear to be trustworthy applications. And instead of trying to protect their code with custom packers and obfuscation engines—which might have drawn suspicion to them—they hid in plain sight. In the case of Flame, the attackers used SQLite, SSH, SSL and LUA libraries that made the code look more like a business database system than a piece of malware.\nSomeone might argue that it’s good we failed to find these pieces of code. Most of the infections occurred in politically turbulent areas of the world, in countries like Iran, Syria and Sudan. It’s not known exactly what Flame was used for, but it’s possible that if we had detected and blocked it earlier, we might have indirectly helped oppressive regimes in these countries thwart the efforts of foreign intelligence agencies to monitor them.\nBut that’s not the point. We want to detect malware, regardless of its source or purpose. Politics don’t even enter the discussion, nor should they. Any malware, even targeted, can get out of hand and cause “collateral damage” to machines that aren’t the intended victim. Stuxnet, for example, spread around the world via its USB worm functionality and infected more than 100,000 computers while seeking out its real target, computers operating the Natanz uranium enrichment facility in Iran. In short, it’s our job as an industry to protect computers against malware. That’s it.\nYet we failed to do that with Stuxnet and DuQu and Flame. This makes our customers nervous.\nThe truth is, consumer-grade antivirus products can’t protect against targeted malware created by well-resourced nation-states with bulging budgets. They can protect you against run-of-the-mill malware: banking trojans, keystroke loggers, and e-mail worms. But targeted attacks like these go to great lengths to avoid antivirus products on purpose. And the zero-day exploits used in these attacks are unknown to antivirus companies by definition. As far as we can tell, before releasing their malicious codes to attack victims, the attackers tested them against all of the relevant antivirus products on the market to make sure that the malware wouldn’t be detected. They have unlimited time to perfect their attacks. It’s not a fair war between the attackers and the defenders when the attackers have access to our weapons.\nAntivirus systems need to strike a balance between detecting all possible attacks without causing any false alarms. And while we try to improve on this all the time, there will never be a solution that is 100 percent perfect. The best available protection against serious targeted attacks requires a layered defense, with network intrusion detection systems, whitelisting against known malware and active monitoring of inbound and outbound traffic of an organization’s network.\nThis story does not end with Flame. It’s highly likely there are other similar attacks already underway that we haven’t detected yet. Put simply, attacks like these work.\nFlame was a failure for the antivirus industry. We really should have been able to do better. But we didn’t. We were out of our league, in our own game.", "label": 1}
{"text": "We are living in an age of unprecedented language creation. Between the explosion of languages on the JVM and the new native languages, we find ourselves with a happy surfeit of very interesting choices. These options are not just the toy creations of comp-sci undergraduates, but sophisticated products with extensive libraries and active communities. Where they tend to be weak, however, is in tooling. And unfortunately, for many language developers, tooling is a metaphor for the coding front end: They strive to create editor plugins to provide basic syntax assistance. The more important support for debugging is often consigned to the use of\nprintf-like statements to dump\ntrace statements and variables' contents to the console.\nWhite PapersMore >>\n- Informed CIO: SDN and Server Virtualization on a Collision Course\n- InformationWeek 2013 Strategic Security Survey\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Agile for Safety Critical Systems: Project Management Practices\nI have always found this substitution of\nprintf for debugging to be a profoundly wrong conflation of two concepts. Yet, because we've all had the experience of using\nprintf or its equivalents to help chase down bugs, we tend to go along with the proposal. Some well-known developers even proclaim their preference for\nThere are multiple aspects of\nprintf statements that make them very poor substitutes and, in fact, at times dangerous tools.\nLocation. Martin advises \"judiciously placed print statements.\" Well, if you're in a serious debugging mode, judiciously placing\nprintf is a very difficult thing to do. It implies some strong knowledge of the nature of the cause of the defect you're chasing. My experience is that, frequently, you get the first attempt at\nprintf wrong, and then must start to guess where else to place the statements. Sometimes, it's not even guessing: You need to put them at several upstream points to coarsely locate where a variable unexpectedly changes values. Finally, when you get the right location, you must then add new statements to track down why the variable is changing. It's a mess that brings me to the second point.\nTime cost. Every\nComplexity. While conceptually nothing is simpler than dumping a variable to the console, in fact, it's no trivial matter. This is particularly true of data structures, especially those containing pointers. Now, the\ndump statement is useful. Debuggers handle this transparently and allow you to walk lists and arrays with no difficulty.\nClean up. Congratulations, you found the bug! Now, it's time to clean up your\nIn almost every dimension, the dumping of variables to the console is an inferior alternative to using the debugger. It takes just as long, if not longer, to find defects, and the practice inserts detrimental artifacts into the codebase.\nWhen I hear developers say that they're happy debugging with", "label": 1}
{"text": "Growing Mobile Phone Use Hurts Energy Security, IEA Says\nWith increased mobile phone and computer use, says the International Energy Agency, comes increased energy use. Unplugging mobile devices once they're charged, and disconnecting a not-in-use charger from the wall, are just two ways to help, according to Nokia.\nBy 2010 there will be more than 3.5 billion mobile phone\nsubscribers, 1 billion personal computers and 2 billion televisions in\nuse around the world, according to the International Energy Agency\n(IEA), an energy policy advisor to 28 member countries.\nAs the numbers of these devices increase, so, too, does the demand for energy.\nPresenting a new IEA publication, \"Gadgets and Gigawatts\" in Paris on May 13, IEA Executive Director Nobuo Tanaka remarked that \"despite anticipated improvements in the efficiency of electronic devices, these savings are likely to be overshadowed by the rising demand for technology in OECD and non-OECD countries.\"\nThe OECD, or the Organization for Economic Co-Operation and Development, was established in 1961 and consists of 30 democratic member countries that discuss answers to common problems and coordinate domestic and international policies.\n\"Without new policies, the energy consumed by information and communications technologies as well as consumer electronics will double by 2022 and increase threefold by 2030 to 1,700 Terawatt hours (TWh). This will jeopardize efforts to increase energy security and reduce the emission of greenhouse gases,\" the IEA wrote in a statement on the book launch.\nIn \"Gadgets and Gigawatts,\" the IEA reports that electricity consumption from residential information and communications technologies, and from consumer electronics, can be cut by more than half through the use of available technologies and processes.\nNokia, the largest mobile device manufacturer in an industry of more than 4 billion users, according to Kirsi Sormunen, Nokia's vice president of environmental affairs, is among the many companies taking steps toward being an environmental steward - which she said has been an interest for Nokia since long before green became trendy.\n\"It's in Nokia's DNA,\" Sormunen told eWEEK. \"And I should know, I've been at Nokia for 28 years myself!\"\nWhile companies throughout the supply chain need to do their parts, Sormunen says there are simple steps end-users can take as well. For example, unplugging the charger from the wall when it's not in use.\nAccording to data from Nokia, the amount of energy lost when a charger is plugged in but not connected to a phone is equivalent to two-thirds of the energy used by a fully charged device.\nAnother energy-saving tip, particularly for those who tend to charge their devices overnight, is to unplug the charger and device as soon as the device is finished charging.\nIn a market of 4 billion devices, Sormunen says: \"There are 1 billion users using our devices. If just those people would unplug the charger, it would provide enough energy [to power] 100,000 homes.\"\nNokia additionally reports that if all 3 billion people using mobile phones around the world recycled one mobile phone a year - the presumption being that each of us has an old phone or two in a drawer - those devices could save 240,000 tons of raw material and reduce greenhouse gases by an amount equivalent to taking 4 million cars off the road.\nDecreasing the brightness of the phone's screen, turning off Bluetooth and WLAN capabilities when not in use, and turning off or disabling sounds on keypads are also ways to increase the energy efficiency of a mobile device.\nThe IEA's \"Gadgets and Gigawatts,\" in another environmentally friendly move, is additionally available in a PDF format.", "label": 1}
{"text": "A \"SYN Attack\"\nis a Denial of Service (DoS) attack that consumes all the resources on your machine, forcing you to reboot. Denials of Service attacks (attacks which incapacitate a server due to high traffic volume or ones that tie-up system resources enough that the server cannot respond to a legitimate connection request from a remote system) are easily achievable from internal resources or external connections via extranets and Internet. Enabling TCP SYN Cookie Protection will help to eliminate the problem.\nEdit the sysctl.conf file (vi /etc/sysctl.conf) and add the following line:\n# Enable TCP SYN Cookie Protection\nnet.ipv4.tcp_syncookies = 1\nOnce the configuration has been set, you must restart your network for the change to take effect.\nThe command to restart the network is the following:\nTo restart all network devices manually on your system, use the following command:\n[root:~ ]# /etc/rc.d/init.d/network restart", "label": 1}
{"text": "Firefox 16, a treat for developers http://t.co/cnd27CzT\nTop 5 security Myths about Linux; and their realities\nLinux, unfortunately has been long surrounded by myths. Despite the speedy adoption of Linux as mainstream operating systems for enterprises particularly, the common misconceptions about Linux seem to continue. The post enlists five traditional myths about Linux Security and attempts to debunk each; discussing real facts.\nThere exist mainly two schools of thoughts regarding security of Linux. One group that assumes ‘ Linux is Virus Proof’ and the other, advocating a completely contrary thought i.e. ‘Linux is more insecure (when compared to contenders), as it makes source code available to everyone’. Let’s investigate in detail.\nMyth 1: Linux is insecure, as it makes source code available to everyone.\nReality: While this is true that Linux makes Source code available to everyone to view and inspect; it is this open source nature that makes Linux superior to any proprietary OS in terms of security. As the source code is available to anyone, thousands of develops around the world scrutinize the source code for security pitfalls. Imagine, even at this very moment number of people are reading and making the code better. It is far more easier to spot and fix security issues on Linux than on any closed-source platform. Additionally, if any security vulnerability is found on closed source platform, it cannot be readily altered to make the software secure. On the contrary, in case of open source software, if any security hole is discovered patches are created as quickly as possible (usually within hours) therefore the security flaw doesn’t last for long enough to be exploited.\nWhen asked about the lack of viruses known for Linux platform, the proprietary camp claims that Linux is not very popular to have viruses. This comprises another common Myth. Interestingly, it’s not only the proprietary camp to believe that Linux lacks virus because of its minimal market share, alot of literature on the internet and in books we find this misconception.\nMyth 2: Linux lacks virus because it is not very popular.\nMany say that the purpose of virus writers is to bring massive destruction. As Linux does not run on as many computers as MS’s Windows does, virus writers only target Windows to damage more and more stations. While this might not be completely wrong, it’s not completely true too.\nReality: Linux might not run on many desktop computers, BUT it runs on most computers in very important places. All super computers run Linux. Many notable governments have approved policies moving governmental computers to Linux. Additionally there was a huge enterprise shift from Proprietary OS to Linux in last 2000s recession. That means Linux, too is a very charming opportunity for hackers; rather hackers would more likely to write virus for Linux than for Windows if they want to bring even more destruction (especially destruction in terms of quality then quantity!). Therefore, the myth can easily be ruled out. Another reason that the proprietary camp gives for lesser known viruses for Linux is that Linux is an advanced OS and can only be used by professions who know how to protect their systems.\nMyth3: Linux is for experts who know how to protect their system and therefore Linux does not get viruses and it generally thought as secure\nIt is also a common misconception that because Linux is for experts, they know well how to deal with viruses. On the other hand, Windows, as being a simpler system is usually used by even non-technical people who are naive enough to get virus and destroy the whole system.\nReality: The concept ‘ Linux is for experts’ is itself a myth and quiet out dated now. Linux is now one of the friendliest OS out there that can be used by novice and experts both. There are Linux based computers dedicated for elderly (heard of the Wow computer?). So to say that Linux is for experts is not true. Linux is for everyone. Consequently to say, the Linux doesn’t get virus because of its technically strong to defend OS is wrong.\nWhat makes Linux secure is neither its lack of popularity nor its technically strong user base. It is the strong architecture of Linux which makes it secure. On Linux systems users do not have “root” privileges; instead they possess lower-level accounts. As a result even if a Linux system is somehow compromised, the virus shall not have root access to bring about any major damage to the system. Windows supports exe files, a format in which virus are transmitted. Linux, on the other hand does not support .exe files. Linux uses configuration files in place of registry files hence closing this door for virus. For the Linux servers now, Linux servers employ several level of security. Linux servers are updated more often. To conclude, it’s the Linux architecture that is different from that of contending proprietary OS which makes it secure. That is to say if Linux is adopted in main stream desktop computing, I am sure that Linux will prove to be more strong and less incline to get virus than contending OS.\nDoes that mean Linux is virus free? This comprises of our third Myth.\nMyth 4: Linux is virus free\nReality: while Linux is very secure and superior to its proprietary counterparts, it’s not virus free. There are a number of viruses known for Linux. I have compiled popular known viruses in this post. It may be noted that all most all the viruses known for Linux are non-destructive in nature (but not non-existent)\nMyth 5: On Linux system you don’t need an Anti virus.\nReality: Yes indeed it’s very much true that when you are running Linux OS you are secure. Never the less one must realize that no OS is 100% secure. While this might not be very important for desktop/home users; enterprise sector which use Linux, may require anti-virus. Occasional scanning, backing up data and checking your system for malicious software does not bring harm to anyone. This does not mean you need to spend substantial amount of cash on expensive anti- virus softwares. Any free or open source and free antivirus would do justice to your security!\nLike us on Facebook\nThis week Top Posts\n- Top Things to do After Installing Ubuntu 13.04 ‘Raring Ringtail’ : Ubuntu 13.04 Raring Ringtail final is almost out. The final release it scheduled for release on Apri...0 comment(s) |\n- Howto: Upgrade to Ubuntu 13.04 Raring Ringtail from 12.04, 12,10 | Desktop & Server : Updated 05-04-2013: Ubuntu 13.04 Raring Ringtail will be released Soon, If you have ubuntu 12,10, 12...0 comment(s) |\n- Install lamp with 1 command in Ubuntu 12.10, 13.04 Raring Ringtail & LinuxMint13 : Updated: 10/09/2012 :LAMP (Linux, Apache, MySQL and PHP) is an open source Web development platform ...0 comment(s) |\n- Scan Your Home Network With Nmap : Who should read this article? Everyone who is interested in computer security and computer networkin...0 comment(s) |\n- How to use Remote Desktop in Ubuntu : Sometimes, we need to access our computer from other locations when we’re not at home and such. This...0 comment(s) |\n- Configure conky-Lua in Ubuntu (12.10 & 13.04 Raring Ringtail), Fedora, debian and LinuxMint | Howto Conky : Updated 05-04-2013: Conky is a free, light-weight system monitor for X, that displays any informatio...0 comment(s) |\n- Secure File from Removal in Linux and Unix\n- How to Install Nginx on FreeBSD 9.x\n- Create a Launcher in Ubuntu Using Bash\n- Scan Your Home Network With Nmap\n- Steganography- Hide Your Files Inside An Image in Linux\n- Unix/Linux File Recognition. Did You Know?\n- Migrate from MySQL to MariaDB in FreeBSD\n- Connect Your Android Galaxy Tablet to Ubuntu via USB\n- ElementaryOS Beta 1 and 2 Comparison and Review\n- Introduction to the Linux Command Line\nCopyright © 2008-2013 Unixmen.com .", "label": 1}
{"text": "Lesson 6 - Chapter Review\nThis is an ongoing series to dissect the PhreakNIC v3.0 code, which\nseen at http://www.phreaknic.org/phreaknic.txt.\nHello class, been studying your current events? PGP has been\nin the news\nrecently, so this is an excellent opportunity to learn how a PGP key is put\ntogether. Evidently PGP versions 5.5 and higher have a security\nvulnerability. If a malicious type could manipulate a PGP key in the public\nkey directory, they could decrypt the victim's encoded messages.\nHere are a couple links if you'd like to read more about it:\nOf course, hint-junkies that we are, we wonder, \"Hmmm, if PGP has\nhole, does that mean we could use it to crack the PGP message in the\nPhreakNIC v3.0 Code?\" Could there be a ray of light, a glimmer of hope?\nAlas though, our PhreakNIC Code message has been encoded with PGP v2.6.2, so\nit's still secure. Curses!\nGetting back to our review, let's go over what we've solved so far . . .\nThe PhreakNIC v3.0 Code can be broken down into five sections:\n(1) The first line of numbers\n(2) A few lines of \"poem\" gibberish\n(3) A rotated PGP message\n(4) A rotated UUencoded message\n(5) The last \"bkkbb\" line\nHere's what we've deciphered in each of those sections:\n(1) The first line: Hexadecimal numbers that translate to\nwhich when converted via ROT-13 decoding say:\n\"Nice start. Now\nit gets tough.\"\n(2) The gibberish after, a 9-line poem rotated via ROT-13.\nEach sentence an\nanagram, with some of the letters set off with () and  marks. But we\nhaven't solved all of it yet.\n(3) A short PGP message, again rotated by ROT-13. We've got\nproperly, but still don't know whether we need to make a key, or find one.\n(4) A short UUencoded message, rotated by ROT-13. Once unrotated,\ntweaked into the proper format, it decodes to a file called un-uu-me.txt.\nThat file turned out to contain a series of columns of 5-character blocks,\nwhich, when decoded, pointed to information about the CIA's Kryptos monument.\nAn interesting journey, but not relevant to the rest of the Code.\n(5) The last line, the \"bkkbb\" section. It's a representation\ncode, which translated to ASCII characters: \"end here\".\nSo, we've solved sections 1, 4, and 5. Which leaves section\n2 (the poem) and\nsection 3 (the PGP message).\nHow do we get into that PGP section? We've solved everything\nelse, and all\nthat's left is the poem, so something in that poem must either tell us how to\nBUILD a key, or else the poem tells us where to FIND a key.\nHow've you been doing on those anagrams? Here's what we found so far:\nThe earnes[t][se]crets sho(n)e.\n(O)ne hears sat[i]re. --> ??\nAhem - r(e)ally rag Satan. --> They are all anagrams.\n(A)(T)M of Hel(l). --> All of them.\nEvil nos[e]energy. --> Every single one.\nO, the (C)IA net lunacy. --> They contain a clue.\nObey luser ca[m]. --> ??\nP[h]one far-fe[t]ched[r]oot text[.] --> For the next part of the code.\nA data-[l]in[k] g[r](u)mbles on the cloud(.) --> ??\nAs for the letters in () and  marks:\n: t se i e m h t r . l k r\n(): n O e A T l C u .\nWhen we did a frequency distribution on the whole lot:\nThe most common letters E and T, followed by R and L. Well,\nE and T *are*\nthe most commonly-used letters in the English language, so, keeping in mind\nthat it's a small sample, it does suggest an english frequency distribution,\nso it's worth assuming that they're anagrams, too. Lots of letters there\nthough, so lots of possible words.\nWe're getting deeper into JonnyX's head, and closer to the end-game\nCode. But there's even more nifty state-of-the-art stuff ahead, and a *very*\ninteresting twist coming up. Not to mention even *more* bad poetry <grin>.\nNext installment: Digging deeper into the poem!\nSee you next time,\n\"I'm a gamer. It's what I am. It's what I do.\"", "label": 1}
{"text": "In this whitepaper, Yahoo engineers Konstantin Shvachko, Hairong Kuang, Sanjay Radia, and Robert Chansle look at HDFS, the file system component of Hadoop. While the interface to HDFS is patterned after the UNIX file system, faithfulness to standards was sacrificed in favor of improved application performance.\nAbstract—The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of HDFS and report on experience using HDFS to manage 25 petabytes of enterprise data at Yahoo!\nA tip of the hat goes to the new Systems We Make blog, who seek to chronicle the growing boom of distributed systems being built in both academia and industry.", "label": 1}
{"text": "Networks are messy. Although they can be made to look neat and tidy by holding all the gear in rack mounted cabinets with serious cable management makeovers, they are still comprised of small islands of hardware each running its own proprietary software and firmware, often on proprietary silicon. For home users this isn’t really an issue, but for large government and business networks things get complicated and convoluted quickly. Especially in the case of internal networks used by governments that need to be as locked down as possible, changing even one switch, server, or connected device on the network is a tedious (and expensive!) process of rewriting security rules on a each and every hardware device.\nEach hardware device (be it a switch, router, server, or firewall) operates as its own isolated island which requires individual configuration. Seeing the shortcomings of such a setup, researchers and startup companies like Nicira have started to develop open software control systems under a coined term of “software defined networking” (SDN). Stuart Miniman defines SDN as “a model for network control, based on the idea that network traffic flow can be made programmable at scale, thus enabling new dynamic models for traffic management.” Similar to the way virtualization can be used to host many (virtual) computers on one physical piece of hardware, these virtualized networks could allow companies to run multiple network slices off of a single physical network.\nThis is a level of control and programmability that is not currently possible due to network hardware vendors using proprietary software in all their devices (Cisco’s IOS for example). SDN takes the proprietary code out of the equation, and — using open software on all the routers, switches, firewalls, and other network devices — separates the data and control planes (the packets and the logic that determines what to do with those packets). The network hardware is then connected and mapped out in software, and network admins are able to manage the entire network from a software interface. They are also able to specialize their network and add new functionality by writing their own code and deploying it across the network.\nOne of the most important benefits of SDN is that commodity hardware can be used, instead of specialty hardware from specific manufacturers. Removing or relocating devices on the network would involve a few mouse clicks in a GUI rather than physically switching Ethernet cables and reconfiguring all the appropriate network devices. Martin Casado, CTO of Nicira (who is one of the companies developing SDN technologies) said that “we’re virtualizing away this physical fabric, and because now we have a virtual layer, you can do anything you want with it. Because of this virtualization, the network can be fashioned from any and all compatible hardware, and can be controlled, transformed, and secured from a software interface rather than from configuring each device individually.\nThere is talk around the web that SDN will spell the end for special network hardwar companies like Cisco as well as eliminate the jobs of network operators. While entirely possible, such an event is not going to happen overnight. Cisco is not likely to give up without a fight, and at this point it still has a chance to react and adapt to this new technology. The reduction in network operator IT positions is possible as well but this virtualization technology is going to open up its own field of study as well, which should lead to positions maintaining SDN. Especially while software defined networking is still a new technology, businesses are going to need their IT personnel.\nNetworking giant Cisco has recently responded to rumors of SDN killing its business by stating that some customers do not want programmable networks. Also, for those customers that do want the flexibility of SDN, it has funded and plans to acquire network startup company Insieme. Insieme is reportedly working on a line of programmable network switches that support OpenStack as the SDN abstraction layer. The CTO of Cisco has been quoted by Network World in stating “Networking is about to be reinvented and Cisco will do that reinvention of networking.”\nIn the end, the idea of a truly modular virtualized network that allows control from a software GUI is really cool. It is a big shift in networking to a programmable, open, and modular network controlled via software software that will make managing large scale networks much easier.", "label": 1}
{"text": "Security 101: E-mail Encryption with PGP and GPG\nPGP and GPG ensure e-mail stays between the sender and its intended recipient.\nWhen you send a cleartext, unencrypted e-mail, you are saying \"I don't care who reads the contents of this message, I don't care if someone possibly alters the contents, and I don't care if someone else pretends to be me.\"\nDoubtless it is not your intention to say these things, but it is an unfortunate fact of life that this is the result.\nOrdinary cleartext e-mails can be intercepted and read by anyone with access to the wires between you and your recipient. This could be snoopy sysadmins, or anyone who has successfully compromised a server, router or network. Sometimes getting onto a network is easy unsecured, poorly-secured and rogue wireless access points are big fat red welcome mats for all the wrong people.\nDid you know that inside jobs, just like in old-time industries like retail and manufacturing, represent the largest percentage of thefts and unauthorized snooping in computer networks? The numbers given vary, but it's safe to say it's a sizable majority.\nThe easiest and best way to secure your e-mail transmissions from end-to-end is to use Pretty Good Privacy (PGP) or its open source/free of cost sibling, Gnu Privacy Guard (GPG). PGP/GPG depend on encryption/decryption key pairs. You have a private key, which you guard zealously and never ever let anyone else get their hands on. Your public key can be distributed freely; many people even post their public keys on Web sites.\nThe way it works is genius-simple: Anyone who wants to send a message to you encrypts it with a copy of your public key. Then you decrypt it with your private key. Your message is completely protected in transit and immune to eavesdropping and altering.\nGPG works on any system on which it can be successfully compiled, which is most Linux and Unix systems. You may also compile and run it on Windows. Windows and Mac OS X users will probably want something a bit easier, such as GPG4Win and Mac GPG.\nPGP costs money and comes in many different flavors. It has support, as well as some nice management tools. PGP and GPG are completely compatible, and in fact share the same code base. So you can encrypt and decrypt messages freely between the two programs. It's the best of all worlds a very easy way to protect your e-mail with very strong encryption.\nThis article was first published on ServerWatch.com.", "label": 1}
{"text": "By: Logan Pierce, editor-in-chief\nIn the latest installment of the Great Issues Lecture Series, Linda Whaley, director, Health Information Technology Program, addressed students, faculty and staff regarding personal health information.\nOne thing Whaley considers both good and bad is the constant policy revisions that take place within the health care industry. “The changes sometimes make my job difficult,” Whaley said, “I’m constantly revising my slides. What I tell you today may be different next week.”\nTracking health information\nWhaley listed several things which are a part of personal health information, including hospital registration and admittance, doctor’s office visits, accessing urgent care clinics, and ambulance rides.\nMedical history goes beyond where you are treated. Physical exams, lab tests, medical imaging and other tests are also recorded.\nWhich begs the question, who has access to such personal information? A surprisingly large number of people, the most obvious being public, state and federal health agencies and health care providers.\nBeyond health care\nThird party payers, i.e. insurance companies, can access a client’s medical records to ensure that the paid procedures have been performed.\nLaw enforcement has a limited access to medical records. Other entities, such as lawyers, need the medical records of their clients if they’re suing as the result of an injury, or when filling out an application for life insurance.\nAnd, of course, individuals have the right to access their medical records. Care should be exercised when attempting to retrieve a hard copy. Depending on the amount of pages, printing fees could cost hundreds of dollars. To save money, individuals should select only those records relevant to their needs.\nAnother option is to request electronic copies of records. While not all facilities keep electronic medical records, government incentives are being pushed to increase these numbers. “Most physicians are migrating to electronic health records,” Whaley said, “$3.1 billion has gone to hospitals who adopt electronic health records.”\nThe benefits of digitally retrieving medical information include reduced paperwork, the rapid sharing of information, and the reduction of unnecessary tests.\n“Security is the downside to electronic health records,” Whaley said, “There’s lots of breaches.”\nThe Department of Health and Human Services’ (HHS) website has a page detailing large breaches of information; breaches which affect 500 or more individuals. Whaley referred to this as the “wall of shame.”\n“You can always get a wealth of information from government websites,” Whaley said, “Oklahoma has only four entries on the wall of shame.”\nOne of the most extreme breaches came from Blue Cross Blue Shield of Tennessee. They received a fine of $1.5 million from HHS after 57 unencrypted computer hard drives were stolen from a leased facility. The hard drives contained the names, social security numbers, dates of birth, diagnosis codes and health plan identification numbers of more than 1 million individuals.\nThe Secure Medical Records Transfer Network (SMRTNET) and their website, smrtnet.net, work to protect Oklahomans from medical identity theft, which is the fastest growing type of identity theft. Their network encompasses 25 hospitals and 60 clinics in Oklahoma, with more than 2,500 users.\n“New [government] guidelines are being enacted,” Whaley said, “Encryption is not a requirement, but it is highly encouraged.”\nOrganizations like SMRTNET are making strides to prevent identity theft, while striving to follow the Health Information Management (HIM) goal “to optimally achieve the accuracy, availability and protection of health information for all.”", "label": 1}
{"text": "The recent volcanic eruption at Eyjafjallajökull in Iceland, which caused major air travel disruptions across Europe due to the resulting ash cloud, is being exploited by cybercriminals to infect users. Searching for information or images related to the event poses an increased risk of leading to malicious pages.\nOn 14 April 2010, the Eyjafjallajökull volcano in Iceland erupted for the second time in 2010, leading to the formation of an ash cloud that is unusually rich in glass particles. The eruption is still on-going and experts claim the volcano might produce ash for weeks to come.\nBecause the ash plume has quickly spread across Europe, many countries were forced to completely or partially suspend air traffic over their territories. At the moment, all major European airports are closed down and thousands of travelers are stranded, in what might become the most severe air travel disruption in history.\nAs the event is affecting flights all over the world, it is understandable that a lot of people use the Internet to keep informed about new developments in real time. A quick look on Google Trends reveals that \"volcano iceland,\" \"uk airspace\" or \"flights canceled\" are amongst the hottest search topics in the USA at the moment.\nUnfortunately, cybercrooks are also paying attention to what people are searching for and waste no opportunity to exploit it to their advantage. By employing artificial page rank inflation techniques, collectively known as black hat search engine optimization (BHSEO), they succeed in pushing malicious links to the top pages of search results.\nAt the moment, a predictable search query such as \"Iceland volcano pictures\" produces malicious results beginning with the second page. These links take users to web pages displaying fake security alerts, that try to convince them to download and install fake antivirus programs on their computer.\nCalled scareware or roguware, such applications produce bogus reports about fictitious infections on the users' systems, in an attempt to convince them to pay for a fix. Such scams usually result in users losing their money and compromising their financial information.\nGoogle is making significant efforts to counter these attacks and tag the fake search results as malicious through its Safe Browsing service. However, as demonstrated by past experiences, this is an endless game of cat and mouse in which cybercriminals currently have the lead.\nBecause of this, Internet users are strongly advised to rely on additional forms of protection, such as capable antivirus programs or browser security extensions. Practicing extra caution when it comes to visiting links listed on Google search result pages is also a must - get your news only from trusted and reputable sources.", "label": 1}
{"text": "A botnet is a network of zombie computers controlled by a single entity. The term is a portmanteau of the phrase \"Robot Network\". Usually, the zombies in use of a botnet are compromised computers running the Microsoft Windows operating system that have been infected with some sort of malware. These computers communicate with other botnet machines via the Internet. Most botnets are distributed-design systems, with the botnet operator giving instructions to only a small number of machines. These machines then propagate the instructions to other compromised machines, usually via IRC. The distributed design prevents the discovery of the controlling computers. The anonymity that a botnet affords often helps the user avoid detection and possible prosecution.\nBotnets are effective in performing tasks that would be impossible given only a single computer, single IP address, or a single Internet connection. Originally, botnets were used for performing distributed denial of service attacks. However, most modern webservers have developed strategies to combat such DDoS attacks, making this use of a botnet ineffective. Additionally, many counter-DDoS strategies blacklist the IP addresses of attacking computers, thus exposing the botnet's machines. As the spam market has become profitable, and ISPs usually discontinue service to subscribers who send spam, botnets were found to be an effective resource for sending spam. Furthermore, many compromised computers contain address books of email addresses which can be incorporated into the list of addresses to send spam to. Zombies that are not actively sending spam at any point in time can be configured to scrape the web looking for new email addresses to spam, adding further value to the botnet.\nA secondary objective of the botnet is to find and compromise additional computers. While this is not considered a primary objective in and of itself, the expansion of the botnet via assimilation of new computers helps it perform the primary objectives more efficiently. Thus, this secondary objective is often the bulk of a botnet's tasks. Many computer networks, especially those using Microsoft Windows computers running the default settings, inherently trust other computers on the same network. Thus, a single compromised machine on such a network constitutes an attack vector against other machines on the network. Other secondary botnot objectives include website advertisement clicking, web browser toolbar installations, keylogging, and social bookmarking poll manipulation.\nSecurity Terminology Questions", "label": 1}
{"text": "Business Case for Open Standards\nBy Erik Sliman\nCreated April 30, 2002\nOpen standards begin when a collaboration of interested parties results in a consensus on specifications for implementing common requirements. They permit open access for anyone desiring to utilize the results in a way that enables conformity across implementations. While open standards describe openness in both the standards setting process as well as access to the specifications, industry de facto and government-led standardization alternatives are less open. The choice to use open standards over the alternatives can improve one's ability to realize common objectives.\nYou can optimize your options through the use of open standards, improving the choices that help you to reduce risk, implement durable solutions, obtain flexibility and benefit from quality. Since multiple vendors can support open standards, you can spread the risk out among them instead of on one proprietary vendor, reducing overall risk related to dependency on and support for the technology. This also leads to increased durability of options, as open standards are able to last longer than limited vendor solutions. Vendors come, and vendors go, but open standards, transcending them all, remain durable. With vendors competing to implement and help you use open standards, your vendor options are more flexible. In a market where accessibility to open standards are high, this leads to higher quality and lower pricing, key differentiators in an environment where conformity to open standards sets the foundation.\nThe more we use and deploy open standards, the greater our vendor independence. Open standards decrease the cost of changing vendors by decreasing the costly components of change, resulting in improved and increased vendor options.\nInteroperability results when components are able to work together to complete a process. Open standards, by helping to define component interfaces, increases interoperability. This leads to simpler, repeatable and quicker integration efforts.\nBy helping those involved in using open standards to use common terminology, communication is improved when organizing, planning and implementing open standards based technology.\nOpen standards help to consolidate competing standards, increasing the aggregate pool of resources available for using them without the cost inefficiencies of a single vendor de facto. For suppliers, this helps to consolidate a larger customer base. Instead of picking the portion of customers using the proprietary standards you are equipped to support, you can instead offer products and services to a larger consolidated base of users. For users, this pools vendors together, increasing competition and price pressures, yielding better quantity and quality of vendor options. This also results in consolidated pools of people skills. Instead of looking for specialists in the proprietary standard you use, you can choose among a larger base of consolidated specialists empowered to support multiple vendors using the same open standard.\nBy reducing costs, speeding time-to-market, and increasing market adoption and acceptance, products and services developed around open standards benefit from a higher Return on Investment (ROI). They benefit from lower barriers to market entry created through decreased customer risk with vendor selection as the association of support and durability with the individual vendor is transferred instead to the pool of vendors supporting open standards.\nObtaining the advantages of open standards begins by declaring it a high priority, considering it in all your options, including it in your planning, and improving your processes to use open standards. Initial steps you can take to lead your organization include opening dialog, increasing participation in open standards processes and raising awareness.\nOpen Standards Introduction\nOpen Standards is the concept of people working together openly to collaboratively develop solutions for addressing common requirements and goals.? Often they work together in committees through open standards organizations, such as the Internet Engineering Task Force (IETF) or the World Wide Web Consortium (W3C).?\nOpen standards permit everyone to utilize the resulting specification to build infrastructure and various solutions.? This creates the opportunity for unlimited vendors competing on the quality of their implementations and their ability to meet the diverse needs of the end-users in the markets utilizing the open standards.?\nFor standards requiring communication or interconnectivity, an open standard can help to ensure that the various implementations by the users can interoperate and integrate.? By using the Internet's TCP/IP communications protocol, for example, virtually any component on a network can talk to any other component, creating an infrastructure for collaborating and coordinating resources across the globe.?\nTo be sure, open standards are not the only means of obtaining standardization.? Whereas open standards exhibit openness in the collaborative efforts to create the standards, and access to the resulting specs and technology necessary to implement those specs, there are other types of standards such as industry de facto and government.?\nIndustry de facto standards often require the adoption of proprietary technology and may require the payment of licensing to a sole or few providers of that technology.?? People often use them because they are popular, increasing the user's ability to interoperate and collaborate others.? Where the benefits of standardization are high, de facto standards can be very difficult for competitors to unseat; yet, in the absence of open standards, continue to abound.?\nGovernment standards can be set through several means, including direct dictates in the form of laws, or mandates via regulatory bodies carrying the force of law.? Sometimes, government agencies may also lead efforts for voluntary compliance, and may even partner with private, public and commercial parties.? While open standards do not necessarily preclude government participation, nor do they require it, and should not be limited by it.?\nOpen standards bodies can include participation from government and industry.? Ideally, they are free to operate with the independence necessary to serve the principles and objectives set forth in their own charters.? Differentiating an ideal open standards body from similar constructs is the ability to permit participation while inhibiting dominance inherent in political, financial or market power.? Its goal is to balance the interests in order to support objectives while adhering to principles.?\nFor decision makers in charge of guiding and influencers able to impact an organization's technical direction, possibly by choosing vendors, products or technologies, it can quickly become challenging to sort out the options.? One needs not only to assess the degree of reliance on proprietary versus open standards each choice can bring, but the impact the decision will have on the organization.?\nAs one begins to take hold of the dynamics of these decisions, and how open standards can play a role, options can become more clear and simple, and commitments more resolute.? Increasing the transparency and understanding of open standards can not only help one realize better decisions, but can help obtain the reassurance that comes from discerning how open standards create improvements.?\nOptimizing options is about giving you more and better choices for accomplishing your goals.? Choices that help you to reduce risk, obtain durable solutions, acquire flexibility and benefit from quality optimize your path to success.? If open standards increase access to these options, then they are an empowering means to help you achieve a better end.?\nOpen Standards increase options that lower risk.? When selecting a proprietary solution, you are often putting your chips in one basket.? You risk that the vendor will be around for awhile, that they will choose to continue to support the technology you implemented, they will improve their product and their improvements will match the growth in your needs.? You also risk interoperability issues.? Will your suppliers, customer, partners and other related entities integrate well?\nOpen standards can reduce this risk in many areas.? Since, by definition, more than one supplier supports them, you spread your chips out among those implementing the standards.? This can increase the probability of long-term availability of support and continuous improvements, and can even open doors to those improvements being more applicable due to the increased representation of interests inherent with open standards.? With broad support and increased vendors behind it, it is easier to achieve interoperability needed to integrate your internal systems with each other, your suppliers, customers and partners.?\nOpen standards, such as the Structured Query Language (SQL), have proven to have higher durability over time than proprietary solutions.? Whereas individual vendors of proprietary solutions have an incentive to alter and phase out support for older technologies to solicit investment in upgrades even if costly upgrades are not the ideal growth strategy for your organization, open standards have demonstrated their resilience to this pressure.? Open standards last longer as they can be more reflective of the demands of the users, and are not subject to a single vendor's interests.?\nSQL is an example of an open standard demonstrating durability in a competitive market place.? Since SQL is used throughout the relational database industry by vendors such as Oracle, Microsoft and IBM, no single vendor has enough control to force you to replace it.? You can choose to continue to use SQL until something has proven to meet your requirements better.?\nOpen standards can continue to improve until you require something new. Since open standards can achieve a high user base through universal adoption, the drive is there to continue improvement so long as it is required.? Of course, if an open standard is ready to be replaced, then a new open standard can be created, opening the door to collaboration on migration and interoperability.?\nThe increased vendors available due open agreement on open standards gives you more flexible options.? In considering supplier options, one size usually does not fit all.? For a proven standard, there may be larger vendors available for those who require global support and higher reliability, while, for the same standard, there may be more localized vendors able to provide you with the implementation you need at a more appealing price, and possibly a more personalized service conducive to your growth needs.?\nIf multiple vendors implement a standard, this can decrease the cost of switching vendors compared to leaving or moving to a vendor of a proprietary solution.? Proprietary solutions are often incompatible with competing solutions, and can also require a high learning curve for the support specialists to make the switch.? Open standards can reduce the impact of change to your systems, your support staff, and other business assets.?\nFor example, using SQL can decrease the impact of switching from one relational database vendor to another.? However, producing code using proprietary super sets of SQL (e.g., Oracle's PL/SQL or Microsoft's Transact SQL) increases the cost of replacement.? Using n-tier architecture, business logic can be coded outside the database avoiding dependency on these supersets and, consequently, their vendors.? A simple decision about where to place logic can optimize options by decreasing the cost of replacing relational database vendors.? Due diligence leading to a better understanding of open standards can go a long way towards improving the effectiveness and efficiency of your IT infrastructure, operations and dependent solutions.\nOpen standards can also provide increased flexibility to your internal systems.? You can leverage interoperability options through open interfaces, giving you options you may not have considered otherwise.? Open source implementing open standards can also offer flexibility by competing with your vendors.?\nCoupled with durability, your flexibility is greater with open standards over the long haul, as technological progress tends to isolate proprietary solutions over time.? This was clear on the Internet when some early commercial Internet Service Providers (ISP) tried to implement proprietary connectivity to the Internet.? The early CompuServe and Prodigy networks are a memory today, while the Internet as a whole continues to grow.?\nQuality is the degree to which a product or service meets your requirements.? One way to measure quality is to measure defects, where a defect is anything other than complete satisfaction of your requirements.? Less defects translates to higher quality.? 100% free from defects would mean that your requirements were wholly met 100% of the time.\nIncreased competition increases quality.? Since the cost of switching vendors is decreased, they have a higher incentive to improve the metrics that impact your decisions, and quality is usually one of those metrics.?\nIncreased vendor competition also increases capacity to meet your requirements.? This capacity can be demonstrated in increased performance, scalability, features, security, or other means.? Since this increase can increase the ability to meet your requirements, you have higher quality selections available to you.?\nOpen standards are subject to the highest degree of peer review since the specs are available to everyone to view and scrutinize.? With open participation in the standard setting process, open standards also enjoy early peer review.? Widespread and early peer review increases early identification and resolution of potential problems, leading to higher quality results than closed proprietary solutions where the public may not be able to adequately determine quality.?\nCASE STUDY: Public peer review of open standards solutions has helped to increase the adoption of Public Key Infrastructure (PKI) solutions based on X.509 standards set by the IETF.? The acceptance of solutions for security business assets requires trust.? In areas of great complexity where it is infeasible for each prospective user to understand all the issues, yet the protection of valuable assets is at stake, open public peer review can offer reassurance where proprietary options might fall short.? The reassurance results from the perception that increased and early peer review can result in higher quality.?\nImprove Vendor Independence\nOne does not need to be in IT long to witness the reality and impact vendor dependence can have.? Many IT decisions have been made due in part to the potential costs of switching vendors, which, much of the time, is ruled infeasible.?\nDe facto industry standards encourage this dependence, reducing choice and competition.? If your customer requires that you transmit an artifact in a proprietary format, the cost to you of not supporting the proprietary solution could translate to lost revenue and profit.? Of course, it may not be your customer's fault.? They may be under the same pressure.? A de facto standard can be hard to break out of because it is like trying to solve the chicken and egg problem, only without a chicken or an egg.? Unless we all change to an alternate solution together, our ability to free our selves from vendor dependence can prove elusive.?\nOf course, not all vendor dependence is this strong or driven by customer requirements.? Sometimes, it is simply too costly to switch vendors due to proprietary technology.? You might, for instance, have a significant portion of your business code written in a proprietary language that is part of a vendor's product.? Switching vendors may require a costly ?rip-and-replace? rewrite.? Also, after the switch, the value of employee knowledge and expertise in that language you no longer use will drop, often requiring retraining or replacement of employees.?\nCASE STUDY:? Although there are plenty of vendors in the relational database market, many have created their own procedural language for creating complex application logic in the database server.? During the client/server era, where the only other alternative was putting all the application logic in the client, a lot of code was written in Oracle's PL/SQL, Microsoft's Transact SQL and other proprietary languages of vendor databases.? Although the n-tier architecture has decreased the reliance on these stored procedures by creating tiers between the front-end client and back-end database where logic can reside, in the absence of vendor independence objectives, the practice continues.? This means the cost of replacing one of one database vendor with another may include the cost of rewriting the server-side logic of the applications.?\nOpen standards help to reduce vendor dependence.? With increasing agreement by vendors on issues involving your business assets, the cost of switching vendors while preserving your business assets is reduced, leading to increased vendor-independence and lower barriers to choice.?\nIncrease Vendor Choice\nIn a market driven by open standards, the quantity and diversity of vendors and their ability to address your requirements can be substantial.? The quantity can grow to address decreasing barriers to entry since the ability to implement the standards is available to all.? The diversity is a result of vendors creating solutions to match the variety of requirements in a market subject to high competitiveness.?\nCASE STUDY: Internet Service Providers (ISP) utilizing open standards to deliver their services are an example of high quantity and diversity of vendor choice.\nPart of what enables this is the decreased cost of switching vendors.? Your ability to easily pick another vendor lowers the barriers to entry for the suppliers, as your current vendor is no longer as strong of a barrier to your competitors.?\nAs you replace proprietary dependency with open standards in potential solutions, risk is transferred from the owner of the single vendor technology to all the vendors supporting the open standards.? Since this offers a more durable option, your overall risk is decreased.? Additionally, a solution that can be more widely supported lowers the barriers to entry for other potential suppliers, giving them more cause to construct offerings crafted to satisfy your requirements.?\nThe combination of your greater accessibility to alternate vendors with the increased ability for them to be able to provide you with open solutions results in an increase in choice, as you are now able to select from a larger pool of supplier options.?\nDecrease Vendor Cost\nThe decreased cost of changing vendors and savings obtained from an increasingly competitive supplier market results in decreased vendor cost through open standards.? The increased competitiveness as open standards lowers barriers to entry in your supplier market also increases efficiencies resulting in lower overall costs throughout your vendor's market.?\nInteroperability is achieved when components are able to function together to share in the fulfillment of a process.? The components that interoperate can be of varying degrees of granularity from components within a single system that work together to create the processes within the system to components between systems tying customer, supplier, vendor, and other external processes into your business.?\nIn between systems you may also have middleware, which can have its own components with varying degrees of interoperability.?\nIncreasing interoperability increases your ability to connect and automate processes that transcend technologies, platforms, languages and customizations.?\nOpen standards and open architectures are continually improving to reduce the barriers to integration of disparate systems.?\nCASE STUDY:? Web services, a set of protocols based on open standards, are the most recent example of ways to increase interoperability options while decreasing costs of integration.? As these standards gained quick acceptance, it became clear that platforms that were previously too economically infeasible to even consider integrating now offer unprecedented synergy.?\nClearly, there are solutions that don't need every interoperability option.? Yet, increasing those options gives you more ability to optimize your use of integration.? Open standards can increase interoperability you need to produce synergy.?\nTwo people talking the same language is simple.? Talking through a translator is not as simple.? Writing a letter, having it translated, sending it, and waiting for a reply is not simple.?\nThe latter example demonstrates some of the techniques used to integrate systems without open standards.? The ability to collect information from one system, transform it into a format another system can understand, then find a way to get the new data correctly inserted into the new system can be a challenge.? One thing is clear, if the two systems could talk directly to each other, then the work would be simpler.?\nOpen standards have become a means of creating common ways all our systems can talk to each other.? Integration tools were quickly revamped to exploit the benefits of recent open standards such as SOAP, while system development platforms have likewise quickly added capability to use open standard protocols to include integration features to new and current systems.?\nThe concept using of ?plug and play? to integrate devices and computer components was born out of the demand for simple and quick integration.? Yet, a look at how it is implemented reveals that it is simply a standardization of integration specifications, automating the satisfaction of repeatable requirements.?\nOpen standards in interoperability issues helps to foster processes for quicker integration of components having standardized interfaces and increased automation of common requirements.?\nEncourage Repeatable Processes\nOpen standards are creating common ways of integrating systems, replacing many unique vendor solutions.? This is helping to foster repeatable integration processes for enterprises, and increasing repeatability throughout dependent industries.?\nOpen standards increase the availability of resources sharing the same processes.? For example, you have five specialists, each using tools that deploy different proprietary technology for achieving the goals, and methodologies developed around each solution, then one of the specialists is not a direct substitute for the other.?\nNow, if all five specialists use the same fundamental technology based on widely adopted open standards, then your ability to substitute one for the other is greater, increasing your pool of available specialists for a given solution one to five.? Specialists, likewise, are able to take advantage of learning efficiencies, as five schools of thought become one.?\nSubstitution increases the pool of knowledge matching your requirements and the ability of knowledge workers to find a need for their skills.? This benefits the technology efforts as a whole by creating the opportunity to increase repeatability.?\nIncrease Available Resources\nJust as using open standards based technology can increase the number of vendors able to address your needs, there are other resources that can increase, as specialization becomes more commonly focused around open standards.?\nCASE STUDY: The Unified Model Language (UML) is an example of an open standard accomplishing this.? By integrating three differing de facto object-oriented modeling standards into one open standard, modelers increased their ability to substitute each other, benefiting providers of modeling skills as well as consumers.? Even though there are many vendors of UML tools, repeatable methods of using UML have arisen permitting enterprises to select the UML tool that best balances their capacity requirements with cost, while choosing a repeatable process using UML transcending vendor implementations.?\nNot only does this increase the UML vendors to choose from in contrast to selecting one of the three primary modeling languages in the early 90s, it also combines the labor pool for the OOAD modeling category.? Whereas before you searched for specialists that supported the standard you selected to avoid learning and conflict costs, you can now simply look for someone who knows UML.?\nThe available labor pool for a project that has already selected specific a vendor's UML tool is increased by virtue of the increased substitutability of human resources that have experience with UML with other vendors.? Although there are differences in UML based toolsets, largely categorized around the bells and whistles not directly relating to UML itself, the use of UML decreases the learning curve from moving from one vendor tool to another in contrast to a change to a tool that uses a different modeling language, increasing substitutability of resources and repeatability of processes.?\nOpen standards can increase the quantity of all resource pools supplying knowledge or technology utilizing the specification by consolidating resources.?\nBesides automated communication improvements yielding improved interoperability, open standards simplifies and streamlines communication between people.?\nBy encouraging open dialog and participation from the outset, open standards encourage communications that leads to consensus.? The unified objective mindset of the contributors to the open standards process encourages adoption of common terminology used in the discussions before the specifications or processes are themselves concluded.\nThe common terms flow outside standards setting processes, advancing throughout industry and public discussions.? As the technology and standards are adopted, communication is increasingly streamlined, permitting educational and corporate institutions to apply the concepts and terminology.? Implementers and users of the standards can communicate more efficiently by using terminology predefined and visible to everyone interested.?\nThe streamlining of communications derived from common open dialog ensures higher productivity from users of open standards in contrast to operating with closed concepts.?\nIncrease Return on Investment (ROI)\nReturn on Investment (ROI) is the return an investment yields over a period of time, a financial metric for helping to determine and contrast the potential value of investments.? The higher the return you achieve with your investment, the greater the positive impact it can have on your bottom line.?\nThere are basically three ways to increase ROI.? The most obvious is to decrease cost.? Another is to increase benefits, or return.? Lastly, since the development of information systems cannot begin to yield a return until they are deployed in production, you can increase ROI by shortening the time it takes to enter production, speeding time-to-market.? This increases ROI by indirectly increasing return for the same period of time.? This may also yield competitive advantages increasing long-term return.?\nYou can decrease costs through the use of open standards, thereby increasing ROI.? Open standards can increase your vendor options, resulting in lower vendor costs.? Consolidation in other resources, such as training costs, can also decrease overall costs.?\nAs you demand quicker time-to-market, increased competition between vendors in an open standards market increases pressure to produce and pass on improvements and efficiencies.? Increased use of open standards increases the ability to share improvements across the industry, yielding improvements for all users.?\nBy helping to decrease cost and speed time-to-market through improved competition among suppliers and consolidation in other available resources, using open standards can help to increase ROI.\nIncrease Acceptance of Products and Services\nBuilding products and services using open standards improves market acceptance, since part of what you are offering, the implementation of open standards, has already been accepted.?\nIncreasing market acceptance by virtue of the choice to use open standards can decrease your barriers to market entry and growth.? In markets where highly proprietary solutions dominate, customers often choose larger vendors to reduce risk, often creating a market where a few are dominant, and barriers to entry are high.? Open standards lowers these barriers, opening markets to you as customers consider you an alternative to their current suppliers.?\nCustomer risk is lowered independent of the vendor chosen as risk is transferred from a single vendor to multiple vendors implementing the same open standards.? The decrease and transfer of risk increases the ability of the customer to consider more vendors.? This increases your accessibility to new customers as your products and services enjoy increased acceptance through the utilization of open standards.\nIncreasing the acceptance of the products and services through the adoption of open standards also means you will be competing for a faster growing market.? The increase in growth can create a business case turning even the most traditional proprietary players into advocates for open standards.? The ISP and website hosting markets are prime examples.?\nFor the consumption of products and services and the creation of internal solutions, using open standards can decrease your costs, speed time-to-market, expand available options and resources, improve communications, reduce risk and create more durable solutions.? Using open standards in the products and services you produce and internal applications directed towards such efforts offers these same benefits plus increased adoption and market acceptance of solutions and lower market barriers through decreased customer risk.? It also allows you to participate in faster growing markets.?\nObtaining these advantages begins with the decision to declare open standards among your highest priorities.? Decide to evaluate open standard options in all your considerations.? Address it in your planning.? Begin to build the process of understanding, contrasting and developing conclusions of how open standards can improve your decisions and impact your business.?\nRaising awareness, increasing participation and supporting dialog of open standards are all steps you can take to help your organization leverage the benefits of open standards.? If you open discussions on open standards, you might be surprised when the dialog lends itself to articulating the business case for open standards.?\nBuilt using Joshua Branch AS, J2EE and JBoss.\nFor questions or comments please contact the webmaster.\nExcept where otherwise noted, this site is\nlicensed under a Creative Commons License", "label": 1}
{"text": "01.Shopping without walls\nGeo-blocking prevents shoppers in some countries from accessing cheaper prices overseas through Internet Service Provider (ISP) restrictions.\nWe look at how international companies such as Amazon, Apple and Microsoft conduct geo-blocking, and offer some tips to circumvent the price discrimination.\nWhat is geo-blocking?\nThe internet is a borderless\nworld – news, shopping and\nsocial interaction with people\nfrom all over the world is at\nour fingertips. But some online retailers\nhaven’t yet embraced this fact, relying\ninstead on copyright and licensing\nrestrictions to vary prices around the\nworld – what’s known as “geo-blocking”.\nRestricting access to content based on geographic location is a popular strategy used by multinational tech giants so they can set different prices in different regions of the globe. The frustrating reality of geo-blocking is common for Australian consumers, who are often charged hefty mark-ups on products from companies such as Apple, Microsoft and Amazon, based on their IP address.\nWhile Amazon, Apple and Microsoft\nare among the main culprits, streaming\nservices such as Netflix and Hulu also\ndivide the globe into random segments,\nonly to grant access to those with a\ncertain IP address (the numerical\naddress that identifies your computer).\nin June this year\nfor a parliamentary\ninquiry into IT price\nbased on online prices of\nmore than 200 products,\nconsumers pay an\naverage of 50% more\nfor PC games, 34%\nmore for software,\n52% more for\niTunes music, 41%\nmore for computer\nhardware and a huge\n88% more for Wii games\nthan our US counterparts.\nAlthough these prices don’t take\ninto account the average 9.6% US sales\ntax (iTunes prices also don’t include\nAustralian GST), the mark-up remains\nFortunately for Australian consumers\nthere are other options that allow you to\nnavigate your way\nboundaries to access\nmore content and\n– see right.\nFor more information about shopping online, see Networking and internet.\nIs it legal?\nThe legality of\nis a grey\narea. Some copyright\nexperts claim those\nwho promote devices\nor programs that\nto infringe copyright\nare breaking the law.\nbelieves consumers who\ncircumvent measures used to\nprotect copyrighted content should be\nexempt from what could be construed\nas a breach of copyright simply because\nthey’re accessing products and services\nthat are being provided knowingly and\nwillingly by the copyright holder.\nIt is legal to use a virtual private\nnetwork (VPN) to protect\nyour online transactions from hackers,\nand there’s little definitive evidence as\nto whether other uses of a VPN breach\nIt’s also important to note that\ncircumventing geo-blocks may breach\nthe terms and conditions of the company\nyou’re buying from, and if discovered,\nyour account could be cancelled, losing\ncredit and access to your downloads.\nAccording to the ACCC, your rights\nwhen dealing with overseas-based\ncompanies to buy products may not\nbe protected by Australian law. While\nsome companies, such as Apple, have\ninternational warranties, others, such\nas Canon and Nintendo, say they refuse\nto recognise products purchased\ninternationally under domestic", "label": 1}
{"text": "U.K. surveillance proposal could reveal driving habits, sleep patterns — even infidelity, warn experts\nExplore This Story\nLONDON—British officials have given their word: “We won’t read your emails.”\nBut experts say that its proposed new surveillance program, unveiled last week as part of the government’s annual legislative program, will gather so much data that spooks won’t have to read your messages to guess what you’re up to.\nThe U.K. Home Office stresses that it is not seeking to read the content of every Britons’ communications, saying the data it was seeking “is NOT the content of any communication.” It is, however, seeking information on who’s sending the message, whom it’s sent to, where it’s sent from, and potentially other details including a message’s length and its format.\nThe government’s proposal is just a draft bill, so it could be modified or scrapped. But if passed in its current form, it would put a huge amount of personal data at the government’s disposal, which it could potentially use to deduce a startling amount about Britons’ private life — from sleep patterns to driving habits or even infidelity.\n“We’re really entering a whole new phase of analysis based on the data that we can collect,” said Gerald Kane, an information systems expert at Boston College. “There is quite a lot you can learn.”\nThe ocean of information is hard to fathom. Britons generate 4 billion hours of voice calls and 130 billion text messages annually, according to industry figures. In 2008 the BBC put the annual number of U.K.-linked emails at around 1 trillion. Then there are instant messaging services run by companies such as BlackBerry, Internet telephony services such as Skype, chat rooms, and in-game services liked those used by World of Warcraft.\nCommunications service providers, who would log the details of all that back-and-forth, believe that the government’s program would force them to process petabytes (1 quadrillion bytes) of information every day. It’s a mind-bogglingly large amount of data on the scale of every book, every movie, and every piece of music ever released.\nSo even without opening emails, how much can British spooks learn about who’s sending them?\nTHEY’LL SEE THE RED FLAGS\nDo you know how fast you were going?\nYour phone does.\nIf you sent a first text from London before stepping behind the wheel, and a second one from a service station outside Manchester only three hours later, authorities could infer that you broke the speed limit to cover the roughly 200 miles which separate the two.\nCrunching location data and communications patterns gives a remarkable rich view of a person’s lives — and their misadventures.\nKen Altshuler, of the American Academy of Matrimonial Lawyers, raves about the benefits which smartphones and social media have brought to savvy divorce attorneys. Lawyers don’t need sophisticated data mining software to spot evidence of infidelity or hints of hidden wealth when they review phone records or text traffic, he said.\n“One name, one phone number that’s not on our client’s radar, and our curiosity is piqued,” he said. The more the communication — a late-night text sent to a work colleague, an unexplained international phone call — is out of character, “the more of a red flag we see.”\nHOW DO YOU SLEEP?\nThe ebb and flow of electronic communication — that call to your mother just before bed, that early-morning email to your boss saying you’ll be late — frames our waking lives.\n“You can figure somebody’s sleep patterns, their weekly pattern of work,” said Tony Jebara, a Columbia University machine learning expert. In 2006, he helped found New York-based Sense Networks, which crunches phone data to do just that.\nJebara said that calls made from the same location between 9 and 5 are a good indication of where a person works; the frequency of email traffic to or from a person’s work account is a good hint of his or her work ethic; dramatic changes to a person’s electronic routine might suggest a promotion — or a redundancy.\n“You can quickly figure out when somebody lost their job,” Jebara said, adding: “Credit card companies have been interested in that for a while.”\nWHO’S THE BOSS\nDrill down, and communication can reveal remarkably rich information. For example, does office worker A answer office worker B’s missives within minutes of the message being sent? Does B often leave colleagues’ emails unanswered for hours on end? If so, B probably stands for “boss.”\nThat’s an example of what Jebara’s Columbia colleagues described as “automated social hierarchy detection,” a technique which can infer who gives the orders, who’s respected, and who’s ignored based purely on whose emails get answered and how quickly. In 2007 four of them analyzed traffic taken from the Enron Corporation’s email archive to correctly guess the seniority of several top-level managers.\nIntelligence agencies may not need such tools to untangle corporate flowcharts, but identifying ringleaders becomes more important when tracking a suspected terrorist cell.\n“If you piece together the chain of influence, then you can find the central authority,” he said. “You can figure that out without looking at the content.”\nWHO ARE YOU TALKING TO?\nSeeing how networks of people communicate isn’t just about finding your boss, it’s about figuring out who are your friends.\nPrograms already exist to determine the density of communications — something that can identify close groups of friends or family without even knowing who’s who. If one user is identified as suspicious, then the users closest to him or her might get a second look as well.\n“Let’s say we find out somebody in the U.K. is a terrorist,” said Kane. “You know exactly who he talks to on almost every channel, so BOOM you know his 10 closest contacts. Knowing that information not only allows you to go to his house, but allows you to go to their houses as well.”\nA SNOOP’S CHARTER?\nDetective work at the stroke of a key is clearly attractive to spy agencies. British officialdom has been pushing for the mass surveillance program for years, but civil libertarians are perturbed, branding the proposal a “snooper’s charter.”\nKane said that the surveillance regime had to be seen in the context of social networks such as Facebook and LinkedIn, where hundreds of millions of people were constantly volunteering information about themselves, their friends, their family and their colleagues.\n“There’s no sense in getting all Big Brother-ish that there are legitimate safeguards in place,” he said. “The bottom line is that we’re all leaving digital trails, everywhere, all the time. The whole concept of privacy is shifting daily.”\n- NEW Pet owner sues vets for pain and suffering over dog’s death\n- Police make second arrest in Tim Bosma murder investigation\n- Man hacked to death in London in suspected terror attack\n- 'The silence is deafening': Rob Ford stays mum on crack allegations\n- NEW A North Korean refugee’s tale of tragedy and bravery\n- Canada’s international reputation rising: Survey\n- As world gawks at Rob Ford scandal, Toronto police wait and watch\n- Boston bombings suspect's friend allegedly confessed to 2011 killings", "label": 1}
{"text": "Thirteen Ways Government Tracks Us\nTrue Activist— Privacy is eroding fast as technology offers government increasing ways to track and spy on citizens. The Washington Post reported there are 3,984 federal, state and local organizations working on domestic counterterrorism. Most collect information on people in the US. (Source)\nHere are thirteen examples of how some of the biggest government agencies and programs track people.\nOne. The National Security Agency (NSA) collects hundreds of millions of emails, texts and phone calls every day and has the ability to collect and sift through billions more. WIRED just reported NSA is building an immense new data center which will intercept, analyze and store even more electronic communications from satellites and cables across the nation and the world. Though NSA is not supposed to focus on US citizens, it does. (Source)\nTwo. The Federal Bureau of Investigation (FBI) National Security Branch Analysis Center (NSAC) has more than 1.5 billion government and private sector records about US citizens collected from commercial databases, government information, and criminal probes. (Source)\nThree. The American Civil Liberties Union and the New York Times recently reported that cellphones of private individuals in the US are being tracked without warrants by state and local law enforcement all across the country. With more than 300 million cellphones in the US connected to more than 200,000 cell phone towers, cellphone tracking software can pinpoint the location of a phone and document the places the cellphone user visits over the course of a day, week, month or longer. (Source)\nFour. More than 62 million people in the US have their fingerprints on file with the FBI, state and local governments. This system, called the Integrated Automated Fingerprint Identification System (IAFIS), shares information with 43 states and 5 federal agencies. This system conducts more than 168,000 checks each day. (Source)\nFive. Over 126 million people have their fingerprints, photographs and biographical information accessible on the US Department of Homeland Security Automated Biometric Identification System (IDENT). This system conducts about 250,000 biometric transactions each day. The goal of this system is to provide information for national security, law enforcement, immigration, intelligence and other Homeland Security Functions. (Source)\nSix. More than 110 million people have their visas and more than 90 million have their photographs entered into the US Department of State Consular Consolidated Database (CCD). This system grows by adding about 35,000 people a day. This system serves as a gateway to the Department of State Facial Recognition system, IDENT and IAFSIS. (Source)\nSeven. DNA profiles on more than 10 million people are available in the FBI coordinated Combined DNA index System (CODIS) National DNA Index. (Source)\nEight. Information on more than 2 million people is kept in the Intelligence Community Security Clearance Repository, commonly known as Scattered Castles. Most of the people in this database are employees of the Department of Defense (DOD) and other intelligence agencies. (Source)\nNine. The DOD also has an automated biometric identification system (ABIS) to support military operations overseas. This database incorporates fingerprint, palm print, face and iris matching on 6 million people and is adding 20,000 more people each day. (Source)\nTen. Information on over 740,000 people is included in the Terrorist Identities Datamart Environment (TIDE) of the National Counterterrorism Center. TIDE is the US government central repository of information on international terrorist identities. The government says that less than 2 percent of the people on file are US citizens or legal permanent residents. They were just given permission to keep their non-terrorism information on US citizens for a period of five years, up from 180 days. (Source)\nEleven. Tens of thousands of people are subjects of facial recognition software. The FBI has been working with North Carolina Department of Motor Vehicles and other state and local law enforcement on facial recognition software in a project called “Face Mask.” For example, the FBI has provided thousands of photos and names to the North Carolina DMV which runs those against their photos of North Carolina drivers. The Maricopa Arizona County Sheriff’s Office alone records 9,000 biometric mug shots a month. (Source)\nTwelve. The FBI operates the Nationwide Suspicious Activity Reporting Initiative (SAR) that collects and analyzes observations or reports of suspicious activities by local law enforcement. With over 160,000 suspicious activity files, SAR stores the profiles of tens of thousands of Americans and legal residents who are not accused of any crime but who are alleged to have acted suspiciously. (Source)\nThirteen. The FBI admits it has about 3,000 GPS tracking devices on cars of unsuspecting people in the US right now, even after the US Supreme Court decision authorizing these only after a warrant for probable cause has been issued. (Source)\nThe technology for tracking and identifying people is exploding as is the government appetite for it.\nSoon, police everywhere will be equipped with handheld devices to collect fingerprint, face, iris and even DNA information on the spot and have it instantly sent to national databases for comparison and storage.\nBloomberg News reports the newest surveillance products “can also secretly activate laptop webcams or microphones on mobile devices,” change the contents of written emails mid-transmission, and use voice recognition to scan phone networks. (Source)\nThe advanced technology of the war on terrorism, combined with deferential courts and legislators, have endangered both the right to privacy and the right of people to be free from government snooping and tracking. Only the people can stop this.", "label": 1}
{"text": "SRTP (Secure Real-Time Transport Protocol or Secure RTP) is an extension to RTP (Real-Time Transport Protocol) that incorporates enhanced security features. Like RTP, it is intended particularly for VoIP (Voice over IP) communications.\nSecuring VoIP Networks: Threats, Vulnerabilities and Countermeasures\nIn an excerpt from the book Securing VoIP Networks:...(SearchSecurity.com)\nExcerpt: Securing VoIP Networks: Threats, Vulnerabilities and Countermeasures\nAuthors Peter Thermos and Ari Takanen discuss t...(SearchCIO.com.au)\nSRTP was conceived and developed by communications experts from Cisco and Ericsson and was formally published in March 2004 by the Internet Engineering Task Force ( IETF ) as Request for Comments (RFC) 3711. SRTP uses encryption and authentication to minimize the risk of denial of service( DoS ) attacks. SRTP can achieve high throughput in diverse communications environments that include both hard-wired and wireless devices. Provisions are included that allow for future improvements and extensions.", "label": 1}
