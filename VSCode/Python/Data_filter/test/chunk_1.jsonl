{"text": "Well, security should be no different. To build secure mobile apps, there are certain things that we're just going to have to do, and darn near every single time we write code.\nSo, what security goodies are in your bag of tricks? Here's some food for thought on some things you might find useful, in no particular order:\n- Protecting secrets at rest --\nInevitably, we need to protect some data locally on the mobile device. Of course, the principles of sound design should guide us to minimize the data we store locally on the device. Some argue that we shouldn't really store anything of value locally, but our users don't always share that view. So we need to protect data locally: usernames (a la remember me button), passwords (best avoided, but for some consumer grade apps, it's acceptable), session tokens, customer names, and on and on.\nWe need a reliable set of tools that help us protect things locally. Both iOS and Android give us some ability to do that, but for times when we cannot rely on the OS, we need more. SQLcipher is one such example. It's an open source extension of SQLite that does AES-256 using the venerable OpenSSL library, and it works on Android and iOS.\n- Protecting secrets in transit --\nOf course, any modern OS and app can do SSL encryption, but things aren't always that simple. Sometimes we want to more strongly verify the SSL certificates on both ends of the connection. Sometimes we want to encrypt data that doesn't play nicely with TCP connections, like Voice over IP data that is best suited for UDP.\n- Server connections --\nWe often need to connect to different types of back-end services, and of course those connections need to be established securely. At a network layer, we can use SSL, like I've described above, but at a data layer, we also need to ensure our connection is strong. For example, if we're connecting to an SQL database of some sort, we need to ensure our SQL API is immutable, and not subject to SQL injection and such.\n- Authentication --\nWe need strong mutual authentication among all of our application components, of course, but we also need to authenticate users and any other entities our app interacts with. We can use x.509 certificates in some cases. Other times we need to use simple username/password combinations. Either way, though, the authentication needs to be mutual and worthy of trust. We have to avoid mistakes like hard coding credentials into our code.\n- Authorization --\nOnce a user or entity is identified and authenticated, we then need to ensure that it is able to get to all the data and resources it needs, of course. But we also need to ensure that it is not able to get to data and resources that it doesn't need -- that it's not authorized to access. That means we need to weave access control throughout our system, and it needs to be consistently applied across our architecture.\n- Input validation --\nAll data entering our application, through whatever input source possible, needs to be validated. For example, if we're expecting a credit card number, then our code should validate that a credit card number has indeed been input, and nothing other than a credit card number. That's called input validation, and it's vital we get it right. Input validation problems lead to cross site scripting and a myriad of other security problems, after all. But there are many decisions to make, like where do we perform input validation? Our design time choices can have vast impacts on our application's ability to perform its given tasks securely.\n- Output escaping --", "label": 1}
{"text": "Strictly speaking, the use of the term \"signature\" about HMAC is improper; it is widespread, but still incorrect: signatures are about asymmetric algorithms with a public and a private key, such as RSA.\nHMAC uses a secret key (i.e. a bunch of arbitrary bytes) which is used for computing the MAC and for verifying it (it is actually verified by recomputing it). So, in your problem, yes, the server must store either the secret key, or some data which is enough to recover it.\nNote that the secret key K can be derived from the password in a non-invertible way. E.g. through a hash function or, better yet, with a Key Derivation Function. The server will store the key K \"in plaintext\" and knowing key K is enough to produce valid HMAC values. However, this forces an attacker to use some specific software for that, not the standard client which requests a user password. Depending on the context and your attack model, this may or may not be a security improvement.\nA way to achieve what you are looking for, but with higher complexity then a plain HMAC, is to use SRP. SRP is an asymmetric key exchange protocol with mutual password-based authentication, with the following characteristics:\n- No need for public key distribution (PKI, certificates...).\n- Client authenticates server and server authenticates client, in the same pass, even in the presence of active attackers (\"Man-In-The-Middle\" attackers are defeated).\n- No active or passive attackers learns enough information to perform offline dictionary attacks (a dictionary attack is guessing the password by trying random words; the attack is offline if it can be done without interacting with the honest client or server for each guess).\n- What the server stores is not enough to learn the password or impersonate the client (but it allows offline dictionary attacks, which is unavoidable).\nThe key which results from the SRP protocol can then be used for a MAC algorithm such as HMAC. It needs not be stored: it is just kept in RAM for the duration of the session.\nSRP can be integrated in TLS, as explained in RFC 5054. The easiest, most standard supported way to use SRP in your context would be to use HTTPS (i.e. HTTP within a SSL/TLS tunnel) with the TLS part using SRP for key exchange. GnuTLS is an opensource implementation of SSL/TLS which supports SRP.", "label": 1}
{"text": "Not only are there multiple agendas at play, given that hardware needs one thing, operating systems something else, app developers something different again. On top of that we have multiple platforms to think about, besides the fact that technology is changing fast: new apps are coming out on different platforms on a daily basis and we’re rapidly moving towards a location-aware world where everything around us is coming to life not just in front of our eyes, but on our devices too.\nSo what to do or can be done?\nMaking use of location datatouches upon delicate privacy issues, since it enables verifying someone‘s location without the person's consent. Strict ethics and security measures are strongly recommended for services that employ positioning, and the user should be giving an informed, explicit consent to a service provider before positioning data from the user's mobile phone can be computed.\nIn Europe, where most countries have a constitutional guarantee on the secrecy of correspondence, location data obtained from mobile phone networks is usually given the same protection as communication itself. The United States, however, has no explicit constitutional guarantee on the privacy of telecommunications, so use of location data is limited by law. In Germany, even obviously criminal intent may not be inferred by such means, although technically possible. Officially, only authorities (like the police) can obtain permission to position phones in emergency cases, in contrast to the current U.S laws that allow tracking suspects – even access a mobile phone's internal microphone to eavesdrop on local conversations while the phone is switched off. By the way, this is a technology that China proposed to use to track commuting patterns of Beijing city residents.\nOne implication of LBS is that data about a subscriber's location and historical movements should be owned and controlled by the network operators, including mobile carriers and mobile content providers. Beside the solution of a legal framework several technical approaches to protect privacy exist, using privacy-enhancing technologies (PETs), such as basic on/off switches to sophisticated anonymization techniques, which are e.g. offered by Google Latitude. Another set of techniques included in the PETs are the location obfuscation techniques, which slightly alter the location of the users in order to hide their real location while still being able to represent their position and receive services from their LBS provider.\nFact is that smartphone devices tend to go with their owners wherever they are and increasingly becoming a payment device, too. But why should smartphone users make use of a trackable black box that makes them feel uncomfortable due to security and location-tracking issues inherent in such transactions? To give the development of the mobile payment industry a push forward, we definitely have to find a good answer to the question.\nDebates sparked last year after monitoring software installed on millions of smartphones had been discovered. In the US the proposal was triggered that carriers and phone makers must inform consumers about the presence of monitoring software and gain their \"express consent\" before collecting and transmitting information from phones. Although all manufacturers say that this software is used only as a diagnostics tool to improve network and service performance, congressmen started denouncing the use of it and class-action lawsuits were filed, followed by a draft legislation that would require disclosure of monitoring software when a consumer buys a mobile phone. This legislation would in addition prevent manufacturers from collecting and transmitting information unless consumer consent is obtained, and would outline security policies companies would have to follow when receiving personal information from smartphones.\nA combination of appropriate technology, education and an opt-in processes, making sure that companies get explicit consent from users in order to share their location data, is probably the best solution. On top it can’t hurt to reconsider what level of privacy is actually needed and desired by users, don’t you think?\nBy Daniela La Marca", "label": 1}
{"text": "A zombie machine is a computer connected to the Internet that has been successfully attacked by a computer virus, worm, or Trojan horse. A hacker will compromise thousands of such machines to create a “Zombie Army” or a “BotNet.” With this network he can then launch spam attacks, attack Web sites, conduct phishing attacks, spread computer viruses, launch DoS attacks, download pornography, or steal personal information. By using zombie machines, spammers can hide the source of spam and hackers can hide the source of malicious content. Using zombie machines also provides hackers with extra bandwidth at the expense of the owner of the machine.\nMost owners of zombie machines are unaware that their machine is being used to launch such attacks. It is difficult to check whether your PC is a zombie, but some symptoms are a suddenly slow broadband connection, an unresponsive mouse or keyboard, excessive hard drive activity, or bounce notifications from people you’ve never tried to contact.\nDelete suspicious emails with attachments: Attachments are the main way malware gets onto your computer. Attachments include office document files (e.g., with .doc or .xls suffixes), program files (e.g., with .exe or .bat suffixes), and compressed files (e.g., with .zip suffixes), all of which can contain malware. The CERT Coordination Center advises users to apply the so-called \"KRESV\" test to detect suspicious emails. KRESV stands for:\n- Know: Do you know the sender?\n- Received: Have you received email from the sender before?\n- Expect: Are you expecting the e-mail?\n- Sense: Do the subject header and attachment name make sense?\n- Virus: Does it contain a virus? You will need antivirus software to check this.\nIf an email with attachments fails any of these tests, delete it. If you know the sender, contact him or her to make sure that the message is legitimate.\nInstall security patches: New security problems are constantly being found in software that has already been released. Software vendors therefore make updates or security \"patches\" available from time to time that fix these problems. A patch is a downloadable piece of software that repairs a security problem or other \"hole\" in the software. Since most intruders exploit these known weaknesses, failing to download a patch creates an unnecessary risk. The unpatched hole could serve as an entry point for hackers who want to examine, damage, or exploit the information and services on your computer.\nPerform frequent backups: Save your important data on a regular basis so that you can recover from a malware attack or intrusion. Thumb drives, CDs, and DVDs are good storage and transport media for large amounts of data. If possible, store your backup media in different location from the computer itself to keep them from both being destroyed in a fire or other disaster.\nAnti-virus software: The popularity of the Microsoft Windows operating system makes it a prime target for hackers and other virus writers, so anti-virus software is crucial for users of this system. Anti-virus software works by identifying files that match definitions of known viruses and keeping them from infecting the system. Make sure that your virus definitions are kept up to date by automatically or manually downloading them from your software manufacturer's Web site. Do not install more than one anti-virus program because incompatibility issues between the programs may end up leaving your system unprotected.\nTwo popular anti-virus packages are Symantec’s Norton AntiVirus and McAfee AntiVirus . AVG , AntiVir and ClamWin are free alternatives. The major anti-virus programs, such as Symantec and McAfee, can protect against worms and Trojan horses as well as viruses.\nPDA and mobile phone anti-virus applications normally interact with the full version on a PC and hold fewer virus definitions. New virus updates are automatically transferred from your desktop computer each time you synchronize your PDA. Therefore it is important to keep your desktop computer's anti-virus software updated and synchronize your PDA regularly. Some commonly used anti-virus packages are Trend Micro's PC-cillin for Wireless and Symantec AntiVirus for Windows Mobile .\nFirewall: A firewall is like a security guard for your computer that monitors the traffic into and out of your computer. A firewall is your first line of defense against intrusions, especially Trojan horses. One popular firewall is Symantec's Norton Personal Firewall . The Windows operating systems such as Windows XP and Windows Vista include a firewall that is turned on automatically. This built-in firewall is described in more detail on the Microsoft site .", "label": 1}
{"text": "Data Removal Recommendations\nFor the general user, the delete or format command appears to be the logical method of removing unwanted data files. These methods, however, are like sweeping something under the carpet: you may not be able to see it, but it's still there. All that deletion has done is remove the pointer to the files, with the data itself residing in unallocated space on the hard drive. This means that data recovery is possible using various software tools.\nWhen sensitive information is stored on the hard drive of a machine that is to be surplussed or transferred to another individual or department, it is therefore imperative that extra measures be taken to wipe clean the hard drive before the computer leaves your area of responsibility. This document describes some common methods and software to assist you with the sanitization process. It also includes links to articles that provide detailed technical descriptions of what occurs during this process.\n2.0 Sanitizing Techniques\nAs described in the much-referenced article Remembrance of Data Passed: A Study of Disk Sanitization Practices, the three most common techniques for properly sanitizing hard drives are:\n1. Physically destroying the drive, rendering it unusable. This is a good alternative for defective hard drives or those that would be too costly to repair. For added security, the disk should be overwritten or degaussed prior to destruction.\n2. Degaussing the drive to randomize the magnetic domains – most likely rendering the drive unusable in the process. Degaussing, or demagnetizing, applies a reverse magnetizing field to data stored on magnetic media, erasing the contents by returning the magnetic flux to a zero state.\n3. Overwriting the drive's data so that it cannot be recovered. Overwriting replaces previously stored data on a drive or disk with a predetermined pattern of meaningless information, rendering the data unrecoverable.\nThe SANS white paper \"Deleting Sensitive Information: Why hitting delete isn't enough\"1 explains:\n\"...Overwriting data once is not usually good enough to prevent data recovery, instead it is recommended that a minimum of three passes are made writing alternating zero and one patterns over the data and then further passes with random data, the more passes the better the chance that no data can ever be recovered.\"\nNOTE: When removing sensitive information, don't forget storage devices such as thumbdrives, back-up external hardrives and CDs. Also, be sure to erase any stored names and numbers from phones and fax machines.\n3.0 Suggested Software\nThe following chart is a collection of disk wiping software recommended by departmental computing coordinators (DCCs) or listed on a variety of other University and security sites. The inclusion of any title does not indicate an endorsement by Brown University or the CIS department, and has only been provided as an aide in making a decision that best matches your specific needs.\n|Darik's Boot and Nuke (DBAN)\n||Shareware||Windows 7, Vista & XP||\nSelf-contained boot disk that automatically deletes the contents of any hard disk that it can detect; prevents all known techniques of hard disk forensic analysis. Designed for consumer use. Professional data erasure tools are recommended for company and organizational users. (It does not provide users with a proof of erasure, such as an audit-ready erasure report.)\n|Disk Utility||Free||Mac OS X||Securely erases data as well as disk’s empty space (latter prevents the recovery of erased files without erasing the entire disk)|\n|DTI Disk Wipe\n||$49.00||Windows 7, Vista & XP||Permanently erases and destroys all existing data on a hard disk|\n|East-Tec Eraser 2013||$39.95||Windows 8, 7, Vista & XP||Exceeds DoD standards; for the permanent erasure of digital info, including confidential documents, evidence of online activities. Also can be used to erase online activity and clean out browsers.|\n|East-Tec DisposeSecure 5||$19.95 (1 sanitization and 1 year of updates and support)||\nFor computer to create boot disk: Windows 7, Vista & XP\n|Designed to remove all traces of data from hard disk, overwriting all data from every sector|\n||Free (shareware)||Windows 7, Vista & XP||Completely removes sensitive data from a hard drive by overwriting it several times with carefully selected patterns|\n||Free version, Pro versions start at $39.95||\nFor computer to create boot disk: Windows 8, 7, Vista & XP\n|Powerful and compact software allowing you to destroy all data on hard disks, USB drives and floppy disks completely, excluding any possibility of future recovery of deleted files and folders; a hard drive and partition eraser utility|\n|Linux||Free||Linux||Use built-in dd, wipe and shred tools|\n||$49.99||Windows 7, Vista & XP||\nIncludes Disk Cleaner (with \"bleach\" feature) to permanently erase all unwanted files\n|Paragon Disk Wiper\n|Windows 7, Vista & XP||Disk Wiper Pro meets DoD sanitizing standards; includes 10 different disk sanitization methods|\n|sDelete||Free (Microsoft utility)||Windows 7, Vista & XP||Securely overwrite your sensitive files and cleanse your free space of previously deleted files using this DoD-compliant secure delete program.|\n|ShredIt||Free trial, $24.95 (download version)||Windows 7, Vista & XP, Mac OS X or earlier||Easy interface, configurable overwrite pattern and number of overwrites|\n||Shareware||Linux, Unix||Uses Gutmann's erase patterns, erasing single files and accompanying metadata or entire disks|\n|WipeDrive / WipeDrive with System Saver\n||$19.95 / $39.95||Bootable PC disk, for all Windows and Mac computers||DoD approved; securely erases IDE and SCSI drives; unlimited wiping of 5 unique hard drives|\n4.0 Removal Tips\nEach of the software products listed above comes with specific instructions, some with an easy-to-use wizard interface. KillDisk (recommended by some DCCs) is the software of choice at Northern Illinois University. Their support for this product includes detailed instructions on its use.\nDell offers an overview document Erasing Data from Your Hard Drive and a link to CNET's (download.com) listing of rated disk wiping software.\nIn addition to the software offered above, Mac computer hard drives can be cleared by zeroing their data. Note that zeroing data (aka \"low level\" format) may take a long time and depends on the hard disk size. It is recommended to use the \"8-way random\" feature in conjunction with the \"zero all data\" option.\n- Mac OS X: How to Zero All Data on a Disk (http://support.apple.com/kb/HT1820)\n- Mac OS X Disk Utility 12.x: Erase a Disk, CD or DVD (http://support.apple.com/kb/PH5849)\n4.3 Unix / Linux / Solaris\n5.0 Related Links\nCompendium of disk wiping software:\n- Darik's Boot and Nuke (DBAN): sourceforge.net/projects/dban/\n- Disk Utility: support.apple.com/kb/PH5849\n- DTI Disk Wipe: dtidata.com/products_disk_wipe.asp\n- East-Tec Eraser 2013: east-tec.com/eraser/\n- East-Tec DisposeSecure 5: east-tec.com/disposesecure/\n- Eraser: eraser.heidi.ie/\n- KillDisk (Active@KillDisk): killdisk.com/\n- Linux: linux.com/learn/tutorials/442455-wiping-your-disk-drive-clean\n- Norton Utilities: us.norton.com/norton-utilities/\n- Paragon Disk Wiper: disk-wiper.com/\n- sDelete: technet.microsoft.com/en-us/sysinternals/bb897443.aspx\n- ShredIt: mireth.com/shredit.html\n- Wipe: sourceforge.net/projects/wipe/\n- WipeDrive: whitecanyon.com/wipedrive-erase-hard-drive.php\n- Securely Disposing of Computers and Other Storage Devices by Rob Lee, SANS' OUCH! newsletter (January 2011)\n- Sanitizing Media (The Linux Method) by Hal Pomeranz, SANS Computer Forensics blog (June 2010)\n- Precautions When Selling, Trading, or Sending a PC to Salvage or to a Repair Shop by H. D. Knoble, Penn State (May 2007)\n- Special Publication 800-88: Guidelines for Media Sanitization by the National Institute of Standards and Technology, NIST (September 2006)\n- Secure File Deletion, Fact or Fiction? by John R. Mallery, SANS Institute (June 2006)\n- Remembrance of Data Passed: A Study of Disk Sanitization Practices by Simson L. Garfinkel and Abhi Shelat, MIT, IEEE Computer Society, Security & Privacy, vol. 1, no. 1 (2003)\n- 1 Deleting Sensitive Information:Why Hitting Delete Isn't Enough by Hans Zetterstrom (2002)\n- What You Don't See On Your Hard Drive by Brian Kuepper, SANS Institute (April 2002)\n- Securely Deleting Files by John Kinney, SANS Institute (2002)\nRelated sites at other universities:\n- Carnegie Mellon: Data Sanitization and Disposal Tools\n- Indiana University Information Security Office: Securely Removing Data\n- Michigan State University: How to Sanitize Data for Disposal\n- Stanford University: Disk and Data Sanitization Policy and Guidelines\n- Syracuse University: Data Sanitizing Policies\n- Univ. of Minnesota OIT Security: Destroying Data\n- Univ. of Pennsylvania Information Security: Computer Recycling and Disposal Options | Cleaning Out Old Computers\nInternally Reviewed and Updated: February 27, 2013", "label": 1}
{"text": "Bot is a contraction of the word ‘robot’. These are small programs that are inserted on computers by attackers to allow them to control the system remotely without the user’s consent or knowledge.\nBotnets are groups of computers infected by bots and controlled remotely by the owner of the bots – known as the bot herder. This person can then send commands which include updating the bot, downloading a new threat, displaying advertising, sending spam or launching denial of service attacks.\nThe compromised computer is known as a zombie. Some botnets can have tens of thousands of zombies under their control.\nThe following image illustrates how botnets operate:\nHere, you can also see a video describing how the botnets work:\nEmail scams are designed to defraud users, often using the lure of large windfalls or lottery wins but which require a sum of money to be paid in advance. They are really a type of hoax used maliciously for financial gain.\nPerhaps one of the best-known email scams is the Nigerian letter scam and its many variants. The initial email tries to convince recipients that there are several million dollars which cannot legally leave Nigeria (or wherever) unless transferred to a foreign account. The fraudsters offer a commission to the recipient of the email for helping them get the money out of the country, but ask for an advanced fee from the intended victim (under a myriad pretexts depending on the particular variation of the scam). However, the whole operation is a fraud.\nMany users have fallen victim to another type of scam which uses catastrophes as a bait, like the Katrina, which devastated New Orleans in 2005, or the tsunami that devastated South-East Asia in 2004. This involves emails asking users to donate money to help the victims of the catatrophes. Needless to say, the victims will not see a penny of any money sent by recipients of the email.\nSpyware programs are applications that compile information about a person or organization without their consent or knowledge. These programs normally steal data about users which could be used for advertising or for other financial gain. The type of information stolen by these programs varies considerably: email login details, IP and DNS addresses of the computer, or users’ Internet habits, among others.\nSpy programs are created by cyber-crooks, who sell them on the black market to be used in online fraud and other cyber-crime.\nSpyware is installed on computers without the user’s knowledge. It can be installed when downloading certain content from the Web or from P2P networks, when installing freeware, or simply when visiting dubious websites. Generally, these spy programs are installed when the user agrees to install other applications, which unbeknown to users, include a caveat in the legal agreement whereby users agree to install the spyware.\nThere is some controversy surrounding what is actually spyware, as some people consider adware or even some toolbars to be variations of spyware. While this may be true to a certain extent, adware programs, as such, are not used with criminal intent, but to advertise products and services.\nHow can you protect yourself?\nIt is very important to have an antivirus program that includes a spam filter installed and up-to-date. Any of Panda Security’s solutions will protect you against these kind of threats. Aditionally, Below you will find a series of tips on how to reduce the risk of falling victim to these threats:\n- Check the source of information received. Don't reply to any email message that asks for your personal or financial information.\n- If you don’t have an antivirus, you can install any of Panda Security’s programs to give you full protection against these and other threats.\n- Analyze you computer for free and check out if you computer is Botnets free.\nDownload Panda Security", "label": 1}
{"text": "Get on-the-go access to the latest insights featured on our Trustworthy Computing blogs.\nWin32/Lethic is a trojan that communicates with a remote server to distribute spam. Variants of Lethic install executable files with varied file names such as “shelldm.exe” or “xcllsx.exe”. The malware loads as a process when Windows starts.\nThe trojan establishes a connection to remote servers using varied TCP ports, such as 1430, 8900, 8090 and so on. It communicates with servers with names such as “dqglobex.com”, “verywellhere.cn”, “iamnothere.cn” among others. Once connected, the trojan allows unauthorized use of the affected computer, including distributing spam.\nForefront Online Protection for Exchange (FOPE) consists of layered technologies to actively help protect businesses’ inbound and outbound e-mail from spam, viruses, phishing scams, and e-mail policy violations.\nImage 1 - Forefront Online Protection for Exchange diagram\nAccording to FOPE spam statistics, Win32/Lethic produces a high volume of spam and thus has been selected for addition this month to the Microsoft Malware Removal Tool (MSRT). Win32/Lethic is not the biggest botnet in terms of IP addresses, however, it is known for sending many messages into a single envelope.\nBelow, you can see the difference in spam distribution models between two malware, Win32/Rustock and Win32/Lethic. Notice that in Rustock, the spam message is a 1:1 ratio where Lethic is 1:many.\nImage 2 – Win32/Rustock spam distribution model\nImage 3 – Win32/Lethic spam distribution model\nYou can do more to protect your Internet experience by running a full AV solution, such as Microsoft Security Essentials, for real-time protection. Download and install Microsoft Security Essentials from http://www.microsoft.com/security_essentials/.\nPatrick Nolan, MMPC", "label": 1}
{"text": "SSH File Transfer Protocol\nIn computing, the SSH File Transfer Protocol (also Secure File Transfer Protocol, or SFTP) is a network protocol that provides file access, file transfer, and file management functionalities over any reliable data stream. It was designed by the Internet Engineering Task Force (IETF) as an extension of the Secure Shell protocol (SSH) version 2.0 to provide secure file transfer capability, but is also intended to be usable with other protocols. The IETF Internet Draft states that even though this protocol is described in the context of the SSH-2 protocol, it could be used in a number of different applications, such as secure file transfer over Transport Layer Security (TLS) and transfer of management information in VPN applications.\nThis protocol assumes that it is run over a secure channel, such as SSH, that the server has already authenticated the client, and that the identity of the client user is available to the protocol.\nCompared to the earlier SCP protocol, which allows only file transfers, the SFTP protocol allows for a range of operations on remote files – it is more like a remote file system protocol. An SFTP client's extra capabilities compared to an SCP client include resuming interrupted transfers, directory listings, and remote file removal. \nSFTP attempts to be more platform-independent than SCP; for instance, with SCP, the expansion of wildcards specified by the client is up to the server, whereas SFTP's design avoids this problem. While SCP is most frequently implemented on Unix platforms, SFTP servers are commonly available on most platforms.\nThe protocol itself does not provide authentication and security; it expects the underlying protocol to secure this. SFTP is most often used as subsystem of SSH protocol version 2 implementations, having been designed by the same working group. However, it is possible to run it over SSH-1 (and some implementations support this) or other data streams. Running SFTP server over SSH-1 is not platform independent as SSH-1 does not support the concept of subsystems. An SFTP client willing to connect to an SSH-1 server needs to know the path to the SFTP server binary on the server side.\nFor uploads, the transferred files may be associated with their basic attributes, such as timestamps. This is an advantage over the common FTP protocol, which does not have provision for uploads to include the original date/timestamp attribute without help.\nHistory and development \nThe Internet Engineering Task Force (IETF) working group \"Secsh\" that was responsible for the development of the Secure Shell version 2 protocol (RFC 4251) also attempted to draft an extension of that standard for secure file transfer functionality. Internet Drafts were created that successively revised the protocol into new versions. The software industry began to implement various versions of the protocol before the drafts were standardized. As development work progressed, the scope of the Secsh File Transfer project expanded to include file access and file management. Eventually, development stalled as some committee members began to view SFTP as a file system protocol, not just a file access or file transfer protocol, which places it beyond the purview of the working group.\nVersions 0 - 2 \nPrior to the IETF's involvement, SFTP was a proprietary protocol of SSH Communications Security, designed by Tatu Ylönen with assistance from Sami Lehtinen in 1997. Differences between versions 0 - 2 and version 3 are enumerated upon in section 10 of draft-ietf-secsh-filexfer-02.\nVersion 3 \nAt the outset of the IETF Secure Shell File Transfer project, the Secsh group stated that its objective of SSH File Transfer Protocol was to provide a secure file transfer functionality over any reliable data stream, and to be the standard file transfer protocol for use with the SSH-2 protocol.\nDrafts 00 - 02 of the IETF Internet Draft define successive revisions of version 3 of the SFTP protocol.\n- SSH File Transfer Protocol, Draft 00, January 2001\n- SSH File Transfer Protocol, Draft 01, March 2001\n- SSH File Transfer Protocol, Draft 02, October 2001\nVersion 4 \nDrafts 03 - 04 of the IETF Internet Draft define version 4 of the protocol.\n- SSH File Transfer Protocol, Draft 03, October 2002\n- SSH File Transfer Protocol, Draft 04, December 2002\nVersion 5 \nDraft 05 of the IETF Internet Draft defines version 5 of the protocol.\nVersion 6 \nDrafts 06 - 13 of the IETF Internet Draft define successive revisions of version 6 of the protocol.\n- SSH File Transfer Protocol, Draft 06, October 2004\n- SSH File Transfer Protocol, Draft 07, March 2005\n- SSH File Transfer Protocol, Draft 08, April 2005\n- SSH File Transfer Protocol, Draft 09, June 2005\n- SSH File Transfer Protocol, Draft 10, June 2005\n- SSH File Transfer Protocol, Draft 11, January 2006\n- SSH File Transfer Protocol, Draft 12, January 2006\n- SSH File Transfer Protocol, Draft 13, July 2006\nSFTP client \nThe term SFTP can also refer to Secure file transfer program, a command-line program that implements the client part of this protocol. As an example, the sftp program supplied with OpenSSH implements this.\nSome implementations of the scp program support both the SFTP and SCP protocols to perform file transfers, depending on what the server supports.\nSFTP server \nThere are numerous SFTP server implementations both for UNIX, Windows and z/OS. The most widely known is perhaps OpenSSH, but there are also proprietary implementations. Typically the port used is 22. SFTP file transfer protocol is part of SSH protocol suite.\nSFTP proxy \nIt is difficult to control SFTP transfers on security devices at the network perimeter. There are standard tools for logging FTP transactions, like TIS fwtk or SUSE FTP proxy, but SFTP is encrypted, rendering traditional proxies ineffective for controlling SFTP traffic.\nThere are some tools that implement man-in-the-middle for SSH which also feature SFTP control. Examples of these tools include Shell Control Box from Balabit  and FileGate SFP from Presaris. These provide functions such as SFTP transaction logging and logging of the actual data transmitted on the wire.\nSee also \n- SSH Communications Security\n- Comparison of SSH servers\n- Comparison of SSH clients\n- AbsoluteTelnet - SSH client that includes a GUI SFTP client for file transfer.\n- SSHFS - Mounting remote filesystem using SFTP and SSH\n- Category:FTP clients\n- Category:SFTP clients\n- Lsh - A GNU SSH-2 and SFTP server for Unix-like OSes\n- List of file transfer protocols\n- Barrett, Daniel; Richard E. Silverman (2001), SSH, The Secure Shell: The Definitive Guide, Cambridge: O'Reilly, ISBN 0-596-00011-1\n- \"Secsh Status Pages\". Tools.ietf.org. Retrieved 2012-08-20.\n- \"ietf.secsh - Formal consultation prior to closing the secsh working group - msg#00010 - Recent Discussion\". Osdir.com. 2006-08-14. Retrieved 2012-08-20.\n- \"OpenBSD \"man\" page for the \"sftp\" command: \"See Also\" section\". OpenBSD.org. Retrieved 2012-12-27.\n- \"Record SSH/RDP/Citrix into Audit Trail - Activity Monitoring Device\". Balabit.com. Retrieved 2012-08-20.\n- \"FileGate\". Presaris. Retrieved 2012-08-20.\n- Chrooted SFTP with Public Key Authentication – Integrating SFTP into FreeBSD production servers using the public key cryptography approach", "label": 1}
{"text": "First, I learned a lot of my information from a combination of my amateur radio experience and an awesome talk I sat in at DEFCON 18. The majority of satellite systems are simple repeaters. The signal that comes in on a transponder is cleaned, amplified, and retransmitted. If you know the location and input frequency, and you pump more effective radiated power than anybody else, you win.\nMany satellites also require command modules. These are used to interpret instructions to boost back into orbit or at the end of life, de-orbit into a \"graveyard\" pattern (or right into the atmosphere itself). Because most satellite systems are custom, it is a real crapshoot what you see for commands and security. I suspect that most command sequences are unencrypted and rely on the fact that a MITM attack on something in space is fairly hard.\nFrequencies vary wildly from MHz to several tens of GHz. Your equipment needs to put out the right frequency through a dish that is the right size. Legally speaking, you will at a minimum foul the FCC or your national equivalent, by violating regulations on licensed broadcasting. Also, \"birds\" and airtime are expensive, so the civil liability if found can be bankrupting.\nAs far as taking a satellite transponder over is concerned, security relies on rarity of attacks, detection, and triangulation of the signal source. Then people come knocking on your door.\nFinding a bird\nFirst, you've got to have a target. Some satellites are geostationary, so they're easy. Other satellites have orbits that sending them in offset patterns around the world. The satellite will come into view at different elevations in the sky tracing different paths, so you'll need to know where it will be and how it will move in order to communicate.\nCommunications satellites tend to either be geostationary or part of a cluster of many satellites such that one or more is always in view of at least one ground station and any other point on the planet.\nThere are websites all over the place for this, and they often end up with military / disavowed satellites listed as people will track them with a telescope and then wonder why that one isn't listed yet.\nTalking to a bird: Bands\nSatellites operate on different frequencies, and the antenna used has to be sized to the frequency of the satellite. Most satellites operate in the microwave spectrum. The ubiquitous (in the United States) DirecTV / Dish Network antennas are usually on the higher end (smaller wavelength) of the spectrum. Because your signal has a lot of travel in its future and your target is small, your goal is to direct as much power in one direction as possible. Anything sent off to the sides, earth, etc. is wasted energy, so you will want an appropriately-sized high-gain antenna. Antenna design can be learned from amateur radio books on the topic.\nBefore someone chimes in and says, \"You don't NEED a directional antenna and tracking motor,\" that's true... but it will help a hell of a lot. Just because your spot messenger or GPS doesn't have one doesn't mean you shouldn't use one if you can. It will keep your signal where you want it and limit the possibility of interference from or with other things using the same frequency. It also means that it will be harder for somebody to hunt you down. Being nicked just because you let strangers hear you might have some costs associated.\nTalking to a bird: Protocol\nNow we're getting a bit trickier. Some satellites are very simple, particularly amateur radio satellites. They receive a signal and they transmit that signal back. There are different variations of protocol, polarisation, modulation (QAM is a good one to understand), etc. If your target does more cleanup than just setting a noise floor and spitting things back out, you'll need to know that information as well.\nHigher-level protocols may be standard IP/TCP, plaintext, encrypted, or some totally imaginary 17 bit codeword system that was dreamed up by a guy like Mel.\nYou need to deliver more power to the right place with the appropriate protocol. Because almost every satellite is a custom design, that's challenging. If you goal is beyond simple re-broadcast, you're up against a big black box every time. Computers are small, low-power, and probably have next to nothing on them.\nThe best bet for MITM\nIf you can't afford to launch your own satellite, figure out where the ground station is and fly over it. Small aircraft are relatively cheap to rent (under $100 / hour to operate), tethered balloons may get high enough to have an effective angle, and if you're quite sneaky you can put something on the transmitter feed line itself.\nMany smaller organizations rent their satellite time. I learned when I was 11 that the guy running the local news station's satellite truck is bored as hell when they're in between shots and will definitely show you all the cool things about his rig. Whatever he's renting is probably one of the easier things to get at because that has to be documented and relatively easy to work with.", "label": 1}
{"text": "(Translated from the original Italian)\nToday I desire to discuss on the real effect of a cyber attack, we have recently introduced the direct and indirect effects of the several cyber espionage campaigns discovered such as Flame and Gauss, but we never approached the problem in future projection examining the possible impacts of an incident many years after it.\nSymantec researchers published an analysis that demonstrate the link between a series of attacks to more than 30 companies and the cyber espionage attacks moved against Google three years ago so-called Operation Aurora.\nOperation Aurora is considered an epical cyber attack which happened during second half of 2009 and publicly disclosed by Google on January 2010.\nThe sophisticated attacks appeared to be originated in China and aimed at dozens of other organizations who were hit, of which Adobe Systems and Juniper Networks confirmed the incident. The press is also convinced that other companies were targeted such as Morgan Stanley, Northrop Grumman and Yahoo.\nAurora attack is one of the most complex operation due the capability of attacker to exploit several 0-day vulnerabilities included one related the popular IE Explorer, in 2010 a notable zero-day exploit was linked to the group of hackers that used a Trojan horse called \"Aurora\" diffused using an Internet Explorer (IE) zero-day, and targeted a large number of Western companies.\nAccording the security firm Symantec the hackers behind the attacks still have knowledge of 0-day vulnerabilities, and at least four of them have been used in recent attacks against different targets across strategic sectors such as energy, defense, aeronautics and financial.\nOrla Cox, senior manager at Symantec's security response division reported that it has been exploited at least eight zero-day vulnerabilities since late 2010, and four since last spring. She said:\n\"We were amazed when Stuxnet used four zero-days, but this group has been able to discover eight zero-days. More, the fact that they have prepared [their attacks] and are ready to go as soon as they have a new zero-day, and the speed with which they use these zero-days, is something we've not seen before.\"\nThe document of security firm reports:\n\"This group is focused on wholesale theft of intellectual property and clearly has the resources, in terms of manpower, funding, and technical skills, required to implement this task,\"\n\"The group seemingly has an unlimited supply of zero-day vulnerabilities.\"\nThe attacks part of the cyber espionage campaign discovered by Symantec has been named \"Elderwood Project\", for their execution have been exploited 0-day vulnerabilities in many large-use software including IExplorer and Adobe Flash Player.\nThe experts from Symantec declared that some of the exploits have been realized from the knowledge of stolen source code.\n\"In order to discover these vulnerabilities, a large undertaking would be required by the attackers to thoroughly reverse-engineer the compiled application,\"\n\"This effort would be substantially reduced if they had access to source code. The group seemingly has an unlimited supply of zero-day vulnerabilities. The vulnerabilities are used as needed, often within close succession of each other if exposure of the currently used vulnerability is imminent.\"\nThe attacks conducted during the recent months have been using an unusual method to infect the victims with a malware, it has been named \"watering hole\" attack and consists to inject malicious code onto the public Web pages of a site that the targets use to visit.\nThe method of injection isn't new and is commonly used by cyber criminals and hackers, the main difference between their use in\ncybercrime and in watering hole attacks is related to the choice of websites to compromise and use in the attacks.\nThe attackers haven't indiscriminately compromised any website but they are focused chhosing websites within a particular sector so as to infect persons of interest who likely work in that same sector and are likely to therefore visit related websites. The Symantec report states:\n\"Targeting a specific website is much more difficult than merely locating websites that contain a vulnerability. The attacker has to\nresearch and probe for a weakness on the chosen website.\nIndeed, in watering hole attacks, the attackers may compromise a website months before they actually use it in an attack. Once compromised, the attackers periodically connect to the website to ensure that they still have access. This way, the attackers can infect a number of websites in one stroke, thus preserving the value of their zero-day exploit. They are even in a position to inspect the website logs to identify any potential victims of interest. This technique ensures that they obtain the maximum return for their valuable zero-day exploit.\"\nOnce a victim visits the compromised site, the software for which the 0-days have been designed will make possible the infection of the machine.\nSymantec researcher have detected the use of this method using at least three different zero-day exploits in the last month.\nThe researchers believe that a specific platform has been implemented to conduct the operations, all the attacks use a Trojan to infect the target computer that is packaged with a packer and also the address of the command-and-control (C&C) server. The delivery of the malware to the final victim is either though an email or a Web based vector.\nI opened the post supporting the idea that Aurora attacks are state sponsored, it's clear that I have no evidences for this, but the nature of the job made, the targets chosen and the complexity of the operations make me believe that it is a result of a government project.\nThe unique certainty according Symantec is a connection between the most recent attacks and those used in attacks in 2011, demonstrable with common technical features and a noticeable similarity in the timing of the attacks and the types of vulnerabilities used between the 2012 and 2011 attacks.\n\"After this initial compromise, the attackers consolidate their beachhead and begin to analyze the stolen information, spreading through networks and maintaining access as needed. By analyzing the information gathered, the attackers can identify yet more targets of interest\"\nCox said Symantec has no hard evidence of this:\n\"But this is a full-time job,\"\n\"The work they do is both skilled and time consuming. They would have to work at it full time, so someone is paying them to do this.\"\n\"The analysis has shown that certain organizations have been hit in different ways, indicating that they're of particular interest to [their paymasters],\"\nI leave you all the interpretations of Symantec expert, but I think that her thought is not far from mine.\nWaiting for further analysis any manufacturers who are in the defense supply chain need to be wary of these type of attacks. Subsidiaries, business partners, and associated companies are considerable priviledged targets, an easy way to break penetrate defense system of large companies\n... raise your guard the enemy may already be in.\nCross-posted from Security Affairs", "label": 1}
{"text": "Is your New Computer Safe?\nWhile recently investigating counterfeit versions of the Windows operating system, Microsoft uncovered a security threat involving pre-loaded malware. The counterfeit operating systems and malware were found on brand-new computers manufactured and sold in China.\nThe discovery further lead to a server hosting 500 different pieces of malware including Nitol. Some of the malicious code found are capable of keystroke logging, denial-of-service attacks, rootkits, backdoors and more.\nNitol is a program that creates a \"bot\" on a user's computer which connects to a network center or a \"botnet.\" There, hackers can subvert the infected computer to do their biding by issuing commands remotely. Nitol is capable of launching DDoS attacks against targets, or opening backdoors for additional malware infections or activity monitoring by turning on a microphone or video camera on a computer.\nYesterday the US Cybersecurity Act of 2012 — a bill that would have given the government more access to monitor our private communications and data — met defeat.\nAs of now, SOPA, HR 1981, and the Cybersecurity Act of 2012 have all been voted down.\nCertainly more bills will foisted on the Internet community in the future. We'll keep you posted!\nSOPA and PIPA\nMost internet users have heard of this proposed legislation by now. Many websites such as Wiki are protesting this legislation today by blacking out their website or otherwise letting their users know about it.\nAmericans should not have to tolerate this type of censorship. I encourage you to take action and to encourage others to do the same. The entertainment industry and others concerned about online piracy should use their own legal and technical resources to resolve the matter.\nOnline piracy is only one of many problems caused by the internet. The entertainment industry argues that it looses $30-$40 Billion to online piracy. Various groups argue that the loses are exaggerated and estimates the loses to be around $445 Million. Regardless of which figure you agree with, studies have shown that Unsolicited Bulk E-mail (SPAM) costs internet providers and employers $70 Billion annually. Other issues such as identity theft and security should be paramount ahead of the entertainment industry's profit.\nIf you are unaware of what SOPA and PIPA are, please take a moment to familiarize yourself with the controversy. More information can be found in the links below.Wikipedia, Google and others have provided convenient tools to locate quickly contact our representatives. Please take a moment of your time to let them know that our Freedom is important and SOPA and PIPA should not be passed.\nCEO, Starpoint Communications, Inc.\nFreedom Wins - SOPA/PIPA Update\nFrom the Associated Press:Senate Majority Leader Harry Reid announced today that he is postponing Tuesday's procedural vote on the Protect IP Act (PIPA). Meanwhile, House Judiciary Committee Chairman Lamar Smith said his committee is postponing consideration of PIPA's House companion, the Stop Online Piracy Act (SOPA), \"until there is wider agreement on a solution.\"\nAre Anti-Virus Programs Worth It?\nRegardless of the antivirus program you use, it will impact your computer's performance. Some more some less. Even programs which incur annual subscription fees are not always cost effective when you consider how much they slow down your computer. For many years we've recommended AVG and for the most part still do. There are a number of excellent antivirus programs that are free and do a terrific job.\nWe would also like to let our user's know about the Microsoft Security Essentials (MSE). This is a complete anti-malware package available from Microsoft itself. So, if you are running windows XP (or newer) and your $50 copy of Norton or McAfee is about to expire, consider uninstalling it and using the MSE software.", "label": 1}
{"text": "In the November issue of The Atlantic, James Fallows shares the disturbing story of what happened when his wife’s Gmail account got hacked earlier this year. First, she couldn’t log into her account. Then, her contacts received a troubling message that she was stranded in Madrid with no money, and she needed them to wire her funds, immediately. (It might sound like a scam, but many recipients were concerned enough to contact her husband.) Soon, she had no access to her account and all her messages—years’ worth—had been deleted.\n[In Pictures: 10 Ways to Start Earning Extra Money Now]\nFallows and his wife, Deb, followed Gmail’s instructions on recovering a compromised account, and eventually regained access, but they were unable to recover her old emails until Google executives got involved. (Before James Fallows called on his own contacts, who happened to be high-level executives in the company, Google had declined to help them further.)\nFallows uses the experience to show just how easy it is for hackers to break into emails and wreak all kinds of havoc on victims’ professional, financial, and personal lives. The Federal Trade Commission reports that 9 million Americans experience some form of identity theft each year, but there are steps people can take to reduce the risk of it happening to them. When it comes to email protection, Fallows suggests the following:\n1. Do not use the same password on multiple sites. Fallows equates this to simply not using a password at all. If you use your email password on less secure sites that also use your email address as a login name, you are essentially telling a less-secure site how to log into your account.\n2. Avoid common words or names. Hackers can simply guess these words, says Fallows, so they don’t offer much protection from attacks.\n3. If you use Gmail, implement the two-step verification system, which means that when you log into your account from any device that is not your normal computer, you need to enter a numerical code that Google sends to your phone. (On computers you use regularly, you only need to enter a code every 30 days.) You also enter a unique code on mobile devices, such as smartphones. Fallows says this system stops almost all attacks, since the hacker would need to have your cell phone as well as your password.\n4. Create a long password that only you know. Fallows’ examples include “Lake Winnebago is deep and chilly,” and “my favorite packer is not brett favre.” Those passwords are so long that a hacker would have a hard time guessing it.\n[In Pictures: 10 Ways to Save on Food Costs]\nHere are four more tips from the identity protection services firm myID.com:\n1. Stay away from any personal information, such as birthdays, sports teams, or children’s names. Anyone who knows you personally—or can find such information about you through social networking sites—will be able to make a reasonable guess at your password.\n2. Use those old elementary school memory tricks. If you want an easy way to remember a complicated password, try making up a sentence about it. For example, “I love my dog Harry so much” can translate into the hard-to-guess password ILMDHSM.”\n3. Change passwords as often as you change your air conditioning filter. That’s about once a month for online financial accounts. Other accounts should be changed every three to four months, says myID.com.\n4. Don’t share. Keep passwords to yourself and try to avoid storing them on your computer or smartphone, where others could see them, including hackers. MyID.com says they belong in your head or a locked safe.\nDo you have any tips on keeping your passwords safe?", "label": 1}
{"text": "Net neutrality may become federal election issue in Canada\nWith the federal election in full swing, Lindsey Pinto is ramping up the fight for an accessible and open Internet. The communications manager for the Vancouver-based group OpenMedia.ca said Canadians need to be aware of the importance of net neutrality.\n“We have some of the strongest net-neutrality regulations in the world, and we do not enforce them at all,” Pinto told the Georgia Straight by phone.\nNet neutrality is the idea that the Internet should be a level playing field for all users. According to this principle, Internet service providers shouldn’t discriminate against applications or websites based on their content or other reasons. Whether it’s a blog about cats, a newspaper website, or peer-to-peer file-sharing, net neutrality says telecommunications companies shouldn’t be able to selectively block, speed up, or slow down access to this content.\n“The Internet is our best source for democratic discourse,” Pinto said. “If Internet service providers can throttle content and give preferential treatment to content that they own or that they make deals with, it is going to stifle that innovation and prevent our economy growing in that capacity.”\nThis week, OpenMedia launched a campaign called Vote for the Internet. The group is encouraging voters to write to their local candidates and plans to survey party leaders about their positions on the Internet’s future.\nOpenMedia has been at the forefront on digital issues such as net neutrality and usage-based billing for Internet service. The group says telecom companies are not playing by bandwidth-throttling rules put in place by the Canadian Radio-television and Telecommunications Commission in 2009.\nUnder CRTC regulations, users who notice their Internet connections are being sped up or slowed down can file a complaint with the regulatory body. The CRTC will then investigate to see if the complaint is credible. If the complaint is valid, the CRTC will then ask the ISP for information about their traffic-management practices.\nAccording to Pinto, this regulatory regime puts the onus on consumers to investigate problems with the complex networks run by telecom companies. She argued there is a better way to police net neutrality.\n“We have been pushing for some time that the CRTC do audits of Internet service providers to make sure that they are complying with these traffic-management rules,” Pinto said. “So, essentially asking them to enforce their own framework.”\nUniversity of Ottawa law professor Michael Geist runs Neutrality.ca, a website that chronicles the constant battle for net neutrality with telecom giants like Rogers, Bell, and Telus. He asserts the CRTC’s regulations are ineffective without proper enforcement.\n“I would like to see the industry minister in particular use their office to find ways to conduct audits and provide either the resources or the direction to make sure that sort of thing happens,” Geist told the Straight by phone from Ottawa.\n“While the [regulations] are pretty good, it ultimately falls onto individual Canadians to investigate and bring complaints. I think, given the lack of transparency in how networks run, that is a very tall order for most individual Canadians to do.”\nConservative industry minister Tony Clement’s staff said he was unavailable for an interview. But in the past, the Conservative party has said it does not support compliance audits and it believes the CRTC’s enforcement strategy is working.\nMeanwhile, the federal NDP and Liberal parties both support mandatory net-neutrality audits by the CRTC to ensure that Internet providers obey the commission’s traffic-management guidelines.\nGeist said there is another way to ensure Canadian ISPs are allowing unrestricted access of the web, arguing more competition between telecom companies would translate into an open and accessible Internet.\n“Other countries in Asia and Europe—where they have got net-neutrality rules—in some ways, they have got enough competition that it is less of a concern,” Geist said.\nTelecom giant Rogers said that having the CRTC or the government perform mandatory inspections on their traffic-management systems is not necessary.\n“We regularly audit our technology,” Rogers spokesperson Patricia Trott told the Straight by phone from Toronto.\nIn January, the CRTC said it had received a number of complaints alleging the company was throttling traffic of peer-to-peer websites to some of its customers without providing 30 days notice.\nTrott said Rogers monitors and limits upstream traffic to limit spam, viruses, and security threats.\n“Rogers does manage upstream traffic for peer-to-peer file sharing applications. So, say if you were downloading a movie you wouldn’t notice anything different in the speed at all,” Trott said.\n“It is just for the upstream that we actually slow it down. And that’s because it takes up a lot of room, and we want to make sure our customers’ services like e-mail and other things are not slowed down,” she added.\nTrott insisted Rogers is transparent about its traffic-management practices, posting its policies on its website.\n“Our customers have access to all over-the-top services, all Internet websites, and so on.”¦We recognize that our customers want to have access to all of the content that they want and so that is what we want to provide them,” Trott said.\nStill, Pinto argued ISPs shouldn’t be controlling how people use the web. She’s urging Canadians to vote for candidates who support strong net-neutrality regulations.\n“We need to have these rules in place,” Pinto said. “These big companies, they are as monolithic as governments are. And they are as threatening as government control is.”", "label": 1}
{"text": "Facebook is reportedly testing out controls that would allow users under the age of 13 to participate on the social network under parental supervision. Citing people who have spoken with Facebook executives about the project, WSJ.com reports mechanisms in testing include “connecting children's accounts to their parents' and controls that would allow parents to decide whom their kids can ‘friend’ and what applications they can use.”\nFacebook has been put in the awkward position of having to consider allowing underaged users because so many currently lie about their age and are using the network anyway. However, it’s not all altruism or damage control; one mechanism they’re trying on would reportedly allow for parents to pay for games or apps their children access through Facebook. Revenue is clearly, at the very least, a secondary driver.\nLast June, Consumer Reports magazine said they had unearthed “several disturbing findings” about children and Facebook, including:\n- 20 million minors had used Facebook within the year prior to their study.\n- 7.5 million of those users were under the age of 13 and not permitted to use the site.\n- 5 million of those were 10 years old or younger.\n- 1 million children had been harassed, threatened, or subjected to other forms of cyberbullying in the year prior.\nAt the time, Federal Trade Commission chair Jon Leibowitz told Consumer Reports, “We are very concerned about kids eliding around COPPA’s restrictions.” COPPA is the Federal Children’s Online Privacy Protection Act of 1998, which prohibits sites from knowingly disclosing children’s personally identifiable information.\nFacebook safety monitoring tool company Minor Monitor reports even scarier trends in their infographic based on a survey of 1,000 American parents (see above). According to their research, 4 percent of children on Facebook are 6 years old or younger.\nAmong parent concerns about their children using Facebook, 56 percent are worried about sexual predators, 49 percent fear their kids will share too much personal information, and 45 percent are afraid their children will connect with strangers. Surprisingly, 17 percent of these parents still don't monitor their child’s Facebook activity at all.\nWeb community Sodahead surveyed 2,000 users back in March to learn whether parents are happy with Facebook’s current minimum age requirement. Forty-eight percent of parent respondents said 13 years old is just too young to use Facebook and felt the minimum age should be increased. Opinions varied widely though; 5 percent said 7- to 9-year-olds should be allowed.\nLawmakers are already expressing concern. What do you think of Facebook opening the floodgates to users of all ages and what controls do you think they need to have in place to make it work? Let us know in the comments.\nJUNE SALE! Save 15%*\nSave on all e-learning certification courses, including: SEO, Social Media, Online Marketing Foundation, Web Analytics and more. Enter CZAJU at checkout »\nOffer expires June 30. *Discount not applicable on SES Online products.", "label": 1}
{"text": "Editor's Note: This article was originally presented at ESC Boston 2011.\nNo software engineering process can guarantee secure code, but following the right coding guidelines can dramatically increase the security and reliability of your code. Many embedded systems live in a world where a security breach can be catastrophic. Embedded systems control much of the world’s critical infrastructure, such as dams, traffic signals, and air traffic control. These systems are increasingly communicating together using COTS networking and in many cases using the Internet itself. Keeping yourself out of the courtroom, if not common decency, demands that all such systems should be developed to be secure.\nThere are many factors that determine the security of an embedded system. A well-conceived design is crucial to the success of a project. Also, a team needs to pay attention to its development process. There are many different models of how software development ought to be done, and it is prudent to choose one that makes sense. Finally, the choice of operating system can mean the difference between a project that works well in the lab and one that works reliably for years in the real world.\nEven the most well thought-out design is vulnerable to flaws when the implementation falls short of the design. This paper focuses on how one can use a set of coding guidelines, called MISRA C and MISRA C++, to help root out bugs introduced during the coding stage.MISRA C and C++\nMISRA stands for Motor Industry Software Reliability Association. It originally published Guidelines For the Use of the C Language In Critical Systems\n, known informally as MISRA C, in 1998. A second edition of MISRA C was introduced in 2004, and then MISRA C++ was released in 2008. More information on MISRA and the standards themselves can be obtained from the MISRA website\nThe purpose of MISRA C and MISRA C++ guidelines are not to promote the use of C or C++ in critical systems. Rather, the guidelines accept that these languages are being used for an increasing number of projects. The guidelines discuss general problems in software engineering and note that C and C++ do not have as much error checking as other languages do. Thus the guidelines hope to make C and C++ safer to use, although they do not endorse MISRA C or MISRA C++ over other languages.\nMISRA C is a subset of the C language. In particular, it is based on the ISO/IEC 9899:1990 C standard, which is identical to the ANSI X3.159-1989 standard, often called C ’89. Thus every MISRA C program is a valid C program. The MISRA C subset is defined by 141 rules that constrain the C language. Correspondingly, MISRA C++ is a subset of the ISO/IEC 14882:2003 C++ standard. MISRA C++ is based on 228 rules, many of which are refinements of the MISRA C rules to deal with the additional realities of C++.\nFor notational convenience, we will use the terms “MISRA”, “MISRA C” or “MISRA C++” loosely in the remainder of the document to refer to either the defining documents or the language subsets.", "label": 1}
{"text": "IPSEC also has the disadvantage of requiring operating system support, since most O/S kernels don't allow direct manipulation of IP headers. This presents legal issues, since cryptographic software is restricted by many governments. Linux IPSEC support (the FreeS/WAN project), for example, isn't included in the standard kernel distribution for this reason, and has to be applied as an add-on. Furthermore, putting the cryptography in the kernel isolates it from the application, making it more difficult to code crypto-aware software. Using SSL, for example, simply requires linking a library into the application and allows the application to easily query what certificates have been used to authenticate a client (for example). Doing the same thing with IPSEC requires the application to query the kernel using some kind of API.\nFigure 1. IPsec Document Roadmap\nIPSEC defines a \"Security Association\" (SA) as its primitive means of protecting IP packets. An SA is defined by the packet's destination IP address and a 32-bit Security Parameter Index (SPI), that functions somewhat like a TCP or UDP port number, in that it allows multiple SAs to a single destination address. SAs can operate in transport mode, where the IPSEC data field begins with upper level packet headers (usually TCP, UDP, or ICMP), or in tunnel mode, where the IPSEC data field begins with an entirely new IP packet header, ala RFC 2003. Furthermore, SAs can be encapsulated within SAs, forming SA bundles, allowing layered IPSEC protection.\nFor example, one SA might protect all traffic through a gateway, while another SA would protect all traffic to a particular host. The packets finally routed across the network would be encapsulated in an SA bundle consisting of both SAs. The other side of the connection could be identical in design, consisting of a gateway implementing a tunnel SA, followed by a host implementing a transport SA, or the entire bundle could be terminated in a single host, which would then implement both SAs.\nFigure 2: Bundled SAs\nA common use of IPSEC is the construction of a Virtual Private Network (VPN), where multiple segments of a private network are linked over a public network using encrypted tunnels. This allows applications on the private network to communicate securely without any local cryptographic support, since the VPN routers perform the encryption and decryption. IPSEC is well suited for this environment, more so than tunneling PPP over SSL or SSH, since it operates directly on the IP packets and preserves a one-to-one correspondence between packets inside and outside the network. In the case of tunneling PPP over an encrypted TCP connection, any packet loss in the public network would trigger a TCP retransmission, stalling the link until the packet was delivered. In particular, running Voice Over IP (VoIP) traffic through a TCP/PPP tunnel would largely defeat the RTP protocol used for VoIP; IPSEC is better suited in this case.", "label": 1}
{"text": "Preventive Medicine for Healthcare Providers: Fighting bugs and viruses of a different sort\nDavid Finn, Health IT Officer at Symantec\nThe doctor’s office is changing. It’s becoming much less common to see the rows of filing cabinets filled with paper files on each patient. Instead, healthcare today is driven more and more by technologies such as computers, servers, smartphones and tablets. Endpoints used to primarily mean PCs, but now there are far more methods for accessing files, especially electronic protected health information (ePHI) about patients. Healthcare professionals now have more ways than ever to provide the care their patients need.\nJust as our bodies are constantly fighting off germs and viruses, largely without our knowledge, most healthcare employees may not see the battle behind the scenes to protect ePHI from cyber criminals as well as accidents that can expose this sensitive information. But just one data loss incident can be devastating for a healthcare provider. And while we are hearing in the news about sophisticated cyberattacks , endpoint security remains a fundamental part of information protection. A recent survey conducted by Symantec revealed that three-fourths of small to mid-sized businesses feel they are safe from threats such as viruses and hackers. Unfortunately, additional research shows that 36 percent of all targeted attacks are now directed at businesses that have fewer than 250 employees.\nThis combination – increasing threats to information and that information being stored and accessed in more places than ever before – means that it’s time for businesses dealing with ePHI to make sure they are doing everything in their power to keep it safe. They also need to protect their own financial records and other confidential data. The following are best practices healthcare facilities can follow to ensure successful protection of their endpoints.\nKnow what you’re dealing with: The first step is to know what information you are storing, and where it is. If you have implemented an electronic medical record and/or practice management system, you should know where those files are being stored. The servers and other machines that have access to that information need the most protection, whereas public information does not require the same level of protection.\nEducate employees: Employee education is a significant part of an effective information protection plan, as they are the first line of defense when it comes to keeping endpoints safe. Be sure your employees are not only aware of long-established threats like malware, but educate them on more recent trends such as social engineering. In this newer kind of threat, cyber criminals can use publicly available information from sources such as social networking sites to craft communications ostensibly from credible sources, sending them to employees. Then they trick them into giving away their login credentials, potentially compromising endpoints, security systems and confidential information. Employees also need to remain vigilant with their Internet use and the files they download.\nChoose the right solutions: Carefully evaluate your current endpoint protection software. You should standardize on a single solution wherever possible, to present a united front against threats. If you need to update or introduce new protection tools, look for a vendor that can satisfy these key requirements:\n- Flexibility: As many businesses begin to embrace virtualization and the cloud, they need to protect both physical and virtual machines. Using two or more endpoint protection solutions is costly and inefficient; be sure your vendor can support both platforms. A simple licensing process will also be valuable as the number of endpoints grows with the business. In addition, more businesses are opting to deploy security as a service, allowing security businesses to utilize their extensive intelligence resources to manage security for clients. This may be especially useful for smaller organizations with fewer IT resources.\n- Effectiveness: Threats are diversifying, and in many cases traditional malware protection alone is not enough. Securing endpoints should include the ability to protect against not only the expected viruses and Trojans, but newer forms of malware that exploit emerging vulnerabilities. The ideal solution should be able to analyze files to dynamically identify new threats based on the latest intelligence. For the best possible results, select an endpoint solution from a reputable and trusted security vendor.\n- Performance: With the amount of information providers are storing drastically increasing, particularly as electronic medical records become more common, there are more files than ever for endpoint protection tools to scan. Healthcare businesses need a solution that can quickly scan this increasingly large number of files. Deduplication can significantly reduce scan times by reducing duplicate files. It should also be intelligent enough to skip duplicate files in the virtual environment, further streamlining the protection process.\nToday’s healthcare providers, from academic medical centers to small physician practices, deal with an enormous amount of sensitive information, and keeping it secure should be the top priority. As part of a multi-layered security approach, ensure that you install sufficient protection on all endpoints, as well as enabling sensible user behavior and intelligently managing where sensitive information is stored. Strengthening your ability to protect ePHI and other confidential files, you can continue to provide the highest quality patient care, knowing that their information is as well cared for as they are.\nCategory: Health Information Technology", "label": 1}
{"text": "What is Computer Forensics?\nComputer forensics is a computer investigation and analysis technique used to acquire civil, criminal or administrative evidence from a computer system. Some reasons for seeking this type of evidence may include: theft of trade secrets, destruction or theft of intellectual property, criminal misuse, or fraud. Kimmons utilizes numerous methods for discovering data on a computer system. These methods can also recover encrypted, damaged or deleted files. The information found can be useful in depositions, litigation, or discovery.\nWho can Benefit from this Type of Investigation?\nCriminal prosecutors use computer evidence when prosecuting crimes involving financial fraud, child pornography, and illegal drug related cases. Civil Litigants use personal and business records found on computer systems when litigating divorces, discrimination, or harassment cases.\nCorporations use computer forensics specialists to gather evidence relating to embezzlement, misappropriation of funds or trade secrets, and sexual harassment. Individuals frequently hire computer forensics specialists to support their claims of age, discrimination, sexual harassment or wrongful termination.\nWhat do Our Computer Forensics Security Services do?\n- Secure the system\n- Discover the files\n- Recover deleted files\n- Reveal hidden, temporary, or swap files\n- Access protected or encrypted files\n- Analyze all relevant data\n- Print overall analysis\n- Provide consultation and/or testimony\n- Protect all information and evidence discovered throughout investigation\nWhy Choose Kimmons Computer Forensics Services?\nProtection of evidence is critical in computer forensics. A knowledgeable computer forensics professional will secure a computer system to ensure no possible evidence is damaged, destroyed or compromised. The specialist will guarantee the computer is not exposed to any additional viruses during the procedure. All evidence is properly handled and protected from other types of damage, including mechanical or electromagnetic interference. Interruptions to business operations are kept minimal. The client-attorney privilege will be maintained and information will be handled ethically and legally.", "label": 1}
{"text": "The Internet’s Reinventions\nPlanetLab aims to transform today’s dumb, simple Internet communications system into a smarter and much more flexible network that can ward off worms, store huge amounts of data with perfect security, and deliver content instantly. Here’s how it fits into a long tradition of academic and government research projects that developed fundamental networking, transmission, and distributed-computing technologies.\nThe first major attempt to use computers for communication, and the testing ground for the standards that would come to define the Internet. Built by universities and technology firms with funding from the U.S. Defense Department’s Advanced Research Projects Agency (now DARPA).\nA network of smaller networks in which computers exchange packets of data formatted and addressed according to, respectively, the Transport Control Protocol and the Internet Protocol (TCP/IP), which were conceived in 1973 and officially replaced the ARPANET’s protocols in January 1983.\nThe Multicast Backbone: a system that allows many people to view the same real-time information, such as video broadcasts, over the Internet. Created by members of the Internet Engineering Task Force in 1992 to overcome the limitations of standard Internet protocols, which can route a given data packet to only one destination.\nA consortium of more than 200 universities that has created Abilene, a network of high-performance routers and fiber-optic links. Abilene is able to transmit an entire DVD movie in about 36 seconds, as much as 3,500 times faster than a typical home DSL or cable connection.\nA collection of public and private organizations and projects that use software developed at the U.S. Department of Energy and the University of Southern California to link scattered supercomputers, scientific instruments, and data storage facilities into a “grid” that can take on tough computational problems-like screening for new drug molecules.\nThe Active Network Backbone: a network built to test the efficiency of “active networking,” in which the network is stripped of nearly all intelligence-even the basic message-passing software that runs on today’s Internet-and packets of data contain all the software and instructions needed to deliver themselves to their destinations. Funded by DARPA and created by SRI International, a private research institute in Menlo Park, CA, and the University of Southern California.\nAn effort by academic and corporate networking researchers to augment, and eventually replace, today’s “dumb” Internet with a much smarter network able to monitor itself for worms and viruses, relieve bottlenecks automatically, and make personal-computing environments portable to any terminal on earth.", "label": 1}
{"text": "WAN optimization is a collection of techniques for increasing data-transfer efficiencies across wide-area networks. In 2008, the WAN optimization market was estimated to be $1 billion, and it will grow to $4.4 billion by 2014 according to Gartner, a technology research firm.\nThe most common measures of TCP data-transfer efficiencies (i.e., optimization) are throughput, bandwidth requirements, latency, protocol optimization, and congestion, as manifested in dropped packets. In addition, the WAN itself can be classified with regards to the distance between endpoints and the amounts of data transferred. Two common business WAN topologies are Branch to Headquarters and Data Center to Data Center (DC2DC). In general, \"Branch\" WAN links are closer, use less bandwidth, support more simultaneous connections, support smaller connections and more short-lived connections, and handle a greater variety of protocols. They are used for business applications such as email, content management systems, database application, and Web delivery. In comparison, \"DC2DC\" WAN links tend to require more bandwidth, are more distant, and involve fewer connections, but those connections are bigger (100Mbit/s to 1Gbit/s flows) and of longer duration. Traffic on a \"DC2DC\" WAN may include replication, back up, data migration, virtualization, and other Business Continuity/Disaster Recovery BC/DR flows.\nWAN optimization has been the subject of extensive academic research almost since the advent of the WAN. In the early 2000s, research in both the private and public sectors turned to improving the end-to-end throughput of TCP, and the target of the first proprietary WAN optimization solutions was the Branch WAN. In recent years, however, the rapid growth of digital data, and the concomitant needs to store and protect it, has presented a need for DC2DC WAN optimization.\nComponent techniques of Branch WAN Optimization include deduplication, WAFS, CIFS proxy, HTTPS Proxy, media multicasting, web caching, and bandwidth management. Requirements for DC2DC WAN Optimization also center around deduplication and TCP acceleration, however these must occur in the context of multi-gigabit data transfer rates.\nWAN optimization techniques \n- Deduplication – Eliminates the transfer of redundant data across the WAN by sending references instead of the actual data. By working at the byte level, benefits are achieved across IP applications.\n- Compression – Relies on data patterns that can be represented more efficiently. Essentially compression techniques similar to ZIP, RAR, ARJ etc. are applied on-the-fly to data passing through hardware (or virtual machine) based WAN acceleration appliances.\n- Latency optimization – Can include TCP refinements such as window-size scaling, selective Acknowledgements, Layer 3 congestion control algorithms, and even co-location strategies in which the application is placed in near proximity to the endpoint to reduce latency. In some implementations, the local WAN optimizer will answer the requests of the client locally instead of forwarding the request to the remote server in order to leverage write-behind and read-ahead mechanisms to reduce WAN latency.\n- Caching/proxy – Staging data in local caches; Relies on human behavior, accessing the same data over and over.\n- Forward error correction – mitigates packet loss by adding an additional loss-recovery packet for every “N” packets that are sent, and this would reduce the need for retransmissions in error-prone and congested WAN links.\n- Protocol spoofing – Bundles multiple requests from chatty applications into one. May also include stream-lining protocols such as CIFS.\n- Traffic shaping – Controls data flow for specific applications. Giving flexibility to network operators/network admins to decide which applications take precedence over the WAN. A common use case of traffic shaping would be to prevent one protocol or application from hogging or flooding a link over other protocols deemed more important by the business/administrator. Some WAN acceleration devices are able to traffic shape with granularity far beyond traditional network devices. Such as shaping traffic on a per user AND per application basis simultaneously.\n- Equalizing – Makes assumptions on what needs immediate priority based on the data usage. Usage examples for equalizing may include wide open unregulated Internet connections and clogged VPN tunnels.\n- Connection limits – Prevents access gridlock in routers and access points due to denial of service or peer to peer. Best suited for wide open Internet access links, can also be used on WAN links.\n- Simple rate limits – Prevents one user from getting more than a fixed amount of data. Best suited as a stop gap first effort for remediating a congested Internet connection or WAN link.\nOpen-source based WAN optimization solutions \n- Machowinski, Matthias. \"WAN optimization market passes $1 billion in 2008, up 29%; enterprise router market down\". Enterprise Routers and WAN Optimization Appliances. Infonetics Research. Retrieved 19 July 2011.\n- Skorupa, Joe; Severine Real (2010). \"Forecast: Application Acceleration Equipment, Worldwide, 2006–2014, 2Q10 Update\". Gartner, Inc. Retrieved 19 July 2011.\n- Cardwell, N.; Savage, S.; Anderson, T.;. \"Modeling TCP latency\". INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE. Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA: IEEE.org. Retrieved 20 July 2011.\n- Jacobson, Van. \"TCP Extensions for Long-Delay Paths\". Request for Comments: 1072. Internet Engineering Task Force (IETF). Retrieved 19 July 2011.\n- Floyd, Sally. \"HighSpeed TCP for Large Congestion Windows\". Request for Comments: 3649. Internet Engineering Task Force (IETF). Retrieved 19 July 2011.\n- Paris, Chandler. \"Latency & Colocation\". Retrieved 20 July 2011.\n- Mark Rabinovich, Igor Gokhman. \"CIFS Acceleration Techniques\". Storage Developer Conference, SNIA, Santa Clara 2009.", "label": 1}
{"text": "What is Antivirus?\nAntivirus or anti-virus software is used to prevent, detect, and remove malware, including but not limited to computer viruses, computer worms, trojan horses, spyware and adware\nIdentification methods: 1.Signature based detection 2. Heuristic-based detection\nSignature based detection: it's most common method to take down virus. This process, antivirus compares contents of the file to directory of virus signatures. Every virus program contains different malicious proggram. Firstly, antivirus collects odd proggram then create virus signature database.\nHeuristic-based detection : There are some renowned antivirus uses this method. Many viruses start as a single infection and through either mutation or refinements by other attackers, can grow into dozens of slightly different strains, called variants. Generic detection refers to the detection and removal of multiple threats using a single virus definition. [source:Wikipedia]\nRootkit Detection: Rootkit is malware, antivirus also can scan it. Rootkits normally changed OS . Several time, hacker injects rootkit to host !\nVirus lists and how to prevent :\n9. Virus Hoax\nThere are various ways to prevent them. In this time, many software like, Antivirus, Smart Security, Internet security,Anti-spyware, Anti-malware etc. there are all paid and trail version.\nI , comfortably, use ESET NOD32 smart security.\nESET is an IT security company headquartered in Bratislava, Slovakia that was founded in 1992 by the merger of two private companies. The company was awarded as the most successful Slovak company in 2008, 2009 and 2010. ESET is privately held and has branch offices in San Diego, California; Montreal, Canada; Buenos Aires, Argentina; Prague, Czech Republic; Kraków, Poland and Singapore as well as distributors in over 180 countries.\nIn December 2010, the company announced the appointment of Richard Marko as Global CEO, Milan Masaryk as CFO, Pavol Luka as CTO, Juraj Malcho as Chief Research Officer, Ignacio Sbampato as director of global sales and marketing, and Andrew Lee as the CEO of its North American branch. ESET's founders remain on as the company's board.\n\"At ESET, we are dedicated to developing high-performing security solutions for home users and corporate customers, keeping out all known and emerging forms of malware.\"\n- Miroslav Trnka, Co-Founder of ESET.\nESET NOD32 is a very renowned antivirus. You could download it as TRIAL version. There are some types of ESET NOD32 Security system\n1. ESET Smart Security\n2. ESET NOD32 Antivirus\n3. ESET cyber security for MAC\n4. ESET Antivirus for Linux\n5. ESET Mobile Security\nMore in: Eset Official Site\nThis antivirus has trial version. We are trying to provide Nod32 USERNAME and PASSWORD.\nRelated search Keywords: nod32 username and password,eset nod32 username password,8 june 2012 nod32 username update, 2012-07-08 nod32 username password, 08-07-2012 eset nod32 username password", "label": 1}
{"text": "Below are the first 10 and last 10 pages of uncorrected machine-read text (when available) of this chapter, followed by the top 30 algorithmically extracted key phrases from the chapter as a whole.\nIntended to provide our own search engines and external engines with highly rich, chapter-representative searchable text on the opening pages of each chapter. Because it is UNCORRECTED material, please consider the following text as a useful but insufficient proxy for the authoritative book pages.\nDo not use for reproduction, copying, pasting, or reading; exclusively for search engines.\nOCR for page 251\nEngaging Privacy and Information Technology in a Digital Age 9 Privacy, Law Enforcement, and National Security The tension between individual privacy and law enforcement or national security interests has been an enduring force in American life, its origins long predating the advent of new media or current technologies. Nowhere else is the tension between “it’s none of your business” and “what have you got to hide” so easily seen.1 Although these tensions predate the information revolution, new technologies, new societal contexts, and new circumstances have sharply intensified that conflict, and even changed its focus. Section 9.1 focuses on the uses of information technology in law enforcement and discusses the pressures that such uses place on individual privacy. Section 9.2 does the same for national security and intelligence. 1 As an illustration of the latter, Houston police chief Harold Hurtt referred to a proposal to place surveillance cameras in apartment complexes, downtown streets, shopping malls, and even private homes to fight crime during a shortage of police officers and told reporters at a police briefing, “I know a lot of people are concerned about Big Brother, but my response to that is, if you are not doing anything wrong, why should you worry about it?” See Pam Easton, “Houston Eyes Cameras at Apartment Complexes,” Associated Press Newswire, February 15, 2006.\nOCR for page 252\nEngaging Privacy and Information Technology in a Digital Age 9.1 INFORMATION TECHNOLOGY, PRIVACY, AND LAW ENFORCEMENT 9.1.1 Background By its very nature, law enforcement is an information-rich activity. The information activities of law enforcement can be broken into three categories. Gathering and analyzing information to determine that a law has been violated; Gathering and analyzing information to determine the identity of the person or persons responsible for a violation of law; and Gathering and analyzing information to enable a legal showing in court that the person or persons identified in fact were guilty of the violation. All of these gathering and analysis activities have been altered in basic ways by functional advancements in the technologies that have become available for collecting, storing, and manipulating data. In actual practice, these categories can overlap or the activities in each category can occur in several temporal sequences. When a police officer observes someone breaking a law, the officer is determining that a law has been violated, gathering information about who broke the law (presumably the person he or she is observing), and gaining evidence that may be introduced in court (the testimony of the officer). The essential difference between these categories is the locus or subject about which the information is gathered. In the first category concerning the breaking of a law, the locus of information is the event or activity. In the second sort of activity, the locus is the determination of an individual or set of individuals involved in the activity. In the third category, information associated with categories one and two are combined in an attempt to link the two in a provable way. Although activities in the first category usually precede those in the second, this is not always the case. Law enforcement authorities have been known to start with “suspicious people” and then seek to discover what laws they might have broken, might be breaking, or might be planning to break. This is one of the rationales for certain kinds of undercover activity and is frequently regarded as more controversial. These distinctions are important because they help to differentiate cases that generate concern about invasions of privacy from those that involve less controversial uses of the state’s investigatory power.\nOCR for page 253\nEngaging Privacy and Information Technology in a Digital Age Concerns about privacy invasions often involve the possibility that law enforcement officials can cast an unduly broad net, or one that is seen as discriminatory, as they gather information about persons in the absence of specific reasons to suspect that these individuals have violated some particular law. A case in which an individual is targeted to see if he or she has violated a law is conceptually (and legally and morally) different from a case in which information is gathered about an individual as part of an investigation into a known or suspected violation of law or in which there are other grounds for suspicion. In the former case, information may be gathered about individuals who in fact were not involved in a violation—which is different in kind from the task of assembling information about an individual in the hope of finding a violation of law. The potential for data gathering targeted at a particular individual or set of individuals to aid in the discovery of previously unknown violations of the law, or the risk that data gathered by law enforcement may be used for political or harassment purposes, often underlies efforts to restrict the kinds of information that law enforcement agencies can gather and the ways in which it is gathered. Even if the information is never used, the very fact that considerable amounts of data have been collected about individuals who have not been accused or convicted of a crime ensures that substantial amounts of information about non-criminals will end up in the databases of law enforcement agencies. Moreover, with such data a permanent part of their files, citizens may be concerned that this information will eventually be misused or mistakenly released, even if they are not suspects in any crime. They may even engage in self-censorship, and refrain from expressing unpopular opinions. For individuals in this position, issues such as recourse for police misbehavior or carelessness are thus very important. Nor are worries about the gathering of information by law enforcement agencies restricted to how that information could be used in legal proceedings. Such proceedings are governed by the laws and professional ethics that protect the privacy of the individual, and the inappropriate use (in a criminal context) of information gathered by law enforcement agencies can be balanced by judicial review. However, even the suspicion of wrongdoing or being a “person of interest” can have an effect on an individual’s ability to fly in a commercial airliner, obtain certain kinds of permits, gain some kinds of employment, obtain financial services, or conduct business. For example, watch lists, such as those used by the Transportation Security Agency, are not subject to the same level of scrutiny as evidence in a court of law yet can still affect the lives of those whose names appear on such lists. These uses of information are often not\nOCR for page 254\nEngaging Privacy and Information Technology in a Digital Age balanced by judicial or any other kinds of review, leaving the individual at a severe disadvantage when information is inaccurate or incomplete.2 None of these concerns about balancing the need for law enforcement agencies to gather information and the need of the citizen for privacy are new. What is new are the modern information technologies that law enforcement agencies can now use to observe situations and identify individuals more quickly, more accurately, and at less expense than ever before. These technologies include surveillance cameras, large-scale databases, and analytical techniques that enable the extraction of useful information from large masses of otherwise irrelevant information. The sections that follow describe a number of technologies that allow law enforcement agencies expanded capabilities to observe, to listen, and to gather information about the population. Just as the ability to tap phone lines offered law enforcement new tools to gather evidence in the past century, so also these new technologies expand opportunities to discover breaches in the law, identify those responsible, and collect the evidence needed to prosecute. And just like the ability to tap telephones, these new technologies raise concerns about the privacy of those who are—rightly or wrongly—the targets of the new technologies. Use of the technologies discussed requires careful consideration of the resulting tension posed between two legitimate and sometimes competing goals: information gathering for law enforcement purposes and privacy protection. 9.1.2 Technology and Physical Observation As a point of departure, consider the issue of privacy as it relates to government authorities conducting surveillance of its citizens. Using the anchoring vignette approach described in Chapter 2 (see Box 2.2), a possible survey question might be, How much does [your/“Name’s”] local town or city government respect [your/“Name’s”] privacy in [your/her/his] routine local activities? Here are a number of possibilities: [Anita] lives in a city that prohibits any form of video or photographic monitoring by government agencies. [Bita] commutes to work every day into a city that automatically photographs each car to see whether it runs a particular stoplight. [Jake] lives in a city that videotapes all cars on city-owned property. 2 See, for example, Peter M. Shane, “The Bureaucratic Due Process of Government Watch Lists,” Ohio State Public Law Working Paper No. 55, February 2006, available at http://ssrn.com/abstract=896740.\nOCR for page 255\nEngaging Privacy and Information Technology in a Digital Age [Beth] lives in a city that videotapes all people inside the hallways of city-owned buildings. [Mark] lives in a city that uses a device in police cars to detect whether individuals are at home. [Juanita] lives in a city that uses an imaging device in police cars that can see through walls and clothes. These vignettes, ordered from most to least privacy-protecting, illustrate only a single dimension of privacy (namely image-based personal information), but they are a starting point for knowing what must be analyzed and understood in this particular situation, and what decisions society will have to make with respect to the issues the vignettes raise. Whether it is used to see that a law has been or is being broken, to determine who broke the law, or to find a suspect for arrest, physical observation has historically been the main mechanism by which law enforcement agencies do their job. Physical observation is performed by law enforcement officers themselves, and also by citizens called as witnesses in an investigation or a trial. The vignettes above suggest that physical observation has evolved far beyond the in-person human witness in sight of the event in question. When individuals are watched, particularly by the state with its special powers, privacy questions are obviously relevant. The usual expectation is that, unless there is a reason to suspect an individual of some particular infraction of the law, individuals will not be under observation by law enforcement agencies. But because of advances in technology, the means by which law enforcement can conduct physical observation or surveillance have expanded dramatically. New technologies that provide automated surveillance capabilities are relatively inexpensive per unit of data acquired; vastly expand memory and analytical ability, as well as the range and power of the senses (particularly seeing and hearing); and are easily hidden and more difficult to discover than traditional methods. They can be used to observe violations of law as well as a particular individual over extended periods of time unbeknownst to him or her. Today, for example, the use of video cameras is pervasive. Once only found in high-security environments, they are now deployed in most stores and in many parks and schools, along roads, and in public gathering places. A result is that many people, especially in larger cities, are under recorded surveillance for much of the time that they are outside their homes. Law enforcement officials, and indeed much of the public, believe that video cameras support law enforcement investigations, offering the prospect of a video record of any crime committed in public areas where they are used. Such a record is believed to have both investigatory value\nOCR for page 256\nEngaging Privacy and Information Technology in a Digital Age (in identifying perpetrators) and deterrent value (in dissuading would-be perpetrators from committing crimes).3 However, these cameras also give those who operate them ever more information, often in the form of a reusable and possibly permanent record regarding where many law-abiding individuals are, who they are with, and what they are doing. Another example concerns automobiles equipped with tracking systems, such as General Motors’ OnStar system, that permit the location tracking to a fairly fine resolution of anyone holding a cell phone. (Such systems may be based on the use of GPS or on cell phones that provide location information as part of E-911 services.) By tracking people’s position over time, it is also possible to track their average speed,4 where they have been, and (by merging the positional information for multiple people) with whom they might have met. If such tracking is recorded, correlations can be made at any time in the future. Indeed, given the right monitoring equipment and enough recording space, it is even possible that the locations of every person for much of a lifetime could be made available to law enforcement agencies or even family members or researchers. Similar issues regarding data reuse arise with respect to the use of video cameras for the enforcement of traffic regulations. In many cities the traffic lights have been equipped with cameras that allow law enforcement agencies to determine violations of red-light stop zones simply by photographing the offending vehicles as they pass through the red light. Such images allow local police agencies to automatically send red-light-running tickets to the vehicle owners. Even such a seemingly straightforward use of surveillance technology, however, brings up a host of privacy 3 It is unquestionable that video records have had forensic value in the investigations of crimes that have already been committed. The deterrent effect is less clear. A study done for the British Home Office on the crime prevention effects of closed-circuit television (CCTV) cameras systematically reviewed two dozen other empirical studies on this subject and concluded that, on balance, the evidence suggested a small effect on crime reduction (on the order of a few percent) and only in a limited set of venues (namely, car parks). The deployment of CCTV cameras had essentially no effect in public transportation or in city-center contexts. Welsh and Farrington also noted that poorly controlled studies systematically indicated larger effects than did well-controlled ones. See Brandon Welsh and David Farrington, Crime Prevention Effects of Closed Circuit Television, Home Office Research Study 252, August 2002, available at http://www.homeoffice.gov.uk/rds/pdfs2/hors252.pdf. 4 A lower-tech version of this capability is inherent in toll systems on highways. For some highways, periodic toll plazas on turnpikes were replaced by a system in which the driver picked up a ticket at the point of entry that was then used to determine the toll at the location where the car exited. Given that these tickets included the time of entry into the turnpike, there were concerns that the tickets could also be used upon exit to determine if the car had exceeded the speed limit. Stories of such secondary use have the ring of urban myth, but they continue to surface on the Internet and are certainly consistent with what the technology enables.\nOCR for page 257\nEngaging Privacy and Information Technology in a Digital Age issues. For example, consider that these cameras could also be used to trace and record the presumed locations of people based on the observed time and location of their cars. That is, they could take pictures even when no car was running a red light. Such a concern is based on the future possibilities for repurposing the information gathered by such cameras rather than on the purpose for which these cameras were originally deployed. Note that nothing intrinsic in the use of a video system to catch those running traffic lights enables secondary use of the information. The system could be designed in such a way that only those images showing someone running a red light were kept, and all other images were discarded immediately. Such a system could not be used to track the location of any but a small number of vehicles. Designing such a system in this way is simple to do when the system is first being built but is far more difficult once the system has been installed. However, privacy concerns associated with possible secondary uses are usually not raised when a system is designed, if nothing else because those secondary uses are not yet known or anticipated. It could be argued that a video camera at the stoplight is no different in principle from posting a live police officer at the same place. A police officer can issue a ticket for a car that runs a red light, and if a live police officer on traffic detail at the intersection is not a threat to privacy, then neither is the placement of a video camera there. Others, however, would argue that a live officer could not accurately record all vehicles passing lawfully through the intersection, and could not be used to trace the movements of every vehicle passing through a busy intersection—lawfully or not—in the way that a video camera can. The image-retention capacity of a video system vastly exceeds that of even the most astute human observer and thus allows the tracking of all vehicles, not just those that are of interest at the time they move through the intersection. The images stored by the video system can, in principle, be not just those of vehicles that have violated the law, but of all vehicles that have passed by the camera. In addition, information gathered by a video camera ostensibly deployed to catch cars running a red light can be used for other purposes, such as tracking the location of particular cars at particular points in time, or finding speeders (this would require combining of information from multiple cameras at multiple locations)—purposes that are not possible with a human officer. Further, when the images are stored, law enforcement agencies gain the capability to track what individuals have done in the past, and not just what they are currently doing. The worry is that once the information has been gathered and stored, it will be used in a variety of ways other than that for which it was originally intended. Such “feature creep” is possible because what is stored is the raw information, in image form, which can be used in a variety of ways.\nOCR for page 258\nEngaging Privacy and Information Technology in a Digital Age Finally, video surveillance is far less expensive than the use of many human officers. From an economic point of view, it is impossible in large jurisdictions to station officers at every intersection, but placing a video camera at many intersections is much less expensive and within the means of many police departments. An important check on executive power has always been based on the allocation of resources, and if technology can enable a greater amount of police activity—in particular, more surveillance—for the same cost, the introduction of that technology changes the balance of power. Perhaps most importantly, this change in the balance of power is often unnoticed or not discussed—and when it is, a dispute about the amount of police activity must be resolved explicitly on policy grounds rather than implicitly on economic grounds. Beyond video technologies such as those discussed above, there is also the prospect that emerging technologies can extend the reach of observation from public spaces into what have traditionally been private spaces. There has been some use of infrared detectors to “look through” walls and see into a suspect’s home;5 although the Supreme Court recently suggested that such law enforcement surveillance tactics might violate the resident’s “reasonable expectation of privacy” (Section 1.5.5), the courts have not categorically rejected the use of such sophisticated imaging devices. If environmental sensors become pervasive, it may in the near future become possible to infer the location of people from the information gathered for purposes such as energy conservation—and to infer identities by correlating that information with other recorded information (such as building access records). The conditions under which law enforcement agencies will or should have access to such information raises difficult questions both of law and of policy. Concern over the potential use of such sensitive information lies at the heart of many privacy-based concerns about the deployment of such technologies. The deepest concern, from the privacy perspective, is the potential for combining constant and non-obvious data gathering and the ability to assemble the data gathered to give the effect of largely constant observation of any space, whether public or private. Such a prospect, combined with the temporally permanent nature of the data when they are stored, appears to give law enforcement agencies the ability to constantly monitor almost any place and to have access to a history of that 5 A number of court cases have been brought addressing the question of whether the use of a thermal-imaging device aimed at a private home from a public street to detect relative amounts of heat within the home constitutes a “search” within the meaning of the Fourth Amendment. The definitive ruling on this point is the decision of the U.S. Supreme Court in Kyllo v. United States, No. 99-8508 and decided on June 11, 2001, which held that it is a search and thus must be governed by the apparatus designed to protect the public against unreasonable searches.\nOCR for page 259\nEngaging Privacy and Information Technology in a Digital Age place. Together with the ability to aggregate and mine the data that have been gathered (discussed below), this prospect would appear to give law enforcement enormous amounts of information. The most serious issues arise if and when such technologies enable monitoring of specific individuals. Many present-day technologies indicate bodies, but not the identities of the persons who own those bodies. Future technologies may enable the identification of individuals—that is, the high-accuracy association of specific names with the bodies within view—in which case the privacy concerns are accentuated many-fold. (Even today, modern cell phones with location identification capabilities yield information about the whereabouts of individuals, because of the generally unviolated presumption that individuals carry their cell phones with them.) 9.1.3 Communications and Data Storage Both communication and data storage technologies have long been of interest and use to the law enforcement community. Being able to observe and overhear the discussions of those suspected of breaking the law and to obtain records of criminal activity has been an important means for gaining evidence—but has also created inevitable threats to principles of privacy. The primary difference between records and communications is that by definition, records are intended to persist over time, whereas communications are more transient. Transient phenomena vanish, and they are generally more private than persistent entities that can be reviewed anew, copied, and circulated. For this reason, technologies that threaten the privacy of records are often seen as less problematic than those that threaten the privacy of communications. For keeping records private, the most common technique used has been to hide the records in a location known only to their owner. One can “hide” records by placing the file in a secret location (e.g., in an “invisible” directory on one’s disk, on a CD-ROM stored under the mattress or under a rock in the back yard or in a safe deposit box, or embedded secretly in another document). Today, there are few generally applicable technologies that enable law enforcement authorities to find records in a secret location without the (witting or unwitting) cooperation of their owner. Thus, debates over the appropriate balance between the privacy of records—even digital records—and the needs of law enforcement authorities for those records have been relatively straightforward, and based on the ability of law enforcement authorities to compel or trick the owner into revealing the records’ location. (The use of encryption to hide records, discussed in more detail below, presents a wrinkle in this debate, but the\nOCR for page 260\nEngaging Privacy and Information Technology in a Digital Age same techniques are available to law enforcement authorities to compel or trick the owner or others into revealing the decryption keys that would allow law enforcement access.) But history paints a much different picture when it comes to communications. For the interception of telephone conversations, e-mail, and Internet-based communication, the proper balance between the claimed needs of law enforcement for access to such communications, and the privacy interests of persons who are the participants in the targeted communication, has been elusive and more difficult to define. When the Bill of Rights was enacted, communication consisted either of spoken language (which could only be heard directly) or written. Written communications are a type of record, and such records can be obtained by law enforcement personnel as the result of a search (under rules covered by the Fourth Amendment). But what of written communications being sent through the mails—were these communications more like utterances made in public, and therefore not subject to the same explicit protections of privacy, or were they more like records private and covered by the protections of the Fourth Amendment? In the case of mail carried by the U.S. Postal Service, the decision was that the outside of the mail (such as the address and return address) was public information, and not covered by the need for a search warrant,6 but that any communication inside the envelope was considered private and any viewing of that information by law enforcement required a search warrant obtained under the requirements of probable cause.7 As communication technologies advanced, the distinction between what was publicly available and what was private in those technologies became the crux of the debates about the privacy of those communica- 6 Ex Parte Jackson, 96 U.S. (6 Otto) 727,733 (1877). 7 The process by which national security investigators have obtained mail cover information has been governed by U.S. postal regulations for nearly 30 years. See 39 C.F.R. 233.3. The authority to use mail covers for law enforcement purposes first appeared in the 1879 postal regulations. Section 212 statutorily authorizes the continued use of mail covers in national security investigations. A “mail cover” is the process by which the U.S. Postal Service furnishes to the FBI the information appearing on the face of an envelope addressed to a particular address: i.e., addressee, postmark, name and address of sender (if it appears), and class of mail. The actual mail is delivered to the addressee, and only the letter carrier’s notation reaches the FBI. A mail cover does not include the contents of any “sealed mail,” as defined in existing U.S. postal regulations (see 39 C.F.R. 233.3(c)(3)) and incorporated in Section 212. Although the Supreme Court has not directly addressed the constitutionality of mail covers (the Court has denied certiorari in cases involving the issue), lower courts have uniformly upheld the use of mail covers as consistent with the requirements of the Fourth Amendment. See Vreeken v. Davis, 718 F.2d 343 (10th Cir. 1983); United States v. DePoli, 628 F.2d 779 (2d Cir. 1980); United States v. Huie, 593 F.2d 14 (5th Cir. 1979); and United States v. Choate, 576 F.2d 165 (9th Cir.), cert. denied, 439 U.S. 953 (1978).\nOCR for page 261\nEngaging Privacy and Information Technology in a Digital Age tions and what access law enforcement agencies had to the communication. Perhaps the best example concerns communication by telephone. When telephones were first introduced, the circuits were connected by an operator who often needed to listen in on the call to monitor quality, and most of the telephone lines were shared or “party” lines, allowing conversations to be heard by anyone with whom the line was shared (although good manners suggested not listening when the call was not for you). With this history, it was generally held that discussions over a telephone were like discussions in public, so that law enforcement agents could listen in on such conversations, and could use in criminal prosecutions the contents of what they heard, with no oversight and without the consent of those whose words were monitored. Indeed, in Olmstead v. United States, 277 U.S. 438 (1928), the U.S. Supreme Court held that “the reasonable view is that one who installs in his house a telephone instrument with connecting wires intends to project his voice to those quite outside, and that the wires beyond his house, and messages while passing over them, are not within the protection of the Fourth Amendment. Here those who intercepted the projected voices were not in the house of either party to the conversation.” In so holding, it ruled that “the wire tapping here disclosed [in the case] did not amount to a search or seizure within the meaning of the Fourth Amendment,” and thus that telephone conversations were not protected or privileged in any way over ordinary speech outside the home. There was, in this view, no (rational) expectation of privacy for such conversations (although the term “expectation of privacy” had not yet come into use). This view of telephone conversations lasted until 1967,8 when the Supreme Court ruled that there was, in fact, a constitutional expectation of privacy in the use of the telephone. By this time, operators were hardly ever used for the connection of circuits and were not expected to monitor the quality of phone conversations, nor were most phone lines shared. However, the decision that there was an expectation of privacy in such conversations lagged significantly behind the technological developments that created such an expectation. At this point, the court decided that telephone calls were like physical mail, in which each call had a public “outside” and a private “contents.” The public envelope contained the information necessary to establish the circuit for the call (including the phone from which the call was being made and the phone to which the call was made) but did not include the contents of the call, which was considered private. Gaining legal access to that part of the call required a warrant issued by a judge after a showing of probable cause. The last two decades have seen a novel set of communication technol- 8 Katz v. United States, 389 U.S. 347.\nOCR for page 292\nEngaging Privacy and Information Technology in a Digital Age the information that was used to make the determination. Even Edward Kennedy, senior senator from Massachusetts, has had problems getting his name off the watch list.29 Even if corrective mechanisms were in place, lists such as these suffer from a cluster of problems having to do with establishing the identity of those who are being compared to the list. If a list is kept in terms of names, its usefulness is limited by the fact that a single name can be shared by many different people. A combination of name and address may be better, but falls prey to the ease with which people move from place to place, and the time lag between such a move and the time at which all relevant records have been updated to reflect the new address. Indeed, such lists seem to presume, contrary to fact, that there is a way (or set of ways) to uniquely identify each person who might appear on such a list. There is no such mechanism available today, and establishing such a mechanism is far from simple.30 9.2.5 Tensions Between Privacy and National Security In many ways, the tension between privacy and national security parallels the tension between privacy and law enforcement. Both law enforcement and national security require government to amass large amounts of information about people, including much information that the subject or target might want to keep private and information that will ultimately not prove useful for any mission-related function. Both law enforcement and national security require that that information be analyzed to try to infer even more about a person. Both are heavy users of technology, and both use technology to gather information, identify individuals, and analyze that information. National security differs from law enforcement, however, in two significant ways. First, law enforcement authorities are usually (though not always) called in when a criminal act has been committed, and the criminal act itself serves to focus investigative resources—that is, they tend to be reactive. National security authorities are most interested in preventing hostile acts from taking place—they tend to be proactive. Second, most of the information gathered by law enforcement and used to prosecute a person for the violation of a law will eventually be made public, along with the mechanisms used to gather that information. Intelligence gathering 29 Rachel L. Swarns, “Senator? Terrorist? A Watch List Stops Kennedy at Airport,” New York Times, August 20, 2004. 30 See National Research Council, Who Goes There? Authentication Through the Lens of Privacy, Stephen T. Kent and Lynette I. Millett, eds., The National Academies Press, Washington, D.C., 2003.\nOCR for page 293\nEngaging Privacy and Information Technology in a Digital Age for the purposes of national security, on the other hand, is an intrinsically non-public activity. The mechanisms used to gather information, along with the information itself, are not made public, even when the information is used in a way that has an impact on the life of the subject of that information. This greater need for secrecy makes it unlikely that citizens will be able to discover if the agencies charged with national security are violating their privacy. The mechanisms for gathering information are often unknown, so those wishing to ensure privacy may not know the techniques against which they must guard. The information gathered must remain secret, and so there is no easy way to know what information is gathered, if that information is accurate, whether it might be subject to different interpretations, or how to correct the information if it is inaccurate or incomplete. The only thing known with certainty is that there is an entity that is capable of gathering information about foreign governments, and it is reasonable to presume that such an entity can easily gather information about private citizens in the United States. Because of the secret nature of the information gathered by national security agencies, it can be difficult to establish a trust relationship if one does not already exist between the citizens about whom the information is gathered and the agencies doing the gathering. There are few in the United States who would worry about the gathering of information even within the borders of the United States and about U.S. citizens if they could be assured that such information was only being used for genuine national security purposes, and that any information that had been gathered about them was accurate and appropriately interpreted and treated. How to obtain that assurance is a public policy issue of the utmost importance. This is why oversight is so important, all the more so in times of crisis. Accountability need not mean indiscriminate transparency; rather, trusted agents such as members of Congress or special commissions should be entrusted with offering, and hopefully can be trusted to offer, needed assurances. 9.3 LAW ENFORCEMENT, NATIONAL SECURITY, AND INDIVIDUAL PRIVACY Even before the formation of our nation, government was seen as posing the principal threats to individual privacy. Many of the grievances against the English crown that were detailed in the Declaration of Independence reflected an erosion of the right to be left alone, and many provisions of the Bill of Rights sought to codify limitations on government power which the framers saw as vital to the new nation. While the Constitution nowhere expressly recognizes a “right to privacy,” several\nOCR for page 294\nEngaging Privacy and Information Technology in a Digital Age provisions (especially, but not only, the Fourth Amendment) unmistakably limit the power of government to invade the lives of citizens. When law enforcement and national security are concerned, the sources of concern about privacy rights are readily apparent. On the one hand, law enforcement must be able to gather information about individuals in order to identify and apprehend suspects and to enforce criminal law and regulatory standards. National security agencies gather and analyze information about individuals and organizations in order to protect and enhance national security. On the other hand, the very process of gathering and using such information may pose serious risks to individual privacy. A somewhat similar set of tensions apply to data that have already been collected for some purpose other than law enforcement or national security. As noted in earlier chapters, a wide variety of personal information on individuals is collected for a wide variety of purposes by both government agencies (e.g., the Internal Revenue Service, the Census Bureau) and private sector organizations such as banks, schools, phone companies, and providers of medical care. In some instances (such as survey data collected by the Census Bureau), such information has been collected under a promise, legal or otherwise, that it would be used for a certain purpose and only for that purpose, and would otherwise be kept confidential.31 If and when external circumstances change (e.g., the nation comes under attack), some would argue strongly that it is criminal to refrain from using all resources available to the government to pursue its law enforcement and national security responsibilities. Others would argue just as strongly that the legal restrictions in effect at the time of data collection effectively render such data unavailable to the government, legally if not physically. According to scholars William Seltzer and Margo Anderson,32 an example of such government use of privileged data occurred during World War II, when the Bureau of the Census assisted U.S. law enforcement authorities in carrying out the presidentially ordered internment 31 One exception is that the USA PATRIOT Act of 2001 allows the attorney general to obtain a court order directing the Department of Education to provide to the Department of Justice data collected by the National Center for Education Statistics (NCES) if such data are relevant to an authorized investigation or prosecution of an offense concerning national or international terrorism. However, the law also requires the attorney general to protect the confidentiality of the data, although the standards used for such protection are formulated by the attorney general “in consultation with” the Department of Education. Prior to the passage of the USA PATRIOT Act, NCES data were to be used only for statistical purposes. 32 William Seltzer and Margo Anderson, “After Pearl Harbor: The Proper Role of Population Data Systems in Time of War,” paper presented at the annual meeting of the Population Association of America, Los Angeles, California, March 2000, available at the American Statistical Association’s Statisticians in History Web site.\nOCR for page 295\nEngaging Privacy and Information Technology in a Digital Age of Japanese-Americans. In a meeting of the Census Advisory Committee held in January 1942, J.C. Capt, director of the census, was reported to say, “We’re by law required to keep confidential information by [sic] individuals. But in the end, [i]f the defense authorities found 200 Japs missing and they wanted the names of the Japs in that area, I would give them further means of checking individuals.” It is not known if the Census Bureau actually provided information on individual Japanese-Americans, but Seltzer and Anderson cite documents indicating that the Census Bureau clearly did provide mesodata (i.e., census results tabulated for very small geographic units, some as small as a city block) that did facilitate the internment process. Indeed, on the Monday after the December 7 attack on Pearl Harbor (which occurred on a Sunday), the Census Bureau initiated the production of reports on the distribution of Japanese-Americans across the United States based on macrodata (data from the 1940 census aggregated in terms of large geographic units). Seltzer and Anderson note also that the Census Bureau has recognized possible threats to privacy arising from certain kinds of mesodata, and in response has progressively introduced stricter disclosure standards. Indeed, the bureau has indicated that under the standards now in place the release of mesodata from the 1940 census on Japanese-Americans would have been severely restricted. A number of points are worth noting about this example. First, whether or not the Census Bureau provided information on individuals, the use of census data violated the spirit of the confidentiality law in the sense that respondents provided information under promises of confidentiality33—information that was subsequently used against them. Second, Capt’s remarks suggest a willingness to exploit legal loopholes in order to cooperate with the internment order. Third, even if the actual wording of the confidentiality promise made a “fine print” provision for “other legally authorized uses,” it would still have left survey respondents with the impression that their responses were confidential. 33 For example, President Herbert Hoover’s proclamation in 1929 for the 15th census said that “the sole purpose of the census is to secure general statistical information regarding the population and resources of the country…. No person can be harmed in any way by providing the information required. The census has nothing to do with … the enforcement of any national, state, or local law or ordinance. There need be no fear that any disclosure will be made regarding any individual person or his affairs….” In addition, the 1940 census enumeration form itself said that “only sworn census employees will see your statements. Data collected will be used solely for preparing statistical information concerning the Nation’s population, resources, and business activities. Your Census Reports Cannot Be Used for Purposes of Taxation, Regulation, or Investigation” [capitalization in the original]. See Thomas F. Corcoran, “On the Confidential Status of Census Reports,” The American Statistician 17(3):33-40, 1963.\nOCR for page 296\nEngaging Privacy and Information Technology in a Digital Age Issues related to privacy in a law enforcement or national security context are hard for citizens to assess. Citizens are not told what information these agencies are capable of gathering or what they do gather, because that knowledge being made public can limit the very information that agencies will be able to gather. In addition, the stakes are higher because these agencies can use information they gathered to imprison citizens. Citizens are asked to trust that abuses are not occurring and to trust in the oversight mechanisms that often require one part of the government to ensure that another is not generally overstepping appropriate bounds. Similarly, law enforcement and national security agencies are put into a difficult position regarding the gathering and analysis of information. If these agencies fail to gather enough information to accomplish their missions, they are faulted for not using the latest techniques and technologies. However, if these agencies are perceived as gathering too much information about ordinary citizens, they are faulted for invasion of privacy. Unfortunately, it is often impossible to determine, before the fact, who is going to be a law breaker or terrorist in the future. There is no way for law enforcement and national security agencies to determine about whom they should gather information without requiring that these agencies also know the future. The conundrum is further accentuated by a declaratory national policy that emphasizes prevention of terrorist attacks rather than prosecution or retaliation after they occur. That is, law enforcement activities must take place—successfully—in the absence of the primary event that usually focuses such activities. With few definitively related clues to guide an investigation, a much more uniform spread of attention must be cast over those who might have some contact or connection, however tenuous, to a possible terrorist event in the future. The best that can be expected is that these agencies put into place the appropriate safeguards, checks, and balances to minimize the possibility that they gather information in an inappropriate way about citizens. But the more such safeguards are in place, so the argument goes, the more likely it is that mistakes are made in the opposite direction, and that these agencies will miss some piece of information that is vital for the performance of their function. Yet areas of overlap between privacy and law enforcement and national security also exist. For example, citizens who have faith in their government and who believe that it generally follows democratic rules (one reflection of which is respect for privacy) will be more likely to cooperate with law enforcement in providing information and other forms of support. In that sense, just as it is sometimes said that privacy is a good business practice, it might also be said that a law enforcement agency’s respect for a citizen’s privacy, rather than necessarily being in opposition to, can be supportive of law enforcement goals.\nOCR for page 297\nEngaging Privacy and Information Technology in a Digital Age An important influence on the process of balancing governmental and societal needs for safety and security and individual privacy is the fact that public safety is—almost by definition—a collective benefit, while government infringements of privacy in the name of public safety tend to affect individuals or relatively small or politically marginal groups of people, at least in the short term. Under such circumstances, it is easier for public safety officials to dismiss or minimize privacy concerns that their actions might raise. As an illustration of the sentiment, Harvard Law School Professor William Stuntz has asserted that “reasonable people can differ about the balance, but one could plausibly conclude that the efficiency gains from profiling outweigh the harm from the ethnic tax that post-September 11 policing is imposing on young men of Middle Eastern origin.”34 The flip side of this sentiment, of course, is that community involvement and good will may well be an essential element, perhaps the most important element, of a strategy that seeks to counter terrorists concealing themselves in the nation’s communities. That is, tips about unusual and suspicious behavior are most likely to emerge when the communities in which terrorists are embedded are allied with, or at least not suspicious of, law enforcement authorities—and singling out young men of Middle Eastern origin for special scrutiny is not an approach that will create a large amount of good will in the affected communities. These tensions have been magnified since the terrorist attacks of September 11. There are many who feel that if the right information had been available, along with the right tools to analyze that information and the right governmental structures that would allow the sharing of the information between law enforcement and national security agencies, those attacks could have been avoided. Part of the reaction to those attacks was the passing of laws and the creation of policies that made it easier for agencies to collect and share information and the weakening of some traditional checks and balances in the hope of enhancing national security. At the same time, there is worry that the increasingly sophisticated technology available for surveillance, data sharing and analysis, and data warehousing, when joined with the weakening of rules protecting individual information, will allow law enforcement and national security agencies a vastly expanded and largely unseen ability to monitor all citizens. The potential for abuse given such an ability is easy to imagine—for example, a law enforcement agency might be able to monitor the group gatherings of citizens objecting to a certain government policy, identifying who they meet with and perhaps what they talk about. Most citizens do not know what is technically possible, either now or in the near future. Because of this, there is often a tendency to believe that the technology 34 See William Stuntz, “Local Policing After the Terror,” Yale Law Journal 111:2137, 2002.\nOCR for page 298\nEngaging Privacy and Information Technology in a Digital Age is capable of far more than it can actually do, either currently or in the foreseeable future. The problem may not be in what these government agencies are capable of doing with technology, but rather with what the citizens believe those agencies can do. These comments should not be taken to suggest that policy makers in government agencies are unaware of privacy interests. For example, under the E-Government Act of 2002, any federal agency contemplating a substantially revised or new information technology system is required to develop a privacy impact assessment (PIA; Box 9.5) for such a system before work on that system begins in earnest. In the case of the Department of Homeland Security (DHS), DHS officials indicate that findings of PIAs are, to some extent, folded into the requirements development process in an attempt to ensure that the program or system, when deployed, is at least sensitive to privacy considerations. (It should also be noted that DHS officials reject the paradigm that privacy trades off against security; they assert that the challenge is enhancing security while protecting privacy.) Nevertheless, the concern from the privacy advocates remains regarding the extent to which privacy considerations are taken into account, and the specific nature of the privacy-driven system or program adaptations. BOX 9.5 The Department of Homeland Security Privacy Impact Assessment A privacy impact assessment (PIA) is an analysis of how personally identifiable information is collected, stored, protected, shared, and managed. “Personally identifiable information” is defined as information in a system or online collection that directly or indirectly identifies an individual whether the individual is a U.S. citizen, legal permanent resident, or a visitor to the United States. The purpose of a PIA is to demonstrate that system owners and developers have consciously incorporated privacy protections throughout the entire life cycle of a system. This involves making certain that privacy protections are built into the system from the start, not after the fact when they can be far more costly or could affect the viability of the project. Personally identifiable information is information in a system, online collection, or technology (1) that directly identifies an individual (e.g., name, date of birth, mailing address, telephone number, Social Security number, e-mail address, zip code, address, account numbers, certificate and license numbers, vehicle identifiers including license plates, uniform resource locators, Internet Protocol addresses, biometric identifiers, photographic facial images, or any other unique identifying number or characteristic), or (2) by which an agency intends to identify specific individuals in conjunction with other data elements, that is, indirect identification. These data elements may include\nOCR for page 299\nEngaging Privacy and Information Technology in a Digital Age Finally, the discussion in this chapter raises the question of what must be done when law enforcement authorities or intelligence agencies invade the privacy of Americans who are law-abiding or who pose no threat to national security. It is unrealistic to expect that the number of false positives (i.e., the number of people improperly implicated) can be reduced to zero, and thus public policy must necessarily anticipate that some such cases will arise. One option is to minimize the number of false positives, and in the event of a false positive, the person improperly implicated simply absorbs the cost and consequences of the false positive (e.g., loss of privacy and any consequential costs, such as personal embarrassment, financial loss, and so on) on behalf of the rest of society. But these costs and consequences can be dire indeed, and at least in principle our society has generally adopted the principle that individuals suffering the consequences of improper or mistaken government behavior are entitled to some kind of compensation. Providing recourse for citizens improperly treated by government authorities is generally thought to make government authorities more careful and more respectful of rights than they might otherwise be. a combination of gender, race, birth date, geographic indicator, and any information that reasonably can be foreseen as being linked with other information to identify an individual. In some cases the technology might only collect personal information for a moment. For example, a body-screening device might capture the full scan of an individual, and even if the information was not retained for later use, the initial scan might raise privacy concerns, and thus the development and deployment of the technology would require a PIA. Questions asked by the PIA include the following: Section 1.0 Information collected and maintained 1.1 What information is to be collected? 1.2 From whom is information collected? 1.3 Why is the information being collected? 1.4 What specific legal authorities, arrangements, or agreements define the collection of information? 1.5 Privacy Impact Analysis: Given the amount and type of data being collected, discuss what privacy risks were identified and how they were mitigated. Section 2.0 Uses of the system and the information 2.1 Describe all the uses of information. 2.2 Does the system analyze data to assist users in identifying previously un\nOCR for page 300\nOCR for page 301\nEngaging Privacy and Information Technology in a Digital Age 6.3 Do individuals have the right to consent to particular uses of the information, and if so, how does the individual exercise the right? 6.4 Privacy Impact Analysis: Given the notice provided to individuals above, describe what privacy risks were identified and how they were mitigated. Section 7.0 Individual access, redress and correction 7.1 What are the procedures that allow individuals to gain access to their own information? 7.2 What are the procedures for correcting erroneous information? 7.3 How are individuals notified of the procedures for correcting their information? 7.4 If no redress is provided, are alternatives available? 7.5 Privacy Impact Analysis: Given the access and other procedural rights provided for in the Privacy Act of 1974, explain the procedural rights that are provided and, if access, correction, and redress rights are not provided, explain why not. Section 8.0 Technical access and security 8.1 Which user group(s) will have access to the system? 8.2 Will contractors to DHS have access to the system? If so, please submit to the Privacy Office with this PIA a copy of the contract describing their role. 8.3 Does the system use “roles” to assign privileges to users of the system? 8.4 What procedures are in place to determine which users may access the system, and are they documented? 8.5 How are the actual assignments of roles and rules verified according to established security and auditing procedures? 8.6 What auditing measures and technical safeguards are in place to prevent misuse of data? 8.7 Describe what privacy training is provided to users either generally or that is specifically relevant to the functionality of the program or system. 8.8 Are the data secured in accordance with FISMA requirements? If yes, when were certification and accreditation last completed? 8.9 Privacy Impact Analysis: Given access and security controls, describe what privacy risks were identified and how they were mitigated. Section 9.0 Technology 9.1 Was the system built from the ground up or purchased and installed? 9.2 Describe how data integrity, privacy, and security were analyzed as part of the decisions made for your system. 9.3 What design choices were made to enhance privacy? SOURCE: Department of Homeland Security, Privacy Impact Assessments: Official Guidance, DHS Privacy Office, available at http://www.dhs.gov/interWeb/assetlibrary/privacy_pia_guidance_march_v5.pdf.\nOCR for page 302\nEngaging Privacy and Information Technology in a Digital Age This page intentionally left blank.\nRepresentative terms from entire chapter:", "label": 1}
{"text": "Technology: Beware the Cyberattacker\n|by Ronald N. Weikers and Kevin P. Cronin\nWinter 2003, Vol. 65, No. 4\nTrespass and burglary used to involve purely physical acts, such as rattling doorknobs, lifting windows and leaving a home bare of valuables. Today, however, our increasingly networked world offers an entirely new landscape for these old crimes. The tools of crime, too, have changed: culprits now use \"port sweeps,\" wireless \"wardriving\" and electronic \"snooping\" and \"sniffing\" to detect vulnerable computer systems over the Internet or through the airwaves, often leaving no clues.\nAlthough data, the target of these intrusions, is intangible, the perceptible damage hackers can cause to security and privacy is of a magnitude unthinkable just a few years ago. To combat this problem, companiesand, to a lesser degree, individualshave begun to use a variety of technical safeguards. Lawmakers, too, are concerned about security and privacy issues and have enacted several major data security and privacy laws and regulations in recent years.\nTechnology's Hidden Cost\nAlthough \"cybersecurity\" can significantly hike the expense of installing and maintaining computer systems, the cost of ignoring security and privacy vulnerabilities may be much higher. Cyberattacksoften using \"malware,\" malicious software, such as worms and virusescause billions of dollars in damage each year. U.S. businesses have spent an estimated $40 billion in remediating cyberattacks in just the past three years. Historically, government agencies were the most common targets of hacking, but today corporations are becoming more frequent victims. The following is a sampling of cyberattacks that have occurred during the past decade:\n- 1994 New York: Russian computer expert, using a personal computer and stolen passwords and IDs, penetrated Citibank's cash management system and illegally transferred more than $10 million to bank accounts in California, Finland, Germany, the Netherlands, Switzerland and Israel.\n- 1996 Connecticut: After being laid off, a former network administrator wrote six lines of software that destroyed his employer's manufacturing system programs. The event led to more than $10 million in losses and $2 million in reprogramming costs, and ultimately caused eighty layoffs.\n- 1996 Nationwide: Hackers tapped into WebCom, a large Internet service provider, wiping out more than 3,000 sites for forty hours. Many of the sites were those of retailers trying to capitalize on the Christmas rush.\n- 1999 Worldwide: The \"Melissa\" virus was the first virus to spread by e-mail through Outlook address books, causing an estimated $1.2 billion in damage.\n- 2000 Nationwide: The first \"Distributed Denial of Service\" (DDoS) attacks were launched, shutting down major commercial Web sites, including Yahoo!, Amazon.com, CNN and e-Bay, and causing more than $1 billion in damage.\n- 2000 Worldwide: The \"Love Bug\" worm spread faster than any worm in history, causing an estimated $8.7 billion in damage to forty million computers.\n- 2001 Worldwide: The \"Code Red\" worm infected more than 250,000 servers within hours of its activation.\n- 2002 Worldwide: The \"Klez\" and \"Bug-bear\" worms broke through anti-virus protections, gathering data from hard drives and logging users' keystrokes.\n- 2002 Worldwide: In October, unknown hackers launched a massive DDoS attack against the Internet's thirteen domain name root serverswhich are critical for directing data flow between other Internet serverscausing nine to crash and the Internet to slow down throughout the world.\nThese attacks may prophesy more numerous and more damaging attacks in the future. The federal government and all fifty states have enacted criminal and civil legislation prohibiting unauthorized access, malware distribution, DDoS attacks and other forms of hacking. These laws generally cast traditional legal concepts, such as trespass and conversion, in terms of modern technology. Also, a number of statutes and regulations require companies to implement preventive security and privacy measures, particularly in the financial and health care industries, such as the Gramm-Leach-Bliley Act (GLBA) and the Health Insurance Portability and Accountability Act (HIPAA), which regulate personal data. Federal Security Laws\nThe Computer Fraud and Abuse Act (CFAA) is the broadest tool for combating computer crime. The CFAA imposes criminal penalties on hackers who improperly access, improperly attempt to access, or damage computers. The 1996 amendments expanded the scope of the CFAA to cover \"protected computers\" used in interstate commerce, which include virtually any computer connected to the Internet. Fines may be levied against violators, and the 2001 amendments under the USA Patriot Act impose prison sentences of up to twenty years.\nThe Electronic Communications Privacy Act (ECPA) expands coverage of the Federal Wiretap Statutes by prohibiting interception of wire and electronic communications, and prohibiting unauthorized alteration or access, or preventing access, to wire or electronic communications while in electronic storage. One of the primary purposes of the ECPA was to extend to electronic communications the same protection against unauthorized interceptions that wiretap laws had been providing for oral and wire communications via common carrier transmissions. In addition to criminal sanctions, the ECPA provides a private cause of action, with minimum statutory damages of $1,000 per violation. A variety of other federal laws prohibit behavior related to hacking. These statutes include the Federal Wire Fraud Statutes, the No Electronic Theft Act, the National Stolen Property Act, the Economic Espionage Act, the Computer Security Act, the Copyright Act, the Lanham Act and the Digital Millennium Copyright Act.\nState Security Laws\nReflecting this federal push for increased security legislation, all fifty states have enacted some form of legislation that prohibits unauthorized access or interruption of a computer system, as well as theft, destruction, copying, examination, use or misuse of data. Depending on the damage caused, the degree of mens rea and the means utilized in committing the crime, penalties may include fines of tens of thousands of dollars and decades of imprisonment.\nIn Pennsylvania, hackers face up to seven years' imprisonment and $15,000 in fines for intentionally spreading viruses or unlawfully accessing or damaging computer systems or data. New Jersey, New York and Delaware hackers face similarly harsh penalties. Because technical measures are not perfectly effective against cyberattacks, it is likely that criminal penalties will begin to have a deterrent effect once prosecutions become publicized.\nHackers typically act independently of any organization that authorizes, or can afford to compensate victims of, their conduct. There have been several documented instances of institutional hacking, but those are rare exceptions to the rule. Thus, if hackers can be found, they are usually judgment proof.\nAs such, in the future it is highly likely that victims of cyberattacks will seek compensation from corporations that are lax in their security measures, enabling hackers to launch attacks from their vulnerable systems, even if the defendants are victims themselves. Plaintiffs will proceed under traditional negligence concepts, arguing that companies have a duty to protect themselves and others from hacking, given that security technology is prevalent and inexpensive relative to the damage that can result. In other words, \"upstream\" victims have a duty to protect \"downstream\" victims based on a reasonableness standard, or based on standards set by new security and privacy rules and regulations, such as GLBA and HIPAA. Plaintiffs may also assert various contract theories where the parties are engaged in business together. They may also allege that owners of servers connected to the Internet implicitly agree to provide a certain level of security.\nAt least one such complaint has already been filed. Apparently, one Web hosting company's negligent security enabled a hacker to use its server as a platform to launch a DDoS attack against another Web hosting company, taking 90,000 Web sites offline in the process. The case settled prior to trial.\nIf a deep pocket cannot be found, victims will seek first-party coverage from insurers for damage to their own systems. Upstream victims may also seek coverage under their third-party liability policies for damage to downstream victims.\nCurrent property policies generally exclude damage to computer systems and data losses. Where cyberattacks are not specifically excluded, courts have almost uniformly held that losses of data and software are not covered by property policies, because they are not \"tangible\" losses. A number of insurers do offer e-commerce or Internet insurance for precisely these types of claims. Premiums, however, have recently skyrocketed, and insurers are becoming so savvy that they are charging even higher premiums for those types of systems that they deem to be more vulnerable, based on statistical analyses of intrusions.\nWhile cyberattacks and digital privacy intrusions can be analogized to more traditional civil and criminal law violations, the technology they employ is totally new, making their perpetrators more elusive, and the damage they cause often more widespread. As we become more dependent upon data and networks to operate our businesses, government, national defense and other critical functions, the risks posed by hacking, malware and cyberattacks escalate. As such, practitioners must inform themselves about data security and privacy compliance, and about remedies for cyberattacks.", "label": 1}
{"text": "I think you're looking in the wrong direction. There are two aspects to consider: the security of your laptop, and the security of your connections.\nFor the security of your connections, what matters is that you are using SSL (or TLS — treat it as a synonym of SSL) with a correct certificate. An HTTPS connection means HTTP (the usual web protocol) over SSL. SSL provides end-to-end confidentiality and integrity protection, so it doesn't matter whether you are browsing from a “secure” network or from a public wifi hotspot.\nWhat does “correct certificate” mean? A certificate is a website's “identity card”, providing a cryptographic means for your browser to verify that the website is who it claims to be. If the certificate verification didn't happen, you would have no way to know whether the SSL connection was going to the legitimate website or to a man-in-the-middle. In a good first approximation, you need to check three things to know that you have a secure connection to the desired website:\n- The URL must begin with\nhttps://, and browsers will typically show a padlock icon next to the URL.\n- If you see any scary warning, the connection is not secure. (A scary warning could be due to server misconfiguration too, and this is unfortunately more common than it should be. But if you see a scary warning when attempting to connect to your bank, I don't advise bypassing the warning.)\n- You must be connecting to the right URL in the first place. This means you should always connect to your bank from a bookmark, not by typing the URL (risk of typo) and never ever by clicking in an email or web link that you're not 200% sure comes from the bank (42nd National Bank is probably not a legitimate site).\nA VPN doesn't add much security over an HTTPS connection. A VPN protects the connection from your laptop to the VPN endpoint, which includes the point at which attacks are most likely (the local network where your laptop is plugged into or the wifi hotspot that it's connected to), but HTTPS provides end-to-end confidentiality and integrity anyway. VPNs have their uses, but they're esentially irrelevant for web banking:\n- An enterprise VPN connects your laptop to your enterprise network. The main point is to make securing the enterprise network a lot easier: anyone trying to connect to a server on the enterprise network must have passed some form of authentication already, either physically on the premises or logically by possessing the VPN key/password.\n- A VPN can provide a bit of privacy at the location where your laptop is connecting from: anyone snooping there will only see your VPN traffic as a whole, instead of individual connections which are undecipherable (if using SSL correctly) but whose endpoint is clearly identified.\n- A VPN can let you connect to sites that are blocked by an enterprise, ISP or government firewall, as long as those sites are visible from the VPN endpoint.\nAs far as securing a connection from your laptop is concerned, WEP and WPA(2) are completely irrelevant. They are technologies for securing a wifi access point; a laptop connecting to that access point doesn't benefit from them in any useful fashion.\nIPsec, SSL/TLS, SSH can be technologies underlying a secure connection such as a VPN, but they're not really relevant at your level. They compete on ease of set up, possibility of piercing through firewalls, performance, but not on security.\nDNSSEC today isn't widely deployed. Until then, assume that DNS is insecure, and rely on SSL to tell you whether you're connecting to the right site. Connection hijacking could happen at the IP level anyway.\nFinally, none of these are relevant to securing your computer against external or internal attacks. For external attacks tried by someone on the local network, what matters is not what protocols you actively use but what protocols you have open on your machine. The defense is not to run services that you don't use, to have sane firewall settings (most laptops don't need to accept any form of incoming connection) and to keep your operating system and applications up to date. The biggest attack vector nowadays is through content that you have retrieved, e.g. a web page that attempts to exploit a bug in your web browser. The defense against these is not to download risky files such as executable, to avoid browsing dodgy sites or clicking on links in suspicious emails, and to keep your operating system and applications up to date.", "label": 1}
{"text": "How to find out that a NIC is in promiscuous mode on a LAN?\nDNS test - many packet sniffing tools perform IP address to name lookups to provide DNS names in place of IP addresses. To test this, you must place your network card into promiscuous mode and sends packets out onto the network aimed to bogus hosts. If any name lookups from the bogus hosts are seen, a sniffer might be in action on the host performing the lookups.\nARP Test - When in promiscuous mode the driver for the network card checks for the MAC address being that of the network card for unicast packets, but only checks the first octet of the MAC address against the value 0xff to determine if the packet is broadcast or not. Note that the address for a broadcast packet is ff:ff:ff:ff:ff:ff. To test for this flaw, if you send a packet with a MAC address of ff:00:00:00:00:00 and the correct destination IP address of the host. After receiving a packet, the Microsoft OS using the flawed driver will respond while in promiscuous mode. Probably it happens just with the default MS driver.\nEther Ping test - In older Linux kernels when a network card is placed in promiscuous mode every packet is passed on to the OS. Some Linux kernels looked only at the IP address in the packets to determine whether they should be processed or not. To test for this flaw, you have to send a packet with a bogus MAC address and a valid IP address. Vulnerable Linux kernels with their network cards in promiscuous mode only look at the valid IP address. To get a response, an ICMP echo request message is sent within the bogus packet leading to vulnerable hosts in promiscuous mode to respond.\nMaybe there are more, the DNS test for me is the most reliable\nVP01 gave the theory, I will give some tools.\nFor use in linux systems:\nSniffDet: This one employs 4 different tests: ICMP test, ARP test; DNS test and also a LATENCY test (which VP01 didn't mention). The tool is recently updated and I recommend it.\nNMAP : There is an NSE script for nmap called sniffer-detect.nse which does just that.\nNAST: - it detects other PC's in promiscuous mode by doing the ARP test.\nPTOOL - does ARP and ICMP test\nFor windows systems: Cain & Abel can do a promiscuous scan using many types of ARP tests.\nMicrosoft has tools for this purpose too. Promqry and PromqryUI - but I'm not really sure how they work.\nAs for general detection techniques, there's also another one, called honeypot detect. Details about the latency test and the honeypot technique can be found in sniffdet's documentation.\nYou can't guarantee that you'll be able to detect it.\nFor example, you can easily make a read-only ethernet cable by looping the TX+ (pin 1) and TX- (pin 2) of the sniffing computer, then set TX+ (pin 1) to RX+ (pin 3 of the sniffer) and TX- (pin 2) to RX- (pin 6 of the sniffer). It will then be impossible for the sniffing computer to affect any data traffic on the network.\nIt may be possible to detect a voltage drop or RF emissions (along the lines of Van Eck phreaking), but I'm not aware of any COTS hardware that will detect it.\nWhile it may not always be possible to identify if the local network is promiscuously sniffing the local network traffic -- it may be possible to crash most or all packet capture applications doing so.\nCheck out Samy's http://samy.pl/killmon.pl script for a starting point. Realize that most applications working in 2011 are vulnerable to at least a DoS crash attack, even if the crash isn't vulnerable as a memory access violation (or a read/write exception that leads to a buffer overflow).\nI believe there is a tool that reliably detects this by looking at the difference in ping response times. The tool sends pings and at the same time send a large number of pings to the same IP address but with a different MAC addresses.\nThe tool works because cards in promiscuous mode will be returning all traffic to the CPU thus when there is a lot of packets hitting the CPU this will slow the response to genuine pings. A card in normal mode would be ignoring all packets with different MAC addresses so there would be no difference in the response time.\nSomeone insert the name of the tool", "label": 1}
{"text": "Responding to the growing threat of identity theft.\nIdentity theft is the fastest-growing crime in the world, and while it is commonly thought of as a mostly petty crime involving stolen personal credit cards or social security numbers, it is now becoming a larger threat to governments and corporations. Multiple Web sites offering fake driver’s licenses and social security cards for as little as $75, paired with identity theft’s increased ties to organized crime, have made it a vital homeland security issue. According to Ali M. AlKhouri, a final-year doctoral researcher at the University of Warwick and a senior government official in the United Arab Emirates, and Jay Bal, an associate professor, principal research fellow in the International Manufacturing Centre and director of the InterLean Ebusiness Centre at the University of Warwick, an increasing emphasis on e-commerce and e-government means that organizations are under major threat to not only protect their customers but their own sensitive and proprietary data.\nIn a 2007 working paper, Digital Identities and the Promise of the Technology Trio: PKI, Smart Cards, and Biometrics, AlKhouri and Bal examine three existing technologies and introduce a framework for how they can be combined into a comprehensive security system. The first of these, biometrics, is the use of an iris scan or physical traits, such as fingerprints, voice, hand or face geometry, to identify an individual positively. The second, smart cards, features integrated chips that store and process data, and they can come with a variety of accessories, including magnetic strips, bar codes, optical strips and holograms. Finally, public key infrastructure is a framework for creating a secure method of exchanging information data through encryption. In a PKI environment, a pair of keys — a public key that is known by the user and a private key used only by the system itself — are employed so data encrypted with one key can be decrypted only with the other complementary key and vice versa.\nAt least one of these three systems is in use in almost every major organization. And most studies have shown that PKI can be employed to handle most security and verification operations, but according to the authors, other requirements such as availability, performance, uncoercibility, untraceability and anonymity cannot be fulfilled without additional measures. PKI on its own will not provide maximum security for authentication unless it is incorporated with other security technologies such as smart cards and biometrics.<", "label": 1}
{"text": "Network and Computer Security Tutorial Version 0.4.0 April 16, 2001\nThis computer security tutorial is written based on my experiences with computer and network security along with my training and information I have read. The field of security is constantly changing so I cannot guarantee that information in this computer security tutorial will be current. This computer security tutorial will define some basic security issues and give insight into what causes security to be a constant issue. This computer security tutorial will help you decide what to protect and provide some basic information about attacks that may be made against your network, computer systems, or data. It will also provide computer and network security recommendations for you or your organization. Although much useful information can be derived from this document without the reader having networking knowledge, to use this document in depth, I recommend that readers of this computer security tutorial have a fundamental knowledge about networking. The information contained in The CTDP Networking Guide contains the networking documentation required to understand this computer security tutorial.\nIn this computer security tutorial, the terms computer security and network security will be used often. When the term computer security is used, it specifically refers to the security of one computer, although the overall security of each individual computer is required for network security. When the term network security is used, it refers to the security of the network in general. This includes such issues as password security, network sniffing, intrusion detection, firewalls, network structure and so forth.\nSecurity Violation Definition\nComputer or network security has been violated when unauthorized access by any party occurs.\nComputer security is required because most organizations can be damaged by hostile software or intruders. There may be several forms of damage which are obviously interrelated. These include:\nThe methods used to accomplish these unscrupulous objectives are many and varied depending on the circumstances. This guide will help administrators understand some of these methods and explain some countermeasures.\nComputer security can be very complex and may be very confusing to many people. It can even be a controversial subject. Network administrators like to believe that their network is secure and those who break into networks may like to believe that they can break into any network. I believe that overconfidence plays an important role in allowing networks to be intruded upon. There are many fallacies that network administrators may fall victim to. These fallacies may allow administrators to wrongfully believe that their network is more secure than it really is.\nThis guide will attempt to clarify many issues related to security by doing the following:\nThere are many different aspects to computer and network security as you will read in this document. These different areas of computer security are interdependent on each other in order for a network to be secure. If one or more areas of computer security are ignored, then the entire security integrity of the organization's network may be compromised. A clear example of this is in the area of computer virus or worm protection. Computer virus protection programs can only filter known viruses or worms. There are viruses or worms that are not yet recognized as virus programs immediately after their release. The best way to make unrecognized virus or worm programs less effective is by quickly removing the vulneribilities that they use. Some of these vulnerabilities are operating system and application program errors. When security patches are created for software, they should be quickly applied. In this way the vulnerabilty to viruses is minimized but not eliminated. There are other steps which may further reduce this vulnerability, but it can never be completely eliminated.\nIf you are reading this document and are thinking that you can get all the information required to make your network completely secure, then you are sadly mistaken. In many ways, computer security is almost a statistical game. You can reduce but not eliminate the chance that you may be penetrated by an intruder or virus. This is mainly for one reason.\nNo one can ever know all the software vulnerabilities of all software used on a system.\nThis is why even those who consider themselves hackers will say that the number one computer security threat is the lack of quality in the applications and operating systems. At this point, I could talk about the various corporate entities that write software and why software lacks the quality that many of us believe that it should possess, but that subject is not only way beyond the scope of this document, but also way beyond the scope of this project.\nThe bottom line here is that unless you can remove all the application and operating system problems that allow viruses and intruders to penetrate networks, you can never secure your network. Additionally the users on your network are potentially a greater security risk than any programs. Obviously removing all vulnerabilities is impossible and will not secure your network against user errors. I have even considered the possibility that an operating system without a network interface can be completely secure, but even this cannot be guaranteed. Unknown viruses or trojan programs can creep in with applications on CDs or floppies. This has been known to happen. Although an attacker may not be able to get data from the system, they can damage or destroy data.\nThe fact that complete security is impossible is the reason security experts recommend \"layered security\". The idea is to have multiple ways of preventing an intrusion to decrease the chance that intrusions will be successful. For example, you should have virus protection on your client computers. To help layer this security you should also filter viruses at your email server. To help even more, you should block the most dangerous types of email attachments to prevent unrecognized viruses and other hostile software from entering your network. Another good defense layer would also include educating your users about viruses, how they spread, and how to avoid them.\nThere are many documents that attempt to define the term hacker. I believe that the term hacker is a connotative term. This means that it is more defined by people's beliefs rather than by a dictionary. Some believe that a hacker is a very skilled computer person. Others believe that hackers are those that perform unauthorized break ins to computer systems. The media and many sources have caused many uninformed people to believe that a hacker is a threat to computer and network security while this is not the case. A hacker is no more likely to break the law than anyone else. I use the more accurate descriptive term, \"intruder\" to describe those who intrude into networks or systems without authorization.\nThis guide will not talk about physical computer security beyond this paragraph. Your organization should be aware how physically secure every aspect of its network is because if an intruder gets physical access, they can get your data. Be sure the your organization properly secures locations and consider the following:\nThis paragaph describes some commonly used computer security terms.", "label": 1}
{"text": "Boonsri DickinsonAssociate Editor of BYTE\nMobile Device Biometrics: The Eyes Have It\nCategory: Smartphones, Social Networking\nWith so much of our banking and interactions taking place on our mobile phones, we still live with a false sense of security because it doesn't take much for someone to hack our phones. By using more unique identifiers biometrics such as eyes, rather than passwords corporations and banks may have a more secure way to authenticate our identity.\nEyeVerify makes biometric technology which uses eye vein patterns. CEO Toby Rush says \"no one can pretend to be you with an eye print. Most eye verification technologies lack 'liveness' detection. With EyeVerify, you can't fake it with photos or videos. You have to stand in front of your camera on any smartphone.\"\nEyeVerify implements a vein biometrics system that only requires software and the device's camera. It allows mobile users to authorize transactions and access secure information. Using the camera on the phone, the software can determine 4 ROIs (regions of interest) in your eye, sending a pass/fail and a confidence interval. If it passes, you are granted access to the application. If it fails, access is denied.\nThe technology came out of academic labs in 2005, after Dr. Reza Derakhshani, University of Missouri-Kansas City (UMKC), and Dr. Arun Ross, West Virginia University (WVU) had developed the technology to identify people by their eyes. Rush saw an opportunity to commercialize it and decided to license the researchers' patent that uses the blood vessels in the back of the eye. As Rush sees it, it's a way for companies to build services that allow their phones to be secure without adding any hardware requirements.\nEven in a BYOD scenario people can use personal phones and have biometric access to access corporate documents, Rush said. He also sees applications in healthcare, where doctors and nurses or patients can access their records. Or in online education, it can let teachers know who is taking the test. Even in logging into social networks such as Facebook, it can authenticate who is online. With EyeVerify, banking applications and others can use the 'liveness' factor for authentication. By using the camera, the software can detect if there's a person there depending on the focus and exposure and white balance.\nBanking in particular could benefit from a more secure system. Most people don't like to use mobile banking because they have security concerns, Rush said, and EyeVerify can give them the confidence they need.\nAs we live our lives more online, protecting our digital identify becomes that much more important. Rush said that in emerging markets such as Nigeria and Indonesia, identity is the biggest issue in combating fraud. Biometrics are not expensive, but have had false starts in the past. For instance, biometric technology that used the retina as verification never really took off. Airports are using the iris and the color of the eye, but that requires an expensive hardware component.\n\"We are looking at the whites of the eye. For corporate applications for authentication, the user would hold the camera away from the face, look left or right and EyeVerify would process it in a few seconds. The software would respond to calling application and either confirm or deny who you say you are. The entire process takes about 4 seconds.\nSecurity researcher Dan Kaminsky said, \"Biometrics have long been seen as a possible solution to the authentication crisis, as we're all enrolled merely by virtue of having bodies. The field has struggled, however, due to problems of deployment (you have to have readers everywhere), accuracy (it's surprising how little uniqueness there is in voices and faces), and security (you leak your biometrics everywhere you go). EyeVerify is interesting in that they're leveraging the ubiquity of cell phones with high resolution cameras to solve the problem of deploying readers, and that they're using one of the few biometrics that is in fact highly unique, and thus effectively discriminates between many users. That being said, like all biometrics, you expose your eyes frequently and in public.\"\nAnother eye verification company called Iris Guard allows customers to conduct banking or buy and pay with their eye, claiming to eliminate identity theft and fraud. Iris Guard uses an iris biometric camera, rather than the whites of the eyes. Even 24 Hour Fitness is using fingerprints to identify people to cut down fraud and to save money on printing plastic cards. While there's no such thing as absolute security, using more unique ways of identifying that you are who you say you are will get us that much closer to fail-safe security. And with the popularity of mobile phones and good cameras in them, EyeVerify may be a step in the right direction. In general, people don't like having to go through inconvenience to lock down their phones, so they will have to make sure the process of verifying your eye is quick and easy to use. EyeVerify says that their iPhone version is done, and is in beta. The Android application will be completed this month.\nKaminsky casts some doubt on Rush's claim that eye prints can't be faked: \"Their pattern can be captured surreptitiously, and replayed forever with no possibility of revocation. But if the only people who have to worry about hacking you are those who can get within a very short distance away -- realistically, that's something of a win. Liveness checking never really works. But it doesn't matter -- if their accuracy is reasonable, they're useful. (It can't work because the pattern is static and effectively 2D. But seriously, they just need to try.) Interestingly, they're slightly worse off than fingerprints, as high resolution photos of your fingers are rarely published while eyes may very well be.\"\nBoonsri Dickinson is the Associate Editor of BYTE", "label": 1}
{"text": "Computer Hacking and Security\nWith the rapid growth of the worldwide Internet user base, online transactions are believed to reach well over a trillion dollars in the next three years. With stakes this high, it makes sense for all parties involved to secure the Internet. Haphazard handling of financial and personal information can lead to the Internet being constantly associated with fraud and privacy abuses instead of being a viable commerce medium. The goal for higher security starts with the individual user.\nThe term \"hacker\" has been around for a while. It originally referred to a person not well versed with a computer trying different things to accomplish a task. To hack was to figure out something through sheer trial and error or logical deduction. Today, a hacker described as a person who breaks into computers for various reasons. Crackers and script-kiddies are two other more commonly used terms describing those involved in the break in or disruption of an online service.\nSecurity problems can occur in any networked environment. Many of the problems are related to the exploitation of the original design of the TCP/IP suite of internetworking protocols, but the majority are due to configuration or operator errors. Hackers are not just looking for websites or government computers to hack - utility grids, emergency information systems, controls for dams and locks, financial information, inter-banking information, military communications and much more sensitive information travels on the Internet and other communication networks.\nIn broad terms, security threats can be classified as active and passive.\nACTIVE HACKING:Active attacks involve the modification of transmitted data and attempts to gain unauthorized access to systems. Data communication is based on a set of handshakes to ensure the smooth and reliable flow of information. A hacker that is between a client and a server and is able to spoof (illegally duplicate) the IP address and sequence numbers, can attack either machine in several ways. The hacker can disable one of the machines and take the identity of the other, or the hacker can mimic either machine and carry on conversations impersonating the other.\nA hacker could also attach additional information to a client request and strip the corresponding additional response from the packet before forwarding the remaining response to the client's original request. All this while having access to information that is assumed to be going back and forth between two 'trusted' systems. Computer viruses and trojans are also examples of active attacks. They can disable machines or in the case of trojans allow malicious hackers access to senstive information by creating a back door.\nPASSIVE HACKING:Passive attacks have to do with evesdropping and monitoring transmissions. All electronic transmissions (email, WWW, telenet, etc) can theoretically be monitored. Since most computers (and the whole Internet) is part of network(s), spying on data transmissions is a major concern. One of the earliest and most sophisticated passive evesdropping example comes to us from the Cold War. The US Navy was able to 'tap' into Soviet undersea fiber optic lines by using special submaries and for years had complete knowledge of that set of communications. On the Internet, protocols like HTTP, FTP and telnet are non-encrypted modes of communications that can easily be compromised. Therefore, encrypted versions (HTTPS, SSH, etc) should be used when transmitting sensitve information.\nRefer to the resources section for other interesting links and sources, consider a personal firewall router and check these personal firewall reviews.", "label": 1}
{"text": "Centers for Disease Control and Prevention’s Active Surveillance Systems for Clinical Care\nThe CDC’s adverse event surveillance systems include the National Healthcare Safety Network (the successor to the National Nosocomial Infections Surveillance System, the Dialysis Surveillance Network, and the National Surveillance System for Health Care Workers) (Tokars et al., 2004) and the National Electronic Injury Surveillance System-Cooperative Adverse Drug Event Surveillance project (NEISS-CADES). Through NEISS-CADES, the CDC conducts nationally representative surveillance for adverse drug events (ADEs) treated in hospital emergency departments. The program is aimed at controlling or preventing injury by identifying and describing the public health burden of outpatient ADEs, generating hypotheses about risk factors for these events, and helping to design interventions for reducing medication errors in the outpatient setting.\nEstimates for 2004 indicate that approximately 700,000 patients were treated in emergency rooms for an ADE, and approximately 100,000 were admitted or transferred to another facility (Budnitz, 2005). Early data indicate that unintentional overdoses were the most common cause of ADEs (39 percent), and that two drugs (i.e., warfarin and insulin) were associated with 16 percent of all ADEs and 33 percent of ADEs in patients over age 50 (Budnitz et al., 2005).\nNEISS-CADES has several important limitations. First, the system is limited to ADEs occurring outside the hospital and to those that result in emergency room visits. Second, the system may fail to capture some serious outpatient ADEs (those treated in a care setting other than an emergency department) and may include nonserious events (as patients may use emergency departments for primary health care) (Walls et al., 2002). Third, the system is designed for national surveillance and not for quality improvement by individual hospitals. Nonetheless, given the importance of monitoring the national health burden of ADEs as one aspect of medication safety and quality improvement, the continued operation and enhancement of NEISS-CADES could play an important role in monitoring the nation’s progress toward reducing medication-related harm in the outpatient setting. The system’s usefulness would be enhanced by identifying appropriate measures of drug exposure, ensuring continued data quality, and developing mechanisms for timely data dissemination.", "label": 1}
{"text": "Disaster recovery blurs into high availability (or other way round?)\nIt's a virtualisation thing\nWorkshop IT managers use two terms when talking about systems availability. These are: High Availability or “HA”, for keeping systems running without any form of unplanned down time; and Disaster Recovery or “DR”, for ensuring that systems are rapidly returned to operation if they fail.\nSome confusion has developed between these terms over the years.\nToday, many vendors use HA and DR almost interchangeably. This is especially evident when they talk of applying the expanding range of virtualisation solutions to improve systems availability. It is almost the case today that the terms have become blurred to such a degree that it is worth asking the question, is there any difference between the two?\nFollowing on from early consolidation of servers using virtualisation, organisations are beginning consider what advantages there might be in actively managing virtualised systems.\nIn addition, there is some interest in creating “private cloud solutions”. This attention, coupled with the hype surrounding external hosted and outsourced services, may help shape thoughts on these capabilities.\nAnother factor coming into play is the question of how virtualisation might help organisations to extend the systems to which they provide HA / DR capabilities. Until very recent times, the high cost and complexity of providing either HA or rapid DR capabilities has meant that only the most important of business services and applications operated in these fashions.\nBut now organisations must work out how to assess the cost of availability/continuity for an expanding range of applications, potentially by creating a business service catalogue that prioritises and costs such characteristics in service level agreements.\nBefore considering if there are any real differences between systems offering HA or DR capabilities today, let us look at the causes of application delivery. The figure below is illuminating in many ways, showing that human generated failures are very well represented as the primary cause of service interruption.\nEffective use of change management processes and tools, coupled with higher levels of “automation”, can help reduce the instances of human error considerably.\nGenuine system problems, such as network failure, physical component failure or power outages, are much less likely to be at the heart of an interruption to service availability. The days when hardware failure was the usual problem to be fixed are behind us as reliability, availability and serviceability features have migrated into commodity servers.\nWe can look deeper into the question of whether HA and DR mean different things today than they did even in the recent past. Until recently, the term HA was applied only to systems that needed to function with strict limits on any interruption to service delivery, at least as perceived by the end users or customers of the service.\nDR, on the other hand, was the phrase applied to the process of getting a service up and running again with users back working, following any form of systems / network failure or any other form of service interruption. In extreme circumstances, DR was also commonly applied to describe how to respond to the complete loss of a service or an entire system, or potentially recuperating from the loss of a building, computer room or data centre.\nToday, it is clear that the accepted usage and understanding of these terms has changed significantly. This is most notable when considering the language commonly used around virtual servers. It is quite common to see the two terms used almost interchangeably with little differentiation. Some vendors are prone to describe the now relatively well established ability to spin up a new virtual machine rapidly following a service degradation or interruption as HA.\nAssume the recovery position\nThis usage is not particularly accurate, as it amounts to just fast, and potentially quite simple to enact, recovery from failure, better known as DR. In fairness it should be mentioned that whilst some vendors use HA in this way, others prefer to describe such scenarios as a natural extension of DR.\nAs mentioned above, a major use of the term DR has been to describe what happens when something big happens to a system that threatens the ability to run a range of services in that location. Expanding DR to include the recovery capabilities of single virtual machines or VMs running on a physical system is not a big stretch in usage. It is now possible to implement genuine HA with virtual systems, but this needs additional software management tools.\nIt remains to be seen if the distinction between the two terms will remain meaningful in the coming years, as virtualised systems and associated management tools become ever more widely deployed. In some ways, the distinction between HA and DR may even prove to be helpful to IT managers, as the chart above highlights just how difficult it has been in the recent past to obtain approval to secure funding to protect systems against failure.\nIn many ways, the reluctance to provide funding for HA mirrors the problem in getting approval to implement better systems management tools generally. It is to be hoped that, as genuine HA systems become more affordable, organisations recognise the value of good management tools to help ensure higher levels of service delivery and the undoubted business benefits delivered by IT as a result.\nSome confusion has developed between these terms over the years.\nTrue, and this article isn't helping.\nTraditionally High Availability (HA) has meant the same as it does today, ensuring that a localised fault such as a server or network outage, or a disk crash, is automatically handled in such a way that a service remains available, or is restored very rapidly.\nDisaster Recovery (DR), as the name implies, is a solution to a more widespread outage, perhaps a fire or a flood, which takes a whole datacentre off-air. It may not be automated, and recovery times are often somewhat longer, especially when it is integrated as part of a general Business Continuity plan which covers more than just the IT aspects of a disaster.\nI would say that there is much more confusion between the terms Fault Tolerant (FT) and Highly Available (HA), which may be what this article is really considering.\nWhat about FT and BC?\nThere's also fault tolerance (FT) which is a very high level of redundancy, such that software is unaware of any failure. I'm thinking especially of Tandem. And then there's business continuity (BC) which is like DR but focuses less on the disastrous aspects. I'm thinking near line storage or data replication. The lines can blur but you really need prudent amounts of both. You don't want to fail over to the bunker just because one disk goes bad. And your RAID6 array doesn't help when it's under water.\nWell, I quite liked the article, don't care so much about whether it's HA or DR as long as it's UP...\nHaving been partially DOWN myself recently, I think this is a very important topic.... I especially like the idea of a \"business service catalogue\" which details costs/benefits of HA solutions, for a particular input.\nI also like the idea of a root cause log, not mentioned in the article but implied by the very nice bar chart. I plan on implementing both as database tables in my BIS.\nHA & DR?\nFrom my perspective, it's online (local memory ... fast ... a workstation), nearline (available over the network, without human intervention ... sometimes slowish ... \"the web\") & offline (tape that isn't physically available to the Memorex robot and needs human intervention ... \"the cloud\") ... but then I come from a real hardware background.\nIn other news ... March of 2008? Is freeformdynamics getting further & further behind? Perhaps they should get their heads out of the Clouds and invest in online storage ...", "label": 1}
{"text": "Posted by Chenxi Wang on February 10, 2009\nIn December 2008, a group of researchers demonstrated a credible attack against MD5 signatures. Since then, Forrester received a number of client inquiries regarding the security strength of their MD5 certificates. There seems to be much confusion over what the attack is about and its actual consequences.\nTo properly understand the security consequence of this attack and the impact on certificates, we need to understand how the attack works. The researchers demonstrated a successful attack against the RapidSSL certificate authority, which uses MD5 signatures to sign certificate requests. This is how the attack worked: the researchers first got the RapidSSL CA to sign a particular certificate request, issued for a domain in their control. This request and the ensuing signature are completely legitimate. The researchers then demonstrated that they were able to create a second certificate bearing the same signature, for a separate made-up entity. In essence, they were able to find two certificates with the same valid signature. In cryptographic parlance, this is a hash “collision” attack.\nHow bad is this attack? It’s important to understand that the researchers were able to create a collision attack for a “particular” original signature, namely a signature that is under the attacker’s control. Not for “any” original signatures. If you have a MD5 valid RapidSSL certificate, the chances are good that no one will be able to create a fake certificate that has the same signature as yours. However, this attack put forth an increased risk of encountering fake MD5 certificates on the Internet.\nVeriSign, the owner of RapidSSL CA, has stopped using MD5 signatures altogether by the end of January 2009. VeriSign is moving to SHA-1 signatures, which is the current standard. Although SHA-1 has also been found to be vulnerable to collision attacks*, finding a collision with SHA-1 requires much more computational power and therefore it is safe to assume that SHA-1 is more secure than MD5. Again, if you currently have a valid MD5 certificate, there is no need to panic and no need to upgrade right now. You can simply let your certificate expire at the end of its lifetime and then move to a SHA-1 certificate.\nWhat is the long term consequence? It’s likely that even SHA-1 will be broken by ordinary means some day, as computational resources become cheaper every day. We at Forrester will do our best to bring you the latest in terms of new attacks and threats. But as an organization that conducts secure business online, you should remain aware of advances in cryptographic technologies and new crytoanalysis methods.\n*Two papers detailed the attack on SHA-1 algorithm were presented at Crypto 2005 rump session: \"Efficient Collision Search Attacks on SHA-0\" and \"Finding Collisions in the Full SHA-1Collision Search Attacks on SHA1” by XiaoYun Wang.", "label": 1}
{"text": "Last week we promised a look\nat Tor, a system for anonymous Internet\ncommunication, primarily developed by Nick Mathewson and Roger Dingledine. Current\ndevelopment is supported by the Electronic\nFrontier Foundation (EFF), but Tor was originally developed as part of\nthe U.S. Naval Research Laboratory's Onion Routing program.\nAs the Tor web page explains, Tor is a \"toolset for a wide range of\norganizations and people that want to improve their safety and security on\nthe Internet.\" What does that mean? In a nutshell, Tor is a\nclient/server application that anonymizes traffic by routing it from the\nclient through a series of nodes to hide the origin of a request. It can\nalso be used to protect services against denial of service attacks and the like by hiding\nTor routes traffic through nodes that \"know\" about the previous node and\nthe next node -- but not the rest of the network. By routing traffic through a series of\n\"onion routers\" Tor makes it difficult for the receiver, observers and\neven other Tor routers to detect the source of traffic. A more complete\ndescription of Tor's design can be found in the design\npaper; a protocol\nspecification is also available for those who wish to build compatible\nTor works as both a server and as a client. By default, Tor runs as a\nclient only, but it can be configured to allow other users to connect to\nyour system as a Tor node. In addition, Tor can be used to run \"hidden\"\nservices that do not reveal your IP address to others at all. The \"hidden\nwiki\" maintains a list of hidden services that users can see as an\nexample. Finally, it's possible to set up one's own Tor network that does\nnot interact with the public Tor network, for those who want to test the\nprotocol but may lack access to the Internet.\nTo achieve best results, one may need to use Tor in conjunction with other\napplications. For example, users who wish to browse anonymously would use\nTor in conjunction with Privoxy. Other applications may require\nuse of tsocks or ProxyChains.\nTo see what Tor had to offer, we installed it on a Ubuntu Hoary machine,\nalong with Privoxy, tsocks and ProxyChains. Configuring services to work\nwith Tor is not terribly difficult, and there is a relatively detailed HOWTO\nfor users who wish to configure specific applications like Gaim, X-Chat,\nSSH or BitTorrent with Tor.\nIt should be noted that using Tor can have an impact on performance for\nclient applications. Using Tor and Privoxy together for browsing, for\nexample, introduced a notable lag. Firefox users may be\ninterested in using the SwitchProxy\nTool extension to switch Proxy use on and off, reserving Tor for\nspecific sites rather than for all web browsing. Users should also be\nprepared for some odd behavior on some sites -- for example, we kept being\nredirected to country-specific versions of Google, rather than Google's main\nsite, when using Tor and Privoxy. Tor itself didn't seem to have much of an\nimpact on system performance overall.\nTor is not completely foolproof. It could be possible for someone who's\nrunning a Tor server to modify Tor or use other software to monitor traffic\ngoing through the server. Traffic coming out of the \"exit node\" (the last\nhop in the Tor \"circuit\") is not encrypted, so a malicious user could set\nup a Tor server and browse traffic coming out of their machine. (It is\npossible to specify your exit node in the Tor configuration.) There are\ntraffic that passes through Tor.\nInterested users should also have a look at the EFF's legal issues page\nabout Tor. Though Tor can be used for things like BitTorrent, it is not\ndesigned to assist copyright infringement or other illegal activity.\nThere is still a lot of development ahead for Tor, but it is definitely\nworth a look for users who are interested in anonymous communication on the\nInternet. Users with bandwidth to spare are also encouraged to set up and\nrun a Tor server to help test its scalability and to help provide a larger\nTor network. See the download\npage for Tor packages and source code.\nto post comments)", "label": 1}
{"text": "|Microsoft Office Outlook® 2003\nMicrosoft Outlook® 2000 and 2002\nCon artists have been around since time began, and now that we are in the Internet Age they are on the Web preying on unsuspecting online consumers. Online fraud is on the rise, and the techniques for creating deceptive e-mail messages and Web sites are getting more sophisticated. Learn more about what you can do to help protect yourself from online fraud.\nWhat is online fraud or phishing?\nPhishing (pronounced “Fishing”) is an online fraud technique used by criminals to entice you to disclose your personal information. Phishing is the fastest rising online crime method used for stealing personal finances and perpetrating identity theft.\nPhishers use many different tactics to lure you, including e-mail and Web sites that mimic well-known, trusted brands. A common phishing practice involves \"spamming\" recipients with fake messages that resemble a valid message from a well-known Web site or a company that the recipients might trust, such as a credit card company, bank, charity, or e-commerce online shopping site. The purpose of fake messages is to trick consumers into providing the following personal information:\nCriminals use this information in many ways for financial gain. For example, a common practice is identity theft, whereby the criminal steals your personal information, takes on your identity, and can then do the following:\n- Apply for and get credit in your name.\n- Empty your bank account and max out your credit cards.\n- Transfer money from your investment or credit line accounts into your checking account, and then use a copy of your debit card to withdraw cash from your checking account at ATMs around the world.\nFor tips on how to avoid being the victim of online fraud, see the Best practices to help protect yourself from online fraud section later in this article.\nExamples of phishing schemes\nSome examples of phishing schemes include:\n- Fake e-mail messages from what appears to be from a company you do business with warning you that they need to verify your account information or your account will be suspended.\n- A combination of auction fraud and fake escrow sites. This occurs when items are put up for sale at a legitimate online auction to lure you into making payments to a fake escrow site.\n- Fake online sales transactions, whereby a criminal offers to buy something from you and requests that they pay you an amount well over the price of the item they are buying. In return, they ask you to send them a check for the difference. The payment to you is not sent, but your check is cashed, and the criminal pockets the difference. Additionally, the check that you send has your bank account number, bank routing code, address, and phone number.\n- Fake charities asking you for money. Unfortunately, many criminals take advantage of your goodwill.\nThere are many more phishing schemes out there. For an up-to-date report on phishing schemes that authorities have uncovered, visit the Anti-Phishing Working Group Web site.\nHow can I tell if an e-mail message is a fraud?\nUnfortunately, as phishing attacks become more sophisticated, it is very difficult for the average person to tell if a message is fraudulent. That is why phishing schemes are so prevelant and successful for criminals. For example, many phony e-mail messages link to real company logos of well-known brands. However, their are things you can be on the lookout for:\n- Requests for personal information in an e-mail message Most legitimate businesses have a policy that they do not ask you for your personal information through e-mail. Be very suspicious of a message that asks for personal information even if it might look legitimate.\n- Urgent wording Wording in phishing e-mail messages is usually polite and accommodating in tone. It almost always tries to get you to respond to the message or to click the link that is included. To increase the number of responses, criminals attempt to create a sense of urgency so that people immediately respond without thinking. Usually, fake e-mail messages are NOT personalized, while valid messages from your bank or e-commerce company generally are. The following is an example from a real phishing scheme:\nDear valued bank member, it has come to our attention that your account information needs to be updated due to inactive member, frauds, and spoof reports. Failure to update your records will result in account deletion. Please follow the link below to confirm you data.\n- Be aware of URLs that include the @ sign. In the following example, the URL would take you to the location that comes after the @ sign, not to Wood Grove Bank. This is because browers ignore anything in the URL that comes before the @ sign:\nThe real location, nl.tv/secure_verification.aspx, could easily be an unsafe site.\n- Another common technique that has been used is a URL that at first glance is the name of a well-known company but on closer scrutiny is slightly altered. For example, www.microsoft.com could appear instead as:\nMicrosoft has recently won several lawsuits against individuals who have used these types of URLs to spoof legitimate Microsoft properties. However, the practice remains pervasive and is often protected by national boundaries.\nOther kinds of images placed in e-mail messages can be linked to a spammer's server and act like Web beacons (web beacon: An embedded object in a webpage or email message usually connected to a graphic that might be invisible to the user. It can be used to verify that your email address is valid because when you view the message, images with the web beacon are downloaded from a tracking web server.). When you open the e-mail message the images are downloaded and information is passed back to the server. This information is used to verify that your e-mail address is valid and so you might be spammed again. Outlook by default automatically blocks these kinds of external images. For more information see About protecting your privacy by blocking automatic picture downloads.\nHow can I tell if a Web site is a fraud?\nSimilar to fraudulent e-mail messages, faked Web sites contain convincing logo graphics and Web links. This makes it hard to tell if they are fraudulent. The best strategy is to not click on links in suspicious messages. Some things to look for that legitimate Web sites should have are as follows:\nImportant Note that https:// is sometimes faked in links, such as in the \"masked link\" example shown in the Fake Links section.\n- A digital certificate for the Web site An additional benefit of SSL is authentication (authentication: In a multiuser or network environment, the process of validating user logon information. A name and password are compared to an authorized list, and, if there is a match, access is granted with the level of permission specified.) – the process of identifying a Web site to you. SSL provides this benefit by using a digital certificate, which the site presents to your browser when you connect. To view the certificate, double-click the lock icon in the lower-right corner of the browser and examine the Issued to field. The name shown on the certificate should match the site that you think you're on. For example, if the site really is Wood Grove Bank, then the Issued to name should match the URL woodgrovebank.com. If the name is different, you might be on a faked site. Again, be very careful of slight misspellings. If the certificate is expired, not trusted by the certificate authority, or has a name that doesn't match the name displayed in the Address bar, Microsoft Internet Explorer displays a warning message.\nTo learn more about the certificate, click the Details tab. If you're not sure whether a certificate is legitimate, don't enter any personal information. Play it safe and leave the Web site. To find out more ways to determine if a site is secure, read How Internet Explorer helps keep your data safe.\nBest practices to help protect yourself from online fraud\n- Never reply to e-mail messages that request your personal information Be very suspicious of any e-mail message from a business or person that asks for your personal information — or one that sends you personal information and asks you to update or confirm it. Instead, use the phone number from one of your statements to call; do not call a number listed on the e-mail message. Similarly, never volunteer any personal information to someone who places an unsolicited call to you.\n- Don't click links in suspicious e-mail Don't click a link contained in a suspicious message. The link might not be trustworthy. Instead, visit Web sites by typing their URL into your browser or by using your Favorites link. Do not copy and paste links from messages into your browser.\n- Use strong passwords and change them often If your account allows them, strong passwords combine uppercase and lowercase letters, numbers, and symbols, which make them difficult for other people to guess. Don't use real words. Use a different password for each of your accounts and change them frequently. It's hard to remember all those passwords. For tips on creating strong passwords and how to remember and store passwords securely, see Creating stronger passwords.\n- Don't send personal information in regular e-mail messages Regular e-mail messages are not encrypted and are like sending a post card. If you must use e-mail messages for personal transactions, use Outlook to digitally sign and encrypt messages by using S/MIME (S/MIME: Secure Multipurpose Internet Mail Extensions (S/MIME) is a specification for secure email messages that uses the X.509 format for digital certificates and uses various encryption algorithms such as 3DES.) security. Outlook Express, Microsoft Office Outlook Web Access, Lotus Notes, Netscape, and Eudora all support S/MIME security.\n- Do business only with companies you know and trust Use well-known, established companies with a reputation for quality service. A business Web site should always have a privacy statement that specifically states that the business won't pass your name and information to other people.\n- Make sure the Web site uses encryption The Web address should be preceded by https:// instead of the usual http:// in the browser's Address bar. Also, double-click the lock icon on your browser's status bar to display the digital certificate for the site. The name that follows Issued to in the certificate should match the site that you think you're on. If you suspect that a Web site is not what it should be, leave the site immediately and report it. Don't follow any of the instructions it presents.\n- Help protect your PC It is important to use a firewall, keep your computer updated, and use antivirus software, especially if you connect to the Internet through a cable modem or a digital subscriber line (DSL) modem. For information on how to do this, visit Protect your PC. For additional information on virus protection, see Best practices for protection from viruses, and Best practices to help prevent spam. You should also consider using anti-spyware software. You can download Microsoft anti-spyware or use a third-party product available from the security software downloads and trials site.\n- Monitor your transactions Review your order confirmations and credit card and bank statements as soon as you receive them to make sure that you're being charged only for transactions you made. Immediately report any irregularities in your accounts by dialing the number shown on your account statement. Using just one credit card for online purchases makes it easier to track your transactions.\n- Use credit cards for transactions on the Internet In most locales, your personal liability in case someone compromises your credit card is significantly limited. By contrast, if you use direct debit from your bank account or a debit card, your personal liability frequently is the full balance of your bank account. In addition, a credit card with a small credit limit is preferable for use on the Internet because it limits the amount of money that a thief can steal in case the card is compromised. Better yet, several major credit card issuers are now offering customers the option of shopping online with virtual, single-use credit card numbers, which expire within one or two months. For more details, ask your bank about perishable virtual credit card numbers.\nHow do I report online fraud and identity theft?\nIf you believe that you have received fraudulent e-mail messages or have been the victim of online fraud, you can report the problem to the following groups:\n- FBI The FBI: Internet Fraud Complaint Center (IFCC) works worldwide with law enforcement and industry to promptly shut down phishing sites and identify the perpetrators behind the fraud.\n- FTC If you believe that your personal information has been compromised or stolen, you should report the circumstances to the FTC: National Resource for Identity Theft and visit their site to learn how you can minimize the damage.\n- Attach and send fake e-mail messages to authorities Reporting fake messages to authorities helps in the effort to combat phishing schemes. There’s information buried in the header of an e-mail message that technical experts require in order to flush out fraud or abuse; without it they may be unable to pursue an investigation. Follow the steps below to send the full, original header of the message you want to report. Some e-mail addresses you can use to report suspicious mail are:\nfirstname.lastname@example.org goes to the Anti-Phishing Working Group, an industry association.\nemail@example.com goes to the FTC.\nfirstname.lastname@example.org goes to MSN.\nemail@example.com goes to Microsoft.\nIn these steps, you copy the headers from the problem message into a new message. You also attach the problem message to the new message.\n- In Outlook, right-click the suspicious message you want to report, and then click Options on the shortcut menu.\n- To copy the full headers, right-click inside the Internet headers box, and then click Select All on the shortcut menu.\n- To copy the full header, press CTRL+C, and then click Close.\n- Open a new message, and type the e-mail address of the company to whom you are reporting the problem message — for example, firstname.lastname@example.org.\n- If Microsoft Word is your e-mail editor, click the down arrow next to Insert File , and then click Item. If Microsoft Word is not your e-mail editor, on the Insert menu, click Item.\n- Click the message you want to report, and then click OK. This attaches the problem message to the new message.\n- In the Subject line, type I am reporting suspicious email, or whatever you think is best to describe what you are doing.\n- In the body of the new message, to paste the header you copied in step 3, press CTRL+V.\n- Click Send.\nTips on safer online shopping and banking\nIf you want more information from Microsoft on ways to help safeguard your personal information while shopping or banking online, visit the Online Fraud Web site. Keep in mind that not all identity thieves are high-tech hackers. Some use low-tech methods, such as dumpster diving, to swipe personal information. Buy a shredder and destroy bills, pre-approved credit offers, and other documents with personal information before throwing them away or recycling them.\nHow Outlook 2003 helps to protect you from phishing schemes\nFor specific information on how Outlook 2003 helps to protect you from phishing schemes, see the article called Block suspicious messages and phishing schemes.", "label": 1}
{"text": "Every now and then I get to talk with college-age students about social media and all the stuff going with privacy, identity, and security on the Internet (most recently at Smith College, my Alma Mater.) More often than not, I find that they really don't know too much about how to protect themselves from fraud, let alone how to construct online identities that won't hurt their job chances. Yet, the assumption continues among lazy adults that \"kids know it all\" about the Internet....\nWell, finally, the Government and tech giants have realized the inanity of believing \"kids know it all\" and have teamed up in an new program that will teach kids not just how to handle cyber bullies, but also how to deal with online frauds and scam artists.\nNow, I'm not thrilled that this is coming out of the Department of Homeland Security, but, when I think about it, what goes on in our little machines on our desks or in our laps could impact the larger network of computers out there.\nWe're never really alone with our machines, if you think about it.\nThe program will be administered by the non-profit National Cyber Security Alliance, has a curriculum, and will send to the schools volunteers from companies such as EMC and Science Applications International Corp. Support will come from Symantec, Cisco, and Microsoft, to name a few of the companies involved.\nApparently, one of the motivators for starting the program was the results of a study done by the Pew Internet and American Life Project which found that only 3 percent of state school curriculums instructed students on proper use of social networks and chat rooms. Yet schools are often giving assignments that require Internet use.\nI guess the assumption was that kids were getting taught *something* about the Internet at home. But think about it: how many of us have heard stories of parents who plop computers in kids' rooms, and then allow the kids to just close the bedroom door? How many of us have heard parents say how they want to \"spy\" on their kids' activities online, rather than find out how things work or what's going on in the greater world of life online?\nSo, I'd hazard a guess that there are indeed bigtime security reasons that may go beyond \"identity theft\" and \"stalkers\" that have become reasons for the government to create a program like this to teach kids the things they're not getting taught anywhere else.\nThink about it.", "label": 1}
{"text": "SASL provides developers of applications and shared libraries with mechanisms for authentication, data integrity-checking, and encryption. SASL enables the developer to code to a generic API. This approach avoids dependencies on specific mechanisms. SASL is particularly appropriate for applications that use the IMAP, SMTP, ACAP, and LDAP protocols, as these protocols all support SASL. SASL is described in RFC 2222.\nThe SASL library is called libsasl. libsasl is a framework that allows properly written SASL consumer applications to use any SASL plug-ins that are available on the system. The term plug-in refers to objects that provide services for SASL. Plug-ins are external to libsasl. SASL plug-ins can be used for authentication and security, canonicalization of names, and lookup of auxiliary properties, such as passwords. Cryptographic algorithms are stored in plug-ins rather than in libsasl.\nlibsasl provides an application programming interface (API) for consumer applications and libraries. A service provider interface (SPI) is provided for plug-ins to supply services to libsasl. libsasl is not aware of the network or the protocol. Accordingly, the application must take responsibility for sending and receiving data between the client and server.\nSASL uses two important identifiers for users. The authentication ID (authid) is the user ID for authenticating the user. The authentication ID grants the user access to a system. The authorization ID (userid) is used to check whether the user is allowed to use a particular option.\nThe SASL client application and SASL server application negotiate a common SASL mechanism and security level. Typically, the SASL server application sends its list of acceptable authentication mechanisms to the client. The SASL client application can then decide which authentication mechanism best satisfies its requirements. After this point, the authentication takes place using the agreed–upon authentication mechanism as a series of client-server exchanges of the SASL supplied authentication data. This exchange continues until the authentication successfully completes, fails, or is aborted by the client or the server.\nIn the process of authentication, the SASL authentication mechanism can negotiate a security layer. If a security layer is selected, that layer must be used for the duration of the SASL session.\nClient and server applications make calls to their local copies of libsasl through the SASL API. libsasl communicates with the SASL mechanisms through the SASL service provider interface (SPI).\nSecurity mechanism plug-ins provide security services to libsasl. Some typical functions that are provided by security mechanisms follow:\nAuthentication on the client side\nAuthentication on the server side\nIntegrity, that is, checking that transmitted data is intact\nConfidentiality, that is, encrypting and decrypting transmitted data\nSSF, the security strength factor, indicates the strength of the SASL protection. If the mechanism supports a security layer, the client and server negotiate the SSF. The value of the SSF is based on the security properties that were specified before the SASL negotiation. If a non-zero SSF is negotiated, both client and server need to use the mechanism's security layer when the authentication has completed.\nSSF is represented by an integer with one of the following values:\n0 – No protection.\n1 – Integrity checking only.\n>1 – Supports authentication, integrity and confidentiality. The number represents the encryption key length.\nThe confidentiality and integrity operations are performed by the security mechanism. libsasl coordinates these requests.\nIn the negotiation, the SASL client selects the mechanism with the maximum SSF. However, the actual SASL mechanism that is chosen might subsequently negotiate a lower SSF.\nApplications communicate with libsasl through the libsasl API. libsasl can request additional information by means of callbacks that are registered by the application. Applications do not call plug-ins directly, only through libsasl. Plug-ins generally call the libsasl framework's plug-ins, which then call the application's callbacks. SASL plug-ins can also call the application directly, although the application does not know whether the call came from a plug-in or from libsasl.\nCallbacks are useful in multiple areas, as follows.\nlibsasl can use callbacks to get information that is needed to complete authentication.\nlibsasl consumer applications can use callbacks to change search paths for plug-ins and configuration data, to verify files, and to change various default behaviors.\nServers can use callbacks to change authorization policies, to supply different password verification methods, and to get password change information.\nClients and servers can use callbacks to specify the language for error messages.\nApplications register two sorts of callbacks: global and session. Additionally, libsasl defines a number of callback identifiers that are used to register for different sorts of callbacks. If a given type of callback is not registered, libsasl takes default action.\nSession callbacks override global callbacks. If a session callback is specified for a given ID, the global callback is not called for that session. Some callbacks must be global, because these callbacks occur outside of sessions.\nThe following instances require global callbacks:\nDetermination of search paths for plug-ins to load\nVerification of plug-ins\nLocation of configuration data\nThe logging of error messages\nOther global configuration of libsasl or its plug-ins\nA SASL callback can be registered with a NULL callback function for a given SASL callback ID. The NULL callback function indicates that the client is equipped to supply the needed data. All SASL callback IDs start with the prefix SASL_CB_.\nSASL provides the following callbacks for use by either a client or a server:\nGets a SASL option. Options modify the behavior of libsasl(3LIB) and related plug-ins. Can be used by either a client or a server.\nThe default SASL plug-in search paths depend on the architecture as follows:\n32-bit SPARC architecture: /usr/lib/sasl\n32-bit x86 architecture: /usr/lib/sasl\n64-bit SPARC architecture: /usr/lib/sasl/sparcv9\nx64 architecture: /usr/lib/sasl/amd64\nSASL provides the following callbacks for use by clients only:\nSASL provides the following callbacks for use by servers only:\nChecks that an authenticated user is authorized to act on behalf of the specified user. If this callback is not registered, then the authenticated user and the user to be authorized must be the same. If these IDs are not the same, then the authentication fails. Use the server application to take care of nonstandard authorization policies.\nWhen the SASL library is first initialized, the server and client declare any necessary global callbacks. The global callbacks are available prior to and during the SASL sessions. Prior to initialization, callbacks perform such tasks as loading plug-ins, logging data, and reading configuration files. At the start of a SASL session, additional callbacks can be declared. Such callbacks can override global callbacks if necessary.\nlibsasl uses a SASL connection context to maintain the state of each SASL session for both SASL clients and SASL servers. Each context can be used for only one authentication and security session at a time.\nThe maintained state includes the following information:\nConnection information, such as service, naming and address information, and protocol flags\nCallbacks specific to the connection\nSecurity properties for negotiating the SASL SSF\nState of the authentication along with security layer information\nThe following diagram shows steps in the SASL life cycle. The client actions are shown on the left of the diagram and the server actions on the right side. The arrows in the middle show interactions between the client and server over an external connection.\nThe sections that follow illustrate the steps in the life cycle.\nWhen sasl_client_init() is run, the SASL client, the client's mechanisms and the client's canonicalization plug-in are loaded. Similarly, when sasl_server_init() is called, the SASL server, the server's mechanisms, the server's canonicalization plug-in, and the server's auxprop plug-in are loaded. After sasl_client_init() has been called, additional client plug–ins can be added by using sasl_client_add_plugin() and sasl_canonuser_add_plugin(). On the server side, after sasl_server_init() has been called, additional server plug–ins can be added through sasl_server_add_plugin(), sasl_canonuser_add_plugin(), and sasl_auxprop_add_plugin().\nSASL mechanisms are provided in the Oracle Solaris software in the following directories according to the architecture:\n32-bit SPARC architecture: /usr/lib/sasl\n32-bit x86 architecture: /usr/lib/sasl\n64-bit SPARC architecture: /usr/lib/sasl/sparcv9\nx64 architecture: /usr/lib/sasl/amd64\nThe SASL_CB_GETPATH callback can be used to override the default location.\nAt this point, any required global callbacks are set. SASL clients and servers might include the following callbacks:\nA SASL server might additionally include the SASL_CB_GETCONF callback.\nThe server and client use establish the connection through the protocol. To use SASL for authentication, the server and client create SASL connection contexts by using sasl_server_new() and sasl_client_new() respectively. The SASL client and server can use sasl_setprop() to set properties that impose security restrictions on mechanisms. This approach enables a SASL consumer application to decide the minimum SSF, the maximum SSF, and the security properties for the specified SASL connection context.\n#define SASL_SEC_NOPLAINTEXT 0x0001 #define SASL_SEC_NOACTIVE 0x0002 #define SASL_SEC_NODICTIONARY 0x0004 #define SASL_SEC_FORWARD_SECRECY 0x0008 #define SASL_SEC_NOANONYMOUS 0x0010 #define SASL_SEC_PASS_CREDENTIALS 0x0020 #define SASL_SEC_MUTUAL_AUTH 0x0040\nAuthentication and a security layer can be provided by the client-server protocol or by some other mechanism that is external to libsasl. In such a case, sasl_setprop() can be used to set the external authentication ID or the external SSF. For example, consider the case in which the protocol uses SSL with client authentication to the server. In this case, the external authentication identity can be the client's subject name. The external SSF can be the key size.\nFor the server, libsasl determines the available SASL mechanisms according to the security properties and the external SSF. The client obtains the available SASL mechanisms from the SASL server through the protocol.\nFor a SASL server to create a SASL connection context, the server should call sasl_server_new(). An existing SASL connection context that is no longer in use can be reused. However, the following parameters might need to be reset:\n#define SASL_DEFUSERREALM 3 /* default realm passed to server_new or set with setprop */ #define SASL_IPLOCALPORT 8 /* iplocalport string passed to server_new */ #define SASL_IPREMOTEPORT 9 /* ipremoteport string passed to server_new */ #define SASL_SERVICE 12 /* service passed to sasl_*_new */ #define SASL_SERVERFQDN 13 /* serverFQDN passed to sasl_*_new */\nYou can modify any of the parameters to sasl_client_new() and sasl_server_new() except the callbacks and protocol flags.\nThe server and client can also establish security policy and set connection specific parameters by using sasl_setprop() to specify the following properties:\n#define SASL_SSF_EXTERNAL 100 /* external SSF active (sasl_ssf_t *) */ #define SASL_SEC_PROPS 101 /* sasl_security_properties_t */ #define SASL_AUTH_EXTERNAL 102 /* external authentication ID (const char *) */\nSASL_SSF_EXTERNAL – For setting the strength factor, that is, the number of bits in the key\nSASL_SEC_PROPS – For defining security policy\nSASL_AUTH_EXTERNAL – The external authentication ID\nThe server can call sasl_listmech() to get a list of the available SASL mechanisms that satisfy the security policy. The client can generally get the list of available mechanisms from the server in a protocol-dependent way.\nThe initialization of a SASL session is illustrated in the following diagram. In this diagram and subsequent diagrams, data checks after transmission over the protocol have been omitted for the sake of simplicity.\nAuthentication takes a variable number of client and server steps depending on the security mechanism that is used. The SASL client calls sasl_client_start() with a list of security mechanisms to use. This list typically comes from the server. libsasl selects the best mechanism to use for this SASL session, according to the available mechanisms and the client's security policy. The client's security policy controls which mechanisms are permitted. The selected mechanism is returned by sasl_client_start(). Sometimes the security mechanism for the client sometimes needs additional information for authentication. For registered callbacks, libsasl calls the specified callback unless the callback function is NULL. If the callback function is NULL, libsasl returns SASL_INTERACT and a request for needed information. If SASL_INTERACT is returned, then sasl_client_start() should be called with the requested information.\nIf sasl_client_start() returns SASL_CONTINUE or SASL_OK, the client should send the selected mechanism with any resulting authentication data to the server. If any other value is returned, an error has occurred. For example, no mechanism might be available.\nThe server receives the mechanism that has been selected by the client, along with any authentication data. The server then calls sasl_server_start() to initialize the mechanism data for this session. sasl_server_start() also processes any authentication data. If sasl_server_start() returns SASL_CONTINUE or SASL_OK, the server sends authentication data. If sasl_server_start() returns any other value, an error has occurred such as an unacceptable mechanism or an authentication failure. The authentication must be aborted. The SASL context should be either freed or reused.\nThis part of the authentication process is illustrated in the following diagram.\nIf the server call to sasl_server_start() returns SASL_CONTINUE, the server continues to communicate with the client to get all the necessary authentication information. The number of subsequent steps depends on the mechanism. If needed, the client calls sasl_client_step() to process the authentication data from the server and to generate a reply. Similarly, the server can call sasl_server_step() to process the authentication from the client and to generate a reply in turn. This exchange continues until the authentication is complete or until an error has occurred. SASL_OK is returned to indicate that the authentication has successfully completed for the client or server. The SASL mechanism might still have additional data to send to the other side so the other side can complete authentication. When authentication has been achieved on both sides, the server and client can inquire about each other's properties.\nThe following diagram shows the interactions between the server and client to transfer the additional authentication data.\nTo check for a security layer, use the sasl_getprop(3SASL) function to see if the security strength factor (SSF) has a value that is greater than 0. If a security layer has been negotiated, the client and server must use the resulting SSF after successful authentication. Data is exchanged between the client and server in a similar fashion to authentication. sasl_encode() is applied to data before the data is sent by the protocol to the client or server. On the receiving end, data is decoded by sasl_decode(). If a security layer has not been negotiated, the SASL connection context is not needed. The context can then be disposed of or reused.\nA SASL connection context should only be freed when the session is not to be reused. sasl_dispose() frees the SASL connection context and all associated resources and mechanisms. The SASL connection contexts must be disposed before calling sasl_done(). sasl_done() is not responsible for releasing context resources for the SASL connection. See libsasl Cleanup.\nWhen a SASL session is freed, the associated mechanisms are informed that all state can be freed. A SASL session should only be freed when the session is not to be reused. Otherwise, the SASL state can be reused by another session. Both the client and server use sasl_dispose() to free the SASL connection context.\nThis step releases all the resources in the SASL library and the plug-ins. The client and server call sasl_done() to release libsasl() resources and to unload all the SASL plug-ins. sasl_done() does not release SASL connection contexts. Note that if an application is both a SASL client and a SASL server, sasl_done() releases both the SASL client and SASL server resources. You cannot release the resources for just the client or the server.\nLibraries should not call sasl_done(). Applications should exercise caution when calling sasl_done() to avoid interference with any libraries that might be using libsasl.", "label": 1}
{"text": "(Phys.org) -- Now that tiny computers and electronic communications systems are being designed into cars, hackers can look toward the car, like the PC, as potential roadkill. If cars are to become computers on wheels, a number of security experts are expanding their focus on car security systems and sources of security threats. U.S. computer scientists from California and Washington state have already identified ways in which computer worms and Trojans are carried over to automobiles. Conduits include onboard diagnostics systems, wireless connections and even tainted CDs played on radios systems.\nExperts point out that the numerous computers known as electronic control units, or ECUs, require tens of millions of lines of computer code to manage interconnected systems. These range from engines, brakes and navigation to lighting, ventilation and entertainment. The same wireless technologies that power cell phones and Bluetooth headsets are in cars and in turn are vulnerable to remote attacks.\nUnlike PCs, though, the attackers goal with cars may not be to rob the victim of information but to steal the car, or spy on in-car conversation, or cause the vehicle to crash.\nMcAfee, a subsidiary of Intel and known for its security work to remedy PC viruses, are conducting research on car security at a Beaverton, Oregon garage. Bruce Snell, a McAfee executive, confirmed that automakers are not blind to risks of cyber attacks and are aware of auto system-hacking repercussions far different from seeing laptop data swiped and wiped. McAfee, a subsidiary of Intel, issued a report on automotive systems security with a title that reveals what it sees as the coming risks: Caution: Malware Ahead.\nResearchers of the University of California, San Diego, and the University of Washington have already figured out how to hack into a modern car using a laptop. The same research team extended the scenario to remotely mount attacks via Bluetooth. According to the McAfee paper, another attack scenario was presented by researchers of the University of South Carolina and Rutgers. They demonstrated it was possible to mount an attack on a vehicle and compromise passengers privacy by tracking Radio Frequency Identification (RFID )tags using long-distance readers at around 40 meters; the RFID tags are used in tires for sensor data over wireless short-distance communication to the vehicle.\nReports do not single out vendors because the issues are relevant to the entire industry; automakers use common suppliers and processes. Nonetheless, a Reuters check of vendor initiatives shows concern in responses.\nMajor U.S. automakers did not say if they knew of any instances in which their vehicles had been attacked with malicious software or if they had recalled cars to fix security vulnerabilities. At the same time, nothing is impossible and they are working to keep their systems as safe as possible.\nFord has its security engineers working on SYNC in-vehicle communications and entertainment system to ensure it is as resistant as possible to attack, according to the Reuters report. Toyota Motor Corp, the world's biggest automaker, said it was not aware of any hacking incidents and that hacking was at least close to impossible. A Toyota source said the vehicles are designed to change their coding constantly. Chrysler is joining industry groups and outside organizations to tackle car security.\nAs noted in Car and Driver, as more people start to access car networks, the auto industry will beef up relevant security. That may also mean something all too familiar to the PC industry, a relentless skirmish between hackers and automakers.\nExplore further: Tech companies eye security that goes beyond passwords", "label": 1}
{"text": "-: Password Hacking :-\nPassword cracking is the process of recovering\nsecret passwords from data that has been stored in or transmitted\nby a computer system. A common approach is to repeatedly try guesses\nfor the password.\nMost passwords can be cracked by using following techniques :\n1) Hashing :-\nHere we will refer to the one way function (which may be either an\nencryption function or cryptographic hash) employed as a hash and\nits output as a hashed password.\nIf a system uses a reversible function to obscure stored passwords,\nexploiting that weakness can recover even 'well-chosen' passwords.\nOne example is the LM hash that Microsoft Windows uses by default\nto store user passwords that are less than 15 characters in length.\nLM hash breaks the password into two 7-character fields which are\nthen hashed separately, allowing each half to be attacked separately.\n||Hash functions like SHA-512,\nSHA-1, and MD5 are considered impossible to invert when used correctly.|\n2) Guessing :- Many passwords\ncan be guessed either by humans or by sophisticated cracking programs\narmed with dictionaries (dictionary based) and the user's personal\nNot surprisingly, many users choose weak passwords, usually one\nrelated to themselves in some way. Repeated research over some 40\nyears has demonstrated that around 40% of user-chosen passwords\nare readily guessable by programs. Examples of insecure choices\n* blank (none)\n* the word \"password\", \"passcode\", \"admin\"\nand their derivatives\n* the user's name or login name\n* the name of their significant other or another person (loved one)\n* their birthplace or date of birth\n* a pet's name\n* a dictionary word in any language\n* automobile licence plate number\n* a row of letters from a standard keyboard layout (eg, the qwerty\nkeyboard -- qwerty itself, asdf, or qwertyuiop)\n* a simple modification of one of the preceding, such as suffixing\na digit or reversing the order of the letters.\nand so on....\nIn one survery of MySpace passwords which had been phished, 3.8\npercent of passwords were a single word found in a dictionary, and\nanother 12 percent were a word plus a final digit; two-thirds of\nthe time that digit was.\n||A password containing both uppercase &\nlowercase characters, numbers and special characters\ntoo; is a strong password and can never\n3) Default Passwords\n:- A moderately high number of local\nand online applications have inbuilt default passwords that have\nbeen configured by programmers during development stages of software.\nThere are lots of applications running on the internet on which\ndefault passwords are enabled. So, it is quite easy for an attacker\nto enter default password and gain access to sensitive information.\nA list containing default passwords of some of the most popular\napplications is available on the internet.\n||Always disable or change the\napplications' (both online and offline) default username-password\n4) Brute Force :-\nIf all other techniques failed, then attackers uses brute force\npassword cracking technique. Here an automatic tool is used which\ntries all possible combinations of available keys on the keyboard.\nAs soon as correct password is reached it displays on the screen.This\ntechniques takes extremely long time to complete, but password will\n||Long is the password, large\nis the time taken to brute force it.\n5) Phishing :-\nThis is the most effective and easily executable password cracking\ntechnique which is generally used to crack the passwords of e-mail\naccounts, and all those accounts where secret information or sensitive\npersonal information is stored by user such as social networking\nwebsites, matrimonial websites, etc.\nPhishing is a technique in which the attacker creates the fake login screen\nand send it to the victim, hoping that the victim gets fooled into entering\nthe account username and password. As soon as victim click on \"enter\"\nor \"login\" login button this information reaches to the attacker\nusing scripts or online form processors while the user(victim) is redirected\nto home page of e-mail service provider.\n||Never give reply to the\nmessages which are demanding for your username-password,\nurging to be e-mail service provider.\nIt is possible to try to obtain the passwords\nthrough other different methods, such as social engineering, wiretapping,\nkeystroke logging, login spoofing, dumpster diving, phishing, shoulder\nsurfing, timing attack, acoustic cryptanalysis, using a Trojan Horse\nor virus, identity management system attacks (such as abuse of Self-service\npassword reset) and compromising host security.\nHowever, cracking usually designates a guessing attack.", "label": 1}
{"text": "During a speech in June 2012, Jonathan Evans, the chief of the UK’s home security agency MI5, stated that it was “fighting 'astonishing' levels of cyber-attacks”. The worry is not just about the number, but the sophistication and the degree of targeting of individual people and organisations. This is making it harder and harder to detect and stop such attacks with conventional cyber security defences.\nAs a consequence, many are evaluating advanced tools that supplement point security products such as anti-virus, firewalls and intrusion prevention systems (IPS). This includes deploying what some are calling advanced security intelligence (ASI). ASI is the ability to look at a wide range of information sources in real time and spot that something anomalous is going on; this could be an attack or dangerous or undesirable user behaviour, another risk that needs to be mitigated.\nASI builds on existing technology such as log management and SIEM (security information and event management) tools. The vendors involved, which include LogRhythm, IBM (via its Q1 Labs acquisition) and McAfee (via its Nitro Security acquisition), are souping their products up, in particular their SIEM tools, to provide ASI capabilities. Some are using the term NG-SIEM (next generation SIEM).\nHere are some examples of where ASI may succeed where point security products have failed:\n- Signature-based anti-virus software cannot detect new malware (zero-day) attacks. However, using ASI to correlate server activity logs could identify that a given server is being used to contact many other end-points on a given private network and is sending messages out to an unusual IP address (probably a command and control server). The recent Flame malware worked in a similar way to this. ASI would have been one way of detecting such an attack in advance (others are pointed out in a recent article by Quocirca).\n- An intrusion prevention system (IPS) may prevent multiple failed attempts to access a server from a particular bad IP address, but may not see that data is already being copied from that server due to a single successful penetration that was well enough disguised. Correlating log and event files could identify that two such events are related and lead to the prevention of a data theft. A so-called advanced persistent threat (APT) could have this sort of profile.\n- It may be normal for a known user to access a given application remotely and out of office hours, but not if the request is coming from a location where they cannot physically be located. Correlating each access request against the previous successful access request and checking the geographic location of the devices used can identify a physically impossible event such as a user having moved from London to Paris in the space a few minutes or hours, even if the bona fide user’s job role could see them legitimately in both locations.\n- It might be usual for an employee to access customer information; it may also be usual for them to download such data to a file for reporting reasons. However, for them to copy the data to a non-compliant location, for example a cloud storage resource in a certain country, should raise an alarm. There may be no malicious intent here; perhaps this is an example of a line-of-business commissioning its own cloud resources (an increasingly common practice). This requires rules that understand user access rights and compliance rules and the ability to correlate these in real time with attempts to copy data and the location of the target storage service.\nASI tools can make use of many sources of IT intelligence data in real time. They also have central policy engines which allow customers to write their own rules as well as including a wide range of out-of-the-box rules (e.g. flagging suspicious activity, such as multiple machines simultaneously attempting connections to unauthorised IP addresses outside of a given network).\nFor businesses, there is no end to the struggle to get the upper hand over cyber-criminals. For governments, the situation is arguably even worse, as cyber-space becomes the 5th theatre for warfare (after land, sea, air and space) and terrorists see cyber-space as a way to go after critical infrastructure. All have to keep upping the ante, to avoid falling too far behind, or perhaps even get ahead, turning cyber security into an offensive rather than defensive act.\nQuocirca’s report Advanced Cyber Security Intelligence is freely available here.", "label": 1}
{"text": "Welcome to the Virus Encyclopedia of Panda Security.\nSysinternalsAntivirus is an adware program which attempts to deceive users by using a known name to be called, like Sysinternals, whose owner is Microsoft.\nSysinternalsAntivirus warns users of unexisting threats in their computers so that they purchase a certain program that removes them from the computer.\nAdditionally, it prevents users from working with the computer, as it blocks the execution of the files with an EXE extension, displaying a message informing them that these files are infected.\nSysinternalsAntivirus can reach the computer when the user accesses certain websites which display banners or pop-up windows which lead to the download of this program. It can also reach the computer in a link that can be received via spam messages, fraudulent websites, etc.\nSysinternalsAntivirus is easy to recognize, as it shows the symptoms below:\n- It reaches the computer in a file with the following icon:\n- When it is run and installed, the interface of the program is displayed and starts scanning the system in search for possible malware:\n- Once finished, it displays a warning message informing users that the program has found several infected programs and documents in the computer:", "label": 1}
{"text": "There are rarely talks about security breaches and problems that did or could result from those breaches in the public. The reason for that are simple, it is often embarrassing for the owner of the compromised account to admit the breach and for the solution provider to get possible flaws exposed that could result into a loss in confidence by existing or future clients into the safety of the clients data that were entrusted to the provider.\nThe fact is that there is in most cases no reason for embarrassment, if the account owner and the solution provider did everything they could to prevent breaches in the security to the extent that is justifiable and practical considering the type of data that need to be protected and the possible consequences for the involved parties if a breach does occur.\nOf course are breaches because of disregard of fundamental does and don’ts embarrassing and not worth to be the subject of a public debate. I am referring to things like the use of “guessable passwords”, such as “password”, “master”, “root” or the first name of the child of the account owner or the fact that factory/system default passwords were not changed, even though the owner was aware of the existence of such things. Also the deployment of fundamental security measures such as firewalls, anti-virus and anti-spyware, proper encryption of data and communication between server and clients and the deployment of the latest security updates to the software that is used on any side, the users and the software provider’s side.\nThere is NO such Thing as 100% Secure\nEven if you do anything right, does it not mean that you are 100% safe and invincible against security attacks, that are targeted or untargeted. You would be a fool who is disconnected from reality if you would believe that.\nThere is no 100% security! Most security relies on the fact that the amount of time and resources necessary to breach the security does it not make worthwhile for an attacker to attempt to break the security of a system or account. If the benefits or gain of breaking into a system or account are worth less than what it takes to actually do it, most attackers are compelled and your system can be considered pretty much safe. The problem is always the type of attackers who don’t want to gain anything but the exploitation and detection of security holes in systems they choose to attack. Those folks are commonly referred to as ethical hackers or “white hat”; because they help companies to make their systems more secure and improve on the implementation of the right security precautions.\nHaving a Plan If the Unlikely Does Happen\nSince nobody can ensure 100% security, is it vital to have a plan and process in place and ready to deploy in the event that a breach does happen. I am always amazed (in a bad sense) to learn that even large companies fail in this respect and do not have plans or procedure to follow in case the unlikely but possible event does actually happen. Google seems to be one of those companies who fail to have a plan for such events. This is disturbing to me, because Google increased their efforts to consolidate and integrate the accounts of their various services into as few accounts as possible and eventually into a single master account that allows access to everything, from AdSense to YouTube.\nReal World (BAD) Example\nHow do I know this? Well, I experienced the unlikely event myself with a personal YouTube account, which I did not link to any of my Google accounts yet, except for a one-way connection to my Google AdSense account. The account is not critical to me (thank god) and also does not expose much access to personal data due to the way how I use the account and the fact that I did not link it to a Google account that would enable the attacker to access data that are critical to me.\nHow the breach happened is still uncertain. I never exposed my user credentials anywhere, my password was not guessable, and I run anti-spyware and anti-virus software and keep them up-to-date. All latest security updates for the operating system and browsers used are installed. Does this exclude the possibility that the attacker was able to exploit vulnerability on my side to be able to break into my YouYube account? No, it does not.\nThe attacker locked me out of my account by changing the password to something else and the email address behind the account to a throw away Yahoo! email. It does not seem to be a targeted attack, in a sense that somebody wanted to gain access to my account in particular. What the attacker wants with my account is also not clear. He logged into the account only twice so far and relatively little was changed in my account.\nI became aware of a problem with the account on January 3, 2008, contacted YouTube support on January 4, 2008 and realized after the initial response another day later on January 5, 2008 that my account was compromised.\nI immediately responded to make YouTube aware of this fact as well as provided as many information I could to a) establish that I am the rightful owner of the account, b) contact details to check my claims even further and to have something in their hands against me, if I would just be a prankster who makes wrong claims. I also suggested blocking access to the account to prevent any further damage to the content and allow further exploitation of the unlawful access to the account. I also wanted to make sure that any abuse of the account that could get me or Google into trouble will be possible, such as using the account to publish illegal content.\nThe account was not blocked. I noticed that a login to the account occurred again 4 days later on January 9, 2008. I sent another email to YouTube without getting a response. This became a troublesome pattern, because response of support declined since I raised the bar by claiming a security breach.\nI was going to the extent to submit another support request via their web form to get a new ticket number. I referred to the existing ticket number in that request. I also used the “report background graphic” form to raise additional awareness of the problem.\nI used the only direct phone number I had at Google support, the service number for Google Apps, where I am a paying customer to get a hold of somebody and to reinforce my claims, plus provide additional identifiable information about by identity. After that phone call I did get an email from the Google Apps support team, requesting additional details in writing to back up my story. I responded with the requested information and again stopped hearing back from anybody. That was on January 9, 2008.\nI wrote a long and nasty email (without swearing, I promise) to several email addresses at Google and YouTube, including YouTube and Google support, YouTube and Google Security and Google Feedback on January 11, 2008. Only the email to Google support bounced. I did receive an email on the next day, with the request to provide 5 things to identify my rightful ownership of the account. I did this already directly or indirectly prior to that, but I did not complain and provided the requested things in the order and format they wanted. This was on January 13, 2008.\nI sent an email to support again today, asking about the status. I received an email four and a half hour later, that acknowledged that my account appears to have been compromised and the new password for the account. They also suggested that I should update the email address back to an account under my control. This is a multiple step process where the attacker was given the opportunity to gain control of the account again. If the attacker would have tried to login to my account again and noticed that the password he set does not work anymore, he could have simply used the “forgot password” form to retrieve the new password and then change it again.\nFortunately did this not happen and I was able to gain control over my account again, 12 days after the breach occurred and 11 days after YouTube was notified about the breach.\nBoy, I am glad that I did not link my YouTube account to my Google account yet and I also do not plan to do so, until I was reassured that the cause for the breach was determined and that the hole was closed.\nI offered my assistance to the YouTube/Google team to investigate the incident and to determine where and how the breach happened. I also hope that this incident and how it was handled will trigger a review or instatement of procedures that deal with those kinds of problems. This becomes even more critical when it comes to security breaches of users Google accounts where the breach can have much greater and severe consequences. The amount of damage possible, if your Google account was hijacked and if you use several of Google’s services under that account, is exponentially greater than the damage possible, if the breach is isolated to only one of the Google services.\nTake Away and the Lesson to be Learned\nThis incident also serves as an example to other companies of how NOT to handle such things and a reminder to double check to double check if and what type of procedure you have in place in case the unlikely does happen. This addresses especially those of you who are responsible for those things in one way or another and are unaware of such procedures. This includes executive level employees and others with a stake in the company who are not directly involved with the security of their companies services. It does not hurt to ask what the plan is if a breach gets reported.\nIf you don’t have plans, you better start working on one, rather sooner than later, before it is too late.\nInternet Marketer and Entrepreneur, owner and editor of the internet marketing resources portal at Cumbrowski.com", "label": 1}
{"text": "Cyber security is a concern and a necessity at all levels. Computers and networks operated by governments, businesses, academia and other associations and agencies have been prime targets of cyber attack, but the number and rate of attacks on privately owned personal computers and smart devices has become explosively endemic. While cyber security and safety is a responsibility of all computer and smart device users, the federal government along with a variety of private and public partners has promoted “National Cyber Security Awareness Month” (NCSAM) for many years. Traditionally, the president of the United States had inaugurated NCSAM with a presidential declaration calling on everyone to be aware of cyber security, and to take all appropriate precautions to secure their digital devices from attack. In October 2012, there will again be a national effort to encourage and promote cyber security.\nThis year, the lead federal agency promoting Cyber Security Awareness Month will be the Department of Homeland Security (DHS), which will be coordinating events and activities with the National Cyber Security Alliance (NCSA) and the Multi-State Information Sharing and Analysis Center (MS-ISAC). According to the DHS, this joint operation, “ ... encourages Americans to ACT – Achieve Cybersecurity Together – reflecting the interconnectedness of the modern world and the responsibility of each of us in securing cyberspace.”\nOne might ask, “So what can I really do to help the cyber security effort?” The various agencies working together have come up with a list of actions and activities all computer and smart device users should implement. One of several behaviors encouraged by the alliance is to “Stop, Think, Connect” (stopthinkconnect.org). According to the alliance, all users should: “Stop: Before you use the Internet, take time to understand the risks and learn how to spot potential problems. Think: Take a moment to be certain the path ahead is clear. Watch for warning signs and consider how your actions online could impact your safety, or your family’s. Connect: Enjoy the Internet with greater confidence, knowing you’ve taken the right steps to safeguard yourself and your computer. Protect yourself and help keep the Web a safer place for everyone.”There are several definitive steps that users can take to implement and improve the security of their digital devices. According to a Microsoft Web page devoted to the National Cyber Security Awareness Month, there are six major practices that we should all accomplish in order to improve our cyber safety and security. Microsoft’s first recommendation is to defend your computer by strengthening your computer’s defenses, and not to be tricked into downloading malicious software. While these first recommendations may seem to be common sense for most computer users, these recommendations are also some of the least implemented. In order to defend our computers and other devices from attack, we need to keep all software (especially Web browsers) up to date; install legitimate and comprehensive security software and keep it current with the latest updates (most security publishers now push hourly or continuous updates); use and never turn off the firewall; be sure to have a hard-to-guess password on your router (and my urging to implement the highest level of encryption available on your wireless access point or device); and to use USB and other flash memory devices cautiously, as they have become a major vector for passing malware between computers and other devices. Microsoft also warns, “Think before you open attachments or click links in an e-mail message, an instant message (IM), or on a social network, even if you know the sender.” Much of the spam and malware being disseminated appears to come from someone we know, as their computers, instant messaging account, address books, or e-mail accounts have been hijacked and used to spread malware and spam to others, under the guise that it is OK because it is from someone you know. Another component of this second recommendation is to never click on links or buttons that appear in pop-up windows.\nIdentity theft and related financial crimes has become a huge source of revenue for cyber crooks the world over, and Microsoft covers this in its second recommendation, “Protect Sensitive Information.” Microsoft warns users that before they enter any sensitive data on a Web site or online form, look for indications that the Web page is secure, such as the Web address beginning with “https” rather than “http,” and some indication from the browser that the connection is secure. Most browsers use a padlock (clearly open or closed) or some similar indication of a secure connection. Another common trick to steal personal information, such as usernames, passwords, banking and credit card information, and other personal information is commonly referred to as “phishing,” where identity thieves attempt to trick the user into disclosing personal information. Much of this phishing is by way of e-mails informing the user that their e-mail account will be locked unless they respond with their username and password; credit card companies, banks and other institutions asking for personal credit card or bank account information; offers of riches in exchange for helping some foreign official or widow to place investments in this country; foreign lottery winnings; and a variety of other scams. One of the latest common scams is known as “ransomware” where the user’s computer is locked, and a warning from the FBI or other law enforcement agency appears on the screen informing the user that unless he pays a “fine,” typically $200, his computer will remain locked, and he will be prosecuted for several felonies, including possessing child pornography.\nSimilar requests for personal information that can be abused often arrive in instant messages or social networking postings. Another common e-mail scam is a post apparently from a friend or relative that claims they lost their wallet, checkbook, passport, return airline tickets and credit cards while visiting a foreign country, and are stranded unable to return home. This recognizable friend or relative then asks you to make him a loan and wire a large sum of money to him such that he can get home. The problem is that this is a complete fraud, and that friend or relative overseas is a name stolen from a hijacked e-mail account or address book! Also be aware of phone calls claiming to be from Microsoft (or a recognizable computer security company) telling you that your computer is infected with a virus, and that either for free or for a fee charged to your credit card, they will remotely access your computer and clean it for you, “So please give us remote access to your computer.” Not only will they not clean your computer of malware, but they will likely plant malware on your computer as well as access and steal all of your personal data and information.\nThird on Microsoft’s list of recommendations is to create strong passwords, and keep them secret. Passwords should be complex long phrases, consisting of upper case (capital) and lower case letters, along with numbers and symbols. These passwords should not be easy for other to guess like permutations of your name, address, phone number, kids names and birthdays; pets’ names; and other information that can be easily obtained through public or online resources. It is also necessary to utilize different passwords on different Web sites, such that if one Web site is compromised, it will not adversely impact your passwords and accounts on other Web sites. Microsoft emphasizes that it is especially important to use different complex passwords on Web sites that contain your financial information, such as banking, credit card and shopping Web sites.\nNo. 4 from Microsoft is “Take charge of your online safety and reputation. Discover what is on the Internet about you and periodically evaluate what you find.” What others say about you online in social networking services, blogs and even eBay user ratings can adversely impact your online reputation. It is important to both maintain a positive online reputation and correct erroneous postings about you, but be careful not to fall into someone’s trap and disclose too much personal information.\nIn its fifth security recommendation, Microsoft urges that users exercise care when using social networks such as Facebook and Twitter. All of the legitimate social networking services offer “settings” or “options” where users can set and manage their privacy and security settings. Users should control who can access their private information, what private information is available, and how others can search for your information. It might be appropriate to block other people from viewing your information. In addition to Microsoft’s suggestions, I would also add do not post information that you are out of town, on vacation or even at a movie or at dinner, as burglars and other crooks read Facebook and Twitter looking for empty homes to burglarize. Turn off the GPS in your digital camera or Smartphone before taking pictures that you want to post on a social networking site such as Facebook, or otherwise strip off the GPS information, as crooks and pedophiles have been known to use the GPS information encoded in digital photographs posted online to locate homes, cars, valuables and children for the purposes of victimization. An old cliché’ says, “Don’t do anything that you would not want your grandmother to read in the newspaper,” and that applies to social media postings as well.\nNo. 6 from Microsoft says, “Take extra steps to help keep kids safer online.” Online safety and security must be a family effort, and incorporate some mix of guidance and monitoring. Microsoft suggests that “(parents) negotiate clear guidelines for Web and online game use that fit your kids’ maturity and your family’s values. Pay attention to what kids do and who they meet online.” Pedophiles and identity thieves troll chat rooms, social networking Web sites, blogs and other online resources looking for potential victims. Parents and children need to be cognizant of the risks, and educated in what to watch for that might indicate potential risks to children. Children must never disclose personal information to anyone, especially others who claim to be the same age and gender as the child (pedophiles often pretend to be a child in order to gain the confidence of the potential victim). Identity thieves try to gain the trust of children and trick them into disclosing private family information; residential burglars will do the same, asking the child about vacation or dinner plans: “We are going out for pizza and then a movie” tells a burglar that the house may be a good target. Children should never go to meet someone face to face that they met online, unless under the direct supervision and participation of a parent.\nThere are a number of National Cyber Security Awareness Month events posted online (staysafeonline.org/ncsam/events), several of which will be streamed free over the Internet. There are also free materials available for parents, teachers, children and businesses that can be used in a variety of environments for educating others (staysafeonline.org/ncsam). While October is officially National Cyber Security Awareness Month, every month should be. Stop, think and connect properly, and stay safe online.", "label": 1}
{"text": "- 12 iPhones Apps That Will Make You a Networking Star\n- 10 Careers Robots Are Taking From You\n- Big Data Gold Isn't Always Where You Would Expect It\n- 6 Tips to Build Your Social Media Strategy\nNetwork World - When it comes to security, most mobile devices are a target waiting to be attacked. That's pretty much the conclusion of a report to Congress on the status of the security of mobile devices this week by watchdogs at the Government Accountability Office.\nCombine the lack of security with the fact that mobile devices are being targeted by cybercriminals and you have a bad situation. For example, the number of variants of malicious software aimed at mobile devices has reportedly risen from about 14,000 to 40,000 or about 185% in less than a year, the GAO stated.\n\"Mobile devices face an array of threats that take advantage of numerous vulnerabilities commonly found in such devices. These vulnerabilities can be the result of inadequate technical controls, but they can also result from the poor security practices of consumers,\" the GAO stated. \"Private [companies] and relevant federal agencies have taken steps to improve the security of mobile devices, including making certain controls available for consumers to use if they wish and promulgating information about recommended mobile security practices. However, security controls are not always consistently implemented on mobile devices, and it is unclear whether consumers are aware of the importance of enabling security controls on their devices and adopting recommended practices.\"\nThe GAO report came up with a list of mobile vulnerabilities it says are common to all mobile platforms and it offered a number of possible fixes for the weaknesses: From the report:\n• Mobile devices often do not have passwords enabled. Mobile devices often lack passwords to authenticate users and control access to data stored on the devices. Many devices have the technical capability to support passwords, personal identification numbers (PIN), or pattern screen locks for authentication. Some mobile devices also include a biometric reader to scan a fingerprint for authentication. However, anecdotal information indicates that consumers seldom employ these mechanisms. Additionally, if users do use a password or PIN they often choose passwords or PINs that can be easily determined or bypassed, such as 1234 or 0000. Without passwords or PINs to lock the device, there is increased risk that stolen or lost phones' information could be accessed by unauthorized users who could view sensitive information and misuse mobile devices.\n• Two-factor authentication is not always used when conducting sensitive transactions on mobile devices. According to studies, consumers generally use static passwords instead of two-factor authentication when conducting online sensitive transactions while using mobile devices. Using static passwords for authentication has security drawbacks: passwords can be guessed, forgotten, written down and stolen, or eavesdropped. Two-factor authentication generally provides a higher level of security than traditional passwords and PINs, and this higher level may be important for sensitive transactions. Two-factor refers to an authentication system in which users are required to authenticate using at least two different \"factors\" — something you know, something you have, or something you are — before being granted access. Mobile devices can be used as a second factor in some two-factor authentication schemes. The mobile device can generate pass codes, or the codes can be sent via a text message to the phone. Without two-factor authentication, increased risk exists that unauthorized users could gain access to sensitive information and misuse mobile devices.\n• Wireless transmissions are not always encrypted. Information such as e-mails sent by a mobile device is usually not encrypted while in transit. In addition, many applications do not encrypt the data they transmit and receive over the network, making it easy for the data to be intercepted. For example, if an application is transmitting data over an unencrypted WiFi network using http (rather than secure http), the data can be easily intercepted. When a wireless transmission is not encrypted, data can be easily intercepted.\n• Mobile devices may contain malware. Consumers may download applications that contain malware. Consumers download malware unknowingly because it can be disguised as a game, security patch, utility, or other useful application. It is difficult for users to tell the difference between a legitimate application and one containing malware. For example, an application could be repackaged with malware and a consumer could inadvertently download it onto a mobile device. the data can be easily intercepted. When a wireless transmission is not encrypted, data can be easily intercepted by eavesdroppers, who may gain unauthorized access to sensitive information.\n• Mobile devices often do not use security software. Many mobile devices do not come preinstalled with security software to protect against malicious applications, spyware, and malware-based attacks. Further, users do not always install security software, in part because mobile devices often do not come preloaded with such software. While such software may slow operations and affect battery life on some mobile devices, without it, the risk may be increased that an attacker could successfully distribute malware such as viruses, Trojans, spyware, and spam to lure users into revealing passwords or other confidential information.\n• Operating systems may be out-of-date. Security patches or fixes for mobile devices' operating systems are not always installed on mobile devices in a timely manner. It can take weeks to months before security updates are provided to consumers' devices. Depending on the nature of the vulnerability, the patching process may be complex and involve many parties. For example, Google develops updates to fix security vulnerabilities in the Android OS, but it is up to device manufacturers to produce a device-specific update incorporating the vulnerability fix, which can take time if there are proprietary modifications to the device's software. Once a manufacturer produces an update, it is up to each carrier to test it and transmit the updates to consumers' devices. However, carriers can be delayed in providing the updates because they need time to test whether they interfere with other aspects of the device or the software installed on it.\nIn addition, mobile devices that are older than two years may not receive security updates because manufacturers may no longer support these devices. Many manufacturers stop supporting smartphones as soon as 12 to 18 months after their release. Such devices may face increased risk if manufacturers do not develop patches for newly discovered vulnerabilities.\n• Software on mobile devices may be out-of-date. Security patches for third-party applications are not always developed and released in a timely manner. In addition, mobile third-party applications, including web browsers, do not always notify consumers when updates are available. Unlike traditional web browsers, mobile browsers rarely get updates. Using outdated software increases the risk that an attacker may exploit vulnerabilities associated with these devices.\n• Mobile devices often do not limit Internet connections. Many mobile devices do not have firewalls to limit connections. When the device is connected to a wide area network it uses communications ports to connect with other devices and the Internet. A hacker could access the mobile device through a port that is not secured. A firewall secures these ports and allows the user to choose what connections he wants to allow into the mobile device. Without a firewall, the mobile device may be open to intrusion through an unsecured communications port, and an intruder may be able to obtain sensitive information on the device and misuse it.\n• Mobile devices may have unauthorized modifications. The process of modifying a mobile device to remove its limitations so consumers can add features (known as \"jailbreaking\" or \"rooting\") changes how security for the device is managed and could increase security risks. Jailbreaking allows users to gain access to the operating system of a device so as to permit the installation of unauthorized software functions and applications and/or to not be tied to a particular wireless carrier. While some users may jailbreak or root their mobile devices specifically to install security enhancements such as firewalls, others may simply be looking for a less expensive or easier way to install desirable applications. In the latter case, users face increased security risks, because they are bypassing the application vetting process established by the manufacturer and thus have less protection against inadvertently installing malware. Further, jailbroken devices may not receive notifications of security updates from the manufacturer and may require extra effort from the user to maintain up-to-date software.\n• Communication channels may be poorly secured. Having communication channels, such as Bluetooth communications, \"open\" or in \"discovery\" mode (which allows the device to be seen by other Bluetooth-enabled devices so that connections can be made) could allow an attacker to install malware through that connection, or surreptitiously activate a microphone or camera to eavesdrop on the user. In addition, using unsecured public wireless Internet networks or WiFi spots could allow an attacker to connect to the device and view sensitive information.\nThe GAO report went on to state that connecting to an unsecured WiFi network could let an attacker access personal information from a device, putting users at risk for data and identity theft. One type of attack that exploits the WiFi network is known as man-in-the-middle, where an attacker inserts himself in the middle of the communication stream and steals information.\nSo what can be done to secure mobile devices? The GAO report offers a number of ideas including:\n• Enable user authentication: Devices can be configured to require passwords or PINs to gain access. In addition, the password field can be masked to prevent it from being observed, and the devices can activate idle-time screen locking to prevent unauthorized access.\n• Enable two-factor authentication for sensitive transactions: Two-factor authentication can be used when conducting sensitive transactions on mobile devices. Two-factor authentication provides a higher level of security than traditional passwords. Two-factor refers to an authentication system in which users are required to authenticate using at least two different \"factors\" — something you know, something you have, or something you are — before being granted access. Mobile devices themselves can be used as a second factor in some two-factor authentication schemes used for remote access. The mobile device can generate pass codes, or the codes can be sent via a text message to the phone. Two-factor authentication may be important when sensitive transactions occur, such as for mobile banking or conducting financial transactions.\n• Verify the authenticity of downloaded applications: Procedures can be implemented for assessing the digital signatures of downloaded applications to ensure that they have not been tampered with.\n• Install antimalware capability: Antimalware protection can be installed to protect against malicious applications, viruses, spyware, infected secure digital cards,b and malware-based attacks. In addition, such capabilities can protect against unwanted (spam) voice messages, text messages, and e-mail attachments.\n• Install a firewall: A personal firewall can protect against unauthorized connections by intercepting both incoming and outgoing connection attempts and blocking or permitting them based on a list of rules.\n• Install security updates: Software updates can be automatically transferred from the manufacturer or carrier directly to a mobile device. Procedures can be implemented to ensure these updates are transmitted promptly.\n• Remotely disable lost or stolen devices: Remote disabling is a feature for lost or stolen devices that either locks the device or completely erases its contents remotely. Locked devices can be unlocked subsequently by the user if they are recovered.\n• Enable encryption for data stored on device or memory card: File encryption protects sensitive data stored on mobile devices and memory cards. Devices can have built-in encryption capabilities or use commercially available encryption tools.\n• Enable whitelisting: Whitelisting is a software control that permits only known safe applications to execute commands.\n• Establish a mobile device security policy: Security policies define the rules, principles, and practices that determine how an organization treats mobile devices, whether they are issued by the organization or owned by individuals. Policies should cover areas such as roles and responsibilities, infrastructure security, device security, and security assessments. By establishing policies that address these areas, agencies can create a framework for applying practices, tools, and training to help support the security of wireless networks.\n• Provide mobile device security training: Training employees in an organization's mobile security policies can help to ensure that mobile devices are configured, operated, and used in a secure and appropriate manner.", "label": 1}
{"text": "Tool:Win32/Hideproc.C is a new version of an old Trojan that’s installed as one part of a larger infection for the purpose of concealing memory processes and other malicious components. Most Trojans like Tool:Win32/Hideproc.C will run without your permission as concealed memory processes and can be observed only indirectly through the side effects of their attacks. Since Tool:Win32/Hideproc.C may be part of a larger threat and even more malicious threat, you should immediately take action to delete Tool:Win32/Hideproc.C from your computer before serious damage occurs.\nThe many Tools of Tool:Win32/Hideproc.C’s Malignant Trade\nTool:Win32/Hideproc.C is just a 2010 version of the Hideproc Trojan that was first noted in 2007. Since that time, different versions of Hideproc have appeared, including Tool:Win32/Hideproc.C as well as Trojan:Win32/Hideproc.F and Trojan:Win32/Startpage.RM.\nEven if your security software can detect one of these threats, your PC may still be vulnerable to attacks by newer versions like Tool:Win32/Hideproc.C. Keeping your anti-malware programs completely updated is a vital step in protecting your PC from Tool:Win32/Hideproc.C. Avoiding initial infections can be done by keeping your browser up to date, disabling scripts from untrustworthy sources and avoiding suspicious files.\nSome versions of Hideproc are installed as specific pieces of a larger infection for the purpose of hiding this infection. Tool:Win32/Hideproc.C may conceal, not only Tool:Win32/Hideproc.C’s own memory processes, but also the memory processes of other malicious programs. When this is combined with a standard Trojan tactic of running automatically when Windows loads, this lets Tool:Win32/Hideproc.C and Tool:Win32/Hideproc.C’s cohorts hide in plain sight while still being active at all times.\nYou can detect hidden memory processes by noting unusual system resource usage or by observing the other side effects of the attacks caused by Tool:Win32/Hideproc.C and similar Trojans.\nThe Rest of what Tool:Win32/Hideproc.C Has in Store for Your Computer\nTool:Win32/Hideproc.C or threats related to Tool:Win32/Hideproc.C may also cause other problems:\n- Tool:Win32/Hideproc.C may hijack your web browser. Hijacks can play advertisements, create fake errors that make it appear as though a benevolent website isn’t safe, change your homepage or redirect you to dangerous websites.\n- Tool:Win32/Hideproc.C may install a Remote Administration Tool or serve as a RAT by itself. RATs let remote criminals control your computer and are often the culprits behind Distributed-Denial-of-Service attacks and other illegal activities.\n- Tool:Win32/Hideproc.C may use keylogger functions or other spyware-related capabilities to record passwords and other information in a log that is later sent to a remote criminal.\n- Tool:Win32/Hideproc.C may block applications and even make it look like those applications are infected when they’re completely fine.\n- Tool:Win32/Hideproc.C may create Trojans that imitate Windows errors to try to fool you into performing self-destructive actions. These Trojans can even imitate specific Windows functions like the Security Essentials Alert.\nTool:Win32/Hideproc.C Automatic Detection Tool (Recommended)\nIs your PC infected with Tool:Win32/Hideproc.C? To safely & quickly detect Tool:Win32/Hideproc.C, we highly recommend you run the malware scanner listed below.\nDownload SpyHunter's* Malware Scanner to detect Tool:Win32/Hideproc.C What happens if Tool:Win32/Hideproc.C does not let you open SpyHunter or blocks the Internet?\nFile System Modifications\n- The following files were created in the system:\n# File Name 1 1 Click PC Fix v3.5.exe 2 11878.dll 3 adsnt.exe 4 appconf32.exe 5 ashampkeygen.exe 6 audiosrv32.dll 7 ce3f3047-08bc-36dd-43e4-358cd4362a09.dll 8 chngu32.dll 9 chp.exe 10 cleaner7.exe 11 core32_175.dll 12 crack maxsea plaisance v10.11.12.exe 13 cryptnet32.dll 14 DCPPaid.exe 15 dispdrv.exe 16 DK.exe 17 dpcfinen.dll 18 Fl_3-8D-0fa-O4.dll 19 gamexl.exe 20 info.exe 21 ISd33_2298.exe 22 lpnedu.dll 23 MsMxEng.exe 24 NEBDFWc.dll 25 oyplemis.dll 26 PornoProtector.exe 27 questbrowse137.exe 28 ramcore.exe 29 sbluini.dll 30 service.exe 31 setup.exe 32 setup_lvk.exe 33 stlubchg.dll 34 SubsHelperBHO.dll 35 Svg64.exe 36 THE7SINS_RETAIL.EXE 37 uinex4.dll 38 updateuser.exe 39 userlib.exe 40 w2_0.exe 41 winntse.bin.exe 42 wrtchry.dll 43 Xtreme Stage Hack.dll 44 xvid_setup1.2.2-win32.exe 45 yaxuvu.dll\nPosted: April 18, 2011 | By SpywareRemove\nThreat Level: 8/10\nRate this article:\nDetection Count: 1,330", "label": 1}
{"text": "Investigating and prosecuting cybercrimes are diverse and fluid fields.\nThe dark-hearted members of the human race have found ways to exploit innovations for their own selfish means throughout time. Now, with the ever-growing global dependence on computer networks, criminals are finding new ways to disrupt lives in the real world through enterprise in the cyber one. The U.S. Department of Justice and its allies have adapted their methods and techniques over the past decade and continue to adjust to prevent the morphing illegal activities in cyberspace, whether the computer crime itself is the full intent or only part of a larger scheme.\nDuring the past 10 years, the Department of Justice (DOJ) has seen changes in intrusions and cybercases, from the crimes themselves to the types of criminals carrying out the illegal actions. Previously, most computer crimes were perpetrated by lone-wolf hackers acting independently, often for fame, publicity or the thrill. Today, cybercrime has become more organized, with financial gain serving as the main motive for most actions. Attacks often are aimed at financial institutions or designed for identity theft. And instead of some solitary computer geek giggling away as he hacks into networks from his basement, groups of people are now coming together, sometimes in tight organizations and sometimes in more loosely knit associations, to achieve a financial end.\nThough the DOJ has seen instances where organized crime uses the Internet to handle some of its activities, most of the online organizations the department battles lack a hierarchy. Instead, people use social networking tools such as instant messaging, forums and e-mail to connect and work together in groups. They buy themselves information so people in different countries or across one nation can work together to perpetrate a crime.\nThis type of networking allows for greater specialization in a particular field. In the past, when cybercrime was conducted mainly by individuals, each criminal had to obtain all the pieces necessary to carry out the transgression. For example, someone aiming to commit financial fraud might need three pieces of information—a credit card number, a fake credit card and a fake identification—to steal money. Now, officials at the DOJ are dealing with more specialized criminals who band together and collaborate to benefit from one another’s individual areas of expertise. People skilled at stealing credit card numbers would sell that information to individuals who are experts at encoding fake credit cards. In 2004, the department made a major bust in this area, taking down a large operation known as Shadow Crew, which was basically a marketplace for selling identification information.\nOne of the DOJ’s greatest challenges is the increasing organization of groups committing cybercrime as well as the increasing intersection of organized and hacking crime groups. International organized criminals are using computer networks to steal hundreds of millions of dollars from the\nIn other efforts to address the problem of organized crime in cyberspace, the DOJ has prioritized and targeted these groups and has employed resources across the government to address the factions. The resources include collecting and synthesizing law enforcement and intelligence information on these targets. In addition, the department continues to expand cooperative cybercrime operations efforts with foreign law enforcement agencies. The Law Enforcement Strategy to Combat International Organized Crime announced by the U.S. Attorney General in April 2008 specifically addresses the threats these groups pose in cyberspace, including the ability of groups to wreak havoc in locations far from their physical geographies.\nIn terms of cybercrime and cybersecurity, the cooperative strategy builds on years of foundational work by the DOJ in international organizations such as the G8, Interpol and the Council of Europe. “Our efforts in these groups involve both building the legal infrastructure so that criminals do not find safe havens in countries that do not have the laws to prosecute them, as well as building the operational infrastructure, ensuring that police and prosecutors are prepared to investigate and prosecute high-tech crime, and to cooperate with other countries in doing so,” Lynch explains.\nOperationally, prosecutors and law enforcement in the\nThese crimes being perpetrated in cyberspace and the methods of carrying them out force the DOJ to adapt its techniques both in apprehending and prosecuting the guilty parties. “It creates challenges in both respects,” Lynch says. Actually identifying the people responsible for computer crimes is difficult and requires the use of many resources from the department’s law enforcement partners. Finding the perpetrators of computer crimes can be a two-fold effort. First, law enforcement officials have to locate the cyber identity of the guilty party. Once that is complete, they still have to dig beyond the nickname to attribute the activities to an actual person.\nTo do this, officials follow both electronic and money trails, and they sometimes find the money trail to be more efficient to trace. Lynch explains that the DOJ and its partners must integrate the information they receive from the cyberside of an investigation with old-fashioned techniques such as forensic accounting and surveillance of people picking up money.\nJurisdiction also is often an issue in cybercrimes. Because cyberspace covers all geographies, criminals working together might be in different parts of one country or different countries. Crimes cross state, district and other boundaries, and Lynch acknowledges that working with state and local law enforcement, international partners and other agencies to identify different people involved with a criminal effort and to prosecute them successfully can create challenges.\nFor example, the first knowledge of an identity-theft ring might come from the New York Police Department when someone tries to pass a fake credit card. That individual may be linked to people in a foreign country or other parts of the\nWhile officials at the DOJ declined to comment on specific current or future cyberoperations, Lynch did explain that the department continues to evaluate the changing shape of criminal behavior. Any information discovered through those efforts will be rolled into the department’s future initiatives. He shares that officials always are looking at the threat and criminal landscape as well as working with their law enforcement partners to ensure appropriate reaction to threats. Other areas where the DOJ holds its cards close include specific technologies used in the detection and prosecution of criminals—these are open for discussion only when they come up in court—and research and development activities.\nThough the department does not comment directly on its research and development, it does work with partners across the public and private sector to ensure the acquisition of necessary capabilities. Beyond basic law enforcement technology, officials with the department must be aware of financial and banking systems operation, and they must share information they learn during investigations with the private sector so institutions can secure themselves better in the future. The DOJ works to ensure a healthy line of information among prosecutors, responders and the private sector. The agency strives to ensure it obtains threat and vulnerability information. That usually does not go directly to prosecutors, but to investigative agencies, underlining the need for robust information-sharing practices.\nInvestigators and prosecutors have a number of methods available to them when trying to track down cybercrimes. Statutes and standards in place enable law enforcement officers to request search warrants from a court to obtain necessary information from contract service providers. Basic customer information also can be obtained with a subpoena. The DOJ continues to examine the tools for investigating crimes on the network to ensure they keep up with current technologies. Officials also continually examine the balance between privacy and law enforcement needs.\nDespite the pervasive nature of cybercrime, Lynch says it is only one of several high-priority fields in the DOJ. The highest priority is terrorism, and much of the department’s work deals with national security issues. In many cases, cyberoperations become a part of other operations. Lynch explains that his office has consulted with law enforcement agencies, and the criminal division works closely with the national security division to ensure that best efforts are applied to investigating terrorist operations.\nLynch explains that cybercrime and cyberhacking are his focus area; however, information related to computer networks has effects across all types of criminal activities. The Child Protection and Obscenity Section of the DOJ, for example, has a large cyberfocus to address child pornography that is being traded online. Across the criminal landscape, perpetrators use computers to commit crimes, so Lynch’s division provides advice and assistance to help equip its partners with the information they need to investigate those misdeeds. Terrorism prosecutors in the National Security Division, for instance, need knowledge of computer operations and how to store information on computer systems legitimately to identify how groups are communicating using computer technologies.\nLynch shares that the military and intelligence communities focus on the cyberterrorism threat in partnership with the DOJ. State-sponsored computer crimes often come to the department as a law enforcement issue. When officials first see an intrusion into a network, they have to determine if the intruder is an individual criminal, a member of an organized crime group or someone working to disrupt national security. The DOJ works with the intelligence community and the FBI to ensure that information about the threat is appropriately shared and handed off to the right people at the right time in the process.\nLynch says that quantifying personal risk versus institutional risk is difficult. If investigators find someone’s personal information is being used for financial theft, they might not know immediately how criminals obtained that information. It could have been stolen when a person voluntarily offered the information in response to a phishing e-mail. Or, the information could have been collected through malicious software that records keystrokes on a computer system. Additionally, information could have been stolen from a bank, retailer or public database.\nAs cybercrime and cyberoperations continue to advance and change, the law has to adjust as well. Several recommendations for changes to the U.S. Code for computer crime were enacted by Congress in August 2008. Updates to the computer crime statute have occurred several times over the last decade to ensure criminality is covered adequately. Lynch explains that when looking at appropriate statutory approaches, the DOJ tries to avoid language that is too specific about technologies and methods so the statute can be used to prosecute new forms of criminality as they emerge. Language should remain neutral when describing crimes and how they are carried out, because otherwise when a new technology comes along, changes must be made to the laws and regulations.\nThe legislative process often moves more slowly than the criminals who are developing means for exploiting the system. To counter this effect, authors try to keep the legislative language as broad as possible to ensure officials can prosecute crimes. Lynch explains that much of what occurs is simply new ways of committing the same crime and that the department wants to ensure the public understands that is illegal.\nDepartment of Justice Computer Crime and Intellectual Property Section: www.usdoj.gov/criminal/cybercrime/index.html\nFederal Bureau of Investigation Cyber Investigations: www.fbi.gov/cyberinvest/cyberhome.htm\nLaw Enforcement Strategy to Combat International Organized Crime: www.usdoj.gov/ag/speeches/2008/ioc-strategy-public-overview.pdf", "label": 1}
{"text": "I am working on application that allows users to upload files containing company data and then share those files with a list of other users that have specific roles within the system.\nI want to encrypt the uploaded files to protect the data at rest while allowing the files to be shared by people who do not know the encryption password. The uploaded files are owned by the company that they belong too not by the user who uploads them.\n- When a user creates an account on the system a private-public key pair is generated for the user, the private key is stored in the database and is encrypted with the users clear text password, which is accessible during the login process. User passwords are salted, , stretched hashes so other than during login the app does not know the clear text of the users password.\n- When a user log's into the system successfully the encrypted user's private key is pulled from the database, decrypted and the private decrypted key is stored in the http session. I am assuming that while the decrypted private key is in RAM it going to be very hard but not impossible for a hacker to get a private key out of the RAM of a running process.\n- When a user uploads a file the following happens:\n- A secure random UUID is generated and used as the password to encrypt the uploaded file using AES 256\n- The generated UUID is then encrypted with the user's public key and stored in the database.\n- The system determines a list of every user that can access that file\n- For every user that can access the uploaded file the generated UUID is encrypted with that user's public key and the encrypted UUID is stored in the database.\n- When a file is being downloaded here is what the system does.\n- It locates the encrypted password for the file being downloaded\n- Decrypt the encrypted password using the user's private key\n- decrypt the file using the file password\n- return the clear text of the file to the user\nTo me this seems to be more secure than just storing the files on the server unecrypted a hacker who steals a copy of the data would not be able to read the files, since they would have to figure out the clear text passwords of the users before they could get at the user's private key.\nThe problem is dealing with password rests, since the users private key is encrypted with the users password if the user forgets their password and does a password reset they would loose their private key and thus access to the files they uploaded. Since I need to have a password rest feature in the application I am into a chicken and egg scenarios because how do I safely store the private keys of the users without end result being less secure than doing nothing?\nIs there any way to store private keys that are encrypted with a users clear text password and still have a way when resetting a password to preserve access to the users data?\nI am not a security expert and would prefer to use a known solution / library for this problem but I can't seem to find any so I have to make my own solution.", "label": 1}
{"text": "The Washington Post\n• Don't share passwords with anyone. Avoid using common words, phrases, or personal information. Update regularly.\n• Keep your operating system, browser, anti-virus and other critical software up to date. Security updates and patches are available free from major companies.\n• Verify the authenticity of requests from companies or individuals by contacting them directly. If you are being asked to provide personal information via email, you can independently contact the company directly to verify this request.\n• Pay close attention to the URLs of websites you visit. Malicious websites sometimes use a variation in common spelling or a different domain (for example, .com instead of .net) to deceive unsuspecting computer users.\n• Major data thefts can happen when attackers gain wireless access to an organization from a conference room or parking lot. Run wireless scanning detection to see unauthorized uses.\n• Restrict access and secure the personal information of employees and customers to prevent identity theft.\n• Run \"penetration testing\" on your own system to expose vulnerabilities.\n• Maintain a functional backup system.\n• Update software with constantly upgraded security.\n• Turn off the option to automatically download attachments.\n• Save and scan any attachments before opening them. If you have to open an attachment before you can verify the source, take the steps listed below.\n• Run anti-virus scans frequently.\nSocial media, videogames, chat sites\n• Limit the amount of personal information you post, such as your address. Watch what friends post about you to make sure you are comfortable sharing that information with strangers.\n• Use privacy and security settings that limit the information you share online.\n• Be wary of strangers and the huge amount of false information online.\n• Only access the Internet over a secure network. Maintain the same vigilance on your mobile device that you would on your computer.\n• Be suspicious of unknown links or requests sent through text message. Do not click on unknown links or answer strange questions sent to your mobile device, regardless of who the sender appears to be.\n• Download only trusted applications from reputable sources or marketplaces.\n• Talk to your children about Internet safety. Keep your family's computer in an open area and talk to your children about what they are doing online, including who they're talking to and what websites they're visiting.\n• Inform children of of online risks so that they are able to recognize suspicious activity and safeguard their personal information.\nSOURCE: Department of Homeland Security, SANs, CSIS", "label": 1}
{"text": "People who use laptops often carry around several gigabytes of information—some trivial and some confidential. Most users depend on their username and password combination to restrict access to this information, but administrators know that this protection is only minimal.\nThe obvious solution to protect data is to encrypt it. Companies such as Sunbelt Software and PC Guardian offer specialized encryption tools, and Windows 2000's Encrypting File System (EFS) offers built-in encryption. But a problem with EFS—compared with other encryption solutions—is that because EFS uses unique private keys, people who share a laptop or workspace can't share the encrypted data. When just one person uses a laptop, this restriction isn't a problem. But I recently worked with a company that needed to protect corporate data on laptops that rotated on a regular basis. The laptops had several data directories that contained confidential customer data. When an employee—let's say Bob—had to do field work, he updated the data and took the laptop with him. If the company used EFS as Microsoft intended, the next employee to use the laptop—Mary, for example—would need to wipe all the data from the disk, then recopy all the data to the laptop to ensure that the network files were encrypted with her key. The company didn't want this hassle. In addition, when a laptop with only one designated user changed ownership, the company didn't want to have to decrypt, then later reencrypt, data on the laptop with the new user's key to ensure that the user could access the information.\nTo meet the company's needs, I had to bend the EFS rules a bit. EFS uses an X.509 certificate to encrypt data. This certificate resides in a user's personal certificate store. When the user has no suitable key, EFS will try to request the key from an enterprise Certificate Authority (CA). If no enterprise CA exists, the workstation will create a self-signed certificate.\nTo share encrypted data, users must have the same key. But the problem is that certificates created in this manner are unique for each user.\nSimply sharing a key isn't difficult. You can use any key pair for which you've marked the private key exportable—including the self-signed certificates EFS can create. However, I wanted to use certificates that a company CA had issued so that the certificates would conform to the company's certificate policy. The company had a standalone root CA in place. (You can also use an enterprise root CA. With an enterprise root CA, you don't need to manually request a certificate, then have an administrator issue the certificate.) For information about installing a standalone root CA, see the Windows Help files.\nTo use a standalone root CA to create an EFS certificate, log on as Administrator and go to the Certificate Services Web site (http://servername/certsrv, where servername is the name of the server on which you installed your CA). This Web site installs automatically when you install Certificate Services. Select Request a certificate. Because the certificate enrollment form doesn't have a default option to request an EFS encryption key, you need to use the advanced request form.\nIn the advanced request form, enter all the requested information. In the name field, enter a name that will help you easily identify the certificate later. Be sure to correctly enter the Object Identifier (OID)—in this case, 126.96.36.199.4.1.3188.8.131.52—and select the option to mark the key as exportable. For a list of OIDs, see the Microsoft article \"Object IDs Associated with Microsoft Cryptography\" (http://support.microsoft.com/?kbid=287547). Finally, select a key size that matches the encryption strength you want.\nNext, you must use the Microsoft Management Console (MMC) Certification Authority snap-in to approve the key request. In the snap-in tree, expand your standalone CA's folder, then open the Pending Requests folder. This folder contains all the certificates that have been requested through the Certificate Services Web site but aren't yet approved. On a standalone root CA, each requested certificate must be approved before it's issued. Right-click the certificate you requested, and select All tasks, Issue. Next, go to the Certificate Services Web site and select Check on a pending Certificate. Select your certificate. On the next screen, click Install this certificate. You can now use the key to encrypt files.\nTo make the key available to other users, load the MMC Certificates snap-in and select the option for the snap-in to manage My user Account. Expand the Certificates Current User folder and select the Personal folder. The Personal folder is the user's personal certificate store. Right-click the appropriate encryption key (which you can identify by the name you entered on the request form) and export the key as a .pfx file (thus including the private key). Multiple users (e.g., Bob and Mary) can now double-click the .pfx file in Windows Explorer to import the file and therefore create encrypted files and access each other's encrypted files.\nWhen a user imports the .pfx file into his personal certificate store, the user needs to mark the file as nonexportable, which is the default. Only use this certificate on domain accounts. A thief could easily circumvent your local user account security: If he or she obtained your machine, he or she could use the private key in your personal store to decrypt your data. Make sure you store the .pfx file in a secure place.\nBy default, the EFS recovery agent role goes to the local administrator. However, you need to assign this role to a domain user (whom I'll call EFSrecoveryUser). Otherwise, a thief could log on as the local administrator to decrypt your data.\nTo create an EFS recovery agent, log on as EFSrecoveryUser and go to the Certificate Services Web site. Follow the same procedure as for the EFS certificate request, except you need to use OID 184.108.40.206.4.1.3220.127.116.11.1 to enroll an EFS recovery certificate. Again, enter a name that will help you easily identify the EFS recovery certificate.\nTo assign the EFS recovery agent to all the machines by using Active Directory (AD), you must export the EFS Recovery public key from EFSrecoveryUser's personal certificate store as a Distinguished Encoding Rules (DER) Encoded Binary X.509 file or a Base64 Encoded X.509 (.cer) file, then use a policy to publish the file. Log on as EFSrecoveryUser and open the Certificates snap-in. Open the Personal folder and right-click the appropriate key (which you can identify by the name you entered on the certificate request form) in the Details pane. Select All Tasks, Export, and select the export format and filename. To publish the public key, open the MMC Active Directory Users and Computers snap-in. Right-click the container where you store your computer accounts. This container is usually the Computers container directly under the root level—but since you can't assign policies to this container, you need to create an alternative container for computer accounts and move the accounts there. Select Properties and click the Group Policy tab. Click New and name your new policy EFS Recovery public key distribution. Then, click Edit. In the new Group Policy window that opens, expand the Machine Configuration, Windows Settings, Security Settings, and Public Key Policies folders. Right-click the Encrypted Data Recovery Agents folder and select Add. In the Add Recovery Agent wizard, click Next. Click Browse Folders and select the .cer file you exported. Click Next, Finish. You're now ready to share encrypted files and recover them if necessary.\nYou might notice that the imported certificate contains a warning that the certificate is from a nontrusted CA. You can use Group Policy to publish your CA as a trusted root CA. Go to the Certificate Services Web site and select Retrieve the CA certificate or certificate revocation list. Select your standalone root CA from the list, select DER encoded format, and click the Download CA certificate link. Save the file to disk. Next, use AD to publish the file. Open the Active Directory Users and Computers snap-in, and right-click the container you added earlier (i.e., where you added the EFS Recovery public key distribution Group Policy). Select Properties and click the Group Policy tab. Select the EFS Recovery public key distribution Group Policy, and click Edit. In the Group Policy window that opens, expand the Machine Configuration, Windows Settings, Security Settings, and Public Key Policies folders. Right-click the Trusted Root Certification Authorities folder and select All Tasks, Import. In the Certificate Import wizard, click Next. Enter the name of the file you downloaded from the Certificate Services Web site and click Next. Click Browse if possible; select the Trusted Root Certification Authorities certificate store and click Next. If Browse is shaded, click Next immediately. Click Finish.\nI admit that my encryption solution exploits the public key infrastructure (PKI) because private keys aren't intended for multiuser use. However, my solution will meet most companies' requirements.", "label": 1}
{"text": "How spammers make their money\nAccording to a US Treasury advisor, global cybercrime turned over more money than drug trafficking in 2004.\nSince then the major global malware epidemic has been putting greater wealth into the hands of criminals than ever before, and security experts have warned that organised crime syndicates have taken over much of the creation and exploitation of malware in circulation today. But how do they make their money and how much?\nSpammers send out millions of messages on behalf of online merchants who want to sell a product. If a spam recipient buys something, the spammer gets a percentage of the sale. For pharmaceuticals the commission can be as high as 50%, and research has shown that the response rate can be rather high. A good example is \"penis related spam\" which has a 5% click rate, meaning that 5% of the recipients actually open the spam mail and click on the link in the mail.\nThis means that spammers can make a massive amount of money. In July 2007, a retired spammer told PC World that at the peak of his power he pulled in $10,000 to $15,000 a week sending e-mails that promoted pills, porn and casinos.\nSpam is usually sent from networks of hacker-controlled computers, so-called botnets. Those machines are often consumer PCs infected with malicious software that a hacker can control. Groups of hacker specialize in creating botnets and make money renting them to spammers by the hour. The going rate for botnets has been from $300 to $700 per hour.\nBotnets are frequently used for so-called Denial of Service (DoS) attacks where hackers demand money to stop bombarding a specific website with requests, making it unavailable to its intended users. In the second half of 2006, an average of 5,213 DoS attacks were recorded per day. The US was the target of most attacks accounting for 52% of the worldwide total.\nIn 2010, Spain topped the bot ranking with 44.49% of all infected computers, according to net-security.org. Next in the ranking, although a long way behind with 14.41%, comes the United States, followed by Mexico (9.37%) and Brazil (4.81%).\nPhishers / Identity thieves\nAccording to Phishing Activity Trends Report released by APWG, Payment Services was the most targeted industry sector in 2010, enduring nearly 38%of detected attacks. Financial Services was second at 33% followed by Classifieds at 6.6%, though the latter exhibited the most rigorous growth of all sectors.\nThe United States is the top country hosting phishing sites, while China, the United Kingdom and Canada each take the second place in rotation.\nThe Swedish bank Nordea suffered one of the biggest publicly known phishing frauds in history. Over 8 million kronor ($1,200,000) disappeared in three months as a result of a tailor-made attack launched by Russian criminals. Reports indicated that 250 customers had become victims.", "label": 1}
{"text": "Editor's note: This is the fifth column in a series that challenges misconceptions about entrepreneurship. Myth: When measuring share of small business employment, the terms \"small firm\" and \"small establishment\" mean the same thing. Reality: To determine the share of employment small businesses account for in the U.S., I've always used data from the Office of Advocacy of the Small Business Administration which provides data produced by the U.S. Census on small business employment. The Census data on the SBA Web site shows that, in 2006 (the latest year available), 50.2% of U.S. employment lies in businesses with fewer than 500 employees. But recently I began looking at data from payroll provider Automatic Data Processing (ADP), which uses payroll data to track U.S. employment. ADP's data shows that the share of U.S. employment in businesses with less than 500 employees is more than 30 percentage points higher. In 2006, the ADP data showed that 82.9% of U.S. employment was in businesses with less than 500 employees. Huh? A 32.7% gap in the share of employment in businesses with fewer than 500 employees is much too large to be the result of just some slight difference in measurement. So something else must be going on. What's Behind the NumbersTo figure out what could explain the differences, I took a look at what the two sources are measuring. Both are comparing employment in businesses of less than 500 employees to the overall number of people employed and both exclude employment on farms. So it's not the size of the businesses or the exclusion of agriculture that's the cause of the difference. It's also not their labor force figures. The two sources' estimates of the number of people employed aren't that far off each other—119,917,000 for the SBA in 2006 and 113,475,000 for ADP in 2006. Even if we assume that every employee counted by the SBA and missed by ADP was employed in a large business, ADP's estimates would show that small businesses accounted for 77.2% of U.S. employment, whereas the Census/SBA estimates would show that small businesses only accounted for 50.2% of U.S. employment. The use of payroll data is also not the explanation. Census measures employment on the basis of payroll tax records, using employer identification numbers to identify businesses. ADP gets its estimates from \"aggregated and anonymous payroll data that represents approximately 400,000 of ADP's 500,000 U.S. business clients\" which are then extrapolated to the overall population. So both sources are using payroll data to measure employment. Different definitions of \"business\"The difference, it turns out, lies in how the two groups define \"businesses.\" ADP is measuring establishments, whereas Census is measuring firms. And small establishments, it turns out, are very different than small firms. According to the U.S. Census, \"an establishment is a single physical location where business transactions take place and for which payroll and employment records are kept.\" Firms are \"groups of one or more establishments under common ownership or control.\" Many more Americans work in establishments with fewer than 500 employees than in firms with fewer than 500 employees because a lot of establishments are part of large firms. For example, the Gap (GPS) outlet at your local mall is considered an establishment if it has fewer than 500 employees, but it is considered part of a firm if it has more than 500 employees. So if we measure employment at establishments with fewer than 500 employees, everyone working at the Gap outlets in different malls around the country would be considered employed in small establishments. However, if we measure employment at firms with fewer than 500 employees, everyone working at those different Gap outlets (as long as they weren't franchised) would be considered employed at large firms. The difference between the establishment and firm data is corroborated by looking at County Business Patterns, a Census Bureau effort to measure establishments. County Business Patterns shows small establishment employment numbers very similar to those shown by ADP. In 2007, the Census data shows 79.7% of employment was in establishments with fewer than 500 employees, while ADP shows that 83.1% of employment was in \"businesses\" with fewer than 500 employees. Skewed Employment StatisticsPutting the data together, it is clear that a lot of people work in small establishments that are part of large firms. Unfortunately, most people looking at the different sources of data don't know this, especially since the different sources are saying that they are measuring \"businesses.\" And, unless people look at both sources at the same time, they probably don't even know they are different. But the difference does make it difficult to discuss a basic fact about small business—the share of employment it accounts for. There are probably a number of reasons why measuring small establishments is problematic when seeking to understand small businesses. But here's just one: suppose policymakers want to put in place policies to increase small business employment if small business isn't accounting for an increasing share of total employment. If policymakers look at establishment data, they will get the wrong answer about what to do. The share of employment in small firms has been constant in recent years, while the share of employment in small establishments has been rising. So looking at establishment numbers would give policymakers the impression that small business is accounting for an increasing share of employment. A fact that turns out to be untrue.", "label": 1}
{"text": "During a recent talk to computer science students and faculty at Florida Gulf Coast University in Fort Myers, Fla., I closed with thoughts about ethics for people who create software. The inclusion of \"backdoors\" into a Web browser, the capability to track people who use cellphones, and the use of facial-recognition programs raise ethical issues. How much intrusion should consumers put up with, and what are the ethical responsibilities of the people who create these applications?\nDuring the question-and-answer session, several people asked me how much intrusion I will put up with. I answered, \"Not much.\" I refuse to show a photo ID when I make an in-person credit card purchase, I have no Facebook page, I rarely use \"affinity\" cards in stores, and my driver's license uses an ID number instead of my Social Security number. My family and I take other privacy measures, too.\nIn some situations, though, we cannot try to protect our privacy until we know someone has violated it. Suppose you slip and fall on spilled liquid in a grocery store and must sue the store chain to recover damages. Because you use an affinity card to get discounts, the store knows how much beer and wine you purchase, and threatens to reveal the quantities and dates at trial. Perhaps then the jury will think you had too much to drink and lost your balance. You thought your records of purchases remained private, and the store never told you otherwise.\nI have heard stories about insurance companies investigating food purchases to determine the type of diet an applicant follows and whether that diet includes a lot of fatty or high-calorie food. So you might get denied life insurance because your grocery purchases reveal an \"unhealthy\" lifestyle. The software doesn't know you buy two dozen donuts each Saturday for your kid's soccer team.\nThe process of gathering information about you and then using it for a purpose unknown to you raises ethical issues for the people who create such systems. Thus, programmers and software designers must revisit the ethics of their profession and consider them carefully.", "label": 1}
{"text": "The invention of LTFS has indeed made life a lot easier for most organizations which used to face problems with magnetic storage tapes. These tapes did not allow the users to store the related metadata in an easily accessible manner. But with the introduction of Linear Tape File System, the scenario has changed for the better.\nHow has LTFS Revolutionized Data Archiving?\n- This new technology from IBM has helped in reducing costs related to archiving and data storage.\n- Easy access is what has made this technology different from the older magnetic tapes storage system.\n- Data can be used and stored since you can access it across many different mediums and platforms.\n- The universal nature of the media makes it more attractive to users across the globe.\n- What's more is that you can use this as a USB drive. You just need an LTO-5 drive to upload the LTFS tape onto it. Then you can mount the tape on the file system.\n- It allows you to tag files using any text. This in turn enables you, as a user, to run searches which are much more intuitive. Hence, you can search the LTO-5 tape libraries as well as the drives more comprehensively.\n- This technology consumes less energy too.\n- The data is encrypted and hence it ensures better data security.\n- The data which is stored on an LTO-5 tape is automatically protected from issues like erasures and over-writings which are done with a malicious intent.\n- The simple drag and drop feature of files storage makes LTFS easy to use and apply.\nSo for active archiving which is low-cost and high on the reliable factor, LTFS is the way to go.\nActive Archiving is a combination process which blends tape as well as disk hardware to offer data storage with many important advantages. Active Archiving is a collaboration between both the hardware as well as the software vendors. LTFS is a preferred option with most manufacturers who are offering archiving solutions. Some of the best known names include IBM and HP.\nFor organizations which need large data storage facilities and are wary of issues like software malfunctions, illegal data access, natural calamities, which cause breakdown of storage systems and make data recovery impossible, Linear Tape File System has a solution. Companies which adopt this system will not have to worry about complex data management, large scale data storage or response times.\nTo install the Linear Tape File System, all you need is a drive firmware level to offer dual partitioning support. You also require a software which you can download; this software includes the run-time executable which helps you write files on an LTO-5 tape, in the LTFS format. This system is available for both Linux as well as MacOS.", "label": 1}
{"text": "The inner workings of United Nations telecommunications agencies aren't usually headline news. But then again, most U.N. confabs don't grapple with topics as slippery as Internet censorship, taxation, and privacy.\nA U.N. agency called the International Telecommunication Union has kicked off what has become a highly controversial summit this week in Dubai, capping over a year of closed-door negotiations over an international communications treaty that could have a direct impact on the Internet. The summit continues through the end of next week.\nIt's true, of course, that U.N. meetings often yield more rhetoric than substance. During a summit in Tunisia in 2005, for instance, Iran and African governments proclaimed that the Internet permits too much free speech, with Cuba's delegate announcing that Fidel Castro believed the time had come to create a new organization \"which administers this network of networks.\"\nThe difference here is that this meeting actually matters: the ITU event is aimed at rewriting a multilateral treaty that governs international communications traffic. It was last updated back in 1988, when home computers used dial-up modems, the Internet was primarily a university network, and Facebook CEO Mark Zuckerberg was a mere 4 years old.\nFor answers to some of your questions about the ITU summit, formally called the World Conference on International Telecommunications (WCIT, pronounced \"wicket\"), read on:\nQ: What's going to happen at the summit?\nIt's too early to say for sure. A series of ITU committees are meeting to draft proposals, with a deadline of December 12. On December 13, the final texts are presented. On December 14, the final treaty is signed.\nBut a coalition of Internet companies, nonprofit groups, and Western governments have taken extraordinary steps in the last few months to warn that proposals from nations with less than a sterling commitment to civil liberties -- among them Algeria, China, and Russia -- could do grave harm to the current free and open Internet.\nIt's no coincidence that some of those nations have geopolitical interests that are in conflict with those of the United States. The Dubai summit gives them an opportunity to depict the current way the Internet is governed as overly U.S.-dominated, and in need of significant changes, a proposal that many poorer nations support for reasons of their own.\nQ: What are some of the concerns?\nThey deal primarily with areas including free speech, taxation, privacy, and cybersecurity. There are secondary concerns about the ITU process itself: meetings are held behind closed doors, and key documents are withheld from public scrutiny -- the precise opposite of the way traditional Internet standards-setting works. A site called WCITLeaks.org, by two policy analysts at the free-market Mercatus Center at George Mason University in Arlington, Va., has sprung up to shine more light on what's happening in secret.\nVint Cerf, co-creator of the Internet's technical underpinnings, warned in a CNN op-ed last week that the ITU \"is the wrong place to make decisions about the future of the internet.\" That's because, he wrote: \"Only governments have a vote at the ITU. This includes governments that do not support a free and open internet. Engineers, companies, and people that build and use the Web have no vote.\"\nGoogle has organized a campaign to draw attention to the summit, saying some governments \"are trying to use a closed-door meeting in December to regulate the Internet.\" Advocacy groups Fight for the Future and AccessNow have launched WhatIsTheITU.org to warn that the ITU poses \"a risk to freedom of expression\" online.\nThe Internet Society has told the ITU (PDF) that some of the proposals that could be inserted in the treaty will harm \"the long term prospects of a global, open Internet.\" And Tim Berners-Lee, the father of the World Wide Web, warned this week about an ITU power grab, telling the BBC that: \"Countries that want to be able to block the Internet and give people within their country a 'secure' view of what's out there would use a treaty at the ITU as a mechanism to do that, and force other countries to fall into line with the blockages that they wanted to put in place.\"\nQ: What's the official position of the U.S. government?\nIn a sharply partisan U.S. election year, this has been a rare point of bipartisan accord: the House of Representatives unanimously approved a resolution this week aimed at sending a strong message to the ITU. It said, in part, that \"the consistent and unequivocal policy of the United States [is] to promote a global Internet free from government control.\"\nDuring a May 2012 House hearing, Democrats and Republicans alike warned that this month's summit could lead to a virtual takeover of the Internet if proposals from China, Russia, Iran, and Saudi Arabia are adopted.\n\"These are terrible ideas,\" Rep. Fred Upton, a Michigan Republican, said. They could allow \"governments to monitor and restrict content or impose economic costs upon international data flows,\" added Ambassador Philip Verveer, a deputy assistant secretary of state in the Obama administration.\nUnless the U.S. and its allies can block these proposals, they \"just might break the Internet by subjecting it to an international regulatory regime designed for old-fashioned telephone service,\" Rep. Greg Walden, an Oregon Republican said.\nThe U.S. could choose to refuse to sign and ratify the new treaty, of course. But that would create additional problems: U.S. network operators and their customers would still be expected to comply with new rules when dealing with foreign partners and governments, leading to a Balkanization of the Internet.\nQ: Are the U.S. and its allies in Europe and Canada having any luck at the summit?\nThe U.S., Europe, and Canada advanced a proposal in Dubai to limit the ITU's rules to only telecommunications providers, not Internet companies like Google and Facebook.\n\"We want to make sure [the ITU treaty] stays focused squarely on the telecom sector,\" said U.S. Ambassador Terry Kramer, according to Reuters. \"We thought we should deal with that up-front.\" Reuters reported this week that this effort stalled, but Kramer said a day later that the wire service report was inaccurate and progress was being made.\nThe ITU's own Web site describes the situation thus (keep reading for more on what Russia proposed):\nA proposal from the Russian Federation to include in the [treaty] a new provision on the Internet (new Article 3A) was supported and endorsed by Algeria. China and the United Arab Emirates also agreed that the Internet should be included... Canada, France, Europe, Sweden, and the United States do not support the proposal, and do not want it discussed [in the committees]. The Chairman of the Conference deferred the discussion on the proposed new provision to the next plenary, with informal discussions in the meantime.\nQ: What does the ITU say?\nFor their part, ITU officials have attempted to downplay criticism, saying that whatever is decided in Dubai is up to the member countries that are sending delegates to the summit. Hamadoun Touré, the ITU's secretary general, wrote in an opinion article in Wired last month:\nGovernments are looking for more effective frameworks to combat fraud and other crimes. Some commentators have suggested such frameworks could also legitimize censorship. However, Member States already have the right, as stated in Article 34 of the Constitution of ITU, to block any private telecommunications that appear \"dangerous to the security of the State or contrary to its laws, to public order or to decency.\"\nAn ITU spokesman, Paul Conneally, wrote a blog post that defended the organization against allegations of secrecy. \"At ITU, transparency is achieved at the national level, through national consultations in national languages,\" Conneally wrote. \"A process we believe more inclusive than simply posting an English language text online.\"\nAnother WCITLeaks-posted document (PDF) from a staff retreat in Geneva in September shows the ITU is highly sensitive to public criticism and the perception it's engaged in a power grab. The internal document says: \"Negative media coverage in the U.S. continues, and is now starting to appear in developing countries, and the Secretariat continues its effort to counter this.\" The ITU has also set up a blog that has denounced \"some of the deliberate misinformation that has been spread before the conference.\"\nIn addition, delegates to the summit agreed to a suggestion by Touré to, in the words of the ITU, \"issue a press release that would send a strong signal about the need to protect the right to freedom of expression.\"\nQ: Why choose to have this event in Dubai?\nIn part it's due to which nations are willing to host a summit. But the choice of the United Arab Emirates is an odd one: the nation has blocked Web sites arbitrarily, has fined journalists for exposing corruption in a state-run company, and has enacted a law allowing any Internet user to be imprisoned for \"opposition to Islam,\" \"insult to any religion recognized by the state\" or \"contravening family values and principles,\" according to Reporters Without Borders.\nFreedomHouse scores the UAE's press freedom laws as \"not free,\" citing \"restrictive legal provisions and widespread censorship, especially online.\"\nQ: What's going on with deep packet inspection?\nAt another Dubai summit that took place last month, the ITU adopted recommendations proposed by China that will help network providers target BitTorrent uploaders, detect trading of copyrighted MP3 files, and, critics say, accelerate Internet censorship in repressive nations.\nThe ITU adopted the confidential Y.2770 standard for deep packet inspection -- only members, not the public, currently have access to the document -- despite objections from Germany. It had warned the ITU must \"not standardize any technical means that would increase the exercise of control over telecommunications content, could be used to empower any censorship of content, or could impede the free flow of information and ideas.\"\nBecause Y.2770 is confidential, many details remain opaque. But a document (PDF) posted by a Korean standards body describes how network operators will be able to identify \"embedded digital watermarks in MP3 data,\" discover \"copyright protected audio content,\" find \"Jabber messages with Spanish text,\" or \"identify uploading BitTorrent users.\" Jabber is also known as XMPP, an instant messaging protocol.\nIn a joint blog post, Alissa Cooper and Emma Llansó from the Center for Democracy and Technology say that the U.N. agency \"barely acknowledges that DPI has privacy implications, let alone does it provide a thorough analysis of how the potential privacy threats associated with the technology might be mitigated.\"\nOne reason why deep packet inspection is so controversial is that it has been used by repressive regimes -- dozens of which are members of the ITU -- to conduct extensive surveillance against their own citizens.\nA Wall Street Journal report last year described how Amesys, a unit of French technology firm Bull SA, helped Moammar Gadhafi spy on his people. Boeing's Narus unit was in talks with Libya about controlling Skype, censoring YouTube, and blocking proxy servers, the report said.\nThe ITU said in a subsequent blog post that it has \"resolved some concerns regarding maintaining privacy after it was noted that the standard deals with the identification of the application used rather than the inspection of users content.\"\nQ: And taxes or other fees for Web companies and their users?\nIn June, a proposal to the ITU was leaked that would target the largest Web content providers, including Google, Facebook, Apple, and Netflix, and possibly cripple their ability to reach users in developing nations. It was drafted by the European Telecommunications Network Operators Association, or ETNO, a Brussels-based lobby group representing companies in 35 nations that wants the ITU to mandate these fees.\nETNO refers to it as the \"principle of sending party network pays\" -- an idea borrowed from the system set up to handle payments for international phone calls, where the recipient's network set the per minute price. A sender-pays framework, however, could prompt U.S.-based Internet services to reject connections from users in developing countries, who would become unaffordably expensive to communicate with.\nLuigi Gambardella, chairman of the ETNO's executive board, told CNET in an interview in August that the principle of sender-party-pays for Internet traffic was a fair solution. (Not-so-coincidentally, a lot of Internet traffic is sent to Europe from the United States.)\n\"We believe that this situation is putting at risk our capacity to invest,\" Gambardella said. \"We need to rethink together and to establish a new balance.\"\nWhile this is the first time this proposal been advanced to the ITU, European network providers and phone companies have been bitterly complaining about U.S. content companies for some time. France Telecom, Telecom Italia, and Vodafone Group want to \"require content providers like Apple and Google to pay fees linked to usage,\" Bloomberg reported in December 2011.\nQ: What's the history of the U.N., the ITU, and the Internet?\nThis isn't exactly the first time that the U.N. or its agencies wanted to expand their influence over the Internet. At a 2004 summit at the U.N.'s headquarters in New York, U.N. Secretary General Kofi Annan criticized the current system through which Internet standards are set and domain names are handled -- that would be the Internet Corporation for Assigned Names and Numbers, or ICANN, and the Internet Engineering Task Force -- and delegates from Cuba, Ghana, Bolivia and Venezula objected to what they said was too much control of the process by the U.S. government and its allies.\nTwo years later, at another U.N. summit in Athens, then-ITU Secretary General Yoshio Utsumi criticized the current ICANN-dominated process, stressing that poorer nations are dissatisfied and are hoping to erode U.S. influence. \"No matter what technical experts argue is the best system, no matter what self-serving justifications are made that this is the only possible way to do things, there are no systems or technologies that can eternally claim they are the best,\" Utsumi said.\nIn an interview with CNET at the time, Houlin Zhao, director of the ITU's Telecommunication Standardization Bureau, said: \"The ITU is trying to ensure its value. Any public network of communications is naturally of interest to ITU. ITU has a lot of expertise and a lot of experience.\"\nIn 2008, CNET disclosed that the ITU was quietly drafting technical standards, proposed by the Chinese government, to define methods of tracing the original source of Internet communications and potentially curbing the ability of users to remain anonymous. A leaked document showed the trace-back mechanism was designed to be used by a government that \"tries to identify the source of the negative articles\" published by an anonymous author.\nIn 1999, a report from the United Nations Development Program proposed Internet e-mail taxes to help developing nations, suggesting that an appropriate amount would be the equivalent of one penny on every 100 e-mails that an individual might send. But the agency backed away from the idea a few days later.\nAnd in 2010, the U.N.'s World Health Organization contemplated, but did not agree on, a \"bit tax\" on Internet traffic.\nQ: What has Russia proposed?\nLast fall, China, Russia, Tajikistan, and Uzbekistan submitted a proposal to the U.N. asking for the creation of an \"International Code of Conduct for Information Security.\" It called for international cooperation in controlling \"dissemination of information\" that \"undermines other countries' political, economic, and social stability\" -- which appears to mean censoring political speech appearing on Web pages, social network posts, and so on.\nAt the time, Russian Prime Minister Vladimir Putin described the proposal as handing the U.N. \"international control of the Internet.\"\nRecently leaked documents show that Russia hasn't moderated its position much since. Russia proposed that the U.N. take over the responsibilities of the Internet Society and ICANN, which manages domain names and addresses. But after criticism of the proposal, which was first reported by CNET, Russia moderated its position.", "label": 1}
{"text": "University information resources are strategic assets, which as property of the State of Texas, must be managed as valuable state resources. The integrity and continued operation of University information resources are critical to the operation of the University. Malicious code can disrupt normal operation of University information resources. This procedure is intended to provide information to University information resource administrators and users to improve the resistance to, detection of, and recovery from the effects of malicious code.\nThis procedure applies to all University network information resources. The purpose of the implementation of this procedure is to provide a set of measures that will mitigate information security risks associated with Malicious Code. The intended audience for this procedure includes all owners, managers, system administrators, and users of University information resources.\nInformation Resources (IR): The procedures, equipment, and software that are designed, employed, operated, and maintained to collect, record, process, store, retrieve, display, and transmit information or data.\nMalicious code: Software that is designed to operate in a manner that is inconsistent with the intentions of the user and which typically results in annoyance or damage to the user's information systems. Examples of such software include:\nViruses: Pieces of code that attach to host programs and propagate when an infected program is executed.\nWorms: Particular to networked computers to carry out preprogrammed attacks that jump across the network.\nTrojan Horses: Hide malicious code inside a host program that appears to do something useful.\nAttack scripts: These may be written in common languages such as Java or ActiveX to exploit weaknesses in programs; usually intended to cross network platforms.\nSpyware:Software planted on your system to capture and reveal information to someone outside your system. It can do such things as capture keystrokes while typing passwords, read and track email, record the sites visited, pass along credit card numbers, and so on. It can be planted by Trojan horses or viruses, installed as part of freeware or shareware programs that are downloaded and executed, installed by an employer to track computer usage, or even planted by advertising agencies to as in feeding you targeted ads.\nOwner of an Information Resource: an entity responsible for:\na business function (Department Head)\ndetermining controls and access to information resources\n4. Prevention and Detection:\nFor each computer connected to the University network, security updates from the manufacturer of the appropriate operating system, and/or application software, must be kept current (e.g., patched and updated).\nWhere feasible, personal firewall software or hardware shall be installed to aid in the prevention of malicious code attacks/infections.\nEmail attachments and shared files of unknown integrity shall be scanned for malicious code before they are opened or accessed.\nDiskettes and mass storage devices will be scanned for malicious code before accessing any data on the media.\nSoftware to safeguard against malicious code (e.g., antivirus, anti spyware, etc.) shall be installed and functioning on susceptible information resources that have access to the University network.\nSoftware safeguarding information resources against malicious code shall not be disabled or bypassed by end-users.\nThe settings for software that protect information resources against malicious code should not be altered in a manner that will reduce the effectiveness of the software.\nThe automatic update frequency of software that safeguards against malicious code shall not be disabled, altered or bypassed by end-users to reduce the frequency of updates.\n5. Response and Recovery:\nAll reasonable efforts shall be made to contain the effects of any system that is infected with a virus or other malicious code. This may include disconnecting systems from the network or disabling email accounts.\nIf malicious code is discovered, or believed to exist, an attempt should be made to remove or quarantine the malicious code using current antivirus or other control software.\nIf malicious code cannot be automatically quarantined or removed by antivirus software, the system shall be disconnected from the network to prevent further possible propagation of the malicious code or other harmful impact. The presence of the malicious code shall be reported to Information Technology Services by contacting the Helpdesk at 936-261-2525, so that they may take appropriate actions in removing the malicious code and protecting other systems.\nPersonnel responding to the incident should have or be given the necessary access privileges and authority to afford the necessary measures to contain/remove the infection.\nIf possible, identify the source of the infection and the type of infection to prevent recurrence.\nAny removable media (including diskettes, mass storage cards, etc.) recently used on an infected machine shall be scanned prior to opening and/or executing any files contained therein.\nInformation Technology Services personnel should thoroughly document the incident noting the source of the malicious code (if possible), resources impacted, and damage or disruption to information resources, and bring the matter to the attention of PVAMU administration.\n2003-2009 PRAIRIE VIEW A & M UNIVERSITY - ALL RIGHTS RESERVED\nP.O. Box 519 - Prairie View, Texas - 77446-0519\nFM 1098 Rd & University Dr, Prairie View, TX 77446\nUniversity Operator: (936) 261-3311\nBest viewed with IE 7.x+ or FireFox 3.x+", "label": 1}
{"text": "Lyme disease surveillance and available data\nLyme disease has been a nationally notifiable condition in the United States since 1991. Reports of Lyme disease are collected and verified by state and local health departments in accordance with their legal mandate and surveillance practices. After removal of personal identifiers, selected information on cases is shared with CDC through the National Notifiable Diseases Surveillance System (NNDSS). For more information on NNDSS, see http://www.cdc.gov/osels/ph_surveillance/nndss/nndsshis.htm. Policies regarding case definitions, reporting, confidentiality, and data release are determined by states and territories under the auspices of the Council of State and Territorial Epidemiologists (CSTE). Surveillance data have a number of limitations that need to be considered in the analysis, interpretation, and reporting of results. Additionally, answers to frequently asked questions related to surveillance are available.\nLimitations of surveillance data\n- Under-reporting and misclassification are features common to all surveillance systems. Not every case of Lyme disease is reported to CDC, and some cases that are reported may be due to another cause. Under-reporting is more likely to occur in highly endemic areas, whereas over-reporting is more likely to occur in non-endemic areas.\n- Surveillance data are subject to each state's abilities to capture and classify cases, which are dependent upon budget and personnel and varies not only between states, but also from year to year within a given state. Consequently, a sudden or marked change in reported cases does not necessarily represent a true change in disease incidence, and should not be construed as such without knowledge of that state’s historical surveillance practices.\n- Surveillance data is captured by county of residence, not county of exposure.\n- States may close their annual surveillance dataset at a different time than CDC. Thus, the final case counts published by CDC may not exactly match numbers published by each state agency for a given year.\n- Following its implementation in 1991, the national surveillance case definition for Lyme disease was modified in 1996 and again in 2008. Changes were generally minor but may have had some impact on surveillance and must be considered when attempting to interpret trends. Case definitions for each period are available.\nPublicly available surveillance data\n- Selected Lyme disease statistics, tables and charts are available on the CDC Lyme disease website.\n- Provisional case counts for states and territories are published weekly in CDC’s Morbidity and Mortality Weekly Report (MMWR), Notifiable Diseases and Mortality Table II (available at: http://www.cdc.gov/mmwr/mmwr_wk/wk_cvol.html). Provisional data are subject to change. Cumulative totals for the current and previous year are presented in the table; however, due to variable reporting delays these numbers cannot be compared directly to determine whether cases are higher or lower than the previous year.\n- Final case counts are published after the year is over and all states and territories have verified their data. A table with the final numbers is published in MMWR Weekly Report in early August of the following year. A more detailed presentation of the data, complete with historical tables, in published in the annual MMWR Summary of Notifiable Diseases (available at http://www.cdc.gov/mmwr/mmwr_nd/).\n- To facilitate the public health and research community’s access to NNDSS data on Lyme disease, CDC has developed a public use dataset. Based on reports submitted to CDC, this dataset provides the number of reported cases by county for the years 1992-2006, in three 5-year intervals. County tabulation is by American National Standard Institute (ANSI) [formerly Federal Information Processing Standard (FIPS) codes]. ANSI county codes ending in “999” represent “unknown” county of residence within each state. More recent county-level case counts are not publicly available at this time. County-level Lyme disease data from 1992-2006 [Excel CSV - 113KB] ––Right–click the link and select \"save\".", "label": 1}
{"text": "Knowledge of application context is used routinely in mobile applications—for example sensing a user's context (e.g. location and physical actions, time, etc), reducing network usage during periods of inactivity and designing for users. But how does this idea transfer to the server?\nI almost called this environmental awareness, but didn't want to cause confusion with discussions about network/server environments. By 'situational awareness' I mean awareness of factors external to the application that might be used to affect its behaviour. In my talk this week about application intrusion detection, I will be discussing how an aspect such as the general risk level to an organisation/application might be used to alter an application's actions (e.g. amount of logging, attack detection thresholds). But this awareness, can be used beyond attacker detection and response.\nInformation is knowledge and additional awareness of external factors can be used to control changes to the application. An adaptive application can learn change in response to outside factors. And no, I don't mean displaying an intrusive and annoying paperclip that says \"It looks like you're writing a letter\". Apart from standard functionality the user sees, some ways your application may already be doing this are:\n- customising content based on:\n- geo-location information\n- user preferences\n- device type (e.g. mobile), browser and screen resolution\n- typical user behaviour\n- implementation of additional delays for failed attempts at authentication\n- use of reputation-based systems\n- displaying the number/identities of active/logged-in users\n- detecting usage of the application by users from a different location than they had used previously (e.g. IP address)\n- showing advertising based on users' behavioural characteristics.\nBut what else can be done? I remember chatting with someone during an unexpected period of severe weather which had disrupted travel in south-east England one morning. They had explained that in situations like this when their call centre was under staffed, they had procedures in place to reduce the length of each customer call, by shortening their own scripts taking out offers for helping with anything else and cross-selling/up-selling. The dialogue script was adapted to the situation. A web application could respond in a similar way during increasing, and higher periods of demand, to increase availability:\n- switch to more static content (e.g. change the home page to static HTML rather than a scripted dynamic page)\n- swap to lower bandwidth assets (e.g. display photographs instead of videos, use lower resolution photos)\n- use third-party servers for some content (e.g. video on YouTube)\n- reduce the size of pages and number of page elements by dropping out non-core material (e.g. promotional items, banners)\n- increase caching\n- delay non-core server intensive activities (e.g. management report generation)\n- provide links to printable forms to divert some or all users of a particular online service.\nSimilarly, if a local (e.g. dynamic PDF creation or chart generation), back-office (e.g. data archive) or third-party service (e.g. payment authorisation, address look-up) is detected as running slowly or has become unavailable, some of the following may be possible:\n- switch to cached data\n- add a queue to access the function\n- slow down the speed at which users can undertake the function\n- offer alternative (quicker) ways to complete the transaction\n- take the service offline, but offer to email users back when it is available again.\nSimilar changes could occur in advance of, or during, known scheduled application maintenance periods:\n- advanced warning notices to users\n- timed count-down to function or application shutdown\n- preventing users beginning new tasks which might not be able to be completed before the shutdown\n- ability for users to request notification that the service is back up.\nThe important thing (remember \"clippy\") is not to change the user experience too noticeably, and where there is a significant change (e.g. download the form instead of doing it online), provide a time-stamped explanation of the change and reasons.\nThese measures all bring complexity, and it is important they do not introduce additional vulnerabilities to the application. The problems are quite likely to be in authentication, authorisation and session management and need to be identified during security specification and verification processes. The effect on data integrity, including accuracy, also needs to be considered. But the measures are worth considering where the alternative is additional standby staff and increased usage of other channels.\nPosted on: 13 July 2010 at 09:30 hrs", "label": 1}
{"text": "The purpose of this article is not to teach you how to hack sites, but to show you some scenarios that may reveal to you how vulnerable your existing site may be, or will hopefully help you prevent any future sites from having these vulnerabilities.\nClosely related to hidden field manipulation, buffer overruns are engineered in a similar fashion; any text input field with a maxchar=n property can be used to potentially shut down the server. The source code can be accessed, and the maxchar property removed. The hacker then enters, say, 10,000 ones and submits the form. What happens next? The server shuts down, taking your business with it. A semi-secure solution to this would again be to encrypt any HTML form source. A better solution would be to allocate memory dynamically, therefore not presetting the memory buffer to a certain size, or writing a function that checks the length of the input before passing the results to the server. If the input exceeds the memory allocation, simply pass back a NULL value.\nA simple, yet effective trick in deterring hackers is to configure your web server to hand out customised error 404 pages with a status of 200 when a resource is not found. Most genuine users will not even notice, and a hacker using software to scan for available resources will think they have stumbled across a gold mine. When the hacker goes to check, they will find that they have been duped and hopefully see examining your site further as a waste of time. This could be seen as hacking hackers or the hacker becoming the hacked...\nYou could take this one step further and use an old UNIX application called netcat to crash anyone who attempts to hack your site. Netcat makes and accepts TCP connections, but it can be used by a hacker for many things, including obtaining remote access to a shell, port-scanning and even hi-jacking services and bypassing firewalls. It can also be used to monitor ports and flood suspicious requests, similar to a buffer over-run, by using it to pretend you are running a service that you are not and using the 'yes' command when someone tries to exploit that service. Netcat is an extremely powerful application in itself and is usually part of any self-respecting hackers' tool-kit. Morally, you could look at this as hitting them back first.\nI hope that I have drawn your attention to some of the more basic but often overlooked entry-points that a hacker may use to gain entry to your web applications, and highlighted the need for basic auditing of the security enforcement of your site.\nThis article is not intended to be a complete solution for defense against hacking, but more the starting point for your considerations. No site is completely hack-proof, but there are few sites that really need to be. As a web developer ,your main security concern is first to assess how much security you will actually need. The more secure you need to be, the more your aims will move toward hiring the services of a professional security solution.", "label": 1}
{"text": "Computer security researchers say that the GSM phones used by the majority of the world's mobile phone users can be listened in on with just a few thousand dollars worth of hardware and some free open-source tools.\nIn a presentation given at the Chaos Communication Conference in Berlin, researcher Karsten Nohl said that he had compiled 2 terabytes worth of data - cracking tables that can be used as a kind of reverse phone-book to determine the encryption key used to secure a GSM (Global System for Mobile communications) telephone conversation or text message.\nWhile Nohl stopped short of releasing a GSM-cracking device - that would be illegal in many countries - he said he divulged information that has been common knowledge in academic circles and made it \"practically useable.\"\nIntercepting mobile phone calls is illegal in many countries, but GSM-cracking tools are already available to law enforcement. Knoll believes that criminals are probably using them too. \"We have just basically copied what you can already buy in a commercial product,\" he said.\nThe flaw lies in the 20-year-old encryption algorithm used by most carriers. It's a 64-bit cipher called A5/1 and it is simply too weak, according to Nohl. Using his tables, antennas, specialised software, and $30,000 worth of computing hardware to break the cipher, someone can crack the GSM encryption in real time and listen in on calls, he said. If the attacker was willing to wait a few minutes to record and crack the call, the total cost would be just a few thousand dollars, he said.\nThere are about 3.5 billion GSM phones worldwide, making up about 80 percent of the mobile market, according to data from the GSM Alliance, a communications industry association representing operators and phone-makers.\nBecause even discussing wiretapping tools can be illegal, researchers have steered clear of this type of work. But after consulting lawyers with the Electronic Frontier Foundation, Nohl and his collaborators set upon a way of conclusively disclosing the flaws in the GSM system without - they believe - breaking the law.\nLast August they kicked off an open-source project to create the cracking tables - something that would take a decent gaming computer about 10 years to compute - and they have shown which open-source tools could be used to intercept messages, but they have stopped short of designing a device to intercept the messages. This is, however, something that a technically sophisticated hacker could figure out, Nohl said.\n\"I don't think anything we did was illegal,\" Knoll said. However, \"using what we produced in certain circumstances would be illegal,\" he added.\nTwo years ago, hackers David Hulton and Steve Miller embarked on a very similar project, but they did not complete their work, Nohl said.\nKnoll, who uses a BlackBerry GSM phone himself, says that the point of the research is to make it clear that encrypted GSM calls can be listened into. \"I certainly use my phone differently than before, trying to keep confidential calls on encrypted lines instead,\" he said.\nA spokeswoman with the GSM Association said that her group would be looking into the researchers' claims in the coming days and stressed that any type of mobile-phone eavesdropping would be illegal in many countries. \"This isn't something that we take lightly,\" she said in an e-mail interview.\nThe group has developed a next-generation standard called A5/3 that is considered much more secure. That's the standard that is used on 3G networks to carry internet traffic.", "label": 1}
{"text": "Jun 27, 2008 (08:06 PM EDT)\nA Tipping Point For The Trusted Platform Module?\nRead the Original Article at InformationWeek\nThe Trusted Platform Module is a hardware component built into PCs and laptops. It's designed to securely generate and store encryption keys, passwords, and digital certificates. The Trusted Platform Module, or TPM, can be used for a variety of purposes, such as encrypting files and folders and authenticating users, applications, and computers.\nAccording to IDC, nearly 250 million PCs will have shipped with TPM hardware by 2009. In theory, this level of deployment means the module should be the foundation for a variety of useful applications widely embraced by enterprises and individual users. In reality, there are few apps that take advantage of TPM. A major reason is the complexity of managing TPM itself and encryption keys; another may be a lack of awareness of the module and its capabilities.\nThe Trusted Platform Module is developed by the Trusted Computing Group, a nonprofit organization that designs and develops open specifications for trusted computing. It has approximately 170 members. The module was designed to help organizations protect sensitive information and enable strong authentication for business use and e-commerce transactions. TPM's hardware-based key-generation capabilities make it very secure against many common attacks.\nWe'll examine why TPM adoption hasn't matched physical deployments and look at the prospects for wider use of the technology.\nA BRIEF HISTORY OF TPM\nUnfortunately for the Trusted Computing Group, Palladium generated a firestorm of negative feedback. Critics argued that Palladium was primarily designed to take control away from the owner of a computer, and privacy rights advocates were riled up over the fact that it was difficult for TPM to allow sufficiently anonymous verifiable transactions. Fortunately, the 1.2 version of the specification has significantly improved the ability for TPM to be used in a way that maintains privacy while still achieving security.\nThe primary criticism was that one of the stated design goals of TPM is that it could be used to create supposedly unhackable digital rights management systems. DRM technology aims to prevent users from copying and sharing digital content, such as music and movies. Many in the technology community argue that DRM restricts their fair-use rights and pits users against their own computers.\n(click image for larger view)\nLOCK IT UP\nWhile a Trusted Platform Module chip could be applied to DRM, it's far from the most common use-case of the technology today. More important in the TPM ecosystem are the other possibilities it affords. The Trusted Computing Group encompasses a variety of platforms, including working groups dedicated to Authentication, Mobile, Software Stack, Storage, Trusted Network Connect, and Virtualized Platform.\nThe most widespread use of TPM today is Microsoft's BitLocker drive encryption technology. BitLocker can operate with or without the TPM hardware, though the recommended and most secure method of operation requires a 1.2 TPM chip, and it's able to offer significantly more security than non-TPM modes of operation. That's because the keys are secured in the hardware rather than in software, making them harder to tamper with or steal.\nAlso teaming up with TPM for data encryption are hard drives capable of handling data encryption and decryption internally, such as Seagate Momentus FDE.2 drives. This is one of the few full-disk encryption architectures that would not be vulnerable to the recently publicized \"cold-boot\" attacks that are able to extract the contents of a computer's memory after it's been powered off and seek out encryption keys.\nThe Web is one reason the Trusted Computing Group repurposed itself from the original goals of Trusted Computing Platform Alliance back in 2003. Instead of creating a platform for trusted PC computing, it wanted to be able to integrate the same techniques across a wide variety of uses and platforms.\nOf course, integrating TPM into the authentication process for a Web application negates one of the values of Web apps in the first place--they're accessible from any Internet-enabled PC.\nThis problem may be solved by cell phones, which could act as a soft token to authenticate users. For example, if a user wants to access an online banking application from a strange machine, the bank can send a one-time password to the user's phone. The user would enter this password into the banking app. Meanwhile, the entire process is secured against tampering by TPM's hardware-enabled trusted connection from the server to the PC being used.\nThis leads directly into the weak spot for TPM--key management. Managing the keys protected by a TPM chip is almost identical to any other encryption platform. Not only must those TPM-generated keys support the usual enterprise key management features--such as enrollment and revocation, and key recovery in case of lost PINs--but there are issues unique to TPM, such as maintaining system state when upgrading, as changes may upset the ability of the module to produce a valid key for an encrypted system.\nSome standalone software tools already are available for IT to manage the Trusted Platform Module. For example, Microsoft offers some free TPM management tools. And a large number of OEMs that manufacture PCs and laptops ship Wave Systems' Embassy Trust Suite, which is capable of providing a variety of services to maintain the module itself. However, more powerful management capabilities might require an upgrade to one of Wave's enterprise-level products.\nEven without an enterprise management platform, however, some organizations may be able to take advantage of the number of TPM chips deployed in their environment right now. The Trusted Computing Group Web site offers a series of white papers on using TPM with existing enterprise systems such as wireless networks, VPNs, and network access control.\nWhile it's important to consider the extra management effort involved, it's definitely worth examining what you can use for free with the built-in tools along with the module.\nTPM: A Matter Of Trust", "label": 1}
{"text": "Freedom of Information Act Gallery 2010\nIn recognition of Sunshine Week\nMarch 15-19, 2010\nThe Freedom of Information Act establishes a legal right for individuals to obtain records in the possession of government agencies. The FOIA is critical for the functioning of democratic government because it helps ensure that the public is fully informed about matters of public concern. The FOIA has helped uncover fraud, waste, and abuse in the federal government. It has become particularly important in the last few years as the government has tried to keep more of its activities secret.\nA hallmark of the new surveillance measures proposed by various government agencies is their disregard for public accountability. As the government seeks to expand its power to collect information about individuals, it increasingly hides that surveillance power behind a wall of secrecy. Congress has long recognized this tendency in the Executive Branch, and sought to limit government secrecy by creating legal obligations of openness under the FOIA and the Privacy Act of 1974. EPIC has used these open government laws aggressively to enable public oversight of potentially invasive surveillance initiatives.\nPublic access through the FOIA not only allows for a more informed public debate over new surveillance proposals, but also ensures accountability for government officials. Public debate fosters the development of more robust security systems and leads to solutions that better respect the nation's democratic values. EPIC's FOIA litigation activity over the past year has resulted in disclosure of information about several government surveillance programs. The EPIC FOIA Gallery highlights some of the most significant documents we obtained in the past year.\nThrough Freedom of Information Act litigation, EPIC obtained contracts and technical specifications for body scanners, machines used to perform digital strip searches of air travelers. The documents include 250 pages of technical data. They reveal that scanners can record, store, and transmit images of Americans stripped naked. This contradicts assurances made by the Transportation Security Administration. The TSA withheld additional records sought by EPIC, including full-resolution body scanner images and documents detailing traveler complaints. EPIC's lawsuit for additional records remains pending.\nResponding to an EPIC FOIA lawsuit, the Department of Homeland Security and the Transportation Security Administration released documents about body scanners in US airports that included complaints from travelers who went through the devices. Travelers reported that they were not told about a pat down alternative or that they were going to be subject to a body scan by TSA officials. Travelers also expressed concern about radiation risks to pregnant women, and the image capture of young children without clothes.\nFollowing a FOIA request, EPIC obtained documents that revealed the Defense Department canceled a contract with Echometrix following an EPIC complaint to the FTC in 2009. Echometrix produces parental control software that monitors children’s online activity. Echometrix analyzes the information collected from children and sells the data to third parties for market-intelligence research. The EPIC complaint alleges that Echometrix engages in unfair and deceptive trade practices by representing that the software protects children online while simultaneously collecting and disclosing information about children’s online activity. Subsequently, the Army and Air Force Exchange Service pulled My Military Sentry, which collects data for marketing purposes, from its online store. The FTC has not yet pursued action against the software company.\nIn response to EPIC’s April 2009 FOIA request, the General Services Administration released several contracts between the federal government and web 2.0 companies. The GSA Agreement with Google exempts the company from privacy requirements, stating: “to the extent any rules or guidelines exist prohibiting the use of persistent cookies in connection with Provider Content applies to Google, Provider expressly waives those rules or guidelines as they may apply to Google.” The documents also include agreements with Blip.tv, Blist, Google (YouTube), Yahoo (Flickr), and MySpace. EPIC also obtained amendments to agreements with Facebook, Slideshare.net, Vimeo.com, and AddThis.com. Some of the agreements permit companies to track users of government web sites for advertising purposes.\nIn September 2009, EPIC and the ACLU filed court papers in Washington, DC asking a federal judge now reviewing an open government case to consider the publication of the Inspectors General Unclassified Report on President Bush's warrantless wiretapping program. EPIC is seeking the release of the relevant legal memos relating to the program, but the government contends that the entire matter is secret. However, the Inspector General's report, which is widely available, discusses several of the memos at issue in the case. EPIC filed the original request for the legal memos in December 2005 after the New York Times first reported on the warrantless wiretapping program. The case is EPIC v. Dep't of Justice.\nIn response to a January 2009 FOIA request to the Department of Homeland Security, EPIC obtained documents revealing that the DHS spent $3 million on a marketing and advertising campaign to promote its E-Verify system. The DHS contracted with Maya Advertising and Communications to launch a campaign “to increase voluntary adoption of the [Employment Eligibility Verification Program] for all sectors of US employers.” In 2007, EPIC testified in Congress that the employment eligibility database is filled with errors and warned that determination errors are likely. Errors can seriously harm American workers, because they can lead to American citizens losing their jobs. EPIC has documented how the use of such a database imposes problems for U.S. workers.", "label": 1}
{"text": "The public should be prepared for more inconclusive BSE, or mad cow disease, reports because of expanded testing launched June 1 by the USDA.\nDavid Smith and David Steffen, University of Nebraska veterinary scientists, say the larger sampling of animals in the USDA's expanded BSE surveillance testing will result in more inconclusive findings from initial rapid screening. As of Tuesday June 29, 8,585 cattle had been screened since June 1.\n\"Anytime you expand testing, you are bound to have more tests that are inconclusive,\" Smith says.\nOn June 25, USDA announced that an animal produced an inconclusive instead of negative result in initial screening for bovine spongiform encephalopathy, or BSE. Late on June 29, USDA announced a second inconclusive result from initial screening. In both instances, further tests are being conducted at USDA's National Veterinary Laboratory in Ames, Iowa.\nCattle futures prices fell sharply June 28 in response to the previous Friday's announcement, but rebounded somewhat on June 29.\nFed cattle prices dropped from $90 to $75 shortly after the nation's only confirmed case of BSE was detected in a dairy cow in Washington in late December, says Darrell Mark, a university livestock marketing specialist. Since then, prices have been rising steadily and are up 20% from early year lows.\n\"The industry was expecting approximately one inconclusive test per 10,000 samples, and after one month and slightly less than that number tested, having two inconclusive tests may indicate we'll see more of these than expected,\" Mark says. \"This will increase market volatility and cause consumers to question the BSE surveillance program.\" But the surveillance program is working as it was designed to, he adds.\nSmith says the public and the markets need to become accustomed to the testing process and the related announcements that will be forthcoming. After the December incident, the USDA was criticized for not disclosing the incident sooner.\nSteffen adds, \"If there is a false positive for every 1,000 tests, then the USDA could expect hundreds of false positive reports from the 200,000 tests to be conducted by next June. The public and the markets need to be prepared for that.\"\nWith the resulting drop in cattle futures prices, Mark says some people are asking why the USDA notified the public of the inconclusive results.\n\"Last time the USDA drew criticism for not announcing sooner,\" says Mark, who noted that full disclosure will benefit the beef industry if people understand the real issues behind the testing process.\n\"The press release from USDA about the (June 25) finding was very clear, but right away a few people started talking about it like it was a new confirmed case of BSE,\" he says.", "label": 1}
{"text": "Some time ago there was a big fuzz over Firesheep: by listening to wifi traffic your login session can be stolen which is very bad because now somebody can e.g. send emails on your behalf. Some people said that using SSL for the whole site was the only solution. But I didn't think this was true: if you can keep the password or equivalent stored on the client side, and you never send this to the server but rather authenticate every request you do with this password, then nobody can impersonate you (unless they know your password). For example when you do a HTTP request\nreq, you instead do the request\nr + \"?hmac=HMAC(password, req)\" to prove that you know the password.\nThen I came across a paper on a protocol called SessionLock, which is targeted at solving the same problem. It is a bit different than what I described above, and I have some questions about it.\nFirst, why do they establish a shared secret over SSL or using the Diffie-Hellman protocol, when there already is a shared secret available (the password or a hashed version of the password)?\nSecond, about the version that uses Diffie-Hellman they say:\nIf the browser loses its secret, it can re-perform a Diffie-Hellman key exchange with the server, using a number of XMLHttpRequest calls.\nCan somebody explain how this works? Supposedly the client side didn't save the password, and it also lost the shared secret. So as far as I can see the client side knows nothing, yet he is able to re-establish a shared secret that can be used to do authenticated stuff. Wouldn't an attacker be able to do exactly the same? What am I missing?", "label": 1}
{"text": "Suppose you want to send a letter to your brother. And let’s suppose it’s got some, oh, maybe potentially embarrassing financial information – he owes you some money and you’re having trouble paying the bills.\nObviously, that’s not the sort of thing you want to put on a postcard; you’d put that in an envelope. (Your brother is notorious about checking his email).\nYou want him to know that the letter is actually from you, so you sign it – you have a distinct signature that is very hard to forge. And, on top of that, you want him to know that nobody else read the letter, so you also sign across the fold of the envelope, so it can’t just be put in a new envelope.\nSo, you’ve done the basic security – it’s authenticated (with your signature), it’s not readable by third parties (because of the envelope) and it’s tamper-evident (because you signed the envelope, too). It’s not the most secure communication possible, but you’ve clearly done due diligence.\nSo what if I told you people were doing that almost 4000 years ago?\nSealing letters in clay envelopes was standard practice. Sometimes it was used for security; other times, in the case of contracts, the contract was written on the inner tablet and the envelope, and both marked with the personal seals of the signatories, making the text of the contract accessible while still having an unalterable copy in case it came into question.\nPeople have known for millennia that secure communication is crucial to business. We’ve known a need for privacy, authentication, and tamper evidence. These aren’t new ideas at all.\nHowever, we seem to have a hard time applying them to modern technology, sadly. That’s the only reason I can figure out to explain why yesterday I had someone asking me to email a scanned image of a check without any encryption.", "label": 1}
{"text": "Hackers and new computer viruses seem to be in the news more frequently, along with regular warnings to update your virus protection and protect your privacy. The task of keeping your computer safe can seem overwhelming. So, what can you do to safeguard access to your computer and to protect yourself and your family from cyber intrusion?\nKnow the terminology\nThe first step is to recognize the risks and become familiar with some terminology. Hackers, attackers or intruders are terms applied to the people who seek to exploit weaknesses in software and computer systems for their own gain. Their actions can range from mischief (creating a virus with no intentionally negative impact) to malicious (stealing or altering information).\nMalicious code includes code such as viruses, worms and Trojan horses. Although some people use these terms interchangeably, they have unique characteristics:\n- Viruses — This type of malicious code requires you to actually do something before it infects your computer. This action could be opening an e-mail attachment or going to a particular Web page.\n- Worms — Worms propagate without you doing anything. They typically start by exploiting a software vulnerability (a flaw that allows the software's intended security policy to be violated). Then once the victim computer has been infected, the worm will attempt to find and infect other computers. Similar to viruses, worms can propagate via e-mail, websites or network-based software. The automated self-propagation of worms distinguishes them from viruses.\n- Trojan horses — A Trojan horse program is software that claims to do one thing while, in fact, doing something different behind the scenes. For example, a program that claims it will speed up your computer may actually be sending your confidential information to an intruder.\n- Spyware — This sneaky software rides its way onto computers when you download screensavers, games, music and other applications. Spyware sends information about what you're doing on the Internet to a third-party, usually to target you with pop-up ads.\nMinimize access to your information\nAs long as you have a computer and connect it to a network or the Internet, you are vulnerable to someone or something else remotely accessing or corrupting your information. Here are some tips to make it more difficult for someone to do this:\n- Lock or log-off your computer when you are away from it. This prevents another person from then sitting down at your computer and accessing all of your information.\n- To be really secure, disconnect your computer from the Internet when you aren't using it. The likelihood that attackers or viruses scanning the network for available computers will target your computer becomes much higher if your computer is always connected.\n- Evaluate your security settings. Many, but not all Internet providers offer free security software. If you don't receive free software, you should consider buying a commercial product that includes virus scan, firewall and pop-up blockers. You should also be aware of your Internet cookies setting. Cookies are short pieces of data used by Web servers to identify users. Some cookies are useful for storing images and data from websites that you frequent, but others are malicious and collect information about you. You'll have to decide how much risk from cookies you can accept.\n- Browsers enable you to block pop-up ads. You can also install anti-spyware to block them.\n- Look for signals that you are using a secure web page. A secure site encrypts or scrambles personal information so it cannot be easily intercepted. Signals include a screen notice that says you are on a secure site, a closed lock or unbroken key in the bottom corner of your screen, or having the first letters of the Internet address you are viewing change from \"http\" to \"https.\"", "label": 1}
{"text": "www.netsmartz.org - Internet\nsafety for all ages – awesome activities to do with your child\n- Instant messengers and internet filter/blocker reviews\nplain language explanations of software\n– Internet safety for k-6\nOnGuard Online provides practical tips\nfrom the federal government and the technology community to help you\nguard against internet fraud, secure your computers, and protect\nwww.webwisekids.org - Kids,\nparents, teachers and law enforcement discover innovative Internet safety\neducation programs to protect today’s youth from online dangers.\nCommon Sense Media.org –\nExcellent site for parents and educators.\nParents can find reviews of movies, video games,\nkid-friendly apps, and great advice for talking to your kids\nabout all things digital.\nEducators can download the Digital Citizenship\nCurriculum for k-12 – free!!!!\nNet Family News – Great\nnewsletter for parents and educators regarding kids’ use of\nup with emerging trends in technology and Internet Safety\nInformation for parents and teens on using technology\nprovides a great guide for how to set the recommended\nprivacy settings for facebook.\nCyberbullyhelp.org – Educate yourself regarding\ncyberbullying on this site.\nIt also provides quick links to report abuse on\nfacebook, Twitter, Instagram, etc.\nABCs of Cyberbullying for\nCyberbullying Quick Reference Guide for Parents\nHelp Tips for\nReporting Offensive Profiles To Social Networking Sites\nhere for adobe pdf of this section)\nCompiled by Patti Agatston, Ph.D.\nMySpace provides a link in their help center to report offensive\nprofiles. You can also enter this url to get to the help page that has a link\nto report harassment or threats:\nEducators can report an “imposter profile” that targets them on MySpace.\nThis is also under the help center and frequently asked questions. The link for\neducators to report fake profiles targeting faculty members is:\ncan request that their child’s profile be removed. The link to make that\nrequest is on the parent safety tips page. Here is the url:\nAnyone can report inappropriate content. This information is also on the\nhelp page. The link is:\nAbuse can be reported by e-mailing Facebook directly at\nemail@example.com. There is also a link provided under the security\npage of Facebook. The security page link is:\nScroll down to the\nsecurity section and click on the link to report abuse.\n2. If someone is harassing/libeling you, Facebook gives the following\nsuggest that you block the person by listing his or her name in the \"Blocking\nPeople\" box at the bottom of the My Privacy page. If this does not resolve the\nproblem, please write an email to firstname.lastname@example.org from your login email\naddress. We will need to know your name, login email address, and school. Also,\nplease provide the name and school of the person who is harassing you along with\na description of the situation.”\n3. Use the e-mail\nemail@example.com to report any other information that you think should not\n1. Schools and parents can contact\nXanga for help at the following url:\n2. Xanga also provides a link to\nwiredsafety’s cyber abuse hotline for severe cases of cyber bullying or other\nabuses such as cyberstalking, identity theft and child\nexploitation. The link to wired safety’s cyberabuse hotline is:\nThe guidelines for uploading appropriate\nvideos are posted on Youtube’s community guidelines. Here is the link:\nAnyone can flag a video as inappropriate. If\nYoutube reviews the video and finds it to be inappropriate, the video is shut\ndown. If they decide to terminate the user’s account the user is prohibited\nfrom ever having another account on Youtube.\nCheck your zip code for Pedophiles\nHow to check where they surfed\nthe history, if the history is blank then ask why they cleared it.\nthe Temporary internet files.\nClick on tools/internet options/settings/view file.\nwill give you a list of all of the graphics and cookies downloaded onto\nClick on a couple and see if they are appropriate.\nRun a Spyware blocking program\nMy House Rules\nfeel threatened, come get the parent to help save the conversation (if you\nget mad and exit, all the data is gone).\ntalk about other people, our feelings, or personal information on-line –\never, end of story.\n- Other kids can sign on with other people’s accounts and pretend to be\nsomeone different – be aware of out of the ordinary questions.\nArticles and fact sheets about youth culture\nSend questions or comments to Jeff\nPage last updated on", "label": 1}
{"text": "Operating systems can't tell the difference between a virtual machine and a physical machine, but manufacturers are seeing -- and celebrating -- the notable difference virtualization is having on their bottom line.\nWith aging plant infrastructures, tighter regulations, data security issues and numerous other challenges to address, process engineers want to get the most from their IT-based plant assets. To do this, many have included virtualization in their automation migration plans. Virtualization is rapidly transforming the IT landscape, and fundamentally changing the way you use hardware resources.\nAnd the return on investment (ROI) is nearly immediate because virtualization helps you build an infrastructure that better leverages manufacturing resources and delivers high availability.\nWhat is Virtualization?\nVirtualization is a software technology that decouples the physical hardware of a computer from its operating system (OS) and software applications, creating a pure software instance of the former physical computer -- commonly referred to as a Virtual Machine (VM). A VM behaves exactly like a physical computer, contains it own \"virtual\" CPU, RAM hard disk and network interface card, and runs as an isolated guest OS installation within your host OS. The terms \"host\" and \"guest\" are used to help distinguish the software that runs on the actual machine (host) from the software that runs on the virtual machine (guest).\nVirtualization works by inserting a layer of software called a \"hypervisor\" directly on the computer hardware or on a host OS. A hypervisor allows multiple OSs, \"guests,\" to run concurrently on a host computer (the actual machine on which the virtualization takes place). Conceptually, a hypervisor is one level higher than a supervisory program. It presents to the guest OS a virtual operating platform and manages the execution of the guest OSs.\n|Virtual machines can be run on any virtualization-enabled physical server, creating a pool of computer resources that helps ensure your highest-priority applications will always have the resources you need without wasting money on excess hardware only needed for peak times.|\nVirtualization in Action\nBut the benefits of virtualization go far beyond the consolidation of computers. Many manufacturers use virtualization to extend their software's longevity. Consider the case of Genentech, a biotech company based in South San Francisco, California. Genentech specializes in using human genetic information to develop and manufacture medicines to treat patients with serious or life-threatening medical conditions.\nThe company estimated that the costs to upgrade one of its Windows 95 PC-based HMIs to a Windows Server 2003-based system would be approximately $40,000. Final figures topped $100,000 because of costs associated with validating the system for use in a regulated industry. Assuming that OSs are updated about every five years, costs quickly become a limiting factor in keeping an installed base of manufacturing computers up-to-date.\nAdditional factors also contribute to the cost of upgrades. \"Computer hardware changes even more frequently than operating systems,\" says Anthony Baker, system engineer at Rockwell Automation. \"Each change incurs engineering expenses and possibly production downtime.\"\nSo instead of investing in the upgrades, Genentech implemented virtualization.\nAccording to Dallas West, [insert title], at Genentech, one of the most lasting effects of virtualization is that it allows legacy operating systems, such as Windows 95, Windows NT, etc., to be run successfully on computers manufactured today. This extends HMI product lifecycles from 5-7 years to 10-15 years and possibly longer.\n\"Having the ability to extend the useful life of a computer system allows a manufacturer to create a planned, predictable upgrade cycle commensurate with its business objectives,\" West says.\n\"No longer is a business forced to upgrade its systems because a software vendor has come out with a new version. Upgrading systems can once again be driven by adding top-line business value by choosing to upgrade when new features become available that will provide an acceptable return on investment,\" he explains.\nWhy Virtualization is a Big Deal\nVirtualized assets also help increase productivity. By not having to maintain physical hardware, administrators are able to carry a heavier workload. A recent study by analyst IDC found that administrators manage an average of about 30 servers. After virtualization, they can manage 60-90 servers -- a significant increase in capacity. They're also able to spend more time architecting their infrastructure for higher levels of productivity.\n\"Gone are the days of \"server sprawl,\" where a new server is needed for each new application or tool and each ends up running at only 8-10% utilization,\" Baker says.\nVirtualization allows companies to create a scalable infrastructure, where new VMs can be added without the need to continuously buy new hardware and other physical devices. When manufacturers start to consolidate, they find they can buy and allocate the appropriate amount of resources for each VM, which reduces system maintenance and energy consumption costs.\nAnother feature of virtualization is that the system doesn't know it's \"virtualized.\" This allows administrators to take hardware offline while the system is up and running.\n\"Since the VMs are not attached to a physical computer, the VMs can be migrated between servers while the system is still running,\" notes Baker.\nDuring a planned outage, administrators can shift their workloads so the server can be taken down with no impact to the system. When the planned outage is complete, the server can be placed back into service.\nAdvantages of a Virtual Machine:\n- Hardware independence\n- Fault tolerance\n- Application-load balancing\n- Rapid disaster recovery\n- Recovery to non-identical hardware\n- Ability to pre-test OS patches or vendor updates\n- Ability to roll-back incompatible OS patches or vendor updates\n- Reduced TCO resulting from consistent datacenter environment\n- Reduced power usage\nBaker adds, \"Rockwell Automation recognizes our customers' desire to make use of the opportunities that virtualization brings to mission critical applications. That's why we've worked closely with VMware, the leader in virtualization technologies, to establish a technical partnership.\" Rockwell Automation supports its software suite in virtualized environments, and has developed a list of software products that are recognized by VMware as \"VMware Ready.\"\nToday, most Rockwell Automation configuration, human interface and information products are certified as VMware ready, and Rockwell Automation is committed to testing all new software products in a virtual environment.\nApplying Virtual Assets\nUsing specially designed host hardware available on the market today, a virtual server can be sized with extensive memory and CPU resources. This allows a large number of VMs to be consolidated onto a single machine without impacting performance.\nYou can create a data center by running a group of servers with hypervisors managed via a virtualization infrastructure management interface. The bare-metal environment frees up a large portion of resources, which can then be dedicated to running the VMs.\nTips for Getting Started\nIf you're thinking about virtualization for your manufacturing facility, consider the following advice:\n- Being able to run legacy software indefinitely doesn't mean you should. If you find a software bug in an old system, don't count on it being fixed. You'll also want to consider the security implications of running legacy software. Virtualization should be used as a tool to moderately extend the life cycle of a computer system to allow an upgrade to take place in a planned and predictable manner when a suitable business driver emerges.\n- Not all network protocols are easily virtualized. The use of standard Ethernet is most widely supported by the various virtualization vendors.\n- Non x86-based systems (ie. SPARC, DEC-Alpha, etc.) cannot be virtualized to run on a x86-based machine, such as Intel, Advanced Micro Devices (AMD), etc.\n- Third-party vendor support for virtualized systems has been limited. There is an added risk of running virtualized software in a production environment that has not been thoroughly tested and endorsed by a respective third-party vendor.\nMore information about Rockwell Automation Process Solutions can be found at www.rockwellautomation.com/go/process", "label": 1}
{"text": "Solaris 11 Supports Two Forms Of VirtualizationOracle's first update of Sun's Unix includes support for Oracle VM hypervisor and Solaris Zones.\nSupport for the Oracle VM hypervisor, derived originally by Sun Microsystems from the Xen open source code, has been added to Solaris. That means Solaris can host virtual machines on either a Sparc server or on a standard Intel or AMD x86 server under Solaris 11 for x86. Unix RISC servers are typically more powerful than x86 servers and are still used for large databases or other demanding applications that have high transaction throughput. Support for Oracle VM gives Solaris users both options.\n- The Critical Importance of High Performance Data Integration for Big Data Analytics\n- Come Together, Right Now, Part 1: The Why, When and How of IT Convergence\n- Top 10 Considerations for Getting Started with Virtualization\n- Beyond Cost Savings: Four Compelling Reasons to Expand Virtualization of Your IT Environment\nIn addition, Solaris includes a second virtualization option, first added to Solaris 10 when it was released in 2005. That's Solaris Zones, a method of dividing up a host server's resources among many applications each in its own software partition, known as a container or zone. For example, a zone would assign an application a share of memory, CPU, network bandwidth, and access to the operating system. A single Solaris host can run \"hundreds\" of zones, said Markus Flierl, VP of Oracle software development, in an interview.\nIt's difficult to directly compare how many zones versus full bore virtual machines might run on a same-sized server, but most virtual machine hosts run fewer than 100.\nMore zones can be run on a single host than VMs because, while each zone contains an application, all the applications make use of a single, shared Solaris operating system kernel. In many cases, they share Solaris root directories, such as /usr and /lib, according to a blogger's FAQ as well. Such sharing does not go on in typical x86 virtualized environments. In VMware or Microsoft Hyper-V virtual machines, each application is paired up with its own operating system. That leaves many operating systems making demands on the host, instead of just one.\nA zone has one-fifteenth the overhead of a VMware ESX Server virtual machine, claimed Markus Flierl, Oracle VP of software development, in an interview. Zones also run \"without artificial limits on memory,\" he added, perhaps a swipe at the new 96-GB limit for a virtual machine running under a VMware enterprise license. \"With Solaris 11, the options for virtualization have dramatically expanded,\" he said.\n[ Want to see a case where a business adopted \"containers\" instead of VMs? See 'Containers' Outperform Virtualization For KV Pharmaceuticals ]\nOracle has added virtual environment management features to Solaris 11 as well. A system administrator may virtualize both network and storage resources to go with the zones or virtual machines generated under a single instance of Solaris. The ability to define network and storage resources to work with other virtualized assets makes it easier to set up complete, virtualized environments, said Charlie Boyle, senior director of product marketing.\nBecause Solaris 11 includes the added virtualization features, it was dubbed \"the first cloud operating system\" upon release Nov. 11. In this use of the term \"cloud,\" a single Solaris system can operate with more flexible and elastic characteristics and manage more virtualized resources than before; nothing in the announcement indicated that it was it was intended to manage thousands of servers with automated provisioning of end users in a cloud data center.\nThe ZFS file system is part of Solaris 11, and its data deduplication capabilities mean storage requirements for a virtualized system under Solaris 11 may be reduced to one-tenth their previous level, said Boyle.\nSolaris 11 has been engineered to work better with Oracle applications, the Oracle 11g database system and Oracle Fusion Middleware, he added.\nUnix has been the sick-old-man of operating systems for so long that some have prematurely written its obituary. Headlines declaring the death of Unix have appeared regularly, but their writers overlook the fact that revenues from Unix servers and software experienced a small uptick this year, according to IDG. It's a market that exceeds $18 billion a year.\nSolaris' main commercial competitors are IBM's AIX and HP's HP-UX and they also offer partitioning of servers into containers. Linux competes with Solaris as open source code. Oracle discontinued the community open source version of Solaris in August last year and replaced it with a free version, Solaris Express.\nUnix is still the operating system of choice for the largest enterprise databases and other large systems doing a specialized, mission critical workload, as opposed to clusters of x86 servers. For more analysis, see a report on Gabriel Consulting, Survey: The Demise Of Unix Is Greatly Exaggerated .\n\"There has been a lot of ill-considered press coverage about the 'death' of Unix and coverage of the wholesale migration of Unix workloads to Linux, some of which (the latter, not the former) I have contributed to. But to set the record straight, the extinction of Unix is not going to happen in our lifetime,\" wrote Richard Fischera, analyst at Forrester Research, on Oct. 26 in \"Unix--Dead or Alive?\"", "label": 1}
{"text": "RONNIE L. WILLIAMS\nDespite increased awareness of cybercrime, cyber-attacks continue to plague companies from Memphis to Brussels to Subic Bay.\nCyber attacks are typically defined as criminal activities that are conducted by means of the Internet. With more and more companies relying on the Internet to do business, the frequency of cybercrime is certain to increase. These technology-based attacks can include stealing an organization’s intellectual property, gaining access to online bank accounts, creating and distributing viruses, and posting confidential business information on the Internet.\nA recent survey by PricewaterhouseCoopers found that 38 percent of the financial service firms surveyed have been hit by cybercrime of one sort or another. Although the financial service industry may experience a higher rate of cybercrime due to the nature of their business, cybercrime is a real threat to other industries as well.\nThe financial impact of cybercrimes can be devastating and the reputational damage may be ruinous for a company. The most costly cybercrimes are those caused by malicious code, denial of service, stolen devices and Web-based attacks. Malicious code and denial of service are typically the most common of the reported cyber attacks and include viruses, worms and Trojan horses.\nCyber crooks are utilizing more and more elaborate schemes in order to swindle businesses out of money, time and resources. Last year, the Department of Justice and the FBI announced the indictment of two individuals from Latvia and the seizure of more than 40 computers, servers and bank accounts as part of Operation Trident Tribunal, an ongoing, coordinated enforcement action targeting international cybercrime. This particular operation took down a cybercrime ring that caused more than $74 million in total losses to 1 million computer users. The size and extent of this cybercrime ring demonstrates the reach of the criminals and the financial impact their activities can generate.\nMitigation of cyber attacks can be a harrowing task. The cyber crooks are always thinking of new schemes that provide unauthorized access to valuable information. The Nigerian prince that only needs your checking account number to make you rich may not be sending you emails anymore, but you may receive an email from a logistics company referencing a package that is waiting for you. Once you open the email, a Trojan horse is placed on your machine that monitors the online transactions performed via the infected computer as well as the passwords and usernames for different services and credit card accounts. This attack can lead to empty bank accounts as well as a huge headache.\nProtection against cyber attacks can include anti-virus software, anti-spyware software and a properly configured firewall. Policies and procedures that deal with access to sensitive data as well as access to certain hardware can make everyone at an organization part of the safeguarding process. As the cyber attacks increase in frequency and sophistication, the efforts to stop the attacks will have to evolve and adapt to meet the challenge. Having a cyber risk-aware culture at your company could be the difference between being a rich prince or being a ruined pauper.\nRonnie L. Williams is the director of finance for HealthChoice LLC.", "label": 1}
{"text": "Today, the most common way of getting hit by malware is by browsing the Internet. It hasn't always been this way. Years ago, floppy disks were the main malware vector. Then sharing of executable files. Then e-mail attachments. But for the past five years, the Internet has been the main source of malware, according to a new report by F-Secure, an anti-virus, cloud content and computer security company based in Helsinki, Finland.\nThere is no exploit without a vulnerability. Ultimately, vulnerabilities are just bugs, that is, programming errors. We have bugs because programmes are written by human beings, and human beings make mistakes. Software bugs have been a problem for as longs as we have had programmable computers - and they are not going to disappear, it says.\nLet's take a look at top domains hosting malware, a software used or created by attackers to disrupt computer operation, gather sensitive information, or gain access to private computer systems.", "label": 1}
{"text": "The view from the top of IT with TechWorld Editor Rohan Pearce\nSSL, or Secure Sockets Layer, is the \"great enabler\" of online commerce.\nIt's the S in HTTPS, and it's the padlock in the address bar of your browser.\nIt's the underlying protocol which stops the cybercrooks enjoying a complete free-for-all when you spend money or read your email online.\nTogether, SSL and its big brother Transport Layer Security (TLS, which is SSL with a beard and in grown-up clothes) provide a ubiquitous cryptographic mechanism by which two people on the internet, including people who have never met or done business with each other before, can exchange information with secrecy, authenticity and integrity.\nLoosely speaking, that means they can verify that they really are talking to each other, not to an impostor; that no-one else is eavesdropping; and that no-one can tamper with the content of their conversation.\nIn sequence, these SSL-related disaster stories involve: the prevalent server-side implementation of SSL/TLS in a cryptographically weak way; a corporate break-in allowing an Iranian hacker to mint himself fake online SSL IDs; an admission by a certificate authority that it had been hacked in 2010 but forgot to tell anyone; stolen SSL certificates used by a virus writer; and a certificate authority that got caught out creating an eavesdropping SSL certificate for a customer.\nIt gets worse. Not one but two research papers have just surfaced, digging into the mechanics of actually building the bits-and-bytes of SSL certificates. The results aren't catastrophic, but they are, to say the least, interesting.\nMost SSL certificates rely on a public key encryption algorithm called RSA for their authentication component. The idea is that I create a pair of keys: one public; the other private. So if I sign something with my private key, you can use my public key to verify that only I could have signed it. And if you encrypt something with my public key, you can be sure than only I can unlock it.\nProvided, of course, that my private key really is private.\nAssuming no-one steals my key, or pays a certificate authority to issue a fake key in my name, just how unique [*] is is my private key? Is there a chance that someone else, without any malice aforethought, might unexpectedly end up with a key pair that is identical or at least dangerously similar to mine?\n\"Yes,\" according to this latest research.\nThe problem comes in key generation. Greatly oversimplified, RSA requires you to generate a unique pair of prime numbers, p and q, and to publish, amongst other things, their product, n. You can't be mathematically certain that your p and q are unique, but if they are generated genuinely randomly, the chance that someone else chose them already ought to be vanishingly small.\nIf you could split n back into p and q, you would have cracked the key. So the security of the system depends on the difficulty of taking that public value nand converting it back into its prime factors p and q. Prime numbers are only divisible by themselves. So the product of two prime numbers is divisible only by itself and those two primes. Factoring small primes is easy. 15, for example is 5 x 3. You can do this in your head. But factoring ever-larger prime products is ever harder. Try doing the 10-digit product 9326222179 [**] in your head, and then bear in mind that the smallest prime products recommended for current use in RSA keys are over 300 digits long (1024 bits).\nSo, if someone else has a key with the same n as yours, you know their pand q, because each n factors in only one way. Alternatively, if they choose one of p or q non-randomly, you have a better-than-average chance of guessing it. Since q = n/p and p = n/q, guessing one prime factor gives you the other one on a plate.\nAnd the recent research found a small but worrying number of public keys which shared the same value of n, or which used prime factors from an obviously non-random source.\nI'm not going to repeat the papers' findings here - the authors deserve that you read the actual results by clicking through to their own articles, here and here - but both sets of researchers found duplicated ns (prime products), and ns which could be factored easily.\nAt least some of these problems are explained by poor (or just plain wrong) random number generation, leading to one or both of p and q being guessable, thus breaking the privacy of the resulting private key.\nAs the famous mathematician and computer scientist John von Neumann is supposed to have said :\nAny one who considers arithmetical methods of producing random digits is, of course, in a state of sin. For, as has been pointed out several times, there is no such thing as a random number. There are only methods to produce random numbers, and a strict arithmetic procedure ... is not such a method.\nIf you're a coder, don't cut corners on randomness. And never, ever try to roll your own pseudo-random number generator, unless you're a world-class cryptographer.", "label": 1}
{"text": "Software developers are racing to patch a recently discovered vulnerability that allows attackers to recover the plaintext of authentication cookies and other encrypted data as they travel over the Internet and other unsecured networks.\nThe discovery is significant because in many cases it makes it possible for attackers to completely subvert the protection provided by the secure sockets layer and transport layer protocols. Together, SSL, TLS, and a close TLS relative known as Datagram Transport Layer Security are the sole cryptographic means for websites to prove their authenticity and to encrypt data as it travels between end users and Web servers. The so-called \"Lucky Thirteen\" attacks devised by computer scientists to exploit the weaknesses work against virtually all open-source TLS implementations, and possibly implementations supported by Apple and Cisco Systems as well. (Microsoft told the researchers it has determined its software isn't susceptible.)\nThe attacks are extremely complex, so for the time being, average end users are probably more susceptible to attacks that use phishing e-mails or rely on fraudulently issued digital certificates to defeat the Web encryption protection. Nonetheless, the success of the cryptographers' exploits—including the full plaintext recovery of data protected by the widely used OpenSSL implementation—has clearly gotten the attention of the developers who maintain those programs. Already, the Opera browser and PolarSSL have been patched to plug the hole, and developers for OpenSSL, NSS, and CyaSSL are expected to issue updates soon.\n\"The attacks can only be carried out by a determined attacker who is located close to the machine being attacked and who can generate sufficient sessions for the attacks,\" Nadhem J. AlFardan and Kenneth G. Paterson researchers wrote in a Web post that accompanied their research. \"In this sense, the attacks do not pose a significant danger to ordinary users of TLS in their current form. However, it is a truism that attacks only get better with time, and we cannot anticipate what improvements to our attacks, or entirely new attacks, may yet be discovered.\"\nA PDF of their paper is here.\nHow it works\nLucky Thirteen uses a technique known as a padding oracle that works against the main cryptographic engine in TLS that performs encryption and ensures the integrity of data. It processes data into 16-byte chunks using a routine known as MEE, which runs data through a MAC (Message Authentication Code) algorithm, then encodes and encrypts it. The routine adds \"padding\" data to the ciphertext so the resulting data can be neatly aligned in 8- or 16-byte boundaries. The padding is later removed when TLS decrypts the ciphertext.\nThe attacks start by capturing the ciphertext as it travels over the Internet. Using a long-discovered weakness in TLS's CBC, or cipher block chaining, mode, attackers replace the last several blocks with chosen blocks and observe the amount of time it takes for the server to respond. TLS messages that contain the correct padding will take less time to process. A mechanism in TLS causes the transaction to fail each time the application encounters a TLS message that contains tampered data, requiring attackers to repeatedly send malformed messages in a new session following each previous failure. By sending large numbers of TLS messages and statistically sampling the server response time for each one, the scientists were able to eventually correctly guess the contents of the ciphertext.\nIt took the scientists as little 223 sessions to extract the entire contents of a TLS-encrypted authentication cookie. They were able to improve their results when they knew details of a the ciphertext they were trying to decrypt. Cookies formatted in base 64 encoding, for example, could be extracted in 219 TLS sessions. The researchers required 213 sessions when a byte of plaintext in one of the last two positions in a block was already known.\nThe Lucky Thirteen attacks are only the latest exploits to subvert TLS, which along with SSL is intended to safeguard bank transactions, login sessions, and other sensitive activities carried out over unsecured networks. One of the most serious recent attacks used a universal wildcard certificate to spoof the credentials of virtually any website on the Internet. The previously mentioned BEAST attack was able to decrypt an eBay authentication cookie, although the technique required the attackers to first subvert something known as the same origin policy. Late last year, the same researchers behind BEAST devised CRIME, an attack that used Web compression to subvert TLS/SSL.\nTLS remains vulnerable to such attacks largely because of design decisions engineers made in the mid-1990s when SSL was first devised, Johns Hopkins University professor Matthew Green observed in a blog post published Monday that explains how Lucky Thirteen works. Since then, engineers have applied a series of \"band-aids\" to the protocols rather than fixing the problems outright.\nThe attacks apply to all implementations that conform to version 1.1 or 1.2 or version 1.0 or 1.1 of TLS or DTLS respectively. They also apply to implementations that conform to version 3.0 of SSL or version 1.0 of TLS when they have been tweaked to incorporate countermeasures designed to defeat a previous padding oracle attack discovered several years ago.\nIt's not the first time SSL and TLS have been brought down using a padding Oracle attack. The protocols were later patched to prevent attacks that used subtle differences in timing to ferret out details about the encrypted plaintext. At the time, some cryptographers acknowledged a tiny window that could still permit that type of exploit.\nThe scientists dubbed their exploit \"Lucky Thirteen\" because it's made possible by the TLS MAC calculation including 13 bytes of header information.\n\"So, in the context of our attacks, 13 is lucky—from the attacker's perspective at least,\" the researchers wrote in their Web post. \"This is what passes for humor amongst cryptographers.\"\nStory updated to add detail about Microsoft in the second paragraph.", "label": 1}
{"text": "A team of Canadian researchers have uncovered an unusual new example of “upstream filtering,” where online content in one country is blocked in another country due to filtering that happens in transit.\nResearchers at the Citizen Lab at the Munk School of Global Affairs at the University of Toronto, revealed that some Oman Internet users using the Omantel ISP are also being subjected to Indian content restrictions because of traffic flowing through India.\n“It goes to show what you can find when you begin to probe beneath the surface of the Internet, and what you see when you have governments start to mess with the openness of the Internet,” Ron Deibert, Citizen Lab's director, told Ars on Thursday. “In this case you have a perverse situation where citizens in one country are subject to filtering in another country.”\nWhile there have been numerous examples of specific countries blocking foreign or domestic content that they find objectionable, as it runs afoul of their own laws or regulations, it’s rare for one country to accidentally block sites due to peering agreements and traffic flows.\nIn this case, Indian ISP Bharti Airtel and Omantel have peering agreements, and partnered with other companies to build the Europe India Gateway, a 15,000-kilometer fibre optic cable that connects 13 countries via the Suez Canal in Egypt.\nCitizen Lab conducted numerous tests in late June 2012 both remotely via a proxy, and also in collaboration with Omani Internet users, but also found that the blocks may not be consistently applied at all times.\nEntertainment, news sites affected\n“The practice of upstream filtering raises a number of questions, including jurisdictional issues and the lack of recourse to users in Oman,” Citizen Lab states in its report.\n“The application of filters in India restricts Internet users in Oman from accessing content, potentially even content produced in Oman itself, as a result of actions taken for domestic purposes within India. Users in Oman did not consent to this blocking, are left with little recourse for challenging these actions, and have limited means of accessing this content, which may or may not be in violation of Omani regulations. Combined with the significant filtering implemented by Omantel itself, this essentially puts Internet users in Oman behind multiple layers of national-level filtering.”\nPrimarily, the sites affected included Indian and Pakistani entertainment sites, political blogs, file-sharing websites, and even IndyBay, a San Francisco-based online news site.\nNot surprisingly, many Internet watchers lament this odd state of affairs online.\n“Decisions made in one country about acceptable online content often affect users in other countries,” wrote Jillian York, the director for international freedom of expression at the Electronic Frontier Foundation, in an e-mail sent to Ars on Thursday. “This can occur through upstream filtering such as in this scenario or through application of a bill like SOPA, where the US government would have been enabled to make decisions about foreign content.\"\nSimilar examples in Central Asia\nOman has its own national filtering system, written in Arabic and English, which announces that it blocks content that is “contrary to the laws of the Sultanate.” Omantel users seeing the Indian block are shown an English-only message, which states: “This website/URL has been blocked until further notice either pursuant to Court orders or on the Directions issued by the Department of Telecommunications.”\nThe Department of Telecommunications is the name of India’s telco regulations agency. But beyond the name coincidence, running a traceroute from Oman or an Oman proxy, shows that the traffic to a US-based site runs through India.\nIndia tends to filter security and Internet tools-related content, according to previous research done by the Open Network Initiative (ONI), while Oman’s tend to be more along the lines of blocking pornographic material, gay and lesbian content, and circumvention tool-related sites.\nThe ONI is a grouping of similar institutions that also includes the SecDev group and the Berkman Center for Internet and Society at Harvard University. In its extensive research on Internet filtering around the world, ONI has found similar examples in the past. Most notably there was a case in Kyrgyzstan, which had some sites blocked by a state ISP from Kazakhstan while selling its service to Kyrgyz Telecom.\n“Similar behavior was observed in Uzbekistan in 2004, where content filtering on one Uzbek ISP closely matched that seen in China, a finding supplemented by evidence that this ISP was purchasing connectivity service from China Telecom,” the Citizen Lab added in the report.\nOf course, any Omantel user or any other Internet user with a VPN or other circumvention tool would easily get around such blocks—a service that a New Zealand ISP advertised earlier this year with the express purpose of getting around Hulu and Netflix's geoblocking.", "label": 1}
{"text": "Receive Your Complimentary White Paper NOW!\n\"Beginner's Guide to SSL Certificates: Making the Best Choice When Considering Your Online Security Options\"\nSSL stands for “Secure Socket Layer.” It is a technology that establishes a secure session link between the visitor's web browser and your website so that all communications transmitted through this link are encrypted and are, therefore, secure. SSL is also used for transmitting secure email, secure files, and other forms of information.\nWhether you are an individual or a company, you should approach online security in the same way that you would approach physical security for your home or business. Not only does it make you feel safer but it also protects people who visit your home, place of business, or website. It is important to understand the potential risks and then make sure you are fully protected against them. In the fast-paced world of technology, it is not always easy to stay abreast of the latest advancements. For this reason it is wise to partner with a reputable Internet security company.\nSponsored by: Symantec Website Security Solutions\nOffered Free by: Symantec Corporation\nOther Resources from:", "label": 1}
{"text": "Google, Amazon, Facebook Help U.K. Researchers Hack Cancer\nThe aim of the resulting game -- codenamed GeneRun -- is to recruit as many \"citizen scientists\" as possible to play what are hoped to be fun and engaging games, but which are actually cleverly disguised ways to get more eyeballs on very complex cancer mutation graphical data.\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Mobility Management Ailments: A Healthcare IT Cure Lessons from HiMSS13\n- Redefining Value in Healthcare: Innovation to expand access, improve quality and reduce costs of care\n- Enabling Healthcare Transformation with Social Business\nAt present, researchers need to carefully spot connections in cancer DNA mutation data by eye, as this is a task that can not yet be automated with computers. The problem: there are not enough scientists to do that, which means insights into the way cells become cancerous are being lost.\n\"Our machines can't pick up on the very slight variations and nuances that only the human eye can pick up on,\" said Amy Carton, Citizen Science projects lead at Cancer Research U.K., the research charity behind the program. \"And we have terabytes of data to get through.\"\n[ Want to learn how big data is contributing to the fight against cancer? See IBM Watson Helps Doctors Fight Cancer. ]\nIf it comes off, GeneRun could add the help of thousands of volunteer \"researchers,\" who will (presumably) be sifting through data while they are solving puzzles or killing virtual aliens.\nThe GameJam hackathon will bring together 40 developers, graphic designers, data specialists and gamers to come up with a basic design by Sunday, March 3. An agency will then build the game, with a proposed summer 2013 launch.\n\"We're making great progress in understanding the genetic reasons cancer develops,\" said professor Carlos Caldas, senior group leader at the Cancer Research U.K. Cambridge Institute at the University of Cambridge.\n\"But the clues to why some drugs will work and some won't are held in data which need to be analyzed by the human eye -- and this could take years. By harnessing the collective power of citizen scientists we'll accelerate the discovery of new ways to diagnose and treat cancer much more precisely.\"\nThe British arm of Amazon Web Services is providing -- for no charge -- the technology platform on which the final game will be hosted, plus supplying the 40 anticipated GameJam participants with free technology resources and expertise to help them start GeneRun game development.\nFacebook U.K. is similarly supporting the cancer GameJam with expertise from its London-based engineering team, and it has been acting as an informal recruiter through its links with some of the British universities sending attendees, including London's City University. Google U.K. will provide financial support and is hosting the hackathon at Campus, its co-working space in the heart of East London's Tech City.\n\"It is exciting to be part of this project and use cloud technology and gamification of data to help in driving research towards finding a cure for cancer,\" said Teresa Carlson, VP of worldwide public sector for Amazon Web Services. Philip Su, engineering site director of Facebook London, said, \"At Facebook we believe the best way to solve a problem is to bring smart people together to 'hack' a solution; that approach is just as valid in the field of life sciences as it is in software engineering.\"\nSpeaking on the BBC Friday morning, Su said, \"We're harnessing the power of people from all over the place here ... The average U.K. Facebook user has 256 friends and if only one of those people potentially downloads this game, then that could really help. We see this as an unqualified 'good.'\"\nFor George Freeman, a politician who is also life science adviser to the government, \"This is a fantastic example of how the U.K. is harnessing the power of the Internet for good, using cutting-edge technology to further research. We look forward to seeing the fruits of this innovative exercise.\"\nGeneRun will combine anonymized Cancer Research U.K. DNA datasets with data analysis technology from The Citizen Science Alliance, a group of organizations committed to increasing the British public's participation in science.\nThe GeneRun experiment follows that organization's earlier attempt to recruit crowdsourcing help in unpicking complex dataset analysis using a game called CellSlider, which gets gamers to help analyze archived cancer tissue samples. Carton told listeners on the BBC Friday that CellSlider was able to process in three months via a global crowdsourcing game effort what otherwise would have taken 18 months.\n\"We've already seen that there are tens of thousands of people happy to contribute their spare time to the cause of science,\" said Dr. Chris Lintott, the Alliance's chair. \"We hope the GameJam will let even more people join forces to help find cures for cancer.\"\n\"We're looking for use of people's 'micro-moments' here,\" added Carton. \"We're asking people to kill a bit of time here and also do what we all want to do at the same time. Kill cancer.\"", "label": 1}
{"text": "What is Cloud Computing?\nCloud computing is a general term for anything that involves delivering hosted services over the Internet. These services are broadly divided into three categories: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS) and Software-as-a-Service (SaaS). The name cloud computing was inspired by the cloud symbol that's often used to represent the Internet in flow charts and diagrams.\nA cloud service has three distinct characteristics that differentiate it from traditional hosting. It is sold on demand - it is elastic -- a user can have as much or as little of a service as they want at any given time; and the service is fully managed by the provider (the consumer needs nothing but a personal computer and Internet access). Significant innovations in virtualization and distributed computing, as well as improved access to high-speed Internet and a weak economy, have accelerated interest in cloud computing.\nCloud Computing revolutionizes the way businesses work by allowing instant, secure access to your private hosted network from anywhere. All of your software programs, data files, emails and other company data is accessible to you from any pc world wide. Cloud Computing offers clients a fully secured, managed, and maintained IT Infrastructure which allows you and your colleagues to work in a high-speed network environment without ever having to take on the cost of purchasing or maintaining servers, expensive networking equipment and backup systems.\nCloud Computing: Advantages for enterprises\nThe most important benefit of the Cloud Computing include—resource and budget optimization with rapid scaling up or down— higher security and improved reliability over a traditional client-server system.\nFixed Monthly Costs Allow For Financial Planning :\nRTCS Cloud Computing is a fully hosted and managed solution that includes secure remote access, data storage, application hosting, backups, antivirus, intrusion detection, hosted desktop, Windows updates, and unlimited support. For a low, fixed per user monthly fee your users will receive a hosted IT Infrastructure that costs thousands of dollars to purchase and maintain, making unpredictable IT costs a thing of the past. Since 2004 RTCS has revolutionized the way businesses work using Hosted IT Infrastructure!\nWhere do the applications and data reside?\nNever Load Programs or Applications on Your Workstation again because your applications and data reside on a secure remote server that is fully managed and supported by a third-party.\nRTCS Cloud Computing eliminates the need to load applications directly onto your local workstation. Whether it is your company’s customer management system, billing and accounting system, or simply your company time clock, everything is stored on your virtual office environment. Your Hosted IT Infrastructure will provide you with an all-in-one fully managed server desktop available to you anywhere at any time.\n24x7 Data Security & Monitoring :\nData security is a vital element for growing businesses in today’s world. More than ever before \"Cyber Intruders\" are on the prowl for vulnerable computer networks. Malicious attempts to compromise the confidentiality, integrity and availability of business resources are on the rise. Our security team monitors your Hosted IT Infrastructure and network environment 24 hours a day to ensure your system is always safe from hackers, viruses, malware and spyware. We understand the importance of security and that is why we include corporate, enterprise level security and monitoring free with your organization’s RTCS hosting. Our security systems include defense mechanisms such as a network antivirus, state of the art Cisco firewalls, and intrusion detection systems. We ensure that only you have access to your programs and files 24 hours a day, 7 days a week. Read More....\nDaily Data Backup :\nProtecting your data from a disaster is critical for companies who rely on electronic data as their medium of communications and operations. In a traditional network, an office manager, or in many cases the owner, assumes the responsibility of backup. Because the designated person is often too busy to manage and monitor the data backups, they are often left undone. In the event of a system failure, data is lost and your business will suffer. RTCS services include fully managed and automated, offsite backup protection for all of your mission critical data. We have dedicated team members who specialize in data backup and disaster recovery procedures to ensure your business continuity in the event of a disaster. Our daily offsite backups along with our weekly server snapshots will ensure that you are protected and never have to worry about losing valuable data.\nData Center Facilities :\nRTCS protects your business with nothing but the best. That is why we deploy our Cloud Computing solutions with SoftLayer, a Tier IV SAS 70 compliant co-location facility that provides a world renowned, reliable data and Hosted IT Infrastructure. With features such as biometric access controls, N+1 cooling systems, fire suppression systems, uninterruptible power solutions, and multi-homed Internet connectivity, your virtual Hosted IT Infrastructure meets your demands and exceeds your expectations.\nUnlimited Dedicated Support :\nRTCS has a professional, friendly support team available to you 24 hours a day, 7 days a week, 365 days a year. We know that your business can’t be put on pause, so we make sure that we are always there to provide you with the highest level of quality support right when you need it. We do our job so you can focus on yours. Hide this content.\nFill the Online Order Form or call 888-408-6044", "label": 1}
{"text": "We often mock \"security through obscurity\", but it is not without value, especially in today's web environment.\nMost attacks today are statistical in nature: a virus attempts to infect 10,000 computers by blasting out random attacks. If it infects even two more computers out of those 10,000, it has achieved its goal.\nThose viruses are aggressive in volume, not precision. They don't all do a port scan, analyze the responses to determine OS version, they don't do a vulnerability assessment, then launch a precise attack the way a human would. Instead, they try to exploit a common weakness - a buffer overrun exploit in PHP, or SQL injection vulnerability in a Wordpress plugin. Anything the system administrator does to alter their defaults: changing the base URL from \"index.html\" to \"index.htm\", or changing the database names in MySQL, might keep a particular automated attack from harming his system. It doesn't remove the vulnerability, it merely changes it so that an attack relying on the defaults will not succeed.\nWill this keep out a determined attacker? Of course not. But it will reduce the number of low-level threats that can still surprise anyone if they exploit a 0day vulnerability. And those low-level threats can quickly escalate to be every bit as damaging as an Advanced Persistent Threat.\nThat's why obscurity, which I define here as to be \"any implementation settings changed from the default\", still improves your overall security picture. It may only reduce a few particular attacks, or delay them by a few days, but those days can be enough to get a real patch installed. In practice, preventing a threat from becoming a successful attack is the true job of security, regardless of whether it was based on bad theory.", "label": 1}
{"text": "Posted by: MelanieYarbrough\nMember Batye recently reviewed Stealing the Network: The Complete Series Collector’s Edition for our Bookworm Blog. It’s a collection of fictional stories that takes a look at the possibilities available to hackers with some time and bad intentions. While the collection is meant to be an aid to ethical hackers and security professionals looking to be proactive, it brings up a moral dilemma. How can you ever ensure that the knowledge you’re passing on will be used for good rather than evil?\nA question was recently posted in the IT Forums regarding embedding executable files into a JPEG, a common tactic for spreading malware to unsuspecting end users. The community responded with mixed feelings toward the intentions of the asker. Who draws the line between helping out your fellow IT professionals and providing ill intent with the recipe for possible harm?\nThe simple answer is that no one draws that line except for you. IT Knowledge Exchange doesn’t expect you to provide any information you feel uncomfortable disclosing, and that goes for answering deceivingly innocuous questions. Member Chippy088 shares his own philosophy on the dilemma:\n[It's] not a good idea to help everyone without thinking about their reason for the question first.\nHave there been circumstances in your tech career that have made you uncertain about passing on your own knowledge? What are some nuggets of advice you’d want to pass on to those who are new to IT Knowledge Exchange or IT in general?", "label": 1}
{"text": "For years computer security experts have been preaching that users should never share the same password across their connected lives -- at online banking sites, at Amazon, on their Web mail services, even on their cell phones.\nApparently, most people ignore that advice.\nA new study by security firm Trusteer found that 73 percent of Web users take their online banking password and use it at other Web sites. And about half of all consumers utilize the same password and user name at online banking sites and other sites.\n\"I must say I was very surprised,\" said Amit Klein, chief technology officer of Trusteer. \"It is surprisingly sad that such a large portion of users use their banking credentials at other sites. ... It exposes those users to attacks that would otherwise be impossible. I thought that people would take banking credentials more seriously, but it turns out that in this digital age, this is not the reality.\"\nWhen consumers use the same password across multiple sites, hacking becomes trivially easy. If a criminal breaks into a smaller Web site -- say a site created by a local grocery store -- and grabs a cache of passwords, their next step is always the major banking Web sites. When you consider that 40 percent of U.S. consumers' checking accounts are tied up in the four largest banks, odds are good that the stolen credentials will work for in one of them.\nPassword overlap also creates an easy end run around sophisticated banking security technology, which is only as strong as the weakest site where the password is used. Banks might enforce strong password creation requirements, for example. But if a consumer uses a bank password at a poorly defended small site, a hacker can break into the small site, steal the log-in information and essentially crack the bank's high-tech system.\n\"This is something that should be of huge concern both to banks and to users,\" said Klein.\nTrusteer unearthed the data through use of its Rapport security software, which is designed to warn users when they are about to enter a critical banking password into a site where it doesn't belong -- a phishing site, for example. The tool was used to examine the behavior of 4 million computer users during a 12-month period. During that span, the firm found that 73 percent used their online banking password on at least one non-financial Web site.\nAnd it didn't help much when the banks enforced strict password controls. When a bank allowed consumers to pick a user ID, 65 percent used it on other sites. When a bank assigned a customer ID, 42 percent used it at other sites and 42 percent used both the ID and the password on at least one other site.\n'They don't think it's worth the trade off'\nLast year, analyst firm Gartner released a survey that reported similar results. It said two-thirds of consumers use the same one or two passwords across all Web sites they access.\nBut Avivah Litan, who directed the Gartner survey, said that choice might not be as unreasonable -- or as unsafe -- as it seems.\n\"They are making a choice for convenience over security,\" she said. \"They are using a cost-benefit equation ... and they don't want to try to remember 10 different passwords for everything they do. They don't think the trade-off is worth it, honestly.\"\nWhile password sharing isn't a safe practice, Litan said, complicating your life with multiple passwords isn't exactly a cure-all.\n\"The truth is criminals steal your passwords lots of ways, such as recording keystrokes, and if they do that, it doesn't matter whether your password is 15 characters and unique or 7 characters and the same for every site. People have figured this out,\" she said.\nUsing multiple passwords is a good idea, but Litan said it is important that consumers understand the risks that remain even if strong passwords are used.\n\"It is another lock on the door but a lock that is easily picked,\" she said. \"Still, it's always better to put as many blocks in the road you can.\"\nLarge banks don't rely on simple user/password combinations to identify users anymore, she added. Numerous technologies are used to prevent fraud through a strategy called \"layered security.\" Device fingerprinting of PCs is a key tool, she said. Web sites tag computer hardware by monitoring unique characteristics, such as exact processor speed or time and date settings. Sites that use device fingerprinting see fraud rates drop 15 to 20 percent, she said.\nBanks also look for suspicious behavior, such as attempted transfers to unusual accounts. Another hacker giveaway: clicks through Web sites that occur at high speed, showing an automated PC -- and not a person -- is attempting a transaction. Humans take, on average, about 10 seconds before they click \"confirm payment.\" Computers controlled by hackers racing through stolen login accounts barely wait at all.\n\"That's best-of-breed security,\" Litan said. \"If you as a bank are relying on passwords for security then you have a poor security system.\"\nRED TAPE WRESTLING TIPS\nIt should be comforting to know that your user ID and password are not all that stands between a hacker and your money. Still, that's no reason to let your guard down. Your banking passwords should be handled with great care, and shouldn't be shared with other Web sites.\nAnd remember, many Web firms that store your critical personal information do not use best-of-breed security on their back end -- meaning you are still at risk. A criminal who stole your Facebook credentials could easily wreak havoc with your life, so protect those accounts, too.\nKlein concedes that the vast majority of computer users will never create unique user/password combinations for all their sites. As a more practical goal, he recommends maintaining three \"families\" of passwords -- one for critical financial sites, a second for sites that store your personal information, and a third for generic log-ins.\n\"And you don't want to mix those passwords,\" he said.", "label": 1}
{"text": "A Pakistani Internet user surfs the YouTube Web site at a local Internet cafe in Islamabad, Pakistan, Feb. 26, 2008. Pakistan defended its clampdown on the YouTube Web site which accidentally interrupted access for Internet users around the globe.\n\"Duties for Internet Service Providers\"\nBelfer Center Programs or Projects: Explorations in Cyber International Relations; Information and Communications Technology and Public Policy; Science, Technology, and Public Policy\n\"Duties for Internet Service Providers\" was commissioned as part of a special paper series for the second annual Cyber Dialogue forum which took place March 18–19, 2012, in Toronto, Canada. Building upon the 2011 successful dialogue — Securing the Cyber Commons? — the 2012 Cyber Dialogue addresses the question: What is Stewardship in Cyberspace?\nIn today's interconnected world, the Internet is no longer a tool. Rather, it is a service that helps generate income and employment, provides access to business and information, enables e-learning, and facilitates government activities. It is an essential service that has been integrated into every part of our society. Our experience begins when an Internet Service Provider (ISP) uses fixed telephony (plain old telephone service), mobile-cellular telephony, or fixed fiber-optic or broadband service to connect us to the global network.1 From that moment on, the ISP shoulders the responsibility for the instantaneous, reliable, and secure movement of our data over the Internet.\nISPs come in many forms and sizes and go by many names: the phone company, the cable company, the wireless company, etc. They are the Internet stewards: planning and managing resources, providing reliable connectivity, and ensuring delivery for traffic and services. And while the communications infrastructure security as a whole is generally believed to be robust, recent events suggest that the networks and the platforms on which Internet users rely are becoming increasingly susceptible to operator error and malicious cyber attack. In 2012, we should therefore ask whether ISPs have additional duties to ensure the reliable delivery of an essential service.\nIn this article, we expose the gap between ISPs' written responsibilities and the unwritten, yet expected ones. Specifically, we define eight ISP duties:\n- Duty to provide a reliable and accessible conduit for traffic and services\n- Duty to provide authentic and authoritative routing information\n- Duty to provide authentic and authoritative naming information\n- Duty to report anonymized security incident statistics to the public\n- Duty to educate customers about threats\n- Duty to inform customers of apparent infections in their infrastructure\n- Duty to warn other ISPs of imminent danger and help in emergencies\n- Duty to avoid aiding and abetting criminal activity\nThe latter duties are helpful in calibrating threats and funding responses to them....\nThe full text may be downloaded below.\n1 Services include: Public-switch telephone network (dial-up); Digital Subscriber Line (DSL) (usually copper), Asymmetric Digital Subscriber Line (ADSL); broadband wireless; cable modem (cable Internet); Fiber to the Premises (FTTx) (optical fiber); Integrated Services Digital Network (ISDN) (transmission of voice, video, data, and other network services over the traditional circuits); frame relay (wide-area network); Ethernet; Asynchronous Transfer Mode (ATM); satellite Internet access; and synchronous optical networking (SONET) (using lasers over fiber).\n- Full text of \"Duties for Internet Service Providers\" (1.8 MB PDF)\nFor more information about this publication please contact the STPP Web Manager at 617-496-1981.\nFor Academic Citation:", "label": 1}
{"text": "So what is SHA-1?\nFrom wikipedia: The SHA (Secure Hash Algorithm) family is a set of related cryptographic hash functions. The most commonly used function in the family, SHA-1, is employed in a large variety of popular security applications and protocols, including TLS, SSL, PGP, SSH, S/MIME, and IPSec. SHA-1 is considered to be the successor to MD5, an earlier, widely-used hash function. The SHA algorithms were designed by the National Security Agency (NSA) and published as a US government standard.\nThe first member of the family, published in 1993, is officially called SHA; however, it is often called SHA-0 to avoid confusion with its successors. Two years later, SHA-1, the first successor to SHA, was published. Four more variants have since been issued with increased output ranges and a slightly different design: SHA-224, SHA-256, SHA-384, and SHA-512 — sometimes collectively referred to as SHA-2.\nFrom w3c.org: The Secure Hash Algorithm takes a message of less than 264 bits in length and produces a 160-bit message digest which is designed so that it should be computationaly expensive to find a text which matches a given hash. ie if you have a hash for document A, H(A), it is difficult to find a document B which has the same hash, and even more difficult to arrange that document B says what you want it to say.\nSome months ago a team of chinese researchers found an algorithm that could produce collisions in SHA-1, i.e., different messages could produce the same hash, which could be used, in theory, to forge certificates. SHA-1 is supposed to require at least 2^80 to produce a collision, which would be enough to keep it squarely out of supercomputer realm. The researchers initially managed to produce collisions in 2^69 operations, and now they were able to do it in 2^63. The lower it gets, the faster it is to break :D\nFor now, this is only a paper... until someone implements it, and then the fun begins. Although the US are recommending a move to SHA-2, there's this interesting quote by the NIST security technology group manager William Burr, in Federal Computer Week: \"SHA-1 is not broken, and there is not much reason to suspect that it will be soon.\" Should become an interesting tagline in a bit of time... hehehe\nFriday, August 19, 2005\nSo what is SHA-1?\nPosted by Andreia Gaita at 18:11\nTuesday, August 16, 2005\nNothing at all related to coding, this one, but leaving it here as a reminder for myself later - from September 23 to October 18, at Faleria António Prates, there will be a show of paintings done by robots created by a painter, Leonel Moura. Tak about conceptual art :p\nPosted by Andreia Gaita at 15:34\nNot directly related to coding, but a very interesting topic on it's own, is Computer Forensics and Incident Response. To relate this to coding, this field is so new that there's a huge need for good solid reliable smart tools to analyze and extract information from systems. I mean, even the most basic of informations, like knowing the memory map of a running windows system, is still an unkown!\nIf you dd (dd - a linux tool also available on windows to dump bytes... be it memory, a drive, whatever - to a file, used to image disks or analyze memory or (yep) do forensics analysys) a windows machine's memory, how do you extract meaningful information out of it? How is it organized, what is the kernel region or the applications region? Process memory is part RAM part swap, how do you deal with that? If you crash dump a windows, you can analyze the dump information on MS's tools, but dd's output is not read by the debuggers, so we need tools for this :p\nWindows Incident Response Blog\nPosted by Andreia Gaita at 13:39", "label": 1}
{"text": "A long-known but little-discussed vulnerability in the modern Internet's design was highlighted yesterday by a report that hackers traced to Iran spoofed the encryption procedures used to secure connections to Google, Yahoo, Microsoft, and other major Web sites.\nThis design, pioneered by Netscape in the early and mid-1990s, allows the creation of encrypted channels to Web sites, an important security feature typically identified by a closed lock icon in a browser. The system relies on third parties to issue so-called certificates that prove that a Web site is legitimate when making an \"https://\" connection.\nThe problem, however, is that the list of certificate issuers has ballooned over the years to approximately 650 organizations, which may not always follow the strictest security procedures. And each one has a copy of the Web's master keys.\n\"There is this problem that exists today where there are a very large number of certificate authorities that are trusted by everyone and everything,\" says Peter Eckersley, senior staff technologist at the Electronic Frontier Foundation who has compiled a list of them.\nThis has resulted in a bizarre situation in which companies like Etisalat, a wireless carrier in the United Arab Emirates that implanted spyware on customers' BlackBerry devices, possess the master keys that can be used to impersonate any Web site on the Internet, even the U.S. Treasury, BankofAmerica.com, and Google.com. So do more than 100 German universities, the U.S. Department of Homeland Security, and random organizations like the Gemini Observatory, which operates a pair of 8.1-meter diameter telescopes in Hawaii and Chile.\nIt's a situation that nobody would have anticipated nearly two decades ago when the cryptographic protection known as SSL (Secure Sockets Layer) began to be embedded into Web browsers. At the time, the focus was on securing the connections, not on securing the certificate authorities themselves--or limiting their numbers.\n\"It was the '90s,\" says security researcher Dan Kaminsky, who discovered a serious Domain Name System flaw in 2008. \"We didn't realize how this system would grow.\" Today, there are now about 1,500 master keys, or signing certificates, trusted by Internet Explorer and Firefox.\nThe vulnerability of today's authentication infrastructure came to light after Comodo, a Jersey City, N.J.-based firm that issues SSL certificates, alerted Web browser makers that an unnamed European partner had its systems compromised. The attack originated from an Iranian Internet Protocol address, according to Comodo Chief Executive Melih Abdulhayoglu, who told CNET that the skill and sophistication suggested a government was behind the intrusion.\nSpoofing those Web sites would allow the Iranian government to use what's known as a man-in-the-middle attack to impersonate the legitimate sites and grab passwords, read e-mail messages, and monitor any other activities its citizens performed, even if Web browsers show that the connections were securely protected with SSL encryption.\nComodo's revelation throws into sharp relief the list of flaws inherent in the current system. There is no automated process to revoke fraudulent certificates. There is no public list of certificates that companies like Comodo have issued, or even which of its resellers or partners have been given a duplicate set of the master keys. There are no mechanisms to prevent fraudulent certificates for Yahoo Mail or Gmail from being issued by compromised companies, or repressive regimes bent on surveillance; Tunisia even has its own certificate-issuing government agency.\n\"These organizations act as cornerstones of security and trust on the Internet, but it seems like they're not doing basic due diligence that other organizations are expect to do, like the banks,\" says Mike Zusman, managing consultant at Web app security firm Intrepidus Group. \"I'm not sure what we need to do but I think it's time we start addressing the issue of trust and issues of certificate authorities potentially not living up to standards that they should be.\"\nOver the last few years, a handful of papers and demonstrations at hacker conferences have focused more attention on the topic. But the Comodo intrusion, which appears to be the first public evidence of an actual attack on the way the Web handles authentication, could be a catalyst for rethinking the way to handle security.\nTwo years ago, for instance, Zusman was able to get a certificate from Thawte, a VeriSign subsidiary, for \"login.live.com\" just based on an e-mail address he created on the Hotmail domain. Even though it was revoked, it still worked in a Web browser during a demonstration at the Black Hat conference in Las Vegas. Comodo, too, has previously been shown to have lax security standards among its resellers as far back as December 2008.\n\"Remember, the only reason Iran has to go to the lengths they've gone to to get certificates is because they don't have a (certificate issuer) of their own... most countries can just generate their own,\" says Moxie Marlinspike, chief technology officer of mobile app developer Whisper Systems, who has discovered serious problems with Web authentication before. One problem, he says, is that companies that issue certificates have a strong economic incentive to make it as easy as possible to obtain them.\nAnother worrisome aspect is that browser makers don't always have a good way to revoke fraudulent certificates. A discussion thread at Mozilla.org, makers of the Firefox browser, shows that after being alerted by Comodo, they had no process to revoke the faux certificates. Mozilla developers ended up having to write new code and test a patch, which took a few days and, even after its release, meant that only users who downloaded new versions of Firefox benefit.\nGoogle's Chrome, on the other hand, uses a transparent update system for desktop versions but not necessarily mobile ones. Microsoft said yesterday that \"an update is available for all supported versions of Windows to help address this issue.\"\nRoss Anderson, professor of security engineering at the University of Cambridge's computer laboratory, offered an anecdote in this paper (PDF): \"I asked a panelist from the Mozilla Foundation why, when I updated Firefox the previous day, it had put back a certificate I'd previously deleted, from an organisation associated with the Turkish military and intelligence services. The Firefox spokesman said that I couldn't remove certificates--I had to leave them in but edit them to remove their capabilities - while an outraged Turkish delegate claimed that the body in question was merely a 'research organisation.'\"\nJacob Appelbaum, a Tor Project developer who is a subject of a legal spat with the Justice Department over his work with WikiLeaks, says Mozilla should have warned of the vulnerability immediately and shipped Firefox 4 with a way to detect and revoke bad certificates turned on by default. (The technique is called Online Certificate Status Protocol, or OSCP).\n\"Mozilla's not taking their responsibility to the Internet seriously,\" said Appelbaum, who wrote an independent analysis of the situation. \"A Web browser isn't a toy. It's being used as a tool to overthrow governments...At the end of the day, they did not put their users first.\"\nSome long-term technical fixes have been proposed, with names like DANE, HASTLS, CAA (Comodo's Philip Hallam-Baker is a co-author), and Monkeysphere. The technology known as Domain Name System Security Extensions, or DNSSEC, can help. The Electronic Frontier Foundation's Eckersley, who runs the groups SSL Observatory that tracks SSL certificates, hints that he'll soon offer another proposal about how to reinforce the Web's cryptographic architecture.\n\"We do in fact need a way not to trust everyone,\" Eckersley says. \"We have 1,500 master certificates for the Web running around. That's 1,500 places that could be hacked and all of a sudden you have to scramble to dream up a solution.\"", "label": 1}
{"text": "A new type of sophisticated — and convincing — malicious e-mail attack has targeted university accounts.\nTwice this academic year (Oct. 29 and Feb. 8) some U-M e-mail users have received a message that includes a logo associated with a real, although former, U-M organization.\nKnown as phishing, such attacks are employed by scammers in an attempt to gather personal information from users.\nAnyone receiving an e-mail that looks suspicious is asked to go to safecomputing.umich.edu/main/phishing_alerts/ for the latest list of phishing messages sent to university e-mail accounts, or contact firstname.lastname@example.org.\n“This message attracted responses from at least 30 users and possibly others we don’t know about. We contacted those we could identify to alert them it was a scam,” says Will Rhee, one of the university’s user advocates. “Not everyone who responded gave away their real password.”\nBesides using the old Information Technology Central Services logo, this e-mail also employed a convincing re-direction: any user who did click the link was directed to an exact duplication of U-M’s authentication page. After entering a username and password — which was captured — the user was then redirected to U-M’s real page, as though the information had perhaps been mistyped.\nThis latest attack demonstrates how cyber-criminals are looking for fresh and new ways to scam users, Information and Technology Services officials say.\n“We can’t say it enough — users must be careful about what they click on,” Rhee says. “Some people may feel like they don’t have much of value to protect in their e-mail, file space, or on their personal computer. However, stolen passwords are valuable because they are used to leverage U-M computing resources to facilitate crimes.\n“Your uniqname and password unlock access to networked resources that criminals want (e-mail, storage, network bandwidth, central processing unit, etc.) in order to be able to commit crimes and obfuscate who is responsible.”\nAccording to the February RSA Online Fraud Report, phishing attacks against public colleges and universities have increased in 2010 compared with 2009.\nThe report suggests that student accounts are widely targeted because, “Compromised webmail accounts may give phishers another foothold in students’ personal computers, since compared with other unsolicited e-mail content, spam e-mails would gain credibility when coming from peers, especially if messages are sent from a university webmail address.”\nTo read the full report, go to www.rsa.com/solutions/consumer_authentication/intelreport/10763_Online_Fraud_report_0210.pdf.\nThe university offers guidance for faculty and staff who create e-mails that include links to forms or Web sites that ask for personal information (surveys, for example).\n• For guidelines to better e-mail security practices, go to tinyurl.com/um-safe-email.\n• To view a sample of the phishing message sent to some U-M e-mail accounts, go to tinyurl.com/um-phish-sample.\nCarrie Stefanski, right, marketing communications specialist, Information & Technology Services, on roller derby action: “I was able to get up quickly and rush to the front of the pack and knock down the opposing jammer. It was very satisfying.”", "label": 1}
{"text": "The Reaper and the future of military flight\nA U.S. army soldier with prepares to launch a UAV -- or drone -- outside Combat Outpost Nolen in the village of Jellawar in The Arghandab Valley.\nThere's an ongoing debate over the ethics of fighting war in a detached, videogame-like manner. You have planes launching missiles on human targets on the ground in Afghanistan but the pilots of those planes are sitting at a console somewhere in Nevada. But that debate hasn't slowed a global push in UAVs. They're cheaper, fewer of your own personnel are put at risk. It's the future.\nThe U.S. has been using Predator drones for a while now. But Predator was built as a spy plane, then retrofitted to carry weapons. Predator is being phased out in favor of a plane called the Reaper.\nWe're joined by Gary Solis. He's an adjunct professor at Georgetown University School of Law and teaches the law of war. As for the difference between the Predator and the Reaper, he says the Reaper \"is bigger, better, faster and has a greater payload. It weighs 5 tons, which is 4x what a Predator weighs. Predator can carry 2 hellfire missiles while a reaper can carry 14. A Predator can fly 140 MPH, Reaper can fly 275 MPH depending on payload.\"\nAt the same time, other countries are developing their own technology and their own drones. Gary talks about one surveillance vehicle out of Israel that essentially looks like a pencil with helicopter blades.\nAlso in this program, Rupert Murdoch plans to launch a newspaper for iPads. Because what everyone wants from the technology of an iPad is to have it be more like a printed newspaper.", "label": 1}
{"text": "what is the difference between authentication and authorization\nAuthentication is the process of obtaining identification credentials such as name and password from a user and validating those credentials against some authority. If the credentials are valid, the entity that submitted the credentials is considered an authenticated identity. Once an identity has been authenticated, the authorization process determines whether that identity has access to a given resource.\nThe purpose of authorization is to determine whether an identity should be granted the requested type of access to a given resource\nIf you are facing any programming issue, such as compilation errors or not able to find the code you are looking for.\nAsk your questions, our development team will try to give answers to your questions.", "label": 1}
{"text": "HIPAA Privacy Rule and Public Health\nGuidance from CDC and the U.S. Department of Health and Human Services*\nThe material in this report originated in the Epidemiology Program Office, Stephen B. Thacker, M.D., M.Sc., Director.\nNew national health information privacy standards have been issued by the U.S. Department of Health and Human Services (DHHS), pursuant to the Health Insurance Portability and Accountability Act of 1996 (HIPAA). The new regulations provide protection for the privacy of certain individually identifiable health data, referred to as protected health information (PHI). Balancing the protection of individual health information with the need to protect public health, the Privacy Rule expressly permits disclosures without individual authorization to public health authorities authorized by law to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability, including but not limited to public health surveillance, investigation, and intervention.\nPublic health practice often requires the acquisition, use, and exchange of PHI to perform public health activities (e.g., public health surveillance, program evaluation, terrorism preparedness, outbreak investigations, direct health services, and public health research). Such information enables public health authorities to implement mandated activities (e.g., identifying, monitoring, and responding to death, disease, and disability among populations) and accomplish public health objectives. Public health authorities have a long history of respecting the confidentiality of PHI, and the majority of states as well as the federal government have laws that govern the use of, and serve to protect, identifiable information collected by public health authorities.\nThe purpose of this report is to help public health agencies and others understand and interpret their responsibilities under the Privacy Rule. Elsewhere, comprehensive DHHS guidance is located at the HIPAA website of the Office for Civil Rights (http://www.hhs.gov/ocr/hipaa/).\nThe shift of medical records from paper to electronic formats has increased the potential for individuals to access, use, and disclose sensitive personal health data. Although protecting individual privacy is a long-standing tradition among health-care providers and public health practitioners in the United States, previous legal protections at the federal, tribal, state, and local levels were inconsistent and inadequate. A patchwork of laws provided narrow privacy protections for selected health data and certain keepers of that data (1).\nThe U.S. Department of Health and Human Services (DHHS) has addressed these concerns with new privacy standards that set a national minimum of basic protections, while balancing individual needs with those of society. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) was adopted to ensure health insurance coverage after leaving an employer and also to provide standards for facilitating health-care--related electronic transactions. To improve the efficiency and effectiveness of the health-care system, HIPAA included administrative simplification provisions that required DHHS to adopt national standards for electronic health-care transactions (2). At the same time, Congress recognized that advances in electronic technology could erode the privacy of health information. Consequently, Congress incorporated into HIPAA provisions that mandated adoption of federal privacy protections for certain individually identifiable health information.\nThe HIPAA Privacy Rule (Standards for Privacy of Individually Identifiable Health Information) (3) provides the first national standards for protecting the privacy of health information. The Privacy Rule regulates how certain entities, called covered entities, use and disclose certain individually identifiable health information, called protected health information (PHI). PHI is individually identifiable health information that is transmitted or maintained in any form or medium (e.g., electronic, paper, or oral), but excludes certain educational records and employment records. Among other provisions, the Privacy Rule\nThe deadline to comply with the Privacy Rule is April 14, 2003, for the majority of the three types of covered entities specified by the rule [45 CFR § 160.102]. The covered entities are\nAt DHHS, the Office for Civil Rights (OCR) has oversight and enforcement responsibilities for the Privacy Rule. Comprehensive guidance and OCR answers to hundreds of questions are available at http://www.hhs.gov/ocr/hipaa (4).\nImpact on Public Health\nPublic health practice and research, including such traditional public health activities as program operations, public health surveillance, program evaluation, terrorism preparedness, outbreak investigations, direct health services, and public health research, use PHI to identify, monitor, and respond to disease, death, and disability among populations. Public health authorities have a long history of protecting and preserving the confidentiality of individually identifiable health information. They also recognize the importance of protecting individual privacy and respecting individual dignity to maintaining the quality and integrity of health data. CDC and others have worked to consistently strengthen federal and state public health information privacy practices and legal protections (5).\nDHHS recognized the importance of sharing PHI to accomplish essential public health objectives and to meet certain other societal needs (e.g., administration of justice and law enforcement). Therefore, the Privacy Rule expressly permits PHI to be shared for specified public health purposes. For example, covered entities may disclose PHI, without individual authorization, to a public health authority legally authorized to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability [45 CFR § 164.512(b)] (Box 1). Further, the Privacy Rule permits covered entities to make disclosures that are required by other laws, including laws that require disclosures for public health purposes.\nThus, the Privacy Rule provides for the continued functioning of the U.S public health system. Covered entities should become fully aware of the scope of permissible disclosures for public health activities as well as state and local reporting laws and regulations. Moreover, a public health authority may also be a covered entity. For example, a public health agency that operates a health clinic, providing essential health-care services and performing covered transactions electronically, is a covered entity.\nThis report provides guidance to public health authorities and their authorized agents, researchers, and health-care providers in interpreting the Privacy Rule as it affects public health. CDC recommends that public health authorities share the information in this report with covered health-care providers and other covered entities and work closely with those entities to ensure implementation of the rule consistent with its intent to protect privacy while permitting authorized public health activities to continue.\nOverview of the Privacy Rule\nWho Is Covered\nThe authority of DHHS to issue health-information privacy regulations was limited by Congress in HIPAA to a defined set of covered entities. More complete definitions of these, and other terms, are located elsewhere in this report (Appendix A). Covered entities are as follows:\nThe Privacy Rule also establishes requirements for covered entities with regard to their nonemployee business associates (e.g., lawyers, accountants, billing companies, and other contractors) whose relationship with covered entities requires sharing of PHI. The Privacy Rule allows a covered provider or health plan to disclose PHI to a business associate if satisfactory written assurance is obtained that the business associate will use the information only for the purposes for which it was engaged, will safeguard the information from misuse, and will help the covered entity comply with certain of its duties under the Privacy Rule.\nThe Privacy Rule does not apply to all persons or entities that regularly use, disclose, or store individually identifiable health information. For example, the Privacy Rule does not cover employers, certain insurers (e.g., auto, life, and worker compensation), or those public agencies that deliver social security or welfare benefits, when functioning solely in these capacities.\nTypes of Health Information\nProtected Health Information\nThe Privacy Rule protects certain information that covered entities use and disclose. This information is called protected health information (PHI), which is generally individually identifiable health information that is transmitted by, or maintained in, electronic media or any other form or medium. This information must relate to 1) the past, present, or future physical or mental health, or condition of an individual; 2) provision of health care to an individual; or 3) payment for the provision of health care to an individual. If the information identifies or provides a reasonable basis to believe it can be used to identify an individual, it is considered individually identifiable health information.\nDe-identified data (e.g., aggregate statistical data or data stripped of individual identifiers) require no individual privacy protections and are not covered by the Privacy Rule. De-identifying can be conducted through\nIn certain instances, working with de-identified data may have limited value to clinical research and other activities. When that is the case, a limited data set may be useful.\nLimited Data Sets\nHealth information in a limited data set is not directly identifiable, but may contain more identifiers than de-identified data that has been stripped of the 18 identifiers [45 CFR § 164.514] (Box 3). A data-use agreement must establish who is permitted to use or receive the limited data set, and provide that the recipient will\nWhat is Required\nFor covered entities using or disclosing PHI, the Privacy Rule establishes a range of health-information privacy requirements and standards that attempt to balance individual privacy interests with the community need to use such data [45 CFR § 164.504]. Among its provisions, the Privacy Rule requires covered entities to\nWith respect to individuals, they are vested with the following rights:\nRequired PHI Disclosures\nA covered entity is required by the Privacy Rule to disclose PHI in only two instances: 1) when an individual has a right to access an accounting of his or her PHI (see previous paragraph); and 2) when DHHS needs PHI to determine compliance with the Privacy Rule [45 CFR § 164.502(a)(2)]. Certain other uses and disclosures of PHI may be permitted without authorization, but are not required by the Privacy Rule. However, other federal, tribal, state, or local laws may compel disclosure.\nPermitted PHI Disclosures Without Authorization\nThe Privacy Rule permits a covered entity to use and disclose PHI, with certain limits and protections, for TPO activities [45 CFR § 164.506]. Certain other permitted uses and disclosures for which authorization is not required follow. Additional requirements and conditions apply to these disclosures. The Privacy Rule text and OCR guidance should be consulted for a full understanding of the following:\nOther Authorized Disclosures\nA valid authorization is required for any use or disclosure of PHI that is not required or otherwise permitted without authorization by the Privacy Rule. In general, these authorizations must\nThe Privacy Rule and Public Health\nThe Privacy Rule recognizes 1) the legitimate need for public health authorities and others responsible for ensuring the public's health and safety to have access to PHI to conduct their missions; and 2) the importance of public health reporting by covered entities to identify threats to the public and individuals. Accordingly, the rule 1) permits PHI disclosures without a written patient authorization for specified public health purposes to public health authorities legally authorized to collect and receive the information for such purposes, and 2) permits disclosures that are required by state and local public health or other laws. However, because the Privacy Rule affects the traditional ways PHI is used and exchanged among covered entities (e.g., doctors, hospitals, and health insurers), it can affect public health practice and research in multiple ways. To prevent misconceptions, understanding the Privacy Rule is important for public health practice. Some illustrative examples are presented in this report (Box 4). Also provided are sample letters that might prove useful in clarifying relationships involving public health and the Privacy Rule (Appendix B).\nA public health authority is broadly defined as including agencies or authorities of the United States, states, territories, political subdivisions of states or territories, American Indian tribes, or an individual or entity acting under a grant of authority from such agencies and responsible for public health matters as part of an official mandate. Public health authorities include federal public health agencies (e.g., CDC, National Institutes of Health [NIH], Health Resources and Services Administration [HRSA], Substance Abuse and Mental Health Services Administration [SAMHSA], Food and Drug Administration [FDA], or Occupational Safety and Health Administration [OSHA]); tribal health agencies; state public health agencies (e.g., public health departments or divisions, state cancer registries, and vital statistics departments); local public health agencies; and anyone performing public health functions under a grant of authority from a public health agency [45 CFR § 164.501].\nPublic health agencies often conduct their authorized public health activities with other entities by using different mechanisms (e.g., contracts and memoranda or letters of agreement). These other entities are public health authorities under the Privacy Rule with respect to the activities they conduct under a grant of authority from such a public health agency. A covered entity may disclose PHI to public health authorities and to these designated entities pursuant to the public health provisions of the Privacy Rule.\nThe Privacy Rule permits covered entities to disclose PHI, without authorization, to public health authorities or other entities who are legally authorized to receive such reports for the purpose of preventing or controlling disease, injury, or disability. This includes the reporting of disease or injury; reporting vital events (e.g., births or deaths); conducting public health surveillance, investigations, or interventions; reporting child abuse and neglect; and monitoring adverse outcomes related to food (including dietary supplements), drugs, biological products, and medical devices [45 CFR 164.512(b)]. Covered entities may report adverse events related to FDA-regulated products or activities to public agencies and private entities that are subject to FDA jurisdiction [45 CFR 164.512(b)(1)(iii)]. To protect the health of the public, public health authorities might need to obtain information related to the individuals affected by a disease. In certain cases, they might need to contact those affected to determine the cause of the disease to allow for actions to prevent further illness. Also, covered entities may, at the direction of a public health authority, disclose protected health information to a foreign government agency that is acting in collaboration with a public health authority [45 CFR 164.512(b)(1)(i)].\nTo receive PHI for public health purposes, public health authorities should be prepared to verify their status and identity as public health authorities under the Privacy Rule. To verify its identity, an agency could provide any one of the following:\nPublic health authorities receiving information from covered entities as required or authorized by law [45 CFR 164.512(a)] [45 CFR 164.512(b)] are not business associates of the covered entities and therefore are not required to enter into business associate agreements. Public health authorities that are not covered entities also are not required to enter into business associate agreements with their public health partners and contractors. Also, after PHI is disclosed to a public health authority pursuant to the Privacy Rule, the public health authority (if it is not a covered entity) may maintain, use, and disclose the data consistent with the laws, regulations, and policies applicable to the public health authority.\nDisclosures for Public Health Purposes\nThe Privacy Rule allows covered entities to disclose PHI to public health authorities when required by federal, tribal, state, or local laws [45 CFR 164.512(a)]. This includes state laws (or state procedures established under such law) that provide for receiving reporting of disease or injury, child abuse, birth, or death, or conducting public health surveillance, investigation, or intervention.\nFor disclosures not required by law, covered entities may still disclose, without authorization, to a public health authority authorized by law to collect or receive the information for the purpose of preventing or controlling disease, injury, or disability, the minimum necessary information to accomplish the intended public health purpose of the disclosure [45 CFR 164.512 (b)] (Box 1).\nFor example, to protect the health of the public, public health officials might need to obtain information related to persons affected by a disease. In certain cases, they might need to contact those affected to determine the cause of the disease to allow for actions to prevent further illness. The Privacy Rule continues to allow for the existing practice of sharing PHI with public health authorities who are authorized by law to collect or receive such information to aid them in their mission of protecting the health of the public. Examples of such activities include those directed at the reporting of disease or injury, reporting adverse events, reporting births and deaths, and investigating the occurrence and cause of injury and disease (1).\nAlthough it is not a defined term, DHHS interpreted the phrase \"authorized by law\" to mean that a legal basis exists for the activity. Further, DHHS called the phrase \"a term of art,\" including both actions that are permitted and actions that are required by law [64 FR 59929, November 3, 1999]. This does not mean a public health authority at the federal, tribal, state, or local level must have multiple disease or condition-specific laws that authorize each collection of information. Public health authorities operate under broad mandates to protect the health of their constituent populations.\nRequirements for Covered Entities\nAccounting for Public Health Disclosures\nAlthough the Privacy Rule permits disclosures of PHI to public health authorities, covered entities must comply with certain requirements related to these disclosures. One such requirement is that a covered entity must be able to provide an individual, upon request, with an accounting of certain disclosures of PHI. The covered entity is not required to account for all disclosures of PHI. For example, an accounting is not required for disclosures made\nHowever, usually an accounting is required for disclosures made without authorization, including public health purposes.\nThe required accounting for disclosures may be accomplished in different ways. Typically, the covered entity must provide the individual with an accounting of each disclosure by date, the PHI disclosed, the identity of the recipient of the PHI, and the purpose of the disclosure. However, where the covered entity has, during the accounting period, made multiple disclosures to the same recipient for the same purpose, the Privacy Rule provides for a simplified means of accounting. In such cases, the covered entity need only identify the recipient of such repetitive disclosures, the purpose of the disclosure, and describe the PHI routinely disclosed. The date of each disclosure need not be tracked. Rather, the accounting may include the date of the first and last such disclosure during the accounting period, and a description of the frequency or periodicity of such disclosures. For example, the vast amount of data exchanged between covered entities and public health authorities is made through ongoing, regular reporting or inspection requirements. A covered health-care provider may routinely report all cases of measles it diagnoses to the local public health authority. An accounting of such disclosures to a requesting individual would need to identify the local public health authority receiving the PHI, the PHI disclosed, the purpose of the disclosure (required for communicable disease surveillance), the periodicity (weekly), and the first and last dates of such disclosures during the accounting period (May 1, 2003 to June 1, 2003). Thus, the covered entity would not need to annotate each patient's medical record whenever a routine public health disclosure was made.\nNotice of Privacy Practices\nWith certain exceptions, under the Privacy Rule, individuals have the right to adequate notice of the uses and disclosures of PHI that may be made by the covered entity, as well as their rights and the covered entity's legal obligations. Notices must be in plain language and clearly posted. Certain covered entities must make a good faith effort to obtain an individual's acknowledgment of receipt of this notice. In certain cases, notice may be provided electronically.\nMinimum Necessary Standard\nThe Privacy Rule usually directs covered entities to limit the amount of information disclosed to the minimum necessary to achieve the specified goal [45 CFR § 164.514(d)(1)]. This requirement usually applies to disclosures to a public health agency. It would not apply, however, if the disclosure were required by law, authorized by the individual, or for treatment purposes. A covered entity may also reasonably rely on a public official's determination that the information requested is the minimum necessary for the public health purpose.\nPublic Health Authorities Performing Covered Functions\nPublic health authorities at the federal, tribal, state, or local levels that perform covered functions (e.g., providing health care or insuring individuals for health-care costs), may be subject to the Privacy Rule's provisions as covered entities. For example, a local public health authority that operates a health clinic providing essential health-care services to low-income persons and performs certain electronic transactions might be defined under the Privacy Rule as a covered health-care provider and therefore a covered entity. Flow charts and interactive tools designed to help determine covered entity status are provided online by the Centers for Medicare and Medicaid Services, available at http://www.cms.gov/hipaa/hipaa2/support/tools/decisionsupport/default.asp.\nThe following are examples of public health authority functions that make them covered entities:\nThe Privacy Rule and Public Health Research\nThe topic of research under the Privacy Rule is covered in depth in the DHHS report, Protecting Personal Health Information in Research --- Understanding the HIPAA Privacy Rule (6). The Privacy Rule provides separate provisions for disclosure without individual authorization for public health purposes and for certain research [45 CFR § 164.512(b)] [45 CFR § 164.512(i)]. Other federal law pertaining to research stresses the importance of distinguishing between research and practice to ensure that human subjects are appropriately protected [45 CFR Part 46]. For certain activities, this distinction is not always clear. A full discussion of the distinctions between public health practice and research is beyond the scope of this document. However, CDC and others provide guidance in this area (7--9).\nResearch Versus Practice\nThe definition of research is the same for the Privacy Rule and the Common Rule (10) --- systematic investigation, including research development, testing, and evaluation, designed to develop or contribute to generalizable knowledge. Research is designed to test a hypothesis, permit conclusions to be drawn, and thereby to develop or contribute to generalizable knowledge. The majority of public health activities (e.g., public health surveillance, and disease prevention and control projects) are based on scientific evidence and data collection or analytic methods similar to those used in research. However, they are not designed to contribute to generalizable knowledge. Their primary purpose is to protect the health of the population through such activities as disease surveillance, prevention, or control.\nThe Belmont Report (11) defines practice as interventions designed solely to enhance the well-being of a person, patient, or client, and which have reasonable expectation of success. The report further states that the purpose of medical or behavioral practice is to provide diagnosis, preventive treatment, or therapy to particular patients. For public health agencies, the patient is the community. Public health practice activities (e.g., public health surveillance, disease control, or program evaluation) are undertaken with the intent to benefit a specific community, although occasionally they may provide unintended generalizable benefits to others.\nSome public health activities that are initially public health practice may subsequently evolve into a research activity (e.g., an investigation to determine the cause of an outbreak that incorporates a research study evaluating the efficacy of a new drug to treat the illness). When that is the case, the disclosures may be made initially under the public health provisions of the Privacy Rule. But when the activity becomes an ongoing research activity, the entity should consider application of the relevant research disclosures provisions to continue to obtain information for this purpose. Moreover, there may be cases where the activity is both research and public health practice (e.g., an ongoing survey to monitor health conditions in the population, data from which can also be analyzed for research purposes). In those cases, disclosures may be made either under the research provisions or the public health provisions, as appropriate --- the covered entity need not comply with both sets of requirements.\nThe Privacy Rule and Other Laws\nReferences to non-DHHS sites on the Internet are provided as a service to MMWR readers and do not constitute or imply endorsement of these organizations or their programs by CDC or the U.S. Department of Health and Human Services. CDC is not responsible for the content of these sites. URL addresses listed in MMWR were current as of the date of publication.\nFederal Government Resources\nDHHS Office for Civil Rights --- HIPAA guidelines\nCDC --- Privacy Rule guidelines\nCenters for Medicare and Medicaid Services\nHealth Resources and Services Administration --- HIPAA\nNational Center for Health Statistics\nNational Committee on Vital and Health Statistics\nNational Health Information Infrastructure\nIndian Health Service --- HIPAA\nNational Institutes of Health\nSubstance Abuse and Mental Health Services Administration --- HIPAA\nState Government Resources\nAssociations, Nonprofit Organizations, and Academic Resources\nAmerican Hospital Association --- HIPAA\nAmerican Medical Association --- HIPAA\nAssociation of State and Territorial Health Officials --- HIPAA\nGeorgetown University Health Privacy Project\nJoint Healthcare Information Technology Alliance\nNational Association of Health Data Organizations\nNational Association of Insurance Commissioners\nNational Governors Association --- HIPAA\nNorth Carolina Healthcare Information and Communications Alliance\nPublic Health Grand Rounds HIPAA Privacy Rule: Enhancing or Harming Public Health?\nStanford University Medical School --- HIPAA\nWorkgroup for Electronic Data Interchange --- Strategic National Implementation Process\nThis report was prepared by Salvatore Lucido, M.P.A., and Denise Koo, M.D., Office of the Associate Director for Science, Epidemiology Program Office, CDC, in collaboration with James G. Hodge, Jr., J.D., Center for Law and the Public's Health, Georgetown and Johns Hopkins Universities, Baltimore, Maryland. The preparers are grateful for the participation of Deborah Tress, J.D., Kenya Ford, J.D., and Heather Horton, J.D., Office of the General Counsel, Department of Health and Human Services, CDC/ATSDR Branch; the CDC Working Group on the Privacy Rule; and Beverly Dozier, J.D., Lance A. Gable, J.D., Lawrence O. Gostin, J.D., Gail Horlick, J.D., and Jennifer Kurle.\nThe preparers also thank the following partners for their valuable input: Association of State and Territorial Health Officers, Council of State and Territorial Epidemiologists, National Association of County and City Health Officials, National Association of Health Data Organizations, Association of Public Health Laboratories, and National Association for Public Health Statistics and Information Systems.\n* Prepared by CDC staff, in consultation with the Office of the General Counsel, the Office for Civil Rights, other offices and agencies within the U.S. Department of Health and Human Services, Washington, D.C., and health privacy specialists.Box 1\nReturn to top.\nReturn to top.\nReturn to top.\nReturn to top.\nDisclaimer All MMWR HTML versions of articles are electronic conversions from ASCII text into HTML. This conversion may have resulted in character translation or format errors in the HTML version. Users should not rely on this HTML document, but are referred to the electronic PDF version and/or the original MMWR paper copy for the official text, figures, and tables. An original paper copy of this issue can be obtained from the Superintendent of Documents, U.S. Government Printing Office (GPO), Washington, DC 20402-9371; telephone: (202) 512-1800. Contact GPO for current prices.**Questions or messages regarding errors in formatting should be addressed to email@example.com.\nPage converted: 4/11/2003\nThis page last reviewed 4/11/2003", "label": 1}
{"text": "Apr. 11, 2011 The Internet has no borders, no universal legislation, and although highly social and distributed is not represented by cooperation across the globe. Given those characteristics how might nations make their plans for counter terrorism in cyberspace as active online as they are in the everyday world?\nA collaboration between researchers in the US and Iran hoped to address that issue and its findings are published this month in the International Journal of Internet Technology and Secured Transactions.\nIncidence of online crime has grown considerably in recent years, with terms such as malware, Trojans, bot-nets and phishing attacks entering the common vernacular. There has also been a significant increase in activity that might at best be described as international commercial sabotage but that some would label more sensationally as cyber-terrrorism. Much of the illicit activity that leads to internet outages, malware infections and other virtual atrocities are being carried out with purely criminal intent. However, there are alleged attacks orchestrated by whole nations against other countries, corporations and organizations that might truly be described more accurately as a form of terrorism.\nArash Barfar from the University of South Florida in Tampa and Kiyana Zolfaghar and her colleague from the KN Toosi University of Technology in Tehran, suggest that the first step that must be taken to surmount the barriers of failed cooperation and legislation is to organize national efforts to use \"web mining\" techniques and \"honeypots\" to wheedle out cyber-terrorists before they attack.\n\"The internet is a very important channel not only for communication, but also for searching information and for doing business, the pattern of counter terrorism should efficiently reflect that,\" the team says. They have now developed a framework that would allow leaders to develop and use the necessary tools to trace cyber terrorists effectively in real-time and to make arrests before any potentially debilitating attack were to take place.\nJournal: \"A framework for cyber war against international terrorism\" in Internet Technology and Secured Transactions, 2011, 3, 29-39\nOther social bookmarking and sharing tools:\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "Posted by Usman Sindhu on February 19, 2010\nJust this Tuesday, February 16th 2010, the Bipartisan Policy Center hosted a mock cyber attack called Cyber Shockwave. The aim of this simulation was to understand the impacts of a cyber attack and assess infrastructure capability during such an incident. There are many articles explaining the motive and results of this simulation, and post mortem is still coming as we speak.\nSo, what did the simulation entail? It depicted a war game taking place in 2011 – basically an application installed on smart phones during ‘March Madness’ thatturned out to be a malware. This hypothetical malware affected telecom and IT infrastructure throughout the country, with the result actually bringing down the nation’s cellular network...but there is more. According to an article from ‘The Atlantic Wire’:\n“Later, two bombs disabled the country's electricity network and destroyed gas pipelines... Soon 60 million cellphones were dead. The Internet crashed, finance and commerce collapsed, and most of the nation's electric grid went dark. White House aides discussed putting the Army in American cities.”\nAlso, according to an article from DarkReading:\n“During the exercise, a server hosting the attack appeared to be based in Russia,\" said one report. \"However, the developer of the malware program was actually in the Sudan. Ultimately, the source of the attack remained unclear during the event.\"\nOne must be thinking, it’s a pretty scary picture. Well yes, but again, it’s a simulation. What is more important is to understand how we would tackle such a scenario.\nMany critics argue that this simulation showed a clear inability to identify the source of this attack and therefore, inability to take immediate action. Cyber attacks are not new; they have existed from the advent of the Internet. And there is plenty of evidence to show that attacks are being launched continuously from internal and external sources. What's new here is this wave of making our critical infrastructure like utilities, healthcare, government services, education, and transportation more IT enabled or ‘Smart’. Smart infrastructure poses new risks and threats, the majority of which are not even identified yet.\nThis simulation serves as a wakeup call and it serves to enlighten our government officials that cyber security needs to be taken seriously. We need a better risk assessment approach as a proactive measure but we also need architecture that mitigates these attacks when they happen. To drive this, multiple constituencies must come to the drawing board in early phases of smart infrastructure deployments. There are many folks that need to get involved in this ecosystem, including government officials and CIOs of infrastructure companies (utilities, telecom, etc.). The private sector faces these types of security concerns regularly. There is lot to be learned from financial, manufacturing, and retail environments. To a large extent, they also have sophisticated security and risk management techniques and technologies, with components ranging from physical hardware, software, and communication infrastructure.\nWe’re still at an early phase of figuring this out…however, there is strong momentum at the White House as well as in security communities at large to acknowledge the importance of cyber security and collaborate to address it.\nOne last thing: be careful installing applications during March Madness on your smart phone J ...\nAs always, I’ll love to hear your thoughts about this and any insight you have.", "label": 1}
{"text": "Security systems could be more effective if officials looked at how organisms deal with threats in the natural world, University of Arizona researchers suggest in the May 20 edition of the journal Nature.\nThe authors are working with security and disaster management officials to help put some of their recommendations - such as decentralizing forces and forming alliances - into practice.\n\"Anytime you have the illusion of full security, you get adaptation,\" said Rafe Sagarin, an assistant research scientist in the UA's Institute of the Environment who is the lead author of the opinion piece. \"Terrorists figure out unexpected means of attack, hackers come up with new software to break through firewalls, and pathogens develop resistance to antibiotics.\"\nInstead of relying on large, centralized bureaucracies that move slowly and often lag behind in addressing threats, the authors encourage officials to look to the natural world for principles that could prove less costly, more flexible and more effective at countering threats.\nThe security issues of modern human societies are analogous to those of many organisms, according to Sagarin and his co-authors. In nature, risks are frequent, variable and uncertain. Over billions of years, organisms have evolved an enormous variety of methods to survive, grow and proliferate on a continually changing planet. The key to their success is their ability to quickly adapt to rapidly changing threats, and change their structures, behaviors and interactions accordingly.\nUnlike many security agencies or entities in the human world, the most adaptable and successful organisms avoid centralization. Instead, they distribute tasks among decentralized, specialized groups of cells or individuals.\nSagarin points to the octopus' camouflaging strategy to illustrate this principle: Its networks of pigment cells, distributed all over its body, react to and match the colors of the surroundings, blending the animal into the background.\n\"We can learn something from the octopus about the war in Iraq and Afghanistan,\" Sagarin said, specifically with regard to the threat from improvised explosive devices, or IEDs.\nJust like the octopus' decentralized network of pigment cells, he pointed out, troops on the ground function like independent sensors that can assess a threat more accurately, more timely and more realistically than a large, centralized organization that is geographically removed from the action and largely follows a top-down approach of command.\n\"The individual soldiers in the war zone are the most adaptable unit out there,\" he said. \"They are in a better position to recognize and address an emerging threat in time than a centralized bureaucracy.\"\nSagarin and co-authors point out that terrorist networks such as Al Qaida have recognized the advantages of this approach and operate a loose network of largely independent subgroups.\n\"About 1,500 soldiers had died from roadside bomb blasts between the time troops identified the threat and the time MRAPs (mine-resistant, ambush-protected vehicles) were deployed to deal with the situation.\"\nEven after the blast-resistant vehicles arrived, they proved only moderately effective against a quickly moving threat that is constantly changing and rapidly adapting to new challenges.\n\"These MRAPs are huge, lumbering things that weigh 16 tons,\" Sagarin said, \"The insurgents, on the other hand, drive around in small pickup trucks. They quickly figured out the MRAPs were limited to certain roads and started placing roadside bombs specifically along those routes.\"\nLet the attacker know you're ready\nAnother lesson could be learned by looking at how organisms deal with the constant threat from predators, according to the authors. A key feature is the capacity to reduce uncertainty and turn it into an advantage.\nHunting prey uses a lot of energy, Sagarin explained, which is why predators seek to ambush their prey. As soon as the prey is aware of their presence and ready to engage in defense, a pursuit might no longer be worth it.\nGround squirrels, for example, use alarm signals when a predator is lurking nearby, not only to warn their peers, but also to make it known to the attacker its cover is blown.\n\"When a prey species makes an alarm call of any kind, the game is up,\" Sagarin said. Suddenly, things have become a lot harder - if you're a hawk, you want to swoop down on a squirrel and not get scratched in the face.\"\nRemarkably, ground squirrels use alarm signals that are very specific to the threat. If the predator is a mammal (which can hear), they utter alarm calls. If it is a snake (which cannot) they use tail-flagging to signal its presence.\nThe less specific an alarm call is, the less efficient it is in eliciting an appropriate response, the authors argue and point to the U.S. Homeland Security's threat advisory for national and international flights, which has remained at level orange (high) since August 2006. This static, ambiguous and nonspecific system creates uncertainty or indifference among the population that it is meant to help protect.\nAnother principle often observed in nature is symbiosis, the formation of allies.\n\"Symbiosis is not always between friends,\" Sagarin said, pointing to the example of cleaner wrasses, small fish specializing in picking parasites off other marine animals, sometimes entering their mouths. The clients could easily swallow the cleaner wrasse while it is going about its job.\n\"But they don't,\" Sagarin said. \"It's a mutual beneficial relationship in which the larger fish provides the cleaner fish with a food source and protection, and the cleaner keeps it free from parasites in return.\"\nA lesson of how symbioses can successfully be applied in the human realm was demonstrated in Iraq in 2007, the authors note, when Gen. David Petraeus's strategy to form alliances with local leaders - including those who had been hostile - resulted in more tip-offs about IEDs and fewer American casualties.\nTwo years ago, Sagarin and colleagues published a book titled \"Natural Security: A Darwinian Approach to a Dangerous World.\" The research group has since begun to \"make its observations more actionable for the people on the ground,\" as Sagarin put it. Working with emergency management coordinators, cybersecurity experts, soldiers, police chiefs, air marshals, homeland security officials, fire chiefs and public health officials, the group's ideas have generated a lot of interest.\n\"One of the main lessons we learned is that issuing challenges is more effective than giving orders when there is a need to develop security measures,\" Sagarin said. He pointed to the DARPA Grand Challenge as an example, in which the Defense Advanced Research Projects Agency of the Department of Defense put on a prize competition for the development of a driver-less vehicle capable of navigating difficult terrain on its own.\n\"Anytime you pose a challenge, not only do you get a diverse population of problem solvers, but you get them to learn from each another.\"\nHowever, despite decentralization, it is important to still have an overarching structure to provide guidance and encourage the development of new ideas.\n\"An octopus is still an octopus,\" Sagarin said, \"not just a random collection of cells.\"\n\"The bottom line of all this is, you can't just put up a wall around something and expect it to protect it against every possible threat. Attackers will always figure out a way.\"\nExplore further: 'Images of the inside of a fly' elected as computed microtomography's Best Film of the Year\n\"Decentralise, adapt and cooperate,\" Rafe Sagarin et al., Nature, Vol. 465, May 20, 2010.\n\"Natural Security - A Darwinian Approach to a Dangerous World,\" Raphael Sagarin and Terence Taylor, University of California Press, 2008.", "label": 1}
{"text": "August 3, 2011: The U.S. Department of Defense has long advocated going on the offensive against criminal gangs and foreign governments that seek (and often succeed) to penetrate U.S. government and military Internet security, and steal information, or sabotage operations. Without much fanfare, the Department of Defense has made preparations to do just that.\nSince the military cannot afford to pay enough to recruit qualified software and Internet engineers for this sort of work, it has turned to commercial firms. There are already some out there, firms that are technically network security companies, but will also carry out offensive missions (often of questionable legality, but that has always been an aspect of the corporate security business.)\nSome of these firms have quietly withdrawn from the Internet security business, gone dark, and apparently turned their efforts to the more lucrative task of creating Cyber War weapons for the Pentagon. It may have been one of these firms that created, or helped create, the Stuxnet worm.\nAn Internet worm is a computer program that constantly tries to copy itself to other computers. Stuxnet was a worm designed, very skillfully, as a weapons grade cyber weapon. The first \"real one\" as Internet security experts came to call it. While released in late 2009, Stuxnet was not discovered until last year, and engineers are still dissecting it, and continue to be amazed at what a powerful Cyber War weapon it is. Stuxnet is the first live example of a first class Cyber War weapon, which means more are on the way (or sitting on someone's hard drive waiting to be deployed.)\nThe success of Stuxnet, and similar worms believed to be out there, may be responsible for more Internet security companies moving over to the Cyber War weapons business. The most dangerous Cyber War weapons are those that, like Stuxnet, take advantage of largely unknown Internet vulnerabilities. These allow the attacker access to many business, government and military computers. This sort of thing is called, \"using high value exploits\" (flaws in code that are not yet widely known). Finding these exploits is expensive, and requires even more skill to use. For a long time, a major source of exploits was hackers for hire. These are skilled hackers, who know they are working on the wrong side of the law, and know how to do the job, take the money, and run. This situation has developed because organized crime has discovered the Internet, and the relatively easy money to be made via Internet extortion and theft.\nBut now commercial firms are hiring hackers and paying them good money to find and \"weaponize\" these exploits. It is believed that those nations that have Cyber War organizations, maintain arsenals of exploits. But exploits have a short shelf-life. Nearly all exploits eventually come to the attention of the publisher that created the exploitable software, and gets fixed.\nHowever, not every user applies the \"patches\", so there will always be some computers out there that are still vulnerable. But that makes \"zero day exploits\" (discovered and used for the first time) very valuable. That's because you can use these exploits on any computer with the flawed software on it. While your average zero day exploit costs up to $100,000, or more, to discover, it is not useful for very long. Thus it is expensive to maintain an exploits arsenal, as you must keep finding new exploits to replace those which are patched into ineffectiveness.\nMost of the Internet combat so far has been done under peacetime conditions. In wartime, it's possible (especially for the United States) to cut off enemy countries from the Internet. Thus potential American foes want to maintain an official peacetime status, so the United States cannot use its ability to cut nations off (or nearly off) from the Internet, and remove easy access to American (and Western) targets. Thus the need to make attacks discreetly, so as to make it more difficult for an enemy to target stronger attacks against you, or threaten nuclear or conventional war.", "label": 1}
{"text": "Safari 6 (OS X Mountain Lion): Identify secure websites and avoid frauds\nWhen you use a website that handles private or financial information, make sure the website is encrypted.\nWhen you go to an encrypted webpage—for instance, to do online banking—Safari checks the website’s certificate and compares it with certificates that are known to be legitimate. If Safari doesn’t recognize the website’s certificate, or if the website doesn’t have one, Safari displays a warning message.\nSafari also checks lists of fraudulent websites that have been identified by security services. If you attempt to visit one of these websites, Safari displays a warning message.\nLook for a Security button\nA Security button near the left end of the address and search field means that the website uses the HTPPS protocol and has a digital identity certificate. Information is encrypted to keep it private as it’s sent to or from the website.\nThe Security button, which has a lock icon inside it, can be gray or green.\n- A gray Security button means the website has a standard certificate.\n- A green Security button means the website has an Extended Validation (EV) certificate, which requires more extensive identity verification than a standard certificate. A green Security button shows the name of the EV certificate owner.\nTo view the contents of a website’s certificate, click the Security button.\nUse a secure connection, if available\nIf a Security button isn’t shown for a website, you may have been given a choice between a secure and an insecure connection when logging in to the site. Go back to the page where you logged in and check for a link to an encrypted (or secure) login. Even if you don’t plan to view private information, it’s best to use an encrypted login whenever possible to ensure that your login information and any other information you send are private.\nHow to respond to a certificate warning\n- Click Show Certificate, and inspect the certificate for suspicious information.\nLook for a message that says the certificate is not trusted, or was signed by an untrusted issuer. If you see a message like that, click Cancel, and do not go to the website.\nClick the triangle next to the word “Details.” Check to make sure that the name and organization match those of the person or organization that owns the website. If anything looks unusual or is not what you expect, click Cancel, and do not go to the website.\nIf you continue to the website, double-check the address in the Safari toolbar to confirm that it is the correct address for the page you want to visit. The name of the website should be spelled correctly. Sometimes fraudulent websites masquerade as trusted websites by changing one or two letters of the trusted website’s address.\n- Contact the administrator of the website, explain the problem, and request more information.\nIf you continue, the certificate is stored on your computer, and this warning isn’t displayed again for this website until you quit and restart Safari. If you like, you can change the trust settings for the certificate later, using Keychain Access.\nHow to respond to a warning that a website is fraudulent\nIf Safari warns you that a website is fraudulent, do not visit that site. If you think the warning message is in error, contact the administrator or owner of the website for information. Never provide secure or personal information at a website unless you are confident that it is secure.", "label": 1}
{"text": "Curtin Teaches Students Real-World Application of Forensic Computing and Cryptography\nOn November 16, Interhack founder Matt Curtin goes to Edison Community College in Piqua, Ohio, to conduct three sessions with students on topics dealing with forensic computing and cryptography.\nSometimes known as digital forensics, forensic computing is the process of analyzing data to answer specific questions for legal proceedings. In some cases, these lines of inquiry can be used to establish facts, to reconstruct information that might otherwise have been destroyed, or to offer expert opinion to the court about how to interpret certain technical facts. Matt will introduce students to an investigation conducted under his direction that identified how one company had critical information about its business stolen by an employee who was leaving the company to go to work for a competitor.\nCryptography is the practice of converting information in human readable form, called \"cleartext,\" into unreadable coded format, called \"ciphertext.\" Cryptography also concerns itself with the protection of of such information.\nSince ancient Egypt, cryptography has been used by diplomats and armies to protect secrets. The twentieth century saw tremendous upheaval in the technology, moving away from mechanical to mathematical systems. Today, cryptography is used by organizations of all types to protect trade secrets, customer records, and other important information. In this session, Matt Curtin will walk students through the process of helping a large retailing company to identify sensitive customer information, and how to use cryptography to protect customers from identity theft and related fraud.\nBased in Columbus, Ohio, Interhack Corporation is a professional services firm with clients all over North America. Founded in 1997 by a team of information security researchers, Interhack accepted the mission to make global computing and communications infrastructures worthy of trust. Interhack's two practice areas, Information Assurance and Forensic Computing, support that mission. The company is a supporting member of The Usenix Association. Additional information about Interhack is available at web.interhack.com.", "label": 1}
{"text": "Programs which give users access to privileges of any sort need to be able to authenticate the users. When you log into a system, you provide your name and password, and the login process uses those to authenticate the login -- to verify that you are who you say you are. Other forms of authentication than passwords are possible, and it is possible for the passwords to be stored in different ways.\nPAM, which stands for ``Pluggable Authentication Modules'', is a way of allowing the system administrator to set authentication policy without having to recompile programs which do authentication. With PAM, you control how the modules are plugged into the programs by editing a configuration file.\nMost Red Hat Linux users will never need to touch this configuration file. When you use RPM to install programs that need to do authentication, they automatically make the changes that are needed to do normal password authentication. However, you may want to customize your configuration, in which case you need to understand the configuration file.\nThere are four types of modules defined by the PAM standard. auth modules provide the actual authentication, perhaps asking for and checking a password, and set ``credentials'' such as group membership or kerberos ``tickets''. account modules check to make sure that the authentication is allowed (the account has not expired, the user is allowed to log in at this time of day, etc.). password modules are used to set passwords. session modules are used once a user has been authenticated to make it possible for them to use their account, perhaps mounting the user's home directory or making their mailbox available.\nThese modules may be stacked, so that multiple modules are used. For instance, rlogin normally makes use of at least two authentication methods: if ``rhosts'' authentication succeeds, it is sufficient to allow the connection; if it fails, then standard password authentication is done.\nNew modules can be added at any time, and PAM-aware applications can then be made to use them. For instance, if you have a one-time-password calculator system, and you can write a module to support it (documentation on writing modules is included with the system), PAM-aware programs can use the new module and work with the new one-time-password calculators without being recompiled or otherwise modified in any way.\nEach program which uses PAM defines its own ``service'' name. The login program defines the service type login, ftpd defines the service type ftp, etc. In general, the service type is the name of the program used to access the service, not (if there is a difference) the program used to provide the service.\nThe directory /etc/pam.d is used to configure all PAM applications.\n(This used to be\n/etc/pam.conf in earlier PAM versions; while the pam.conf file is still read if no\n/etc/pam.d/ entry is found, its use is deprecated.) Each application (really, each service) has its own file. A file looks like this:\n#auth required /lib/security/pamsecuretty.so auth required /lib/security/pampwdb.so shadow nullok auth required /lib/security/pamnologin.so account required /lib/security/pampwdb.so password required /lib/security/pamcracklib.so password required /lib/security/pampwdb.so shadow ¬ nullok useauthtok session required /lib/security/pampwdb.so\nThe first line is a comment. Any line that starts with a # character is a comment. Lines two through four stack up three modules to use for login authorization. Line two makes sure that if the user is trying to log in as root, the tty on which they are logging in is listed in the /etc/securetty file if that file exists. Line three causes the user to be asked for a password and the password checked. Line four checks to see if the file /etc/nologin exists, and if it does, displays the contents of the file, and if the user is not root, does not let him or her log in.\nNote that all three modules are checked, even if the first module fails. This is a security decision---it is designed to not let the user know why their authentication was disallowed, because knowing why it was disallowed might allow them to break the authentication more easily. You can change this behavior by changing required to requisite; if any requisite module returns failure, PAM fails immediately without calling any other modules.\nThe fifth line causes any necessary accounting to be done. For example, if shadow passwords have been enabled, the pam_pwdb.so module will check to see if the account has expired, or if the user has not changed his or her password and the grace period for changing the password has expired.\nThe sixth line subjects a newly-changed password to a series of tests to ensure that it cannot, for example, be easily determined by a dictionary-based password cracking program.\nThe seventh line (which we've had to wrap) specifies that if the login program changes the user's password, it should use the pam_pwdb.so module to do so. (It will do so only if an auth module has determined that the password needs to be changed---for example, if a shadow password has expired.)\nThe eighth and final line specifies that the pam_pwdb.so module should be used to manage the session. Currently, that module doesn't do anything; it could be replaced (or supplemented by stacking) by any necessary module.\nNote that the order of the lines within each file matters. While it doesn't really matter much in which order required modules are called, there are other control flags available. While optional is rarely used, and never used by default on a Red Hat Linux system, sufficient and requisite cause order to become important.\nLet's look at the auth configuration for rlogin:\nauth required /lib/security/pamsecuretty.so auth sufficient /lib/security/pamrhostsauth.so auth required /lib/security/pampwdb.so shadow nullok auth required /lib/security/pamnologin.so\nThat looks almost like the login entry, but there's an extra line specifying an extra module, and the modules are specified in a different order.\nFirst, pam_securetty.so keeps root logins from happening on insecure terminals. This effectively disallows all root rlogin attempts. If you wish to allow them (in which case we recommend that you either not be internet-connected or be behind a good firewall), you can simply remove that line.\nSecond, pam_nologin.so checks /etc/nologin, as specified above.\nThird, if pam_rhosts_auth.so authenticates the user, PAM\nimmediately returns success to rlogin without any password checking\nbeing done. If\npam_rhosts_auth.so fails to authenticate the user, that failed authentication is ignored.\nFinally (if pam_rhosts_auth.so has failed to authenticate\nthe user), the\npam_pwdb.so module performs normal password authentication.\nNote that if you do not want to prompt for a password if the securetty check fails, you can change the pam_securetty.so module from required to requisite\nThe pam_pwdb.so module will automatically detect that you are using shadow passwords and make all necessary adjustments. Please refer to Section 11.5 for more information on the utilities that support shadow passwords.\nThis is just an introduction to PAM. More information is included in the /usr/doc/pam* directory, including a System Administrators' Guide, a Module Writers' Manual, an Application Developers' Manual, and the PAM standard, DCE-RFC 86.0. In addition, documentation is available from the Red Hat web site, at http://www.redhat.com/linux-info/pam/.", "label": 1}
{"text": "A new report on how states in the European Union implement ID cards has found 17 countries have made national ID cards mandatory for their citizens, while only four have not, Security Document World reports.\nOf the 17 countries, 13 use traditional plastic ID cards and eight have introduced new smartcard technology. Smartcards feature an embedded chip that can store more detailed information, making them a stronger security tool than conventional IDs.\nSmartcards can also include biometric information, which currently is one of the strongest security mechanisms available for governments to defend against counterfeit plastic cards. Of the eight countries that use smartcards, Belgium, Italy, Lithuania, Portugal, Spain and Sweden are the only ones that have introduced biometric data on to them, the report relays.\nCountries across the globe have introduced smart card technology to improve safety and convenience for residents. Canada was one of the leading adopters of biometric passports, using the technology to ensure more oversight and security within its borders.\nRelated ID News:", "label": 1}
{"text": "Publisher: Prentice Hall PTR\nIn recent years, with the explosion of web-based applications and the ever-growing popularity of the Java programming language and related Java based technologies, there has been an increasing number of vendors offering middle-tier products on which developers could build and deploy applications. This major shift from two-tier client-server paradigm to n-Tier architecture brings many challenges, especially in the area of system security. To learn about how to secure your J2EE applications, read on.\nAbout the author\nPankaj Kumar is a Software Architect at HP's Web Services management Organization and has worked extensively in the area of middleware and security. He has presented on Java and Web services technologist events ranging from SD West and SD Forum to HP World.\nInside the book\nThis book is organized into three main parts. Part one is all about basic security and the Java platform. Part two introduces the readers to the basic building blocks of the Java platform's security architecture - APIs for cryptographic operations, PKI infrastructure, access control mechanisms, Java Secure Socket Extensions, and APIs for XML. And finally, the third and final part links together the concepts introduced in part two.\nThe first part of the book kicks off with a look at news reports and case studies to get a feel for computer and network security problems. The first chapter ends with brief description of how to enable technologies in the fight against computer crime and how application security fits into the overall scheme of things.\nWhat follows is an overview on the Java platform, consisting of J2SE and J2EE, with focus on security aspects.\nThe second part of the book starts with an explanation of cryptographic services and the Java API supporting these services. Basic cryptographic APIs (JCA and JCE) are covered. Here you learn about the secret key and PK cryptography, message digests, Message Authentication Code, and digital signature.\nThe following chapter discusses Java support for PKI components such as X.509 certificates, certification authorities, and certificate revocation lists.\nNext, you encounter an explanation of the security model used to protect resources within JVM with a Security Manager.\nWe continue by going deeper into security with chapter six that explains SSL also known as transport layer security, protocol for securing exchange of information over unprotected networks at the transport level.\nIn last chapter in the second part of the book the author writes about message security as a means to secure messages independent of transport. XML security standards XML Signature and XML Encryption are explained.\nThis third part of the book starts with a discussion of the security issues in developing RMI based distributed applications. It covers the use of the security manager to limit privileges of downloaded code, SSL for transport level security and JAAS for user authentication.\nIf you're interested in web application security you'll be glad to know that chapter nine contains information about different forms of declarative and programmatic security for Servlets and JSPs. Apache Tomcat is used to illustrate example programs.\nThe author continues by illustrating how the EJB architecture facilitates the development of software components for assembling secure enterprise applications. BEA's WebLogic Server is used to explore security concepts.\nChapter eleven talks about security issues surrounding the developing, deploying and invoking of Web services. Open source SOAP engine Apache is used to illustrate the APIs and the examples.\nThe book closes with on overall review of the subject of the book which is analyzed from a distance, identifying patterns, general principles and relations between topics.\nJ2EE Security is a well written book; it makes a rather difficult topic easy to understand.\nIf you are a java programmer, a system administrator who is in charge of managing J2EE applications, a system architect, or a project manager you will definitely enjoy reading this book. It's worth every penny.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "FreeBSD Jailsby Mike DeGraw-Bertsch\nWhat is a Jail?\nThose familiar with Java recognize the security concept of a sandbox. For those that aren't, it's the concept that everyone gets a unique, well-equipped sandbox to play in, and a person in\none sandbox isn't allowed into anyone else's sandbox, not even to share\nanything with anyone else. On FreeBSD, jails implement this concept —\nthey keep processes in their own part of the system, denying access to anything\nelse. A jail requires its own dedicated IP address, though, which can make life\ndifficult for those with limited address space. If this presents you with a\nhardship, consider at least using\nwon't afford you as much security, but it does help.\nHow does this help security? Take, for example, a box with an external FTP server and the company extranet. An exploit for the server is discovered, and a cracker manages to gain root access through the FTP daemon. If the FTP server is not run in a sandbox or jail, the cracker will have access to everything on the machine, including sensitive information destined for the company's partners through the extranet. If, however, the FTP server is run in a jail, the cracker will only have access to the FTP files.\nThere are, of course, still potential risks. If you run at secure level\n0, the cracker can simply access the raw disk device and read data\nfrom there. The solution is obvious — on a box sensitive enough to require\njails, use appropriate secure levels as well. This will eliminate a cracker's\nability to read from or write to raw disk devices.\nConfiguring a Jail\nConfiguring a jail is pleasantly simple.\nFirst, ensure that your system environment is jail-friendly. Because each\njail requires its own IP address, the services on your box must be configured\nto listen to specific addresses, not just every available address. For\nexample, if the box's addresses are\n188.8.131.52 (main) and\n184.108.40.206 (jail), to get\ninetd to listen only on\ninetd_flags=\"-wW -a 220.127.116.11\" to /etc/rc.conf. If you fail to do this, conflicts may occur over the aliased IP address.\nFor some daemons, this is not an easy process —\nrpcbind are two examples. If you're using these services on\nyour box, you might consider simply running them inside of a jail of their own.\nAfter configuring all of the non-jailed daemons to listen to a specific address,\nreboot the machine. This will put everything into a known state, eliminating\nany potential for confusion.\nWith the proper host environment in place, create the directory that will house the jail. In this example, it's /usr/jail/ftp. Now go to /usr/src and run:\n# make world DESTDIR=/usr/jail/ftp # cd etc # make distribution DESTDIR=/usr/jail/ftp # cd /usr/jail/ftp/dev # sh # MAKEDEV jail # cd .. # ln -sf /dev/null kernel\nThese commands build the jail and populate it with all of the tools that your\nprocesses will need to run. Actually, they put in a lot more than just what your\nprocesses will need. For example,\nsendmail will all be installed, but you probably don't need them\nin your jail. Keep in mind, though, that it's a lot easier to take stuff out\nuntil something breaks than it is to put stuff back in until everything\nTo configure the jail environment, you might want to copy\n/stand/sysinstall into /usr/jail/ftp/stand, to\nprovide you with an easy configuration interface. I'll show you how to use it\nin just a second.\nWith the system rebooted, you're now ready to configure the jail environment. Start the jail for the first time by running:\n# jail /usr/jail/ftp jail.hostname.com 18.104.22.168 /bin/sh\nThis will put you at a shell prompt in your jail environment. From here, you\n/stand/sysinstall (literally, since\nrefers to the jail's root directory, not the system's.)\nThere are several configuration tasks to perform, such as setting the root\npassword (don't make it the same as the main system root password!), adding\nuser accounts, and configuring /etc/resolv.conf. Read\njail for more configuration tasks that you'll need to perform. Keep in\nmind that you want to be able to log in to the environment, so consider running\nan SSH daemon inside the jail.\nOnce you're done configuring the jail environment, exit the shell and the jail will be shut down.\nYou're almost ready to start the jail \"for real.\" First, add the appropriate IP address alias. For our example, this is done via:\nifconfig fxp0 inet alias 22.214.171.124 255.255.255.255\nYou can configure this in /etc/rc.conf to be done automatically at boot.\nNow, let's start the jail! This is done with two commands:\n# mount -t procfs proc /usr/jail/ftp/proc # jail /usr/jail/ftp jail.hostname.com 126.96.36.199 /bin/sh /etc/rc\nYou'll see some warning messages scroll by, but don't worry about them. You\ncan now see all the daemons running inside the jail, as indicated by the\nJ flag shown in the\nps output. If you enabled SSH\nwithin the jail, you can\nssh to the jail environment.\nSince normal shutdown commands like\nhalt don't work in the\njail, you must take a special measure to shut the jail down. First, log in to\nthe environment and become\nroot. You can then kill all the\nprocesses inside the jail via\nkill -TERM -1 or\nkill t -KILL\n-1. You can also do this from outside the jail by manually killing any\nPID within the jail.\nYou should now be able comfortably to create and use jails to secure everything from FTP daemons to DNS servers. Before we finish, there's just one more note.\njail.set_hostname_allowed on pre-5.0 machines)\nsysctl variable determines whether or not the superuser\nwithin the jail can set the hostname. This is enabled by default, and you might consider disabling it by placing\nsecurity.jail.set_hostname_allowed=0 in /usr/jail/ftp/etc/sysctl.conf. Remember that it's\njail.set_hostname_allowed=0 on machines running FreeBSD-4.x!\nYou've now seen both how jails work and how to set one up. Whether you're running multiple public services from the same box, providing login shells to untrusted users, or offering a public service on an otherwise private machine, using jails properly will help you sleep at night.\nMike DeGraw-Bertsch is a security and Unix system administration consultant in the Boston, Mass. area. When he's not at a job, writing, hacking with Perl, or playing with his wireless network, he can usually be found playing goal in ice hockey.\nReturn to the BSD DevCenter.\n- Trackback from loose-yourself.sharelex.com\n2005-07-29 06:13:33 [View]\n- Trackback from loose-yourself.sharelex.com\n2005-07-29 06:13:32 [View]\n- Trackback from klip.sharelex.com\n2005-07-29 06:06:50 [View]\n- Trackback from http://michael.fuckner.net/me/blog/index.php?/archives/179-Verbockt,-Rechner-platt.html\nVerbockt, Rechner platt\n2005-07-27 02:39:37 [View]\n- Trackback from http://mdnava.network.com.ve/archives/2_Linux_Strikes_Back_SCO_Unix_vs_Linux_World.html\nLinux Strikes Back (SCO Unix vs. Linux World)\n2004-04-25 19:28:50 [View]\ncore dump when starting jail\n2003-11-02 18:23:51 anonymous2 [View]\nFreebsd Jail To good to be true?\n2003-10-27 00:31:11 anonymous2 [View]\n2003-10-08 07:54:24 rubeng [View]\n2003-09-15 03:32:11 anonymous2 [View]\nUseful ; thanks for the article\n2003-09-06 05:05:54 anonymous2 [View]\n2003-09-05 13:11:47 anonymous2 [View]\nChroot jail HOWTO for Linux\n2003-09-05 13:00:09 anonymous2 [View]\n2003-09-05 09:41:45 anonymous2 [View]\n2003-09-05 03:01:18 otto [View]", "label": 1}
{"text": "I have looked around and found no information on how Android manages to store passwords on the device. Especially Gmail passwords. I'm looking to learn how Android encrypts and stores passwords ? What key does it use and where is this key stored, and what encryption algorithm it uses.\nGmail's official app doesn't store password in your device. Your password is 100% safe if you use this app.\nThis is how it works: The password is used by Google's authentication servers for the first time ONLY. After first successful authentication, an\nNote: These all aren't true if you use third-party email apps for Gmail viz. Stock Email app, K-9 Mail etc. IMAP or POP protocol needs original password to authenticate users everytime. So, plain password needs to be available to email app before sending it to server. So, most of email apps store passwords in plain text (hashing/encryption is useless because hashing/encryption key needs to be stored locally). In this case, I'd recommend you to enable\n|show 17 more comments|\nAndroid passwords used with the built-in Email application are stored in plain text inside a SQLite Database. This is in contrast to the Gmail application, which uses Auth Tokens as described in Sachin Sekhar's answer.\nFor Jelly Bean, the database location is:\nThe above location varies with the Android version\nThis location on a non-rooted device is secured and protected by the Operating System.\nA member from the Android Development Team posted an explanation that till today still applies:\nAditionally, since this issue appears to disturb many Android users, you can also follow this discussion at Slashdot - Android Password Data Stored In Plain Text.\n|show 2 more comments|", "label": 1}
{"text": "\"Rather than some automated tool or complex virus, Google and Wikipedia searches appear to have been the weapons used to knock down the walls guarding [Sarah Palin's] e-mail,\" according to this eWeek item.\nMost people are vulnerable to the type of attack that compromised Palin's email account, as Markus Jakobsson wrote recently in IT World, \"...almost all of us reuse what we may think of as “meta passwords” – the information used to reset passwords...\"\nEvery three months about 1.5% of Yahoo's 250 million email account holders forget or lose their email login or password. This creates tens of millions of password email reset/recovery requests per year, according to this research report. This translates into a lot of wasted time in password recovery purgatory (at best) or opportunities for privacy problems and online fraud (at worst).\nThe password security and password recovery process is vulnerable to several different types of attacks:\n1) Phishing attacks - where someone mimics a trusted website usually by sending an email directing you to a \"fake site.\" There they get you to enter in personal information/ data like passwords/credit card information or social security numbers or \"meta password data\" like birthdays or mother's maiden name, name of your first pet. The phisher captures this information and uses it be assume your identity and either access your sensitive accounts or creates new accounts in your name.\nLastpass protection: They protect against phishing attacks by verifying that every site you log into is the actual website you're trying to enter. When you attempt to log-in to a website using Lastpass, the password manager will highlight login/form fill fields and offer auto login only to confirmed, legitimate website where you have an account. You’ll see the Lastpass icon and highlighted fields and know it is safe to proceed.\n2) Brute force attacks - where someone methodically applies password combinations in an attempt to guess your password. One popular variation of this theme is a dictionary attack where weak passwords are uncovered by simply probing your password by testing it against the words in a dictionary.\nLastpass protection: They make creating, using and remembering strong passwords simple. Most people, myself included, make it too easy for brute force attacks to be successful because we use weak passwords (that are easier to remember than strong, complex ones) and reuse these weak passwords across different sites (meaning if one password is stolen/compromised, many of my sites are vulnerable). Lastpass makes it easy to use strong and unique passwords for every website. I use Lastpass to auto generate strong passwords for me and remember these passwords for me so I don’t have to.\n3) \"Meta password\" attacks (a.k.a. mother's maiden name and other common password retrieval challenges). Under this increasingly common scenario, someone collects your personal information via Facebook, public record searches, ect. They use that information to figure out what they need to reset my account password and access my information.\nLastpass help: The password manager enables me to change the way I answer these “meta password” questions. Basically, I can offer less personal information. Gone are the days where I enter in simple answers, now I auto generate strong password-like answers to questions like mother’s maiden name and my elementary school? I use the password generator to make up “junk” answers and save these answers in the “edit site information” notes section with each new account. Because Lastpass auto logs me in to websites I no longer have to use the meta password data to reset passwords. If I were to need to access the meta question answers, that info is securely saved and accessed from my Lastpass portal page.\nBecause Lastpass does password management differently, they sync all my information across platforms and machines and I can still access all my account information, log-into my websites without uploading any sensitive information to their servers.\nSo, unlike many password managers, Lastpass doesn’t require too much “trust “from me. It saves all my sensitive information and encrypts it locally on my machine. They don’t have access to any of my information, it doesn’t get saved onto their servers, it remains secure, encrypted and on my computer.\nIt’s probably time for all of us including Sarah Palin to rethink our online information management and make life easier and safer with a password manager like Lastpass.", "label": 1}
{"text": "Drones Fail 'Perch And Stare' Contest\nDARPA competition to develop unmanned aerial vehicles capable of landing and relaying real-time surveillance video ends without a winner.\nDARPA launched the competition to create a portable unmanned aerial vehicle (UAV) for intelligence gathering a year ago. The goal was to develop a \"military-relevant, backpack-portable UAV\" capable of vertical take-off, flying out of sight, landing, capturing video, and returning. More than 140 teams entered the contest, called UAVForge, but none of them successfully completed the required maneuvers.\nMore Government Insights\nWhite PapersMore >>\n\"While some teams were able to reach the observation area, none were able to land on a structure and complete the mission,\" DARPA said in a statement announcing the results.\nDARPA established a website, UAVForge.net, to encourage and support crowd-sourcing of ideas during the competition. The entries were narrowed to nine teams of finalists, which participated in a \"fly off\" at Fort Stewart in Georgia. The course required the UAV to fly below 1,000 feet, maneuver around obstacles, land on or hover above a physical structure, and visually track moving objects in real time.\n[ Read NASA Sees Drones Flying In U.S. Airspace. ]\nDetails on the performance of each finalist, and the cost to build it, are available on the competition website. An entry dubbed \"Halo,\" which received the highest score, was also the most expensive to build, at $9,487.\nDARPA has been working to develop its own \"perch and stare\" UAVs, which would perform essentially the same tasks as those in the UAVForge contest, as part its Shrike program. The research agency is also developing smaller, \"nano\" air vehicles that weigh less than 20 grams. One experimental design, disguised as a hummingbird, aims to fly indoors for use in urban warfare.\nThe Office of Management and Budget demands that federal agencies tap into a more efficient IT delivery model. The new Shared Services Mandate issue of InformationWeek Government explains how they're doing it. Also in this issue: Uncle Sam should develop an IT savings dashboard that shows the returns on its multibillion-dollar IT investment. (Free registration required.)", "label": 1}
{"text": "St. Louis (KSDK) -- Internet thieves are finding new ways to trick consumers everyday. Thieves use a practice known as phishing to get consumers to hand over their banking and other personal information.\nThe Consumer Fraud Task Force recommends being very careful before you even open an e-mail from someone you don't know or responding to suspicious phone calls or postal mailings.\nIn the past few months, criminals have used a variety of techniques to get consumers to turn over sensitive information, the Task Force said. Among the ruses:\n- A scam that targeted fiancées of service members to \"register\" with the Defense Finance and Accounting Service in order to receive benefits in the event of the service member's death. Thieves used the ploy to extract money and personal information from victims.\n- A scam using a phony email itinerary for US Airways to phish for personal information.\n- Notification to consumers that they have been awarded a free Walmart gift card and then directing them to a site that asks them for personal information.\n- A variety of scams allegedly from the Better Business Bureau, the Federal Bureau of Investigation, the Internal Revenue Service or other governmental or non-governmental organizations seeking confidential information or using links that could damage consumers' computer systems through malware or other programs.\n- Scams using the names of popular online sites like Facebook, eBay, Craigslist, Google and a variety of gaming sites, again designed to obtain sensitive data from consumers.\nEarlier this year, the FBI reported cyber crooks were using spam e-mails purportedly from organizations like the Federal Reserve Bank or the Federal Deposit Insurance Corporation to infect computers with malware and gain access to bank accounts. the malware, called \"Gameover,\" was designed to steal usernames and passwords.\nThe Task Force offers the following suggestions to avoid phishing scams:\n- Don't trust unsolicited emails, even if they appear to be from familiar businesses or agencies. If you're concerned about the validity of an email, contact the business or agency directly by phone or through its website to ask about it.\n- Don't open any attachments in suspicious emails and don't click on any links or give any personal information unless you are confident where it is going. If you have concerns, run your cursor over a link (but don't click it) to determine if the actual link is the same as the one shown.\n- Delete any suspicious email from your inbox and from your trash or recycling folder.\n- Don't give your Social Security number, bank account number or any other personal information to unfamiliar persons contacting you by phone or by mail.\n- Be wary of misspellings, poor English or other signs that the person or persons contacting you may not be legitimate.\nThe Task Force is a coalition of local, state and federal government agencies and nonprofit business and consumer groups in Missouri and Illinois that work together to protect consumer and donor rights and guard against fraud. Previous Task Force releases have focused on payday loans, tax scams, timeshare resellers, home remodelers, work-at-home scams, sweepstakes offers, online auctions, credit repair scams, debt management advice, foreclosure scams, extended auto service contracts, sweetheart scams and fire and police organizations.\nTo obtain information, or to report a scam, you may contact members of the Task Force:\nBetter Business Bureau Serving Eastern Missouri and Southern Illinois - (314) 645-3300\nFederal Trade Commission - (877) FTC-HELP (382-4357)\nIllinois Attorney General - (800) 243-0618\nMissouri Attorney General - (800) 392-8222\nU.S. Attorney, Eastern District of Missouri - (314) 539-2200\nU.S. Postal Inspection Service - (877) 876-2455;\nU.S. Secret Service - (314) 539-2238", "label": 1}
{"text": "Posted by: GuyPardon\nauthentication, blogging, business, collaboration, community, cool, free, howto, interactive media, Internet, interoperability, learning, multimedia, open source, tool, trend, tutorial, useful, video, Web services, word meanings, YouTube\nOne of our newest definitions explains OpenID:\n“OpenID is a decentralized single sign-on authentication system for the Internet. The goal of the OpenID initiative is to allow users to log in at websites around the Internet with one ID instead of having to create multiple unique accounts. OpenID was developed using the open source software model to be an interoperable protocol independent from any single organization. (Continued…)”\nActivating and using an OpenID is quite easy — I was able to sign up for TravelWiki, for instance, using one from Yahoo!. Activation and setup took about a minute. I’ve embedded three videos below that explain more about how OpenID works and how to use it. Enjoy!\nThe video below explains more about how to use an OpenID to login, in this case to votay.com:\n[kml_flashembed movie=\"http://www.youtube.com/v/wN2DG95V8Gk\" width=\"425\" height=\"350\" wmode=\"transparent\" /]\nHere’s another one that explains how to use OpenID with WordPress:\n[kml_flashembed movie=\"http://www.youtube.com/v/Uu_MAUOdZVo\" width=\"425\" height=\"350\" wmode=\"transparent\" /]\nDave provides a short, clear explanation of OpenID using a whiteboard here:\n[kml_flashembed movie=\"http://www.youtube.com/v/xcmY8Pk-qEk\" width=\"425\" height=\"350\" wmode=\"transparent\" /]\nAnd finally, in a Google TechTalk, Simon Willison (co-creator of the Django Web framework) discusses the implications of OpenID and explores the best practices required to take advantage of the new technology while avoiding the potential security pitfalls. This one’s a bit long but excellent.\n[kml_flashembed movie=\"http://www.youtube.com/v/DslTkwON1Bk\" width=\"425\" height=\"350\" wmode=\"transparent\" /]", "label": 1}
{"text": "Abbreviation for \"Windows NT LAN Manager\"\nThe NTLM protocol was the default for network authentication in the Windows NT 4.0 operating system. It is retained in Windows 2000 for compatibility with down-level clients and servers. NTLM is also used to authenticate logons to standalone computers with Windows 2000. Computers with Windows 3.11, Windows 95, Windows 98, or Windows NT 4.0 will use the NTLM protocol for network authentication in Windows 2000 domains. Computers running Windows 2000 will use NTLM when authenticating to servers with Windows NT 4.0 and when accessing resources in Windows NT 4.0 domains.*\nNTLM uses a challenge-response mechanism for authentication, in which clients are able to prove their identities without sending a password to the server. It consists of three messages, commonly referred to as Type 1 (negotiation), Type 2 (challenge) and Type 3 (authentication). The protocol continues to be supported in Windows 2000 but has been replaced by Microsoft Kerberos as the default/standard.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "Choose Privacy Week\nPrivacy is a particularly slippery and amorphous issue, about which people hold a wide variety of opinions and beliefs, particularly in the post-9-11 world in which we live.\nLibraries and library workers think about privacy issues a lot - and want our customers to think critically about privacy issues, too. Personal privacy issues touch everyone at virtually every stage of life, and even into death (e.g., access to the Social Security Death Index online), raising a universe of hard questions to be answered.\nSponsored by the ALA’s Office for Intellectual Freedom (OIF), Choose Privacy Week is an annual initiative inviting library users of all ages and backgrounds into a national conversation about privacy rights in a digital age. The theme for this year's Choose Privacy Week is \"Freedom from Surveillance.\"\nLibraries have been interested in maintaining the privacy of individuals. Beaufort County Library Board of Trustees adopted the American Library Association Core of Ethics years ago. It's part of our core values as library workers. Why? Because freedom of speech is meaningless without the freedom to read.\nClick here [http://www.privacyrevolution.org/images/uploads/Trina_UserHandout.pdf] for handout explaining why librarians and libraries insist upon empowering our customers to explore, research, and make choices based upon their individual needs.\nQ: Where are the lines drawn between \"right of privacy\" and \"right to know\" today ?\nThe major source used in the preparation of this entry was http://www.privacyrevolution.org/. Please explore the website - and think hard about where you stand on the issue of individual privacy rights.", "label": 1}
{"text": "Cybercriminals gangs are creating a surge in ransomware, says a new report from Symantec.\nRansomware is a type of malware best described as an online extortion racket. Malware locks or disables your PC in some way and then demands payment in the form of a \"fine\" to render your PC usable again. Like most scams, the ransomware message claims to come from a legitimate organization, such as the government or a public corporation, to try to convince victims that they did something wrong to incur the fine.\nBut paying the fine does nothing since the initial malware remains on the PC and must still be manually removed.\nThis scam has risen in popularity over the past several years, but 2012 witnessed an increase in both the number and variety of ransomware campaigns, Symantec said in its report. That growth is due largely to a upsurge in the number of worldwide criminal gangs using this scheme to make a buck.\n\"From just a few small groups experimenting with this fraud, several organized gangs are now taking this scheme to a professional level and the number of compromised computers has increased,\" the report noted. \"Symantec has identified at least 16 different versions of ransomware.\"\nOne malware investigation mentioned in the report discovered 68,000 affected computers in a single month. Another one caught a Trojan attempting to infect 500,000 PCs over the course of just 18 days.\nCriminals go where the money is, and ransomware can be a cash cow. As much as 2.9 percent of all people affected by ransomware end up paying the ransom, Symantec said. Criminal gangs have stolen more than $5 million a year from unsuspecting victims, according to one estimate, however, Symantec believes the dollar amount to be much higher.\nThough a variety of different gangs are active, many get their ransomware from the same source, the report said. A single individual, who remains unknown, seems to have a full-time job of developing ransomware to fill requests from the criminal gangs.\nOne of ransomware's weaknesses is that it's usually obvious, Symantec noted. Many users who receive such messages simply scan their PCs, which then removes the Trojan associated with the ransomware.\nBut as more users fail to fall for the scam, the criminal gangs may simply fine-tune their methods of attack.\n\"As awareness of these scams increases, the attackers and their malware are likely to evolve and use more sophisticated techniques to evade detection and prevent removal, the report said. \"The 'ransom letter' will likely also evolve and the attackers will use different hooks to defraud innocent users.\"", "label": 1}
{"text": "Updated 01/16/2013 06:57 PM\nExperts warn online passwords more vulnerable than ever\nJust how secure are your online passwords? You may believe that you've set up complicated passwords for each of your online accounts, but experts warn they probably are not complex enough to keep hackers at bay. Our Candace Hopkins has simple tips to keep your information secure.\nTo view our videos, you need to\ninstall Adobe Flash 9 or above. Install now.\nThen come back here and refresh the page.\nUNITED STATES -- Computers and smart phones have simplified every day activities like banking, shopping and communicating with friends. But when these functions moved online, users were forced to create dozens of accounts, each guarded with a password.\n\"You've got your email. I do web development, so there's servers and publishing software and things like that to log into, so there was a ton of different sites,\" said Syracuse University senior Andrew Bauer.\nBut experts say the average person can only remember about five passwords, meaning some get used for several different accounts.\n\"I try to switch them up, use similar names, but switching up the characters, using dollar signs or asterisks or capital letter here, lower case the next and switching it up,\" said Syracuse University junior Anthony Dann.\nThat's a common practice. But experts warn those variations are not enough. That's because most passwords can be hacked by computer programs in just minutes.\n\"Even combinations of like two dictionary words together is easily hackable, as is replacing a dictionary word with typical characters like you might replace an ‘a’ with an @ symbol or an ‘e’ with a ‘3.’ Those are things most hackers have caught on to and makes your password easy to break,\" said SU School of Information Studies Adjunct Professor Michael Fudge.\nThe best way he says to strengthen your password is by adding length to it, which can be done by placing a number sequence at the end. And if you can't remember such complicated passwords, there are websites called password database managers that can do that for you. You simply set up a master password and the program creates and stores passwords for all of your other log-ins.\n\"You don't have to remember any of the other passwords, when you go to a site login box, you tell the password manager to initiate a log-in for you. Many of the passwords I use on all my sites, I don't even know them, I know they're long and complicated and hard to guess and different from all the other sites,\" said Fudge.\nAnd experts say don't worry, those password database managers have the strongest security possible in place. Many password database manager sites charge a monthly fee, but there is at least one you can download for free.\nClick here to access LastPass' website, which offers a basic version of the service for free.", "label": 1}
{"text": "Solutions to common problems with logging on to Windows\nHere are solutions to some common problems with logging on to Windows.\nHere are several possible solutions to fix this problem:\nCaps Lock might be on.\nPasswords in Windows are case-sensitive, which means that every time you type your password, you have to capitalize each letter in exactly the same way that you did when you first created it. If you have accidentally pressed Caps Lock (sometimes the key name is spelled CapsLk), then you're inadvertently typing your password in all capital letters. Make sure Caps Lock is off, and then type your password again.\nYou might be typing the wrong password.\nIf you can't remember your password, you need to reset your password, either with a password reset disk or an administrator account. For more information, see Reset your Windows password.\nAn administrator on the computer might have reset your password.\nIf your computer is on a network, a network administrator has the ability to reset your password. If you think this might be the problem, check with your network administrator. If your computer is in a workgroup, anyone who has an administrator account on the computer can change your password.\nYou might be trying to log on to the wrong user account.\nIf you have more than one user account on the computer, make sure you're logging on to the account that matches the password you're using.\nTo log on to a local user account on your computer, you need to know the name of your computer and the user name for the account that you want to log on to. If you don't know the name of your computer, see Find your computer name. To log on to a local user account,\nfollow these steps:\nOn the Welcome screen, click Switch User.\nClick Other User.\nIn the user name field, type the name of your computer, a backslash (\\), and the user name for the account that you want to log on to. For example: computer name\\user name\nType your password, and then press Enter.\nIf you upgraded to this version of Windows from a previous version of Windows, your fingerprint reader should continue to work. If your fingerprint reader is not working, an updated driver or application might be available for download through Action Center or Windows Update. For more information on Action Center, see What is Action Center?\nFor more information on Windows Update, see Install Windows updates in Windows 7. If you are not able to find a driver using Action Center or Windows update, you should contact your computer or fingerprint reader manufacturer for drivers that are compatible with this version of Windows.\nArticle ID: MSW700047", "label": 1}
{"text": "Yesterday, we talked about the rise of phishing in shared hosting environments. Of course, you probably know that you can be a phishing victim in other types of hosting environments as well. These attacks can be catastrophic for businesses, as well as the individuals whose data is compromised.\nLet’s take a look at the statistics of phishing: how often it occurs, who’s affected, and if there is anything you can do to protect yourself. These statistics and all associated information is compiled from the Anti-Phishing Working Group (APWG) April 2013 report, and all data gathered from all over the world represents the latter half of 2012.\nHow Many Attacks Were There, And What Sites Were Affected?\nAccording to the report, 123,486 separate attacks took place worldwide. If you compare that to the 93,462 that took place in the first half of 2012, you’ll see that’s quite the increase. As we discussed in yesterday’s article pertaining to shared hosting, attacks occurring on shared virtual servers allowed multiple domains to be attacked all at the same time.\nBecause of the attack on shared hosting environments, 89,748 separate domain names were compromised. 2,489 of those attacks were exposed on 1,841 separate IP addresses instead of on domain names. It is important to note that none of these phishing attacks took place on IPv6 addresses.\nIPv6 is the latest IP, designed by the Internet Engineering Task Force (IETF) to address the problem they knew would come: the exhaustion of IPv4 addresses. It isn’t interoperable with IPv4, but is rather an independent network working in parallel with IPv4. One of the reasons no attacks have taken place could simply be because IPv6 traffic share is only nearing 1%: the majority of internet traffic is still carried on IPv4.\nHacked/Compromised Domains vs. Maliciously Registered Domains\nOut of that 89,748 domain names that were the victim of phishing, the APWG thinks 5,835 domains were maliciously registered by the phishers themselves. That is good, because it appears this practice is declining: 7,712 were labeled as malicious in the first half of 2012, and 14,650 in the beginning of 2011.\nThe rest of the domains were hacked, whether shared or cheap web hosting environments. When it comes to phishers using sub-domain services, the numbers fell here as well: only 14% to 8% of the overall number of attacks.\nPhishers are still relying on URL shortening services to trick phishing URLs, but only 785 phishing attacks such as this took place in the second half of 2012.\nURL shortening is often harmless, like within the Twitter platform, when the number of characters that can be entered is limited. Think Bitly, a URL shortening service that saw their shortened links accessed 2.1 billion times in November 2009. When a spammer or hacker uses URL shortening, it can lead to the shutting down of the URL by their cheap web hosting provider. 65% of shortened URLs found to be malicious were discovered at one provider alone, TinyURL.com.\nAre Some TLDs More Popular For Phishing?\nIt seems that phishers maliciously register domains in only three TLDs: .com, .info, and Thailand’s .tk. Phishers also seem to love Paypal, as it sees 39% of the overall attacks. 48% of phishing domains were .com.\nWhat About Registrars?\n79% of maliciously registered domains appear to have been registered with 21 different registrars, most of them in China. They include Shanghai Yovole Networks; Hang Zhou E-Business Services; Chengdu West Dimension Digital Technology; Intenret.bs; Jiangsu Bangning Science; Melbourne IT; Beijing Innovative; 1API; Directl/PDR; Bizcn.com; Register.com; Xin Net Technology Corp; OVH; GoDaddy; Name.com; Fast Domain; eNom Inc.; tucows; and 1 and 1 Internet AG.\nThere may be no way to fully protect yourself against phishing attacks. However, by staying away from a shared servers and knowing the information that could help you decrease the chances you’ll fall victim, you can make cheap web hosting work for you without compromising your data.\nIs phishing a concern of yours? Have you taken the proper steps to decrease your chances of being a victim?", "label": 1}
{"text": "Lookout, an organization who produces the eponymously-named Lookout app (a free app to help protect your phone from would-be evil-doers) has come up with some scary data in their App Genome Project. To quote Lookout, the App Genome Project is the:\nWorld’s largest analysis of mobile applications to provide insight into what applications are doing and identify potential mobile threats.\nBasically, the App Genome Project is Commissioner Gordon to Lookout’s Batman. The findings are pretty scary (quoted from Lookout):\n- 29% of free applications on Android have the capability to access a user’s location, compared with 33% of free applications on iPhone\n- Nearly twice as many free applications have the capability to access user’s contact data on iPhone (14%) as compared to Android (8%)\n- 47% of free Android apps include third party code, while that number is 23% on iPhone*\nThey’ve also found a number of security vulnerabilities, including one that allows apps to see sensitive device data – for example, Android 2.1 and below allows apps to access location data logs – and that’s not even the worst of it. According to Engadget, an app called Jackeey grabs your browsing history, voicemail password, texts, and SIM ID and sends it to China.\nLookout plans on releasing more details during Black Hat this week; hopefully manufacturers and programmers take heed.", "label": 1}
{"text": "What is computer hacking?\nIn a cyber security world, the person who is able to discover weakness in a system and managed to exploit it to accomplish his goal referred as a Hacker , and the process is referred as Hacking.\nNow a days, People started think that hacking is only hijacking Facebook accounts or defacing websites. Yes, it is also part of hacking field but it doesn't mean that it is the main part of hacking.\nSo what is exactly hacking, what should i do to become a hacker?! Don't worry, you will learn it from Break The Security. The main thing you need to become a hacker is self-interest. You should always ready to learn something and learn to create something new.\nNow , let me explain about different kind of hackers in the cyber security world.\nScript KiddieScript Kiddies are the persons who use tools , scripts, methods and programs created by real hackers. In a simple word, the one who doesn't know how a system works but still able to exploit it with previously available tools.\nWhite Hat Hacker:\nWhite Hat hackers are good guys who does the hacking for defensing. The main aim of a Whitehat hacker is to improve the security of a system by finding security flaws and fixing it. They work for an organization or individually to make the cyber space more secure.\nBreak The Security only concentrates on white-hat hacking and help you to learn the Ethical Hacking world.\nBlack Hat Hacker:\nBlackHat hackers are bad guys , cyber criminals , who have malicious intent. The hackers who steal money, infect systems with malware ,etc are referred as BlackHat hackers. They use their hacking skills for illegal purposes.\nThe hackers who may work offensively or defensively, depending on the situation. Hackers who don't have malicious intentions but still like to break into third-party system for fun or just for showing the existence of vulnerability.\nThe hackers who use their hacking skills for protesting against injustice and attack a target system and websites to bring the justice. One of the popular hacktivists is Anonymous.", "label": 1}
{"text": "The Role of XML in Agile Enterprise Architecture, Page 2\nXML Usage in Each Tier\nNow, we've covered a brief introduction to XML, its virtues, and resultant innovation. We've also covered a typical tier structure for describing enterprise architecture. Let's see how XML and XML technologies map to the enterprise tiers.\nOne of the initial uses of XML was to communicate messages between tiers. It didn't matter that tiers may reside on different hardware and software platforms. XML is portable between heterogeneous platforms because it is a standard, self-describing, text-based format. Once XML became prevalent in inter-tier communication, it began to be used intra-tier as well.\nXML's cousin, HTML, has reigned in the client tier. While HTML may not be going away soon, it is changing, and how HTML is generated is changing as well.\nXHTML is HTML that is also a well-formed XML document. It basically turns HTML into an XML vocabulary. Why is this significant? HTML was a bit too lax and forgiving, causing ambiguous markup code and browser compatibility issues. By being well-formed, XHTML improves upon HTML's slackness. It can be parsed with standard XML parsers, queried by XPath, and even transformed via XSLT.\nXSLT, a transformation language for rendering XML into other markup formats, makes it possible to render HTML directly on the client from an XML data source. This provides a clean separation from the data, represented in the XML document, and the presentation, represented in the generated HTML. CSS (Cascading Style Sheets) are another technology that can be used on the client to present XML documents in a browser and eliminate HTML altogether.\nXForms is a maturing technology that has the potential to revolutionize user interface development. It also separates data from presentation and adds features lacking in HTML forms, such as strong typing, validation, reduced server trips, reduced need for scripting, and an XML representation of form instance data. It provides an XML-friendly manner of data capture.\nBecause of browser compatibility issues with non-standard XSLT implementations, XSLT has also become prevalent in the presentation tier. Often, the view in a MVC framework is implemented in XSLT. In this approach, the stylesheet may be called from the controller to render an XHTML response to the client from an XML source document.\nIt is also becoming more common for the model in MVC to be implemented in XML. With this approach, XML documents might be held in session, accessed via DOM or XPath API, and wrapped by objects to add behavior and encapsulate the XML.\nService-oriented architecture is not a new concept. However, it has gotten a shot in the arm from XML. Web Services—a recent implementation of SOA—owes a debt of gratitude to XML for enabling this technology to flourish and prosper. HTTP and XML have become the standard protocol and payload for sending and receiving messages with the service tier.\nA typical service tier utilizes many XML vocabularies. WSDL (Web Services Definition Language) is a vocabulary for describing a service and its contract. SOAP (Simple Object Access Protocol) is a vocabulary for passing objects between components in a decentralized distributed environment. There are a plethora of industry standard vocabularies, such as ACORD XML in the insurance industry, used to describe the messages passed in a SOA.\nTo receive and send messages, the service tier uses XML parsing API such as DOM, SAX, and StAX. A service provides an interface to applications, components, and resources which themselves may have an XML-based API. Often, the service will use XSLT to transform requests and responses to and from these components as per the service contract.\nBecause the service payload is in XML, a service management tool usually has the capability to \"mine\" the request and response messages via XPath for relevant auditing, metering, billing, and traceability information.\nOnce XML became prevalent in other tiers, it naturally led to XML being persisted in the resource tier. All relational databases support XML storage in some way. XML databases have emerged as a specialized category of databases for storing XML documents. These databases excel at storing unstructured data, transient data, and configuration data. Because XML Schemas can often be changed without impacting clients, XML provides a very versatile and agile data structure.\nXML is becoming the de facto standard for storing configuration data. It has several advantages over other approaches. A single document can store complex data structures of related meta data elements in a cohesive manner. This document can be versioned in a configuration management tool. Document-oriented meta data can be made available to an application via an XML database, filesystem, or URI. It can be loaded in memory as a DOM and easily queried.\nXML was born in 1997. Its elegant simplicity, cross-platform compatibility, and many other virtues have led to wide adoption. XML has inspired many technologies. In enterprise architecture, XML has become the standard for inter-tier communication. Within each tier, XML and XML-related technologies have become pervasive.\nWhy has XML made such an impact in such a short time? Software architectures utilizing XML and XML technologies are more maintainable, portable, reusable, integrable, and testable. XML has tremendously improved agility in enterprise architecture.\nIs XML really boring? How people have used it is rather inspiring. How are you going to use XML and XML technologies to improve your agility today? The rest is up to you!\nAbout the Author\n|Jeff Ryan is an architect for Hartford Financial Services. He has twenty years experience designing, developing and delivering automated solutions to business problems. His current focus is on Java, XML and Service Oriented Architecture. He may be reached at email@example.com.|", "label": 1}
{"text": "IT Technician Job Description\nA IT technician job description can mean anything from overseeing the activities meant to support the network, mainframe or microcomputer computing field. They install and maintain everything related to these environments, including software, hardware and networks. They must be aware of the procedures, practices, methods, regulations, policies and all other laws related to the fields. They can also provide end user assistance and training whenever necessary.\nA more detailed IT technician jobs description will look something like this:\nPerform installations, maintenance and repair work on any computer related equipment that supports the business from laptops, desktops, communications equipment (digital & IP phones), tablets (ex. iPad’s), smart phones (ex. Blackberry’s, iPhone’s, Android’s), printers, local area networks, wide area networks, any piece of computer related peripheral or software an end user would be using. An IT technician has to perform the majority of the mentioned tasks while providing a high level of customer service to the user.\nThe job responsibilities of an IT technician can be classified as follows.\n1. Monitoring and maintaining technology for maximum access, which includes:\na. Connecting and setting up hardware\nb. Installing work stations\nc. Loading all necessary software\nd. Providing network access and connectivity to the staff\ne. Monitoring security\nf. Installing and maintaining passwords and Foolproof\ng. Advising staff about any security breach such as change in password\nh. Ensuring that lock out programs are installed\ni. Troubleshooting all issues in a timely manner\nj. Maintaining IP addresses\nk. Maintaining a list of necessary maintenance and repairs\nl. Researching both current and potential services and resources\nm. Making recommendations about the purchase of resources\nn. Identifying and preparing hardware for safe disposal\no. Ensuring hardware is secured and stripped before disposal\n2. Ensuring technology is equipped with the latest hardware and software and is accessible,\nwhere the main activities are:\na. Troubleshooting network operating system, software and hardware\nb. Being familiar with network operating system, software and hardware\nc. Work within a ticketing system and create documentation for new processes\nd. Training staff to maximize the potential of existing technology\ne. Taking new users through the orientation process\nf. Providing individual support and training upon request\ng. Providing recommendations about support and information access\nh. Maintaining an updated inventory of software, hardware and resources\ni. Demonstrated aptitude for continuous learning and innovative thinking\nj. Able to work independently and in a team environment\nk. Strong written, oral and interpersonal skills with a demonstrated ability to communicate with outside vendors and internal staff.\n3. Performing any other IT related duties during working hours and when necessary sometimes after hour on-call work.\nMost organizations have a wide array of technologies to support which mostly consist of the following:\n- Microsoft Windows XP, Windows 7 operating systems\n- Microsoft Office 2003, 2007, 2010\n- Microsoft Exchange, Outlook email client\n- IBM Lotus Domino & Lotus Notes email client\n- Novell Groupwise\nIT Technician & Desktop Certifications:\n- CompTIA: Computer Technology Industry Association\n- A+: Certified Computer Technician\n- MCITP: Microsoft Certified IT Professional\n- MCTS: Microsoft Certified Technology Specialist\n• University degree or college diploma in computer science or one year’s equivalent work experience\n• Extensive experience of computers and servers or at least MCSE 2000 qualification\n• Thorough understanding of PC and network hardware\n• Experience in hands-on hardware troubleshooting\n• Experience in equipment support\n• Working technical knowledge of the latest operating systems, network protocols and standards.\n• Ability to read all relevant documents, including OEM guides, procedural documentation and technical manuals and understand them well.\n• Ability to use peripheral accessories, components and other related tools.\n• Ability to carry relevant research\n• Ability to perform tasks and prioritize in high-pressure environments\n• Attention to detail\n• A good understanding of the organization’s objectives\n• Good interpersonal and relationship-building skills\n• Good customer-service orientation\n• Physical Demands: IT technicians spend a lot of time sitting, which may lead to muscle strain. They are also required to lift computer equipment, materials and supplies.\n• Environmental Conditions: The IT technicians must be prepared for interruptions as they manage several projects simultaneously. They may work under noisy and busy\nenvironments. They need time, stress and organizational management skills.\n• Sensory Demands: Using computers for extended periods may lead to eyestrain and headaches. It may also be challenging to concentrate when working in noisy and busy\n• Mental Demands: Since the IT technicians will deal with frustrated clients who require their services immediately, the work environment may be rather stressful.\nThere are several certifications and hands on training courses that can be found in most educational institutes, training facilities and software companies. These certifications can be obtained to make sure IT Technicians are always up to date with the latest versions of software, hardware and operating systems. Many of these certifications build on each other and some are more suitable for more experienced IT Technicians. Who then can pursue a Systems Administrators position, which administer and support the infrastructure and servers that the desktops and laptops connect too. One can even pursue a Network Administrator position. This individual would be in charge of the network itself, everything from the switch, routers and connectivity for the entire infrastructure. Getting the proper training, experience under your belt and becoming certified can provide a wide array of opportunities, higher paying jobs and an exciting career in the Information Technology sector which is always in demand.", "label": 1}
{"text": "Many IT organizations today are scratching their heads debating whether the advantages of implementing a Storage Area Network (SAN) solution justify the associated costs. Others are trying to get a handle on today's storage options and whether SAN is simply Network Attached Storage spelled backwards. In this article, I introduce the basic purpose and function of a SAN and examine its role in modern network environments. I also look at how SANs meet the network storage needs of today's organizations and answer the question, could a SAN be right for you.\nPeel away the layers of even the most complex technologies and you are likely to find that they provide the most basic of functions. This is certainly true of storage area networks (SANs). Behind the acronyms and revolutionary headlines, lies a technology designed to provide a way of offering one of the oldest of network services, that of making access to data storage devices available to clients.\nIn very basic terms, a SAN can be anything from two servers on a network accessing a central pool of storage devices to several thousand servers accessing many millions of megabytes of storage. Conceptually, a SAN can be thought of as a separate network of storage devices physically removed from, but still connected to, the network. SANs evolved from the concept of taking storage devices, and therefore storage traffic, off the LAN and creating a separate back-end network designed specifically for data.\nSANs represent the evolution of data storage technology to this point. Traditionally, on client server systems, data was stored on devices either inside or directly attached to the server. Next in the evolutionary scale came Network Attached Storage (NAS) which took the storage devices away from the server and connected them directly to the network. SANs take the principle one step further by allowing storage devices to exist on their own separate network and communicate directly with each other over very fast media. Users can gain access to these storage devices through server systems which are connected to both the LAN and the SAN.\nThis is in contrast to the use of a traditional LAN for providing a connection for server-storage, a strategy that limits overall network bandwidth. SANs address the bandwidth bottlenecks associated with LAN based server storage and the scalability limitations found with SCSI bus based implementations. SANs provide modular scalability, high-availability, increased fault tolerance and centralized storage management. These advantages have led to an increase in the popularity of SANs as they are quite simply better suited to address the data storage needs of today's data intensive network environments.\nThe advantages of SANs are numerous, but perhaps one of the best examples is that of the serverless backup (also commonly referred to as 3rd Party Copying). This system allows a disk storage device to copy data directly to a backup device across the high-speed links of the SAN without any intervention from a server. Data is kept on the SAN, which means the transfer does not pollute the LAN, and the server processing resources are still available to client systems.\nSANs are most commonly implemented using a technology called Fibre channel (yes, that's fibre with an 're', not an 'er'). Fibre Channel is a set of communication standards developed by the American National Standards Institute (ANSI). These standards define a high-performance data communications technology that supports very fast data rates (over 2Gbps). Fibre channel can be used in a point-to-point configuration between two devices, in a 'ring' type model known as an arbitrated loop, and in a fabric model.\nDevices on the SAN are normally connected together through a special kind of switch, called a Fibre Channel switch, which performs basically the same function as a switch on an Ethernet network, in that it acts as a connectivity point for the devices. Because Fibre channel is a switched technology, it is able to provide a dedicated path between the devices in the fabric so that they can utilize the entire bandwidth for the duration of the communication.\nThe storage devices are connected to Fibre Channel switch using either multimode or single mode fiber optic cable. Multimode for short distances (up to 2 kilometers), single mode for longer. In the storage devices themselves, special fiber channel interfaces provide the connectivity points. These interfaces can take the form of built in adapters, which are commonly found in storage subsystems designed for SANs, or can be interface cards much like a network card, which are installed into server systems.\nSo, the question that remains is this. Should you be moving away from your current storage strategy and towards a SAN? The answer is not a simple one. If you have the need to centralize or streamline your data storage then a SAN may be right for you. There is, of course, one barrier between you and storage heaven, and that's money. While SANs remain the domain of big business, the price tag's of SAN equipment is likely to remain at a level outside the reach of most small or even medium sized businesses. As the prices fall, however, SANs will find their way into organizations of all sizes, including, if you want, yours.\nYour White Papers Search Results\nThe Top Ten Headaches Caused by Remote Office Storage\nIT directors at growing, distributed enterprises face a number of unique challenges, particularly when it comes to storage. IT has to ensure that...\nThe Criteria to Select the Right Virtual Server Backup Software Solution for...\nOne of the most important decisions small and midsize enterprises (SMEs) face from an IT perspective is how to best leverage virtualization in...", "label": 1}
{"text": "New miniature camera technology may be about to give the US military's insect-sized surveillance drones a new way of seeing the world that's more energy-conscious than before. Yay, technology?\nNew Scientist reports that a new microchip-sized digital camera, developed by the California Institute of Technology using funding from NASA and the Pentagon, has been patented and is expected to replace current camera technology on the tiny spy drones. According to the article, the revolutionary aspect of the design is that the new size means that the main power drain on existing minicams - connecting the chips for the sensors and support circuitry - is no longer necessary, making the new remote controlled camera use much less energy, and therefore be more suited for secret surveillance missions. I'm not sure how I feel about this news, not least of all because I didn't even know that the US military even had insect-sized surveillance drones before.\nSpying roboflies to get minicam eyes [New Scientist]", "label": 1}
{"text": "Air Force Research Lab's vision for military MAVs\nIn a recent blog post we've asked if autonomous battlefield robots can behave more ethically than humans. But today's weaponized robots are not the only ones that raise ethical concerns. The development of miniature robots will soon allow surveillance to move out of the cyberspace, bringing privacy concerns to a new level.\nA video released by the Air Force Research Laboratory and published via the Chicago Tribune now shows how the military envisions the future use of micro air vehicles (MAVs) for both, surveillance and direct attack missions using chemical or explosive payloads.\nThe video shows a swarm of MAVs being dropped out of a high flying airplane and then goes on to explain how the MAVs could be hidden in plain sight, for example disguised as flies or doves. It envisions MAVs forming sensor networks to enhance their sensing and operating capabilities, and harvesting their energy from the environment including power lines to extend their mission time indefinitely.", "label": 1}
{"text": "What are common sources of threats to mobile devices or the health information on them?\nThe United States Government Accountability Office (GAO) recently issued a report to Congress called “Information Security: Better Implementation of Controls for Mobile Devices Should Be Encouraged.” The Report identified mobile device threat sources such as hackers, cybercriminals and Botnet operators. The Report explains how threat sources get control of or gain access to information on mobile devices.\n- Botnet Operators: Botnet operators widely distribute malware to mobile devices and coordinate remotely controlled attacks on websites. They also distribute phishing schemes, spam, and malware attacks on individual mobile devices.\n- Cybercriminals: Cyber criminals attack mobile devices for money. They gain access to information stored on a mobile device using spam, phishing or spyware/malware and use the information to commit identity theft, online fraud, and computer extortion. International criminal organizations attack mobile devices to conduct industrial espionage and large-scale money and intellectual property theft, posing a threat to corporations, institutions and government agencies.\n- Hackers: Hackers sometimes attack mobile devices to show their skills or gain prestige in the hacker community. Hacking used to require computer skills and knowledge, but today’s hackers can download attack scripts and protocols from the Internet and launch them against mobile devices.", "label": 1}
{"text": "The digital signatures play a vital role in the organizations since this technology enables the businesses to reduce the human errors, ultimately minimizes the paper work. Digital signatures enable the businesses to manage their monetary subsidiary and cost of paper work. Also, these signatures help the companies in proving that they’re utilizing the green policies and eco friendly procedures by cutting back the use of paper.\nThis vast technology even reduces the time consumed in sending numerous emails and documents, since the entire work is entitled in few moments. The corporations prove their sharp time management skills through this technology.\nWhat does a digital signature actually do?\nMost businesses use the digital signatures for the different types of paper transactions. These signatures analyze and approve the documents directly, as the whole information is preserved digitally by them. Thus, there is no more need to move to various locations for documents approval.\nNowadays, most of the companies and corporations in the market are adopting this technology for business purposes. The great thing about it is that it’s an efficient and safe method that ensures the security and reliability of the confidential information. Since, it’s a secure method most of the companies use this technology. Digital signatures enable the huge companies and businesses to store and secure their essential documents digitally.\nWhat’s the role of digital encryption in the digital signatures process?\nThe digital signatures technique has one aspect named as digital encryption that is significant in the whole procedure of this method. This technology enables the companies to acknowledge and authenticate the user’s id. Digital encryption can validate various kinds of digitally stored contents and documents.\nOften the digitally stored files ensure that their content won’t be accessed and attacked through an illegal process. The hash methods and numerical values are used to protect the data. In order to access the information the users are asked to follow the validation procedures to generate the permission and after the validation the user will be able to access the information.\nIn this whole procedure if the user tries to access or copy the data illegally the system never allows the user to do it because the keys entered by him won’t match certain authentication keys. Thus, he won’t be able to get into the documents stored by the digital signatures. First the confirmation is asked to the receiver, thus the authenticity totally lies on the reliability of the user.\nSignificance of protective measures in digital signatures:\nAs different kinds of variations occur in computer networks with time, the protection and authentication methods are hugely required to secure the information. Protection is required in every facet, so various kinds of strategies and processes should be applied to maintain the aspects related with security.\nGenerally, the digital signatures are applied for different functions and its major function is to store and protect the confidential information. This major function involves in identifying the user, who is requesting to access the information and sending the security messages to the user.", "label": 1}
{"text": "Cloud computing technology is deployed in three general types, based on the level of internal or external ownership and the technical merits: public cloud (external), private cloud (internal), or hybrid cloud.\nPublic cloud is the provision of cloud computing services whereby applications, storage and other resources are shared among multiple customers over the internet or a private network, with varying degrees of data privacy control.\nPrivate cloud uses similar computing architectures to the public cloud, but is generally built, managed and used internally by an enterprise.\nHybrid cloud is a mix of public cloud services, internal cloud computing architectures and traditional IT infrastructure, forming a hybrid model that meets the specific needs of the customers.\nTax treatment of cloud computing\nThere is no comprehensive set of US guidance for the tax treatment of cloud computing (e.g. characterization, sourcing and reporting obligations). The US Treasury instead adapts existing tax principles to the cloud rather than creating new or additional tax regimes.\nCharacterization of income\nThe character of the income earned from cloud computing drives the tax determinations of the treatment and the reporting obligations. Though the rules are not immediately clear, the character classification generally depends on the nature of the underlying interest that is granted to the customers as part of their access. Where the cloud operator earns income by providing access to applications, software, or storage, the transaction could be characterized as either a transfer of a computer program (sale or license) or a service provision that generates services income.\nThe character of payments to a cloud computing provider generally depends on the following (non-exclusive) factors:\n- Whether any derivative rights (such as the rights to make copies for purposes of distribution or to prepare derivative work) relating to the application or software were transferred as part of the access.\n- Whether the customers have physical possession of or control over their access to the software.\n- Whether the customers bear the risk associated with the maintenance of the software or application.\n- Whether the customers have exclusive access to the applications and software.\nThe determination will depend on the particular facts and circumstances of the arrangement. Generally, a transaction involving a computer program will be treated as a sales transaction if, subsequent to the transaction, the customer receives all substantial rights and bears the relevant benefits and risks of ownership with respect to the program. A transaction will be treated as a license if less than all substantial rights are transferred. Finally, a transaction will generally be treated as a provision of services if the customer merely has access to the computer program and does not bear the benefits and risks associated with ownership.\nSource of income\nThe source of income depends on the underlying character of the income. Generally, sales income is sourced where title and risk of loss is transferred; royalty income is sourced where the underlying right or property is used or protected; and services income is sourced at the location where the services are performed.\nEven after the character of income has been determined, the source of income analysis may still not be straightforward. For example, for services income, there is little guidance over where the services are considered to be performed for business activities conducted over the Internet. Applicable authorities suggest that the US tax authorities may treat the services as being performed at the location of the servers, provided there is limited human or additional outside involvement in the provision of the services.\nThe source of income can affect whether the income from cloud services will be taxable in the US, and whether withholding taxes are imposed on payments received from its cloud computing transactions.\nCorporate income tax\nCloud computing providers that are treated as tax residents of the US are generally subject to tax at the graduated corporate income tax rate on all income earned, regardless of its source.\nForeign corporations that provide cloud computing services (foreign opcos) are generally subject to corporate income tax in the US where their business income is connected with a US trade or business.\nA Foreign OpCo will generally be treated as conducting a US trade or business if it conducts considerable, continuous and regular business activities in the US. In addition, a Foreign OpCo may be treated as having a US trade or business through the activities of its agent, if the agent has the ability to bind or conclude contracts on behalf of the principal.\nThere are no clear rules on whether a Foreign OpCo should be treated as having engaged in a US trade or business as a result of utilizing servers in the US. However, if the US servers function as a critical part of a foreign opco’s business operations, such fact may be sufficient for US tax authorities to argue that the Foreign OpCo engages in considerable, continuous and regular business activities in the US and therefore has a US trade or business.\nIf a Foreign OpCo has a US trade or business, it is required to file a US federal income tax return, regardless of whether it has any income subject to tax during the taxable year. Nonetheless, the amount of income subject to US tax may be reduced or wholly exempted if the opco qualifies for benefits under an applicable US income tax treaty.\nIncome tax treaty and permanent establishment\nIf a Foreign OpCo qualifies for benefits under an applicable US income tax treaty, certain business income earned may be exempted from US corporate income tax. In most US income tax treaties, a Foreign OpCo must generally meet the requirements of the Limitation on Benefits Article to qualify for benefits under the treaty. While the specifics of the tests vary from treaty to treaty, a Foreign OpCo generally qualifies for benefits if it meets one of the following tests:\n- test based solely on ownership\n- ownership/base erosion test\n- active trade or business test.\nWhere a Foreign OpCo earns business income that qualifies for benefits under an income tax treaty, it may be exempted from US corporate income tax if it does not have a permanent establishment (PE) in the US. In determining whether a particular cloud provider has a PE in the US, one must consider the location of the servers used by the provider, and the outside functions that may be required to operate the cloud computing operations.\nUS tax authorities generally adopt the Organisation for Economic Co-operation and Development’s (OECD) approach, published in its commentary on e-Commerce, which considers an enterprise to have a PE at the location of the server, but only if the enterprise has the server at its own disposal. There are no specific criteria for determining when an enterprise may be considered to have a server at its disposal. However, the OECD commentary on PEs generally states that if a taxpayer owns (or leases) and operates the server, it may be treated as having a server at its disposal and, therefore, a PE.\nThus, if a Foreign OpCo conducts its cloud operations through servers located in the US, there is a risk that it will be treated as having a US PE. However, where its cloud operations also require additional human intervention or other functions to be performed outside of the US, the Foreign OpCo may allocate portions of the income earned to those functions in accordance with the profit attribution principles under the treaty.\nA Foreign OpCo may be subject to US withholding tax if it earns US source income that is treated as fixed, determinable, annual and periodic (FDAP) income that is not effectively connected with a US trade or business. FDAP income is defined broadly to include most income that is not derived from gain from the sale of property. In cloud computing, typical FDAP income that may arise includes royalty, interest and dividend payments.\nIf a Foreign OpCo earns US source FDAP income that is not connected with a US trade or business, such income will generally be subject to a 30 percent US withholding tax. The withhold tax on FDAP income may be reduced or wholly exempted if the Foreign OpCo qualifies for benefits under an applicable income tax treaty.\nUS trade or business analysis\nForeign OpCo may be treated as having a US trade or business in this case, because it is using its parent company’s US servers to accept orders from its customers. In addition, Foreign OpCo may also be treated as having a US trade or business based on the use of the server co’s US servers to host the platform that the customers access. Though reasonable arguments could be made otherwise, the significance of the US servers to the Foreign OpCo’s business operations is probably sufficient for US tax authorities to argue that Foreign OpCo has a US trade or business.\nIf Foreign OpCo is treated as having a US trade or business, it will be subject to US tax on its US source income, either as income connected to a US trade or business (subject to graduated corporate income tax) or FDAP (subject to a 30 percent withholding). As previously discussed, the source of income will depend on the income tax characterization of the payments.\nIf payments for access to the digital platform are treated as payments for the provision of services, the payments may be sourced in the US based on the location of the servers. Such US source income would generally be treated as effectively connected to foreign opco’s US trade or business if the income is derived from assets used in foreign opco’s conduct of a US trade or business, or if the activities of foreign opco’s US trade or business constitute a material factor in the realization of income.\nAssuming Foreign OpCo qualifies for benefits under an applicable income tax treaty, any income that is connected to a US trade or business may be exempted from US taxation if Foreign OpCo can establish that it does not have a US PE. In this case, Foreign OpCo may be treated as having a US PE through the activities of both server co and its US parent.\nA Foreign OpCo may argue that the activities of the server co should not establish a US PE on its behalf, if server company is legally and economically independent and does not otherwise act for or on behalf of the Foreign OpCo.\nThe Foreign OpCo may have more difficulty establishing that its US parent is not its agent, because the parent has (and exercises) the authority to bind Foreign OpCo when the parent accepts the order on the US servers. Unless additional facts exist to establish that the parent acts as the principal and compensates the Foreign OpCo for its marketing services, it is likely that the Foreign OpCo will be treated as having a US PE as a result of its agency relationship with the US parent. As a result, the Foreign OpCo’s income that is attributable to the US PE will be subject to corporate income tax in the US.\nRelated party transactions\nIf taxpayers engage in related party transactions as part of their cloud operations, such transactions are generally subject to US transfer pricing principles under Section 482. Generally, taxpayers that engage in related-party or controlled transactions may be subject to adjustments and allocations of income and deductions by the US tax authorities, if the transaction does not meet the arm’s length standard under Section 482.\nIn order to avoid transfer pricing adjustment-related penalties, taxpayers must maintain adequate transfer pricing documentation that meets the regulatory guidelines.\nState income tax\nThere are two key state income tax issues that cloud computing providers should address. First, does the enterprise have sufficient connection (nexus) in a particular state that would create an obligation to file state income tax returns? Second, if the enterprise has nexus in the state, does the enterprise have to include income from cloud computing when determining the state’s apportionment formula?\nStates generally have not issued comprehensive or uniform guidance on how a cloud computing arrangement should be treated and taxed. As a result, enterprises that provide cloud computing services should analyze on a state-by-state basis whether and how much of their income from cloud operations should be subject to state income tax.\nSales and use tax\nIn addition to state income tax, most states also impose sales and use tax collection responsibility on businesses that operate within their jurisdiction. Generally, the character of the transaction and source of the income derived from the transaction are the issues that need to be analyzed for sales and use tax purposes.\nMost states have not issued guidance on how the traditional sales and use tax principles should be applied to the provision of cloud computing services. To the extent that guidance has been issued, it is often limited and differs for each jurisdiction. As there can be significant differences between the states on how the same cloud computing transaction should be treated, cloud providers (and to some extent, their customers) should carefully analyze the transaction on a state-by-state basis, to determine whether they have any sales and use tax obligation.", "label": 1}
{"text": "What you can do about spyware and other unwanted software\nWhat is spyware?\nSpyware is a general term used for software that performs certain behaviors such as advertising, collecting personal information, or changing the configuration of your computer, generally without appropriately obtaining your consent. You might have spyware or other unwanted software on your computer if:\n? You see pop-up advertisements even when you're not on the Web.\n? The page your Web browser first opens to (your home page) or your browser search settings have changed without your knowledge.\n? You notice a new toolbar in your browser that you didn't want, and find it difficult to get rid of.\n? Your computer takes longer than usual to complete certain tasks.\n? You experience a sudden rise in computer crashes.\nSpyware is often associated with software that displays advertisements (called adware) or software that tracks personal or sensitive information. That does not mean all software which provides ads or tracks your online activities is bad. For example, you might sign up for a free music service, but \"pay\" for the service by agreeing to receive targeted ads. If you understand the terms and agree to them, you may have decided that it is a fair tradeoff. You might also agree to let the company track your online activities to determine which ads to show you.\nOther kinds of unwanted software will make changes to your computer that can be annoying and can cause your computer slow down or crash. These programs have the ability to change your Web browser's home page or search page, or add additional components to your browser you don't need or want. These programs also make it very difficult for you to change your settings back to the way you originally had them. These types of unwanted programs are also often called spyware.\nThe key in all cases is whether or not you (or someone who uses your computer) understand what the software will do and have agreed to install the software on your computer.\nThere are a number of ways spyware or other unwanted software can get on your system. A common trick is to covertly install the software during the installation of other software you want such as a music or video file sharing program. Whenever you are installing something on your computer, make sure you carefully read all disclosures, including the license agreement and privacy statement. Sometimes the inclusion of unwanted software in a given software installation is documented, but it may appear at the end of a license agreement or privacy statement.\nSigns of spyware\nIf your computer starts to behave strangely or displays any of the symptoms listed below, you may have spyware or other unwanted software installed on your computer.\n? I see pop-up advertisements all the time. Some unwanted software will bombard you with pop-up ads that aren't related to a particular Web site you're visiting. These ads are often for adult or other Web sites you may find objectionable. If you see pop-up ads as soon as you turn on your computer or when you're not even browsing the Web, you may have spyware or other unwanted software on your computer.\n? My settings have changed and I can't change them back to the way they were. Some unwanted software has the ability to change your home page or search page settings. This means that the page that opens first when you start your Internet browser or the page that appears when you select \"search\" may be pages that you do not recognize. Even if you know how to adjust these settings, you may find that they revert back every time you restart your computer.\n? My Web browser contains additional components that I don't remember downloading. Spyware and other unwanted software can add additional toolbars to your Web browser that you don't want or need. Even if you know how to remove these toolbars, they may return each time you restart your computer.\n? My computer seems sluggish. Spyware and other unwanted software are not necessarily designed to be efficient. The resources these programs use to track your activities and deliver advertisements can slow down your computer and errors in the software can make your computer crash. If you notice a sudden increase in the number of times a certain program crashes, or if your computer is slower than normal at performing routine tasks, you may have spyware or other unwanted software on your machine.\nHow to get rid of spyware\nMany kinds of unwanted software, including spyware, are designed to be difficult to remove. If you try to uninstall this software like any other program, you might find that the program reappears as soon as you restart your computer. If you're having trouble uninstalling unwanted software, you may need to download a tool to do the job for you. Several companies offer free and low-cost software that will check your computer for spyware and other unwanted software and help you remove it.\nSome Internet Service Providers (ISPs) include anti-spyware software in their service packages. Check with your ISP to see if they can recommend or provide a tool. If your ISP doesn't offer a removal tool for spyware and other unwanted software, ask people you trust to recommend one, or see the list below for a few well-known tools. Keep in mind that removing unwanted software with these tools may mean you will no longer be able to use a free program that came with the spyware.\nTo remove spyware\n1. Download the new Microsoft Windows AntiSpyware (Beta) or another spyware removal tool.\n2. Run the tool to scan your computer for spyware and other unwanted software.\n3. Review the files discovered by the tool for spyware and other unwanted software.\n4. Select suspicious files for removal by following the tool's instructions.\nHow to prevent spyware\nSpyware and other unwanted software can invade your privacy, bombard you with pop-up windows, slow down your computer, and even make your computer crash. Here are several ways you can help protect your computer against spyware and other unwanted software.\nStep 1: Update your software\nIf you use Windows XP, one way to help prevent spyware and other unwanted software is to make sure all your software is updated. First, visit Windows Update to confirm that you have Automatic Updates turned on and that you've downloaded all the latest critical and security updates.\nStep 2: Adjust Internet Explorer security settings\nYou can adjust your Internet Explorer Web browser's security settings to determine how much?or how little?information you are willing to accept from a Web site. Microsoft recommends that you set the security settings for the Internet zone to Medium or higher.\nTo view your current Internet Explorer security settings:\n1. In Internet Explorer, click Tools and then click Internet Options.\n2. Select the Security tab.\nIf you're running Windows XP Service Pack 2 (SP2) and you use Internet Explorer to browse the Web, your browser security settings for the Internet zone are already set to Medium by default. Internet Explorer in Windows XP SP2 also includes a number of features to help protect against spyware and many other kinds of deceptive or unwanted software.\nStep 3: Use a firewall\nWhile most spyware and other unwanted software come bundled with other programs or originate from unscrupulous Web sites, a small amount of spyware can actually be placed on your computer remotely by hackers. Installing a firewall or using the firewall that's built into Windows XP provides a helpful defense against these hackers. To learn more about firewalls, read Why you should use a computer firewall and get answers to your Frequently asked questions about firewalls.\nStep 4: Surf and download more safely\nThe best defense against spyware and other unwanted software is not to download it in the first place. Here are a few helpful tips that can protect you from downloading software you don't want:\n? Only download programs from Web sites you trust. If you're not sure whether to trust a program you are considering downloading, ask a knowledgeable friend or enter the name of the program into your favorite search engine to see if anyone else has reported that it contains spyware.\n? Read all security warnings, license agreements, and privacy statements associated with any software you download.\n? Never click \"agree\" or \"OK\" to close a window. Instead, click the red \"x\" in the corner of the window or press the Alt + F4 buttons on your keyboard to close a window.\n? Be wary of popular \"free\" music and movie file-sharing programs, and be sure you clearly understand all of the software packaged with those programs.\nStep 5: Download and install anti-spyware protection\nMicrosoft currently offers anti-spyware beta software for download; more information is available on our Microsoft Windows AntiSpyware (Beta) site.", "label": 1}
{"text": "Cybercriminals using digitally signed Java exploits to trick users\n- — 05 March, 2013 17:52\nSecurity researchers warn that cybercriminals have started using Java exploits signed with digital certificates to trick users into allowing the malicious code to run inside browsers.\nA signed Java exploit was discovered Monday on a website belonging to the Chemnitz University of Technology in Germany that was infected with a Web exploit toolkit called g01pack, security researcher Eric Romang said Tuesday in a blog post.\n\"It's definitely go01 pack,\" Jindrich Kubec, director of threat intelligence at antivirus vendor Avast, said via email. The first sample of this signed Java exploit was detected on Feb. 28, he said.\nIt was not immediately clear if this exploit targets a new vulnerability or an older Java flaw that has already been patched. Oracle released new Java security updates on Monday to address two critical vulnerabilities, one of which was being actively exploited by attackers.\nJava exploits have traditionally been delivered as unsigned applets -- Java Web applications. The execution of such applets used to be automated in older Java versions, which allowed hackers to launch drive-by download attacks that were completely transparent to the victims.\nStarting with the January release of Java 7 Update 11, the default security controls for Web-based Java content are set to high, prompting users for confirmation before applets are allowed to run inside browsers, regardless of whether they are digitally signed or not.\nThat said, using signed exploits over unsigned ones does provide benefits for attackers, because the confirmation dialogs displayed by Java in the two cases are considerably different. The dialogs for unsigned Java applets are actually titled \"Security Warning.\"\nDigital signing is an important part of assuring users they can trust your code, Bogdan Botezatu, a senior e-threat analyst at antivirus vendor Bitdefender, said via email. The confirmation dialog displayed for signed code is much more discrete and less threatening than the one displayed in the case of unsigned code, he said.\n\"Additionally, Java itself processes signed and unsigned code differently and enforces security restrictions appropriately,\" Botezatu said. For example, if the Java security settings are set to \"very high,\" unsigned applets won't run at all, while signed applets will run if the user confirms the action. In corporate environments where very high Java security settings are enforced, code signing may be the only way for attackers to run a malicious applet on a targeted system, he said.\nThis new Java exploit has also brought to light the fact that Java does not check for digital certificate revocations by default.\nThe exploit found by researchers Monday was signed with a digital certificate that's most likely stolen. The certificate was issued by Go Daddy to a company called Clearesult Consulting based in Austin, Texas, and was subsequently revoked with a date of Dec 7, 2012.\nCertificate revocations can apply retroactively and it's not clear when exactly Go Daddy flagged the certificate for revocation. However, on Feb. 25, three days before the oldest sample of this exploit was detected, the certificate was already listed as revoked in the certificate revocation list published by the company, Kubec said. Despite this, Java sees the certificate as valid.\nOn the \"Advanced\" tab of the Java control panel, under the \"Advanced security settings\" category, there are two options called \"Check certificates for revocation using Certificate Revocation Lists (CRLs)\" and \"Enable online certificate validation\" -- the second option uses OCSP (Online Certificate Status Protocol). Both of these options are disabled by default.\nOracle does not have any comment about this issue at this time, Oracle's PR agency in the U.K. said Tuesday via email.\n\"Sacrificing security for convenience is a serious security oversight, especially as Java has been the most targeted third-party piece of software since November 2012,\" Botezatu said. However, Oracle is not alone in this, the researcher said, noting that Adobe ships Adobe Reader 11 with an important sandbox mechanism disabled by default for usability reasons.\nBoth Botezatu and Kubec are convinced that attackers will increasingly start using digitally signed Java exploits in order to bypass Java's new security restrictions more easily.\nSecurity firm Bit9 recently revealed that hackers compromised one of its digital certificates and used it to sign malware. Last year, hackers did the same with a compromised digital certificate from Adobe.\nThose incidents and this new Java exploit are proof that valid digital certificates can end up signing malicious code, Botezatu said. In this context, actively checking for certificate revocations is particularly important because it is the only mitigation available in case of certificate compromise, he said.\nUsers who require Java in a browser on a daily basis should consider enabling certificate revocation checking to better protect against attacks exploiting stolen certificates, said Adam Gowdiak, the founder of Polish vulnerability research firm Security Explorations, via email. Security Explorations researchers have found and reported over 50 Java vulnerabilities in the past year.\nWhile users should manually enable these certificate revocation options, many of them will probably not do it considering that they don't even install security updates, Kubec said. The researcher hopes that Oracle will turn on the feature automatically in a future update.", "label": 1}
{"text": "Passwords are an integral part of securing both IT systems and online accounts. In order to keep your system and information safe, it is important to take the time to create strong passwords that hackers and online thieves won't easily figure out.\nIf you think using 'password' as your password is no big deal, then it's time to rethink.\nSecurity experts have recently compiled a list of the worst passwords users can choose, and 'password' is at the very top of the list. Weak passwords make your information more vulnerable simply because hackers can guess them. It may be easier to pick a password that you don't have to think about, but it's a choice that you may come to regret.\nTo help you avoid common password choice mistakes that users make, management application provider SplashData has compiled a list of the 25 worst passwords to use:\nNo matter how sophisticated your security system is, a weak password gives hackers and online thieves an advantage. Helping all the users in your organization understand the importance of password strength will help you secure the IT systems in your organization.\nIf you're interested in learning more, please contact us so we can develop a comprehensive and custom security blueprint that meets your specific needs.\nReference: Worst Internet Passwords", "label": 1}
{"text": "Phishing has always been one of the most common e-mail threats, but it has now become a fairly difficult threat to detect and block. As we noted earlier in the year, the content of phishing emails has become essentially identical to legitimate messages.\nFrom the point of view of blocking and detecting email based on content, this is a serious issue. Because they are so similar to legitimate emails, any pattern likely to detect these phishing messages is also likely to detect many legitimate messages. This would raise the number of false positives to unacceptable levels.\nDetecting phishing emails based on analyzing URLs also presents a challenge because phishing sites are going down very quickly after they go online. According to the Global Phishing Survey report for the first half of 2012 that was released by the Anti-Phishing Working Group, the average uptime of a phishing site is now down to below 24 hours, with the median uptime just below six hours. This means that there is now relatively limited time to analyze and detect malicious sites, potentially reducing the effectivity of URLs for detecting phishing messages.", "label": 1}
{"text": "Air Force to launch robotic winged space planeApril 3rd, 2010 in Space & Earth / Space Exploration\n(AP) -- After a decade of development, the Air Force this month plans to launch a robotic spacecraft resembling a small space shuttle to conduct technology tests in orbit and then glide home to a California runway.\nThe ultimate purpose of the X-37B Orbital Test Vehicle and details about the craft, which has been passed between several government agencies, however, remain a mystery as it is prepared for launch April 19 from Cape Canaveral, Fla.\n\"As long as you're confused you're in good shape,\" said defense analyst John Pike, director of Globalsecurity.org. \"I looked into this a couple of years ago - the entire sort of hypersonic, suborbital, scramjet nest of programs - of which there are upwards of a dozen. The more I studied it the less I understood it.\"\nThe quietly scheduled launch culminates the project's long and expensive journey from NASA to the Pentagon's research and development arm and then to a secretive Air Force unit.\nHundreds of millions of dollars have been spent on the X-37 program, but the current total has not been released.\nThe launch date, landing sites and a fact sheet were released by Air Force spokeswoman Maj. Angie I. Blair. She said more information would be released soon, but questions on cost and other matters submitted by e-mail weren't answered by Friday.\nWhile the massive space shuttles have been likened to cargo-hauling trucks, the X-37B is more like a sports car, with the equivalent trunk capacity.\nBuilt by Boeing Co.'s Phantom Works, the 11,000-pound craft is 9 1/2 feet tall and just over 29 feet long, with a wingspan of less than 15 feet. It has two angled tail fins rather than a single vertical stabilizer.\nUnlike the shuttle, it will be launched like a satellite, housed in a fairing atop an expendable Atlas V rocket, and deploy solar panels to provide electrical power in orbit.\nThe Air Force released only a general description of the mission objectives: testing of guidance, navigation, control, thermal protection and autonomous operation in orbit, re-entry and landing.\nThe mission's length was not released but the Air Force said the X-37B can stay in orbit for 270 days. The primary landing site will be northwest of Los Angeles at coastal Vandenberg Air Force Base.\nThe significance of the X-37B is unclear because the program has been around for so long, said Peter A. Wilson, a senior defense research analyst for the RAND Corp. who several years ago served as executive director of a congressional panel that evaluated national security space launch requirements.\n\"From my perspective it's a little puzzling as to whether this is the beginning of a program or the end of one,\" Wilson said Friday in a telephone interview from Washington, D.C.\nAs NASA anticipated the end of the shuttle, the X-37B was viewed as a working prototype of the next-generation design of a fully reusable spacecraft, but the space agency lost interest and the Air Force picked it up, Wilson said.\n\"It's viewed as a prototype of a vehicle that could carry small payloads into orbit, carry out a variety of military missions and then return to Earth,\" he said.\nThe Air Force statement said the X-37 program is being used \"to continue full-scale development\" and orbital testing of a long-duration, reusable space vehicle.\nWilson sees the upcoming launch as \"a one-shot deal.\"\nHe acknowledged that he does not know if there is a classified portion of the program but said there is no evidence of a second vehicle being built to follow the prototype. In aerospace, a prototype typically remains a test vehicle used to prove and improve designs for successive operational vehicles.\nTo fully function as a completely reusable launch system there would also have to be development of a booster rocket that is capable of landing itself back on Earth to be reassembled with the spacecraft, according to Wilson, who does not see any support for such an initiative.\nWilson also said the usefulness of payloads such as small military satellites is in question, which would undercut the need for the launch system.\nThe X-37B is now under the direction of the Air Force's Rapid Capabilities Office. Its mission is to speed up development of combat-support systems and weapons systems.\nOperating since 2003, the office has worked on several things, including upgrading the air defenses around the nation's capital as an anti-terrorism measure and assessing threats to U.S. combat operations, according to an Air Force fact sheet.\nNASA began the X-37 program in 1999 in a cooperative deal with Boeing to roughly split the $173 million cost of developing an experimental space plane. The Air Force put in a small share.\nThe X-37, initially intended to be carried into space by shuttles in 2003, was a larger version of the Air Force X-40A, a concept for a \"Space Maneuver Vehicle\" to put small military satellites in orbit. The X-40A was dropped from a helicopter in glide and landing tests but was never capable of actual space flight.\nIn 2002, NASA awarded Boeing a $301 million contract to complete a version of the X-37 to be used in approach and landing tests and begin designing an orbital version that would fly in 2006.\nBut in 2004 NASA turned the project over to the Defense Advanced Research Projects Agency, the Defense Department's research and development arm. In 2006, the X-37 was put through captive-carry and drop tests using Mojave-based Scaled Composite LLC's White Knight, the jet that launched SpaceShipOne on the first private suborbital manned space flights.\nThe Air Force then began work on the X-37B, projecting it would fly in 2008. An Air Force News story at the time reported that the first one or two flights would check out the performance of the vehicle itself and then it would become a space test platform with unspecified components flown in its experiment bay.\n©2010 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\n\"Air Force to launch robotic winged space plane.\" April 3rd, 2010. http://phys.org/news189528362.html", "label": 1}
{"text": "What different types of security do there exist? Why and when should they be implemented?\nExample: SQL Injection Prevention\nPreventing Buffer overflow\nI cannot count the exploit that are based on this.\nI am no expert, but in my experience, there are several well-known attack vectors for systems:\nUnvalidated user data\nThis is the classic buffer-overrun, SQL injection, drive-by-download mechanism and is caused by insufficient planning or education on secure coding practices. It is important to ensure developers understand how any insecure code can be leveraged to exploit a zero-day attack on a computer. Just because your website doesn't do anything particularly secret/important, doesn't mean that getting root access on your webserver can't harm the other parts of the organisation.\nThis can be a blend of poor security infrastructure, policy or just bad passwords. The worlds most popular password is 'password1' since most email providers started insisting on alpha-numeric passwords - previously it was 'password'. If a dictionary-based attack can guess a users' password, the policy was insufficient.\nSome enterprising programmers leave quick-access backdoors in code in case they need to jump in and 'fix' the system. If you have any of these, deliberate or otherwise, your system is a ticking time-bomb.\nWhat to do about it\nIt depends completely on the type of app, what a potential exploit might accomplish and the expected environment.\nIf you are running in an environment assumed to be safe then you could argue few to none.\nIf you are writing a web app that is publicly exposed, or an app that involves a publicly exposed API you would have to think through the likely scenarios like defacement, false submissions, authentication exploits, getting access to data not belonging to you, etc.\nIf you are building an app that stores data locally you might need to be concerned with the security of that data, keeping it separate between users on a multi-user system, etc.\nIMHO there are not any security concerns that are ALWAYS applicable in every situation.\nBased on the number of attacks - see stats by Verizon, OWASP, WHID and others - the single biggest thing you can do to improve the security of a web application is implement solid input validation. Do not trust anything the client/browser sends you. This will pretty much sort your SQL injection issue, and help out in a number of other areas including field/buffer overflow.", "label": 1}
{"text": "Windows Azure Networking\nThe easiest way to connect to Windows Azure applications and data is through an ordinary Internet connection. But this simple solution isn’t always the best approach. Windows Azure also provides technologies for connecting users to Windows Azure datacenters. This article takes a look at these technologies.\nTable of Contents\nWindows Azure Virtual Network\nWindows Azure lets you create virtual machines (VMs) that run in Microsoft datacenters. Suppose your organization wants to use those VMs to run enterprise applications or other software that will be used by your firm’s employees. Maybe you want to create a SharePoint farm in the cloud, for example, or run an inventory management application. To make life as easy as possible for your users, you’d like these applications to be accessible just as if they were running in your own datacenter.\nThere’s a standard solution to this kind of problem: create a virtual private network (VPN). Organizations of all sizes do this today to link, say, branch office computers to the main company datacenter. This same approach can work with Windows Azure VMs, as Figure 1 shows.\nFigure 1: Windows Azure Virtual Network allows creating a virtual network in the cloud that’s connected to your on-premises datacenter.\nAs the figure shows, Windows Azure Virtual Network lets you create a logical boundary around a group of VMs, called a virtual network or VNET, in a Windows Azure datacenter. It then lets you establish an IPsec connection between this VNET and your local network. The VMs in a VNET can be created using Windows Azure Virtual Machines, Windows Azure Cloud Services, or both. In other words, they can be VMs created using either Windows Azure’s Infrastructure as a Service (IaaS) technology or its Platform as a Service (PaaS) technology. Whatever choice you make, creating the IPsec connection requires a VPN gateway device, specialized hardware that’s attached to your local network, and it also requires the services of your network administrator. Once this connection is in place, the Windows Azure VMs running in your VNET look like just another part of your organization’s network.\nAs Figure 1 suggests, you allocate IP addresses for the Windows Azure VMs from the same IP address space used in your own network. In the scenario shown here, which uses private IP addresses, the VMs in the cloud are just another IP subnet. Software running on your local network will see these VMs as if they were local, just as they do with traditional VPNs. And it’s important to note that because this connection happens at the IP level, the virtual and physical machines on both sides can be running any operating system. Windows Azure VMs running Windows Server or Linux can interact with on-premises machines running Windows, Linux, or other systems. It’s also possible to use mainstream management tools, including System Center and others, to manage the cloud VMs and the applications they contain.\nUsing Windows Azure Virtual Network makes sense in many situations. As already mentioned, this approach lets enterprise users more easily access cloud applications. An important aspect of this ease of use is the ability to make the Windows Azure VMs part of an existing on-premises Active Directory domain to give users single sign-on to the applications they run. You can also create an Active Directory domain in the cloud if you prefer, then connect this domain to your on-premises network.\nCreating a VNET in a Windows Azure datacenter effectively gives you access to a large pool of on-demand resources. You can create VMs on demand, pay for them while they’re running, then remove them (and stop paying) when you no longer need them. This can be useful for scenarios that need fast access to a preconfigured machine, such as development teams building new software. Rather than wait for a local administrator to set up the resources they need, they can create these resources themselves in the public cloud.\nAnd just as Virtual Network makes Windows Azure VMs appear local to on-premises resources, the reverse is also true: Software running in your local network now appears to be local to applications running in your Windows Azure VNET. Suppose you’d like to move an existing on-premises application to Windows Azure, for example, because you’ve determined that it will be less expensive to operate in the cloud. But what if the data that application uses is required by law to be stored on premises? In a situation like this, using Virtual Network lets the cloud application see an on-premises database system as if it were local—accessing it becomes straightforward. Whatever scenario you choose, the result is the same: Windows Azure becomes an extension of your own datacenter.\nWindows Azure Traffic Manager\nImagine that you’ve built a successful Windows Azure application. Your app is used by many people in many countries around the world. This is a great thing, but as is so often the case, success brings new problems. Here, for instance, your application most likely runs in multiple Windows Azure datacenters in different parts of the world. How can you intelligently route traffic across these datacenters so that your users always get the best experience?\nWindows Azure Traffic Manager is designed to solve this problem. Figure 3 shows how.\nFigure 3: Windows Azure Traffic Manager intelligently directs requests from users across instances of an application running in different Windows Azure datacenters.\nIn this example, your application is running in VMs spread across four datacenters: two in the US, one in Europe, and one in Asia. Suppose a user in Berlin wishes to access the application. If you’re using Traffic Manager, here’s what happens.\nAs usual, the user’s system looks up the DNS name of the application (step 1). This query is redirected to the Windows Azure DNS system (step 2), which then looks up the Traffic Manager policy for this application. Each policy is created by the owner of a particular Windows Azure application, either through a graphical interface or a REST API. However it’s created, the policy specifies one of three options:\n- Performance: All requests are sent to the closest datacenter.\n- Failover: All requests are sent to the datacenter specified by the creator of this policy, unless that datacenter is unavailable. In this case, requests are routed to other datacenters in the priority order defined by the policy’s creator.\n- Round Robin: All requests are spread equally across all datacenters in which the application is running.\nOnce it has the right policy, Traffic Manager figures out which datacenter this request should go to based on which of the three options is specified (step 3). It then returns the location of the chosen datacenter to the user (step 4), who accesses that instance of the application (step 5).\nFor this to work, Traffic Manager must have a current picture of which instances of the application are up and running in each datacenter. To make this possible, Traffic Manager periodically pings each copy of the application via an HTTP GET, then records whether it receives a response. If an application instance stops responding, Traffic Manager will stop sending traffic to that instance until it resumes responding to pings.\nNot every application is big enough or global enough to need Traffic Manager. For those that do, however, this can be a quite useful service.", "label": 1}
{"text": "Computer security and privacy protection is becoming more and more of a practical necessity. These days, data collection and the dangers of hacking are becoming more and more present and pervasive: nearly every website collects user data, and nearly every person with a computer should be thinking about how to protect their sensitive information. Norton Internet Security makes some of the best products for protecting privacy and ensuring the general security of your technology against viruses and other malicious threats like phishing and trojans. Norton has been making protective security software since 1990, and they offer a fairly comprehensive line of products to help their customers keep their computer systems and private information safe and secure.\nPrivacy is becoming an increasing issue in an age where nearly everything can be done or negotiated online. There are troubling statistics about just how much personally identifiable information is floating around unprotected on the Internet. Recently, for example, researchers at Carnegie Mellon found they could accurately predict the full nine-digit social security numbers of millions of people using publicly available information on the web. With 1 and 10 consumers in the US already having fallen victim to identity theft, investing in software to help protect your sensitive and private information is a wise decision. This infographic has some useful tips about how to further protect your data, and it lays out some of the facts about how pervasive data collection is and how it works.", "label": 1}
{"text": "You have probably received emails from associates warning you to be aware of a specific \"virus\"; if you did, you have most likely been the victim of a virus hoax. The DOT-COMmunications' helpdesk receives more calls about virus hoaxes than about any individual real virus.\nNote: some links on this page will open in a separate brower window\nVirus hoaxes are false reports about usually non-existent viruses, often claiming to do impossible things. Unfortunately some recipients occasionally believe a hoax to be a true virus warning and may take drastic action (such as shutting down their network) or deleting innocent files from their hard disk.\nTypically such hoaxes circulate by emails, which describe a dangerous new undetectable virus, usually using bogus technical terms. Hoaxes often ask you to avoid reading or downloading emails that have a particular subject line. Examples include Budweiser Frogs, It Takes Guts to Say Jesus, and Join the Crew.\nFor instance, the Good Times hoax claims to put your computer's CPU in \"an nth-complexity infinite binary loop, which can severely damage the processor\". Good thing it doesn't exist. The hoax warns you not to read or download anything with the subject \"Good Times\" because the message is a virus.\nOthers such as the Jdbgmgr.exe hoax rely on the presence of an existing file on people's computers to ensure that the hoax is perpetuated. Those supposedly infected are advised to send emails to everyone in their address book warning them that its likely that you have been infected by a virus that is not detected by Anti-virus systems. This virus supposedly sits quietly on your computer for 14 days before damaging the system. It is sent automatically by 'messenger' and by address book, whether or not you've sent e-mail to your contacts and advises you to search for a file with the name jdbgmgr.exe and which has a teddy bear icon. It advises you to delete the file and then urges you to warn as many people on their address book as possible that they may have been infected through your address book.\nYou are not helping people. The continued re-forwarding of these hoaxes simply wastes time and email bandwidth and could result in your email address being blocked as spam by others. It is also possible that you may receive a hoax via email with a file attached or advising you to download a special program. Obviously, such files should be treated with caution, as they may be viruses, spyware or Trojan programs.\nIn the case of hoaxes such as the Jdbgmgr.exe, the hoax encourages you to delete a legitimate Windows file from your computer. Jdbgmgr.exe is in fact the Microsoft Debugger Registrar for Java. The Jdbgmgr.exe file may be installed when you install Windows and does not do any harm to your system but its presence on your hard disk seeming confirms the \"truth\" of the warning and results in widespread hoax warnings.\nDOT-COMmunications' recommends deleting all virus hoax emails immediately, whether they contain file attachments or not and making sure you have a good anti-virus program installed, constantly updated and ran regularly.\nAlthough no official research has been done on the subject, it is estimated that hoaxes can cost you even more than a genuine virus incident. After all, no anti-virus program will detect hoaxes because they aren't really viruses and no amount of updates or new programs will detect something that doesn't exist. Some people panic when they receive a hoax virus warning - making the situation much worse. The amount of email that a typical hoax can generate is also a cost to organisations. Once a few people in your organisation have received a warning and mailed it to all their friends and colleagues, a mail overload can easily result.\nYour organisation may like to consider circulating a policy on virus hoaxes to your staff and volunteers, in an attempt to reduce the costs involved.\nHere is an example policy you could use:\n\"You shall not forward any virus warnings of any kind to *anyone* inside or outside the organisation other than <insert name of the department or staff member who looks after anti-virus issues or alternatively forward it to viruses@DOT-COMmunications.co.uk>. It doesn't matter if the virus warnings have apparently come from an anti-virus vendor or been confirmed by any large computer company or your best friend. *All* virus warnings should be sent to <insert name>, and <insert name> alone. It is <insert name>'s job to send round all virus warnings, and a virus warning which comes from any other source should be ignored.\"\nKeep yourself informed - you can ensure you have useful, up-to-the-minute data on the latest, \"hottest\" hoaxes with very little effort by visiting our latest virus information page.", "label": 1}
{"text": "Posted December 5, 2012 Atlanta, GA\nStudy finds security indicators sacrificed to accommodate small screens\nATLANTA – Dec. 5, 2012 – How unsafe are mobile browsers? Unsafe enough that even cyber-security experts are unable to detect when their smartphone browsers have landed on potentially dangerous websites, according to a recent Georgia Tech study.\nLike their counterparts for desktop platforms, mobile browsers incorporate a range of security and cryptographic tools to provide a secure Web-browsing experience. However in one critical area that informs user decisions—the incorporation of tiny graphical indicators in a browser’s URL field—all of the leading mobile browsers fail to meet security guidelines recommended by the World Wide Web Consortium (W3C) for browser safety, leaving even expert users with no way to determine if the websites they visit are real or imposter sites phishing for personal data.\n“We found vulnerabilities in all 10 of the mobile browsers we tested, which together account for more than 90 percent of the mobile browsers in use today in the United States,” said Patrick Traynor, assistant professor in Georgia Tech’s School of Computer Science. “The basic question we asked was, ‘Does this browser provide enough information for even an information-security expert to determine security standing?’ With all 10 of the leading browsers on the market today, the answer was no.”\nThe graphic icons at issue are called either SSL (“secure sockets layer”) or TLS (“transport layer security”) indicators, and they serve to alert users (a) when their connection to the destination website is secure and (b) that the website they see is actually the site they intended to visit. The tiny “lock” icon that typically appears in a desktop browser window when users are providing payment information in an online transaction is one example of an SSL indicator. Another is the “https” keyword that appears in the beginning of a desktop browser’s URL field.\nThe W3C has issued specific recommendations for how SSL indicators should be built into a browser’s user interface, and for the most part, Traynor said, desktop browsers do a good job of following those recommendations. In mobile browsers, however, the guidelines are followed inconsistently at best and often not at all.\nThe principal reason for this, Traynor admits, is the much smaller screen size with which designers of mobile browsers have to work. Often there simply isn’t room to incorporate SSL indicators in same way as with desktop browsers. However, given that mobile devices are widely predicted to face more frequent attacks from cyber-criminals, the vulnerability is almost sure to lead to increased cyber-crime unless it is addressed.\n“Research has shown that mobile browser users are three times more likely to access phishing sites than users of desktop browsers,” said Chaitrali Amrutkar, a Ph.D. student in the School of Computer Science and principal author of the paper that described the SSL research. “Is that all due to the lack of these SSL indicators? Probably not, but giving these tools a consistent and complete presence in mobile browsers would definitely help.”\nThe paper, “Measuring SSL Indicators on Mobile Browsers: Extended Life, or End of the Road,” earned Amrutkar a Best Student Paper award at this year’s Information Security Conference, held Sept. 19-21 in Passau, Germany. Traynor and Amrutkar said the study, essentially a measurement analysis of the current state of visual security indicators in mobile browsers, is a necessary first step in developing a uniform set of security recommendations that can apply to mobile browsers.\n“We understand the dilemma facing designers of mobile browsers, and it looks like all of them tried to do the best they could in balancing everything that has to fit within those small screens,” Traynor said. “But the fact is that all of them ended up doing something just a little different—and all inferior to desktop browsers. With a little coordination, we can do a better job and make mobile browsing a safer experience for all users.”\nAssistant Director of Communications\nCollege of Computing at Georgia Tech", "label": 1}
{"text": "Trust & security\nYou should always assume:\n- If somebody can login to a Unix/Linux host as a user, they can get root on that host.\n- If somebody can get root on a host, they can see anything that you type on that host (via keyboard or tty sniffing), even if you use an encrypted network connection.\nFor that reason, there are a few ways to look \"trust\" & system security:\n- Host A can be said to trust host B if someone from host B can login (especially if they login as root) to host A.\n- A user can be said to trust a host if the user types confidential information, such as important passwords, at that host.\nIf you are a system administrator, you need to take extra care to protect passwords that can be used to login to, or become root on, large numbers of hosts. For that reason, such passwords should only be typed on hosts that you have reason to believe are secure (such hosts are sometimes referred to as \"trusted hosts\" within SCS). A general rule of thumb is that trusted hosts only have accounts for people that you trust to be careful and take reasonable security precautions with their own passwords.\nOne way to avoid typing passwords at hosts that you administer to use your Kerberos root instance to allow Kerberized telnet & SSH autologins to remote hosts. See section on security in the local Unix administrators guide for details. If you need local console access to such hosts, one method is to set a temporary local root password that is unique to that host.\nThe following off-site links will open in a new browser window:\n- Trust & SATAN\n- A discussion of \"trust\" from a host-centered perspective.", "label": 1}
{"text": "May 25, 2011\nChallenge announced for creating new, small unmanned flying machine\nSmall unmanned aerial vehicles (UAVs) play a critical role in modern military operations. The next generation of these aerial robotic systems needs to have enhanced takeoff and landing capabilities, better endurance, require less support equipment and be adaptable to mission needs in varying conditions.\nThe Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center Atlantic (SSC Atlantic) call on innovators of every kind; scientists, engineers, citizen scientists and dreamers to collaborate on the UAVForge Challenge and win $100,000 USD.\nThe UAVForge challenge uses crowdsourcing to build small UAVs through an exchange of ideas and design practices. The goal is to build and test a user-intuitive, backpack-portable UAV that can quietly fly in and out of critical environments to conduct sustained surveillance for up to three hours.\nAccording to Jim McCormick, DARPA program manager, “The UAVForge crowd-sourced approach seeks to capture and mature novel ideas and systems integration methods from communities outside the traditional DoD acquisition process.”\nSelf-selected teams will participate in a series of peer-reviewed milestones where participant rating will identify the top ten teams that advance to the UAVForge Fly-Off Competition. During the competition, vehicles will be tested in a simulated high-stress surveillance mission.\n“This is a fascinating challenge and the solution space is wide open,” explained McCormick. “We’re excited to see what innovative ideas emerge, so we’re trying to give individuals and teams lots of time to develop their concepts prior to the initial design submission date planned for late this fall.”\nThe winning team will be awarded $100,000 and the opportunity to showcase its design in an overseas military exercise. Additionally, the winning team will work with a government-selected UAV manufacturer to produce a limited quantity of systems for future warfighter experimentation.\nWatch ideas take flight and learn more by visiting www.UAVForge.net.\n# # #\nMedia with inquiries, contact DARPA Public Affairs, DARPAPublicAffairsOffice@darpa.mil\nPlease direct all media queries to Outreach@DARPA.mil", "label": 1}
{"text": "The natural level of discomfort that results from the thought of global warming is reinforced by numerous reports claiming inevitable environmental doom. A recent article in the Nature Magazine went as far as predicting that over the next fifty years, well over one million species will cease to exist due to global warming.\nImpact of the Information Technology\nCoupled with the fear prompted by environmental experts and know-it-alls is a plethora of scams. Some attempt to persuade our beliefs, while others operate with the intentions of fraud. Far from being verified is one claim that global warming is a man-made predicament. Instead of drawing these conclusions from observable facts, these assumptions are based on methods of computer modeling that generate artificial, manipulable graphic-based visions of the earth. A computer can only process the information fed to it, which in this case is usually fraudulent data intended to stir up controversy.\nOther types of environmental fraud target those who carry enough concern about the planet to make a difference. These scams typically find their way to you via email, online survey or fraudulent website. Often, criminals will make an attempt to persuade you into contributing to the prevention of global warming, preservation of the rain forest or other environmental issues. These frauds are experienced and rather savvy, able to produce content that makes them appear legitimate. Some of them will even steal logos and other identifying materials to masquerade themselves as reputable environmental organizations. To further complicate matters, you typically will have no way of knowing where your contribution actually went. In a worst case scenario, a scam artist uses your personal information to commit identity theft and runs up hundreds to thousands in debt.\nIn the End\nIt just may be safe to assume that environmental problems such as global warming has everything to do with politics and little to do with science. Scientists who endorse these theories command and often receive robust government grants to conduct their research. Without the prevalence of imminent threats, scientists wouldn’t get funded, essentially making these environmental issues a big business. Right behind these scientist is a group of criminals determined to play on your fear and genuine concern to turn a profit. In the end, it is at your discretion whether or not you choose to believe or financially support these highly publicized environmental issues. At the same time, you must keep in mind that many of these theories are not supported by verifiable documentation while remaining aware of the numerous scams lurking in the background. You can do your part at preserving the environment by viewing the tips on the following website:www.environmental-expert.com", "label": 1}
{"text": "Important Aspects Of Cloud Computing\nImportant Aspects Of Cloud Computing\nCloud computing offers an answer to universities, research laboratories, the military, and the govt. agencies which utilize supercomputers to do complex jobs like securing the nation, seeking solutions to medical dilemmas, and analyzing the consequences of climate change. It’s able to making billions and trillions of computations per second.\nThrough cloud computing, users may be able to perform tasks like analysis of sales data, storing medical information of patients, and estimating business venture risks. Generally, cloud computing includes infrastructure-as-a-service, software-as-a-service, and platform-as-a-service. For an ordinary business, the computing costs are an analogous and the company often absorbs any upfront costs associated with cloud computing.\nThe infrastructure of cloud computing is commonly located off-site and accessible during the internet. It is also provided by a third-part and users should not have to have technological expertise. Lack of control and access in addition to potential security risks are common issues raised against cloud computing. Users, however, experience device and site independence they usually can access different applications through an internet browser using different devices.\nOften, cloud computing is confused with autonomic computing, grid computing, and utility computing although various providers do rely upon grids. It does share some traits with autonomic computing and feature an identical billing methods like those utilized by utilities. These days, these same providers have expanded and people systems available now now not have centralized billing infrastructures or systems . Large business organizations are actually tapping the largest cloud computing services providers for his or her needs.\nCloud computing was in a position to raise awareness towards resource optimization. Business executives are actually looking into savings they’ll generate from support personnel, software licenses, power, and space in the event that they get to the cloud. Initial steps are being undertaken by businesses, which not yet able to bring their computing requirements to the cloud, to pool and consolidated data and computing resources in addition to software efficiency.\nOn-demand, scaling, and automation features often lessen delivery lead-time for services and software to only a couple of minutes which ends to controlled steady-state expenses, diminished time-to-value, and captured runaway demand. Cloud computing is ready to push these business organizations to adopt technological strategies and investment practices in addition to operating models which will balance operating cash flows, capital outlays, control, time, and opportunity.\nCloud computing operating practices and technologies turn support and delivery right into a commodity. It offers a substitute for business executives. Those providers of data technology need to step up their profiles and offerings in order that they get nearest to their suppliers and customers, and business innovation by providing a brand new and higher capability delivery. They should adopt architectural practices, management, and technology strategies so they provide services and products which are easily bundled.\nCloud computing is usually capable of show its effectiveness as regards to software design discipline. It’s totally dependent upon the deployment readiness, quality, and design of its software to ensure that it to supply cost containment, performance, resource optimization, and scalability.\nLastly, cloud computing also paves the best way for the emergence of platforms. Which includes mobility and Web 2.0, it has altered the advance experience from working with data storage, middleware protocols, and O/S services to application programming interface and development toolkits. Developers can reap the benefits of cloud computing presentation, assembly, data, and infrastructure services then add their very own configurations and/or codes to lead to new personal, consumer, or business capabilities.\nBy Florence G. de Borja", "label": 1}
{"text": "How to Spot Fraudulant Emails\nEvery internet user should know about Internet fraud known as \"phishing\" or \"spoofing.\" Phishing is a technique used to trick you into revealing your personal information such as bank and credit card account numbers, passwords, your birth date and your social security number.\nThe scam is very simple. You receive an e-mail that appears to be from a company with whom you do business. It will tell you that your account information is out of date or needs to be re-verified, and it will include a link that will take you to a fake copy of the company's website. There, you'll be asked for your personal information which is then deposited into the hands of the criminals, which they can use to steal your money and your identity.\n- There may be obvious spelling or grammatical mistakes in the text of the e-mail.\n- The e-mail may convey a sense of urgency. For example, it might claim that you might be assessed a fee or that your account will be closed or suspended, if you do not respond quickly.\n- There are embedded links that appear to be legitimate because they contain the company's name. These links will take you to fake websites or pop-up windows that will ask you to provide your sensitive personal information.\nDo not be fooled! The Community State Bank or other companies will never ask you for your personal information via e-mail.\nHow to Protect Your Accounts\n- Never click on links found in unsolicited e-mails, especially if they ask for your personal information. Even if you don't enter any personal information, some of these links can install spyware or viruses on your computer that can record your account information.\n- Bookmark the websites of companies with whom you frequently do business, or type the URL by hand into your browser instead of clicking on links in emails.\n- Change your passwords regularly.\n- Make sure that you regularly install security updates on your computer. Many companies, including Microsoft and Netscape, offer these updates for free.\n- The Community State Bank will never telephone or e-mail you and ask you to provide your personal account information. Although you may be asked to verify your identity if you call us, we will never contact you requesting this information.\n- Never send personal information such as account numbers, passwords, your social security number or other confidential information in e-mail.", "label": 1}
{"text": "If you use Internet Explorer, it is vital that you read this announcement and act upon its contents. If not, it's still in your best interest to read on.\nSome weeks ago, a flaw was found in Microsoft's JPEG parser. Now, it appears somebody has created a JPEG virus that can actually infect your computer.\nWhat does this mean?\nIn the past, opening images was completely harmless from a security point of view, or at least it seemed to be. Not anymore. IE users with unpatched systems can be infected by simply looking at a malicious JPEG image.\nSo what does MC have to do with this?\nMembers of MC can put images inside their posts or signature or link to them, even upload them. Avatars are also pictures. We can't deny the possibility that somebody would put up a malicious image, although we hope and believe that none of our users would ever do so. One solution would be to turn off those features, but that would hardly be acceptable. However, this does prompt us to issue a very severe warning:\nIf you haven't done so already, update your computer!\nWindows Update will both update GDI+ and run a small program that determines what other programs on your computer need patching. Install the update, run the program, patch your other programs if necessary and then, if you use Microsoft Office, go to Office Update and install all available patches. Once you've completed these steps, you should be safe. However:\nMYSTcommunity and its staff are in no way responsible for the content posted by its members, including malicious images and other malware.\nAnd one more thing, which should speak for itself but is nonetheless very important:\nAny user found posting such malicious images on MC, linking to them, or referencing them in any other way will automatically be banned. No exceptions, no excuses.\nPage 1 of 1\nWarning about malicious JPEG images Very important information\nShare this topic:\nPage 1 of 1", "label": 1}
{"text": "Apples iCloud service lets users sync a staggering amount of data between Macs, Windows PCs, iPhones, and iPads. Though Apple says it stores this data securely in an encrypted format, just how safe is it? An Ars reader wrote in to ask us this question, so we decided to investigate.The simple answer is that your data is at least as safe as it is when stored on any remote server, if not more so. All data is transferred to computers and mobile devices using secure sockets layer via WebDAV, IMAP, or HTTP. All data except e-mail and notes—more on that later—are stored and encrypted on disk on Apples servers. And secure authentication tokens are created on mobile devices to retrieve information without constantly transmitting a password.", "label": 1}
{"text": "PHP Security and YOU - Including files the right way\nAs a web host we fight the battle against hackers and bad code on a daily basis. So HostNexus is looking to encourage clients to use file inclusion within PHP in a more security conscious and safe manner.\nIncluding files with PHP is a common practice and most usage comes in 2 forms. These are including internal files from your own domain and including files from remote (external) sources. This looks something like:\nBoth are valid syntax in the PHP world but there are two main problems we see on the servers. Sometimes when you include a file using the the URL of your local domain you can cause a PHP loop that initiates\nendless HTTP requests which causes server load issues and even a server crash due to the load. If you want to include files from your local domain you just need to use the server path instead:\nAnd now onto using include() for calling external files:\nThe main problem with include() is that runs everything through the PHP parser and evaluates code. The main problem comes from setting a variable for include() which can be easily exploited. Here is an example of code in an index.php:\necho \" <body>\\n\";\necho \" </body>\\n\";\nThe $go variable above is easily exploited like:\nThe hacker can now execute commands on your files, installing phishing sites, sending spam and stealing data.\nIf you want to include files from remote domains use PHP's readfile() function instead:\nWhile not 100% secure it still provides more protection as readfile() simply outputs data to a browser rather than parsing everything as PHP.\nI emailed about this issue in a recent NewsFlash and the blog post has been up for quite some time. We will be setting allow_url_include to off on all servers from August 1st so please check your code if you use includes and make the easy changes.\nTha's All Folks!\nSee you all next time.\n- Laurence, Head Coffee Maker, HostNexus", "label": 1}
{"text": "WASHINGTON – The U.S. Department of Homeland Security’s (DHS) Stop.Think.Connect.™ campaign has announced a new partnership with the Girl Scouts of the USA to help raise awareness among more than 3.2 million youth across the country about the importance of cybersecurity and online safety.\n“Today, we are more connected to the Internet than ever before, but increased interconnectivity increases the risk of theft, fraud and abuse,” said Secretary of Homeland Security Janet Napolitano. “We are proud to partner with Girl Scouts of the USA to help women and girls protect themselves online and do their part to ensure that cyberspace is a safe and secure environment for all Internet users.”\n“This collaboration between Girl Scouts and the U.S. Department of Homeland Security will empower girls to become leaders and advocates for the safe and responsible use of technology,” explains Anna Maria Chávez, Chief Executive Officer of the Girl Scouts of the USA. “We know that girls are online. As adults, it is our responsibility to create an environment that encourages girls to establish healthy online habits.”\nThe campaign will provide the Girl Scouts of the USA with tools and resources to help raise awareness among kids, teens, and young adults about emerging online threats and the importance of cybersecurity. This partnership builds on the campaign’s ongoing efforts to highlight curriculum resources available to communities, and to educate America’s youth about safer online practices.\nStop.Think.Connect.™ is a national public awareness effort to guide the nation to a higher level of Internet safety and security by educating and empowering the American public to be more vigilant about practicing safe online habits. The campaign encourages Americans to view Internet safety and security as a shared responsibility at home, in the workplace, and in our communities.", "label": 1}
{"text": "Dec. 9, 2010 A researcher at the University of Luxembourg has demonstrated a new class of attacks against mobile phones at the security conference DeepSec in Vienna. Using a base transceiver station (available for 1000 euro) he has shown how common programming errors in the communication stack of mobile phones can be exploited to gain control of the devices.\nRalf-Philipp Weinmann found devastating flaws in a large percentage of cellular communication stacks. According to him, sufficiently motivated attackers are able to attack phones in a way that is almost undetectable. Vulnerable cell phones can be taken over if they are within the range of the rogue transceiver, which may mean hundreds of phones at a time in crowded urban areas. Attackers can cause billing problems by either dialing premium numbers or sending text messages to premium services; or they can monitor the complete communications of the cell phone user.\nEavesdropping on nearby cell phones is also possible by making the vulnerable cell phone pick up incoming calls automatically -- without the user noticing.The attacking transceiver needs to be online for just a couple of seconds to perform the attack.\nThe University of Luxembourg, is working together with a number of vendors for both cellular communication chips and mobile phones. The objective is to fix the security flaws found and to prevent similar flaws from happening in the future.\nOther social bookmarking and sharing tools:\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "What is Tor?\nTor is free software and an open network that helps\nyou defend against a form of network surveillance that\nthreatens personal freedom and privacy, confidential business\nactivities and relationships, and state security known as traffic analysis\nLearn more about Tor »\nWhy Anonymity Matters\nTor protects you by bouncing your communications around a\ndistributed network of relays run by volunteers all around\nthe world: it prevents somebody watching your Internet\nconnection from learning what sites you visit, and it prevents\nthe sites you visit from learning your physical location.\nTor works with many of your existing applications, including\nweb browsers, instant messaging clients, remote login, and\nother applications based on the TCP protocol.\nGet involved with Tor »\nOur ProjectsLearn more about our projects »\nWho Uses Tor?\nPeople like you and your family use Tor to protect themselves, their children, and their dignity while using the Internet.\nBusinesses use Tor to research competition, keep business strategies confidential, and facilitate internal accountability.\nActivists use Tor to anonymously report abuses from danger zones. Whistleblowers use Tor to safely report on corruption.\nJournalists and the media use Tor to protect their research and sources online.\nMilitaries and law enforcement use Tor to protect their communications, investigations, and intelligence gathering online.\nCombined flashproxy and pyobfsproxy bundles now available. See the announcement for details.\nTails, The Amnesic Incognito Live System, version 0.16, is now available.", "label": 1}
{"text": "...making Linux just a little more fun!\nBy Ray Ingles\n\"There are two ways of constructing a software design. One way is to make it so simple that there are obviously no deficiencies, and the other is to make it so complicated that there are no obvious deficiencies.\" - C.A.R. Hoare\n\"Sure I'm paranoid, but am I paranoid ENOUGH?\" - Unknown\nSystem administrators frequently want to be able to work on the machines they run even when they are far away from them. There are secure tools that allow full remote shell access, like ssh and lsh, but due to their complexity they have suffered critical exploits from time to time. In addition, their overhead can be excessive for some purposes. Fortunately, other options are available that can be used alone or can be combined with remote shells to create a more secure overall system.\nMaybe the pager has just gone off when you're home in bed, and the boss wants you to fix the broken database now. Or perhaps you're out for lunch and someone calls to tell you the mailserver has been cracked and is currently spamming the world, and you need to bring it down fast. Possibly you've checked and your Web server has wedged itself and needs to be restarted. Or suppose you're just on vacation and find you want to update your home Web site with some new photos. In all these cases, you'd like to do something to the machine over the Internet without having to actually sit in front of it - things you don't want just anybody to be able to do.\nTools like ssh and lsh are great for allowing secure remote access to your system. They offer essentially full, flexible remote control of a machine, in an encrypted and authenticated manner. But they are complex pieces of software; there's no way to do what they do without being complex. And with complexity comes bugs. SSH and lsh, and related tools like Webmin, have all had serious flaws that would allow an attacker to get full control over your system. Leaving them available all the time is a risk - sometimes it's necessary, but it's still a risk. And in some cases, you'd like to be able to tell the machine to do something, but it's not even attached to the network on a regular basis.\nIt would be nice to enable remote shell access only when necessary. And perhaps (for something like shutting down a mail server) you don't even need a full shell, just a way to fire off a script remotely. Of course, the problem then becomes, how do you know that the alternative software is any more secure than ssh itself? Various people have worked on this problem in the past, and several potential solutions are available, ranging from the simple and venerable to the new and exotic.\nXringd uses a modem to control a machine remotely. Mail filters can be used to trigger actions based on special messages. Some solutions (like 'port knocking' and 'Net::Pcap') use the network, but without requiring even a single open port. Lando runs commands over a network, using username and password. Most recently, a program specifically for secure remote execution called Ostiary has been developed.\nThe eXtended Ring Daemon, or \"Xringd\", uses a modem to monitor rings on a phone line. It counts the number of rings, and the time between them. If a 'sequence' matches one of the ones that it has been set up to detect, Xringd will run an associated command.\nThis is very nice from a security perspective. Since it uses no network connection at all, it's entirely immune to network attacks like buffer overflows. It can be used even when a network connection is unavailable (it's often used to cause a computer to initiate a dialup connection). The only 'client' you need is a phone. If you use it to start up ssh on demand, then the attacker needs to know the right phone number and the right ring pattern - it's quite hard to sniff that kind of thing remotely. It's also highly resistant to a man in the middle attack. (If you have to worry about someone rerouting your phone calls, you're in more trouble than Xringd can save you from.)\nThere are some practical issues that may make this unattractive in some circumstances. You need a modem and a telephone line to the server. (Fortunately, you don't need a fast modem at all; even a 1200 baud one will do nicely, but some servers are not placed close to a telephone jack.) Also, things like answering machines or voicemail (or even other people answering the telephone) can interfere with Xringd. If you give the server a dedicated line, you can avoid these problems, but that can be costly.\nFinally, note that the rings you hear when making a call are not necessarily synchronized with the ring signals actually sent to the telephone. In most circumstances, they are close enough, but reliability can be an issue at times.\nMost of the mail filtering programs have a way to invoke scripts when mail matching a pattern is received (in the simplest case, mail to a particular address). Assuming the server is running an SMTP daemon, this can be a nice way of triggering actions remotely. Technically, one could even send a shell script to be run, and have it e-mail the results back to you, giving you the equivalent of a very slow remote shell. The only client needed is an e-mail program, or even a webmail account.\nThe first problem is that if the box you want to talk to doesn't accept e-mail, this obviously won't work. (Adding an entire mail server, with the attendant risks of bugs, spam load, etc., just for remote execution doesn't make a lot of sense.) Some machines only periodically collect e-mail from a primary server, so there can be a substantial delay between when a command is sent and when it is acted upon.\nFurthermore, if you don't encrypt the traffic in some way (or at least sign it with PGP), then anyone sniffing traffic between you and your server may be able to take advantage of the same channel to do mischief, or perform a man-in-the-middle-attack. (E-mail traffic is notoriously easy to falsify; hence the avalanche of spam these days.)\nCVTSA, or \"ClairVoyanT SysAdmin\", is a system designed specifically for running commands through e-mail. It has some support for using passwords, but does not (currently) encrypt them in transit, so a sniffer could capture them and use them again.\nOf course, if the only things you want to do with this type of system are emergency shutdowns and other such (hopefully rare) crisis management, then even an unencrypted channel might work. However, you'll need to change the 'magic trigger pattern' each time after you use it, or you take the risk that an attacker might capture it and 'replay' it at an inconvenient time.\nWith port knocking, a daemon monitors firewall logs, looking for particular sequences of connection attempts to particular (closed) ports. When it sees a sequence it recognizes, it runs the associated command. This isn't terribly bandwidth efficient, but it has some nice properties. First, it's hard to tell if a server is listening for port knocks. Second (and most important), it's awfully hard to crack a closed port. (Linksys routers have had a simple version of this for a while, BTW, that they call port triggering.)\nHowever, a clever attacker with a sniffer could notice this traffic, and duplicate it for their own use. More complicated encodings could express something like a PGP signature (indeed, in theory one could create an entire network protocol based on port knocks), but things rapidly become difficult to work with. As with 'mail filtering' solutions, one can either use it sparingly in emergencies, or move to real cryptography.\nIt's also important to realize that this system is critically dependent on the probe packets actually being delivered, and delivered in the order that they were sent. This is not guaranteed on the Internet. What's more, depending on where you're at (e.g., an Internet cafe or behind a business firewall), you might not be allowed to connect out to arbitrary ports. The more complex you make the 'knocks', the less reliable the system will be.\nAlso, notice that at least one entire IP packet (28 bytes or so minimum) is used to transmit roughly one bit of information. In terms of network efficiency, it's almost hideous. For a simple 'open up ssh' message, it's not a consideration, but actually adding cryptographic security to this system could use up a decent chunk of the available bandwidth.\nFinally, this increases the CPU load for each entry in the firewall log. Depending on how detailed the logs are, and how fast and busy the network is, this can be a significant drain on resources.\nAnother interesting approach is to use Net::Pcap or other network capturing software to look for specific packets on the network (e.g., DNS requests) and examine them for particular data (e.g., a particular address). If found, it can enable ssh temporarily, or perform other actions.\nOne potential benefit of this approach is that a computer doesn't have to have an address on a network in order to monitor traffic on that network. You can set the card to 'promiscuous mode' and examine all the traffic on the wire. (It's very hard to hack a machine you don't even know is there.) Once the 'trigger' is spotted, the sniffer can use other means (a separate network, a serial link, even Xringd) to open up SSH on a target machine. Of course, you can also simply run the sniffer directly on the target.\nAgain, a clever attacker with their own sniffer may be able to detect the unusual activity and correlate it. To make this system truly secure, you would need more complex encoding/encryption of the 'trigger' traffic.\nAdditionally, the CPU load for this solution can be even worse than for 'port knocking' systems. A 'port knocking' daemon monitors firewall logs, which can have variable levels of detail. By necessity, a 'sniffer' solution must examine every packet on the network segment, which can be a substantial task for a busy gigabit line.\nLando allows a user to run a preconfigured set of commands remotely, using passwords, and even allowing the user to supply arguments to them. While it currently has only a Windows client, and passwords are sent in the clear (making it suitable only for use on a trusted local network, or perhaps on a VPN), it can be very useful for, e.g. operating a local firewall box without going to the trouble of logging in.\nAll of the above solutions have their advantages, but each has some practical issues that can make them unsuitable for particular applications. Ostiary was designed to be a secure alternative that uses minimal resources. It tackles this problem with what might be termed \"aggressive simplicity\". It does require an active connection to the network (unlike Xringd and sniffing), but allows for much better default security with very low CPU, RAM, disk, and network bandwidth requirements.\nAn Ostiary server has one open port that it listens on. When someone connects, the server sends a random fixed length 'salt' message 16 bytes in size - the size of an MD5 hash. It then waits (with a timeout) for a reply from the client. It reads (at most) 16 bytes of reply, and closes the connection.\nOstiary has a list of commands to run, with associated passwords. It runs through the list, and hashes these passwords with the 'salt' it sent to the client. If one of these hashes matches the reply from the client, the associated command is run. (One final touch is that a record is kept of connections, and clients with too many failed attempts are 'locked out', and all subsequent communication from them is ignored.)\nA detailed security analysis is available, but a few things about this system should be clear. With a protocol this simple, the chances for dangerous bugs are drastically reduced. Using fixed-length messages essentially eliminates the chances of a buffer overflow or other memory error. (Indeed, Ostiary does no dynamic memory allocation of any kind - everything is stored in static, fixed-size data structures.) Replay and man-in-the-middle attacks are also effectively useless. Ostiary limits how fast it accepts connections, enforcing low CPU and network usage. (The first production Ostiary server was a 16MHz 68030 machine.) Client requirements are even lower: Clients are available for Palm Pilots and even Windows.\nUnlike a procmail-based solution, where you can put arbitrary commands (with arguments) in the message, Ostiary can only run the fixed set of commands you have preconfigured. The only argument it supplies to the commands is the IP address of the client that initiated the command. It requires an active network connection (unlike Xringd) and an open port (unlike port knocking or sniffing), which may entail configuring a firewall to open a new port. (Although one could run Ostiary on, say, port 22, and upon receipt of the correct command, it could terminate itself and spawn sshd...)\nSince Ostiary uses TCP, it is as reliable as the network it uses to communicate. Problems with miscounted phone rings (a la Xringd) or randomly dropped packets (a la port knocking) are not a concern.\nThe following table summarizes the pros and cons of the various systems outlined above. \"Replay\" and \"Man-in-the-middle\" indicate if the default system is vulnerable to the corresponding attacks. \"Command arguments\" indicates if the system can run arbitrary commands with arguments. \"CPU load\" indicates that CPU time can be a significant consideration. \"Special client\" indicates that a specific client program is needed to work with that system.\n|System||Xringd||Mail filter||Port knocking||Sniffers||Lando||Ostiary|\nNone of these approaches is right for everyone. But all of them can be used to make attacks at least more inconvenient, and in many cases far more difficult. Remember, though, to analyze their pros and cons relative to your specific situation. Also remember that true security is a process, not a goal - you can never just install some software and be done thinking about it.\nRay Ingles has been involved with Linux since 1995. In\naddition to being an active member of the\nMetro Detroit Linux User's Group,\nhe has made minor contributions to the UPS HOWTO and the Linux", "label": 1}
{"text": "20 June 2012 by Pelle Neroth\nAnother example: Two years ago cyber thieves stole 30 million euros' worth of carbon allowances from the European carbon trading exchange, forcing trading to cease for some days on order of the European Commission. A third recent incident: the social and business networking website LinkedIn had six million user passwords leaked online after users were targeted by fake emails asking them to confirm their login details in a so called \"phishing attack\" by hackers.\nCyber crime is a broad church, including denial of service attacks, attacks on critical infrastructures (like the Stuxnet worm), botnets which marshal thousands of innocent owners' computers to do cyber criminals' work, malware, online frauds, and child pornography picture trading. It is a costly problem - £27bn a year just in the UK, according to a 2011 Home Office study and it is growing threat as more and more services like taxes and benefits payments migrate online.\nIt is also under reported. A lot of scams affect millions of individuals but only small sums per individual, so many feel it's not worth going to the police about. And companies have their own reasons. Their incentives are misaligned. They are unwilling to disclose problems for fear of losing customers as their reputations would take a hit for being insecure. Many do short term fixes on their systems and price fraud into their business model. And keep very quiet about breaches.\nLaw enforcement agencies are arguably understaffed, though the situation is getting better. Europol, the EU policing agency, has just 7 out of 457 staff dealing with cybercrime from its shiny new offices in the Hague, according to a Commission-funded report. CEPOL, the UK based European police college, does not have cybercrime experts among its 42 staff.\nLaw enforcement agencies are put off by jurisdictional failures from covering crimes of an essentially global and dispersed nature. Communicating by instant messenger or through bulletin boards websites, malware writers, malware distributors, and credit card abusers are all different people who may never meet and are located in different countries. Clear up rates are low.\nA dozen EU countries have separately adopted national cybercrime strategies, among them the UK. The cybercrime unit will be an important part of the new National Crime Agency launching next year, according to the UK's \"Mr Cyber\", cabinet office minister Francis Maude. But cybercrime is one of those areas crying out for international coordination and several initiatives are afoot. NATO is developing its own strategy, and has its own cyber warfare centre in Tallinn, Estonia. The EU itself at the end of May agreed to set up a cybercrime centre (ECCC) at Europol, consisting of 55 persons that will help coordinate national efforts. The European Commission will also be proposing new legislation in the third quarter of 2012 making notification of security breaches compulsory for companies in the energy, transport, banking and financial sectors. The requirement to report could worsen the reputational damage to companies that have experienced security breaches. So rather than do that they will spend more on security to lower their vulnerability, officials say. Telecoms and internet firms are already subject to reporting obligations.\nYou have to ask whether the ECCC is an effective solution, though. According to the Commission's own estimates, 8 trillion dollars a year changes hands through e-commerce. The Commission-funded feasibility study* proposes a three million euro budget for the ECCC for its first year of operation. That is not a lot when you look at the science prizes of up to one billion the EU is handing out for basic research projects - or compared to the $57bn budget for the US Department of Homeland Security.\nPelle Neroth -- EU correspondent\nPosted By: Pelle Neroth @ 20 June 2012 08:28 AM Brussels\nFuseTalk Standard Edition - © 1999-2013 FuseTalk Inc. All rights reserved.\n\"Summer is on the way, so we turn our attention to a few leisurely pursuits - and some not-so leisurely ones...\"\n- Greenpeace frowns at Centrica's getting a shale-gas venture stake\n- World’s most advanced comms satellite shipped to launch site\n- HMS Queen Elizabeth nears completion\n- Scientist to benefit from exascale supercomputer deal\n- Dinosaurs’ app uses augmented reality\n- Chinese space capsule reaches its ‘Heavenly Palace’\n- Transformers Vector Group [04:55 pm 19/06/13]\n- E&T magazine - Debate - HS2, the need for speed [01:33 pm 18/06/13]\n- Creating an Iphone App [05:50 pm 17/06/13]\n- CO2 is good [07:29 pm 16/06/13]\n- DECC-EDF makes yet another attempt to fund 3rd Generation Nuclear at any cost [05:02 pm 15/06/13]\nTune into our latest podcast", "label": 1}
{"text": "Whatever its origin, the Stuxnet worm provided something that few publicly-debated online incidents have offered to date.\nFor at least 15 years, security experts have warned that cyber attacks would one day strike at “critical infrastructure” – whether it’s power grids, energy supply, air traffic control (in the more extreme imagination of Richard Clarke, at least), emergency services and so on.\nReal-world incidents have been limited, however: most countries have no single electricity “off-switch” accessible from the Internet, for example. In attacking SCADA software, Stuxnet has acted as a proof-of-concept for something rarely seen in the wild. Arguably, it also demonstrated that environments like SCADA systems are, to date, not typically Internet-connected: its medium of infection was USB keys.\nBut in a world that’s probably growing weary of the jump-at-shadows mindset of IT security journalism, Stuxnet wasn’t a shadow but a real event.\nDr Prescott Winter, former director and CIO of the US National Security Agency and now CTO (Public Sector) for security vendor ArcSight, argues that it’s time for governments to take a more active role in finding ways to secure the Internet.\nSpeaking to journalists in Sydney in early October as part of an ArcSight national roadshow, Dr Winter said that while private industry (particularly in America) might chafe at government intervention and regulation of the online world, it’s as inevitable as regulation of air traffic became in the 20th century.\nThe prime manifestation of the problem, Dr Winter said, is the ongoing problem of the “botnet”. Individuals at home aren’t protected, he told the roadshow; their computers become incubation grounds for botnets.\n“Some kind of protective process to clean that up is absolutely essential,” he said.\n“There are botnets residing in millions of home computers around the world, and those can be turned-on ‘like that’.”\nToday’s “scattershot” approach to the botnet problem isn’t enough protection, he said: “we have bans on aircraft ... bans on ‘bad packets’ is an area governments need to work on.”\nAnd that in itself is a challenge. The “bad packet” problem is international – and around the world, the relationship between the government and the private sector changes from country to country.\nDr Winter said America may not even be the best country to take the lead in protecting Internet users, because of its historical gulf between government and the private sector. As a result, an effort like the IIA’s Internet code of practice is “almost unimaginable in the US.\n“I think this case in Australia is going to be very interesting to watch. It seems to have come about with a group of the leading ISPs and service providers coming together to design this solution.\n“There are a lot of things it doesn’t have in it yet – but as an initial outline for a policy framework to clean up ... the Australian part of the Internet, it is certainly a commendable start. Eventually, you probably want to make sure that you have all your service providers involved.”\nWorms and the Real World\nGiven that “physical attacks” – damage to infrastructure, attacks on emergency services and the like – hold such a high profile in the popular mind, it’s interesting that Dr Winter nominated attacks against intellectual property as today’s leading concern.\nOne reason, he said, is that “some action has been taking in protecting the critical systems ... for example, the FAA is getting a complete rebuild from the ground up.”\nThe shift in emphasis “from catastrophic failure to IP”, Dr Winter said, is because “the steady drain of intellectual property out of the leading technical nations of the world is a major cause for concern.\nThe investment in developing products and services, he said, is in danger of “leaking” to countries like China, but “IP protection and the integrity of the supply chain are currently lower on most peoples’ threat radar than a catastrophic cyber ‘Pearl Harbour’”.\nSecurity, software and the Cloud\nSecurity would seem to provide a great marketing entree for cloud providers: if everything the home user needs can be hosted by a cloud provider, the user’s exposure to threats could fall dramatically.\nHowever, it’s not playing out that way.\n“I don’t think there’s as much progress as any of us would like to see ... we have had some discussions with people at Microsoft about trust models you can begin to build into the Internet.”\n“App store” markets are another area Dr Winter would like to see paying more attention to security, since users place an implicit trust in the integrity of the software they download from an app store.\nThat, however, leads to the vexed question of software quality. If cloud providers and app sellers are expected to warrant that their software is secure, shouldn’t a similar requirement apply to the whole software industry, which typically escapes liability with disclaimers?\nYes: “The software industry has gotten away with murder on this point forever,” Dr Winter said. “Deploy, then fix, is the old habit of the software industry, and that model isn’t viable in the cloud.”\nHe said software quality processes need to be put into place industry-wide (and world-wide), and this will represent a culture-shock for the software industry.", "label": 1}
{"text": "Have you ever noticed that some things in certin places on the internet on occasion require the use of a password, or log-in of some kind? Ever wonder if there was possibly a way around this “barrier”? Maybe you forgot a password to your msn account, or maybe someone you hate has a website that you’d like to see destroyed… Eitherway, a password or login is required and your sitting in your chair doing nothing usefull… You may not know alot about it yourself, but your aware of “hackers” and “crackers”. Ask yourself an honest question… What do they know that you dont? Why is it that a 13 year old halo nerd can steel my bank info and ring up a huge bill on my visa? What am i missing here…\nRainbow Tables. Contrary to what the name might imply, Rainbow tables are an extreamly powerful and useful tool in the computer world, and they are alot less complicated then you may think.\nWhat are they?\n(accoarding to Wikipedia)\nA rainbow table is a lookup table offering a time-memory tradeoff used in recovering the plaintext password from a password hash generated by a hash function, often a cryptographic hash function. A common application is to make attacks against hashed passwords feasible. Salt is often employed with hashed passwords to avoid this attack.\n(In English More Less)\nRainbow tables use a refined algorithm by using a number of different reduction functions to create multiple parallel chains within a single “rainbow” table, reducing the probability of false positives from accidental chain collisions, and thus increasing the probability of a correct password crack. As well as increasing the probability of a correct crack for a given table size, the use of multiple reduction functions also greatly increases the speed of lookups. See the paper cited below for details.\nRainbow tables are specific to the hash function they were created for e.g., MD5 tables can crack only MD5 hashes. The theory of this technique was first pioneered by Philippe Oechslin  as a fast form of time-memory tradeoff  (PDF), which he implemented in the Windows password cracker Ophcrack. The more powerful RainbowCrack program was later developed that can generate and use rainbow tables for a variety of character sets and hashing algorithms, including LM hash, MD5, SHA1, etc.\nWhat that all means isssss???\nThey allow you to hack the shit out of things If theres a password you need, or an account name to something, you can use Rainbow Tables to “recover” them. Say your friend has a clan. Part of his clan is a website. You dont like his website. With Rainbow Tables you could figure out the admin’s username and his password, and in return, log in and make changes\nWHY DOESNT EVERYONE HAVE THEM IF THEIR SO 13ET??\n1) They are underground. Not many people know they even exsist.\n2) They are fairly complicated as first look, but have a HUGE community backing them up.\n3) They are massive in size. A shitty set of tables runs at about 8 Gigabytes, and would prove very in-effective for most uses. If you wanted to “crack” serious things, you’d need a set running about 120 Gigabytes in size. Currently they are working on a set that are approx. 420 Gigabytes in size. So basically, unless you want to wait 6 months for download your out of luck with getting them.\n(However some programs are offered where they will ship them to you on a hard drive the download)", "label": 1}
{"text": "Web users are getting anxious about their personal data being collected by search engines for targeted advertising, according to a recent report released by the Pew Internet.\nThe Pew Internet & American Life survey showed that 65 percent of Internet users feel that it’s a bad thing if a search engine is collecting information about their searches and then using it to rank future search results, as it would limit information users get online and what search results they see.\n73 percent of the respondents said that they would not be OK with a search engine keeping track of searches and personalizing future search results, as it would be an invasion of their privacy.\nOnly 29% of those surveyed said that it’s a good thing that search engines collect information about the searches and use it to rank future search results, because it gives users results that are more relevant to them, while 23% said that they are Ok with search engines keeping track of their searches and using that information to personalize their future search results, even if it means they are gathering information about them.\nMost of the users are not aware of the ways they can limit the information that websites gather about them. Only 38% of Internet users said that they knew of things they could do to limit personal information. Among this group, one common strategy people used to limit personal data collection was to delete their web history.\nDespite these concerns about online privacy, the Pew research found that users’ overall views of search engine performance is positive. Use of search engine is still one of the most popular online activities, rivaled only by email. Users expressed high levels of confidence in the capabilities of search engines, with 91% stating that they always or most of the time find the information they are seeking, and 73% stating that most or all the information they find using search engines is accurate and trustworthy.\nAs expected, Google topped the list of most popular search engines, with 83 percent of stating that they used Google to carry out most of their searches.", "label": 1}
{"text": "Recently 4800 plus credit cards of Saudi Arabia were hacked by Israeli Hackers and after that they put all information about these cards on internet too. So internet is not a safe place unless you take some security measures in order to protect computer from malicious attacks. Computer experts says that if you connect new computer to the internet than this new computer will be effected by viruses with few minutes. That’s unsafe internet is, so its important that you first secure your computer and than connect it with internet otherwise you will be in the hands of some hacker.\n1. Install an Antivirus Software\nAntivirus software is the first line of defense for any computer out there on internet and without it your are take very big risk of your precious data and files. Although Windows operating system are getting much and much secure after time but hackers can still find security loop holes in your system and can take it down. There are mainly two types of antivirus software’s available on internet free and paid. Both works well but premium software allows to update and use more advanced features which are not available in the free version.\nThe first thing you should do is to install a free Norton antivirus software but if you cannot afford to buy antivirus software than you can also use free Norton Internet security 2012 giveaway and get your free key. The way is works is very simple, companies want to promote there software and hence give some free product keys to the websites which review their products. These blogs than gives software’s to general public via giveaways in which you can easily participate. After you get your antivirus software, install it and update its virus definitions in order to maximizes its protection ability.\n2. Change and Update you Browser\nUnfortunately the most reliable browser of last century is the most UN-reliable browser of 21st century. I am talking about Microsoft Internet Explorer. I don’t know why Microsoft is not taking it seriously and they are far behind from other internet browsers like Mozilla Firefox and Google Chrome.So if you are one of those who are still using Microsoft Internet explorer than my friend your laptop can any time get hacked or infected by viruses.\nIf you are using browser other than Microsoft Internet Explorer than its essential that you upgrade your browser when ever a new update is available. Generally Mozilla Firefox Nightly updates are released every month so its better to check manually or set your browser settings to auto so that it can automatically checks and updates your browsers. Now a days browsers plugins and extensions are very popular among young guys but let me tell you that these extensions can inject some malicious code into your browser so its better to not use these plugins.\n3. Use Firewall Program\nJust installing antivirus software is not enough in order to make your system 100 percent secure. Now a days any antivirus programs are equipped with firewalls but unfortunately these are not good for your system. Try to use third part firewalls as these are created by professional and they will also provide you full customer support.\nFirewall is another option which will make sure that only the request generated by your system will enter in your computer. When ever you want to visit some website your computer sent signals to the out side world. Now of course these signals have to cross whole world and than return to your computer but the problem is that any one can see you computer on the internet and send requests to enter into your system.\nRequests generated by outsiders will totally be rejected. This way you can easily block hackers attacks. Although windows 7 firewall is very good but in addition to that you can also install ZoneAlarm, GFI etc.\n4. Try to Avoid Adobe Flash Player and Acrobat Reader\nYou may be wondering what is this. These are the most used applications on internet and why they are not safe. Yes but this is the problem with these applications. There popularity makes them ideal for hackers to target and hence find security loop holes in it. Adobe Flash is so unreliable that Apple has not chosen to add support for this application in there gadgets.\nNow i know you are saying that without these software your work can be effected so let me tell you some alternatives that can help you. You can use HTML5 instead of Flash which worlds perfectly fine and recently YouTube is also experimenting with HTML5 in their videos. If this project will be successful than they will also adapt this technology. For acrobat files you can use another free alternative and that is Google chrome browser. Not many people know that Chrome can also open and read Acrobat files so go and install it now if you don’t have it.\n5. Stay away from Malware Websites\nOne of the main reason that your computer or laptop is effected by some virus or malicious software’s is that you have visited some bad URL or website that redirects to some malicious website. These websites consists of websites which give illegal keys and breaks software’s codes to use into your system. But as you may know that they are genius people so they will also do some trick with you and inject some code int you browser. I am using browser again and again because its the front line application that interact with out side world.\nAlso stay away from websites which will promise you to make you millionaire over night or give you money. You can imagine that if some body is offering you free money than why not he is taking this money and become rich. So please stay away from these stupid schemes. You can also use free Anit Malware software to detect these websites.\nLast but not least never accept files by outsiders while chatting, via Email or some other source. Always update your all software’s including antivirus, programs you use or internet browsers.", "label": 1}
{"text": "The current version of Apache is 1.3.9. The main Apache site is at http://www.apache.org/. Another good source of information is Apacheweek at http://www.apacheweek.com/. The Apache documentation is ok, so I'm not going to go into detail in setting up apache. The documentation is on the website and is included with the source (in HTML format). There are also text files included with the source, but the HTML version is better. The documentation should get a whole lot better once the Apache Documentation Project gets under way. Right now most of the documents are written by the developers. Not to discredit the developers, but they are a little hard to understand if you don't know the terminology.\nApache is included in the Red Hat, Slackware, and OpenLinux distributions. Although they may not be the latest version, they are very reliable binaries. The bad news is you will have to live with their directory choices (which are totally different from each other and the Apache defaults).\nThe source is available from the Apache web site at http://www.apache.org/dist/ Binaries are are also available at apache at the same place. You can also get binaries from sunsite at ftp://sunsite.unc.edu/pub/Linux/apps/www/servers/. And for those of us running Red Hat the latest binary RPM file can usually be found in the contrib directory at ftp://ftp.redhat.com/pub/contrib/i386/\nIf your server is going to be used for commercial purposes, it is highly recommended that you get the source from the Apache website and compile it yourself. The other option is to use a binary that comes with a major distribution. For example Slackware, Red Hat, or OpenLinux distributions. The main reason for this is security. An unknown binary could have a back door for hackers, or an unstable patch that could crash your system. This also gives you more control over what modules are compiled in, and allows you to set the default directories. It's not that difficult to compile Apache, and besides you not a real Linux user until you compile your own programs ;)\nFirst untar the archive to a temporary directory. Next change to the src\ndirectory. Then edit the Configuration file if you want to include any special\nmodules. The most\ncommonly used modules are already included. There is no need to change the\nrules or makefile stuff for Linux. Next run the Configure shell script\n./Configure). Make sure it says Linux platform and gcc as the compiler.\nNext you may want to edit the httpd.h file to change the default directories.\nThe server home (where the config files are kept) default is\n/usr/local/etc/httpd/, but you may want to change\nit to just\n/etc/httpd/. And the server root (where the HTML pages are\nserved from) default is\n/usr/local/etc/httpd/htdocs/, but I like the directory\nRed Hat default for Apache). If you are going to be using su-exec (see\nspecial features below) you\nmay want to change that directory too. The server root can also be changed from the\nconfig files too. But it is also good to compile it in, just encase Apache\ncan't find or read the config file. Everything else should be changed\nfrom the config files.\nFinally run make to compile Apache.\nIf you run in to problems with include files missing, check the following things. Make sure you have the kernel headers (include files) installed for your kernel version. Also make sure you have these symbolic links in place:\nLinks can be made with\n/usr/include/linux should be a link to /usr/src/linux/include/linux /usr/include/asm should be a link to /usr/src/linux/include/asm /usr/src/linux should be a link to the Linux source directory (ex.linux-2.0.30)\nln -s, it works just like the cp command except it makes a link (\nln -s source-dir destination-link)\nWhen make is finished there should be an executable named httpd in the\ndirectory. This needs to be moved in to a bin directory.\n/usr/local/sbin would be good choices.\nCopy the conf, logs, and icons sub-directories from the source to the server\nhome directory. Next rename 3 of the files files in the conf sub-directory\nto get rid of the\n-dist extension (ex.\nThere are also several support programs that are included with Apache. They\nare in the\nsupport directory and must be compiled and installed separately.\nMost of them can be make by using the makefile in that directory (which is\nmade when you run the main\nConfigure script). You don't need any of them to\nrun Apache, but some of them make the administrators job easier.\nNow you should have four files in your\nconf sub-directory (under\nyour server home directory). The\nhttpd.conf sets up the server daemon (port\nnumber, user, etc). The\nsrm.conf sets the root document tree, special\nhandlers, etc. The\naccess.conf sets the base case for access. Finally\nmime.types tells the server what mime type to send to the browser for each\nThe configuration files are pretty much self-documented (plenty of comments), as long as you understand the lingo. You should read through them thoroughly before putting your server to work. Each configuration item is covered in the Apache documentation.\nmime.types file is not really a configuration file. It is used by the\nserver to translate file extensions into mime-types to send to the browser.\nMost of the common mime-types are already in the file. Most people should\nnot need to edit this file. As time goes on, more mime types will be added\nto support new programs. The best thing to do is get a new mime-types file\n(and maybe a new version of the server) at that time.\nAlways remember when you change the configuration files you need to restart\nApache or send it the SIGHUP signal with\nkill for the changes to take\neffect. Make sure you send the signal to the parent process and not any of\nthe child processes. The parent usually has the lowest process id number. The\nprocess id of the parent is also in the\nhttpd.pid file in the log\ndirectory. If you accidently send it to one of the child processes the\nchild will die and the parent will restart it.\nI will not be walking you through the steps of configuring Apache. Instead I will deal with specific issues, choices to be made, and special features.\nI highly recommend that all users read through the security tips in the Apache documentation. It is also available from the Apache website at http://www.apache.org/docs/mics/security_tips.html.\nVirtual Hosting is when one computer has more than one domain name. The old way was to have each virtual host have its own IP address. The new way uses only one IP address, but it doesn't work correctly with browsers that don't support HTTP 1.1.\nMy recommendation for businesses is to go with the IP based virtual hosting until most people have browsers that support HTTP 1.1 (give it a year or two). This also gives you a more complete illusion of virtual hosting. While both methods can give you virtual mail capabilities (can someone confirm this?), only IP based virtual hosting can also give you virtual FTP as well.\nIf it is for a club or personal page, you may want to consider shared IP virtual hosting. It should be cheaper than IP based hosting and you will be saving precious IP addresses.\nYou can also mix and match IP and shared IP virtual hosts on the same server. For more information on virtual hosting visit Apacheweek at http://www.apacheweek.com/features/vhost.\nIn this method each virtual host has its own IP address. By determining the IP address that the request was sent to, Apache and other programs can tell what domain to serve. This is an incredible waste of IP space. Take for example the servers where my virtual domain is kept. They have over 35,000 virtual accounts, that means 35,000 IP addresses. Yet I believe at last count they had less than 50 servers running.\nSetting this up is a two part process. The first is getting Linux setup to accept more than one IP address. The second is setting up apache to serve the virtual hosts.\nThe first step in setting up Linux to accept multiple IP addresses is to make a new kernel. This works best with a 2.0 series kernel (or higher). You need to include IP networking and IP aliasing support. If you need help with compiling the kernel see the kernel howto.\nNext you need to setup each interface at boot. If you are using the Red Hat Distribution then this can be done from the control panel. Start X-windows as root, you should see a control panel. Then double click on network configuration. Next goto the interfaces panel and select your network card. Then click alias at the bottom of the screen. Fill in the information and click done. This will need to be done for each virtual host/IP address.\nIf you are using other distributions you may have to do it manually.\nYou can just put the commands in the\nrc.local file in\n/etc/rc.d (really they should go in with the networking\nstuff). You need to have a\nroute command for each device. The\naliased addresses are given a sub device of the main one. For example eth0\nwould have aliases eth0:0, eth0:1, eth0:2, etc. Here is an example of\nconfiguring a aliased device:\nYou can also add a broadcast address and a netmask to the ifconfig command. If you have alot of aliases you may want to make a for loop to make it easier. For more information see the IP alias mini howto.\nifconfig eth0:0 192.168.1.57 route add -host 192.168.1.57 dev eth0:0\nThen you need to setup your domain name server (DNS) to serve these new domains. And if you don't already own the domain names, you need to contact the Internic to register the domain names. See the DNS-howto for information on setting up your DNS.\nFinally you need to setup Apache to server the virtual domain correctly.\nThis is in the\nhttpd.conf configuration file near the end. They give you an\nexample to go by. All commands specific to that virtual host are put in\nvirtualhost directive tags. You can put almost any command in there.\nUsually you set up a different document root, script directory, and log\nfiles. You can have almost unlimited number of virtual hosts by adding\nvirtualhost directive tags.\nIn rare cases you may need to run separate servers if a directive is needed for a virtual host, but is not allowed in the virtual host tags. This is done using the bindaddress directive. Each server will have a different name and setup files. Each server only responds to one IP address, specified by the bindaddress directive. This is an incredible waste of system resources.\nThis is a new way to do virtual hosting. It uses a single IP address, thus conserving IP addresses for real machines (not virtual ones). In the same example used above those 30,000 virtual hosts would only take 50 IP addresses (one for each machine). This is done by using the new HTTP 1.1 protocol. The browser tells the server which site it wants when it sends the request. The problem is browsers that don't support HTTP 1.1 will get the servers main page, which could be setup to provide a menu of virtual hosts available. That ruins the whole illusion of virtual hosting. The illusion that you have your own server.\nThe setup is much simpler than the IP based virtual hosting. You still need to get your domain from the Internic and setup your DNS. This time the DNS points to the same IP address as the original domain. Then Apache is setup the same as before. Since you are using the same IP address in the virtualhost tags, it knows you want Shared IP virtual hosting.\nThere are several work arounds for older browsers. I'll explain the best\none. First you need to make your main pages a virtual host (either IP based\nor shared IP). This\nfrees up the main page for a link list to all your virtual hosts. Next you\nneed to make a back door for the old browsers to get in. This is done using\nServerPath directive for each virtual host inside the\ndirective. For example by adding\nServerPath /mysite/ to www.mysite.com old\nbrowsers would be able to access the site by www.mysite.com/mysite/. Then\nyou put the default page on the main server that politely tells them to get\na new browser, and lists links to all the back doors of all the sites you\nhost on that machine. When an old browser accesses the site they will be\nsent to the main page, and get a link to the correct page. New browsers\nwill never see the main page and will go directly to the virtual hosts. You\nmust remember to keep all of your links relative within the web sites,\nbecause the pages will be accessed from two different URL's (www.mysite.com\nI hope I didn't lose you there, but its not an easy workaround. Maybe you should consider IP based hosting after all. A very similar workaround is also explained on the apache website at http://www.apache.org/manual/host.html.\nIf anyone has a great resource for Shared IP hosting, I would like to know about it. It would be nice to know what percent of browsers out there support HTTP 1.1, and to have a list of which browsers and versions support HTTP 1.1.\nThere are two different ways to give your users CGI script capability. The\nfirst is make everything ending in\n.cgi a CGI script. The second is to make\nscript directories (usually named\ncould also use both methods. For either method to work the scripts must be\nworld executable (\nchmod 711). By giving your users script\naccess you are creating a big security risk. Be sure to do your homework to\nminimize the security risk.\nI prefer the first method, especially for complex scripting. It allows you\nto put scripts in any directory. I like to put my scripts with the web pages\nthey work with. For sites with allot of scripts it looks much better than\nhaving a directory full\nof scripts. This is simple to setup. First uncomment the\nat the end of the\nsrm.conf file. Then make sure all your directories have\noption ExecCGI or\nAll in the\nMaking script directories is considered more secure.\nTo make a script directory you use the ScriptAlias directive in the\nsrm.conf file. The first argument is the Alias the second is the actual\ndirectory. For example\nScriptAlias /cgi-bin/ /usr/httpd/cgi-bin/ would make\n/usr/httpd/cgi-bin able to execute scripts. That directory would be used\nwhenever someone asked for the directory\n/cgi-bin/. For security reasons\nyou should also change\nthe properties of the directory to\nOptions none, AllowOveride none in the\naccess.conf (just uncomment the example that is there). Also do not make\nyour script directories subdirectories of your web page directories.\nFor example if you are serving pages from\n/home/httpd/html/, don't make the\n/home/httpd/html/cgi-bin; Instead make it\nIf you want your users to have there own script directories you can use\nScriptAlias commands. Virtual hosts should have there\nScriptAlias command inside the\nvirtualhost directive tags.\nDoes anyone know a simple way to allow\nall users to have a cgi-bin directory without individual ScriptAlias\nThere are two different ways to handle user web directories. The first is to\nhave a subdirectory under the users home directory (usually\nThe second is to have an entirely different directory tree for web directories.\nWith both methods make sure set the access options for these directories\nThe first method is already setup in apache by default. Whenever a request\n/~bob/ comes in it looks for the\npublic_html directory in bob's\nhome directory. You can change the directory with the\nUserDir directive in\nsrm.conf file. This directory must be world readable and executable.\nThis method creates a security risk because for Apache to\naccess the directory the users home directory must be world executable.\nThe second method is easy to setup. You just need to change the\nUserDir directive in the\nsrm.conf file. It has many\ndifferent formats; you may want\nto consult the Apache documentation for clarification. If you want each\nuser to have their own directory under\n/home/httpd/, you would use\nUserDir /home/httpd. Then when the request\n/~bob/ comes in it would translate to\n/home/httpd/bob/. Or if you want to have a subdirectory under bob's\ndirectory you would use\nUserDir /home/httpd/*/html. This would translate to\n/home/httpd/bob/html/ and would allow you to have a script directory\ntoo (for example\nThere are two ways that apache can be run. One is as a daemon that is always running (Apache calls this standalone). The second is from the inetd super-server.\nDaemon mode is far superior to inetd mode. Apache is setup for daemon mode by default. The only reason to use the inetd mode is for very low use applications. Such as internal testing of scripts, small company Intranet, etc. Inetd mode will save memory because apache will be loaded as needed. Only the inetd daemon will remain in memory.\nIf you don't use apache that often you may just want to keep it in daemon mode and just start it when you need it. Then you can kill it when you are done (be sure to kill the parent and not one of the child processes).\nTo setup inetd mode you need to edit a few files. First in\nsee if http is already in there. If its not then add it:\nRight after 79 (finger) would be a good place. Then you need to edit the\n/etc/inetd.conffile and add the line for Apache:\nBe sure to change the path if you have Apache in a different location. And the second httpd is not a typo; the inet daemon requires that. If you are not currently using the inet daemon, you may want to comment out the rest of the lines in the file so you don't activate other services as well (FTP, finger, telnet, and many other things are usually run from this daemon).\nhttp stream tcp nowait root /usr/sbin/httpd httpd\nIf you are already running the inet deamon (\ninetd), then you only need to\nsend it the SIGHUP signal (via kill; see kill's man page for more info) or\nreboot the computer for changes to take effect. If you are not running\ninetd then you can start it manually. You should also add it to your\ninit files so it is loaded at boot (the\nrc.local file may be a good\nThe newer web publishing tools support this new method of uploading web pages by http (instead of FTP). Some of these products don't even support FTP anymore! Apache does support this, but it is lacking a script to handle the requests. This script could be a big security hole, be sure you know what you are doing before attempting to write or install one.\nIf anyone knows of a script that works let me know and I'll include the address to it here.\nFor more information goto Apacheweek's article at http://www.apacheweek.com/features/put.\nThis is one of my favorite features. It allows you to password protect a directory or a file without using CGI scripts. It also allows you to deny or grant access based on the IP address or domain name of the client. That is a great feature for keeping jerks out of your message boards and guest books (you get the IP or domain name from the log files).\nTo allow user authentication the directory must have\nAuthConfig set in the\naccess.conf file. To allow access control (by domain\nor IP address) AllowOverrides Limit must be set for that directory.\nSetting up the directory involves putting an\n.htaccess file in the\ndirectory. For user authentication it is usually used with\n.htpasswd and optionally a\n.htgroup file. Those files can be shared among\n.htaccess files if you wish.\nFor security reasons I recommend that everyone use these directives in there access.conf file:\n<files ~ \"/\\.ht\"> order deny,allow deny from all </files>\nIf you are not the administrator of the system you can also put it in your .htaccess file if AllowOverride Limit is set for your directory. This directive will prevent people from looking into your access control files (.htaccess, .htpasswd, etc).\nThere are many different options and file types that can be used with access control. Therefore it is beyond the scope of this document to describe the files. For information on how to setup User Authentication see the Apacheweek feature at http://www.apacheweek.com/features/userauth or the NCSA pages at http://hoohoo.ncsa.uiuc.edu/docs-1.5/tutorials/user.html.\nThe su-exec feature runs CGI scripts as the user of the owner. Normally it is run as the user of the web server (usually nobody). This allows users to access there own files in CGI scripts without making them world writable (a security hole). But if you are not careful you can create a bigger security hole by using the su-exec code. The su-exec code does security checks before executing the scripts, but if you set it up wrong you will have a security hole.\nThe su-exec code is not for amateurs. Don't use it if you don't know what you are doing. You could end up with a gaping security hole where your users can gain root access to your system. Do not modify the code for any reason. Be sure to read all the documentation carefully. The su-exec code is hard to setup on purpose, to keep the amateurs out (everything must be done manually, no make file no install scripts).\nThe su-exec code resides in the\nsupport directory of the source. First you\nneed to edit the\nsuexec.h file for your system. Then you need to compile\nthe su-exec code with this command:\nThen copy the suexec executable to the proper directory. The Apache default is\ngcc suexec.c -o suexec\n/usr/local/etc/httpd/sbin/. This can be changed by editing\nhttpd.hin the Apache source and recompiling Apache. Apache will only look in this directory, it will not search the path. Next the file needs to be changed to user root (\nchown root suexec) and the suid bit needs to be set (\nchmod 4711 suexec). Finally restart Apache, it should display a message on the console that su-exec is being used.\nCGI scripts should be set world executable like normal. They will\nautomaticaly be run as the owner of the CGI script. If you set the SUID (set user id) bit on the\nCGI scripts they will not run. If the directory or file is world or group\nwritable the script will not run. Scripts owned by system users will not be\nrun (root, bin, etc.). For other security conditions that must\nbe met see the su-exec documentation. If you are having problems see the\nsu-exec log file named\nSu-exec does not work if you are running Apache from inetd, it only works in daemon mode. It will be fixed in the next version because there will be no inetd mode. If you like playing around in source code, you can edit the http_main.c. You want to get rid of the line where Apache announces that it is using the su-exec wrapper (It wrongly prints this in front of the output of everything).\nBe sure and read the Apache documentation on su-exec. It is included with the source and is available on the Apache web site at http://www.apache.org/docs/suexec.html\nApache has the ability to handle server side imagemaps. Imagemaps are\nimages on webpages that take users to different locations depending on\nwhere they click. To enable imagemaps first make sure the imagemap module\nis installed (its one of the default modules). Next you need to uncomment\n.map handler at the end of the\nsrm.conf file. Now all files ending in\n.map will be imagemap files. Imagemap files map different areas on the\nimage to separate links. Apache uses map files in the standard NCSA\nformat. Here is an example of using a map file in a web page:\nIn this example\n<a href=\"/map/mapfile.map\"> <img src=\"picture.gif\" ISMAP> </a>\nmapfile.mapis the mapfile, and\npicture.gifis the image to click on.\nThere are many programs that can generate NCSA compatible map files or you can create them yourself. For a more detailed discussion of imagemaps and map files see the Apacheweek feature at http://www.apacheweek.com/features/imagemaps.\nServer Side Includes (SSI) adds dynamic content to otherwise static web pages. The includes are embedded in the web page as comments. The web server then parses these includes and passes the results to the web server. SSI can add headers and footers to documents, add date the document was last updated, execute a system command or a CGI script. With the new eXtended Server Side Includes (XSSI) you can do a whole lot more. XSSI adds variables and flow control statements (if, else, etc). Its almost like having an programming language to work with.\nParsing all HTML files for SSI commands would waste allot of system\nresources. Therefore you need to distinguish normal HTML files from those\nthat contain SSI commands. This is usually done by changing the extension\nof the SSI enhanced HTML files. Usually the\n.shtml extension is used.\nTo enable SSI/XSSI first make sure that the includes module is installed.\nsrm.conf and uncomment the\nAddHandler directives for\n.shtml files. Finally you must set\nOptions Includes for all directories where\nyou want to run SSI/XSSI files. This is done in the\naccess.conf file. Now\nall files with the extension\n.shtml will be parsed for SSI/XSSI commands.\nAnother way of enabling includes is to use the\nXBitHack directive. If you\nturn this on it looks to see if the file is executable by user. If it is\nOptions Includes is on for that directory, then\nit is treated as an SSI file. This only works for files with the mime type\n.html .htm files). This is not the preferred method.\nThere is a security risk in allowing SSI to execute system commands and CGI\nscripts. Therefore it is possible to lock that feature out with the\nOption IncludesNOEXEC instead of Option Includes in the\naccess.conf file. All the\nother SSI commands will still work.\nFor more information see the Apache mod_includes documentation that comes with the source. It is also available on the website at http://www.apache.org/docs/mod/mod_include.html.\nFor a more detailed discussion of SSI/XSSI implementation see the Apacheweek feature at http://www.apacheweek.com/features/ssi.\nFor more information on SSI commands see the NCSA documentation at http://hoohoo.ncsa.uiuc.edu/docs/tutorials/includes.html.\nFor more information on XSSI commands goto ftp://pageplus.com/pub/hsf/xssi/xssi-1.1.html.\nApache can be extended to support almost anything with modules. There are allot of modules already in existence. Only the general interest modules are included with Apache. For links to existing modules goto the\nApache Module Registry at http://www.zyzzyva.com/module_registry/.\nFor module programming information goto http://www.zyzzyva.com/module_registry/reference/", "label": 1}
{"text": "MySQL has the advantage of containing several storage engines providing you with what is effectively several different types of databases in one software package. You install MySQL then choose MyISAM or InnoDB or one of the other storage engines. InnoDB became the default in MySQL 5.1.\nInnoDB is now the default database engine and is benefiting from the extra focus. MySQL 5.5 includes InnoDB enhancements to make better use of storage technology coupled with multiple processor cores. The main change splits a workload into two separate streams to let the workloads run on separate cores. Input/Output requests should start faster, producing more requests per second. You then need faster disks to serve those extra requests.\nThere are several improvements to make better use of multiple core processors. You will not see a difference when you step up from 2 cores to 4 cores. The difference will be noticeable when you jump up to 12 cores, as provided in an AMD Operon chip.\nThe improvement is created by splitting workloads into multiple streams to let them run in parallel. Some of the workloads are controlled by parameters you can set to fit your hardware. There is more statistical information recorded to help you tune the workloads.\nBenchmarks show there is little difference for 4 cores or less because there were already enough streams running in parallel. There is little benefit above 30 cores because there are not enough streams to service more cores.\nThis is a bit like backing up your data with RAID 1. You get at least two copies. The process works when you replicate from a master database to some slaves.\nThink of a master database replicating updates to several slave databases to serve many Web servers. You commit a transaction on the master and the change is saved to the master before the transaction is completed. You have one safe copy. Then your master server dies and you have no safe copies.\nTry that again with semisynchronous replication. You commit the transaction. MySQL updates the master but does not tell you the transaction is finished. Instead it waits for one slave to take a copy of the update. When the slave has secured a copy of the update and replied to the master, the master tells your program the transaction is complete. The master server dies. You simply switch the slave to become the master and carry on with 100 percent of your data.\nThis feature is definitely of value to people running transactions in a master/slave replication.\nMySQL installs easily on Windows if you have administrative access. There are 32 bit and 64 bit versions for automatic installation.\nOracle own MySQL and Oracle sell a rebranded Red Hat Linux. MySQL is available for both. MySQL is also available in source code andgeneric forms for Linux and some Unixes.\nMySQL is not available in Deb format for automatic installation in Debian or derivatives of Debian including Ubuntu and Linux Mint. Some applications are also available in a PPA library for automatic download bypassing the Debian and Ubuntu releases. MySQL is not available in PPA form.\nThere are promises to set up a PPA library and a Deb download and to fast track MySQL 5.5 into Debian.", "label": 1}
{"text": "Attack on computer memory reveals vulnerability of widely used security systems\nPosted February 21, 2008; 11:42 a.m.\nA team of academic, industry and independent researchers has demonstrated a new class of computer attacks that compromise the contents of \"secure\" memory systems, particularly in laptops.\nThe attacks overcome a broad set of security measures called \"disk encryption,\" which are meant to secure information stored in a computer's permanent memory. The researchers cracked several widely used technologies, including Microsoft's BitLocker, Apple's FileVault and Linux's dm-crypt, and described the attacks in a paper and video published on the Web Feb. 21.\nThe team reports that these attacks are likely to be effective at cracking many other disk encryption systems because these technologies have architectural features in common.\n\"We've broken disk encryption products in exactly the case when they seem to be most important these days: laptops that contain sensitive corporate data or personal information about business customers,\" said Alex Halderman, a Ph.D. candidate in Princeton's computer science department. \"Unlike many security problems, this isn't a minor flaw; it is a fundamental limitation in the way these systems were designed.\"\nThe attack is particularly effective against computers that are turned on but are locked, such as laptops that are in a \"sleep\" or hibernation mode. One effective countermeasure is to turn a computer off entirely, though in some cases even this does not provide protection.\nHalderman's Princeton collaborators included graduate students Nadia Heninger, William Clarkson, Joseph Calandrino and Ariel Feldman and Professor Edward Felten, the director of the Center for Information Technology Policy. The team also included Seth Schoen of the Electronic Frontier Foundation, William Paul of Wind River Systems and independent computer security researcher Jacob Appelbaum.\nFelten said the findings demonstrate the risks associated with recent high-profile laptop thefts, including a Veterans Administration computer containing information on 26 million veterans and a University of California-Berkeley laptop that contained information on more than 98,000 graduate students and others. While it is widely believed that disk encryption would protect sensitive information in instances like these, the new research demonstrates that the information could easily be read even when data is encrypted.\n\"Disk encryption is often recommended as a magic bullet against the loss of private data on laptops,\" Felten said. \"Our results show that disk encryption provides less protection than previously thought. Even encrypted data can be vulnerable if an intruder gets access to the laptop.\"\nThe new attacks exploit the fact that information stored in a computer's temporary working memory, or RAM, does not disappear immediately when a computer is shut off or when the memory chip is taken from the machine, as is commonly thought. Under normal circumstances, the data gradually decays over a period of several seconds to a minute. The process can be slowed considerably using simple techniques to cool the chips to low temperatures.\nDisk encryption technologies rely on the use of secret keys -- essentially large random numbers -- to encode and protect information. Computers need these keys to access files stored on their own hard disks or other storage systems. Once an authorized user has typed in a password, computers typically store the keys in the temporary RAM so that protected information can be accessed regularly. The keys are meant to disappear as soon as the RAM chips lose power.\nThe team wrote programs that gained access to essential encryption information automatically after cutting power to machines and rebooting them. The method worked when the attackers had physical access to the computer and when they accessed it remotely over a computer network. The attack even worked when the encryption key had already started to decay, because the researchers were able to reconstruct it from multiple derivative keys that were also stored in memory.\nIn one extremely powerful version of the attack, they were able to obtain the correct encryption data even when the memory chip was physically removed from one computer and placed in another machine. After obtaining the encryption key, they could then easily access all information on the original machine.\n\"This method is extremely resistant to countermeasures that defensive programs on the original computer might try to take,\" Halderman said.\nThe attacks demonstrate the vulnerability of machines when they are in an active state, including \"sleep mode\" or the \"screen lock\" mode that laptops enter when their covers are shut. Even though the machines require a password to unlock the screen, the encryption keys are already located in the RAM, which provides an opportunity for attackers with malicious intent.\nNone of the attacks required specialized equipment. \"I think we're going to see attackers doing things that people have previously though impractical or impossible,\" Appelbaum said.\nThe researchers were able to extend the life of the information in RAM by cooling it using readily available \"canned air\" keyboard dusting products. When turned upside down, these canisters spray very cold liquid. Discharging the cold liquid onto a memory chip, the researchers were able to lower the temperature of the memory to -50 degrees Celsius. This slowed the decay rates enough that an attacker who cut power for 10 minutes would still be able to recover 99.9 percent of the information in the RAM correctly.\n\"Hints of problems associated with computers retaining their temporary memory have appeared in the scientific literature, but this is the first systematic examination of the security implications,\" said Schoen.\nThe researchers posted the paper describing their findings on the website of Princeton's Center for Information Technology Policy. They submitted the paper for publication and it is currently undergoing review.\nIn the meantime, the researchers have contacted several manufacturers to make them aware of the vulnerability: Microsoft, which includes BitLocker in some versions of Windows Vista; Apple, which created FileVault; and the makers of dm-crypt and TrueCrypt, which are open-source products for Windows and Linux platforms.\n\"There's not much they can do at this point,\" Halderman said. \"In the short term, they can warn their customers about the vulnerability and tell them to shut their computers down completely when traveling.\"\nIn the longer term, Halderman said new technologies may need to be designed that do not require the storing of encryption keys in the RAM, given its inherent vulnerability. The researchers plan to continue investigating this and other defenses against this new security threat.", "label": 1}
{"text": "A Tale of Two Passwords\nMarch 05, 2008\nLearn the secrets to savvy password creation.\nThere's no two ways about itpasswords can be a pain in the...well, you know. Most people would avoid dealing with them if they could and thus engage in some bad password habits, like creating overly simplistic passwords (plus using the same password for everything) and failing to change default passwords.\nOn your broadband router, there are two passwords in particular, that when set improperly, can leave your network vulnerable.\nRouter Administration Password\nThis is a password that's commonly overlooked. Given that people may seldom need to access the router's settings beyond an initial configuration, many either inadvertently or intentionally leave the password at its factory default value, which is usually the manufacturer's name, \"password,\" \"1234\" or sometimes even no password at all.\nLast year, some security researchers effectively invented and documented this kind of attack. In a nutshell, code embedded in a Web page or e-mail message is used to remotely log into a router using a known default password. (The default password for almost any brand and model of router is easily looked up online. See for yourself at www.routerpasswords.com, which is just one site among many.)\nIn drive-by pharming, once granted access to the router, an attacker can then configure it to use the attacker's own DNS servers not unlike how we configured a router to use OpenDNS a few weeks back and from there exercise total control over which sites the user is taken to. (For a narrated animation describing how a drive-by pharming attack works, check out www.symantec.com/enterprise/security_response/weblog/upload/2007/02/db-pharming.html.)\nWhat was once a theoretical risk has (perhaps inevitably) become a very real one. According to Symantec security researcher Zulfikar Ramzanone of the researchers who originally discovered and documented the attack drive-by pharming has now just been spotted \"in the wild\", which means it's actually been done in the real world as opposed to just in a computer lab. It was in Mexico, to be specific, where it was used to redirect folks using a specific router to a faux Web site posing as that of a major bank. (Read a detailed description on Ramzan's blog.)\nLong story short, if you're one of those that forgot to change your router's password or didn't think you needed to, now is an excellent time to log you're your router and correct that mistake. If you don't know your router's default password offhand, you'll very likely find it on the site mentioned above.\nAnother router-based password that you'll want to take a close look at is the one you use to WPA-encrypt your wireless network. Those in the know wisely choose WPA over WEP because of the superior security it can provide, but this isn't automatic the password you create will directly affect the level of protection you receive.\nCase in point: a WPA password can be as short as 8 characters or as long as 63, but as with all passwords, there's a tendency to use the shortest and easiest to remember WPA password possible. People commonly set up WPA passwords that are dictionary words or proper names of family members or pets, because it must be typed into every device on their wireless networks.\nOne of the reasons WEP is so weak is because it uses a static encryption key which can eventually be decoded if you monitor the network long enoughoften for just hours or minutes. WPA is better because it uses the password you specify to generate a constantly-changing series of encryption keys. But all those keys are still derived from that single WPA password (also known as the Pre-Shared Key, or PSK), so a longer and more complex password will produce keys that are stronger and harder to decode. Put another way, a lengthy WPA password made up of random characters is far preferable to something like \"samandmary\".\nIf you're using such a short-and-simple WPA key, it's highly advisable that you change it. Don't despair about having come up with a long complicated password, though, because there are Web sites that can help. You can head over to www.passpub.com/wpa256.php to grab an instant 52 character key, or generate a custom-length password at www.kurtm.net/wpa-pskgen/. (The former site sends your key over an SSL-encrypted connection, while the latter generates it directly on your computer, so there's no danger of eavesdropping.)\nAnd yes, you will have the inconvenience of entering your newly long and cumbersome key at each of your wireless computers. But you'll only have to do it once, and it's a small price to pay for better security. These days, you can't be too careful.\nStory courtesy of PracticallyNetworked. Joe Moran is a regular contributor to PracticallyNetworked.\nTo learn more about WPA, read \"The Wi-FiPlanet Guide to WPA.\"", "label": 1}
{"text": "Parents, teachers, non-profits, government, and industry have been working hard to protect kids online. However, we also need to think about protecting the Internet from kids who might abuse it.\nThe Department of Justice categorizes computer crime in three ways:\n- The computer as a target - attacking the computers of others (spreading viruses is an example).\n- The computer as a weapon - using a computer to commit \"traditional crime\" that we see in the physical world (such as fraud or illegal gambling).\n- The computer as an accessory - using a computer as a \"fancy filing cabinet\" to store illegal or stolen information.\nReports of alleged computer crime have been a hot news item of late. Especially alarming is the realization that many of the masterminds behind these criminal acts are mere kids. In fact, children no longer need to be highly skilled in order to execute cyber crimes. \"Hacker tools\" are easily available on the Net and, once downloaded, can be used by even novice computer users. This greatly expands the population of possible wrongdoers. Children (and in some cases - their parents) often think that shutting down or defacing Web sites or releasing network viruses are amusing pranks. Kids might not even realize that what they are doing is illegal. Still other kids might find themselves hanging out online with skilled hackers who share hacking tools with them and encourage them to do inappropriate things online. Unfortunately, some of these kids don't realize that they are committing crimes until it is too late. Even more distressing and difficult to combat is the fact that some in the media portray the computer criminal as a modern day Robin Hood. Nothing could be further from the truth.\nSo what are cyber crimes? Can the law enforcement authorities find criminals online? How can you create context for your children to understand what cyber crimes are? The following information (and areas throughout the site) will help familiarize you with unethical and illegal online behavior. Additionally, to learn more about cyber crime, visit the Department of Justice Computer Crime & Intellectual Property Section's website at www.cybercrime.gov.\nThe Computer Emergency Response Team (CERT) at www.cert.org and the National Infrastructure Protection Center at the FBI at www.infragard.net provides regularly updated information and descriptions of cyber crimes.", "label": 1}
{"text": "Digital Makeover: Learn How to Protect Yourself Against Viruses and Malware #30DaysofGOOD\nLast week, computer-security company McAfee released its latest research on malware, spam, and viruses (pdf). The new data paints a dismal picture, showing the largest surge in cyberattacks to occur in four years. McAfee says it has identified more than 8 million new types of malicious software in the past few months alone. And unlike in previous years, these threats aren't limited to only PC users.\n\"Attacks that we've traditionally seen on PCs are now making their way to other devices,\" said Vincent Weafer, head of McAfee Labs. \"This report highlights the need for protection on all devices that may be used to access the Internet.\"\nToday's task is to learn how to protect yourself and your digital devices against viruses, bugs, worms, and other Internet nasties. Like we said when we talked about the need for creating better passwords, there may not be a way to fully guarantee online safety, but there are several things you can do to reduce the likelihood that you'll be the victim of malware.\nThe FBI offers a basic (but quite valuable) guide to protecting your computer, with tips for using firewall software and keeping your operating system up to date, plus suggestions for safer web surfing.\nAlthough Windows IT Pro generally focuses on tech solutions for the professional IT community, the site also has some great resources for average users like you and me. This directory of free programs for keeping your Windows PC secure includes web-based tools, browser plug-ins, and downloadable software.\nIf you're a Mac user, take a look at Wired's guide to checking for malware. It's part of Wired's collaborative How-To project; since it's in wiki form, you can make edits and add your own Mac security tips.\nFInally, be sure to bookmark PCWorld's recent article about protecting your smartphones and tablets. It's got explanations of all the different online threats, and offers practical tips for finding a comprehensive security solution for your specific collection of devices.", "label": 1}
{"text": "Every computer that is connected in some way to the internet should be running software designed to protect the system from the numerous security risks that are easily encountered in \"cyberspace\". In a perfect world, this would be all that the user would need to do to protect a computer from viruses and spyware. Unfortunately, due to the dynamic nature of the internet, and the almost constant proliferation of new bugs, viruses, and spyware, even the best anti-virus software will never be able to provide 100% protection for your computer. The following is a guide that provides basic maintenance and troubleshooting steps that the general user can use to cleanup and safeguard their system.\n- First, as stated, make sure that you are running the most current updates for an anti-virus software package. If you do not have software of this type on your computer, a good freeware anti-virus program is AVG Antivirus, which is free to individual users for home/dorm-use. Although most reputable anti-virus applications will automatically download current updates, in the end it is the user's responsibility to make sure that software is current. Updates should be performed at least once a week. This is (as mentioned earlier) crucial to the effectiveness of the software, because new security risks arise daily. (It is also imperative that all Windows Security Updates and Service Packs be installed, especially Service Pack 2 with the Firewall enabled.)\nIn addition to anti-virus software, most people will also want to run anti-spyware/adware applications on their computer. While not necessarily malicious, spyware and adware nevertheless pose a serious risk to your personal information. The majority of these programs are downloaded in conjunction with free software that the user has installed on his or her computer, but some are bundled with more \"reputable\" programs that the user has paid for! Adware and spyware usually run totally unnoticed in the background, \"mining\" the user's personal information and at the very least using up system resources. Spybot Search & Destroy and AdAware are two software packages that are excellent for screening your system for adware and spyware. Be aware, however, that most of the time \"free\" software will be disabled if the adware/spyware associated with it is eliminated. A few software packages that are notorious for bundling malware are:\n- Kazaa, Morpheus, iMesh, BearShare, (and any number of other \"Peer-to-peer\" file sharing programs.): Peer to peer (or \"P2P\") file sharing puts your computer at the highest risk for infection. In addition to this, most \"free\" P2P applications of this type come bundled with adware that cannot be disabled without disabling the P2P application as well.\n- RealPlayer: a media player that is (unfortunately) the only player able to play A/V files with extension \".rm\" Unless a user has a very pressing need to view files of this type, it is strongly recommended that this application be avoided.\nAfter running updated malware removal software on your computer, you can also check your (Windows) system directly.\n- Pressing Ctrl-Alt-Delete at the same time will bring up the Windows-Security Menu.\n- Click on the Task Manager button.\n- Choosing the Processes Tab will display a full list of all processes that are currently running on the computer. Running a check on google using the name of any of these processes (svchost.exe, for example) should display any number of websites that will reveal what the process's job is. If the process has something to do with malware, your web-search will most likely find some sites that will not only tell you what the process is doing, but should also contain instructions on removing the problem. If you suspect that a process may be suspect, you can also go directly to an antivirus website such as Symantec or Sophos, and search their online database directly for information.\n- Though all these steps go a long way toward keeping your system secure, new security threats are always popping up, and \"hackers\" can be quite ingenious when it comes to finding ways to bury their code in your system. If the steps listed above don't seem to be helping, don't be afraid to ask for help from the CIS Helpdesk, at x77777.", "label": 1}
{"text": "DDoS: in depth\nDistributed Denial of Service Attacks have recently emerged as one of the most newsworthy, if not the greatest, weaknesses of the Internet. Overview Distributed Denial of Service (DDoS) attacks are a relatively new development; reports of the first DDoS attacks surfaced in mid-1999, with the highest-profile attacks coming in early 2000 against sites like Amazon.com, CNN.com, eBay and E-Trade. Clearly, the challenge these attacks present is a serious one. While you alone can't do much to protect yourself, as a community we can improve the situation. The victims were unreachable for several hours each. A brief note on usage: the network where these attacks are taking place is called the ``Internet'', with a capital ``I''; it is the public network shared by people all over the world. An ``internet'', with a lower-case ``i'', is a collection of networks interconnected; many organizations have private internets. The Internet is the result of inter-connecting a gigantic number of private internets.\n[ Read more ]\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "Our passwords give us access to a number of very valuable resources. They control access to our bank accounts, photos of our families, email correspondence, and all kinds of other information. As valuable as all this information is, it is amazing how little effort most people put into making sure they have good passwords. Here are six password resolutions for 2009 to help protect your data with more secure passwords.\n1. Resolve to use different passwords on each website.\nThere are a few ways to do this. The most secure is to use a completely different randomly generated password on each site. If you use a password management program like 1Passwd this isn’t too difficult. Another option is to create a scheme that allows you to modify your password slightly based on each site. For example, if you use a base password of $5*9twoop, you could use $5*9twoop6 for Amazon.com, $5*9twoop5 for Yahoo.com and $5*9twoop3 for wsj.com. The last number is just the number of characters in the domain name that comes before the .com of each site.\nThis doesn’t make for the most secure passwords, but if some website is hacked or someone gets one of your passwords they won’t automatically have all of your password for every site.\n2. Resolve to use longer passwords.\nThere are two types of brute force approaches to cracking passwords. One is to try every possible combination of letters in sequence. For example, trying every three letter password would look like: aaa, aab, aac, aad, etc. Another common approach is to use a dictionary and just try common words that might be used as a password. Unless you are using a dictionary word, an eight character password is going to be much more difficult to break than a six character one. I’ve started using passwords that are over 10 characters long. We will talk about passphrases in a minute as a way to accomplish this.\n3. Resolve to keep password lists encrypted.\nIf you use a different password for every site, you will probably need to keep a record of them somewhere–particularly if you use completely random passwords and not some scheme like we mentioned in point one. If you use password management software, it may support automatic encryption. If you just keep them in a text file, you will need to investigate other encryption methods.\n4. Resolve to use random symbols in passwords.\nPasswords that have symbols (like *#&@!) are much more difficult to break using a brute force attack. Along the same lines you should make sure you can use both capital and lower case letters.\n5. Resolve to use passphrases.\nPasswords like The^funny@clown! are much more secure than a password like clown99 or Cl()wn simply because they are longer. With a phrase, you get a memorable password while increasing the length considerably.\n6. Resolve to password protect your computer.\nIf the average computer is stolen, simply turning it on will get you access to everything on the hard drive. At the very least, you laptop should prompt you for a password when you boot it and when it comes out of sleep mode. This doesn’t protect the hard drive like encrypting all of your data, but if a thief is after your hardware (not your data) they will probably just reinstall the OS to sell the machine. If they immediately have access to all your data, you significantly increase your chances of them poking around a bit to see if they can find any valuable information before selling it.", "label": 1}
{"text": "Internal security is a longstanding issue on the political agenda, and governments provide well for it.\nTwo issues have recently provided challenges to internal security policy. First, extremist right- and left-wing activities are an increasing problem, arising mainly but not exclusively in the federal states of the former East Germany. Second, fighting terrorist and extremist activities has emerged as both a domestic and international phenomenon. Recent events have clearly demonstrated that even small terrorist groups of Islamic fundamentalists are able to paralyze the whole security system for weeks at a time. Today, internal security policy is closely intertwined with EU strategies and policies.\nDue to the events of 9/11 and its effects on the subsequent “war on terrorism,” former Minister of the Interior Wolfgang Schäuble focused on policies strengthening internal security in order to prevent future terrorist attacks. In 2007, there was a debate on data retention, with policy mandating the storage of all phone and Internet communications for six months. In Germany, the government implemented an EU policy on data retention, but this law was overturned by the Federal Constitutional Court in March 2010.\nAnother law enables the police forces of the Federal Criminal Police Office to implement preventive measures against terrorism, including monitoring private communications via personal computers or telephones, and observing individuals with video cameras. There has also been some debate over how the military forces could be used domestically to prevent terrorist attacks, an idea that was ultimately dropped.\nIn 2009, the EU Commission recommended the implementation of body scanners at European airports to increase safety. Most European governments initially refused to use them, but another failed attack would probably lead the scanners to be implemented soon. Generally, the relationship between security and freedom consistently drives heated and controversial discussions. Nonetheless, authorities have so far been successful in preventing major terrorist attacks, at times by detecting conspiracies at an early stage.\nFischer Weltalmanach 2009\nhttp://ww w.bmi.bund.de/cln_174/SharedDocs/Re den/DE/2010/01/rede_bt.html\nhttp:/ /www.bmi.bund.de/cln_174/SharedDocs /Pressemitteilungen/DE/2010/03/politisch_motivierte_kriminalitaet.html ?nn=303936\nBusch, Andreas, 2010: Kontinuität statt Wandel: Die Innen- und Rechtspolitik der Großen Koalition, in: Christoph Egle/Reimut Zohlnhöfer (eds): Die zweite Große Koalition. Eine Bilanz der Regierung Merkel, 2005-2009, Wiesbaden: VS.", "label": 1}
{"text": "|By K. Thor Jensen May 5, 2011|\nAs email began to become the preferred method of business communication, it became only natural for virus makers to start treating it as a disease vector. One of the first worms to get major attention was the Melissa virus, created in 1999 by David L. Smith and named after a stripper he had a crush on. Sent through an email, it was built on a simple Microsoft Word macro - if you opened the attached document, it would automatically replicate itself and re-send to the top 50 names in your address book. Melissa crashed multiple networks before it was contained, but it was only the beginning.\nAs more and more people started using email in their daily life, it's not surprising that virus makers are targeting kids with their work as well. The 2007 Pikachu worm is widely regarded to be the first piece of malware that focused on the pre-teen set. An email containing an image of the electric mouse Pokemon and some amazing Engrish reading \"Between millions of people around the world I found you. Don't forget to remember this day every time MY FRIEND.\" led to a mass email to everybody in your address book as well as the addition of instructions to your autoexec.bat file that would wipe your hard drive on next boot.\nOne of the most devastating aspects of viruses is how they can lay dormant in your computer waiting for further instructions. The first virus to really create a worldwide panic was dubbed Michelangelo after its date of activation - on March 6th, the famous painter's birthday, this malicious bit of code would roar into action and delete the first 100 sectors of your hard drive, rendering your machine inoperative. Things got really crazy when it was discovered that some hardware manufacturers including Intel had shipped products that were accidentally pre-infected with the virus, and the media actually advised people to not turn their computers on at all on the 6th until a cure could be found.", "label": 1}
{"text": "Experts Want To Keep Your Car’s Computer Safe From Attack\nMichael Harper for redOrbit.com – Your Universe Online\nA virus on a computer can be bad enough, possibly leading to hacked accounts and even broken hardware. A virus on your car’s computer however, could be downright dangerous.\nAs our world progresses, so too does our desire to computerize everything, and our cars have become quite advanced. Staying one step ahead, the McAfee team at Intel Corp has been working away in a very unusual office for computer programmers and hackers: a West Coast garage.\nMcAfee, makers of the popular anti-virus software, are just one of the teams looking to protect automobiles from many bugs and viruses which could wreak havoc on the tiny computers inside modern cars.\nAs the cars become increasingly advanced and the technology becomes cheaper, more and more of these wide open and vulnerable computers are driving freely on our Nation’s interstates, freeways and city streets. According to some experts, many automakers have yet to address the issue, giving hackers the ability to not only eavesdrop, but also steal cars and potentially cause them to crash into one another.\nThough there have yet to be any violent attacks on car computers reported, companies like Intel’s McAfee and even Ford Motor Company aren’t waiting for the hackers to strike first.\n“Ford is taking the threat very seriously and investing in security solutions that are built into the product from the outset,” said Alan Hall, a spokesman for Ford. According to Hall, his company has given their security engineers the job of making their Sync in-vehicle offerings as imperceptible to hacking attacks as possible.\nIn 2010, a group of computer scientists from the US showed the automobile just how dangerous a virus on a car’s computer could be when they took control and damaged some cars moving at high speeds at a decommissioned airport.\nAfter this exhibit, SAE International, an association of more than 128,000 automobile and aerospace technicians, tasked a committee with advising automobile manufacturers on how to not only detect attacks on their automobiles, but also to prevent infiltrations.\n“Any cyber security breach carries certain risk,” said Jack Pokrzywa, SAE’s manager of ground vehicle standards, speaking to Reuters.\n“SAE Vehicle Electrical System Security Committee is working hard to develop specifications which will reduce that risk in the vehicle area.”\nThe same group of computer scientists who presented that harrowing demonstration in 2010 issued a second report last year, this time saying automobiles can also be susceptible to trojans and worms via their onboard diagnostic systems and even CD players. A hacker disguised as a technician, or a technician turned hacker, could place one of these viruses on a seemingly innocuous plug and install the virus all while appearing to be checking the system’s emissions.\nThough the group of scientists did not mention specifically which car manufacturers they used to demonstrate these security vulnerabilities, they told Reuters that all cars were in danger of being hacked, especially when considering that most of these automakers use the same development processes and suppliers.\nThe world’s largest automaker, Toyota Motor Corp, seems confident in their offerings, saying they haven’t heard of any hacking attacks on their cars.\n“They’re basically designed to change coding constantly. I won’t say it’s impossible to hack, but it’s pretty close,” said John Hanson, a spokesman for Toyota.\nLater, Hanson said, “Viruses are something that needs to be addressed directly. How we guard against that transfer to our system is a primary focus of our efforts.”", "label": 1}
{"text": "« More News Stories\nJune 8, 2012—Having successfully coordinated projects that resulted in secure coding standards for the C, C++, and Java programming languages, the CERT Secure Coding Initiative has unveiled work on a draft standard for Perl. The members of the CERT Secure Coding Team have analyzed thousands of vulnerability reports, including reports produced by the CERT Vulnerability Analysis Team, to identify insecure coding practices in Perl. From this analysis, the team has developed the draft Perl secure coding standard. The goal for the standard is to provide software developers with a tool for reducing or eliminating vulnerabilities before deployment. This work is being sponsored by the Department of Homeland Security, Network Security Deployment Division.\n“In our analysis, we performed Perl code audits using the Source Code Analysis Lab (SCALe),” said the Secure Coding Team’s David Svoboda. “Our audit process presupposes a secure coding standard. So, auditing Perl code required us to have a draft standard, which also served as a nascent set of issues. That is, many of our rules were inspired by vulnerabilities in the code we analyzed.”\nMost software vulnerabilities stem from a relatively small number of common programming errors. Coding standards encourage programmers to follow a uniform set of rules and guidelines determined by the requirements of the project and organization, rather than by the programmer's familiarity or preference. Once established, these standards can be used as a metric to manually or automatically evaluate source code.\nThe draft CERT Perl Secure Coding Standard provides a core of well-documented and enforceable coding rules and recommendations for the Perl programming language. Developing this core of draft rules into a comprehensive standard can help programmers realize significant security improvements in a variety of programming contexts. “Perl is the most prominent scripting language in the Unix world,” noted Svoboda. “It predates other scripting languages like PHP, Python, and Ruby.”\nTo augment the standard, the CERT Program invites collaboration from interested professionals in the software development and software security communities. As with all of the Secure Coding Team’s standards work, the goal of this project is to eliminate insecure coding practices that can lead to exploitable vulnerabilities. Its application will lead to higher-quality systems that are more robust and resistant to attack. To get involved, software development professionals should visit www.securecoding.cert.org, create an account, sign in, and start commenting on the rules.\nFor more information on the CERT Secure Coding Standard for Perl, please visit www.securecoding.cert.org/confluence/display/perl/CERT+Perl+Secure+Coding+Standard.", "label": 1}
{"text": "Most kids associate October with the scares related to the traditional Halloween standbys – ghosts, witches, and zombies. But, the month also marks National Cyber Security Awareness month, calling attention to frightening things like online identity theft, cyber bullying, viruses and damaging malware.\nIf your teen is among the 93 percent of 12 to 17-year-olds using your family’s laptop, smartphone or tablet to surf the Internet, they are vulnerable to multiple cyber threats, many of which could be detrimental.\nMoreover, teens do not realize the abundance of threats awaiting them, nor do they recognize a tweet or photo upload can impact not only their reputation and future, but their safety, as well. Microsoft’s research shows that 55 percent of teens say they give little or no thought to the consequences of posting something online.\nAnd, according to a recent survey, 1 in 4 parents are overwhelmed by technology and just hope for the best.\n“As hackers continue plotting attacks, the increase in vulnerability among teens is likely, but parents may not realize they are actually the first line of defense in keeping their families safe online,” says Linda McCarthy, cyber security expert, former senior director of internet safety at Symantec and author of “Own Your Space: Keep Yourself and Your Stuff Safe Online.”\nThe increase in prospective cyber threats provides opportunities in the career field of cyber security. If your teen enjoys spending time online, it’s never too early to begin discussing the education required to enter this field.\nAccording to the U.S. Bureau of Labor Statistics, cyber security related fields are projected to grow more than 28 percent by 2020. DeVry University, which has partnered with McCarthy to provide complimentary copies of the “Own Your Space” eBook to parents, teachers and teens, recognizes the growing need for professionals with the skills required to protect individuals and organizations from cyber-attacks. By also partnering with technology leaders like Cisco and Microsoft, its students are provided with a mix of relevant theoretical and hands-on education.\nCyber security is a moving target, and as threats develop daily, it’s imperative for parents and teachers to educate teens about these dangers. “The goal is to inform and educate teens, not scare them about the dangers of sharing information online,” says McCarthy. “By protecting your family’s devices and empowering teens with the information needed to recognize impending threats, cyber sabotage is avoidable.”\nDownload the eBook by clicking on the cover image below.\nYou can also download a complimentary copy of the official Facebook Security Guide here.", "label": 1}
{"text": "I know many of you have new computers in your homes, but how many of you realize that this computer is already vulnerable? How can this be? How can a brand new computer be vulnerable? There are many reasons for this:\n- Most computers have insecure default configurations.\n- Your software is probably already outdated. New vulnerabilities have likely been discovered between the time the computer was built and configured by the manufacturer and the day you power on your new system.\n- Numerous viruses and worms are already circulating on the Internet capable of taking advantage of the latest vulnerabilities.\n- Hackers know where you are! They regularly scan the common broadband and dial-up IP address ranges.\nBefore You Connect\nLet's talk about what you should do before you connect this new system to the Internet.\nYou should not connect your computer directly to the Internet. You should, instead, use a network firewall or firewall router. A network firewall or firewall router is a hardware device that users can install between the computers on their Local Area Network (LAN) and their broadband device (cable/DSL modem). By blocking inbound access to the computers on the LAN from the Internet at large (yet still allowing the LAN computers' outbound access), a hardware-based firewall can often provide sufficient protection for a user to complete the downloading and installation of necessary software patches. A hardware-based firewall provides a high degree of protection for new computers being brought online.\nIf you're running Windows XP (and if this is a new system, you probably are) you enable the Internet Connection Firewall (ICF). Microsoft has provided instructions for enabling the built-in Internet Connection Firewall on Windows XP.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "Do you know your child could be a target for identity theft?\n(BPT) - Imagine that you've taught your child everything they need to know about personal finance. Then as he's getting ready to head off to college and applies for financial aid, he's unexpectedly rejected for financial aid due to poor credit. Yet he's never applied for credit in his life. Sounds outrageous, doesn't it? But this can happen to victims of child identity theft\nMost Americans are aware that identity theft is a significant problem, and that it's important to take measures to protect your identity. What people might not know is their children may also be targets of identity theft before they even become old enough to own a credit card. The Federal Trade Commission\nhas identified child identity theft as a growing problem and encourages parents to do what they can to minimize the risks to their children.\nHow does it happen?\nThe most common way a criminal can steal or misuse the identity of a child is to get access to the child's Social Security number. The perpetrator then uses the Social Security number to open credit card accounts or loans, rent an apartment, sign up for utilities like cell phone service, or even apply for a job. Credit issuers often don't have a way to verify the age of the applicant, so if the criminal changes the age of the identity associated with your child, it's possible that the issuer may approve them for credit, according to the Identity Theft Resource Center\nOnce an account has been established in your child's name, it's easier for criminals to establish subsequent accounts until this fraud is discovered. If your child's identity is stolen at an early age and the theft goes undiscovered until she reaches the age where she begins to establish her own credit, it can be very difficult to discover how the fraud first occurred.\nHow can you help prevent it?\nParents can take a number of steps to help prevent their children from becoming identity theft victims:\n* Store your children's Social Security cards in a safe place like a safety deposit box. Only give out your children's Social Security number when it's absolutely necessary, and provide alternate verification whenever possible.\n* Teach your children to never reveal personal information to anyone, no matter how trustworthy that person may seem. People close to the family are often found to be perpetrators in child identity theft cases.\n* If your child receives pre-approved credit card offers in the mail, you may want to check in with a credit reporting agency or Social Security. If you've been contacted by a collection agency regarding an account in your child's name, there's a possibility your child's identity was stolen.\n* Consider signing up your family members for a credit monitoring and identity protection solution such as the Equifax Complete(TM) Family Plan\n, which can help to protect two adults and up to four minor children. With this product, you will be notified of any changes or suspicious activity on your adult credit files; in addition, you can monitor your minor child's identifying information for existence of an Equifax credit file and lock it, thereby preventing creditors from accessing this file while the child is enrolled in the plan.\nBy taking a few extra precautions to protect your children's identities, you can help ensure they get off on the right foot as they become adults and begin establishing their own credit histories.", "label": 1}
{"text": "California's secretary of state, Debra Bowen, believes that open-source software should be used in elections involving electronic voting machines, to protect against error and fraud.\nSpeaking in Cambridge, MA, [on Thursday] during a panel discussion at the EmTech organized by Technology Review, Bowen noted that individual counties are currently responsible for purchasing voting machines. Often the choice is left up to an IT professional who may lack detailed knowledge of cryptography and computer security. But the biggest concern, according to Bowen, is a lack of access to the machines' underlying code. \"Many times, a person has no legal right to review the software, even if they could,\" she said.\nBowen has a history of pushing for greater transparency and accountability in election technology. After taking office in November 2006, she commissioned a top-to-bottom review of e-voting systems, including detailed analyses of source code, documentation, security, and usability. \"All of the systems had security issues,\" Bowen said.\nThe study revealed a variety of problems, from software vulnerabilities that could let an attacker install malicious software that changes the outcome of a vote, to opportunities to tamper with the devices while they are held in storage.\nE-voting companies are working to address these problems, but Bowen is still frustrated that the software running on voting machines is proprietary.\nWhen asked about future elections, Bowen said the one technology she'd like to see integrated into voting systems tomorrow is open-source software for creating ballots and tabulating votes. Both tasks are horrendously complicated, she added, and so need to be very carefully monitored. For example, Los Angeles County alone may use 330 different ballots for a single election, because dozens of local races may be going on in different neighborhoods. And one common problem there with early deployments of touch-screen voting machines was that voters were presented with ballots that didn't show all the races that applied to them.\nTabulating votes is also problematic. Votes arrive through a variety of channels, via mail as well as polling stations, and must be tabulated quickly and accurately. But there is little regulation or oversight of the way existing software does this. \"A lot of the concern comes out of the fact that no one can look at the software,\" Bowen says. She notes that voting-machine analysis often has to be performed under a nondisclosure agreement, meaning that the details of some flaws remain undisclosed.\nMIT computer science professor Ron Rivest, who has studied the security and privacy of voting systems, says that these systems should be designed to work even if the software underneath is somehow flawed. \"Do you have to trust the software in order to trust the election results?\" he asks. The ideal situation, Rivest says, is one where the presence of bugs or malware cannot affect the outcome of an election.", "label": 1}
{"text": "SNMP is a simple protocol that can be used on just about any networking device in use today. In some environments it’s used heavily, in others it’s scarce. Some view it as a security threat; others see it as a way to efficiently manage some of their key systems.\nThe SNMP protocol was designed to provide a \"simple\" method of centralizing the management of TCP/IP-based networks – plain and simple. If you want to manage devices from a central location, the SNMP protocol is what facilitates the transfer of data from the client portion of the equation (the device you are monitoring) to the server portion where the data is centralized in logs for centralized viewing and analysis.\nSNMP design is pretty simple. There are two main players in SNMP. The manager and the agent. The manager is generally the ‘main’ station such as HP Openview.\nThe agent would be the SNMP software running on a client system you are trying to monitor.\nThe manager is usually a software program running on a workstation or larger computer that communicates with agent processes that run on each device being monitored. Agents can be found on switches, firewalls, servers, wireless access points, routers, hubs, and even users' workstations – the list goes on and on. As seen in the illustration, the manager polls the agents making requests for information, and the agents respond when asked with the information requested.\nThe types of data the agent and manager exchange are defined by a database called the management information base (MIB).The MIB is a virtual information store. It is a small database of information and it resides on the agent. Information collected by the agent is stored in the MIB. The MIB is precisely defined; the current Internet standard MIB contains more than a thousand objects. Each object in the MIB represents some specific entity on the managed device.", "label": 1}
{"text": "The U.S. intelligence community on Tuesday unveiled its own secretive version of Wikipedia, saying the popular online encyclopedia format known for its openness is key to the future of American espionage.\nThe office of U.S. intelligence czar John Negroponte announced Intellipedia, which allows intelligence analysts and other officials to collaboratively add and edit content on the government’s classified Intelink Web much like its more famous namesake on the World Wide Web.\nA “top secret” Intellipedia system, currently available to the 16 agencies that make up the U.S. intelligence community, has grown to more than 28,000 pages and 3,600 registered users since its introduction on April 17. Less restrictive versions exist for “secret” and “sensitive but unclassified” material.\nThe system is also available to the Transportation Security Administration and national laboratories.\nIntellipedia is currently being used to assemble a major intelligence report, known as a national intelligence estimate, on Nigeria as well as the State Department’s annual country reports on terrorism, officials said.\nSome day it may also be the path intelligence officials take to produce the president’s daily intelligence briefing.\nBut the system, which makes data available to thousands of users who would not see it otherwise, has also stirred qualms about potential security lapses following the recent media leak of a national intelligence estimate that caused a political uproar by identifying Iraq as a contributor to the growth of global terrorism.\n“We’re taking a risk,” acknowledged Michael Wertheimer, the intelligence community’s chief technical officer. “There’s a risk it’s going to show up in the media, that it’ll be leaked.”\nIntelligence officials say the format is perfect for sharing information between agencies, a centerpiece of the reform legislation that established Negroponte’s office as national intelligence director after the September 11 attacks.\nThey also said it could lead to more accurate intelligence reports because the system allows a wider range of officials to scrutinize material and keeps a complete, permanent record of individual contributions including dissenting points of view.\nThat might help avoid errors of the kind that led to the widely criticized 2002 national intelligence estimate that said Saddam Hussein possessed large stockpiles of weapons of mass destruction.\nIntelligence officials are so enthusiastic about Intellipedia that they plan to provide access to Britain, Canada and Australia.\nEven China could be granted access to help produce an unclassified intelligence estimate on the worldwide threat posed by infectious diseases.\n“We’d hope to get down to the doctor in Shanghai who may have a useful contribution on avian flu,” senior intelligence analyst Fred Hassani said.\n|copyright © 2006 Reuters. All rights reserved.|", "label": 1}
{"text": "1. What two protocols provide data authentication and integrity for IPsec? (Choose two.)\n2. After conducting research to learn about common remote connection options for teleworkers, a network administrator has decided to implement remote access over broadband to establish VPN connections over the public Internet. What is the result of this solution?\nA reliable connection is established at greater speeds than what is offered from dialup over POTS. Security is increased, but username and password information are sent in plain text.\nThe connection has increased security and reliable connectivity. Users need a remote VPN router or VPN client software.\nSecurity and reliability are increased at a substantial loss in throughput, which is considered acceptable when supporting a single user environment.\nReliability and security are increased without the need for additional equipment, when compared to dialup connections using POTS.\n3. A company is using WiMAX to provide access for teleworkers. What home equipment must the company provide at the teleworker’s site?\na WiMAX tower\na one-way multicast satellite\na WiMAX receiver\nan access point connected to the company WLAN", "label": 1}
{"text": "Do you know the most common password in the business world? If you do, that's the problem. Lots of other people also know or can guess: It's Password1.\nThat bit of confirming wisdom is contained in the 2012 Global Security Report from security firm Trustwave, released last month. The report, built on data from 2,000 vulnerability scans at client companies and 300 recent investigations into security breaches, highlights key data security risk areas and trends -- and one of the ongoing ones is selection of an insufficiently obscure and complex password.\nSatisfies Active Directory\nThe most common way of breaking into protected computers or networks is by guessing the password. Password1, in that exact form, satisfies the conditions that are required by Microsoft 's Active Directory, in that it has a capital letter, a number, and a sufficient number of characters.\nWhile Password1 is the most common single password, some variation on the word 'password' accounts for about 5 percent of all passwords. The next most popular, accounting for about 1 percent, is the word 'welcome.'\nTrustwave used several commonly available password-cracking tools on some of its clients' systems. Out of 2.5 million passwords, it was able to figure out about 10 percent of them. Trustwave puts the blame not only on employees, but also on businesses, since they allow employees and system administrators to use weak passwords.\nThe company's Global Security Report also focused on some other data security-related trends. For instance, a new target for hackers is franchises, with more than a third of data security investigations last year involving franchise businesses. One of the reasons that franchises have become popular targets, according to the report, is because the same IT systems are used across multiple stores, providing a larger payoff once that system is broken.\nA key trend cited in the report is a targeting of consumer records, with nearly 90 percent of all attacks intended to acquire personal, confidential information, including credit card data.\nThe food and beverage industry is the top target of cybercriminals, for the second year running. Investigations into data breaches are also rising. Trustwave said that it conducted 42 percent more investigations last year than in 2010, in 18 countries. The company said the increase was due to \"targeted, sophisticated attacks resulting in breaches,\" as well as more Asia-Pacific region investigations.\nThe most likely time for a malicious e-mail attachment to be sent? According to the report, it's between 8 a.m. and 9 a.m. Eastern time in the U.S.\nThe report also found that the ability or inclination of companies to detect security breaches declined in 2011, with only 16 percent of attacked companies able to determine by themselves that they had been compromised.\nThe other 84 percent had to rely on external information from a regulator, law enforcement or the public. Businesses that had to rely on external information gave the attackers an average of 173.5 days to enjoy that target company's environment without detection.", "label": 1}
{"text": "An extension to the HTTP protocol to support sending data securely over the World Wide Web. Not all Web browsers and servers support S-HTTP. Another technology for transmitting secure communications over the World Wide Web -- Secure Sockets Layer (SSL) -- is more prevalent. However, SSL and S-HTTP have very different designs and goals so it is possible to use the two protocols together. Whereas SSL is designed to establish a secure connection between two computers, S-HTTP is designed to send individual messages securely. Both protocols have been submitted to the Internet Engineering Task Force (IETF) for approval as a standard.\nS-HTTP was developed by Enterprise Integration Technologies (EIT), which was acquired by Verifone, Inc. in 1995.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "Helping people with computers... one answer at a time.\nKeeping data on your computer secure is important. Being able to password protect a folder seems an obvious approach. Unfortunately it's not that simple.\nCan I put a password on a folder so that only I can see its contents?\nYes and no.\nYou can do something similar to password protecting it using Windows security features. It depends, though, on using the computer the \"right\" way. On top of that, I actually don't really recommend it. If you have something that you want to password protect and keep secure, I recommend a slightly different approach.\nWindows allows you to place restrictions on who can do what with a folder, or even a file. In Windows Explorer, right click on a folder and Properties, and then click on the Security tab:\nHere you can see the properties of a folder on my machine called \"books\".\nHere you can control who has access to that folder. The default way my machine is set up, everyone can examine the contents of that folder. I can remove that and further restrict on an account-by-account basis which users can access that folder, and whether they can modify, read or even see the folder contents.\nIt's actually very powerful, if a tad complex.\nHowever, it's based on Windows user accounts. Thus if you give your own account full access to the file, as I assume you would, then anyone that can login to the machine as you can immediately access the file. There's no real password on the folder, it's your ability to login to Windows using your login password that controls your access to the file.\nAnd since it's based on Windows user accounts it assumes you're actually using different user accounts for different people. It's very common for that not to be the case.\nThe approach I prefer, and in fact use myself, is to use the free open-source tool TrueCrypt.\nWith TrueCrypt, you create a single file on your computer's hard drive that is encrypted. If someone looks at that file all they see is random data - there's no way to know what that file contains.\nOnce you \"mount\" that file using TrueCrypt, and supply the correct password or pass-phrase to unlock it, the contents of that file appear as another drive on your system.\nFor example, I might have a file \"c:\\Windows\\secretstuff.tc\". There's nothing you can do with that file without TrueCrypt and the password to the file. Since I know the password, I can mount it using TrueCrypt and suddenly a new drive appears - say \"P:\". That drive then contains all my protected files. I can change them, update them, delete them - whatever. Once I'm done, I can hide them all again by simply unmounting the TrueCrypt drive.\nIt's both simple and elegant.\nAnd it's not tied to Windows, user accounts or anything else. In fact, you can copy your encrypted file to another machine entirely and mount it with TrueCrypt. Even using other systems such as Linux.\nAnd while any encryption is vulnerable if you pick a bad password, the actual encryption algorithms used by TrueCrypt are \"industrial strength\" and nearly impossible to crack with current technologies.", "label": 1}
{"text": "updated Jan 27, 2009 12:07 pm | 4,375 views\nThe term \"account harvesting\" refers to the attacking technique or activities of grabbing legitimate user IDs and even passwords to gain access to target systems for illegal or malicious purposes.\nThe term account harvesting refers to the attacking technique or activities of grabbing legitimate user IDs and even passwords to gain access to target systems for illegal or malicious purposes. \nJavvin Technologies \nAccount Harvesting is the process of collecting all the legitimate account names on a system. Sniffing software is often used to harvest accounts.\nAccount Harvesting is often used to refer to computer spammers, individuals who try to sell or seduce others through email advertising or solicitation. Account harvesting involves using computer programs to search areas on the Internet in order to gather lists of email addresses from a number of sources, including chat rooms, domain names, instant message users, message boards, news groups, online directories for Web pages, Web pages, and other online destinations.\nAccount harvesting is a type of authentication attacks. It usually works out for applications that respond differently to a login request with an incorrect user ID and/or an incorrect password. Different reponses from the server to valid versus invalid authentication requests may allow the valid accounts on the system to be guessed and harvested.\nIt is noteworthy that different login error messages may sometimes be intentional - simply to let legal users know immediately what login information is wrong. However, the difference in the application response provides the attacker with significant hints to the correct account information.\nDifference in the application response may be classified into the following:\nCOMMON DEFENSIVE MEASURES\nHere are some common defensive measures against account harvesting:\nEnsure that consistent error messages are utilized for account-relevant requests with multiple outcomes (e.g., incorrect user id and/or incorrect password); To defend against the enumeration of valid accounts, use generic messages like \"Login Invalid\".\nEnsure that the accompanying information items listed below are consistent for different account-relevant error messages:\nEnsure that error messages are returned in approximately the same time. It is also an option to set a random wait time for all responses to conceal the timing details from the attacker.\nAccounts can be locked out temporarily when account harvesting is detected. \nThe attack can be considerably slowed down by the required additional information to access the secret question for a valid account. The additional information can be the birthdate of the user's mother, the combinition of the user's and his wife's birth years, last six of the user's SSN or some numbers on a credit card. without providing the additional information, the access to the selected secret question of an account should not be allowed. \nMonitor and analyze login logs via application intelligence for suspicious login patterns. Such patterns may cover a series of login failures across a list of accounts, a series of login failures across a single account, and a series of login failures for invalid accounts. That will help to detect account harvesting attempts. \nMost of account cracking tools, key-stroke loggers, packet sniffer tools, packet capture utilities, rootkits and Trojan login programs can be leveraged for account harvesting.\nRelated White Papers and Webcasts\nDisclaimer: IT Wiki is a service that allows content to be created and edited by anyone in the community. Content posted to this site is not reviewed for correctness and is not supported by Toolbox.com or any of its partners. If you feel a wiki article is inappropriate, you can either correct it by clicking \"Edit\" above or click here to notify Toolbox.com.", "label": 1}
{"text": "Over the years, the term malware has been used to describe any type of malicious software, including viruses, Trojan horses, worms, spyware, scareware, and adware. In the early days of computers, malware was considered more a prank used to annoy people through destructive behavior or to show off programming skills. Basically, the more people your malicious program could infect, the greater your status in certain circles. The malicious programs were often delivered to their intended victims as email attachments, shared through removable storage media or through file-sharing services.\nAlthough malware of this sort caused a wealth of problems for its victims, the driving force behind it did not motivate as many people to get involved because the payoff wasn't as lucrative to a wide base. Today, the driving force behind malware has shifted to money. Because these attacks are driven by financial rewards, there is more malware in the wild than ever before. Not only are more people involved in the creation and distribution of malware, but the attacks have grown more sophisticated. Cyber-criminals have learned how to use malware to turn large profits by:\n- Displaying and clicking ads\n- Stealing confidential data\n- Hijacking user sessions\n- Compromising user login credentials\n- Stealing financial information\n- Making fraudulent purchases\n- Creating spam\n- Launching denial-of-service attacks\nTo deliver their malicious software to as many victims as possible, cyber-criminals have turned to websites as one of their primary sources of distribution.\nPeople have learned not to download files attached to emails, and they have stayed away from popular file-sharing services because so many files are infected with malware. One thing that people have not stopped doing, though, is surfing the Web. According to Internet World Stats (see Resources for a link), in 2011 there were 2,279,709,629 active Internet users, and that number continues to grow.\nWith an attack landscape this large and with so many users not being suspicious, it's no wonder that websites have become the favorite media used to infect users with malware. In fact, malicious websites have become so prevalent that Google blacklists roughly 6,000 websites every day because they carry some sort of malicious software that is dangerous to visitors.\nThose responsible for infecting websites with malware do so in one of three ways:\n- They create a malicious website of their own.\n- They exploit a vulnerability on the web server or in its configuration.\n- They exploit a vulnerability in the applications the website relies on.\nBecause this article focuses on what you can do to prevent your websites from falling victim to these attacks, I address only the latter two methods.\nAfter an attacker has found a vulnerability that he or she can successfully exploit, the attacker needs to determine how he or she will deliver malware to the website's visitors. Table 1 lists some of the common methods.\nTable 1. Common ways websites distribute malware\n|Downloads||The user is tricked into downloading the malicious code. A common tactic used is to tell the visitor that he or she needs to update multimedia software to view a video, or a victim is tricked into downloading a PDF or other type of file that actually contains malware.|\n|Banner ads||Users are tricked into downloading malicious files when they click infected ads that appear on the website.|\nIn addressing server-based vulnerabilities, I look at two of the more popular web server applications on the market: Apache and Microsoft® Internet Information Services (IIS). These two servers power 78.65 percent of all websites.\nBoth Apache and IIS—or any other web server—have vulnerabilities that malicious attackers can exploit. When attackers are able to compromise the server software or the server itself, they are able to upload malicious code or even entire web pages that deliver malware to the site's visitors. Examples of vulnerabilities that allow this type of attack to take place come from two primary sources.\nWhen web server software is installed, the default configuration is usually set up to make publishing a website easy, not secure. Unnecessary modules and services may also be part of a web server's default installation. These extras may give an attacker unrestricted access to your website's files.\nEach operating system, web server software, and version has unique vulnerabilities that can be found with a simple web search. Before a website goes live, any known vulnerabilities should be addressed.\nThis source encompasses all aspects of user authentication and the management of active sessions. According to the Open Web Application Security Project (OWASP), \"A wide array of account and session management flaws can result in the compromise of user or system administration accounts. Development teams frequently underestimate the complexity of designing an authentication and session management scheme that adequately protects credentials in all aspects of the site.\"\nTo mitigate against this type of vulnerability, those responsible for the administration of the web server and site need to adhere to password policies that determine the strength, storage, and change controls of all passwords. Furthermore, remote management capabilities for the web server should be secured or even turned off so that user credentials are not compromised through transit.\nIf websites were still static text and images, it would be much more difficult for the bad guys to use a legitimate website to serve up malicious software. However, today's websites are powered by databases, complex code, and third-party applications that make the user experience much richer while opening the site to any number of vulnerabilities.\nTake WordPress, for example. This blogging application has changed how websites are created by making it easy for anyone with a bit of technical knowledge to create a multimedia-rich, interactive website. It is so popular that it powers more than 50 million websites. WordPress's ease of use, however, was also the cause of a recent outbreak, in which between 30,000 and 100,000 sites running the application redirected victims to malicious sites.\nSites that installed a particular plug-in found their pages infected with code that redirected visitors to another site. This site would then infect the victim's computer with malware based on the operating system and applications that the computer was running. The Flashback Trojan that infected more than 500,000 Macs was one of the malicious programs that spread through this exploit.\nExamples like this are not limited to WordPress, however. Applications like Joomla!, Drupal, MediaWiki, Magento, Zen Cart, and many others have all had vulnerabilities in them that allow malicious hackers to upload malware to these sites to be distributed to visitors.\nFor attackers to exploit a web application, they must find some type of vulnerability. Unfortunately for the owners of websites, there are so many different types of known vulnerabilities that they can't all be listed here. Some you may be familiar with, however:\n- Cross-site scripting (XSS)\n- Structured Query Language injections\n- Cross-site request forgery injections\n- URL redirects\n- Code execution\n- Cookie manipulation\nAnd the list goes on.\nFortunately, there are ways to find out if your site is vulnerable to any of the known exploits by using web application-penetration techniques. By thoroughly testing a website for known vulnerabilities, you can address these threats before an attack is able to manipulate them to distribute malware to your visitors. You can do so using a variety of open source or commercial tools, or you can outsource the service to companies that specialize in this.\nAlthough penetration testing will help identify problems that need to be fixed in your website's code, web application firewalls can help stop threats before they reach your site. By identifying known attack patterns, you can thwart the efforts of malicious hackers before they are able to cause damage to your site. More advanced web application firewalls can even provide protection against unknown, zero-day threats by identifying illicit traffic.\nWhenever a server is configured, it is a best practice to install only the modules and applications that are necessary. By now, this is not only a best practice but a common practice.\nThere are other basic steps that you should take to limit the vulnerabilities that exist in Apache's web server. Throughout the course of this article, I use the commands relevant to the Ubuntu distribution of Linux®. For Apache running on other operating systems or distributions, simply search for the steps required to perform each task.\nBy default, Apache shows its name and version number upon a web request, announcing to any potential attackers what exactly the website is running. Disabling that banner makes it more\ndifficult to pinpoint any other vulnerabilities. You can do so by navigating to /etc/apache2/apache2.conf and disabling the\nAnother default is the ability to print a list of files found in the web site directories. This feature lets an attacker map your server and identify potentially vulnerable files. To mitigate against this issue, you need to disable the autoindex module. Simply open the terminal and use the following commands:\nrm -f /etc/apache2/mods-enabled/autoindex.load\nrm -f /etc/apache2/mods-enabled/autoindex.conf\nWeb-based Distributed Authoring and Versioning (WebDAV) is the file-access protocol of HTTP that allows for the uploading, downloading, and changing of file contents on a website. In any production website, WebDAV should be disabled so that an attacker cannot change your files to upload malicious code.\nUsing the terminal, you disable the dav, dav_fs, and dav_lock files by removing them with the following:\nrm -f /etc/apache2/mods-enabled/dav.load\nrm -f /etc/apache2/mods-enabled/dav_fs.conf\nrm -f /etc/apache2/mods-enabled/dav_fs.load\nrm -f /etc/apache2/mods-enabled/dav_lock.load\nrequest can be tricked into printing session cookies and this information used to hijack\na user session to launch an XSS attack. You can disable this trace by navigating to the\n/etc/apache2/apache2.conf file and making sure that\nOne thing that makes Windows Server® products so attractive to the consumer market is their ease of installation. Using IIS, a company can get a web server up and running with a few clicks. When the server software is installed out of the box, there is little need for configuration: It's done for you.\nTo address security issues in its web server product, Microsoft has made significant changes to how IIS is configured and what is installed by default. There are, however, some steps that you can take to better protect against threats.\nCode Red and Nimda were both worms that attacked the Windows Server operating system, and both did a great deal of damage. Without adequate antimalware protection on the host operating system itself, a website quickly becomes vulnerable to attack. Using keystroke loggers, Trojans, and other malware, attackers can not only easily compromise the web administrator's login credentials, but they also have the ability to insert malicious code into the files that are served up to people visiting the site.\nAfter antimalware software is installed, it should be immediately updated and then run before any website files are uploaded. If anything is found, all passwords should immediately be changed.\nBefore a web server running IIS goes live, be sure to update the operating system software and web server software with the latest updates from Microsoft. These updates usually contain patches that address vulnerabilities specific to Microsoft products.\nWhen a website is guilty of causing harm to its visitors, you must take steps immediately. To begin with, take down and quarantine your site. If you need to have your site up and running so as to avoid interrupting your business, rely on a backup that is verified malware free.\nWhen your web presence is taken care of, it's time to clean the infected files. Some infections require only the removal of a few lines of code, while more sophisticated attacks might require that you rewrite the entire file. Whatever steps are necessary to remove malware from a site need to be taken at this point.\nWhen Google and the other search engines find a site that is serving malware, they can pull it from their results. This can have devastating effects on a business.\nAfter all malware has been removed and any vulnerabilities patched, submit the site to the search engines for review. If they determine that it is no longer a threat to any visitors, the website can be re-listed and traffic from the search engine can be restored.\nIf the malware infection has compromised user account information, all users should be notified immediately so that they can deal with any ramifications. In addition, an organization will need to see whether any laws or regulations have been violated as a result of the breach and take appropriate measures to mitigate any negative effects and keep them in compliance.\nIn a report by Dasient, approximately 1.1 million websites were found to have some type of malware in the fourth quarter of 2010. Other studies show that 85 percent of all malware comes from the Web. Now, it would be easy to write this off if the sites that were causing all the problems had a malicious intent from the beginning. Unfortunately, it is the small business website, the church website, or even the well-respected news website that is responsible for infecting so many computers.\nThe responsibility for protecting websites against attack is falling on the shoulders of the web developer. The days of sitting back and writing awesome code are over. Now, the developer needs to make sure that his or her code is functional and secure.\nThe techniques listed in this article will certainly help the developer who doesn't understand web site security build a foundation for his or her knowledge, but it shouldn't stop here. The threat landscape changes daily. As zero-day exploits emerge and cyber-criminals adapt to countermeasures, web developers too need to adapt and be on the lookout for how they can better secure their sites.\nInternet World Stats: Find more Internet statistics.\nGoogle blacklists: Read more about why Google blacklists roughly 6,000 websites every day.\nPrevalence of Apache and IIS: According to Netcraft, Apache and IIS power 78.65 percent of all websites.\nWordPress: Read more about the prevalence of WordPress.\n\"Hardening the Linux server:\" Learn how to harden your Linux server (developerWorks, December 2008).\nOWASP Top Ten Web Application Security Threats: Learn more about OWASP and its work.\nWeb development zone: Find resources for Web 2.0, Ajax, wikis, PHP, mashups, and other web projects.\ndeveloperWorks technical events and webcasts: Stay current with technology in these sessions.\ndeveloperWorks on Twitter: Join today to follow developerWorks tweets.\ndeveloperWorks podcasts: Listen to interesting interviews and discussions for software developers.\ndeveloperWorks on-demand demos: Watch demos ranging from product installation and setup for beginners to advanced functionality for experienced developers.\nGet products and technologies\nIBM product evaluation versions: Download or\nexplore the online trials in the IBM SOA Sandbox\nand get your hands on application development tools and middleware products from DB2®, Lotus®, Rational®, Tivoli®, and WebSphere.®\n: Connect with other developerWorks users while exploring the developer-driven blogs, forums, groups, and wikis.\nJeff Orloff is a freelance technology writer who also works as a technology coordinator with the School District of Palm Beach County, Florida. Throughout his career, he has worked with web technologies, specializing in security. He has served as the director of technology for SafeWave, as a security evangelist for Applicure Technologies, and as the editor of Developer Drive, a blog dedicated to website development tutorials.", "label": 1}
{"text": "David E. Evans\nAssistant Professor of Computer Science\nSchool of Engineering and Applied Science\nWhat Biology Can Teach Us About Computer Security\nWitty Worm. Code-Red. Nimda. Sapphire/Slammer SQL.\nTheir names are curious, engaging, almost comical, but computer worms and other viruses are no laughing matter. Viruses and other malicious software cost businesses billions each year, and cause users hours of frustration.\nPart of the problem is that modern viruses spread so quickly, the old ways of combating them are no longer effective. Machines are highly connected, and the Internet is open to everyone, so malicious code can spread remarkably quickly.\n2003, the Cooperative Association for Internet Data Analysis reported\nthat the Sapphire/Slammer SQL worm spread worldwide in only 10 minutes,\nand at its\npeak — three minutes after its release — scanned the Internet at\nmore than 55 million addresses per second. Researchers have speculated that a\nwell-designed worm could infect all vulnerable machines on the Internet within\na few hours of its launch.\nThe problem with our current methods of fighting computer virus attacks is that we cannot cope with unfamiliar enemies. Computer antivirus software recognizes the signatures of known viruses, and gets rid of them. But it can’t get rid of a virus that it hasn’t seen before. Human intervention is needed to identify and analyze the attack code, create a signature for detecting it, and update anti-virus software to recognize and prevent the new attack.\neffective defenses must be able to defend systems from attacks that do not\nConsider the way in which the human immune system works. Viruses\nand bacteria attack their human hosts. The human immune system responds\nby isolating and\nattacking the foreign bodies. It does this, responding to unfamiliar things,\nwhat is familiar and concluding that what is not familiar is foreign and\nmust be eliminated. Unlike computer anti-virus software that recognizes\nof known viruses, the human immune system is able to recognize and destroy\npreviously unknown viruses.\nComputer systems, however, suffer from a lack of diversity. Nearly all computers on the Internet run the same operating systems and applications. Without diversity, systems all are vulnerable to the same attacks. A monoculture enables people to share programs and data, but means attacks can be shared in the same way.\nResearchers are beginning to develop ways to build systems that are diverse as far as attackers are concerned, but still appear the same for legitimate users. DARPA, the Defense Advanced Research Project Agency, is funding research to develop technologies for computer systems that provide critical functions even while under attack. The projects funded under this new initiative include a $1 million contract to researchers at the University of Virginia and Carnegie Mellon University to explore the idea of biologically inspired diversity as an approach to computer security. The project goal is to add an element of diversity throughout the system without changing the way users interact with it.\nResearchers are still grappling with the problem of how to automatically create enough diversity to foil attacks, while preserving the program behavior and performance users expect.\nUnlike nature, where attacks evolve, computer attacks are engineered, and sophisticated attackers can design malicious code intended to circumvent or fool defenses. As in natural selection, there is a continual arms race between those attempting to build secure computer systems, and those attempting to compromise them.\nFor now, computer professionals are racing to keep pace with the attackers and struggling to develop specific defenses for every new attack. Before long, we hope to be able to create the computer equivalent of a broad-based antibiotic that can protect systems from any attack, known or unknown.\nDavid Evans is an assistant professor in the Department of Computer Science whose research focuses on encryption and computer security.\n|*All opinions on this page belong to the authors and do not necessarily reflect the opinions of the University of Virginia. All other text, images, logos and information contained on official University of Virginia Web sites are the intellectual property of U.Va. ©\nby the Rector and Visitors of the University of Virginia\nFaculty Opinions site edited and maintained by Charlotte Crystal", "label": 1}
{"text": "Decision-Making and the Straw Man\nby Rick Brenner\nIn project work, we often make decisions with incomplete information. Sometimes we narrow the options to a few, examine their strengths and risks, and make a choice. In our deliberations, some advocates use a technique called the Straw Man fallacy. It threatens the soundness of the decision, and its use is very common.\nNatalie interrupted Geoff. \"I don't think that's a realistic approach at all. Even if we had the budget, we don't have time to hire thirty people.\"\nGeoff was now on defense. \"I never suggested that — I said that to make the scheduled date would require thirty more people. Hiring is probably the worst way to get there.\"\nPlaying defense, Geoff's task is not only to make his original point, but also to remove the distortions that Natalie has introduced into the debate by using a technique called the Straw Man fallacy.\nTo use Straw Man, you state your partner's position in a form that's easy to refute. Then you refute your restatement of it, often by showing that it has unacceptable implications.\nMost of us use Straw Man from time to time. It's so common that we rarely notice it. Here are some indicators that your partner may have used Straw Man.\n- A sense of frustration\n- Feelings of frustration during debate can arise from many possible sources, but check for Straw Man first.\n- Someone characterizes your position\n- Your partner characterizes your position, and you have little or no opportunity to critique the characterization before the process of drawing extremely undesirable inferences has begun.\n- Absolute language\nThe Straw Man fallacy\nis so common that\nwe rarely notice it\n- In the characterization of your position, nuances and qualifications are removed, and an absolutist version of your position emerges. Words like every, nobody, all, none, always, never, forever, 100%, completely, and so on are good indicators.\n- I never said...\n- If you feel the need to clarify, or to deny that you said something, there's a good chance that your partner has used Straw Man.\nIf the user of Straw Man prevails, success might be based not on the strength of the argument, but on a distorted premise. And anything constructed on that basis is more likely to be wrong. To manage this risk, be prepared to deal with the Straw Man fallacy when it appears.\n- Make sure that everyone understands the Straw Man fallacy, how it works, and what it costs.\n- Notice characterizations\n- When you notice that someone's position is being characterized, speak up. Before the implications begin to flow, ask for discussion of the characterization, and gain agreement that it's fair and complete.\nWhen we use Straw Man in the decision-making context, we typically intend to eliminate something from the list of candidates so that the group will choose one of the other options. This is a setup for tragedy. If the ploy works, we will have chosen that option not by comparing it to the options we do have, but to distortions of them. And we will have built our decision on a foundation of straw. Top Next Issue\nFor more on the Straw Man fallacy, see D. Walton, \"The Straw Man Fallacy,\" in Logic and Argumentation, J. van Bentham, et. al., ed. Amsterdam: North Holland, 1996. Available at io.uwinnipeg.ca/~walton/96straw.pdf.\nAre you fed up with tense, explosive meetings? Are you or a colleague the target of a bully? Destructive conflict can ruin organizations. But if we believe that all conflict is destructive, and that we can somehow eliminate conflict, or that conflict is an enemy of productivity, then we're in conflict with Conflict itself. Read 101 Tips for Managing Conflict to learn how to make peace with conflict and make it an organizational asset. Order Now!\nYour comments are welcome\nWould you like to see your comments posted here? Send me your comments by email\n, or by Web form\nAbout Point Lookout\nThank you for reading this article. I hope you enjoyed it and found it useful,\nand that you'll consider recommending it to a friend\nPoint Lookout is a free weekly email newsletter. Browse the archive\nof past issues. Subscribe for free.\nSupport Point Lookout by joining the Friends of Point Lookout,\nas an individual or as an organization.\nDo you face a complex interpersonal situation? Send it in,\nanonymously if you like, and I'll give you my two cents.\nMore articles on Emotions at Work\n- Feedback Fumbles\n- \"Would you like some feedback on that?\" Uh-oh, you think, absolutely not. But if you're like many of us, your response is something like, \"Sure, I'd be very interested in your thoughts.\" Why is giving and receiving feedback so difficult?\n- Demanding Forgiveness\n- Working together under stress, we do sometimes hurt each other. Delivering apologies is a skill critical to repairing those hurts and maintaining our relationships.\n- It's a Wonderful Day!\n- Most knowledge workers are problem solvers. We work towards goals. We anticipate problems as best we can, and when problems appear, we solve them. But our focus on anticipating problems can become a problem in itself — at work and in Life.\n- Sixteen Overload Haiku\n- Most of us have some experience of being overloaded and overworked. Many of us have forgotten what it is not to be overloaded. Here's a contemplation of the state of overload.\n- The Focusing Illusion in Organizations\n- The judgments we make at work, like the judgments we make elsewhere in life, are subject to human fallibility in the form of cognitive biases. One of these is the Focusing Illusion. Here are some examples to watch for.\nSee also Emotions at Work, Effective Communication at Work, Critical Thinking and Rhetorical Fallacies for more related articles.\nI offer email and telephone coaching at both corporate and individual rates.\nContact me for details at rbrenner@ChacoCanyon.com\nor (617) 491-6289, or toll-free in the continental US at (866) 378-5470.\nGet the ebook!\nPast issues of Point Lookout\nare available in six ebooks:\nReprinting this article\nAre you a writer, editor or publisher on deadline?\nAre you looking for an article that will get people talking and get compliments flying your way? You can have 500 words in your inbox in one hour. License any article from this Web site. More info\n- The Race to the South Pole: Ten Lessons for Project Managers\n- On 14 December 1911, four men led by Roald Amundsen reached the South Pole. Thirty-five days later, Robert F. Scott and four others followed. Amundsen had won the race to the pole. Amundsen's party returned to base on 26 January 1912. Scott's party perished. As historical drama, why this happened is interesting enough, but to project managers, the story is fascinating. Lessons abound. Read more about this program. Here's an upcoming date for this program:\n- The Race to the South Pole: The Power of Agile Development\n- On 14 December 1911, four men led by Roald Amundsen reached the South Pole. Thirty-five days later, Robert F. Scott and four others followed. Amundsen had won the race to the pole. Amundsen's party returned to base on 26 January 1912. Scott's party perished. As historical drama, why this happened is interesting enough. Lessons abound. Among the more important lessons are those that demonstrate the power of the agile approach to project management and product development. Read more about this program. Here's an upcoming date for this program:\n- The Politics of Meetings for People Who Hate Politics\n- There's a lot more to running an effective meeting than having the right room, the right equipment, and the right people. With meetings, the whole really is more than the sum of its parts. How the parts interact with each other and with external elements is as important as the parts themselves. And those interactions are the essence of politics for meetings. This program explores techniques for leading meetings that are based on understanding political interactions, and using that knowledge effectively to meet organizational goals. Read more about this program. Here's an upcoming date for this program:\n- TBD, Mansfield, MA: August 21, Regional Event, PMI MassBay, PMI Central Mass, Ocean State PMI, PMI Keene, PMI Southern New England.", "label": 1}
{"text": "Challenge-response techniques called \"CAPTCHAs\" designed to keep spambots off Web sites can easily be broken by humans who are paid to type in the responses, according to a new report from security firm Imperva.\nCAPTCHAs, which stands for Completely Automated Public Turing test to tell Computers and Humans Apart, are created by programs and are intended to be difficult for computers to fill out.\nWhen it launched in 2010, NuCaptcha touted its proprietary technology as being able to \"provide the highest level of security available\" by using video streams to display those distorted letters you type in to prove you're really a human.\nNow, however, the company's claims of providing \"the next generation of Captcha security\" look a tad optimistic.\nA team of Stanford University researchers said today that they discovered a way to break the security of a recent version of NuCaptcha's video Captcha by borrowing concepts from the field of machine vision, which developed techniques … Read more\nPALO ALTO--A team of Stanford University researchers has bad news to report about Captchas, those often unreadable, always annoying distorted letters that you're required to type in at many a Web site to prove that you're really a human.\nMany Captchas don't work well at all. More precisely, the researchers invented a standard way to decode those irksome letters and numbers found in Captchas on many major Web sites, including Visa's Authorize.net, Blizzard, eBay, and Wikipedia.\nGoogle TV uncovers an update, something is sucking the life from the iPhone 4S, and evil robots cannot be stopped by Captcha...or at least some of them.\nLinks from Monday's spook-tacular episode of Loaded:Captchas can't stop evil bots Google TV... it's baaaaack GameStop gone mad? It's selling tablets now. The Microsoft Kinect SDK is alive! What's sucking the life from iPhone 4S? Subscribe: iTunes (MP3) | iTunes (320x180) | iTunes (HD) | RSS (MP3) | RSS (320x180) | RSS HD\nModern captchas are effective at keeping bots and algorithms from accessing Web sites made for humans. They also generate collateral damage and keep up to 25 percent of humans out, too, according to Ron Moravek, COO of NuCaptcha. He says he has a better, more flexible technology for filtering humans from bots.\nNuCaptcha is a replacement technology for the free, Google-owned ReCaptcha service. There are two major differences between NuCaptcha and ReCaptcha. First, NuCaptcha displays moving text against a moving image. While this makes it harder for computers to discern text from background, it makes it much easier for humans. … Read more\nCybercriminals are likely to find more jobs next year, one of five top trends forecast by security vendor Fortinet.\nIn an ironic twist in the job market, more positions will open up for developers who can write customized malware packers, people who can break CAPTCHA codes, and distributors who can spread malicious code, according to Fortinet.\nAnd though cybercrooks have typically deployed their own botnets themselves, Fortinet believes this job will increasingly be farmed out to middlemen, citing the Alureon and Hiloti botnets as two examples of malware distributed this way. Money mules responsible for wiring funds and cashing checks … Read more\nFacebook just launched a new suite of features for Facebook Places that might be the beginning of the end for Web privacy as we know it. Luckily Natali Del Conte is around to calm us down and explain what's really going on with the new location-based deals.\nFacebook Places is a service that lets users share their location directly on their mobile phones, but the latest product is called Deals, and it allows businesses to advertise to target customers by offering a special discount for those who \"check in\" at a location.\nOnce users activate it, Facebook will share the deal on their walls so others can cash in as well, and business can even offer \"loyalty\" discounts for members that return to a venue. The FourSquare and Loopt offices must be getting pretty hot right now.\nIf mobile tracking weren't enough, soon you won't even be able to watch a movie without being watched yourself! In an effort to combat Web piracy, some movie theaters are installing video cameras in front of the movie screens, designed to also monitor crowd reactions to trailers for market research on what audiences prefer to watch.\nEven worse, the same company, Aralia Systems, is also planning to roll out infrared scanning systems at the ticket-purchasing stations that scan for recording devices and will sound an alarm to alert management if an illegal instrument is detected. It sounds similar to the TSA's \"enhanced\" security screenings we've been hearing about recently!\nInternet \"Captchas\" have been around for a while--they're tests placed on some Web sites to determine whether the user is human, and they usually come in the form of a randomly generated word or phrase that you have to copy into a field to gain access.\nThey're only slightly irritating and require little participation to enter, but a software firm called NuCaptcha is hoping that video advertisement captchas will be the online ads of the future.\nInstead of traditional squiggly words, the new system forces users to watch a video advertisement with a short message scrolling across it. After it's done, it'll ask you to identify and retype a part of the message to continue toward your destination, and although it sounds like an annoying process, companies like EA, Wrigley, and Disney have already signed up with hopes that people will actually pay attention to the ads instead of just clicking through. Soon we'll be reminiscing about a time when all you needed was a pop-up blocker to surf under the radar!\nThanks to Natali Del Conte for joining us on this rainy Thursday, and be sure to check us out tomorrow morning with Steve Guttenberg, aka The Audiophiliac!Episode 702 Subscribe in iTunes audio | Suscribe to iTunes (video) | Subscribe in RSS Audio | Subscribe in RSS Video… Read more\nNatali Del Conte joins us in the studio to discuss really important issues such as boobquake day, cartoons, and violent video games. Oh, come on, we also discuss Google's failed attempts to reinvent the mobile phone sales paradigm, unfounded causal links between violent video games and sociopathic behavior, and the dangers of colonization. Good show, guys.Subscribe with iTunes (audio) Subscribe with iTunes (video) Subscribe with RSS (audio) Subscribe with RSS (video) EPISODE 1214\nGoogle Nexus One Gone From Verizon Lineup http://jkontherun.com/2010/04/26/no-nexus-one-on-verizo/ http://preview.bloomberg.com/news/2010-04-26/verizon-says-it-has-no-current-plans-to-distribute-google-nexus-one-phone.html http://www.cnet.com/8301-19736_1-20003397-251.html… Read more\nFacebook on Thursday fended off an attack in which multiple identical profiles were created to spread malware.\nAntivirus provider AVG Technologies said users of its LinkScanner service detected numerous profiles that were identical except with different names and each included a link to what was represented as a home video but which instead displayed a fake antivirus alert when clicked. The scams are designed to trick people into paying for software they don't need, to get credit card information from victims for identity fraud purposes, and often to install spyware on the computer.\n\"Clearly, the Data Snatchers have … Read more", "label": 1}
{"text": "Single Sign On\nWhen the World Wide Web made its debut more than a decade ago, keeping track of login names and passwords was fairly simple. As the web grew in popularity, and new services like banking and shopping online came of age, more and more services required users to create special names and passwords to access personal information, or other 'members only' features.\nFor an active Internet user, these login combinations could multiply quickly. Passwords soon needed to be at least eight characters and contain extra numbers or characters to prevent security problems. Some times when you created a new user name, you found your username was in use, and pretty soon you needed a file to keep all your different login combinations straight. Often post-it notes with your usernames and passwords could be found stuck on your monitor or under your keyboard. How secure is that?\nRecently, a new alternative to all the confusion is gaining momentum in the online world, called OpenID. The concept, originally developed in 2005, allows users to get access to any OpenID enabled site using a single 'trusted' username and password. You may already have an OpenID you aren't aware of from services like Google, Yahoo, AOL, Verisign, Paypal and many others. When you encounter a service using OpenID, your username and password is checked from a trusted OpenID source like those mentioned above, and you're granted access.\nThis system is considered to be very secure, and very convenient, and is now being adopted by many government bodies who see the benefits of individuals using a single, secure identification for the web, including the City of Nanaimo.\nOpenID in Government\nThe City of Nanaimo is not alone in recognising this global need. The US Federal Government has recently committed to embrace OpenID to allow simple access to citizen resources (http://openid.net/government/). As of November 2008, there were over 500 million OpenIDs on the Internet and approximately 27,000 sites had integrated the OpenID standard*. (* see - http://en.wikipedia.org/wiki/OpenID)\nCity of Nanaimo Services Using OpenID\nThe first two City sites to use OpenID are Secret Nanaimo (www.secretnanaimo.com) and our recently updated Emergency Notification System (http://www.nanaimo.ca/EN/main/departments/FireRescue.html#CallAlert). City departments are working to provide new online services using OpenID. We are also working closely with commercial software providers to enable OpenID support for all of our citizen services.Go to Top", "label": 1}
{"text": "Utilities around the world are implementing smart utility networks to strengthen an aging electricity grid. Smart Grid renovation is well underway in the US, Europe ,China and Australia. Momentum is picking up everywhere in the world. For example: the UK is working on a major implementation, and has just released Smart Meter Technical Specifications;\nSmart utility networks using wireless mesh networking technology have seen the largest implementation to date . However, other systems based on Cellular technology, Powerline Communications (PLC), WiLAN, and WiMax, are also being used for backhaul communication.\nThe special report discusses the network architecture, system and network components, and comparison of different technology options. The report also addresses the standards being used for these networks. While the main focus is on electric utilities, water and gas distribution networks are also addressed.\nSmart Utility networks support a number of applications ranging from reading of energy consumption at end-points, consumption/\nThe report is useful to all those involved in the smart grid/smart energy business. It provides a basic understanding of the network and sensor technologies deployed in the utility distribution network, and the applications they are being used for. Further, the report addresses the utilization of IPv6 in these networks. Standards are an important element and the report addresses the international standards utilized in these networks, and test and certification process employed.\nA summary of the report is published in the SPOTLIGHT section in Smart Energy Universe this week. Contact SEU at firstname.lastname@example.org for more information about ordering the report.\nSEU is currently working on security aspects of the Grid and a report to be released shortly will address cybersecurity issues in the smart grid.\nAbout Smart Energy Universe\nSmart Energy Universe (www.smartenergyuniverse.com) provides the latest and most comprehensive coverage of global smart energy/smart grid business, systems, technology, and standards. SEU’s site is completely refreshed with totally new content each week.", "label": 1}
{"text": "Friends and colleagues have been expressing doubt about entrusting their data to “The Cloud”, especially in light of the recent high profile attacks on the CIA, the Senate, and Sony (among many others). As educators are increasingly adopting cloud-based tool in instruction, it’s very important to have a clear idea of what we’re really talking about here, and to clear up as much FUD as possible.\n“The Cloud” is not one thing—while the many recent hacks are being lumped together in the mainstream media, there were different circumstances in each case, and each teaches us a different lesson about online security.\nThe Sony hack was a particularly bad one because they stored all their users’ passwords in un-encrypted text. Since so many people use the same password for multiple online services, it’s likely that your playstation password is also the password you use for your email, your bank, and your paypal account. Hackers got these poorly-protected passwords, Sony didn’t notify the public for 5 days, so the hackers had a field day with the data and got into several other accounts.\n1. Use unique strong passwords for all of your different “cloud” accounts. This way if one password gets compromised it does not open up all the rest of your accounts as well. Using a password manager like LastPass can help (I swear by it), or you can also create a hard-to-guess-but-easy-to-remember password formula.\n2. Don’t store your passwords in your browser’s memory. Again, LastPass is great for this because it encrypts them.\n3. Investigate the security practices of cloud services you trust with your sensitive data.\nSome of the most high-profile attacks by LulzSec (like the CIA & Senate website attacks) were Denial of Service (DOS) attacks—meaning that they did not actually gain access to any unprotected data. A DOS basically floods a website with so many requests that it can’t process them all and the website goes offline temporarily. It’s like getting everyone you know to go ring someone’s doorbell one after another until they stop answering the door. It might drive that person nuts, but it also doesn’t open the door. These attacks are now commonly performed with botnets—large armies of computers infected with viruses that allow one hacker to direct millions of computers (often unbeknownst to their owners) to access the target website and bring it down. Large cloud services like Amazon and Google are designed to withstand these attacks by re-allocating their enormous computing resources to meet all the requests and keep the websites up and running during the attack. Smaller servers without as many resources are most vulnerable to DoS attacks.\n1. Use virus protection software on your computer and perform all necessary updates as soon as they’re released.\n2. Keep your browser & plugins up to date. This tool will scan your browser and plugins for security vulnerabilities.\nOf course, LulzSec and others have been perpetrating more sophisticated attacks than DoSes. They have been exposing security flaws in their targets’ websites which will eventually lead to better security practices across the board. I know it has forced me to be more careful with my personal security practices and it has been pretty easy to do. (My data was exposed in the Sony hack and last year’s Gawker hack, but I’ve taken some simple steps to minimize the damage that anyone can do.)\nIn the meantime, there is a lot you can do to protect yourself online—even in “The Cloud”.\n- Guard That Password (and Make Sure It’s Encrypted) (nytimes.com)\n- 6 Password Protection Lessons Learned from the Sony Hacker Attack (savings.com)\n- LastPass Alternatives That Keep Your Passwords Safe From Online Hacking (gizmodo.com.au)\n- Hackers attack Sony network again (bbc.co.uk)\n- Sony BMG Greece hacked (go.theregister.com)\n- Why I Can Guess Your iPad Password (techland.time.com)", "label": 1}
{"text": "Malware and spam in blogs\nWhatever attracts us on the Internet also attracts malware. So as blogs (short for web logs) became popular by 2003, spammers and hackers discovered new possibilities to spread spam and malware.\nBlog spam (also called comment spam or spomments) is created by automatically posting random comments or promoting commercial services in the comment section of blogs, as well as in guestbooks, wikis, or other publicly accessible online discussion boards. Any web application that displays hyperlinks submitted by visitors is a potential target.\nThe goal of the spammer is to add links across the web that point to his website, thus artificially increasing that site's search engine ranking and the number of potential visitors and paying customers. This type of spam originally appeared in Internet guestbooks, where spammers repeatedly filled guestbooks with links to their own website and no relevant comment.\nMost blog spam falls into one of three categories:\nComment spam - unsolicited and mostly unrelated comment on a blog that advertises a product or a website. Some of it might be added manually by a person to a particular blog entry, but most comment spam comes from scripts that can add many comments automatically to one post or many posts simultaneously.\nTrackback spam - spammers develop scripts that use blog software's trackback features to automatically place spam on different blogs.\nSpam blog (or splog) - a blog created for no other purpose than to advertise products or point visitors to various websites. Though ignored by most people, these blogs pollute the results of search engines that index websites.\nBlogs hosting malware\nApart from spam, blogs are also becoming a means of spreading malicious code and keylogging software. Blogs are an obvious backdoor opportunity for unknown exploits to invade legitimate sites.\nAccording to a report from March 2011, more than one million websites were believed to be infected with malware in the fourth quarter of 2010, nearly double compared to the previous year. The year 2010 also saw various variants of the computer virus Liza Moon using blogs to spread. Liza Moon has affected more than 4 million website, according to a recent report by AllVoices.com. The virus, named after the website that discovered it, was first reported on March 29 2010, with the first confirmed attack taking place in December 2010.\nThe virus infects computers by injecting malicious SQL codes on a website and redirects users to another website containing a Trojan. Users are then told their computers are infected by a computer virus and are prompted to download an anti virus software called Windows Stability Centre, the report stated.\nAs a blogger, you have several ways of preventing spam comments: from verification text boxes which require human action (such as typing the letters displayed in a picture) to dedicated prevention tools - such as Akismet for Wordpress. You can prevent more serious attacks to the blog structure by keeping your blog platform updated (just like you would do with your operating system).\nIf you don’t have one yourself, but like to read other peoples blogs, you can stay safe by having active and updated internet security software on your PC at all times.", "label": 1}
{"text": "NASA Releases Interactive Space Communications Mobile Game App\nMOFFETT FIELD, Calif. -- Just in time for World Space Week, NASA has released a new mobile application that challenges gamers to take on the role of a space communications network manager and puts them in charge of building a communications network to support scientific missions.\nThe educational application, \"Space Communications and Navigation: NetworKing,\" was developed at NASA's Ames Research Center in Moffett Field, Calif., for the iPad and iPhone. NetworKing provides an interactive, 3-D experience with an insider's perspective into how mission controllers and scientists communicate with spacecraft and satellites using the space, deep space and near Earth networks.\n\"This game introduces the complex world of space communications to gamers,\" said Barbara Adde, policy and strategic communications director for the Space Communications and Navigation Division at NASA Headquarters in Washington. \"It gives players the opportunity to enjoy a challenging game while absorbing the basic concepts of space communications. The game provides an engaging way to increase interest in the areas of science, technology, engineering and mathematics and opens minds to potential careers in these fields.\"\nNetworKing allows players to build increasingly large and complex communication networks to support client satellites conducting scientific missions. Players who upgrade their communication networks can acquire more complex clients, such as the International Space Station and NASA's Hubble and Kepler space telescopes.\nBy providing insight into the complex world of communications between astronauts, mission controllers, scientists and satellites in real mission scenarios, the game is not only challenging, but also entertaining.\nIn addition to the mobile application, NetworKing also is available free on the NASA 3-D Resources website. Players can access the game on their web browsers or it can be downloaded and run on PC or Macintosh operating systems.\nFor links to download the app, download the game or play in a web browser, visit:\n- end -\ntext-only version of this release\nNASA press releases and other information are available automatically by sending a blank e-mail message to\nTo unsubscribe from this mailing list, send a blank e-mail message to\nBack to NASA Newsroom |\nBack to NASA Homepage", "label": 1}
{"text": "With technological advancement, there comes a risk for every convenience. The popularity of online shopping and banking also gave birth to the opportunists such as hackers. Before, virus used to be the most difficult security issue to resolve but the evolution of malware changes everything. Identity theft and other means of privacy invasion have been rampant these days. Blame the spyware for it.\nSpyware is a type of malware which can be installed on computers to collect user information without the owner’s knowledge and permission. Personal computers used to be the target of spyware but as day goes on, keyloggers have been installed on shared, corporate and public computers. Different spyware programs can collect personal information, control user’s activity in the form of webpage redirection, allow download or installation of related spyware, modify computer settings, trasmit information and more.\nTo prevent cases like this, it is important to have antispyware software. There are applications that offer antivirus, antispyware and firewall all in one. But some companies prefer specific programs for each line of security.\nAntispyware for Enterprises is a corporate antispyware solution that can centralize the antispyware monitoring among IT administrators. Businesses need a good antispyware package to ensure security. Though there may be different standard, a good antispyware should be able to do the following: scan, protect, remove and update. Real-time monitoring should be activated all the time. It should also prevent spyware attacks, remov existing spyware, and update itself to keep abreast with the developing threats.", "label": 1}
{"text": "Email scams and malicious email, sometimes called phishing, are types of electronic fraud commonly carried out through requests to gather personal information. These types of emails appear to come from reliable sources like Northwestern or your banking institution, and often contain urgent requests that require the recipient to provide personally identifiable information―passwords, credit card account numbers, and Social Security Numbers―by either replying to the email directly, or by entering this information on a bogus Web site.\nNUIT is providing you with a central location of scam emails that are received by the University. If you are unsure about the legitimacy of an email, compare it to the recent list of attempts at Northwestern. If it is not listed, immediately forward the complete message with email message headers to email@example.com.\nNorthwestern’s Phishing Net\nIn an effort to prevent email scams from reaching the University’s central email server Northwestern’s Email Defense System (EDS), powered by Symantec Messaging Gateway, blocks the majority of viruses and messages that carry malicious code from being distributed across the University community.\nOccasionally, some malicious or junk email attempts slip through this security net. NUIT recommends that all Northwestern email recipients use EDS for increased computer security, and to prevent the potential for falling victim to such attempts.\nKnow the Signs\nThe best defense against malicious email attempts is an educated user. Have a security mindset and be skeptical of any unprompted requests for personal information. Learn key identifiers of malicious emails by watching the How to Identify Phishing video below or by taking the SonicWALL Online Phishing and Spam IQ Quiz.\nRemember, Northwestern University will never ask for personally identifiable information.\nWhen you receive any email requesting personally identifiable information, follow these best practices to protect yourself and the University:\n- NEVER reply to an unsolicited email that asks for your personal information, including requests for NetID passwords, Social Security Numbers, or requests for credit card information. Remember, Northwestern University will never request personal information via email. Other institutions (your bank or credit card company) would not email you requesting this type of information either.\n- COMPARE suspicious emails to the list of recent phishing email attempts collected and posted by NUIT.\n- DON'T click on links directly from emails. Open a new browser and type the address yourself. You can also bookmark the NU Validate pages to update or verify your NetID password.\n- BE WARY of messages with suspicious, misspelled, or awkward language, or that reference non-existent Northwestern departments like \"University Webmail Support\" or the \"Webmail Messaging Center.\"\n- DELETE messages you confirm or recognize to be phishing attempts from your \"Inbox\" and your \"Deleted Items\" folder to avoid accidentally accessing the Web sites within the bogus email.\n- DO NOT send personally identifiable information, such as passwords, credit card account numbers, and Social Security Numbers, through email.\n- Regularly UPDATE and USE antivirus and anti-spyware software, and your firewall.\n- BE CAUTIOUS about opening any attachments or downloading any files from emails you receive, regardless of who sent them.\nTook the Bait? Report It!\nIf you believe you have responded to a malicious email, change your NetID password immediately and call the NUIT Support Center at 847-491-4357 (1-HELP) to report the scam.\n- Scam Email Attempts at Northwestern\n- Scam Email Attempt Archive\n- Email Defense System\n- The Federal Trade Commission\n- Anti-Phishing Working Group\n- FBI Cyber Investigations\n- The Internet Crime Complaint Center (ICCC)\n- National Consumer's League's phishinginfo.org\n- SonicWALL Online Phishing and Spam IQ Quiz\n- Information Security News Podcasts\nNUIT Support Center\nCentral service desk for students, faculty, and staff.\nSubmit a Support Request\nLast Updated: 17 May 2013", "label": 1}
{"text": "1 day ago\nWith the cars becoming more powered and connected to the internet and operated by computers, the risk of cyberattacks have arisen. The US based National Highway Traffic Safety Administration (NHTSA), believes that the interconnected electronic system is helpful in creating opportunities for vehicle safety and reliability but these systems now also pose cybersecurity threats of a very different nature. According to a report by Stuff.co.nz, a new office within the agency will research upon the vehicle electronic safety and analyze the potential cyberattack risks leading to catastrophic accidents. As cars are increasingly controlled electronically rather than manually, NHTSA will be conducting the research in bringing car technology to prevent crashes. NHTSA has prepared a testimony for a Senate Commerce Committee meeting in order to establish the new office for analyzing the possible cyber security attacks, the reports added.", "label": 1}
{"text": "By John Kamensky\nOctober 24, 2012\nHow do you organize a cross-agency collaborative effort to get results no single agency could accomplish on its own? The Government Accountability Office (GAO) has developed an inventory of “mechanisms that the federal government uses to lead and implement interagency collaboration,” along with a self-assessment checklist to consider when using them.\nGAO’s latest study on collaborative governance is based on an analysis of more than 300 past GAO reports covering issues such as homeland security, agriculture, and health, as well as a series of interviews with experts on the topic.\nGAO previously reported in 2005 on eight “key practices to enhance and sustain interagency collaboration,” including leadership, trust, and organizational culture. That report lays out how network managers should behave. But it was largely silent on the structural mechanisms for organizing such collaborative efforts. In 2010, a new law requires the Office of Management and Budget (OMB) to develop and implement cross-agency priority goals that rely on a great degree of collaboration. These more formal collaborations require mechanisms for accountability, measures of progress, and resource sharing. This spurred congressional interest in understanding more about various mechanisms that the executive branch might use.\nOMB identified 14 cross agency priority goals in the 2013 budget and has begun to implement them. These include goals such as doubling exports, which involves more than eight contributing agencies and over 40 programs within these agencies; and improving cybersecurity, which involves virtually every agency in the government. How should the executive branch best organize these agencies and programs to achieve results?\nThe new GAO report catalogs a dozen specific mechanisms the government currently uses to collaborate across boundaries, ranging from special presidential assistants to the use of social media technologies. More significantly, the report offers a self-assessment checklist (Appendix III) of seven key design features that collaborative network leaders need to consider when using these approaches. These features include:\nThe GAO report also provides concrete examples of the various collaborative mechanisms it has cataloged, ranging from the federal government’s climate change activities, to the use of working capital funds, to the federal response in 2007 to the pandemic flu scare. It also describes how some collaborative mechanisms are used for various purposes, such as policy development, program implementation, oversight, and information sharing.\nInterestingly, in a recent blog post, my colleague Dan Chenok notes that effective collaboration in networks used to implement results-oriented initiatives should rely on more than just practices and mechanisms. He says that government leaders should move beyond collaboration to “joint management.” He observes that “successful leaders in government can follow the enterprise model of the private sector, using technology and information to manage ‘jointly’ across agencies – building from collaborative networks to shared operations.”\nWhat things have you found essential for cross-agency collaboration?\n(Image via Michael D. Brown/Shutterstock.com)\nBy John Kamensky\nOctober 24, 2012", "label": 1}
{"text": "What comes to your mind when you hear the word hacker? Most of us think hackers are hacking computer security systems to steal important and confidential information. It is only partially true, since there are hackers who contribute real solutions to social problems such as corruption.\nWhen we asked participants of the global Transparency International hackathon that took place on the first weekend of October who considered themselves a hacker, many raised their hands, explaining that they did not see “hacker” as a bad word, and that their role is often misunderstood.\nOne said, “Wikileaks is a collection of hackers who disclose hidden information to the public. It helps people to have access to better information.”\nResponding to the “problem statements” presented by seven participants, our friendly hackers were extremely excited to contribute their skills to provide a technological platform that would address corruption problems. He hopes it will rectify public misperceptions about hackers.\nThe hackers know better than anyone that for social media to help fight corruption, we need to create additional applications that people can use to communicate with each other directly. Twitter has already served as a powerful communication tool has already happened in Egypt.\nTeten Masduki, secretary general of Transparency International Indonesia argues that Wikileaks developed as a form of disclosure to dismantle some of the control over information held byelites. “In Indonesia, Facebook and Twitter are a way to curb corruption,” he explained.\nTeten observes that ministries and state agencies have not provided enough information for the public. They provide very limited basic information. “This has little benefit for the community,” he said.\nSouth Asian presence in Jakarta\nProgrammers, developers, graphic and interface designers and anti-corruption activists joined us in Jakarta from South Korea, Cambodia, Fiji, Indonesia, Malaysia, Sri Lanka, and Vietnam. Participants from Indonesia also came from various areas such as Jakarta, Semarang, Batang, Yogyakarta, Bandung, Bekasi, Balikpapan and Makassar. They submitted 12 “problem statements” – challenges in our daily efforts to fight corruption that we want technology to help with:\n- TI Indonesia wanted a Corruption Court Decisions Index. This tool is expected to gauge public perception of fairness judgments of national and local level. We crave a site that shows information about the corruption proceedings, a little like our name and shame site for corruption offenders.\n- Our Malaysian colleagues wanted to enhance their Forest Watch illegal logging site where people can tag areas affected by illegal logging. Likewise, there is a clear demand for a system that can measure the performance of public institutions as well as reporting public services using photos and comments to the local council.\n- Much of the requests of Transparency International staff to the hackers related to areas they are already working in. Awareness raising is a priority for TI Sri Lanka, who regularly hold public exhibitions. TI Vietnam, whose recent study showed 30% of people facing bribes in the health sector, concentrated on the assessment of public health services.\n- An online platform for corruption reporting is also vital for TI South Korea, which the public would be able to access through smartphones, either as victims, witnesses or whistleblowers. Previously, their site has provided anti-corruption education in the form of a quiz.\n- TI Fiji wanted online campaign tools to engage youth in the fight against corruption and a platform to monitor intimidation, violence and irregularity during elections.\nThe Hackathon was held in 5 countries simultaneously. Beside Jakarta, Transparency International organised the same event in Moscow (Russia), Bogota (Columbia), Budapest (Hungary), and Vilnius (Lithuania). The activity was streamed worldwide from each location so that participants can exchange reports and share the atmosphere.\nThe above was adapted from an article written by M.A. Maulidin, Editor of klikmagz.com.", "label": 1}
{"text": "Storage area network (SAN) management is more involved than simply cabling servers and storage systems together. Storage resources must be configured, allocated, tested and maintained as new devices\nStorage resource management (SRM) applications are designed to monitor and manage physical and logical SAN resources. Physical resources include storage arrays, RAID systems, tape libraries and FC switches, while logical storage features involve file systems and application-oriented storage elements (e.g. Oracle database files). It's usually best to select one tool that can provide centralized management of the entire storage infrastructure through a single console. Ideally, a centralized SRM tool should be able to detect storage resources, evaluate their capacity and configuration, and measure their performance. The SRM tool should also be able to affect changes to the configuration and support consistent policies across the various storage technologies being managed. SAN management tools are available from EMC Corp., Symantec Corp. (Veritas), McData Corp., Hewlett-Packard Co., IBM, Sun Microsystems Inc. and CA Inc.\nIn actual practice, selecting a SAN management/SRM tool can be an extremely challenging process -- usually because each tool accomplishes its suite of tasks in a unique way. Consequently, a good management tool should offer heterogeneous support, being able to accurately detect, discover and visualize a SAN across a variety of network equipment, storage systems and operating systems. The tool should provide meaningful monitoring and reporting features, including performance measurement, and that data should provide practical information that can help an administrator identify and resolve problems within the SAN.\nThis tip originally appeared on SearchStorage.com.\nThis was first published in November 2006", "label": 1}
{"text": "E-mail (in its simplest form) is inherently insecure. There's no built-in encryption, so it's easy to snoop on people's messages as they're sent across the network, and there's no built-in validation, so it's easy to spoof a message to make it look like it came from somebody else. If you're a mischievous college student, you can exploit these vulnerabilities to read your roommate's mail, or send fake love letters from your roommate to the creepy goth chick down the hall. But if you're an actual criminal, you can exploit these vulnerabilities to commit fraud, industrial espionage, or treason. S/MIME solves these problems by providing certain cryptographic guarantees, including authentication, message integrity, and privacy.\nGuaranteeing authentication, message integrity, and privacy (and making it all easy-to-use) is actually a really hard thing to do. A search of the web for \"encrypted e-mail\" turns up solutions like this one, but these types of applications tend to suffer from the same types of problems.\n- Key Distribution: Home-grown systems tend to use a single symmetric key that all trusted parties share. But trying to let the trusted parties know what the key is results in a chicken-and-egg scenario. There's no secure channel without the secret key, so that means that you have to send the secret key to all trusted parties in an insecure way. A better system would allow you to negotiate a channel in a secure way, without having to distribute any secret information ahead of time.\n- Key Management: A single shared key creates two classes of people. If you know the key, you're trusted; if not, you're untrusted. That's a pretty coarse distinction. Here's an imaginary scenario. You have 5 friends who all have the shared key, and you're planning a surprise party for one of them. You want to send a message that can be read by everyone except the guy you're throwing the party for. A single shared key doesn't allow for that type of distinction. A better system would allow you to control which users can decrypt an encrypted message on a user-by-user basis.\n- Sender Authentication: If the secret key is shared by, say, 3 people, then you have a guarantee that if you receive an encrypted message, it came from one of those 3 people. But you don't have any assurances beyond that. If Alice, Bob, and Charlie all share a key, and Alice receives an encrypted message that seems to come from Bob, she can be sure that an untrusted person (like Dorothy) didn't spoof the message, but she can't be sure that a trusted person (like Charlie) didn't spoof it. A better system would provide for strong sender authentication to ensure that nobody can convincingly spoof a message.\n- Implementation: Home-grown systems tend to cut corners in their implementations. The above-referenced example solution is password-based, which almost certainly means that the derived encryption keys won't actually be as strong as they should be (most passwords don't have anywhere near the strength of a 128-bit encryption key), and it handles initialization vectors poorly. Whenever possible, it's better to use security protocols that were designed by people who actually know what they're doing, rather than growing your own.\nS/MIME is designed to solve all of these problems. It's a well-defined standard (RFC 2633), and it's implemented in all the major mail clients (although I only tested Outlook, Outlook Express, and Mozilla Thunderbird). It is not, however, natively supported by .NET. That's where this library comes in.\nI'm going to assume that you already know something about public-key cryptography in general, and about S/MIME in particular. I'm also going to assume that you already have a signing certificate for yourself (complete with private key), and the encryption certificates of anybody you want to send encrypted mail to (without the private key, of course). If you and your friends don't already have certificates, they're pretty easy to come by. I got my personal signing/encryption certificate from Verisign (at about $20/year, they're pretty cheap).\nUsing the Code\nThe object model was designed to resemble the\nSystem.Net.Mail classes pretty closely, so you should find it to be pretty intuitive. The primary differences just involve certificate handling.\nIf you're going to send a signed message, you need to create a\nSecureMailAddress that has a signing cert associated with it. Your cert will either be in the certificate store, or it'll be in a file (like a .pfx file). If you're reading the certificate out of a file, the code to create a\nSecureMailAddress for the sender will look something like this:\nX509Certificate2 myCert =\nnew X509Certificate2(@\"c:\\certs\\myCert.pfx\", \"SomeSecretPassword\");\nReading a certificate out of the cert store is a bit more work, so I've included a helper method to do it for you. Just specify the serial number, and it'll retrieve the certificate from your local store.\nX509Certificate2 myCertFromStore = CryptoHelper.FindCertificate(\"1B37D3\");\nOnce you've loaded your certificates, you need to attach them to a\nSecureMailAddress, like this:\nSecureMailAddress senderAddress = new SecureMailAddress\n(\"email@example.com\", \"Alice\", aliceEncryptionCert, aliceSigningCert);\nSecureMailAddress recipientAddress = new SecureMailAddress\n(\"firstname.lastname@example.org\", \"Bob\", bobEncryptionCert);\nNotice that we specified a signing cert for the sender, but we only need one if we're planning on sending a signed message. For all the recipients, we only need the encryption certs. Also note that we need to specify the sender's encryption cert when we send an encrypted message, in addition to each of the recipients' encryption certs. If we didn't, then the sender wouldn't be able to read his own message, even though he's the one who sent it.\nSecureMailMessage class supports most of the stuff that the regular\nSystem.Net.Mail.MailMessage class can do. You can CC and Bcc recipients, set a ReplyTo address, send attachments, and send HTML mail. Here's a full example which demonstrates, front-to-back, how to send a signed and encrypted message.\nSecureMailMessage message = new SecureMailMessage();\nX509Certificate2 signingCert = CryptoHelper.FindCertificate(\"1B37D3\");\nX509Certificate2 encryptionCert = CryptoHelper.FindCertificate(\"22C590\");\nX509Certificate2 recipientCert = new X509Certificate2(@\"c:\\certs\\bob.cer\");\nmessage.From = new SecureMailAddress\n(\"email@example.com\", \"Alice\", encryptionCert, signingCert);\n(\"firstname.lastname@example.org\", \"Bob\", recipientCert));\nmessage.Subject = \"This is a signed and encrypted message\";\nmessage.Body = \"<h2>Sent from the Cpi.Net.SecureMail library!</h2>\";\nmessage.IsBodyHtml = true;\nmessage.IsSigned = true;\nmessage.IsEncrypted = true;\nSystem.Net.Mail.SmtpClient client =\nnew System.Net.Mail.SmtpClient(\"mymailserver\", 25);\nclient.Credentials = new NetworkCredential(\"YourSmtpUserName\", \"YourSmtpPassword\");\nNotice that you can use the regular\nSystem.Net.Mail.SmtpClient class to send the message. That's because the\nSecureMailMessage class has an implicit casting operator which turns it into a\n- This library signs, encrypts, and formats the message in accordance with RFC 2633, but it's important to note that I didn't personally implement the actual cryptographic stuff involved in the signing and encryption. (I'm not qualified to implement cryptographic algorithms securely. Neither are you, in all likelihood. Don't try it.) The cryptographic stuff is handled by the classes in the\nSystem.Security.Cryptography.Pkcs namespace, which was introduced in .NET 2.0. Thanks, Microsoft, for doing a lot of the heavy lifting here.\n- The library is, to the best of my knowledge, a compliant implementation of RFC 2633, but it isn't a complete implementation. It implements all of the MUSTs in the RFC, but not all of the SHOULDs. This means that any compliant mail client should be able to read the messages that this library sends. (It's been tested in Outlook, Outlook Express, and Mozilla Thunderbird.)\n- I built this library partially by reading the appropriate specifications, and partially by setting up a homegrown TCP proxy and snooping on the traffic that existing mail clients send. (The TCP proxy isn't ready for prime-time, but it'll probably make an appearance in a future article.) There are some places in the spec that allow certain freedoms to individual implementations (such as whether to sign first, then encrypt, or encrypt first, then sign. The spec allows arbitrarily nested layers of signing and encryption.) In these cases, I just copied what the existing implementations do. (In this particular case, sign first, then encrypt.)\n- One of the constructors for\nSecureMailMessage accepts both a signing certificate and an encryption certificate. It's possible that you have a single certificate that you use for both signing and encryption. (That's how my personal certificate works.) The reason that they're separated into two separate parameters is because some organizations (like my workplace) issue separate certificates for signing and encryption. That way, the organization can keep a backup of your encryption certificate (so they can read your mail if you quit, or die, or if they just feel like it), but they don't keep a backup of your signing certificate (because if they did, then a malicious sysadmin could still send mail signed as you, which defeats the whole purpose of cryptographic signatures). If you have separate certificates for signing and encryption, then supply both of them to the corresponding\nSecureMailAddress constructor parameters. If you only have one, though, just supply it as both the signing cert and the encryption cert.\n- This is a pretty serious topic, and is closely related to the type of stuff I do professionally, so I've treated it a bit more seriously than some of my previous articles, which were just for fun. (There are, for example, no toy airplanes or dead fish.) Sorry about that.\n- Whenever you talk about cryptography, there's a standard set of imaginary users that you reference (Alice, Bob, Charlie, etc.) in your examples. I'll admit that I sometimes feel closer to these imaginary people than I do to my own friends and co-workers. (Except for Mallory, of course...I hate her so much!)\n- August 23, 2009 - Initial posting\n- February 19, 2010 - Fixed a bug which prevented non-ASCII characters from being encoded correctly in encrypted e-mail\n- March 12, 2010 - Fixed a bug which caused a\nNullReferenceException if you sent a message with an empty body\n- July 14, 2010 - Fixed a bug which caused certain messages to become corrupted if any lines start with a period. Stupid SMTP protocol...", "label": 1}
{"text": "Kids and Computer Security\nThe security of your computer can affect the safety of your online experience — and your kids’. Talk to your kids about what they can do to help protect your computer and your family’s personal information.\nTalk to your kids about:\n- protecting their personal information. Social Security numbers, account numbers, and passwords are examples of information to keep private.\n- Watching out for \"free\" stuff. Free games, ring tones, or other downloads can hide malware. Tell your kids not to download anything unless they trust the source and they've scanned it with security software.\n- Using strong email passwords and protect them. The longer the password, the harder it is to crack. Personal information, your login name, common words, or adjacent keys on the keyboard are not safe passwords. Kids can protect their passwords by not sharing them with anyone, including their friends.\nIn addition, be sure your family computers are protected by reputable security software and use these basic computer security practices.\nSome kids share music, games, or software online. Peer-to-peer (P2P) file-sharing allows people to share these kinds of files through an informal network of computers running the same software. P2P file-sharing has risks:\n- You could accidentally provide many people with access to your private files.\n- If your kids download copyrighted material, you could get mired in legal issues.\n- A shared file could hide spyware, malware, or pornography.\nHere are some tips to help your kids share files safely:\n- Install file-sharing software properly. Activate the proper settings so that nothing private is shared.\n- Before your kids open or play any file they’ve downloaded, advise them to use security software to scan it. Make sure the security software is up-to-date and running when the computer is connected to the internet.\nFor more tips, read P2P File-Sharing Risks.\nPhishing is when scam artists send fake text, email, or pop-up messages to get people to share their personal and financial information. Criminals use the information to commit identity theft.\nHere are tips you can share with your kids to help them avoid a phishing scam:\n- Don't reply to text, email, or pop-up messages that ask for personal or financial information, and don't follow any links in the message.\n- Be cautious about opening any attachment or downloading any files from emails you receive, regardless of who sent them. Unexpected files may contain malware.\nGet your kids involved, so they can develop their scam “antennas” and careful internet habits. Look for \"teachable moments\" — if you get a phishing message, show it to your kids. A demonstration can help them recognize a potential phishing scam and help them understand that messages on the internet aren't always what they seem. Learn more about Phishing.", "label": 1}
{"text": "OpenVMS User's Manual\n1.3.2 Changing Your Initial Password\nLog in to your account soon after it is created to change your\npassword. If there is a time lapse from the moment your account is\ncreated until your first login, other users might log in to your\naccount successfully, gaining a chance to damage the system. Similarly,\nif you neglect to change the password or are unable to do so, the\nsystem remains vulnerable. Possible damage depends largely on what\nother security measures are in effect. See Section 1.7 for more\ninformation on changing passwords.\n1.3.3 Restrictions on Passwords\nThe system screens passwords for acceptability, as follows:\n- It automatically compares new passwords to a system dictionary.\nThis helps to ensure that a password is not a native language word.\n- It maintains a history list of your old passwords and compares each\nnew password to this list to be sure that you do not reuse a password.\n- It enforces a minimum password length, which the system manager\nspecifies in your UAF record.\nThe system rejects any passwords that it finds in a system dictionary,\nthat you have used before, and that are shorter than the minimum\npassword length specified in your UAF.\n1.3.4 Types of Passwords\nThere are several types of passwords recognized by the OpenVMS\n- User password\nRequired for most accounts. After entering your user name, you are\nprompted for a password. If the account requires both primary and\nsecondary passwords, two passwords must be entered.\n- System password\nControls access to particular terminals and is required at the\ndiscretion of the security administrator. System passwords are usually\nnecessary to control access to terminals that might be targets for\nunauthorized use, such as dialup and public terminal lines.\n- Primary password\nThe first of two passwords to be entered for an account requiring\nboth primary and secondary passwords.\n- Secondary password\nThe second of two passwords to be entered for an account requiring\nboth primary and secondary passwords. The secondary password provides\nan additional level of security on user accounts.\nTypically, the primary user does not know the secondary password; a\nsupervisor or other key person must be present to supply it. For\ncertain applications, the supervisor may also decide to remain present\nwhile the account is in use. Thus, secondary passwords facilitate\ncontrolled logins and the actions taken after a login.\nSecondary passwords can be time-consuming and inconvenient. They\nare justified only at sites with maximum security requirements. An\nexample of an account that justifies dual passwords would be one that\nbypasses normal access controls to permit emergency repair to a\n1.3.5 Entering a System Password\nYour security administrator will tell you if you must specify a system\npassword to log in to one or more of the terminals designated for your\nuse. Ask your security administrator for the current system password,\nhow often it changes, and how to obtain the new system password when it\nTo specify a system password, do the following:\nPress the Enter key until the terminal responds with the recognition\ncharacter, which is commonly a bell.\nType the system password and press Enter. There is no prompt and the\nsystem does not display the characters you type. If you fail to specify\nthe correct system password, the system does not notify you.\n(Initially, you might think the system is malfunctioning unless you\nknow that a system password is required at that terminal.) If you do\nnot receive a response from the system, assume that you have entered\nthe wrong password and try again.\nWhen you enter the correct system password, you receive the system\nannouncement message, if there is one, followed by the Username:\nprompt. For example:\nMAPLE - A member of the Forest Cluster\nUnauthorized Access is Prohibited\n1.3.6 Entering a Secondary Password\nYour security administrator decides whether to require the use of\nsecondary passwords for your account at the time your account is\ncreated. When your account requires primary and secondary passwords,\nyou need two passwords to log in. Minimum password length, which the\nsecurity administrator specifies in your UAF, applies to both passwords.\nAs with a single password login, the system allots a limited amount of\ntime for the entire login. If you do not enter a secondary password in\ntime, the login period expires.\nThe following example shows a login that requires primary and secondary\nWILLOW - A member of the Forest Cluster\nWelcome to OpenVMS on node WILLOW\nLast interactive login on Friday, 11-DEC-2002 10:22\n1.3.7 Password Requirements for Different Types of Accounts\nFour types of user accounts are available on OpenVMS systems:\n- Accounts secured with passwords that you or the security\nadministrator change periodically. This account type is the most common.\n- Accounts that always require passwords but prohibit you from\nchanging the password. By locking the password (setting the LOCKPWD\nflag in the UAF), the security administrator controls all changes made\nto the password.\n- Restricted accounts limit your use of the system\nand sometimes require a password.\nOpen accounts require no password. When you log in to\nan open account, the system does not prompt you for a password and you\ndo not need to enter one. You can begin entering commands immediately.\nBecause open accounts allow anyone to gain access to the system, they\nare used only at sites with minimal security requirements.\n1.4 Reading Informational Messages\nWhen you log in from a terminal that is directly connected to a\ncomputer, the OpenVMS system displays informational system messages, as\nshown in the following example.\nWILLOW - A member of the Forest Cluster (1)\nUnlawful Access is Prohibited\nYou have the following disconnected process: (2)\nTerminal Process name Image name\nVT320: RWOODS (none)\nConnect to above listed process [YES]: NO\nWelcome to OpenVMS on node WILLOW (3)\nLast interactive login on Wednesday, 11-DEC-2002 10:20 (4)\nLast non-interactive login on Monday, 30-NOV-2002 17:39 (5)\n2 failures since last successful login (6)\nYou have 1 new mail message. (7)\nNote the following about the example:\nThe announcement message identifies the node (and, if relevant, the\nOpenVMS Cluster name). It may also warn unauthorized users that\nunlawful access is prohibited. The system manager or security\nadministrator can control both the appearance and the content of this\nA disconnected process message informs you that your process was\ndisconnected at some time after your last successful login but is still\navailable. You have the option of reconnecting to the old process, in\nthe state it was in before you were disconnected.\ndisplays the disconnected message only when the following conditions\n- The terminal where the interruption occurred is set up as a virtual\n- Your terminal is set up as one that can be disconnected.\n- During a recent session, your connection to the central processing\nunit (CPU) through that terminal was broken before you logged out.\nIn general, the security administrator should allow you to reconnect\nbecause this ability poses no special problems for system security.\nHowever, the security administrator can disable this function by\nchanging the setup on terminals and by disabling virtual terminals on\nthe system. (For information on setting up and reconnecting to virtual\nterminals, refer to the OpenVMS System Manager's Manual.)\n- A welcome message indicates the version number\nof the OpenVMS operating system that is running and the name of the\nnode on which you are logged in. The system manager can choose a\ndifferent message or can suppress the message entirely.\n- The last successful interactive login message\nprovides the time of the last completed login for a local, dialup, or\nremote login. (The system does not count logins from a subprocess whose\nparent was one of these types.)\n- The last successful noninteractive login\nmessage provides the time the last noninteractive (batch or network)\nThe number of login failure messages indicates the number of failed\nattempts at login. (An incorrect password is the only source of login\nfailure that is counted.) To attract your attention, a bell rings after\nthe message appears.\n- The new mail message indicates if you have any\nunread mail messages.\n1.4.1 Suppressing Messages\nA security administrator can suppress the announcement and welcome\nmessages, which include node names and operating system identification.\nBecause login procedures differ according to operating system, it is\nmore difficult to log in without this information.\nThe last login success and failure messages are optional. Your security\nadministrator can enable or disable them as a group. Sites with\nmedium-level or high-level security needs display these messages\nbecause they can indicate break-in attempts. In addition, by showing\nthat the system is monitoring logins, these messages can be a deterrent\nto potential illegal users.\n1.4.2 Successful Login Messages\nEach time you log in, the system resets the values for the last\nsuccessful login and the number of login failures. If you access your\naccount interactively and do not specify an incorrect password in your\nlogin attempts, you may not see the last successful noninteractive\nlogin and login failure messages.\n1.5 Types of Logins and Login Classes\nLogins can be either interactive or noninteractive. When you log in\ninteractively, you enter a user name and a password. In noninteractive\nlogins, the system performs the identification and authentication for\nyou; you are not prompted for a user name and password.\nIn addition to interactive and noninteractive logins, the OpenVMS\noperating system recognizes different classes of logins. How you log in\nto the system determines the login class to which you\nbelong. Based on your login class, as well as the time of day or day of\nthe week, the system manager controls your access to the system.\n1.5.1 Interactive Logins\nInteractive logins include the following login classes:\nYou log in from a terminal connected directly to the central\nprocessor or from a terminal server that communicates directly with the\nYou log in to a terminal that uses a modem and a telephone line to\nmake a connection to the computer system. Depending on the terminal\nthat your system uses, you might need to execute a few additional steps\ninitially. Your site security administrator can give you the necessary\nYou log in to a node over the network by entering the DCL command\nSET HOST. For example, to access the remote node HUBBUB, you enter the\nIf you have access to an account on node HUBBUB, you can log in to\nthat account from your local node. You have access to the facilities on\nnode HUBBUB, but you remain physically connected to your local node.\nFor additional information on remote sessions, see Section 1.12.2.\n1.5.2 Noninteractive Logins\nNoninteractive logins include the following:\n- Network Logins\nThe system performs a network login when you initiate a network\ntask on a remote node, such as displaying the contents of a directory\nor copying files stored in a directory on another node. Both your\ncurrent system and the remote system must be nodes in the same network.\nIn the file specification, you identify the target node and provide an\naccess control string, which includes your user name and password for\nthe remote node.\nFor example, a network login occurs when user\nGREG, who has an account on remote node PARIS, enters the following\n$ DIRECTORY PARIS\"GREG 8G4FR93A\"::WORK2:[PUBLIC]*.*;*\nThis command displays a listing of all the files in the public\ndirectory on disk WORK2. It also reveals the password 8G4FR93A. A more\nsecure way to perform the same task would be to use a proxy account on\nnode PARIS. For an example of a proxy login, see\n- Batch Logins\nThe system performs a batch login when a batch job that you\nsubmitted runs. Authorization to build the job is\ndetermined at the time the job is submitted. When the system prepares\nto execute the job, the job controller creates a noninteractive process\nthat logs in to your account. No password is required when the job logs\n1.6 Login Failures\nLogins can fail for any number of reasons. One of your passwords might\nhave changed or your account might have expired. You might be\nattempting to log in over the network or from a modem but be\nunauthorized to do so. The following table summarizes common reasons\nfor login failure:\nNo response from the terminal\nA defective terminal, a terminal that requires a system password, or a\nterminal that is not powered on.\nNo response from any terminal\nThe system is down.\nNo response from the terminal when you enter the system password\nThe system password changed.\n\"User authorization failure\"\nA typing error in your user name or password.\nThe account or password expired.\n\"Not authorized to log in from this source\"\nYour particular class of login (local, dialup, remote, interactive,\nbatch, or network) is prohibited.\n\"Not authorized to log in at this time\"\nYou do not have access to log in during this hour or this day of the\n\"User authorization failure\" (and no known user failure occurred)\nAn apparent break-in has been attempted at the terminal using your user\nname, and the system has temporarily disabled all logins at that\nterminal by your user name.\nThe following sections describe the reasons for login failure in more\n1.6.1 Terminals That Require System Passwords\nYou cannot log in if the terminal you attempt to use requires a system\npassword and you are unaware of the requirement. All attempts at\nlogging in fail until you enter the system password.\nIf you know the system password, perform the steps described in\nSection 1.3.5. If your attempts fail, it is possible that the system\npassword has been changed. If you do not know the system password and\nyou suspect that this is the problem, try to log in at another terminal\nor request the new system password.\n1.6.2 Login Class Restrictions\nIf you attempt a class of login that is prohibited in your UAF record,\nyour login will fail. For example, your security administrator can\nrestrict you from logging in over the network. If you attempt a network\nlogin, you receive a message telling you that you are not authorized to\nlog in from this source.\nYour security administrator can restrict your logins to include or\nexclude any of the following classes: local, remote, dialup, batch, or\n1.6.3 Shift Restrictions\nAnother cause of login difficulty is failure to observe your shift\nrestrictions. A system manager or security administrator can control\naccess to the system based on the time of day or the day of the week.\nThese restrictions are imposed on classes of logins. The security\nadministrator can apply the same work-time restrictions to all classes\nof logins or choose to place different restrictions on different login\nIf you attempt a login during a time prohibited for that login class,\nyour login fails. The system notifies you that you are not authorized\nto log in at this time.\n1.6.4 Batch Jobs During Shift Restrictions\nWhen shift restrictions apply to batch jobs, jobs you submit that are\nscheduled to run outside your permitted work times are not run. The\nsystem does not automatically resubmit such jobs during your next\navailable permitted work time. Similarly, if you have initiated any\nkind of job and attempt to run it beyond your permitted time periods,\nthe job controller aborts the uncompleted job when the end of your\nallocated work shift is reached. This job termination behavior applies\nto all jobs.\n1.6.5 Failures During Dialup Logins\nYour security administrator can control the number of opportunities you\nare given to enter a correct password during a dialup login before the\nconnection is automatically broken.\nIf your login fails and you have attempts remaining, press the Enter\nkey and try again. You can do this until you succeed or reach the\nlimit. If the connection is lost, you can redial the access line and\nThe typical reason for limiting the number of dialup login failures is\nto discourage unauthorized users attempting to learn passwords by trial\nand error. They already have the advantage of anonymity because of the\ndialup line. Of course, limiting the number of tries for each dialup\ndoes not necessarily stop this kind of break-in attempt. It only\nrequires the perpetrator to redial and start another login.\n1.6.6 Break-In Evasion Procedures\nIf anyone has made a number of failed attempts to log in at the same\nterminal with your user name, the system can respond as though a\nbreak-in attempt is in progress. That is, the system\nconcludes that someone is attempting to gain illegal access to the\nsystem by using your user name.\nAt the discretion of your security administrator, break-in evasion\nmeasures can be in effect for all users of the system. The security\nadministrator controls how many password attempts are allowed over what\nperiod of time. Once break-in evasion tactics are triggered, you cannot\nlog in to the terminal---even with your correct password---during a\ndefined interval. Your security administrator can tell you how long you\nmust wait before reattempting the login, or you can move to another\nterminal to attempt a login.\nIf you suspect that break-in evasion is preventing your login and you\nhave not personally experienced any login failures, contact your\nsecurity administrator immediately. Together, you should attempt\nanother login and check the message that reveals the number of login\nfailures since the last login to confirm or deny your suspicion of\nbreak-in attempts. (If your system does not normally display the login\nmessage, your security administrator can use the Authorize utility\n(AUTHORIZE) to examine the data in your UAF record.) With prompt\naction, your security administrator can locate someone attempting\nlogins at another terminal.\n1.7 Changing Passwords\nChanging passwords on a regular basis promotes system security. To\nchange your password, enter the DCL command SET PASSWORD.\nThe system manager can allow you to select a password on your own or\ncan require that you use the automatic password generator when you\nchange your password. If you select your own password, note that the\npassword must follow system restrictions on length and acceptability\n(see Section 1.3.3).\nThere is no restriction on how many times you can change your password\nin a given period of time.\nThe following example shows a password choice that is too short:\n$ SET PASSWORD\n%SET-F-INVPWDLEN, password length must be between 12 and 32\ncharacters; password not changed", "label": 1}
{"text": "Preliminary Report Shows \"Cloud\" Computing Technology Should Make Sharing Medical Images Easier and More Efficient\nMount Sinai was the first site to go live in August 2011 and currently has about 190 patients enrolled in project.\nPatients find \"cloud\" technology a faster, more efficient way to store and distribute their medical images than current options, according to the preliminary findings of an image sharing project led by The Mount Sinai Medical Center in conjunction with four other academic medical institutions. The Phase I results of the Radiological Society of North America (RSNA) Image Share project are being presented today at the American Roentgen Ray Society Annual Meeting in Vancouver, Canada.\nMount Sinai was the first site to go live in August 2011 and currently has about 190 patients enrolled in project. A total of about 600 patients are participating in all sites, which also include University of California - San Francisco, University of Chicago Medical Center, Mayo Clinic, and the University of Maryland Medical Center in Baltimore.\n\"Cloud\" computing involves using a network of remote servers hosted on the Internet to store, manage, and process data, rather than a local server or a personal computer.\n\"This is the next revolution in digital imaging,\" said David Mendelson, MD, FACR, Chief of Clinical Informatics at The Mount Sinai Medical Center and Chief Clinical Investigator for RSNA Image Share. \"It gives the patient ownership over their records and makes the information more accessible to physicians. Plus it decreases unnecessary radiation exposure that can be caused by physicians ordering duplicate examinations due to records not being easily available.\"\nTo use RSNA Image Share, patients create an account and password and then are given access to import their images and reports into the personal health record account. For patient confidentiality and security reasons, when the information leaves the server at each local radiology site and goes outside a hospital's firewall, it remains encrypted until it arrives in the patient’s account, where it's unencrypted so the patient can see it.\n\"We're dealing with sensitive health information, so creating a secure and confidential system is of the utmost importance,\" said Dr. Mendelson. \"But if you look at online banking or shopping, which both transport sensitive financial information; we know creating a secure, widely used system is an attainable goal.\"\nIn phase two of the trial, patients will be allowed to share their images without the images first being uploaded to an Internet-based personal health record. This should be useful in the event of severe acute trauma, with transfer to a trauma center. In phase three, the data will be de-identified and then made available for clinical trials.\nThe RSNA Image Share project was funded by the National Institute of Biomedical Imaging and Bioengineering at NIH.\nAbout The Mount Sinai Medical Center\nThe Mount Sinai Medical Center encompasses both The Mount Sinai Hospital and Mount Sinai School of Medicine. Established in 1968, Mount Sinai School of Medicine is one of the leading medical schools in the United States. The Medical School is noted for innovation in education, biomedical research, clinical care delivery, and local and global community service. It has more than 3,400 faculty in 32 departments and 14 research institutes, and ranks among the top 20 medical schools both in National Institutes of Health (NIH) funding and by U.S. News & World Report.\nThe Mount Sinai Hospital, founded in 1852, is a 1,171-bed tertiary- and quaternary-care teaching facility and one of the nation’s oldest, largest and most-respected voluntary hospitals. In 2011, U.S. News & World Report ranked The Mount Sinai Hospital 16th on its elite Honor Roll of the nation’s top hospitals based on reputation, safety, and other patient-care factors. Of the top 20 hospitals in the United States, Mount Sinai is one of 12 integrated academic medical centers whose medical school ranks among the top 20 in NIH funding and U.S. News & World Report and whose hospital is on the U.S. News & World Report Honor Roll. Nearly 60,000 people were treated at Mount Sinai as inpatients last year, and approximately 560,000 outpatient visits took place.\nFor more information, visit http://www.mountsinai.org/.", "label": 1}
{"text": "3.1 Data Theft?\nData theft occurs when a fraudster steals identifying information--names, addresses, financial data--from an unsuspecting victim and sells the information or uses it for personal gain. Keyloggers can skim Web users' e-mail addresses and passwords by using software that surreptitiously captures the keystrokes they type, for example. Phishing scams use bogus e-mails and Web sites that seem legitimate but are actually designed to trick users into revealing personal and financial information. Computer criminals can then use the data to spy on or blackmail users, hijack their online accounts (including bank accounts), spread rumors, or operate under the victim's identity.\nAlthough minors don't risk as much financial loss as adults, they are in danger of exposure to interlopers aiming to hijack or share their online identity. Children are especially vulnerable because they're often unable to identify and report data-snatching malware, and because they tend to be less cautious about sharing sensitive information with strangers and friends.\n- Long, hard-to-guess passwords that include a mix of numbers, letters, and characters\n- Do not disclose passwords to friends and strangers\n- Know how to identify malicious software\nMalicious software--or malware--is the umbrella term for unsolicited software intended to annoy, destroy, or exploit. The category includes malicious adware, viruses, keylogging software, and backdoor Trojan programs, which allow attackers unauthorized access to and control over a user's computer. Malicious software often loads through infected links and downloads when users click on ads or buttons designed to launch the programs. The links and buttons may be presented to an intended victim via phishing e-mail or on a malicious Web site. Malware can sometimes load invisibly and, in a worst-case scenario, allow others to control your computer. It's a good idea to become familiar with security terms and what danger each security threat poses.\nKids often value \"free\" over \"safe\". Young surfers involved in link-sharing and file-sharing among peers are at higher risk of downloading infected programs. Malware distributors know kids seek out free software, music, and \"cracks\" (serial numbers) for pirating commercial games; they also know these same kids often trust links and e-mail attachments far more than they should.\n- Teach kids to be extremely cautious when opening downloads or links from friends and strangers\n- Never click ads or answer unsolicited e-mails\n- Teach kids to refrain from automatically clicking \"yes\" buttons anywhere on the screen--read all text carefully\n- Download legitimate software only, and only from trusted sites. Software is available that can help spot the bogus software offers\n- Kids should immediately report anything suspicious to an adult\n3.3 Inappropriate Content\nWhat's inappropriate for a minor? That's largely a matter of common sense and, depending on the age of their child, varies from parent to parent. Some countries ban adult content for all users, while in the U.S. school libraries receiving federal funds are obliged to block online access to such content.\nRisk and defense\nEven if a minor isn't looking for adult or violent material online, it's sometimes easy to stumble across it simply by following search-engine or instant-message links.\nScammers, meanwhile, often use pornographic pop-ups to lure users into clicking links that load malicious software. Parents often rely on content-blocking and filtering software to limit what kids can see, but be forewarned that older kids with computer skills are often adept at working around such controls.\nIt's frightening and hurtful when bullies taunt and deride their peers at the schoolyard. It can be even more damaging when it happens online. Cyberbullying includes threats, gossip, and insults that are spread via e-mail and IM, broadcast on social networking sites, planted in forums, and distributed through community-oriented online games.\nRisk and defense\nSadly, there's no easy way to protect children from determined bullies, online or offline. The best defense is early detection (does your child become anxious when going online or answering the cell phone?) and knowing your options. For example, Roland Park Country School, a K-12 school for girls in Baltimore, cites examples of cyberbullying (\"A girl gets e-mail every day after school from an anonymous person who calls her the fattest, stupidest, ugliest girl who ever lived\") and offers good advice on what to do if the harassment escalates. Specific tips also are available through the About.com Web portal.\n- Emphasize that kids should talk to an adult if they become victims of bullying\n- Save the evidence\n- Report incidents to your Internet service provider, e-mail provider, or Web site host. If the incidents begin occurring offline, report the encounters to the bully's parents or to school officials\nEvery parent's worst Web nightmare, online predators are most commonly adults who use various techniques to establish a close relationship with young Web users.\nPredators typically pose as young people and take their time befriending minors, gathering personal information and other clues in the virtual world so they can lure, blackmail, abuse or kidnap their targets in the real world.\nYoung \"netizens\" become susceptible to predators when they chat online with strangers and make photos and personal details publicly accessible. Predators use clues about their vulnerabilities and whereabouts to get emotionally and physically close.\nNumerous organizations provide tips for keeping kids aware of and away from suspicious online strangers. Guidelines include staying private online and using parental control software. Just as important, parents should discuss the tactics and dangers posed by online predators openly and honestly with kids and teens.\n- What is Yahoo!?\n- Facebook Facts\n- Facebook Finally Makes Money\n- Facebook & Your Privacy\n- What is Google?\n- Google Pagerank Facts\n- Google's Quantum Algorithm\n- Internet Addiction Facts\n- MySpace Facts\n- What made Amazon.com so Big?\n- Twitter Facts\n- 10 signs of Twitter Addiction\n- What are Cookies?\n- What's a Browser?\n- What is Surfing the Net?\n- What is Phishing?\n- What's Spam?\n- What's Malware?\n- What's an Internet Virus?\n- What's a Trojan Horse?\n- What are Blended Threats?\n- What's the best way to protect your computer from Viruses, Worms and Trojan Horses?\n- What's Spyware?\n- What's Adware?\n- What is Rogue Anti-virus Software?\n- What is a Temporary Internet File?\n- What are LANs, WANs & ISPs?\n- What's a Protocol?\n- What are Routers & Modems?\n- What is Affiliate Marketing?\n- What's a Server?\n- What are Software and Hardware?\n- Set up your Profile\n- Follow People with Similar Interests\n- Get into the Conversation\n- Don't Spam\n- Update Daily\n- Find the Biggest Buzz and Contribute\n- Help other People out\n- Create Relationships\n- Integrate Twitter with other Social Networks\n- Establish Relationships even outside Twitter\n- The History of EBay\n- The History of Amazon.com\n- The History of Facebook\n- The History of Twitter\n- The History of Google\n- The History of Yahoo!\n- The History of Wikipedia", "label": 1}
{"text": "Read Part 2 of this article.\nSince the turn of the century, wireless networking has grown from a very exclusive tech toy into a full-blown phenomenon. For less than $50, anyone who can plug in a toaster can essentially set up a wireless local area network (WLAN). The problem with this plug-and-play generation of users is that very few understand how their data is sent through the air, much less comprehend the associated risks. Even as I write this, an estimated 40–50% of all wireless users are not implementing any form of protection. On the bright side, this percentage is falling, albeit very slowly.\nThe security problem is exacerbated by the fact that early attempts at encryption were flawed. Wired Equivalent Privacy (WEP) was found to be vulnerable to various statistical weaknesses in the encryption algorithm it employed to scramble data passed over the WLAN. While attempts were made to correct the problem, it's still a relatively simple feat to crack WEP and essentially pull the password right out of the air. In addition, WEP suffers from other problems that make it unacceptable for use in any secure environment.\nThe wireless community knew early on that these problems existed. However, they also realized that it would take years until the standardized correction was designed and implemented into new hardware. In the meantime, millions of users needed reliable protection. The Wi-Fi Alliance stepped up to the challenge and created an interim \"standard\" called Wi-Fi Protected Access (WPA).\nWPA did an excellent job of patching the problems in WEP. With only a software upgrade, it corrected almost every security problem either created or ignored by WEP. However, WPA also created new problems:\n- One flaw allowed an attacker to cause a denial-of-service attack, if the attacker could bypass several other layers of protection.\n- A second flaw exists in the method with which WPA initializes its encryption scheme. Consequently, it's actually easier to crack WPA than it is to crack WEP. This flaw is the subject of this article.", "label": 1}
{"text": "What is IP VPN\nA Virtual Private Network ( VPN) delivers private network services over a public infrastructure. An IP VPN is a partitioned private network constructed over a shared IP-based backbone that utilizes technologies to ensure privacy of data. They offer enterprise-class scalability and reachability across multiple IP-based infrastructures, along with many of the performance and security characteristics traditionally found only in dedicated private environments.\nMPLS (Multi Protocol Label Switching) technology based VPNs combines the intelligence of private IP routing with the added performance of label switching to move packets between any location on the network. With only one access link to the MPLS \"cloud\" from each of your locations, full mesh connectivity will improve your network scalability, reliability, and internal network application performance.\nMPLS also provides a greater degree of security for voice and other types of business traffic since each VPN is a virtually separated network infrastructure over the SLT's MPLS IP Backbone.\nSLT IP VPN gives you choices in your network design of sophisticated VPN technologies, access, security and voice, with the flexibility to add on options such as remote access and hosting in IDC (Internet Data Centre).", "label": 1}
{"text": "What Is Identity Theft, Anyway?\nJerome Powell remembers being irritated with himself for not paying closer attention to his driving. When the Mountain View, Colorado, police car’s blue lights came on behind him, Powell, a government contractor, had just driven through a yellow light as it turned red. Now he would be late for his next appointment. He apologized to the officer and handed over his driver’s license and insurance information. He watched in his rearview mirror as the officer radioed from his cruiser for a license check.\nIt seemed to be taking a long time to write a routine ticket. Finally, the officer approached Powell’s window and told him to get out of the car. Powell was stunned to find himself under arrest on two outstanding felony warrants. He was shocked and humiliated as the officer made him put his hands behind his back and then cuffed him and read him his Miranda rights. The Navy veteran spent hours in jail, shaking from fear that he might wind up charged with a crime he didn’t commit.\nThe warrants for his arrest were issued in 2003, when a thief used Powell’s driver’s license to buy more than $10,000 in computer equipment and other items. Despite overwhelming evidence that it was a case of identity theft—the stolen goods were delivered to the apartment of a career criminal who bore no resemblance at all to Powell—he was forced to spend several thousand dollars to post bond and get a lawyer to clear his name.\nJerome Powell’s unnerving and expensive experience is a true case of identity theft—the thief used Powell’s driver’s license to impersonate Powell. Not to be picky about it, but what the media and most people call “identity theft” is actually an umbrella term for two different crimes: identity theft and identity fraud. As in Powell’s case, identity theft occurs when criminals steal personal information and use it to impersonate the victim. An illegal immigrant using a stolen Social Security card to get a job is a good example of such an impersonation, as is a driver who has lost his or her license because of multiple convictions for driving while intoxicated and buys a fake driver’s license from an underground dealer containing the name and information of an identity-theft victim. True identity theft accounts for about a third of the 685,000 identity crime complaints reported to the Federal Trade Commission in 2005.\nFar more common is identity fraud. It happens when thieves obtain a victim’s sensitive personal information to steal money from bank accounts, buy goods and services with existing credit-card accounts or use the data to open new credit lines. The shocking thing is that these types of criminals are frequently people we know. Such betrayals by family or close friends are emotionally draining and almost certainly underreported since victims often find it difficult to report the crime or feel pressured by family members to keep the theft quiet.\nNot Abigail Kelly. Abigail had given her Social Security number to her sister Delia after Delia said she was going to make Abigail the beneficiary of her life-insurance policy. Delia promptly used Abigail’s information to open fraudulent credit and utility accounts. As a result, Abigail not only suffered damage to her credit history, but she didn’t get the job after an employee background check turned up an arrest warrant for an unpaid home heating bill in her name in Maine. Abigail had never even been to Maine. But Delia lived there. Abigail later learned that her sister was behind numerous accounts opened in her name, though Delia wasn’t arrested or charged with any crime. Local law enforcement refused to get involved in what looked like a family dispute, so Abigail wound up suing her sister in civil court instead. After Abigail sued her, Delia finally agreed to pay most of the $50,000, but the incident tore their relationship apart. “You are dead to me,” Delia later told Abigail.\nRoutine one-on-one crimes are the most common and are largely ignored by the media and, unfortunately, many times by law enforcement. It’s the big-time scams and plots that get the attention. In August 2005, employees at Sunbelt Software Inc. stumbled upon a massive identity- theft ring while researching “CoolWebSearch,” a dangerous software program that hijacks Internet servers and Web home pages—as well as other browser applications. The software was routinely obtaining and broadcasting data such as individual names, bank-account numbers, passwords and PINs, and other extremely sensitive personal information from millions of infected computers. That investigation continues today.\nIt’s surprisingly easy to become an identity thief or fraudster by joining the ranks of criminals who simply buy the information from any number of legal or illegal sellers of sensitive consumer data. Once little-known to most Americans, the data-broking industry burst into the spotlight in February 2005, when ChoicePoint, a seller of consumer data to financial institutions and government agencies, disclosed that criminals posing as legitimate businesspeople had purchased personal information on 145,000 people. (Later, the figure was revised to 162,000.) Americans were staggered by the types of personal information being sold by ChoicePoint, including their names, their spouses’ names, current and previous addresses, phone numbers, Social Security numbers, names of employers and even information about family members and neighbors. While individuals can sometimes buy such data legally, most legitimate data brokers sell only to corporate customers. But the fact that there’s no regulation of legal data sales means it’s easier for criminals to get their hands on your information.\nCOMPANIES RESPOND TO DATA BREACHES\nHere’s a sampling of what some specific companies and organizations have offered to do in response to disclosures that sensitive consumer information was lost or stolen from their databases.\nA contractor moving backup tapes discovered that one tape containing data, including many Social Security numbers, on 600,000 current and former employees, was missing. Time Warner offered a year of free credit-monitoring service.\nA Fidelity employee’s laptop, containing personal information on 196,000 current and former Hewlett-Packard workers, was stolen from a rental car. In response, the fund giant alerted credit-reporting agencies and offered free credit-monitoring service for a year to current and former HP employees.\nAdministrators discovered unusual activity on a university-owned computer with data, including some Social Security numbers, on 106,000 alumni. Tufts set up an 800 number for assistance and encouraged people to put alerts on their credit reports, but did not offer to pay for monitoring.\nUniversity of California, Berkeley\nA laptop was stolen containing Social Security numbers belonging to 98,000 students, alumni and applicants. UC Berkeley set up a hotline and encouraged people to put alerts on their credit reports, but didn’t offer to pay for monitoring.\nFour computers containing sensitive personal data for thousands of people were stolen from a vendor that prints loan statements. Wells Fargo responded by offering a year of free credit monitoring using its own service.\nSource: The Wall Street Journal Online.\nOver the last five years, media coverage has increased as dozens of companies, universities, government agencies and other organizations have reported that vast amounts of sensitive consumer information was either lost or stolen. The list of companies that have reported lost or stolen consumer information reads like a “Who’s Who” of big business: Bank of America, Fidelity, Hewlett-Packard, Time Warner and Verizon, among others. In some instances, data-storage tapes went missing or laptops containing sensitive information were stolen; in others, employees of the companies or organizations obtained unauthorized access to the information. Even the federal government isn’t immune. In 2006, thieves stole data on about 26.5 million military personnel from the U.S. Department of Veterans Affairs. The laptop with the missing data was recovered a month after it was stolen, and two teens were arrested for the theft. But the department stumbled twice more, first when it canceled the credit-monitoring service it had offered the victims of the laptop theft, infuriating innumerable veterans who were counting on it to help protect the breach of their sensitive information. And then it happened again! Another department laptop disappeared. Needless to say, there are some decidedly unhappy vets wondering just how inept the department can get.\nNot surprisingly, victims are beginning to fight back in the courts against companies and organizations that report breaches of sensitive consumer data. In June 2006, a coalition of veterans groups filed a class-action suit against the federal government in the U.S. District Court in Washington, D.C., seeking $1,000 in damages for each of the roughly 26.5 million military personnel, both current and former, whose data was on the stolen laptop mentioned earlier. In July 2005, a group of plaintiffs filed a class-action lawsuit in California Superior against CardSystems Solutions Inc. after the company disclosed that computer hackers had obtained data on about 200,000 credit- and debit-card accounts.\nGARDEN VARIETY IDENTITY FRAUD\nI’ll get into some of the more exotic types of identity theft and fraud later. For the moment, let’s take a look at some of the most common forms of identity crimes. It isn’t hard to guess that by far the favored tool of identity thieves is the ubiquitous credit card. We all have them and we love to use them. So do identity thieves. The Federal Trade Commission (FTC) found that 26 percent of all complaints of identity fraud in 2005 involved fraudulent charges on an existing account or new accounts opened using lost or stolen consumer information.\nHow easy is it to fall victim to credit-card fraud? Let me count the ways.\nWe use credit cards so often and in so many places—online and in person—that it is almost impossible to avoid tripping up and revealing your account information to a potential thief. I shudder to think of how careless I was with my credit-card account information before I discovered that I’d become the victim of identity fraud. I would routinely crumple up credit-card receipts containing my signature and entire account number and then casually toss them in the nearest trash receptacle for a would-be thief to snatch. When making travel reservations at work, I’d broadcast my credit-card number when giving it out to hotels or car-rental agencies, so that anyone within the sound of my voice could jot it down. When using ATMs, I worried more about the guy behind me invading my personal space than I did about whether the offending person was “shoulder surfing” to learn my account’s password. Online, I remembered— occasionally—to check to see if a site’s Web address started with the telltale “https://” and the tiny closed-padlock symbol at the bottom of the Web browser that indicated I was shopping at a secure site. I almost never checked sites such as the Better Business Bureau (www.bbbonline.org) and TRUSTe (www.truste.com) to ensure that the Web site I was using was a legitimate business.\nThen a phone call from my credit-card issuer made me aware of just how easy it is to fall victim to identity fraud. The company’s representative said the company noticed I’d made two purchases within hours of each other using my card—one in New York, the other in France. Fortunately for me, the card company put the purchases on hold until it could contact me and verify that I had made them. I was shocked—and a little scared. If my credit-card information had been stolen, what other personal information could the thief have?\nSo now I pay close attention to things like keeping my voice down when making travel reservations or making sure no one gets too close in the ATM line. I also routinely monitor my credit-card statements online for signs of fraudulent charges. When shopping online, I always use a credit card, rather than my debit card, which is attached to my checking account, because federal law limits liability for unauthorized credit-card use to $50 per card, though many companies will waive this amount if they are notified of the charge in a timely manner. Some debit cards don’t have this kind of zero- liability protection against fraud, but, more importantly, even if your bank offers zero-liability coverage on your checking account, it could take weeks to recover your account after a thief has wiped it out—and you could find yourself vulnerable to bounced-check fees on outstanding payments.\nCALLING ALL THIEVES\nAfter credit-card fraud, phone, cable and utilities fraud is the second most common form of identity theft, making up 18 percent of all complaints reported. Dishonest people steal personal information in order to apply for cell-phone contracts or improperly gain access to cable, telephone, gas and electric energy, or other types of utilities. It’s a difficult crime to combat, which is why it’s so popular among identity thieves. They open accounts in one place and then quickly move on to the next to avoid capture. By the time victims discover the crimes, the thief is usually long gone.\nKevin Scott of Philadelphia discovered he was the victim of utility fraud when he requested a copy of his credit report after being denied a loan. A thief had obtained Scott’s Social Security number and used it to open utility accounts at several addresses, racking up thousands of dollars in phone, cable, gas and electric bills. The utility companies allowed the criminal to open these accounts despite the fact that duplicate accounts already existed in Scott’s name at his true address. They also never bothered to contact him. He spent hundreds of hours clearing his good name at companies such as Bell Atlantic, Comcast Cablevision, PECO Energy and Philadelphia Gas Works. He was also frustrated because state and local law enforcers refused to help him track down the thief, despite the fact that authorities had his picture on file after the thief obtained a Pennsylvania driver’s license using Scott’s name.\nTAKE IT TO THE BANK\nBank fraud is only slightly less common than utilities fraud, which is surprising given that banks are among the more\nsecurity-conscious businesses—and fooling around with a bank can earn a thief a visit from the Federal Bureau of Investigation. Bank fraud accounts for 17 percent of reported identity-theft cases, with nearly 2 million Americans reporting that thieves transferred funds out of their checking accounts in 2004. The average loss per incident was $1,200. Fortunately, consumers rarely are left holding the bag. If the fraud is reported promptly, most banks won’t hold the customer liable for losses resulting from the crime. While fraudulent loans accounted for some bank fraud, the most frequent types of fraud involved electronic funds transfers and forged checks.\nMailboxes are the venue of choice for bank fraudsters. It isn’t difficult to recognize a box of checks sitting in a mailbox, although it takes a diligent thief to check dozens of mailboxes on any given day to find the occasional box of checks. More sophisticated thieves look for bill-payment envelopes left in the mailbox for pickup—then use special chemicals to erase the ink and insert different names.\nExcerpted from The Wall Street Journal. Complete Identity Theft Guidebook by Terri Cullen. Copyright © 2007 by Terri Cullen. Excerpted by permission of Three Rivers Press, a division of Random House, Inc. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.", "label": 1}
{"text": "Personalised scams occur when scammers gather your personal information and use it to specifically target you with a scam. The fact that the scammer knows so much about you may make you think they are legitimate. These scams have become more common in recent years and have taken on a new dimension in the online environment.\nScammers target both individuals and businesses in this manner, leading their victims to believe that they have been specifically selected to receive an offer. In reality scammers will make the same offer to hundreds of other people. They often use the internet to gather personal information, for example through social networking websites and approach victims by phone, SMS, letter, email, fax, or through online networking, dating or chat services and blogs.\nScammers often trawl the internet for your personal details and have also been know to search your mailbox or recycling bin to get hold of discarded personal documents such as bank statements and bills.\nThe types of details which scammers search for include your:\ndate of birth\nemail address (personal and work)\ntelephone numbers (home, work and mobile)\nphysical address (home, work or postal address)\nbank account and credit card details\nsocial networking account, email account and online banking passwords\nother personal numbers, such as Tax File Numbers and Medicare numbers\nupcoming or current travel/holiday plans\nrelatives’ and friends’ names and contact details.\nIf scammers get hold of any of these details they may use them to pose as a legitimate government representative, a company, or a person you know and trust.\nRemember - Your personal details are private and invaluable – keep them that way.\nBe aware, in some cases scammers will simply use readily available public information such as your name and phone number from online directories and make educated guesses about you. For example, they may ask if you have a computer or an account with a specific bank – they pretend to know this about you but are simply guessing!\nIn this section\nView information on the following personalised scam types:\nSCAMwatch is warning Australians to erase their hard drive before parting with old computers and laptops. Simply deleting individual files is not enough to remove personal details, documents and passwords stored on the machine.\nGrooming occurs when a scammer tries to build a trusting relationship with you by making regular contact. Groomers use this relationship to extract greater amounts of money and/or sensitive personal and financial information from their victim.\nPharming is when you are redirected to a fake version of a website which may look identical to the website you were trying to view. The scammer will use the fake site to gather your sensitive personal information which they may then use to commit identity fraud.\nSocial networking websites allow you to create your own profile and to interact with your friends and other online users. Scammers also use social networking sites to steal personal information and trick people out of their money.\nVictim lists are directories of people who have previously responded to an offer or fallen victim to a scam. These lists are created by scammers and contain personal information and contact details. They are compiled for the purpose of approaching those listed with other scams.\nWhaling or spear phishing occurs when scammers personally target employees in order to steal confidential business information and money. Scammers send emails about fake business matters aiming to convince their victims to follow a link to a scam website and provide confidential and financial details.", "label": 1}
{"text": "OAuth (used by the likes of Twitter and others) is a protocol designed to negate the need for users to give 3rd-parties their username & password. A laudable goal!\nHowever, using it can be a real pain when building a desktop application. It’s easiest to describe the problem with an example.\nSay you want to build a desktop application that integrates with Twitter. To do so, you have to signup for an API account at Twitter (true for any OAuth service provider), and obtain a secret key which you must ensure never falls into the hands of anyone but you and your application. The reason this key must stay secret is that it is used to create a hash (OAuth refers to it as signing) of every API message sent from your application to the OAuth service provider; lose the key, and anyone can impersonate your application.\nSo the secret key must stay secret. And what do you, the hapless developer, do? You put it on a server, because it’s the only place you can ensure that it stays safe. So, now, for your desktop application to do anything with the API, it has to send messages up to your server to have the API message signed.\nNow here’s the real sticking point. You have to know the identity of the user before signing the request coming to your server. And how do you know that? The user has to somehow log in to this server you were using previously just to perform signing.\nGreat. Now the user has to create a username & password to your site, just so you can use OAuth with Twitter.\nSo, in the end, you users still have to get involved with a username & password. Sure, your Twitter username & password stays locked in Twitter… which is good, no question. But the user experience is still cumbersome, and the amount of work the developer to do is quite high, especially in the case that you don’t already have a web site and login process.\nSo, in summary, to make a desktop application secure with OAuth, you are forced to make a website with a login if you don’t already have one. Ouch.\nI’m admittedly new to OAuth but as far as I can tell, this is the state of affairs with OAuth and desktop applications.", "label": 1}
{"text": "When you think about it, it's ridiculous: almost all of those billions of e-mails that find their way around the globe every day are sent in the clear with no encryption of any kind applied to the message. There are two ways to encrypt e-mail: with S/MIME, built into Apple's Mail application—but this requires getting (read: buying) a certificate—and GPG.\nGPG is a command line utility and GPGMail is a plugin that lets Mail.app use GPG to create and check digital signatures and to encrypt and decrypt messages. Unfortunately, as the GPGMail team has put it, \"GPGMail is a complete hack, relying on Mail's private internal API. Use it at your own risks!\" One of these risks is that Apple brings out OS X 10.4 or 10.5 and it takes many months or even more than a year for an update to come out that supports the new OS. (But complaining is easy; GPGMail is open source, so don't complain too much. Help with coding instead.) Anyway, fairly recently, GPGMail 1.2.0 was released. Leopard users can finally read and write encrypted mail again. Yippee!\nFor those of you who have no idea what I'm talking about but are still reading:\nThese days, simply encrypting something is pretty easy. There are several strong algorithms around and computers are plenty fast to run them. The problem is: how do you make sure the intended recipient and nobody else is able to decode the message? This is where public key cryptography comes in. There are several algorithms that have two different keys: a public one for encryption or checking signatures, and a private one for decryption and creating signatures. Simply generate a pair of keys, keep the private one and publish the public one, and you're in business.\nWell, not entirely. The problem that remains is how to be sure that a public key belongs to a certain person. For HTTPS/SSL, this issue is handled by \"trusted third parties\" (I'm sorry, I can't say those words with a straight face) such as Verisign or DigiCert, who provide a certain level of assurance that a public key (in the form of a certificate) belongs to the party the certificate says it belongs to. However, that's not free—not as in beer (certificates cost money) and also not as in speech, because only organizations that can bribe Apple, Microsoft, the Mozilla Foundation, et cetera get to be \"trusted\" third parties.\nThis is where GNU Privacy Guard (GPG) comes in. GPG is an open source tool that encrypts, decrypts, signs, and checks signatures. It also manages a \"key chain\" of public keys and a web of trust. The idea is that, rather than having a list of trusted third parties and trusting them when they say that someone is who they say they are, everyone manages their own trust relationships and exports these for use by others. So, if I trust Jacqui and Jacqui trusts Clint, just attaching her signature to his public key wouldn't ensure me that this public key is indeed Clint's. But if David and Eric also sign Clint's key, that's good enough for me and I'll trust Clint's key, too. (Note that \"trust\" just means \"knows that this is indeed that person's key.\" It's perfectly reasonable to sign a stranger's key after checking his or her ID.)\nGPG is a command line tool, but after installing it and generating a public/private key pair and uploading it to a key server, it's generally not necessary to use the command line—GPGMail adds a bunch of menu items to Mail that make it possible to use GPG from within Mail.", "label": 1}
{"text": "How to Secure a Web Site\nSecurity is a very important aspect for any\ndeveloper of ecommerce web sites. To secure a web site, we must make sure\nthat private data that's sent between the client and server can't be deciphered.\nTo accomplish that, we use an Internet Protocol called SSL (Secure Socket\nLayer). Its an important protocol that lets you transmit data over the\ninternet using data encryption.\nHow Secure Sockets Layer (SSL) connections Work:\nSSL is the protocol used by the world wide web that allows clients and servers to communicate over a secure connection.\nWith SSL, the browser\nencrypts all data that's sent to the server and decrypts all data that's\nreceived from the server. Conversely, the server encrypts all data that's sent\nto the browser and decrypts all data that's received from the\nSSL is able to\ndetermine if data has been tampered with during transmit and verify that a\nserver or a client is who claims to be.\nTo to determine if\nyou're transmitting data over a secure connection, you can read the URL in the\nbrowser's address bar. If it starts with HTTPS rather than HTTP, then you're\ntransmitting data over a secure connection as shown in the folowing diagram:\nTo test an application that uses SSL, you must run the application under the control of IIS.\nWith some browsers, a\nlock icon is displayed when a secure connection is being used.\nHow digital secure\nTo use SSL to transmit data, the client and the server use Digital secure certificates as shown in below diagram.\nCertificates are the electronic counterparts to driver licenses, passports\nand membership cards. You can present a Digital Certificate electronically to\nprove your identity or your right to access information or services online.\nA Digital Certificate\nis issued by a Certification Authority (CA) and signed with the CA's private\nCertificates serve two purposes. First, they establish the identity of the\nserver or clients. Second,they provide the information needed to encrypt data\nbefore it's transmitted. By default, browsers are configured to accept\ncertificates that come from trusted sources. If a browser doesn't recognize a\ncertificate as coming from a trusted source, however, it informs the user and\nlets the user view the certificate. Then, the user can determine whether\nthe certificate should be considered valid. If the user chooses to accept the\ncertificate, the secure connection is established. The certificate dialog box\nfor a digital secure certificate is as shown in the following figure:\nHow to determine\nif a Digital Secure Certificate is installed on your server\nIf IIS is running on\nyour local machine, chances are that certificate hasn't been installed. But if\nIIS is running on a server on a network, you can use the procedure as shown in\nabove figure to determine if a certificate has been installed and to view the\nHow to get a\nDigital Secure Connection\nIf you want to\ndevelop an ASP .NET application that uses SSL to secure client connections, you\nmust first obtain a digital secure certificate from a trusted source such as:\nauthorities, or CAs verify that the person or company requesting the\ncertificate is a valid person or company by checking with a registration\nauthority, or RA. To obtain a digital secure certificate, you'll need to provide\na registration authority with information about yourself or your company. Once\nthe registration authority approves the request, the certificate authority can\nissue the digital secure certificate.\nHere are some related resources:", "label": 1}
{"text": "Editor's note: Bruce Schneier is a security technologist and author of \"Beyond Fear: Thinking Sensibly About Security in an Uncertain World.\" Read more of his writing at http://www.schneier.com/\n(CNN) -- Google made headlines when it went public with the fact that Chinese hackers had penetrated some of its services, such as Gmail, in a politically motivated attempt at intelligence gathering. The news here isn't that Chinese hackers engage in these activities or that their attempts are technically sophisticated -- we knew that already -- it's that the U.S. government inadvertently aided the hackers.\nIn order to comply with government search warrants on user data, Google created a backdoor access system into Gmail accounts. This feature is what the Chinese hackers exploited to gain access.\nGoogle's system isn't unique. Democratic governments around the world -- in Sweden, Canada and the UK, for example -- are rushing to pass laws giving their police new powers of Internet surveillance, in many cases requiring communications system providers to redesign products and services they sell.\nMany are also passing data retention laws, forcing companies to retain information on their customers. In the U.S., the 1994 Communications Assistance for Law Enforcement Act required phone companies to facilitate FBI eavesdropping, and since 2001, the National Security Agency has built substantial eavesdropping systems with the help of those phone companies.\nSystems like these invite misuse: criminal appropriation, government abuse and stretching by everyone possible to apply to situations that are applicable only by the most tortuous logic. The FBI illegally wiretapped the phones of Americans, often falsely invoking terrorism emergencies, 3,500 times between 2002 and 2006 without a warrant. Internet surveillance and control will be no different.\nOfficial misuses are bad enough, but it's the unofficial uses that worry me more. Any surveillance and control system must itself be secured. An infrastructure conducive to surveillance and control invites surveillance and control, both by the people you expect and by the people you don't.\nChina's hackers subverted the access system Google put in place to comply with U.S. intercept orders. Why does anyone think criminals won't be able to use the same system to steal bank account and credit card information, use it to launch other attacks or turn it into a massive spam-sending network? Why does anyone think that only authorized law enforcement can mine collected Internet data or eavesdrop on phone and IM conversations?\nThese risks are not merely theoretical. After September 11, the NSA built a surveillance infrastructure to eavesdrop on telephone calls and e-mails within the U.S. Although procedural rules stated that only non-Americans and international phone calls were to be listened to, actual practice didn't match those rules. NSA analysts collected more data than they were authorized to and used the system to spy on wives, girlfriends and notables such as President Clinton.\nBut that's not the most serious misuse of a telecommunications surveillance infrastructure. In Greece, between June 2004 and March 2005, someone wiretapped more than 100 cell phones belonging to members of the Greek government: the prime minister and the ministers of defense, foreign affairs and justice.\nEricsson built this wiretapping capability into Vodafone's products and enabled it only for governments that requested it. Greece wasn't one of those governments, but someone still unknown -- A rival political party? Organized crime? Foreign intelligence? -- figured out how to surreptitiously turn the feature on.\nAnd surveillance infrastructure can be exported, which also aids totalitarianism around the world. Western companies like Siemens and Nokia built Iran's surveillance. U.S. companies helped build China's electronic police state. Just last year, Twitter's anonymity saved the lives of Iranian dissidents, anonymity that many governments want to eliminate.\nIn the aftermath of Google's announcement, some members of Congress are reviving a bill banning U.S. tech companies from working with governments that digitally spy on their citizens. Presumably, those legislators don't understand that their own government is on the list.\nThis problem isn't going away. Every year brings more Internet censorship and control, not just in countries like China and Iran but in the U.S., the U.K., Canada and other free countries, egged on by both law enforcement trying to catch terrorists, child pornographers and other criminals and by media companies trying to stop file sharers.\nThe problem is that such control makes us all less safe. Whether the eavesdroppers are the good guys or the bad guys, these systems put us all at greater risk. Communications systems that have no inherent eavesdropping capabilities are more secure than systems with those capabilities built in. And it's bad civic hygiene to build technologies that could someday be used to facilitate a police state.\nThe opinions expressed in this commentary are solely those of Bruce Schneier.", "label": 1}
{"text": "The next thing to take a look at is the security in your system against attacks from local users. Did we just say local users? Yes!\nGetting access to a local user account is one of the first things that system intruders attempt while on their way to exploiting the root account. With lax local security, they can then \"upgrade\" their normal user access to root access using a variety of bugs and poorly setup local services. If you make sure your local security is tight, then the intruder will have another hurdle to jump.\nLocal users can also cause a lot of havoc with your system even (especially) if they really are who they say they are. Providing accounts to people you don't know or for whom you have no contact information is a very bad idea.\nYou should make sure you provide user accounts with only the minimal requirements for the task they need to do. If you provide your son (age 10) with an account, you might want him to only have access to a word processor or drawing program, but be unable to delete data that is not his.\nSeveral good rules of thumb when allowing other people legitimate access to your Linux machine:\nGive them the minimal amount of privileges they need.\nBe aware when/where they login from, or should be logging in from.\nMake sure you remove inactive accounts, which you can determine by using the 'last' command and/or checking log files for any activity by the user.\nThe use of the same userid on all computers and networks is advisable to ease account maintenance, and permits easier analysis of log data.\nThe creation of group user-id's should be absolutely prohibited. User accounts also provide accountability, and this is not possible with group accounts.\nMany local user accounts that are used in security compromises have not been used in months or years. Since no one is using them they, provide the ideal attack vehicle.\nThe most sought-after account on your machine is the root (superuser) account. This account has authority over the entire machine, which may also include authority over other machines on the network. Remember that you should only use the root account for very short, specific tasks, and should mostly run as a normal user. Even small mistakes made while logged in as the root user can cause problems. The less time you are on with root privileges, the safer you will be.\nSeveral tricks to avoid messing up your own box as root:\nWhen doing some complex command, try running it first in a non-destructive way...especially commands that use globing: e.g., if you want to do rm foo*.bak, first do ls foo*.bak and make sure you are going to delete the files you think you are. Using echo in place of destructive commands also sometimes works.\nProvide your users with a default alias to the rm command to ask for confirmation for deletion of files.\nOnly become root to do single specific tasks. If you find yourself trying to figure out how to do something, go back to a normal user shell until you are sure what needs to be done by root.\nThe command path for the root user is very important. The command path (that is, the PATH environment variable) specifies the directories in which the shell searches for programs. Try to limit the command path for the root user as much as possible, and never include . (which means \"the current directory\") in your PATH. Additionally, never have writable directories in your search path, as this can allow attackers to modify or place new binaries in your search path, allowing them to run as root the next time you run that command.\nNever use the rlogin/rsh/rexec suite of tools (called the r-utilities) as root. They are subject to many sorts of attacks, and are downright dangerous when run as root. Never create a .rhosts file for root.\nThe /etc/securetty file contains a list of terminals that root can login from. By default (on Red Hat Linux) this is set to only the local virtual consoles(vtys). Be very wary of adding anything else to this file. You should be able to login remotely as your regular user account and then su if you need to (hopefully over Section 6.4 or other encrypted channel), so there is no need to be able to login directly as root.\nAlways be slow and deliberate running as root. Your actions could affect a lot of things. Think before you type!\nIf you absolutely positively need to allow someone (hopefully very trusted) to have root access to your machine, there are a few tools that can help. sudo allows users to use their password to access a limited set of commands as root. This would allow you to, for instance, let a user be able to eject and mount removable media on your Linux box, but have no other root privileges. sudo also keeps a log of all successful and unsuccessful sudo attempts, allowing you to track down who used what command to do what. For this reason sudo works well even in places where a number of people have root access, because it helps you keep track of changes made.\nAlthough sudo can be used to give specific users specific privileges for specific tasks, it does have several shortcomings. It should be used only for a limited set of tasks, like restarting a server, or adding new users. Any program that offers a shell escape will give root access to a user invoking it via sudo. This includes most editors, for example. Also, a program as innocuous as /bin/cat can be used to overwrite files, which could allow root to be exploited. Consider sudo as a means for accountability, and don't expect it to replace the root user and still be secure.", "label": 1}
{"text": "For the past few months I've been beta-testing Microsoft Internet Explorer 7. It comes with a number of new features but, because I'm a language watcher, the feature that most interested me was the Phishing Filter. Huh? Could Microsoft, as corporate and mainstream as a tech company can get, be using the jargon term phishing in its flagship Web browser? At first I figured that it must be some sort of internal code name, but no, it's the actual mass-market name of the feature.\nThis small ripple in the linguistic pool is a reflection not of a newfound coolness on Microsoft's part but of the phishing phenomenon itself, particularly how pervasive it has become and how most folks grasp the theory and seriousness of this vulnerability.\n\"Phishing\" refers to creating a replica of an existing Web page to fool users into submitting personal, financial, or password data to what they think is their bank or a reputable online retailer. The term comes from the fact that Internet scammers use (increasingly sophisticated) lures to \"fish\" for users' sensitive data. Hackers have an endearing tendency to change the letter \"f\" to \"ph,\" so \"fishing\" becomes \"phishing.\" (The f-to-ph transformation is not new among hackers; it first appeared in the late 1960s among the hackers of the telephone system, who called themselves phone phreaks. There are still plenty of these phreaks around today, but often their targets are more modern. A good example is VoIPhreaking, which involves hacking voice-over-Internet-Protocol telephony systems.)\nThe most common ploy used by phishers is to copy the page code from a major Web site--such as AOL or eBay--and use that code to set up a replica page that appears to be legitimate. (This is why phishing is also called brand spoofing.) Fake e-mail is distributed with a link to this page, which solicits the user's credit card data or password. (If it's the latter, then the page is called a password trap.) When the user submits the form, the data go to the scammer, and the user ends up on an actual page from the company's site, so he or she doesn't suspect a thing.\nThe easiest way to detect a phishy page is to look at the page address. A legitimate page will have the correct domain--such as aol.com or ebay.com--while a spoofed page will have only something similar--such as aol.whatever.com or blah.com/ebay. However, some phishers employ tricks such as domain spoofing, replacing the lowercase letter \"L\" with the number \"1\" or the uppercase letter \"O\" with the number \"0.\" This is also called homograph spoofing or a look-alike attack. A similar ploy is IDN spoofing, which uses domain name ambiguities in the user's chosen browser language. (\"IDN\" is short for \"international domain names,\" which refers to domain names written in languages other than English.)\nAnother good way to detect phishing e-mail is to examine the address of the link that you're supposed to click on. Again, this address will point to an obviously nonlegitimate site. Or will it? Recent phishing attempts have used a technique called DNS cache poisoning, a Domain Name System exploit where a \"poisoned\" DNS server is configured to redirect surfers from a legitimate site to the scammer's site. Because the switch occurs somewhere in the network between the user's computer and the Internet at large, it can be very hard to spot.\nAs people become more aware of phishing, they're less likely to fall for obvious ploys such as requests for passwords and credit card data. So the world's dot con artists are revising their schemes to compensate. The latest tool in their nefarious arsenal is spear phishing, which refers to phishing that is targeted at a specific person. This usually consists of sending an e-mail message that has a subject line, body text, and return address that make it appear as though it were sent by someone the recipient knows. For example, you might get a message that appears to come from the head of your IT department, requesting that you visit a particular site to update your password.\nAnother reason people are less likely to fall for a phishing scam is that big corporations are doing a better job of warning their customers and teaching them how to spot fraudulent requests. Scammers are hip to this, so they're trying a new tactic: targeting smaller companies that might not do as good a job warning their customers. These smaller-scale attacks are called puddle phishing. Phishers are also breaking out of the \"fake e-mail and Web site\" paradigm and turning to fraudulent phone calls that attempt to con people out of sensitive data such as their credit card's three- or four-digit security number. This is called phone phishing.\nSo Microsoft is right to include antiphishing technology in Internet Explorer 7, because clearly we need all the help we can get. Maybe the folks there will really get into the spirit of things and hack the company's name, too. Microsopht, perhaps?\nAbout the Author\nPAUL MCFEDRIES is a technical and language writer with more than 40 books to his credit. He also runs Word Spy, a Web site and mailing list that tracks new words and phrases (http://www.wordspy.com).", "label": 1}
{"text": "You must have heard about it before: formally verified microkernels that offer 100% security... Why don't we use such a microkernel in Qubes then? (The difference between a micro-kernel and a type I hypervisor is blurry. Especially in case of a type I hypervisor used for running para-virtualized VMs, such as Xen used in Qubes. So I would call Xen a micro-kernel in this case, although it can also run fully-virtualized VMs, in which case it should be called a hypervisor I think.)\nIn order to formally prove some property of any piece of code, you need to first assume certain things. One such thing is the correctness of a compiler, so that you can be sure that all the properties you proved for the source code, still hold true for the binary generated from this source code. But let's say it's a feasible assumption -- we do have mature compilers indeed.\nAnother important assumption you need, and this is especially important in proving kernels/microkernels/hypervisors, is the model of the hardware your kernel interacts with. Not necessarily all the hardware, but at least the CPU (e.g. MMU, mode transitions, etc) and the Chipset.\nWhile the CPUs are rather well understood today, and their architecture (we're talking IA32 here) doesn't change so dramatically from season to season. The chipsets, however, are a whole different story. If you take a spec for any modern chipset, let's say only the MCH part, the one closer to the processor (on Core i5/i7 even integrated on the same die), there are virtually hundreds of configuration registers there. Those registers are used for all sorts of different purposes -- they configure DRAM parameters, PCIe bridges, various system memory map characteristics (e.g. the memory reclaiming feature), access to the infamous SMM memory, and finally VT-d and TXT configuration.\nSo, how are all those details modeled in microkernels formal verification process? Well, as far as I'm aware, they are not! They are simply ignored. The nice way of saying this in academic papers is to say that \"we trust the hardware\". This, however, might be incorrectly understood by readers to mean \"we don't consider physical attacks\". But this is not equal! And I will give a practical example in a moment.\nI can bet that even the chipset manufactures (think e.g. Intel) do not have formal models for their chipsets (again, I will give a good example to support this thesis below).\nBut why are the chipsets so important? Perhaps they are configured \"safe by default\" on power on, so even if we don't model all the configuration registers, and their effects on the system, and if we won't be playing with them, maybe it's safe to assume all will be fine then?\nWell, it might be that way, if we could have secure microkernels without IOMMU/VT-d and without some trusted boot mechanism.\nBut we need IOMMU. Without IOMMU there is no security benefit of having a microkernel vs. having a good-old monolithic kernel. Let me repeat this statement again: there is no point in building a microkernel-based system, if we don't correctly use IOMMU to sandbox all the drivers.\nNow, setting up IOMMU/VT-d permissions require programming the chipset's registers, and is by no means a trivial task (see the the Intel VT-d spec to get an impression, if you don't believe me). Correctly setting up IOMMU is one of the most security-critical tasks to be done by a hypervisor/microkernel, and so it would be logical to expect that they also formally prove that this part is done flawlessly...\nThe next thing is the trusted boot. I will argue that without proper trusted boot implementation, the system cannot be made secure. And I'm not talking about physical attacks, like Evil Maid. I'm talking about true, remote, software attacks. If you haven't read it already, please go back and read my very recent post on \"Remotely Attacking Network Cards\". Building on Loic's and Yves-Alexis' recent research, I describe there a scenario how we could take their attack further to compromise even such a securely designed system as Qubes. And this could be possible, because of a flaw in TXT implementation. And, indeed, we demonstrated an attack on Intel Trusted Execution Technology that exploits one such flaw before.\nLet's quickly sketch the whole attack in points:\n- The attacker attacks a flaw in the network card processing code (Loic and Yves-Alexis)\n- The attacker replaces the NIC's firmware in EEPROM to survive the reboot (Loic and Yves-Alexis)\n- The new firmware attacks the system trusted boot via a flaw in Intel TXT (ITL)\n- If the system uses SRTM instead, it's even easier -- see the previous post (ITL)\n- If you have new SINIT module that patched our attack, there is still an avenue to attack TXT via SMM (ITL)\nAnd this is the practical example I mentioned above. I'm sure readers understand that this is just one example, of what could go wrong on the hardware level (and be reachable to a software-only attacker). Don't ignore hardware security! Even for software attacks!\nA good question to ask is: would a system with a formally verified microkernel also be vulnerable to such an attack? And the answer is yes! Yes, unless we could model and prove correctness of the whole chipset and the CPU. But nobody can do that today, because it is impossible to build such a model. If it was, I'm pretty sure Intel would already have such a model and they would not release an SINIT module with this stupid implementation bug we found and exploited in our attack.\nSo, we see an example of a practical attack that could be used to fully compromise a well designed system, even if it had a formally verified microkernel/hypervisor. Compromise it remotely, over the network!\nSo, are all those whole microkernel/hypervisor formal verification attempts just a waste of time? Are they only good for academics so that they could write more papers for conferences? Or for some companies to use them in marketing?\nPerhaps the formal verification of system software will never be able to catch up with the pace of hardware development... By the time people will learn how to build models (and how to solve them) for hardware used today, the hardware manufactures, in the meantime, will present a few new generations of the hardware. For which the academics will need another 5 years to catch up, and so on.\nPerhaps the industry will take a different approach. Perhaps in the coming years we will get hardware that would allow us to create untrusted hypervisors/kernels that would not be able to read/write usermode pages (Hey Howard;)? This is currently not possible with the hardware we have, but, hey, why would a hypervisor need access to the Firefox pages?\nAnd how this all will affect Qubes? Well, the Qubes project is not about building a hypervisor or a microkernel. Qubes is about how to take a secure hypervisor/microkernel, and how to build the rest of the system in a secure, and easy to use, way, using the isolation properties that this hypervisor/microkernel is expected to provide. So, whatever kernels we will have in the future (better formally verified, e.g. including the hardware in the model), or based on some exciting new hardware features, still Qubes architecture would make perfect sense, I think.", "label": 1}
{"text": "Backdoor:Win32/Tosct.A is dangerous computer backdoor that makes use of network channel vulnerabilities to infect target computers. Backdoor:Win32/Tosct.A gets into a computer without detection. Once installed, Backdoor:Win32/Tosct.A damages the system by infecting system files. It may allow hackers gain remote access to the affected system and steal sensitive info. Thus, the computer will be put under additional threat, being more vulnerable. Backdoor:Win32/Tosct.A disables various antivirus. It is recommended to manually remove Backdoor:Win32/Tosct.A virus.\nBackdoor:Win32/Tosct.A is Very Dangerous:\n- Backdoor:Win32/Tosct.A is a kind of malicious Backdoors\n- Backdoor:Win32/Tosct.A allows all sorts of harmful system modification from intruders\n- Backdoor:Win32/Tosct.A allows access for remotely host and may lead to illegal action by installing hidden FTP sever\n- Backdoor:Win32/Tosct.A may come with or spread other spywares\n- Backdoor:Win32/Tosct.A steals your privacy information and compromises your security\n- Backdoor:Win32/Tosct.A can cause the infected computer work slow and it’s very difficult to remove Backdoor:Win32/Tosct.A\nSince Backdoor:Win32/Tosct.A has so many harmful characteristics, get rid of Backdoor:Win32/Tosct.A with the manual instructions in this article immediately.\nWhy can’t antivirus program help?\nEven though you have the best firewall or antivirus tool available, the Backdoor:Win32/Tosct.A virus still gets through without your consent. That is because Backdoor:Win32/Tosct.A is designed to have been changed the code so antivirus can’t keep up. Once executed, Backdoor:Win32/Tosct.A virus can block your antivirus program or firewall. In such circumstance, manual removal is required.\nHow to Manually Remove Backdoor:Win32/Tosct.A ?\n1. Find and stop Backdoor:Win32/Tosct.A associated processes:\n2. Locate and delete Backdoor:Win32/Tosct.A associated files:\n%Windows%\\system32\\[random].exe C:\\Users\\[User Name]\\AppData\\Roaming\\[random] c:\\Users\\[User Name]\\AppData\\Local\\Temp\\[random]\n3. Detect and remove Backdoor:Win32/Tosct.A related registry entries:\nHKEY_CLASSES_ROOT\\CLSID\\[random numbers] HKEY_CURRENT_USER\\SOFTWARE\\bifrost\nExpert Recommendation: Tee Support is the #1 place to get IMMEDIATE live help for your PCs, peripherals, devices and software applications 24/7. It is faster, much cheaper and more convenient than in-store repair or service call, saving your time and money and avoiding hours of unnecessary frustration. Get your problems solved right now and make your PC run like new again!\n- How to Remove Backdoor:Win32/Wkysol.H, Backdoor:Win32/Wkysol.H Manual Removal Help\n- VirTool:JS/Obfuscator.CE – Remove VirTool:JS/Obfuscator.CE Efficiently, Removal Guide\n- Cannot Uninstall Backdoor.Vercuser.A? Guide to Remove Backdoor.Vercuser.A infection Completely and Quickly\n- How to Remove Backdoor:BAT/Agent.H Virus, Guide for Backdoor:BAT/Agent.H Removal\n- How to Remove Backdoor:MSIL/Pontoeb.J Virus Effectively, Backdoor:MSIL/Pontoeb.J Removal\n- Completely Remove BackDoor-DOQ.gen.k, Uninstall BackDoor-DOQ.gen.k Effectively\n- Easily Get Rid of Backdoor.Cycbot.A (Manual Removal Guide)\n- How to Remove Backdoor:Win32/IRCbot.gen!M – Guide to Get Rid of Backdoor:Win32/IRCbot.gen!M Easily\n- Delete Backdoor:Win32/Cycbot!cfg – Backdoor:Win32/Cycbot!cfg Removal Guide\n- How to Remove Trojan.Generic.dx!b2fv Completely and effectively\n- SecureMyPCScanner, Remove/ Uninstall Fake SecureMyPCScanner\n- Trojan-Spy.HTML.Cunt.b How to Remove? Get Rid of Trojan-Spy.HTML.Cunt.b Manually\n- Delete Trojan:Win32/Comiproc Thoroughly (The Trojan:Win32/Comisproc Manual Removal Tips)\n- Guide to Remove Trojan.Agent.MRGGen Virus Step by Step in a Safe Manual Way\n- Trojan.Script.12023 Won't Go Away? How to Remove Trojan.Script.12023 for Good?\n- How to Remove Generic.dx!nw, Generic.dx!nw Removal\n- Uninstall Fake Windows Smart Partner Step by Step (Windows Smart Partner Virus Manual Removal Guide)\n- How to Safely Remove TR/Sirefef.16896/ Tips for Trojan Virus Removal", "label": 1}
{"text": "Jul 11 2011\nThe Internet provides children with wonderful social and developmental opportunities, but the Internet can also be fraught with nasty surprises — if parents don’t keep a watchful eye.\nSep 08 2010\nHow does a computer get infected if you’re just surfing the Internet? And how do cybercriminals make money from tricking users? This article aims to answer these questions.\nApr 19 2010\nSocial Networking is the one area of the Internet that nearly every computer-literate person indulges in these days. It doesn’t matter whether it’s your company boss, your neighbor, your boyfriend or your girlfriend, everybody’s contactable via at least one of the Social Networking portals.\nMar 03 2010\nToday’s threat landscape is very complex. Cybercriminals use a wide range of threats to hijack people’s computers and to make money illegally. These threats include Trojans of many different kinds, worms, viruses and exploit code which is designed to enable malware to make use of vulnerabilities in the operating system or applications.\nSep 24 2009\nWe all learn at a very young age to analyse – either consciously or unconsciously – other people's body language and intonation\nDec 20 2005\nTwo Kaspersky Lab virus analysts share their thoughts on the role people play in ensuring information security.\nOct 21 2005\nThis latest report continues Kaspersky Lab's sequence of quarterly reports on malware and cyber threat evolution.\nApr 18 2005\nKaspersky Lab presents an overview of malware evolution in the first quarter of 2005.", "label": 1}
