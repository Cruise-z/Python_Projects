{"text": "Sniff ZigBee Packets\nA variety of software and hardware lets you monitor and analyze IEEE 802.15.4 radio traffic.\nby Jon Titus, Senior Technical Editor\nWhen engineers tackle a project that uses ZigBee communications they may get a surprise. Unlike point-to-point communications, ZigBee involves a network that can establish nodes, repeaters and complex mesh topologies. The proper test tools--often called \"sniffers\"--help engineers diagnose ZigBee-network problems that could otherwise turn into nightmares.\nMicrochip Technology includes the ZENA Wireless Network Analyzer with its PICDEM Z demonstration kit so engineers can see what goes on among ZigBee devices. The ZENA tool also can sniff and decode Microchip's MiWi protocol that, like ZigBee, uses IEEE 802.15.4 radios. According to Steve Bible, an applications engineering manager at Microchip, ZENA time stamps packets and displays them in a graphical format.\n\"The screen shows the destination and source addresses, the payload and the data,\" explained Bible. \"We add some color coding and provide data as hexadecimal values. Users also see a received signal strength indication, or RSSI--an uncalibrated relative value.\"\nNot only will ZENA display the packets, but it also shows how a network forms. \"When you power a ZigBee node, it first looks for an available ZigBee network,\" said Bible. \"If none exists, it sets itself up as the network coordinator and waits for other stations to query it as they power up. The coordinator lets the newly powered nodes know a network exists, it lets them join and it assigns them an ID number. Some customers find that a difficult concept to grasp.\"\nThe ZENA analyzer also logs data into a file so users can later examine in detail the association and disassociation of nodes. \"When customers email us a log file, we can help analyze it,\" said Bible. \"ZENA goes beyond analysis and lets you specify radio channels, whether a radio will serve as a coordinator, and so on. Then it creates .h files that go into our MPLAB IDE to produce code for Microchip MCUs.\"\nEngineers who need detailed analyses of ZigBee and 802.15.4 communications can purchase more sophisticated products from companies such as Frontline Test Equipment and Perytons.\n\"ZigBee and IEEE 802.15.4 technologies require a shift in how we analyze and manage ad-hoc wireless networks,\" said Matt Perkins, VP of technology development at Awarepoint, a supplier of wireless asset-tracking systems. \"An analyzer should take time-sliced snapshots of network traffic, 'mine' the traffic for metrics such as throughput, bottlenecks and end-to-end delays, and presents information in a concise graphical form.\"\nPerkins has used the Frontline MeshDecoder packet sniffer and protocol analyzer and he looks for two features in such a product. \"First, you must be able to view an entire network and view details that convey how each node connects to its neighbors. Second, designers want to quickly relate custom packet information to their top-level application.\" Frontline's DecoderScript language lets designers create such decoders.\nEric Kaplan, Frontline's founder, describes protocol analysis in three areas, debug, interoperability test and verification. Debugging helps engineers figure out why their program or network doesn't work. \"You can see messages and responses to determine if they are correct and then give that information to programmers,\" said Kaplan.\n\"If devices from two vendors don't interoperate properly, watch the packets as they attempt to communicate and then analyze where the problems lie,\" said Kaplan. \"Often specs are ambiguous, companies misinterpret them or don't stay current with changes.\"\nKaplan also noted, \"You must verify that in addition to interoperating, your devices exchange the proper information. So you watch the communications and verify that messages conform to the spec.\"\n\"The 802.15.4 communications use only 16 channels in the 2.4 GHz band, so you can use inexpensive dongles and monitor all channels simultaneously,\" explained Yaron Soffer, founder and CEO at Perytons. \"You also want time-domain information that shows related events such as beacon transmissions, queries, replies, and so on.\"\nA Perytons analyzer monitors multiple channels, so it can overcome problems with multi-path communications. \"A typical network uses retransmissions to try to overcome multipath problems,\" noted Soffer. \"But a passive analyzer cannot do that. We put two dongles on the same 802.15.4 channel and use antenna diversity to mitigate multipath and interference effects. In some cases we can reduce the number of lost packets from 10 percent down to 0.1 percent.\"\nPerytons' analyzer provides many analysis tools as well as a pointer tool that displays definitions of packets and signal characteristics in a given signal. Thus, technicians need not master the 802.15.4 or ZigBee specs before they can interpret information.\n\"We discovered many engineers use 802.15.4 radios in proprietary ways because they couldn't wait for the ZigBee protocol to become a standard,\" said Soffer. \"They can use our APIs and examples to put their own protocol into the analysis software. They don't need one instrument to analyze lower protocol layers and another to analyze their data.\" \"This permits people to use the same tool during development, production, testing, quality assurance and other functions.\"\nA protocol analyzer's software should be flexible enough to adapt to revised standards, too. \"The approval of the ZigBee Pro protocol in 2007 required some software changes, but engineers didn't have to buy new hardware because the basic 802.15.4 radios stayed the same,\" noted Soffer. \"You don't want to ask your boss for a new instrument when standards change.\"", "label": 1}
{"text": "These are links having to do\nwith protecting your computer from security breaches, hackers and\nsecurity flaws. Links below are alphabetized by name and address\nviruses, spyware and other intrusion attempts.\nSpyware is becoming more and more of a problem on the Internet. It is relatively new and may be the cause of problems such as your start\npage changing automatically, new toolbars added to Internet Explorer,\nyou can connect to the net but cannot view websites (page cannot be\ndisplayed error) or causing your browser to crash. Spyware can also be programs that track your\nactivities on the net and websites that you visit often, so as to market you with pop up ads or email\nSpyware can be contracted by simply visiting websites or opening\nemails that contain spyware. Windows 95, 98, NT, ME, 2k & XP are\nvulnerable to getting Spyware.\nAd-Aware Cost: Free\nwww.lavasoft.de/software/adaware/ (Download size: 1654 kb)\nAdAware is a program that will scan any memory drives in your computer\n(hard drives, disk drives, etc) for any known programs (Spy programs)\nthat are using your computer to acquire data from you. This program\nwill quarantine the offending programs/components and will allow you\nto purge them from your system. This program also has a built in\nupdate mechanism that allows you to download latest updates from the\nweb. Note: If you are running Kazaa or another file sharing program,\nAd-ware may disable its functionality.\nAVG Anti-virus Free Edition Cost: Free to paying\nAVG Free Edition is for private, non-commercial, single home computer\nGRC Cost: Free to paying www.grc.com\nThis site contains many free security programs that are\nIconix Cost: Free\nThis programs ads a \"visual ID\" to your email. This software helps\nidentify trusted Email and protects against \"Phishing\".\nMcafee Cost: Varies www.mcafee.com\nThis is another well known anti-virus company.\nNorton Anti Virus Cost: Varies us.norton.com\nNorton is a well known and respected anti-virus and security program.\nThis is the place to look first for information about new threats,\nworms, and viruses.\nTheir Security Response USA website is invaluable as it lists the\nlatest virus threats, security updates, removal tools, and virus\ndefinitions. The removal tools are free for downloading. The main\nprogram does cost money but is well worth it - it runs on your\ncomputer and checks for viruses, worms, and other security problems as\nwell as provides a live update via the web when new known viruses are\nSpyBot Cost: Free www.spybot.info\nThis program is available in 8 different languages and is our\nrecommendation for safely removing Spyware. Once you install this software you must\ngo online and get the updates before actually\nrunning it (the program doesn't really remind you to get the online\nupdates although in the program itself, there is an\nStinger Cost: Free\nis a stand-alone utility used to detect and remove specific viruses -\nits free and is brought to you by the well-known Anti Virus company,\nMcAfee. This program should not be used as a substitute for full\nanti-virus protection. Click on the above link for the download and\ninstall file as well as step by step setup and installation\nZone Alarm Cost: Varies www.zonelabs.com\nThis is a software based firewall program. It monitors all incoming\nnetwork traffic for your computer - and it can be setup to only allow\nconnections that you know and want to receive. Basically it works by\nclosing off ports on your computer that you do not need open. For\nexample port # 80 is the port that you use to browse web sites, so\nthis port of course would remain open.\nThis software also helps hide your computer on the net - which helps\nprevents hackers and other data mining programs from finding\nPhishing is when someone tries to\ngain access to sensitive data usually by sending out emails that pretend\nto be from legitimate companies in which they ask you to fill out\ninformation usually by going to a website that they link in their email\n(common phishing emails pretend to be from PayPay, Amazon, Ebay etc).\nWe have a \"phishing\"\nThis is the official Microsoft Windows Update page. On occasion\nMicrosoft will release \"updates\" and depending on which\nOperating System you have, will need to be installed on your computer.\nThe Critical updates are the most important as they \"patch\"\nknown security flaws. If you do not have the windows updates you will\nbe extremely vulnerable to security flaws, and other\nworms. Please visit: http://windowsupdate.microsoft.com\nInternet Explorer for Windows based operating systems\nThis page contains information and also the latest version\nInternet Explorer for Macintosh based operating systems\nThis page contains information and also the latest version\nit in the can)\nunsolicited (unwanted) emails sent out via mass mail. Visit the SPAM\nsection of our support page for other\nmethods of fighting SPAM. Pacific Online runs a server\nside anti-SPAM program which catches literally hundreds of thousands\nof junk mails each month. Spam is held in the quarantine section of\nwebmail, http://email.pon.net for\n10 days before being auto deleted. For more information about spam\nfiltering in webmail click\nRecommended SPAM Blocker Program:\nIf you are on a WindowsTM\nsystem we recommend using SpamPal\nAdditional SPAM Blocker Programs:\nThe following program (1.51mb) is freeware\nand is called MailWasher - it is a\nprogram that will filter incoming mail to your specifications.\nanalyses each email as it arrives and warns you if it is suspected\njunkmail or a virus. This program only analyses incoming mail - it\ndoes not send mail for you.\nThe following program (1.1mb) is freeware and is called\nWeasel - the\nprogram arrives pre-configured, collects mail from multiple POP\naccounts, & uses powerful and flexible rules to identify Spam.\nThis program also only analyses incoming mail - it does not\nsend mail for you.\nIn addition McAfeeTM\nhas an inexpensive program to fight Spam using blocking and filtering.\nThis program is called SpamKiller.\nWe recommend Net Nanny - this is a rather\ninexpensive program that lets you control what your children see on\nthe Internet. You are able to filter harmful websites, monitor online\nactivity, and even restrict Internet access.\nhere for more information.\nWith the variety and numbers\nof viruses on the Internet it is always a good idea to run a virus\nscan/cleanup on your PC. The following program is a web based online virus scanner which will scan\nand clean your PC system for viruses. Please\nMicroTM for their online virus scanner.\nIn addition, Norton AntiVirusTM\n2002 Free Trialware is available here\nPop Up Ad Remover\nPopup Killer is\nfreeware and is 62kb in size. Note: it only\nworks with Windows and MicrosoftTM\nInternet Explorer. Download,\nprogram and follow the step by step instructions. Once you have\ndownloaded this program it will appear in your System Tray on the\nStart menu bar as a small\nicon. You can toggle this program on and off by clicking your mouse on the icon\n(it is ON when the red X appears through the icon, meaning it will\nblock pop ups). You should turn Popup Killer off while using Webmail", "label": 1}
{"text": "Mismatched Wi-Fi Security SettingsSeemingly the most common cause of wireless network setup issues, incompatibility in settings between two Wi-Fi devices (such as the router and a PC) will prevent them from being able to make a network connection. Check the following settings on all Wi-Fi devices to ensure they are compatible:\n- Network mode: A router must be enabled to support all versions of Wi-Fi used by the network clients. For example, routers configured to run in \"802.11g only\" mode will not support 802.11n or old 802.11b devices. To fix this kind of network failure, change the router to run in mixed mode.\n- Security mode: Most Wi-Fi devices support multiple network security protocols (typically different variations of WPA and WEP). All Wi-Fi devices including routers belonging to the same local network must use the same security mode.\n- Security key: Wi-Fi security keys are passphrases or sequences of letters and digits. All devices joining a network must be programmed to use a Wi-Fi key recognized by the router (or wireless access point). Many home network routers (access points) support only one key that all devices must share in common. Some newer routers can store multiple Wi-Fi security keys instead of one, however, technically allowing local devices to have different key settings (although keeping their keys all the same can simply setup and troubleshooting).\nMAC Address RestrictionsMany network routers support a feature called MAC address filtering. Although disabled by default, router administrators can turn this feature on and restrict connections to only certain devices according to their MAC address number. If having difficulty getting a specific device to join the local network (particularly if it is new), check the router to ensure either (a) MAC address filtering is 'off' or (b) the device's MAC address is included in the list of allowed connections.\nLoose or Disconnected CablesSometimes the router is turned off, or someone in the family accidentally unplugs power to it. Ensure power strips are switched on and receiving electricity from the outlet, and if applicable, that any Ethernet cables are firmly seated - the connectors should make a clicking sound when snapping into position. If the router can't connect to the Internet but is otherwise operating normally, ensure any modem cables are connected properly.\nOverheating or OverloadingDownloading large files or streaming data for long periods causes a home network router to generate heat. In some cases, routers will overheat due to the sustained heavy load. An overheated router will behave unpredictably, eventually disconnecting devices from the local network and crashing. Shutting down the router and allowing it to cool down solves the problem temporarily, but if this issue occurs often, ensure the router has proper ventilation (no vents blocked) and consider moving it to a cooler location.\nHome routers can typically handle ten (10) or more connected clients, although if too many devices actively use the network at once, similar overloading problems can result. Even when not physically overheating, the high network activity can cause outages. Consider adding a second router to the network in these cases to better handle the load.\nWireless Signal LimitationsBecause the range of Wi-Fi radio signals is limited, home network connections sometimes fail because a device's radio cannot reach the router's.\nSome people also have had their functioning wireless network go offline as soon as anyone in the house turned on the microwave oven. Garage door openers and other consumer gadgets inside homes also can interfere with the signals of Wi-Fi networks, particularly those that use the 2.4 GHz radio bands.\nIt's also common in cities for the signals of several home Wi-Fi networks to intermingle with each other. Even inside their own home, a person may discover one or more of their neighbor's wireless networks when trying to connect to their own.\nTo work around these wireless radio interference and range limitations, change the Wi-Fi channel number on the router, or re-position the router. Finally, consider changing your router's name (SSID) if a neighbor is using the same one.\nDefective or Outdated Hardware or FirmwareIt's not uncommon for routers to fail after years of regular use. Lightning strikes or other electrical power surges can also damage the circuitry of network equipment. Because they have few moving parts, trying to repair network routers rarely is practical. Set aside some budget for periodically replacing your router (and any other essential network equipment). Also consider keeping some spare cables and a cheap backup router to help with emergency troubleshooting.\nBefore finally giving up a router, try updating the router's firmware first. Sometimes no firmware update will be available, but in other cases newer firmware may contain fixes for overloading or signaling issues.", "label": 1}
{"text": "(Edited: My bad, it was 1.3TB/s, not 1TB/s).\nWhat do you do when you need so much I/O performance that no one single storage system can deliver it, no matter how large?\nTo be specific: What if you needed to transfer data at 1TB per second? (or 1.3TB/s, as it eventually turned out to be)?\nThat was the problem faced by the U.S. Department of Energy (DoE) and their Sequoia supercomputer at the Lawrence Livermore National Laboratory (LLNL), one of the fastest supercomputing systems on the planet.\nYou can read the official press release here. I wanted to get more into the technical details.\nPeople talk a lot about “big data” recently – no clear definition seems to exist, in my opinion it’s something that has some of the following properties:\n- Too much data to be processed by a “normal” computer or cluster\n- Too much data to work with using a relational DB\n- Too much data to fit in a single storage system for performance and/or capacity reasons – or maybe just simply:\n- Too much data to process using traditional methods within an acceptable time frame\nClearly, this is a bit loose – how much is “too much”? How long is “too long”? For someone only armed with a subnotebook computer, “too much” does not have the same meaning as for someone rocking a 12-core server with 256GB RAM and a few TB of SSD.\nSo this definition is relative… but in some cases, such as the one we are discussing, absolute – given the limitations of today’s technology.\nFor instance, the amount of storage LLNL required was several tens of PB in a single storage pool that could provide unprecedented I/O performance to the tune of 1TB/s. Both size and performance needed to be scalable. It also needed to be reliable and fit within a reasonable budget and not require extreme space, power and cooling. A tall order indeed.\nThis created some serious logistics problems regarding storage:\n- No single disk array can hold that amount of data\n- No single disk array can perform anywhere close to 1TB/s\nLet’s put this in perspective: The storage systems that scale the biggest are typically scale-out clusters from the usual suspects of the storage world (we make one, for example). Even so, they max out at less PB than the deployment required.\nThe even bigger problem is that a single large scale-out system can’t really deliver more than a few tens of GB/s under optimal conditions – more than fast enough for most “normal” uses but utterly unacceptable for this case.\nThe only realistic solution to satisfy the requirements was massive parallelization, specifically using the NetApp E-Series for the back-end storage and the Lustre cluster filesystem.\nA bit about the solution…\nAlmost a year ago NetApp purchased the Engenio storage line from LSI. That storage line is resold by several companies like IBM, Oracle, Quantum, Dell, SGI, Teradata and more. IBM also resells the ONTAP-based FAS systems and calls them “N-Series”.\nThat purchase has made NetApp the largest provider of OEM arrays on the planet by far. It was a good deal – very rapid ROI.\nThere was a lot of speculation as to why NetApp would bother with the purchase. After all, the ONTAP-based systems have a ton more functionality than pretty much any other array and are optimized for typical mostly-random workloads – DBs, VMs, email, plus megacaching, snaps, cloning, dedupe, compression, etc – all with RAID6-equivalent protection as standard.\nThe E-Series boxes on the other hand don’t do thin provisioning, dedupe, compression, megacaching… and their snaps are the less efficient copy-on-first-write instead of redirect-on-write. So, almost the anti-ONTAP\nThe first reason for the acquisition was that, on purely financial terms, it was a no-brainer deal even if one sells shoes for a living, let alone storage. Even if there were no other reasons, this one would be enough.\nAnother reason (and the one germane to this article) was that the E-Series has a tremendous sustained sequential performance density. For instance, the E5400 system can sustain about 4GB/s in 4U (real GB/s, not out of cache), all-in. That’s 4U total for 60 disks including the controllers. Expandable, of course. It’s no slouch for random I/O either, plus you can load it with SSDs, too…\nAgain, note – 60 drives per 4U shelf and that includes the RAID controllers, batteries etc. In addition, all drives are front-loading and stay active while servicing the shelf – as opposed to most (if not all) dense shelves in the market that need the entire (very heavy) shelf pulled out and/or several drives offlined in order to replace a single failed drive… (there’s some really cool engineering in the shelf to do this without thermal problems, performance loss or vibrations). All this allows standard racks and no fear of the racks tipping over while servicing the shelves (you know who you are!)\nThere are some vendors that purely specialize in sequential I/O and tipping racks – yet they have about 3-4x less performance density than the E5400, even though they sometimes have higher per-controller throughput. In a typical marketing exercise, some of our more usual competitors have boasted 2GB/s/RU for their controllers, meaning that in 4U the controllers (that take up 4U in that example) can do 8GB/s, but that requires all kinds of extra rack space to achieve (extra UPSes, several shelves, etc). Making their resulting actual throughput number well under 1GB/s/RU. Not to mention the cost (those systems are typically more expensive than a 5400). Which is important with projects of the scale we are talking about.\nMost importantly, what we accomplished at the LLNL was no marketing exercise…\nThe benefits of truly high performance density\nClearly, if your requirements are big enough, you end up spending a lot less money and needing a lot less rack space, power and cooling by going with a highly performance-dense solution.\nHowever, given the requirements of the LLNL, it’s clear that you can’t use just a single E5400 to satisfy the performance and capacity requirements of this use case. What you can do though is use a bunch of them in parallel… and use that massive performance density to achieve about 40GB/s per industry-standard rack with 600x high-capacity disks (1.8PB raw per rack).\nFor even higher performance per rack, the E5400 can use the faster SAS or SSD drives – 480 drives per rack (up to 432TB raw), providing 80GB/s reads/60GB/s writes.\nEnter the cluster filesystem\nSo, now that we picked the performance-dense, reliable, cost-effective building block, how do we tie those building blocks together?\nThe answer: By using a cluster filesystem.\nLoosely defined, a cluster filesystem is simply a filesystem that can be accessed simultaneously by the servers mounting it. In addition, it also typically means it can span storage systems and make them look as one big entity.\nIt’s not a new concept – and there are several examples, old and new: AFS, Coda, GPFS, and the more prevalent Stornext and Lustre are some.\nThe LLNL picked Lustre for this project. Lustre is a distributed filesystem that breaks apart I/O into multiple Object Storage Servers, each connected to storage (Object Storage Targets). Metadata is served by dedicated servers that are not part of the I/O stream and thus not a bottleneck. See below for a picture (courtesy of the Lustre manual) of how it is all connected:\nHigh-speed connections are used liberally for lower latency and higher throughput.\nA large file can reside on many storage servers, and as a result I/O can be spread out and parallelized.\nLustre clients see a single large namespace and run a proprietary protocol to access the cluster.\nIt sounds good in theory – and it delivered in practice: 1.3TB/s sustained performance was demonstrated to the NetApp block devices. Work is ongoing to finalize the testing with the complete Lustre environment. Not sure what the upper limit would be. But clearly it’s a highly scalable solution.\nPutting it all together\nNetApp has fully realized solutions for the “big data” applications out there – complete with the product and services needed to complete each engagement. The Lustre solution employed by the LLNL is just one of the options available. There is Hadoop, Full Motion uncompressed HD video, and more.\nSo – how fast do you need to go?", "label": 1}
{"text": "The global body in charge of allocating Internet addresses expects to hand out the final blocks of IPv4 (Internet Protocol version 4) addresses to regional registrars early next year, it said Monday.\nThose allocations would mark a depletion at the global level of IPv4 addresses -- something that has been anticipated for years -- and put further pressure on network operators to switch to the newer IPv6 address system, which has massively more addresses available.\n[ It's time to get cracking on your IPv6 transition plan. | IPv6 laggards have to watch out for another pitfall in the transition: the black market for IP addresses, as reported by InfoWorld's Mel Beckman. | Keep up on the latest networking news with our Technology: Networking newsletter. ]\nAfter a recent allocation of IPv4 numbers to APNIC, the Regional Internet Registry (RIR) for the Asia Pacific region, the Number Resources Organization (NRO) said that the global pool of free addresses it manages now stands at just 12 blocks. Each block represents 16 million addresses, or 1/256th of the roughly 4 billion IPv4 addresses available.\n\"This is a major milestone in the life of the Internet, and means that allocation of the last blocks of IPv4 to the RIRs is imminent,\" said Axel Pawlik, NRO chairman, in a statement. \"It is critical that all Internet stakeholders take definitive action now to ensure the timely adoption of IPv6.\"\nIP addresses lie at the heart of communication on the Internet. Each computer, server and router connected to the Internet needs its own address and traffic is routed across the global network using these addresses.\nThe IPv4 addresses were defined in the early eighties. At the time the Internet consisted largely of universities and research labs and the 32-bit addresses were deemed sufficient, but about 10 years later people began worrying about a future day when IPv4 addresses would run out.\nThose worries increased in the mid-nineties when businesses and home users began connecting to the Internet. At about the same time, in 1995, the Internet Engineering Task Force published the specification for a new version of the Internet Protocol, IPv6, which moved from 32-bit addresses to 128-bit addresses.\nThe new protocol brought a massive increase in the number of available addresses, but the two systems were incompatible so adoption was slow. Technologies like NAT (network address translation), which allow several devices to share the same IPv4 address, have delayed the inevitable exhaustion of IPv4 addresses, but now that moment is near.\nThe NRO issues blocks of numbers to five regional registries, which in turn issue them to companies and organizations in their respective regions. The final five blocks will be distributed equally to the registries, meaning there are only seven more blocks available under the normal distribution system, the NRO said. Current depletion rates point to NRO issuing the final blocks in early 2011, it said.\nThe addresses will be held by the regional registries for issue in their region, so the actual issue of the final IPv4 addresses to end-users won't come until sometime later in 2011.", "label": 1}
{"text": "Content Management Systems Security and Associated Risks\nCompromised web servers are increasingly being utilized by malicious actors to carry out cyber attacks, such as distributed denial-of-service attacks against critical infrastructure companies around the world. These web servers offer increased networking and computing capacity compared with average user workstations, and are therefore a target of choice for malicious actors to build their attack infrastructure. For this reason, it is imperative to secure servers according to best practices, and thus limit their exposure to control by potentially malicious actors.\nSpecifically, the compromised servers running Content Management Systems (CMSs) are consistently targeted and leveraged to launch cyber attacks. CMSs are software suites that allow site administrators to easily manage the design, functionality, and operation of websites with minimal technical expertise. In recent years there has been an increase in the number of deployments of CMS software on the Internet. This has been fueled by popular open source projects which are freely available under General Public License (GPL) model. Unfortunately, some CMS web server operators are not following security best practices, exposing them and others to cyber security risks such as compromise and denial of service.\nJoomla! is one of the most widely used CMSs in the world. It is PHP-based and allows rapid deployment of dynamic content on websites. It is recognized for its simplicity of deployment and usage while offering extensive features and plugins. However, like many other large software packages, Joomla! has been the subject of a number of vulnerabilities in recent years and, if left unpatched, can represent a risk for site owners, and any other Internet users.\nThe Canadian Cyber Incident Response Centre and US-CERT are aware of malicious actors exploiting unpatched CMS installations, primarily Joomla! installations, to gain control of web servers and launch distributed denial-of-service (DDoS) attacks against critical infrastructure organizations.\nIn general, web site administrators should strive to follow patching instructions from their software providers. Additional security practices and guidance are made available by community efforts such as The Open Web Application Security Project (OWASP) and US-CERT's Technical Information Paper TIP-12-298-01 on Website Security.\nJoomla! and other CMS packages regularly update their software as vulnerabilities are reported and patches are developed. The National Institute of Standards and Technology (NIST) National Vulnerability Database (NVD) provides assessments of such vulnerabilities, accompanied by links to specific remediation activities for users and administrators to follow.\nSpecifically, administrators of Joomla! CMS servers should ensure their installation includes the latest software version available. Additionally, administrators should consider guidance found under the Joomla! community security section and review the following best practices:\n- To the extent possible, maintain moderator control for the creation of user accounts. This may limit the use of automated account creation tools and associated automated posting of malicious content or even site compromise.\n- Ensure underlying server operating systems, services and software packages, especially third party plugins, are patched and up-to-date.\n- Limit common security threat access by leveraging the security capabilities of the .htaccess file of the Apache web server (or equivalent access control features of Nginx or Microsoft IIS).\n- Ensure accounts and files permissions are set properly, including changing the default administration user name and password.\n- Enforce strong user password policy.\n- Limit version number exposure of extension files by changing their default name to avoid remote automated scanning looking for specific version for which exploits may exist.\n- Implement SSL certificates and ensure that non-encrypted sessions fail rather than defaulting to insecure connections. This is especially important in payment processing extension.\n- Remove unused services and associated files.\n- Consider deployment of a server security monitoring solution including anti-virus. Additionally, security monitoring and logging including administrative login attempts should be considered.\n- January 24, 2013: Initial release", "label": 1}
{"text": "In the rush to create mobile apps that work across the leading smartphones and tablets, many developers have leaned heavily on web development tools and use embedded browsers as part of their packaged applications. But security researchers have shown that relying on browser technology in mobile apps—and even some desktop apps—can result in hidden vulnerabilities in those applications that can give an attacker access to local data and device features through cross-site scripting.\nOsborn said other vulnerabilities that have been discovered, and that in most cases have now been patched, include Skype on Apple's iOS and Gmail on Android and iOS. The vulnerabilities aren't limited to mobile platforms—many desktop applications that use Webkit or another web rendering engine have also had issues, Osborn said. The Skype vulnerability was originally discovered on Mac OS X, and similar bugs have been discovered and patched in the Adium instant messaging client on OS X and Empathy social networking client on Ubuntu.", "label": 1}
{"text": "You’re probably one of the lucky people. You live within the coverage zone of a 3G or 4G cellular network, you have access to Internet at home and work over a connection measured in tens of megabits per second, and when you turn on your laptop (or your tablet, or your smartphone) you can see three, four, or twenty nearby WiFi networks. Cloud computing was invented for people like you—but it might turn out to be of even more benefit to the billions of people who don’t own a computer—those dark places on Facebook’s map of connections—and whose lives could be changed dramatically by a couple of mobile apps.\nTake Africa, for instance, where an emerging information technology industry is betting its future on serving customers and businesses through mobile cloud applications. At the same time, governments and non-governmental organizations are betting that cloud-based technology can help transform their economies and societies, spurring improvements in education, public health, and the environment.\nIt sounds great, but making the cloud work in Africa remains a non-trivial problem. Just ask anyone who has run a data center there—they will tell you how expensive and frustrating it can be to work on a continent where it’s often cheaper to connect back to an overseas data center from a co-location facility than to connect with a customer a few miles away; where most people don’t even have landline, let alone wired Internet; and where the electrical grid could suddenly stop working for hours or even days at a time.\nThose very challenges make Africa an increasingly attractive proving ground for cloud computing, though, especially for mobile applications. Out of the one billion people in Africa, only an estimated 140 million use the Internet, but over 600 million use mobile phones, according to data from the World Bank.\nAt the East Africa Outsourcing Summit in Nairobi on June 6, Kenya ICT Board CEO Paul Kukubo said, “The world is beginning to pay attention to the idea that even in Africa, if you can solve African problems, you can create an IT product that is attractive to the rest of the world.” As the tagline of Shimba Technologies, a Nairobi-based mobile application developer, says, “If it works in Africa, it will work anywhere.”\nWhile the problems Africa faces in terms of making cloud computing work are uniquely African, the solutions developed there could help to provide more universal access to Internet and cloud services elsewhere—including underserved areas here in the US.\nBleeding for bandwidth, gasping for power\nBroadband availability in Africa has been a major issue for both business and personal access to the cloud. Fortunately, African bandwidth has improved dramatically over the past few years—especially for businesses looking to connect to cloud resources elsewhere in the world.\nBefore 2001, aside from South Africa, most of the continent’s Internet connectivity was limited to satellite-based uplinks (some sponsored by a USAID project in the late 1990s) and analog telecommunications connections. The South Atlantic 3/West Africa Submarine Cable went live in 2001 and gave much of western Africa its first reliable, terrestrial, and digital connection with a bandwidth of 340Gbps. But the cost of connecting over the cable was astronomical—an E1 connection (much like a T1 line in the US) in South Africa used to cost $300,000 a month.\nIn the mid-2000s, the situation remained bad across much of the continent. One paper on African broadband (PDF) provides a typical example of how pricing discouraged actual use of the Internet, all the way down to the very local level. \"Mbarara University [of Uganda] pays US$2,190 per month for a bandwidth of 384kbps,\" wrote G.M. Muwanga, who works at the school. \"This translates into very slow and frustrating Internet connectivity, and to prevent slowing the system even further, many computers on university campus are not connected to the Internet.\"\nEven in places like South Africa, the bandwidth situation was tough. Barry Gill, an enterprise consultant for e-mail software-as-a-service provider Mimecast, helped launch the company’s first offerings in South Africa in 2005. “We had one server hosted in a rack moving less than a gigabyte of data a month,” he said in a phone interview with Ars, “but the cost of that per month was more than my salary. That was a massive problem for us.”\nSince 2009, seven more undersea cable networks have gone live to the continent. South Africa’s fifth cable, the West Africa Cable System (WACS), was activated in May, and its 11 percent share of cable capacity brings South Africa’s national bandwidth up to about 8 terabits per second. That increase in capacity has lowered the cost for Mimecast to connect to the company’s overseas data centers. But the cost of connecting within South Africa is still high. “Buying bandwidth to get from Point A to Point B within South Africa costs more than getting to the US or Asia,” Gill said.\nGill had come to Mimecast from the Botswana Telecommunications Corporation’s Internet service provider subsidiary, so he \"knew everyone in the ISP game.\" That turned out to be a good thing. By the end of 2005, Mimecast’s operation had grown from one Intel-based server to eight AMD-based Sun Microsystems servers configured in two separate “data centers” on separate cooling and power (but just across the hall from each other in the same building). But Gill had a hard time finding someone to provide him with crossover connectivity between them.\n“I was approaching Verizon and others, saying ‘I need cross connections,’” he said, but he had a hard time finding someone who could help. Before they finally negotiated a solution with a provider, Gill said, “We were prepared to spend close to one million rand (around US$120,000) for a microwave link, but we needed someone licensed to do it.”\nAlex Laverty is a graduate student cross-enrolled in the University of California Los Angeles’ African Studies and the University of Southern California Annenberg School’s public diplomacy programs; he formerly worked in South Africa for Trans Africa Forum and Human Rights Watch, and now he tracks information technology issues in Africa for The African File website.\nIn a conversation with Ars, Laverty said that bandwidth in countries like South Africa is actually available—“if you can afford to pay for it.” But it's the price of broadband that still challenges anyone looking to use cloud-based services.\n“What's holding it up is the lack of competition,” he said. “The telecoms used to be state-run organizations, and they still have dominance in reach. When I was there in 2010, the second provider of broadband had just launched, and they were offering competitive pricing, but in terms of availability it just wasn’t there.”\nNairobi has another sort of bandwidth problem. Laverty said that as demand for bandwidth in Nairobi has increased with the growth of the IT business there, so has the worst kind of competition. “Broadband providers won't share fiber optic cables,” Laverty said, “so they're all running their own cables to the wealthy areas of Nairobi. The competition is so fierce that people are digging up competitors’ cables and cutting them.”\nAside from the issues with wired broadband, would-be cloud service providers in Africa face another serious problem: the power grid. “South Africa is very first-world in many things,” Gill said, but electrical service is not one of them. “People are cursing the incumbent power provider all the time.”\nGill said that Mimecast’s South African data center providers “say they have hundreds of diesel generators on hand, and they fire these things up all the time. They have contracts with fuel providers to get resupplied, because they’ll chew through two or three thousand gallons of diesel over a weekend, with no guarantee that the power will be coming back on.” There are still cases where the power will go away for three to four days with no warning or explanation.\nAlong with the unreliability, there’s a lack of electrical capacity. “If you’re in a power-hungry environment, there’s not enough power being generated to keep you going,” Gill said. “The power stations are in a state of disrepair and getting decommissioned, and there are nuclear reactors that were never commissioned. You end up chasing around whatever providers there are” to try to keep operations going.\nFor those reasons, Mimecast isn’t interested in building its own data center in South Africa anytime soon. While the company has just built out a new set of data centers within another provider’s facility, Gill said, “The cost of deploying generators is so significant, we’d rather have a third party bear that cost.”", "label": 1}
{"text": "The name given to a method by which your online personal data is hacked and exposed. Because some Wi-Fi networks are unsecure, \"sidejacking\" works like this: When you login to a secure Web site or browse the Web on an unsecured Wi-Fi network, the fact is everything from the contents of your e-mail to who your friends and acquaintances are, could be easily exposed by hackers.\nEven though some sites, such as Gmail, offer secure, SSL-based login pages, things aren't as secure after you login. Unlike many bank Web sites that offer a secure browsing experience for the entire duration of the session, most sites dump the user right back out into unsecured territory after logging in, thus exposing their personal data to anyone who wants to get at it.\nThe solution is to stick to secured Wi-Fi networks that you know and trust (such as your home network that would not have any strangers on it running packet sniffers). But when you do need to use public access points, avoid accessing Web pages that might transmit personal information. For those of you who want to be extremely careful, you should never use a Wi-Fi hotspot unless you are using VPN (virtual private networking) or SSL (secure sockets layer) to access your accounts.\nNetLingo Classification: Net Technology\nSubscribe to Word of the Day - Email this Definition to a Friend", "label": 1}
{"text": "Virtualization allows administrators to create virtual versions of resources such as a hardware platform, operating system, storage device, or network resource. This process allows the creation of multiple versions of a resource on a single physical machine. This configuration allows the advantages of multiple resources while simplifying management tasks and improving use of physical resources. In this way, virtualization can be used to enhance IT service performance, scalability, efficiency, availability, and security. Configuring these virtual machines requires the use of hypervisor software.\nHowever, network switches are not aware of virtual machines. If you run each virtual machine on a dedicated set of servers, performance and security needs can be met by configuring the network settings for each servers. However, this nullifies the main benefits of virtualization. You can get better IT service performance, scalability, efficiency, and availability by creating multiple virtual resources on the same server. For this configuration, you need a way to apply unique network settings for each virtual resource.\nIBM® VMready® is a software solution that supports open standards virtualization based on IEEE 802.1Qbg Edge Virtual Bridging. It allows administrators to create groups of virtual machines, administer them from a central location, and migrate them. VMready works with all major hypervisor software, including VMware, Microsoft Hyper-V, Linux Kernel-based Virtual Machine (KVM), Citrix XenServer, or IBM PowerVM®. It requires no proprietary tagging or changes to the hypervisor software. This IBM Redbooks® publication helps IT systems and networking professionals to understand IBM VMready technology options. It includes instructions on how to install, tailor, and configure VMready networking solutions.\nTable of contents\nPart 1. Virtualization and VM-aware networking overview\nChapter 1. What you need to know about system virtualization\nChapter 2. Introducing VMready\nChapter 3. Management for VMready\nPart 2. Implementing a VM-aware network\nChapter 4. Implementing VMready to support VMware\nChapter 5. Implementing VMready to support PowerVM\nChapter 6. Implementing VMready to support KVM\nChapter 7. Implementing VMready to support Hyper-V and other virtualization environments\nOthers who downloaded this publication also downloaded", "label": 1}
{"text": "From time to time when we mange an active directory or even a local computer we may need to reset user accounts, and we reset user accounts by resetting the password as we know a user must have both their names and their passwords in order to logon to the system. So, we reset their password. We are resetting their ability to gain access to resources. This might happen if the user forgets their password. We should be aware that the complexity of the systems in today's network resetting their password might not solve the entire problem. For example if they have keys that are associated with that password for access to other resources they may still have a problem. In another words their encryption keys are not going to work with the new password. Any internet passwords that they have that are based on their password will have to be reset as well. So it is just the beginning of a series of ** they may have to go through if they forget their password. So it is a training issue. User should be encouraged to use a complex password but also what is easier for them to remember. We also might need to reset computer accounts for example if we have restored a computer from a backup but the system would have put a different password. In another words the domain controller transfer password information that is it is automatically transferred between computers. If we have restored from backup there was previous to the current password than the password that the computer has will be out of date. So we need to reset the password at the computer. Let us take a look how we do each of these. So, we are going to go to active directory users and computers and we are going to go into the sales OU where Susan Brown is located and let us say we wanted to reset Susan Brown's password. Let us say Susan Brown calls us, \"I can get on to the network, I am sorry I forgot my password\", then we right click on Susan Brown's account, click on reset password and then we will type in a new temporary password for her, whatever we want to type in. Whatever is the standard that our company is using and then we click on user must change password in next logon. So, then we can tell Susan look I have reset your password, it is just temporary. This is your new password tell or on the phone or you can even send her an email. Because it will be just a temporary password to get into her account until she changes it at her next logon. This should be very soon. So, that way we can get Susan Brown's password reset. You should know this both for the real life as well as for the test. But there are going to be some issues with regards to encryption keys regards to internet password options as well. So Susan Brown now is taken care of the user account. I have a computer account, say that this computer click on computers, say this computer PC1, is out of date because we had to restore it from a backup and now the active directory is basically saying I cannot authenticate this machine. It does not have a valid password. We can reset the password by right clicking on PC1 and click on reset account. The system says, are you sure, you want to reset this computer account? We click on Yes and that is all to restore. So, we can reset user passwords and we can reset the computer accounts what we should be aware that in order to reset a user password, that is a domain user we must be a domain admin or some one with delegated permissions to be able to reset the password. And in order to reset a password for a user that is local to your machine first of all you can not use active directory user and computers, we have to use computer management console and then we will have to be a local administrator to reset that password. And regards to resetting account for computers we have to be either a domain admin and enterprise admin or an account operator in order to reset these accounts. You should be aware of this for real life as well as for the test. In addition to resetting the password we manage users and computers by putting them into the right places. And we can put them into right place when we create them, in another words in the right OU. But, things change in organization so we may want to move objects around. And we have new tools to move these objects around and Windows Server 2003. So in our next section we will discuss moving domain objects.\nTERMS & CONDITIONS OF USE\nBY SUBSCRIBING TO THIS SERVICE, YOU ARE CONSENTING TO BE BOUND BY AND ARE BECOMING A PARTY TO THIS AGREEMENT, THE TERMS AND CONDITIONS OF WHICH SHALL PREVAIL IN GOVERNING YOUR RIGHTS OF USE. BY CLICKING THE \"BECOME A MEMBER\" BUTTON, THE INDIVIDUAL OR ENTITY LICENSING THE PRODUCT (\"YOU\") IS CONSENTING TO BE BOUND BY AND IS BECOMING A PARTY TO THIS AGREEMENT. IF LICENSEE DOES NOT AGREE TO ALL OF THE TERMS OF THIS AGREEMENT, THE BUTTON INDICATING \"BECOME A MEMBER\" MUST NOT BE SELECTED, AND LICENSEE MUST NOT INSTALL OR USE THE SOFTWARE.\n\"VTC\" refers to Virtual Training Company,\n\"You\" refers to the user or subscriber.\n\"Software\" refers to the VTC training content and software.\n2. LICENSE: VTC hereby grants to You a worldwide, non-royalty bearing, non-exclusive license to use the Software according to the provisions contained herein and subject to payment of the applicable subscription fees.\n3. RESTRICTIONS: You may not do any of the following:\nSave the Software to Your hard disk or other storage\nmedium; permit others to use the Software except as specified by addendum;\nmodify, reverse engineer, decompile, or disassemble the Software; make\nderivative works based on the Software; publish or otherwise disseminate\nthe Software. VTC, Inc., VTC Online University, and the Virtual Training\nCompany site is owned and operated by VTC, Inc. as a corporation of\nAll materials on this site are the property of VTC unless otherwise specified. No material from these pages may be copied, reproduced, republished, downloaded, uploaded, posted, transmitted, or distributed in any way. Modification of the materials or use of the materials for any other purpose is a violation of U.S. copyright law and other proprietary rights. For purposes of this Agreement, the use of any such material on any other web site or networked computer environment is prohibited.\n4. FEES: The rights granted under this Agreement\nare effective only upon payment of the subscription fees, which are\nstrictly non-refundable other than as expressly provided herein. The\nterm \"monthly subscription\" is defined as any 30 day period.\nThe term \"yearly subscription\" is defined as one 365 day\nperiod. A yearly subscription ends on the same numerical date as it\nbegan (example July 28, 2004 to July 28, 2005).\nThe VTC Online University is access to every VTC training tutorial in our library. You pay a flat fee for access to these titles. You are billed according to your renewal selection below, and can renew monthly, yearly, or in any other increment offered. If you choose to be billed monthly, you will be billed every 30 days for the subscription until you request the subscription be cancelled. Our terms of service state that you must cancel a monthly subscription at least two business days before your renewal date. These two days give us enough time to ensure that you will not be charged again.\n5. LIMITED WARRANTY: VTC warrants that the Software, if operated as directed, will substantially achieve the functionality described. VTC does not warrant, however, that Your use of the Software will be uninterrupted or that the operation of the Software will be error-free or secure. In addition, the security mechanisms implemented by the Software have inherent limitations, and You must determine that the Software sufficiently meets Your requirements. VTC also warrants that the media containing the Software, if provided by VTC, is free from defects in material from the date You acquired the Software. VTC's sole liability for any breach of this warranty shall be, in VTC's sole discretion: (i) to replace Your defective media or Software; or (ii) to advise You how to achieve substantially the same functionality with the Software as described; or (iii) if the above remedies are impracticable, to refund the subscription fee You paid for the Software. Only if You inform VTC of Your problem with the Software during the applicable subscription period will VTC be obligated to honor this warranty. VTC will use reasonable commercial efforts to repair, replace, advise, or refund pursuant to the foregoing warranty within thirty (30) days of being so notified. If any modifications are made to the Software by You during the warranty period; if the medium is subjected to accident, abuse, or improper use; or if You violate the terms of this Agreement, then this warranty shall immediately terminate. This warranty shall not apply if the Software is used on or in conjunction with hardware or software other than the unmodified version of hardware and software with which the Software was designed to be used as described.\nTHIS IS A LIMITED WARRANTY, AND IT IS THE ONLY WARRANTY MADE BY VTC OR ITS SUPPLIERS. VTC MAKES NO OTHER WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT OF THIRD PARTIES' RIGHTS. YOU MAY HAVE OTHER STATUTORY RIGHTS. HOWEVER, TO THE FULL EXTENT PERMITTED BY LAW, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, SHALL BE LIMITED TO THE ABOVE LIMITED WARRANTY PERIOD. MOREOVER, IN NO EVENT WILL WARRANTIES PROVIDED BY LAW, IF ANY, APPLY UNLESS THEY ARE REQUIRED TO APPLY BY STATUTE NOTWITHSTANDING THEIR EXCLUSION BY CONTRACT. NO DEALER, AGENT, OR EMPLOYEE OF VTC IS AUTHORIZED TO MAKE ANY MODIFICATIONS, EXTENSIONS, OR ADDITIONS TO THIS LIMITED WARRANTY.\n6. PROPRIETARY RIGHTS: VTC reserves all proprietary rights in and to the Software, is protected by copyright and other intellectual property laws and by international treaties. VTC, Inc.\nTrademark Notice: VTC, Virtual Training Company,\nInc., The VTC Logo, and VTC Online University, are trademarks of VTC,\nInc. All other company and product names may be trademarks of their\nThe information contained herein is subject to change without notice. Copyright © 1995 - 2005 VTC, Inc. All rights reserved.\n7. TERMINATION: This Agreement shall automatically terminate if You fail to comply with the restrictions described herein. Your obligations to pay outstanding subscription fees shall survive any termination of this Agreement.\n8. LIMITATION OF LIABILITY: UNDER NO CIRCUMSTANCES\nAND UNDER NO LEGAL THEORY, TORT, CONTRACT, OR OTHERWISE, SHALL VTC\nOR ITS SUPPLIERS OR RESELLERS BE LIABLE TO YOU OR ANY OTHER PERSON\nFOR ANY INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF\nANY CHARACTER, INCLUDING WITHOUT LIMITATION, DAMAGES FOR LOSS OF GOODWILL,\nWORK STOPPAGE, COMPUTER FAILURE OR MALFUNCTION, OR ANY AND ALL OTHER\nCOMMERCIAL DAMAGES OR LOSSES. IN NO EVENT WILL VTC BE LIABLE FOR ANY\nDAMAGES IN EXCESS OF THE AMOUNT VTC RECEIVED FROM YOU FOR A LICENSE\nTO THE SOFTWARE, EVEN IF VTC SHALL HAVE BEEN INFORMED OF THE POSSIBILITY\nDAMAGES, OR FOR ANY CLAIM BY ANY OTHER PARTY. THIS LIMITATION OF LIABILITY SHALL NOT APPLY TO LIABILITY FOR DEATH OR PERSONAL INJURY RESULTING FROM VTC'S NEGLIGENCE TO THE EXTENT APPLICABLE LAW PROHIBITS SUCH LIMITATION. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OR LIMITATION OF INCIDENTAL OR CONSEQUENTIAL DAMAGES, SO THIS EXCLUSION AND LIMITATION MAY NOT APPLY TO YOU.\n9. Links To Other Materials: Linked sites found at the VTC site are not under the control of VTC, and we are not responsible for the content of any linked site or any link contained in a linked site. VTC may change links based solely on our discretion, and we reserve the right to terminate any link or linking program at any time. VTC does not, by linking to sites, endorse companies or products to which it links and reserves the right to note as such on its web pages. If you decide to access any of the third party sites linked to this site, you do this entirely at your own risk.\nForums, and Chat are not always screened by VTC, and we are not responsible for the content of any public or open forum content at the site. VTC may change these public forums based solely on our discretion, and we reserve the right to terminate any forum at any time. VTC does not, by allowing these forums, endorse companies or products which may be mentioned in these forums, and reserves the right to note as such on its web pages. If you decide to access any of the public forums in this site, or linked to this site, you do this entirely at your own risk.\n9. GOVERNING LAW & DISPUTE RESOLUTION: This Agreement is governed by Virginia law. All disputes between You and VTC shall be finally resolved through arbitration in Winchester, Virginia. This site is controlled by VTC from its offices within the United States of America. VTC makes no representation that materials in the site are appropriate or available for use in other locations, and access to them from territories where their content is illegal is prohibited. Those who choose to access this site from other locations do so on their own initiative and are responsible for compliance with applicable local laws. You may not use or export the Materials in violation of U.S. export laws and regulations. Any claim relating to the Materials shall be governed by the internal substantive laws of the Commonwealth of Virginia, USA.\nVTC may revise these Terms at any time by updating this posting. You should visit this page from time to time to review the then-current Terms because they are binding on you. Certain provisions of these Terms may be superseded by expressly designated legal notices or terms located on particular pages at this Site.\nIf you have any questions regarding this policy,\nor your information specifically,\nyou may email us at:email@example.com.", "label": 1}
{"text": "Virtualization is a key enabling technology for the modern datacenter. Without virtualization, tricks like load balancing and multitenancy wouldn't be available from datacenters that use commodity x86 hardware to supply the on-demand compute cycles and networked storage that powers the current generation of cloud-based Web applications.\nEven though it has been used pervasively in datacenters for the past few years, virtualization isn't standing still. Rather, the technology is still evolving, and with the launch of I/O virtualization support from Intel and AMD it's poised to reach new levels of performance and flexibility. Our past virtualization coverage looked at the basics of what virtualization is, and how processors are virtualized. The current installment will take a close look at how I/O virtualization is used to boost the performance of individual servers by better virtualizing parts of the machine besides the CPU.\nPart 1 described three ways in which a component might be virtualized; emulation, \"classic\" virtualization, and paravirtualization, and part 2 described in more detail how each of these methods was used in CPU virtualization. But the CPU is not the only part of a computer that can use these techniques; although hardware devices are quite different from a CPU, similar approaches are equally useful.\nI/O basics: the case of PCI and PCIe\nBefore looking at how I/O devices are virtualized, it's important to know in broad terms how they work. These days most PC hardware is, from an electronic and software perspective, PCI or PCI Express (PCIe); although many devices (disk controllers, integrated graphics, on-board networking) are not physically PCI or PCIe—they don't plug into a slot on the motherboard—the way in which they are detected, identified, and communicated with is still via PCI or PCIe.\nIn PCI, each device is identified by a bus number, a device number, and a device function. A given computer might have several PCI buses which might be linked (one bus used to extend another bus, joined through a PCI bridge) or independent (several buses all attached to the CPU), or some combination of the two. Generally, large high-end machines with lots of I/O expansion have more complicated PCI topologies than smaller or cheaper systems. Each device on a bus is assigned a device number by the PCI controller, and each device exposes one or more numbered functions. For example, many graphics cards offer integrated sound hardware for use with HDMI; typically the graphics capability will be function zero, the sound will be function 1. Only one device can use the bus at any given moment, which is why high-end machines often have multiple independent buses—this allows multiple devices to be active simultaneously.\nPCIe operates similarly. PCIe is a point-to-point architecture rather than a bus architecture; rather than all devices (and all hardware slots) on the same bus being electrically connected, in PCIe there are no connections between devices. Instead, each device is connected solely to the controller. Each connection between device and controller is regarded as its own bus; devices are still assigned numbers, but because there can only be one device on each \"bus,\" this number will always be zero. This approach allows software to treat PCIe as if it were PCI, allowing for easier migration from PCI to PCIe. This point-to-point topology alleviates the bus contention problem in PCI—since there is no bus sharing, there are fewer restrictions on concurrent device activity.\nActual data transfer to and from the device can use three mechanisms—system memory, x86 I/O ports, and PCI configuration space. x86 I/O ports are there to provide legacy compatibility, and PCI configuration space is used primarily for configuration. The main way that the OS communicates with PCIe devices is through system memory; this is the only mechanism that allows for large, general-purpose transfers. (With I/O ports, reads and writes are limited to 32 bits, and the CPU must take action after every single read or write, making communication slow and processor-intensive. And PCI configuration space is limited to 256 bytes, and used only for device configuration). Each device is assigned a block of system memory to which it can read and write directly (\"DMA,\" direct memory access). For I/O devices requiring bulk transfers—disk controllers, network adaptors, video cards—this is the primary communication mechanism, as each of these devices performs regular large transfers.\nWhen software wants to tell a PCI device to do something, the host delivers a command to the bus. Each device inspects the command, and acts on it if necessary. When the device wants to tell the CPU to do something—either because it has completed a command, or received some data—it interrupts the CPU, which in turn executes the device driver. PCI interrupts are generally delivered using 4 physical interrupt connections. These connections are shared between all devices on the same bus, so the device driver must then examine the interrupt to ensure it is handled properly. PCIe interrupts do not use physical hardware; instead, a message is sent to the device driver by writing to the block of memory assigned to the device—PCIe uses the same system for interrupts as it does for data transfer. This avoids the need to share interrupt lines, by enabling interrupts to be directed specifically and solely to the device that needs them.\nVirtualizing PCI and PCIe\nSo, how do these things get virtualized? The first approach is emulation. Just as CPU emulation requires an entire virtual CPU to be run \"in software,\" the same is true of device emulation. Generally, the approach taken is for the virtualization software to emulate well-known real-world devices. All the PCI infrastructure—device enumeration and identification, interrupts, DMA—is replicated in software. These software models respond to the same commands, and do the same thing as their hardware counterparts. The guest OS will write to its virtualized device memory (whether it be system memory, x86 I/O, or PCI configuration space), and trigger interrupts, and the VMM software will respond as if it were real hardware. Even this interrupt signalling uses emulation; one of the emulated devices is an interrupt controller.\nThis \"response\" generally means making an equivalent call to the host OS. So, for example, to write some data to disk, the guest OS will use its driver to write that to the disk controller's device memory, which sits inside a device model—a kind of virtual controller—along with the PCI configuration space and a virtual version of the controller chip. Then, using an interrupt sent via the VM's virtual interrupt controller, the guest OS commands the VMM's virtual disk controller to write that to a particular location on the disk. In turn, the VMM's disk controller will tell the host OS to write the data to a particular spot in a file (or, when used with so-called raw disks, to a particular spot on disk). The host OS then does the same thing as the guest OS—it copies the data to the disk controller's device memory via its driver and signals an interrupt.\nIn the diagram above, you can see that there's an entire virtual device and a virtual interrupt controller in the VM, and then another pair of these in the VMM. That's two layers of emulation before you get to the hardware. (The one element of the diagram above that's probably not at all self-explanatory is the little tab with gears on it beneath the OS. That's the device driver, and device model in the VMM uses it to interface with the hardware.)", "label": 1}
{"text": "Google has created a new mobile app that gives people facts about the places around them — unprompted, without the need to even ask for the information.\nThe app, Field Trip, offers historical trivia about a park, an architectural factoid about a building or reviews of a nearby restaurant. Google says it’s like having a local friend with you as you make your way through a city.\n“The idea behind the app was to build something that would help people connect with the real, physical world around them,” said John Hanke, a vice president of product at Google who runs a small lab at the company building location-based and social mobile apps. “It’s always running in the background, so it knows where you are and is always looking to see if something interesting is in your immediate physical environment.”\nWhile the app might seem small, it reveals a lot about the big directions Google wants to go.\nGoogle, along with other companies and researchers, dreams of so-called ubiquitous computing or ambient intelligence — computers woven into the texture of life as opposed to being separate machines. Eventually, the theory goes, computers will be part of the environment, know where people are and anticipate what they want to know.\nThe Field Trip app is a small step in that direction, and an example of what Google is capable of doing. Another is Google Glass, the Internet-connected eyeglass frames with a small screen. With Field Trip, Google is trying to move beyond the first generation of mobile apps, which were not much more than desktop transplants, Mr. Hanke said.\nGoogle wants to “move the device out of your way and put the information front and center,” he said, so people can “scan the environment and know what the Web knows about the places around you.”\nFans of “Iron Man,” “The Terminator” or William Gibson’s science fiction will recognize this idea of augmented reality, he said. “What we’re doing is essentially building the information framework and tools to enable that kind of experience in the future.”\nMore immediately, Field Trip is a big step toward helping Google get its services and ads in front of mobile users. While it has long been a dream of advertising companies to deliver ads to people on their phones when they are near a business, that is still relatively rare. But with Field Trip, Google is able to show restaurant reviews from its Zagat service or sell deals from Google Offers or city tours from Vayable, all based on a person’s location.\nIn addition to Google’s own services, most of the information in Field Trip comes from a few dozen publishing partners, some esoteric, including Arcadia Publishing, Atlas Obscura, Curbed, Eater and Cool Hunting.\nField Trip uses signals from nearby cellphone towers to determine a user’s location. Its users can choose from which publishers they receive alerts — so they could turn off alerts for Google Offers, for instance — and how frequently they want to receive them. They can also choose not to receive alerts, in which case they open the app to find information.\nUsers can also ask Field Trip to read them notifications if the phone is connected to a headset or Bluetooth or if they are driving — and the app will determine on its own that they are driving based on how fast they are moving.\nMr. Hanke, who co-founded Keyhole, a mapping start-up that Google bought to help it develop maps, was the head of Google Maps for several years. Last year, he decided he wanted to leave Google to found another start-up. But Larry Page, Google’s chief executive, persuaded him to stay, Mr. Hanke said, and start a small lab in San Francisco. He named it Niantic Labs, after a ship that traveled to San Francisco during the Gold Rush.\nField Trip is available for Android phones; Google is working on an iPhone version. To introduce the app, Google on Saturday is playing host at parties in New York, San Francisco, Los Angeles, Boston, Chicago and Minneapolis for people to explore the cities. Attendance is free. Registration is at FieldTripDay.com.", "label": 1}
{"text": "Analysis of the USA Patriot Act related to Libraries\nThe Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act of 2001 (“USA Patriot Act”) became law on October 26, 2001. The legislation originated with Attorney General John Ashcroft, who asked Congress for additional powers that he claimed were needed to fight terrorism in the wake of the events of September 11, 2001. Few amendments were made to Ashcroft’s initial proposal to Congress, and the bill became law without any hearings or markup by a Congressional committee.\nThe Patriot Act amended over 15 federal statutes, including the laws governing criminal procedure, computer fraud and abuse, foreign intelligence, wiretapping, immigration, and the laws governing the privacy of student records. These amendments expanded the authority of the Federal Bureau of Investigation and law enforcement to gain access to business records, medical records, educational records and library records, including stored electronic data and communications. It also expanded the laws governing wiretaps and “trap and trace” phone devices to Internet and electronic communications. These enhanced surveillance procedures pose the greatest challenge to privacy and confidentiality in the library.\nEnhanced Surveillance Provisions Affecting Library Confidentiality\nSection 215: Access to Records Under Foreign Intelligence Security Act (FISA)\n- Amends the business records provision of the Foreign Intelligence Surveillance Act (FISA) to allow FBI agents to obtain \"any tangible thing,\" which includes books, records, papers, floppy disks, data tapes, computers and their hard drives, and any type of record in any format. Prior to the PATRIOT Act, FISA only permitted agents to obtain car rental records, hotel records, storage locker records, and common carrier records for a foreign agent.\n- Allows FBI agents to ask the Foreign Intelligence Surveillance Court (FISC) to issue an ex parte, secret court order to obtain any kind of record or tangible thing when the record sought is for an investigation into terrorism or foreign espionage.\n- Lowers the legal standard for obtaining a court order under FISA. Under the new FISA, the agent need only \"specify that the records concerned are sought for an authorized investigation\" in order to obtain a warrant from the special FISA court. Prior to the PATRIOT Act, the agent needed to demonstrate \"probable cause\" that the target of the investigation was an agent for a foreign power.\n- Allows investigations to target U.S. citizens, as long as the investigation is not based solely upon activities protected by the First Amendment. (Note that this does not exclude investigations into acts and behavior that may include First Amendment protected activities.) Prior to the PATRIOT Act, FISA could only be used when pursuing non-citizen foreign agents.\n- Prohibits the library from notifying the patron under suspicion, the press, or anyone else that a warrant has been served upon the library, or that records have been surrendered.\n- Under the rules of the FISA Court, only FBI agents or authorized U.S. attorneys can appear before the FISA court, eliminating any possibility of challenging the order.\nCodified at 50 U.S.C. Â§ 1862\nSection 216: Relating to the Use of Pen Register and Trap and Trace Devices\n- Grants expanded wiretapping authority to federal and state law enforcement agencies that allows monitoring of public computers under the Electronic Communications Privacy Act (ECPA).\n- Extends the telephone monitoring laws (\"pen register,\" \"trap and trace\") to include routing and addressing information for all Internet traffic, including email addresses, IP addresses, and URLs of Web pages.\n- FBI may install hardware or software on your network to accomplish monitoring if yours won't work.\n- State law enforcement agencies may apply for and obtain an order under this provision, which is not limited to the investigation of terrorism or foreign intelligence matters.\n- prohibits the library from notifying the patron under suspicion, the press, or anyone else that an investigation is underway.\n- This provision will NOT sunset in 2005.\nCodified at 18 U.S.C. Â§Â§ 3121-3127\nSection 214: Pen Register and Trap and Trace Authority under FISA\n- Extends the FBI's telephone monitoring authority in FISA investigations (\"pen register,\" \"trap and trace\") to include routing and addressing information for all Internet traffic, including email addresses, IP addresses, and URLs of Web pages.\n- As with Section 215, the agent only needs to claim that he believes that the records he wants are \"sought for\" an ongoing investigation related to terrorism or intelligence activities.\nCodified at 50 U.S.C. Â§1852\nSection 505: Miscellaneous National Security Authorities\n- Authorizes the Federal Bureau of Investigation to issue National Security Letters (NSLs) to entities providing wire or electronic communication services. NSLs are a type of administrative subpoena.\n- NSLs can be used to compel entities providing wire or electronic communications services to turn over subscriber information, billing information, and electronic communication transactional records to the FBI. In some circumstances, libraries may be deemed to be \"wire or electronic communications service providers.\"\n- NSLs are issued by an FBI agent without any review by a court of law. Does not require the agent to demonstrate \"probable cause,\" the existence of specific facts to support the belief that a crime has been committed or that the records sought are evidence of a crime. Instead, the agent only needs to claim that the items are relevant to an ongoing investigation to protect against international terrorism or espionage.\n- As with Section 215, libraries or librarians served with an NSL may not disclose, under of penalty of law, the existence of the NSL or the fact that records were produced as a result of the NSL. A patron cannot be told that his or her records were given to the FBI or that he or she is the subject of an FBI investigation.\n- A federal district court recently ruled this provision unconstitutional; however, the government is appealing the court's decision, and the court's decision is stayed while the government appeals the court's decision.\nCodified in law at 18 U.S.C. Â§2709.\nOther Provisions of Interest That Do Not Directly Affect Libraries\nSection 218: Foreign Intelligence Information Requirement for FISA Authority.\n- Amends FISA so that foreign intelligence or terrorism need only be “a significant purpose” of the investigation, rather than “the purpose” of the investigation. Relaxes the legal standard for FISA surveillance.\nSection 219: Single-Jurisdiction Warrants for Terrorism\nSection 220: National Search Warrants for Electronic Evidence\n- Both provisions permit federal courts located in a district where a crime or act of terrorism has occurred to issue a court order that may be served and executed nationwide. Section 220 affects stored e-mail and other electronic data.\nSection 206: Roving Surveillance Authority under FISA\n- Permits the use of “roving wiretaps” in a FISA investigation, which allows the investigating agency to obtain a single court order to monitor the electronic communications of a person at any location or on any device, including e-mail and Internet communications.\n- The order need not identify the person or entity whose assistance is required for the monitoring. It is a generic order that may be presented at any time to a newly discovered service provider.\n- Updates FISA to match federal wiretap laws that allow roving wiretaps.\nAmerican Library Association, Office for Intellectual Freedom, October 2005", "label": 1}
{"text": "CNET GLOSSARY: Terms for the techie\nAn assault on a computer network or a server that floods it with so many superfluous requests that service is either slowed or interrupted. Common types of DoS attacks include buffer overflow and smurf attacks. In a buffer overflow attack, the assailant overwhelms the target system with oversized data packets or with e-mail messages that have unusually large file names. In a smurf attack, the assailant sends an IP ping request to a server with instructions to broadcast the request to a number of hosts within the server's network. The return address on the request is falsely identified (spoofed) as the server targeted to receive the DoS attack. The result is that a flood of ping replies overwhelm the targeted server.\nCan't find your term here? Have a question about the glossary? E-mail us.", "label": 1}
{"text": "You may recall a column from several months ago that described cloud computing. The concept of cloud computing is that all operations would be carried out in the Internet, rather than on a user’s computer. Software and documents would be resident in the Internet rather than on the user’s machine. Further, software would be sold on a subscription basis, rather than by periodic updates. This was considered a boon for companies – and individuals -- with large storage requirements and, with the proper security in place, the need for off-site storage of sensitive or critical data. The cloud is used as an amorphous metaphor for the Internet as a whole.\nNow comes Apple with its latest contribution to computing technology, iCloud, released earlier this month for mobile devices and soon to be available at no charge for both Mac and Windows platforms.\niCloud allows iPod, iPhone, iPad, Mac and PC users to store their tunes – and a lot of other content – on Apple’s servers and access it via the Web. Apple wants to help its customers distribute apps, digital music and other content purchased through Apple on all of the Apple devices those customers own.\nIn its basic incarnation, iCloud allows users to store music, photos, applications, documents iBooks and contacts, as well as serving as a platform for Apple’s e-mail servers and calendars. Each account has 5GB of free storage. Purchased music, apps and books will not reduce this free space. Any music purchased from iTunes is automatically downloaded to any registered devices, e.g., iPods, iPhones and computers. When a user registers a new device, all iTunes content can be automatically downloaded.\nA pilot version of iCloud is available, with the full service coming this fall concurrent with the launch of the company’s iOS 5 mobile operating system.\nWith new apps you can create presentations and write reports directly from whichever iOS device you happen to be using. You don’t have to manage your documents in a complicated file system or remember to save your work because your documents are stored in your apps – in iCloud – with the latest updates. Accessing your documents is just as easy, seamless and automatic.\nDevelopers have been given tools with which to write apps that work with iCloud, so in the near future the capabilities of your iOS device will be limited only by your imagination.\niCloud automatically backs up every day over Wi-Fi. But rather than backing up everything, iCloud uploads only what you have changed. Restoration is not a major enterprise, either. To set up a new iOS device or restore information on one you already have, you just connect your device to Wi-Fi and enter your Apple ID and password.\nThere are security issues, however. Of course, devices that rely entirely on software and data hosted on the Internet lose all utility when access to the Internet is cut off as a result of cyber attack or some other outage or interruption. Apple has continuously improved the security of iOS and has developed tools that enable IT admins to enforce policies and exert some control over remote iPhones and iPads.\nA website that addresses specific business issues regarding iCloud and cloud computing in general is www.cloudbusinessreview.com.\nStan Elias writes on business and technology issues and operates Tensor Communications, a West Barnstable-based marketing and communications agency specializing in high-tech companies. He can be reached at", "label": 1}
{"text": "[HT Bruce Schneier]\nHere’s an excellent article on the use of biometrics in security system. Here are some highlights.\nAuthentication of a person is usually based on one of three things: something the person knows, such as a password; something physical the person possesses, like an actual key or token; or something about the person’s appearance or behaviour. Biometric authentication relies on the third approach. Its advantage is that, unlike a password or a token, it can work without active input from the user. That makes it both convenient and efficient: there is nothing to carry, forget or lose.\nThe downside is that biometric screening can also work without the user’s co-operation or even knowledge. Covert identification may be a boon when screening for terrorists or criminals, but it raises serious concerns for innocent individuals. Biometric identification can even invite violence. A motorist in Germany had a finger chopped off by thieves seeking to steal his exotic car, which used a fingerprint reader instead of a conventional door lock.\nAnother problem with biometrics is that the traits used for identification are not secret, but exposed for all and sundry to see. People leave fingerprints all over the place. Voices are recorded and faces photographed endlessly. Appearance and body language is captured on security cameras at every turn. Replacing misappropriated biometric traits is nowhere near as easy as issuing a replacement for a forgotten password or lost key. In addition, it is not all that difficult for impostors to subvert fingerprint readers and other biometric devices.\nThe panel of scientists, engineers and legal experts who carried out the study concludes that biometric recognition is not only “inherently fallible”, but also in dire need of some fundamental research on the biological underpinnings of human distinctiveness. The FBI and the Department of Homeland Security are paying for studies of better screening methods, but no one seems to be doing fundamental research on whether the physical or behavioural characteristics such technologies seek to measure are truly reliable, and how they change with age, disease, stress and other factors. None looks stable across all situations, says the report. The fear is that, without a proper understanding of the biology of the population being screened, installing biometric devices at borders, airports, banks and public buildings is more likely to lead to long queues, lots of false positives, and missed opportunities to catch terrorists or criminals.", "label": 1}
{"text": "Tricking others into giving out passwords or other sensitive information has a long tradition in the attacker community. Traditionally this activity has been performed through the process of social engineering. In the 1990s, with the increasing growth in interconnected systems and the popularity of the Internet, attackers started to automate this process and attack the mass consumer market. The first systematic research to cover such activity was published in 1998 by Gordon and Chess (Sarah Gordon, David M. Chess: Where There's Smoke, There's Mirrors: The Truth about Trojan Horses on the Internet, presented at the Virus Bulletin Conference in Munich, Germany, October 1998). Gordon and Chess were researching malware on AOL, but they were faced with phishing attempts instead of the expected trojan horse attacks. The term phishing (\"password harvesting fishing\") describes the fraudulent acquisition, through deception, of sensitive personal information such as passwords and credit card details by masquerading as someone trustworthy with a real need for such information. A phishing message described by Gordon and Chess is shown below:\nEarly phishing attacks were primarily aimed at gaining access to the victim's AOL accounts, or occasionally at obtaining credit card data for fraudulent purposes (e.g. to make illegal purchases with this information). Often the phishing messages contained a simple ruse to trick unskilled computer users and relied heavily upon the victim’s innate sense of trust in \"automated\" system functions or (apparent) figures of authority. As demonstrated in the previous example, this could be a story about a broken hardware device or the failure of a database, and most normal system users would take at face value any reasonably official-looking or highly urgent technical request that appeared to offer them assistance. Users were usually prompted to enter sensitive information quickly to avoid a serious problem, for example via the phrase \"[...] and re-state your password. Failure to comply will result in immediate account deletion\". To avoid potentially dire consequences the victims often complied immediately, unknowingly providing the social engineer with the credentials they required. Anecdotal evidence suggested that the culprits usually were acting alone or in small, unsophisticated groups. Literature often portrays early phishers as adolescents desiring account data for causing mischief and to make long distance phone calls, usually with little high level organisation or malice.\nToday, the preferred strategy chosen by phishers is to bulk email their lures to as many end users as possible whilst masquerading as a trusted brand - usually one with whom the phisher hopes there is a chance that the victim already trusts. A request for urgent action is sent, often ironically to protect the user's confidential data from malicious activities, and this spoof email will contain an obscured link to a remote web-page that masquerades as the public web site of the target brand. The phisher hopes that victims will be tricked into submitting their credentials into a fake, but apparently legitimate looking \"official\" web interface for the trusted brand. Examples of the organisations being targeted by phishers include many well-known banks, credit card companies or well known Internet traders requiring regular payments (e.g. eBay and PayPal). Numerous examples of phishing emails targeting customers can be found at the Anti-Phishing Working Group web site, which has a archive of phishing emails, many of which illustrate the high degree of accuracy with which phishers can trick innocent users into believing they are accessing a legitimate web interface.\nFollowing this brief introduction to the concepts of phishing, we will now review the actual techniques and tools we have captured during phishing attacks observed in the wild. If you are interested in further background on phishing, we have prepared this page of detailed background information.", "label": 1}
{"text": "By JP Blaho\nThe Internet, over the last two decades, has helped create a different way of interacting, transferring knowledge, and conducting business. It has helped create a level playing field in which companies of any size, and from anywhere in the world, can compete for a consumer’s business. This has also introduced a completely new form of risk– network security.\nNetwork security has become one of the fastest growing sectors within IT because of the growing number of cybercriminals. This black-market has designed a business model where the focus is on breaking into businesses via the Internet. The intent is mainly to exploit their targets for money: whether it’s through holding a company’s network hostage via a DDoS attack, or stealing company data to sell to someone else. The level of success achieved by cybercriminals has grown to scale so that it has become a volume business which has been estimated to be in the billions of dollars annually. This does not bode well for organizations, especially those in the mid-market space.\nAs taught in Economics 101, economies of scale is good for the business achieving it, and dangerous to those who are not shielded from this success. Initially cybercriminals were looking for and attacking organizations with large brands, solid reputations, and deep pockets. Attention was not given to the smaller organizations whose transactions over the Internet were considered low volume. Now that these cybercriminals have achieved a volume-based business, they are able to scale their attack to many companies of all sizes. Would you rather sell one product for one hundred dollars or one thousand products for one dollar? This is where cybercrime has moved. Instead of hunting for the whales, they are casting large nets into the water. Instead of attacking and breaching one large company, they are attacking and breaching hundreds if not thousands of organizations – many of whom do not even know the breach has occurred.\nThe other change is that these attacks are no longer immediate and noticeable. The level of sophistication inherent in today’s security landscape is so intricate that cybercriminals can lay dormant for weeks or months, or slowly collect bits of data at levels which are hardly detectible. This does not bode well for any company, but especially for the small and medium-sized organization. Fortunately, there are many affordable tools and services out there to help SMBs monitor and prevent these attacks. I will discuss these resources in my next post.", "label": 1}
{"text": ", a security tool developed by the US Department of Energy (DOE).\n\"Hone gives users a “’glanceable’ type of view of what’s happening on\nthe network and what’s happening on the machine,” [Hone creater Glenn Fink]\nsaid. Hone also is a tool that has uses beyond understanding and responding to attacks, Fink said. It can be used to help programmers debug new networked applications being developed. In addition, security administrators can use data from Hone to ensure that only certain processes on their systems can communicate with the network, and to monitor what their systems are doing, which would help them identify such threats as viruses, spyware and rootkits.\nto post comments)", "label": 1}
{"text": "How do you know if the web site you’re about to visit, or the sites listed in a web search, are safe? One of the easiest ways to get infected or scammed is to simply browse the web without first ascertaining if the sites you visit are safe to do so.\nWhile web browsers do have some protection built-in, they tend to only target fake web sites, which come and go in 24 hours. Other web sites deemed to have privacy and security issues are usually left well alone. As a result, you’re left surfing the web blind, with little or no idea if the web site in question can be trusted or not.\nSome security tools offer web-filtering add-ons for major browsers, but Web of Trust aims to provide a safe browsing environment for those who don’t have access to such luxuries. It’s a free browser add-on which is also available for Chrome, Firefox and Internet Explorer.\nSites, search engine results and even links in web-based email accounts like Gmail and Windows Live Hotmail are rated green, amber or red based on their safety and security ratings, enabling you to avoid sites that harbour malware and other dangers (if you inadvertently visit a site rated dangerous a clearly visible warning will pop up). The ratings are provided by over three million WOT users, and you can add your own to the list. Unfortunately these ratings aren’t 100 per cent accurate, and a growing number of people are complaining that perfectly safe sites are being blocked due to subjective reviewing criteria.\nYou can also configure the add-on to automatically block sites that aren’t suitable for children, so it adds another layer of protection to your loved ones’ online experience without forcing you into a blanket ban.", "label": 1}
{"text": "One of the most important principles of individual privacy is the ability to act anonymously. When people are driving to a store or reading a book at home, they have a reasonable assumption that nobody is monitoring their behavior and attaching it to their name and address.\nThe same should be true on the internet: when you are online, there should be a presumption of anonymity. Nobody -- including websites, ad networks, ad exchanges, widgets, outside analytics services, etc. -- should know who you are and what you do unless you sign up or log in.\nIn a better world with sufficient anonymity online, your search history and the sites you visit should not be matched back to personally-identifiable information (like your name, address, email, etc.) so it cannot be stolen, used to discriminate against you, or subpoenaed by the government.\nIn online advertising, there are various standards for what constitutes sufficient online anonymity. But unless companies adhere to the highest standard and increase awareness to consumers, internet users may think their browsing behavior is being tied to their identity and may subsequently dramatically decrease internet consumption and be less likely to experiment with new online services. In short, the lack of available anonymity could stifle the online economy and all the innovation happening on the web.\nWhat Anonymity Means\nThe key to protecting anonymity is to make it technically impossible -- not just contractually prohibited or difficult -- to tie an internet user to their name and address when they are not explicitly logged in.\nThis doesn't mean that websites and third party services can't know something interesting about you. They might know that you are a woman who lives in the New York area, plays tennis, enjoys Settlers of Catan, is in market for a trip to Italy, and drives a hybrid. This is good because they can use this data to give you a more personalized experience: content you like, better customer service, more targeted ads, and less spam. But they should not know that it is you.\nOf course, once you log in or when you link to your name or Twitter profile, people might know it is you. But it is important that when you first arrive at a site, nobody knows exactly who you are unless you explicitly log in.\nPrescriptions to improve online privacy and anonymity\nHere are some prescriptions that online services should use to raise the bar on online privacy:\nA Machine ID is like your computer's fingerprint that can usually uniquely identify you. It is the information that your computer may send to the sites you visit, like your IP address, browser configuration, \"clock skew\" (the millisecond difference in the clock on your machine and that on the server), and more.\nOne reason sites and third-parties collect Machine ID is to help customize the online experience for people based on past machine behavior. But this can be uniquely identifiable because people largely use the same computers, meaning that machine IDs can potentially be looked up and traced back to an individual (there is a marketplace for addresses-to-IP matches today). In fact, IP address alone can be traced back to 30% of households today.\nMany firms store a unique ID in a user's browser cookie and ping cloud servers with this unique ID to \"see\" data associated with the cookie. This system of storing unique cookie IDs has a lot of benefits since it enables the information associated with cookies to be quickly updated and more easily analyzed.\nBut using unique IDs also means people may no longer be anonymous. A more privacy-centric solution is to store all the segments of a person directly on a cookie. The data can be encrypted and secured so that only the cookie-placer can access it.\nChanging the cookie system from unique ID-centric to segment-centric is a large technical challenge and might take some sites, ad networks, and widgets many months to complete. But it would be great that if by this time next year, all companies could be more pro-consumer in the way they store data within cookies.\nBut storing the data directly on the cookie is only part of the challenge. Data also needs to be anonymized appropriately. Simply stripping personally identifiable information out of a cookie is not enough to make it anonymous. Recently, Netflix had to shut down its million-dollar Netflix recommendation contest as a result of an FTC inquiry about their anonymization practices.\nIf there is data on me that says my company is \"Rapleaf\" and my title is \"CEO,\" it is not anonymous because I am the only person that fits the join of both of those attributes. A more appropriate description would be company \"technology start-up\" and title of \"executive\"-that gives me room to add other criteria like lives in \"SF Bay Area,\" plays \"soccer,\" and reads lots of books on \"foreign policy\" without knowing it is me. Many people fit all those characteristics.\nThese are just three of many prescriptions that companies should implement to help ensure the presumption of anonymity. Adopting these changes will require a short-term sacrifice for web sites and third-parties, but long-term these are the right decisions for companies to make.\nGiving technologists a better appreciation of why privacy - and in particular anonymity - is really important is not an easy task. Most Silicon Valley companies come from the perspective that their technology is sacrosanct. As an engineer, I admit that we started my company Rapleaf with that approach. However, years of engagement with our web users, customers, partners, privacy experts and advocates (including our own privacy advisory board), have made it clear that investing in a safe infrastructure where users have the presumption of anonymity will ensure that the Internet will continue to grow and stay vibrant.\nSpecial thanks to Michael Hsu, Joel Jewitt, Jeremy Lizt, Travis May, and others for their help and edits....\n(If you like this, please send it to a friend, tweet it, and \"like\" it on Facebook)\n... See more comments and comment yourself at: Summation blog: The Erosion of Online Anonymity\nFollow Auren Hoffman on Twitter: www.twitter.com/auren", "label": 1}
{"text": "A scientist from Dartmouth College, Hany Farid, has been developing digital forensics software that can tell if a digital photograph has been manipulated with Adobe Photoshop- the world’s most popular image editing software. The forensics software can identify if an image has been tampered with by checking its properties against a database of every digital camera ever made. The software then detects if there are any variations in the signature or traces left behind by Adobe Photoshop which are tell-tale signs that the photograph has been tampered with. The scientist plans to sell the software to law enforcement agencies that need unaltered photographs for court evidence, though it’s uncertain when we’ll actually see it in use. There are limitations to Farid’s software though. The software can only tell if an image has been doctored, but not which part of it, but at least progress is being made. It’s not going to totally eliminate fake photography, but you can bet forgers will be working a lot harder now.\nLEGO X-Wing Is A World-Breaking Creation With Over 5M Pieces\nGoogle Rumored To Be Interested In Waze As Well\nVisit Galapagos Islands With Google Street View\nRain Room Art Installation Doesnt’ Get You Wet", "label": 1}
{"text": "Seoul (CNN) -- Picture the scene: dozens of computer hackers poring over their keyboards in a room filled with powerful computers, feverishly typing in code most of us could never comprehend.\nTheir mission? To \"break in\" to virtual servers in a simulated world.\nYet these particular hackers are not breaking the law, they are actually reinforcing it.\nThey are taking part in a six-month program organized by the South Korean government to train some of the brightest code-breaking minds to become the nation's first line of defense in the war against cyber crime.\nAccording to the Korea Information Technology Research Institute (KITRI), the \"Best of the Best\" program is designed to train computer experts to defend against domestic and foreign cyber attacks.\nSouth Korea, which is one of the most Internet-connected nations in the world, is frequently subject to cyber attacks, especially from its northern neighbor, with whom it is still technically at war.\nIn 2009, a number of government websites, including the presidential Blue House and National Assembly, crashed for days after being targeted with malicious code. And in 2011, a bank's entire computer system was hacked and shut down. The attack left tens of thousands of computers infected and some permanently damaged, according to the country's prosecutors.\nThe Seoul government pointed the finger at Pyongyang, citing similarities in code used in earlier cyber attacks by South Korean nationals in collaboration with hackers believed to be connected with a North Korean intelligence agency, South Korea's prosecutor's office said in a press release.\nThe North Korean government has yet to comment on the claims.\nThe official value of the loss from the attacks is unknown, but the Hyundai Research Institute estimates the financial loss from the 2009 attacks alone at between $33.7 million and $50.5 million.\nAttacks from domestic and foreign sources are on the increase, authorities say. Cyber attacks rose by 37% from 2008 to 2011, according to Korea Internet Security Agency.\n\"Cyber attacks in general are getting more and more complicated. It is also known that North Korea is training highly skilled hackers,\" Jung Soo-whan from South Korea's Soongsil University told CNN.\n\"But what if they, for instance, hack into our nuclear power systems? We need a stronger defense system.\"\nAccording to Lee Seung-jin, the chief consultant for the \"Best of the Best\" program, a cyber attack from the North is like fighting an asymmetric war. It is very difficult to counter attack.\n\"The South Korean Internet industry developed very fast. It is essential to train cyber security experts in all fields including those who will be working for commercial companies,\" said Lee, a prominent name in the South Korean hackers community.\nSixty computer experts, from high school students to college students, were selected for the program. Most participants were already well known in the country and some are award-winning hackers from local and foreign hacker competitions.\nKwon Hyuk, 17, is one of the survivors of the first phase of candidates on the program. He focuses his work on printer networking systems, an area easily exposed by cyber attacks.\n\"Companies may print confidential documents using network printers. If the security was breached, companies potentially could be eavesdropped,\" he said.\nThe program, which is now down to 20 hackers, will only graduate one expert from six fields in its final stage.\nAside from receiving 20,000,000 KRW ($18,500) as a prize, each graduate will then be recommended to companies or government agencies they wish to work for in the future.\nThe six fields include digital forensic, security consulting, vulnerability analysis, mobile phone security, converged security and cloud-computing security.", "label": 1}
{"text": "MIT Researchers Turn Heads With WLAN Tech: Coded TCP\nLee H. Badman\nOctober 29, 2012\nIn the late 1990s, WLAN data rates up to 11 Mbps were impressive. For that matter, simply accessing the network over the air back then at any usable speed was impressive. Since those days, researchers and vendors have employed a variety of technologies to enhance data rates and make wireless networks more reliable. Just a few years ago, the 802.11n standard turned the WLAN world on its ear. Topics like antenna diversity and single channels gave way to Multiple Input Multiple Output (MIMO) antennas, a slew of new modulation types and channel bonding. Now 802.11ac promises to push the wireless realm into the gigabit era.\nBut 11ac isn't the only news from the front lines of the war for faster wireless. Researchers at MIT caught the attention of the media and the wireless-minded thanks to a recently discovered scheme that uses mathamatic equations to reduce the number of inevitable retransmissions on the wireless network, called Coded TCP.\n- Get Actionable Insight with Security Intelligence for Mainframe Environments\n- How Cloud Facilitates an Agile Contact Center\nWhite PapersMore >>\nIf it lives up to its promise (a big if in these early days), this upstart technology is just as compelling for what it doesn't do as it is for its expected benefits. By not requiring any more spectrum or output power, Coded TCP immediately becomes interesting to a world of wireless admins who need to worry about both spectrum and signal strength. What's the lure of Coded TCP? By employing simple algebra-based changes to the way packets are sent, the receiving device can compute what data is missing when loss occurs, rather than asking for a retransmit. And the payoff evidently is quite large.\nTest scenarios by the researchers developing Coded TCP, led by Muriel Medard, an MIT professor, have yielded startling increases in performance. A 500-Kbps connection before Coded TCP became 13.5-Mbps by using the new method. A 1-Mbps experience became 16-Mbps. Evidently the industry is taking note. An MIT/Caltech startup company called Code-On Technologies has reportedly licensed its magic to several companies, although the list isn't public information yet. The techniques used in Coded TCP can also potentially be applied to 3G and 4G networks.\nThe wireless industry has come a long way by harnessing the power of new techniques and technologies to make WLANs robust and effective, and the interest in 802.11ac is a prime example. If a development like Coded TCP bears fruit, we'll have some pretty exciting days ahead of us, as well.", "label": 1}
{"text": "CCSP certification is the certification given by Cisco to the people who are professionals in system security and network security. CCSP stands for Cisco certified Security professional. Network security is a very much important part of networking because if the network is vulnerable to hackers it becomes a disaster for that network. Good network engineers and network administrators should know how to maintain a certified security system for their network and also they should know how to clog the breaches in security. Becoming a network administrator is not an easy task because these network administrators have a lot of demanding work on them and they are supposed to work round the clock to maintain the network of that particular establishment in top-notch condition.\nThey are responsible for the security breaches and if any of the part of the network is found to be faulty they are responsible for it. There are surely many people who are very much talented in this field of networking security but they are not getting employed in the various highly ranking institutions because they are not certified by the industry in a standard procedure. If a person knows how to create full security networks and how to maintain them in a very good condition without having a lot of problems he may not be able to get a job only for his knowledge because every company looks out for people who are officially certified. CCSP certification is one such certification that is a requirement of a networking professional who wants to be in the networking security field.\nCCSP certification is also very famous as the CCNA. People who have the CCSP certification are rarely found unemployed and they are also employed in such areas where they get demanding salaries and all so are highly respected. CCSP certification requires a lot of preparation and dedication because the questions that are asked then this certification exam are a combination of simple and difficult questions. For taking this exam, one needs to have a combination of good knowledge and have practical knowledge, so that he can get industry ready.", "label": 1}
{"text": "A security incident response system consists of several steps and processes that your organization should document. There are many event types that you may be come across, and each one will have a number of responses to consider.\nAny security incidents will, at their root, be the actions of a person or group of people. These incidents can have varying degrees of severity, and the first step in a response is to decide how serious the incident is for your organization.\nGenerally, incidents fall into three categories:\n- Ordinary or normal: These do not affect your organization's operations, nor do they require notification of management. They can be contained and dealt with within the security group or help-desk function in your IT department.\n- Elevated or serious: These can affect operations, and they will require an implementation in order to be dealt with. Management will have to be notified and perhaps even involved in the resolution.\n- Emergency: These can affect people's health and well-being, breach your normal business controls, affect your financial performance or even place your organization in violation of public law. Management must be informed, as well as possibly vendors, customers and public officials.\nEach type of incident needs a tailored response. Ordinary incidents, for example, can be logged and handled during the normal course of business. But serious and emergency incidents need to have a response plan in place.\nThe first thing to do is identify the specifics of the incident and determine if it is ongoing or a one-time event. If it is ongoing, your response should be to first identify the source and then stop the incident from continuing. This could be something like discovering a breach of your system via the FTP server function. If the person performing the breach is still logged on to your system, you should first get as much identifying information as possible and then cut them off by shutting down the FTP server function on your System i. This may affect other users on your system, but the integrity of your system is at risk and you need to take action to protect your organization's assets.\nOnce the event has been identified and suspended, you need to analyze it and determine how it was accomplished and what security safeguards can prevent it from happening again. If at all possible, the affected system should not be placed back into normal use until steps have been taken to prevent a repeat of the incident.\nAs soon as the incident's severity has been determined, you will have to notify management and your organization's principals. If the incident includes law violations, such as theft of identity information, public officials will also have to be notified. During this process, it might also be wise to contact your organization's public relations staff to make sure that the facts made public are correct and not overstated.\nEach step along the way must be documented, with permanent records kept for future reference. This will show how the event was dealt with, along with providing a blueprint to prevent a repeat incident.It's not enough to have a security policy in place; you need to prepare for what might be needed when the security policy breaks down.\nIf you have any questions about this topic, you can reach me at firstname.lastname@example.org.\nThis was first published in October 2009", "label": 1}
{"text": "Technology behind data recovery in hard disk\nThere are many tools available for data recovery but it is not easy to recover all the data which was lost so it is preferred to back up hard disks using DVDs or online backup. The online backup has increased much popularity because it provides easy way of backup with more security you can save the data like photos, softwares, music files, and many other important records.\nThe backup can be done by data recovery it uses various retrive technics it uses recovery tool can be overwhelming can be gained some lost files without worry using file recovery tool the harmful viruses like Trojan horse, virus threat also can remove using this data backup.\nIt uses various methods like using tape as datastorage method and efficient methods like incorporating virtualisation which takes the address of the derived tape and uses different methods for the datastorage.\nPartner Link: Hard Drive Destruction\nTags: Technology , Technique , Data Storage , Hard Disk , Backup , Data\nThis work is licensed under a Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 License.", "label": 1}
{"text": "Source: Doug Powell, 785-317-0560, firstname.lastname@example.org\nNews release prepared by: Tyler Sharp, 785-532-2535, email@example.com\nWednesday, Dec. 8, 2010\nDIALOGUE AND COMMUNICATION KEY IN IMPROVING FOOD SAFETY\nMANHATTAN -- It's not going to happen to me.\nIssues of food safety are often met with this kind of attitude, according to Doug Powell, associate professor of food safety at Kansas State University. This lack of concern places a greater emphasis on how food safety messages are presented.\n\"The way people learn is through telling stories in surprising ways and making it relevant,\" he said.\nPowell has combated this attitude in a variety of ways, including at http://www.barfblog.com, a blog on food safety issues worldwide, which he operates with several co-authors. Powell and barfblog are highlighted in a section on food safety in a new book, \"Cooking for Geeks: Real Science, Great Hacks and Good Food.\" The book is written by computer scientist Jeff Potter and is 432 pages of musings on experimentation in cooking.\nPowell's contributions to the body of knowledge on food safety also are in the classroom, albeit through a computer screen. He teaches a graduate distance course called Food Safety Risk Analysis, involving the assessment, management and communication of food safety risks.\nOutdated approaches by government entities make new ways of conveying information on food safety even more important, according to Powell.\n\"Most of our government agencies are stuck at the 'we produced a brochure stage' of information provision,\" he said. \"That's not going to work with the younger demographic. We're always looking for new media to exploit.\"\nAwareness is the best asset for enhancing the food safety culture, Powell said. The best approaches come through incentives and the punishment of bad behavior. A prominent example is restaurant disclosure. This is based on giving letter grades for inspections. The greatest benefit is that it establishes a dialogue, he said, but the information has to be posted.\n\"Publishing the information in the newspaper every couple of weeks doesn't help when you're walking through the restaurant's door,\" Powell said. \"It needs to be right there.\"\nPowell said he's encouraged by the level of dialogue on improving food safety, but acknowledges there's plenty of work to do.\n\"For every step forward there always seems to be a few steps back,\" he said. \"When you look at the billions of meals served in the country each year, food safety is pretty good. But when someone screws up, it's pretty bad.\"\nThat happened this summer when more than 550 million eggs were recalled nationwide because of a salmonella outbreak that sickened more than 1,800 people. The eggs came from an Iowa egg producer.\nOn a personal level, Powell said he is respectful of food when he cooks. But he cautions against being too paranoid.\n\"I think of any raw food as containing microorganisms that could be dangerous,\" he said. \"I don't treat it like nuclear waste, but I treat it with respect.\"\nMore information on food safety and Powell is available at http://barfblog.foodsafety.ksu.edu", "label": 1}
{"text": "The majority of the biggest malware incidents that took place in the second quarter of 2010 were linked in some way to botnets. New bots were created and existing bots further developed, such as TDSS, an article on which has been published by our virus analysts, and Zbot (ZeuS), which we discuss below.\nThe evolution of the ZeuS (Zbot) Trojan, which is used to build botnets, is worth describing. A new modification of the malicious program was detected in late April. It included file virus functionality, which meant it could infect executable files. The malware writers decided to use relatively unsophisticated code and a similarly simple infection routine. Instead of the Trojan itself, a 512-byte-long fragment of code was added to .exe files, after which the infected file’s entry point was changed so that the appended code would be executed prior to the original code.\nThe injected code is designed to download the new versions of the Trojan to the infected computer if the main ZeuS component has been removed. The malware writers used computers in the US to test the new version of the Trojan. ZeuS primarily targets online banking accounts and as online banking is more evolved in the US than anywhere else, computers located in the US users are tasty morsels for cybercriminals. The ZeuS version that the injected piece of code loaded was detected by Kaspersky Lab products as Trojan-Spy.Win32.Zbot.gen and had been created specifically to steal accounts from customers of Bank of America, a major US bank.\nAnother notable innovation is that ZeuS is distributed using pdf files. An independent researcher has discovered that executable files embedded in pdf documents can be executed without having to exploit any vulnerabilities. The file is executed using the Launch function described in the pdf format specification. Just a few days after this information was published on March 29, people started to get emails with a specially crafted pdf document, which used the file launching method described above to infect computers with the ZeuS Trojan. In order for the computer to become part of a botnet, all the user needed to do was open the attachment.\nIn our previous quarterly reports we wrote about cybercriminals’ first attempts to control botnets via social networks. Those were only proof-of-concept efforts and we expected further developments. We did not have to wait long. A bot building utility called TwitterNET Builder appeared on the Web in May. The program builds a botnet using a Twitter account as a command and control center.\nSince no programming skills are required to use the builder, it’s an ideal toy for script kiddies, who are able build a bot with only a couple of mouse clicks. Kaspersky Lab classifies this ‘toy’ as Backdoor.Win32.Twitbot. The resulting bot has the following features: it can be used to downloads and run files, conduct DDoS attacks and open websites specified by the bot’s owners. To receive commands, the bot searches for the relevant Twitter account, which is used by the bot master to publish commands in text form.\nFortunately, this bot never became widespread, because security researchers were tracking such tricks. A botnet with such primitive control system (the commands were sent unencrypted via a social network) is easy to detect and disconnect from the command and control center by closing the cybercriminal’s account. To the credit of the network’s security service, there were no such command centers on Twitter by the end of June.\nSocial networks have become a popular means of exchanging information. Cybercriminals take advantage of this by increasingly using them for fraudulent attacks, to send spam and distribute malware. Below we focus on the most notable incidents that took place on social networks in the second quarter.\nRecently, we’ve seen links to social networks being actively distributed in spam messages. Eventually, social networks may, to a great extent, replace email in spreading malware.\nOne example is Brazil, where, until recently, banking Trojans were primarily spread by email. Brazilian cybercriminals must have realized that social networks are much more suitable for this purpose: since the start of Q2, social networks have seen significant amounts of spam targeting Brazilian bank customers.\nStatistics confirm that social network spam is effective: in just one attack on Twitter, over 2,000 people followed the link sent by spammers within the space of an hour.\nA notable iPhone-related story took place on Twitter. On May 19, the social network’s administration officially announced a new application, Twitter for iPhone. Cybercriminals decided to ride the wave of interest caused by the announcement. Less than an hour after the news was published, Twitter was flooded with messages that included the words “twitter iPhone application” and links leading to malware: Worm.Win32.VBNA.b.\nThis particular piece of malware is notable for several reasons. One is that this worm has relatively good self-protection: it uses anti-emulation tricks to disable some Windows system programs and spreads via USB devices. Another is that its principal function is to steal information required to conduct financial operations. The piece of news that was used to spread the worm wasn’t chosen at random: most smartphone owners have bank accounts and cards which are a prime target for cybercriminals. Therefore, it’s not surprising that about a third of all VBNA.b attacks (27-33%) targeted US computers, which are of greatest interest for cybercriminals.\nClick fraud has always been a lucrative proposition for cybercriminals and it has became even more profitable with the advent of social networks, since the major social networks have as many users as the world’s largest countries.\nA new type of attack appeared on Facebook in May in response to the introduction of the new Like feature. As can be easily guessed, the feature is associated with a list of the things that the owner of an account liked on the Internet. Thousands of users fell victim to an attack that was dubbed “likejacking” (by analogy with clickjacking.)\nLuckily, so far we have not seen any cases of links to malware being distributed in this way.\nTwo unexpected events involving vulnerabilities and Google took place in Q2. In both cases, a Google employee disclosed full information about vulnerabilities. Since at the time of disclosure there were no patches for the vulnerabilities, this predictably led to mass exploitation by black hats.\nA zero-day vulnerability in Java Web Start (CVE-2010-0886) was disclosed on April 9. Oracle worked hard to develop a patch, which was released on April 16. However, cybercriminals beat them to it: a couple of days after the vulnerability disclosure, an exploit was widely available and even added to an exploit pack. Exploits are clearly mass-produced by cybercriminals these days: the domain that was subsequently used to conduct attacks was registered one day before information on that particular vulnerability was published.\nIn the second instance, the same Google employee disclosed a vulnerability in the Windows Help and Support Center (CVE-2010-1885). The situation repeated itself and working exploits became available on the Internet very soon after the information had been disclosed.\nA researcher disclosing information about vulnerabilities is probably impelled to do so by an acute sense of justice. He believes that by making that information public, he is doing a good deed. But is this really the case?\nOn the one hand, when a vulnerability is disclosed, software vendors try to release a patch as quickly as possible. On the other hand, all cybercriminals receive a brand new weapon that is nearly 100% effective. In addition, while fixing today’s software that is made up of millions of lines of code takes much longer than a day, cybercriminals can take advantage of the vulnerability virtually at once. Isn’t this too high a price to pay for fixing bugs?\nOur research demonstrates that such attempts to do good lead in quite the opposite direction. According to our data, exploits that target the CVE-2010-0886 vulnerability became widespread very soon. In their heyday, they boasted a 17% share of all vulnerabilities! The situation with the exploit that targets the HSC vulnerability (CVE-2010-1885) is similar. It is rapidly gaining ground and has risen as high as thirteenth in the quarterly exploit ranking, in spite of the fact that it only appeared in the last month of the quarter. It can only be hoped that this will be a good lesson to all researchers.\nOn May 31, Google announced that it was abandoning Windows and migrating to Linux and Mac OS. Security issues were among the reasons for this decision cited by Google representatives. However, Linux and Mac OS are, in fact no better protected than Windows.\nThe second quarter saw malware for alternative platforms gaining new ground. A new backdoor for Mac OS X, Backdoor.OSX.Reshe.a, appeared on April 20. Once on the victim machine, the malware protects itself by disguising as iPhoto, a popular application, and configures itself to start at system startup. The backdoor offers an attacker full control of the infected computer, with the ability to send spam, search for and steal files, download and execute programs, take screenshots and much, much more. It is written in RealBasic and can run on Apple computers based on both PowerPC and Intel processors. So far, mass use of this malware has not been detected, but it nevertheless remains a weapon in the hands of cybercriminals.\nOn June 3, several days after Google’s announcement that it was migrating to alternative operating systems, Kaspersky Lab detected a new Trojan Spy for Mac OS X. The malware was disguised as an advertising system and was distributed in a bundle with legitimate software. In addition to stealing information from the computer, the malware has backdoor functionality, enabling attackers to send commands to the computer.\nMany Mac OS users have a false sense of security. They are convinced that there are simply no threats that target their operating system. At the same time, Apple Computers admits that malware for Macs does exist. In the latest update for OS X 10.6.4, Apple quietly added a new signature to its antivirus scanner to protect computers against Backdoor.OSX.Reshe.a, which we described above. However, these quiet updates provided by the vendor only support users’ false sense of security instead of dispelling it.\nIt should be noted that there are no operating systems that are completely safe. Today, Mac OS X is no more secure than, say, Windows 7 because, Mac OS X also requires anti-malware protection. Given the incidents described above, it is quite conceivable that targeted attacks on Macs are not far away.\nIn the past three months, over 540 million attacks were blocked in 228 countries. Last quarter, even Norfolk Island with a population of 2,141 appeared on Kaspersky Lab’s antivirus radar. During the quarter, the average number of infection attempts increased globally by 4.5% per month.\nAs the table below shows, the likelihood of a computer becoming infected depends on its location.\nDistribution of attacks by country Q2 2010 and Q1 2010\n|№||Q2 2010||№||Q1 2010|\n|2||Russian Federation||11.36%||2||Russian Federation||13.18%|\n|4||United States||5.96%||4||United States||5.25%|\n|5||Viet Nam||5.44%||5||Viet Nam||3.73%|\nThe distribution of attacks remains virtually unchanged. The only exception is that the Bangladesh have replaced Philippines in nineteenth place. The five leading countries are still China (17.09% of all attacks), Russia (11.36%), India (9.30%), the USA (5.96%) and Viet Nam (5.44%).\nIn terms of the share in the total number of attacks, the most noticeable changes are shown by Russia (-1.82%), and Viet Nam (+1.71%).\nIt’s been a long time since Australia (31 position, 0.5%), which actively combats cybercrime, appeared on the rankings. The latest report presented by the Australian House of Representatives Standing Committee on Communications recommends that Internet service providers refrain from providing Internet access to computers without antivirus protection or firewall installed. This recommendation may become a requirement for all Australian users.\nThis may seem harsh, but take another look at the rankings. The top position is taken by China, where, according to a poll conducted by CNNIC, about 4.4% (approximately 17 million!) of all users connect to the Internet without any protection whatsoever. This is the online equivalent of leaving home with all the doors and windows wide open. Moreover, Chinese users are not eager to learn from their own mistakes: according to the same poll, one sixth of all respondents admitted to having fallen victim to cybercriminals and lost virtual property – virtual property which these days can very easily be converted into real money …\nIn Q2 2010, Kaspersky Lab products blocked 157,626,761 attempts to infect computers via the Internet.\nThe five most common types of malware on the Internet includes various Trojans, exploits and adware, with nearly half (48%) being accounted for by Trojans. Of these, 57% were malicious scripts injected by cybercriminals into various websites, including legitimate sites with thousands, even millions of visitors. These scripts are categorized by Kaspersky Lab as Trojan.Script.Iframer and Trojan.Script.Generic. They make users follow a link that is not visible in the browser window and which takes them to a web page created by cybercriminals. Such links usually lead to pages with exploits (in more professional schemes, exploit packs), which enable attackers to make their first step towards evading security applications and, ultimately, to download and run any file on the victim machine. Exploits are discussed in more detail below.\nAdware accounts for 7.15% of all detections. In the first quarter, 70% of all adware programs detected belonged to the Zwangi and Boran families. In Q2, they ceded their place to the Shopper (26.06%) and FunWeb (22.81%) families, which together accounted for 49% of adware detections.\nOver a third of all Shopper, FunWeb and Zwangi detections were on US and UK computers. At the same time, in 93% of all cases Boran, whose share diminished to 8%, was detected on computers in China.\nAn increase in the share of Shopper – a Browser Helper Object that provides online shopping advice – is due to the way in which it is currently being spread. It is now distributed in installation packages with free software handed out under the GPL license. When a free program received from an unofficial source is installed on a computer, Adware.Win32.Shopper installs together with the main program.\n157,626,761 attacks conducted from online resources located in different countries were identified in Q2, 2010. Over 95% of all the attacks recorded originated from twenty countries.\nTop 20 countries with servers hosting malicious code\n|№||Q2 2010||№||Q1 2010|\n|1||United States||28.99%||1||United States||27.57%|\n|2||Russian Federation||16.06%||2||Russian Federation||22.59%|\n|7||United Kingdom||4.62%||7||United Kingdom||3.29%|\n|20||Viet Nam||0.36%||20||Viet Nam||0.25%|\nAs in the previous quarter, the top three positions in the ranking are taken by the US (28.99%), Russia (16.06%) and China (13.64%). The latter did not succeed in regaining the top position, which it had lost in the previous quarter.\nThe proportion of infected sites in Russia was down by 6.5 percentage points. At the same time, the number of attacks coming from web resources in the Netherlands and Sweden increased, with shares growing by 2.8 and 3.4 percentage points respectively.\nThe majority of Internet attacks start with exploits which make it possible for cybercriminals to surreptitiously access systems and download malware to victim machines. It’s therefore hardly surprising that exploit packages cost in the region of thousands of dollars.\nA total of 8,540,223 exploits were detected in Q2, 2010. The table below shows the ten exploit families most commonly used by cybercriminals:\nExploits which target vulnerabilities in Adobe Reader remain the most common. However, it’s striking that the share of these programs decreased significantly in comparison to Q1, dropping by 17.11%.\nThe reason for this is that the Exploit.JS.CVE-2010-0806 and Exploit.JS.Agent.bab families have become increasingly widespread. These two exploit families target CVE-2010-0806, a vulnerability in the Peer Object component (aka iepeers.dll) in Microsoft Internet Explorer 6 and 7. The Q1 report describes how these exploits were spread. After inclusion in the metasploit (www.metasploit.com; en.wikipedia.org/wiki/Metasploit_Project) framework, these exploits were added (almost unmodified) to many exploit packages; this meant they were then used on a wide scale. On average, Kaspersky Lab products counteracted 31,000 attacks of this type every day – attacks which used Exploit.JS.Agent.bab and Exploit.JS.CVE-2010-0806 to target the CVE-2010-0806 vulnerability.\nThese exploits were used with a number of aims; however, the main target was online gaming accounts. Research shows that downloader programs installed by Exploit.JS.CVE-2010-0806 mostly attempted to download Trojan-GameThief.Win32.Magania and Trojan-GameThief.Win32.WOW to infected machines. The geographical distribution of attacks using these exploits also confirms the hypothesis that online gaming accounts were the main prize: the five most targeted countries (accounting for 96.5% of all attacks) were China, Taiwan, Korea, the USA and Vietnam. All of these are countries where the number of MMORPG players is traditionally high.\nAnother significant change is the increased proportion of Java exploits which target CVE-2010-0886 and CVE-2009-3867. The 2% increase in the proportion of Java malware in Q2 2010 is mainly due to these exploits, which were mostly used to conduct attacks targeting European - Germany, the UK, Russia, Italy, Ukraine and Spain - and North American countries – the USA and Canada. The attacks resulted in Backdoor.Win32.Bredolab being downloaded to victim machines. This malware is designed to, in its turn, download and install other malicious programs with varied payloads ranging from spam bots and programs designed to steal FTP passwords to rogue antivirus programs.\nThe exploits used in the Aurora attack are rapidly losing ground: in Q2 their share decreased by 7.08%. The mass media coverage of the attack, which exploited CVE-2010-0249, seemed to have a positive effect: users with Internet Explorer 6.0, which contained the vulnerability, started to upgrade their browsers. According to Net Applications www.netmarketshare.com , the market share of Internet Explorer 6.0 has dropped 3% since January 2010.\nThe decline in the number of people using Internet Explorer 6.0 has resulted in a decrease in the share of the Exploit.JS.Adodb family exploits which target an old vulnerability in this version of the browser.\nThe exploits which target the CVE-2010-1885 vulnerability in Windows Help and Support Center (see above) are rapidly increasing in number. In Q2 they took thirteenthplace even though the vulnerability was only identified on June 9. A patch was released over a month later in Microsoft Security Bulletin MS10-042, on July 13. This meant cybercriminals had plenty of time to exploit the vulnerability. It was primarily Russian, German, Spanish and American users who were targeted by attacks using these exploits. Mostly, they were used in pay-per-install (affiliate) schemes where one cybercriminal grouping pays others to distribute a particular piece of malware, with the amount paid depending on the number and location of infected machines.\n2010, Kaspersky Lab products detected 33,765,504 vulnerable files and applications on users’ computers. Notable, one in four computers had over seven unpatched vulnerabilities.\nThe table below shows the ten most common vulnerabilities:Ten most common vulnerabilities detected on users’ computers\n|№|| Secunia |\n|Change||Vulnerabilty||Impact|| Percentage |\n| Release |\n|1||SA 38805||7||Microsoft Office Excel Multiple Vulnerabilities||System access, execution of arbitrary code with local user privileges||39.45%|| 2009- |\n|2||SA 37255||new||Sun Java JDK / JRE Multiple Vulnerabilities||Security bypass||38.32%|| 2010- |\n|3||SA 35377||-2||Microsoft Office Word Two Vulnerabilities||System access, execution of arbitrary code with local user privileges||35.91%|| 2010- |\n|4||SA 38547||-1||Adobe Flash Player Domain Sandbox Bypass Vulnerability||Security bypass||30.46%|| 2009- |\n|5||SA 31744||1||Microsoft Office OneNote URI Handling Vulnerability||System access, execution of arbitrary code with local user privileges||27.22%|| 2007- |\n|6||SA 34572||-2||Microsoft PowerPoint OutlineTextRefAtom Parsing Vulnerability||System access, execution of arbitrary code with local user privileges||21.14%|| 2008- |\n|7||SA 39272||new||Adobe Reader / Acrobat Multiple Vulnerabilities||System access, execution of arbitrary code with local user privileges |\n|21.12%|| 2010- |\n|8||SA 29320||2||Microsoft Outlook \"mailto:\" URI Handling Vulnerability||System access, execution of arbitrary code with local user privileges||19.54%|| 2008- |\n|9||SA 39375||new||Microsoft Office Publisher File Parsing Buffer Overflow Vulnerability||System access, execution of arbitrary code with local user privileges||16.08%|| 2010- |\n|10||SA 37690||-1||Adobe Reader/Acrobat Multiple Vulnerabilities|| System access, execution of arbitrary code with local user privileges |\n|15.57%|| 2009- |\n6 out of 10 vulnerabilities were found in Microsoft products, 3 in Adobe products and 1 in a Sun product. This does not mean, however, that these companies’ products contain errors than products from other vendors, simply that these products are those which are most widely used.\nIn Q2, 2010 there were two new additions to the ten most widespread vulnerabilities: vulnerabilities in MS Office Publisher (SA 39375) and Adobe Reader (SA 39272). Both of them have a high threat rating because they can be used by cybercriminals to gain full access to a system and to execute arbitrary code. Both vulnerabilities were identified in the middle of April with one day between the disclosures.\nThe Microsoft automatic update system is now enabled by default on most computers, whereas the new update system for Adobe Reader/Acrobat Reader was only introduced on 13 April, 2010 along with the regular quarterly update. Automatic updates for popular applications are an important factor which affects the security of the operating system as a whole. Vendors who add update functionality to their products are going in the right direction as it not only makes it possible to add new functions but also, most importantly, patch security loopholes in an effective way. The quicker vendors release and automatically download patches to users’ machines, the less likely it is for these computers to get infected via vulnerabilities.\nStatistics from the Kaspersky Security Network show that 203,997,565 infection attempts were blocked in Q2, 2010.\nTwenty most common malicious programs detected on users’ computers in Q2, 2010\n|3||Net-Worm.Win32.Kido.ir||7.4%||0||Internet, removable disks|\n|5||Net-Worm.Win32.Kido.ih||3.82%||0||Internet, removable disks|\n|6||Net-Worm.Win32.Kido.iq||3.51%||0||Internet, removable disks|\n|7||Worm.Win32.FlyStudio.cu||2.78%||0||Local and removable disks|\n|14||Worm.Win32.Generic||1.19%||-4||Internet, removable disks|\n|15||Worm.Win32.Mabezat.b||1.16%||-4||Internet, removable disks, email, file infection|\n|16||Trojan-Dropper.Win32.Flystud.yo||1.11%||1||Network and removable disks|\n|17||Worm.Win32.Autoit.tc||1.02%||-4||Network and removable disks|\nFive out of twenty positions in the ranking are occupied by heuristic detections (Generic); this is because heuristic methods are one of the most effective ways of detecting complex threats.\nA range of Trojans, which are detected as Trojan.Win32.Generic (12%), head the table. These programs are unable to self-replicate, but have various payloads which range from stealing passwords to providing full access to a victim machine.\nMalware detected by Kaspersky Lab’s Urgent Detection System (UDS) as DangerousObject.Multi.Generic comes in second place, with 10%. The UDS technology provides real-time protection to users who have opted-in to KSN.\nIn third, fifth, and sixth place are three Kido modifocations which have maintained their positions since Q1. Although no new versions of Kido have appeared, and malware writers have not made further efforts to distribute the program, the worm’s propagation routine is extremely effective, and it therefore shows no signs of leaving the rankings. In contrast, there have been new variants of Sality (fourth place), a virus that infects executable files and which also maintains its position. Nevertheless, the most common modification remains Sality.aa, which first appeared at the end of 2008.\nThe ranking includes two programs written in “E”, a relatively uncommon programming language: Win32.FlyStudio.cu (seventh place) and Trojan-Dropper.Win32.Flystud.yo (sixteenth place). These malicious programs are regional, and mostly found only in one country, China. Trojan.Win32.Pakes.Krap.l (eighteenth place) is another new addition among malware writing in cripting languages; it detects obfuscated malware written in AutoIT.\nContrary to the previous quarter when there were no exploits among the most common malicious programs, this time there are two. Firstly, Exploit.Script.Generic (tenth place) which detects exploits written in different scripting languages. Second is Exploit.JS.Agent.bab (thirteenth place) which exploits the Internet Explorer vulnerability that allows cybercriminals to download and launch programs on a user’s computer. Kaspersky Lab statistics show that exploits are one of the most effective ways of infecting victim machines.", "label": 1}
{"text": "Excessive input is used to overrun input buffers, thus\noverwriting program or data storage so as to grant the attacker undesired\naccess. Examples include sendmail overflows resulting in unlimited system\naccess from attackers over the Internet, Web server overflows granting\nInternet attackers unlimited access to Web servers, buffer overruns in\nprivileged programs allowing users to gain privilege, and excessive input\nused to overrun input buffers causing loss of critical data so as to deny\nservices or disrupt operations.\nComplexity: In the case of denial of\nservice, these attacks are trivial to carry out with a high probability of\nsuccess. If the attacker wishes to gain access for more specific results,\nit is usually necessary to identify characteristics of the system under\nattack and create a customized attack version for each victim configuration.\nThis is not very complex but it is time and resource consumptive.", "label": 1}
{"text": "When using the Internet, unless you are very inquisitive, skilled and have a lot of time, you know nothing about the site you visit other than the information displayed by the site. Scammers work very hard to mask themselves with Web sites that appear legitimate. Their intention is to tempt you to disclose your personal information. In fact, sites set up to steal personal information have become significant and widespread enough to warrant labels like \"phishing\" and \"pharming.\"\nPhishing usually employs e-mail messages or Web advertisements enticing you to go to a phony site. The incentives range from unbelievably tempting deals, like a $500 bonus card if you submit your personal details to messages like \"There has been an unusually large purchase on your VISA card -- please visit our site to validate.\" Some phishing messages, called “spear phishing”, are personalized - an unsuspecting person receiving them cannot imagine that they are coming from scammers. For example, after you bid at an auction and do not win, you might receive a message telling you that you have been given a second chance to win at the price you offered. The scammers, pretending to belong to the auction site, take your money and you get nothing.\nPharming is an even more shifty approach. It uses DNS spoofing. This is a set of technical tricks, available on the Internet, which actually changes the destination of the URL that you see on your browser and directs you to an \"undercover\" site. In other words, you type www.mybank.com, you are sure you are accessing your bank, but you're actually entering a scam site.\nThere is a myth that the solution for phishing and pharming is tokens. These are small devices usually provided by banks or institutions who want their customers to connect to their web site. Some tokens can protect users from phishing, but most use a one-time password. In order to log into a site, the token is activated and the user is given a displayed password. The user must then type the password and login quickly because the password is valid for only a short time.\nA phishing technology known as \"man-in-the-middle\" succeeds in accessing accounts of users protected by OTP tokens. The phishing site fools the user into thinking that it is the real site he or she has accessed before. This phishing site works during the login process as a proxy. It is connected to the real site and transparently transfers the data between the real site and the user, until the login process is complete. At that point, the phishing site disconnects the user. The operator of the phishing site has full access to the account of the unsuspecting user. If it is a bank account, financial transactions can be executed. If it is a corporate or government site, confidential information can be extracted. Several man-in-the-middle attacks were detected in 2005 causing banks to turn down their online banking sites until the scam site was shut down.\nMost users are aware of the risks caused by phishing. They receive frequent e-mails from banks where they have no account and recognize the problem. Subsequently, most users are afraid of becoming victims. They get numerous frightening warnings about the grave consequences of providing personal information to scammers. As a result, most users refrain from executing transactions through online banking. Instead, they only view their accounts online. Banks try to encourage users to execute transactions, but users rightfully demand protection against Internet fraud.\nAlthough most users are aware of the risks in online banking, many of them are easy targets for unbelievable deals on the Internet. If they search for a new PC and find a half price offer from a company that has a name that looks familiar, they may choose to buy from that vendor and submit personal details, unaware of the fact that the site is bogus. Because of fear and uncertainty many e-commerce sites face a problem. Users that have bought goods and services on unfamiliar e-commerce sites have become more suspicious. Instead of looking for the best deal, they limit their search to large, well-known sites. Medium and small sites are the victims of this trend, and they are unable to influence users' behavior.\nMany sites, especially large e-commerce and online banking sites, ask users to login in order to execute a transaction. The simple login process, utilizing user name and password makes it an ideal target for scammers.\nThe phishing and pharming scams discussed above tempt users to disclose their login parameters. But even if the user is well protected against phishing and pharming, a spyware - malicious software that may sneak into the user’s machine, can detect the keystroke sequence or the sequence of mouse clicks and the associated screenshots used to login to a site, and send this sequence to an external source while the user remains unaware of the problem.\nCallingID, a software company based in New Haven, Connecticut, provides solutions to encourage usage of Internet for business and to avoid all the potential problems of Internet fraud. CallingID for the Internet is a solution for individual users. CallingID Safety Seal is a website solution that provides strong authentication and anti-fraud protection. This solution focuses on online banking, eCommerce and corporate sites.\nCallingID for the Internet\nCallingID for the Internet is a simple browser add-on.. When users install CallingID they experience the Internet from a new angle. For the first time they see who owns the sites they visit, where the owner is located and receive an immediate indication about the risk level of sending data to these sites. When visiting msn.com they see that the site is owned by Microsoft and it is OK to send personal information to this site, but when they visit kazza.com they see that the owner of this site is hiding his identity and consequently, sending data to such a site is considered high risk (information sent to someone who deliberately hides his identity may be used by scammers). CallingID verifies for the user when it is OK to send data, particularly personal information which requires an encrypted session, and when there is a risk involved.\nCallingID's unique use of 52 different verification tests to evaluate web sites provides the highest level of protection. When any of these tests fail, the users are urged to rethink their intention to submit personal information, username, password and credit card number, or to place an order from that site. It summarizes the results of the tests in a simple indication to help the user decide whether to proceed.\nIndicates that exposing private or confidential information to this site is very risky and may be misused by the site owner. Such risk is a result of a pattern usually utilized by scammers. It may be, for example, masking site owner's identity; using a pirate server in a legitimate site or using a known phishing site.\nReveals that the site has a problem. The user should be aware of the problem and decide whether to take the risk of sending data to such a site. Low risk sites are sites whose owner was not identified as an organization conducting business, sites that were not registered correctly, etc.\nSignals that it is safe to submit information and make purchases at these sites. The site was identified as an organization conducting business located at a real address and passed all 52 verification tests.\nCallingID provides you with added value beyond the protection - whenever you visit a site you automatically see who owns it, and where its owner is located. This information is particularly useful when visiting new sites and deciding if they are real businesses and whether to trust the information provided by them.\nSamples of a phishing site and the real PayPal site with CallingID indications:\nCallingID for the Internet uniqueness:\n1. CallingID is a comprehensive solution. It uses databases that contain information about more than 200,000,000 companies.\n2. CallingID has a unique technology to automatically find the actual owners of web sites and their addresses. The technology validates that the owner is a real organization conducting business at the address it claims to be. The process is usually completed in 30 seconds when a positive verification is achieved and within 60 seconds when the automatic verification fails. In such a case a manual process is executed where a group of analysts try to manually detect whether the site belongs to a real organization at a specific address.\n3. CallingID detects sites that hide the owner identity. These sites are defined as High-Risk unless their owners contact CallingID and provide sufficient information to verify their real name and location.\n4. CallingID looks inside the web page to detect cases where data you type will be sent to a site other than the site you visit.\n5. CallingID uses its black lists of fraud sites to protect users automatically. More than 100 new phishing sites are detected daily and added to that list.\n6. CallingID displays its data in a short toolbar that automatically expands when the mouse is dragged over it. We received many positive comments because users appreciate that it does not take much of their valuable space.\nCallingID Safety Seal\nCallingID Safety Seal is an ideal solution for eCommerce, corporate sites and banks. When users of these sites try to login to their account at the site, they are well protected against attempts to use their login parameters and credentials. The solution is composed of three levels of protection to shield users when they log into a web site.\n- Site Authentication for the user. The users are shown a unique shared secrete they have disclosed to the site. They known that the site is authentic before they login.\n- Automatic detection of phishing sites. Extra level of protection is added, enabling automatic detection of login attempts to suspected sites. All known phishing techniques, including man-in-the middle, frame injection and pharming (DNS spoofing) are automatically detected. CallingID stops the user before login data is submitted and the user is alerted to abort.\n- Neutralization of spyware. Even if the users’ computer is infected by hostile software like spyware, Trojan, screen capture or key-logger, his login parameters cannot be identified by that software. When a user logs into his online account, in cases where such hostile software exists the hostile software is led to detect a false password while the real password is safely delivered to the site using strong encryption. CallingID uses special technology that thwarts all hostile software.\nSafety Seal is available for any Internet web site and requires registration of the site with CallingID. Two different versions are available:\nSafety Seal Basic - Provides all web users basic protection against Internet fraud, without installing any software on the client PC, whenever they log into a website registered with Safety Seal.\nSafety Seal Pro - Provides the functionality of Safety Seal Basic as well as a strong encryption of the password typed by the user, neutralizing Trojans and spyware from detecting the real password.\nInstitutions offering CallingID Safety Seal to their clients now have a way to considerably reduce the risk and concern that their clients have of being scammed, thus addressing their reluctance to conduct business over the Internet. The clients feel that the institution has taken the necessary steps to secure them, and since no complex procedure is added, they can significantly increase their business activities with the institution. We see this solution widely adopted by banks since Safety Seal helps banks comply with the latest FFEIC guidelines of October 2005 and two FDIC recommendations of June 2005 for a reliable form of authentication for customers when accessing their account online, and July 2005 for the protection of their customers against spyware.\nThe recommendations can be found at\nThe institutions will also be considered by their customers as proactive at protecting their interests and removing the barriers for executing online transactions.\nInternet fraud has become a real threat for e-commerce and online banking. CallingID provides a comprehensive set of solutions that individuals can count on when using the Internet. The solutions are simple to use and are powerful enough so consumers can feel free to shop online. They know with whom they are dealing and when a problem is detected, they will be made aware of it immediately.\nWhen users login to a web site protected by Safety Seal, the simple process of providing username and password is protected, keeping users’ login parameters out of reach for phishing sites and spyware.\nCallingID was established in 2004 with the goal of encouraging computer users to utilize the Internet safely for business while avoiding Internet fraud – Phishing, pharming, spyware and Trojans. CallingID products enable safer browsing and promote healthy consumer practice. CallingID is headquartered in New Haven, Connecticut. Its team is composed of veteran executives and highly acclaimed software security professionals. The R&D center is located in Haifa, Israel.", "label": 1}
{"text": "A long-time reader of Dr. Dobb's recently asked me why anyone would code in C anymore. This theme has lately appeared in some comments posted on our site, and earlier in several conversations with industry figures, particularly at Microsoft. In the early days of C++, there were many reasons to choose either C or C++ depending on your needs; but as C++ has evolved, a lot of the traditional distinguishing traits of C have indeed become less advantageous. Because these points are generally the first to appear in any comparison of the two languages, let's examine them.\n- IDC Analyst Connection: Using Blade Systems to Cut Costs and Sharpen Efficiencies\n- Application Testing Strategies in the IBM z/OS Environment\n- Strategy: How to Conduct an Effective IT Security Risk Assessment\n- Strategy: Smartphone Smackdown: Galaxy Note II vs. Lumia 920 vs. iPhone 5\n- The Untapped Potential of Mobile Apps for Commercial Customers\n- Why is Information Governance So Important for Modern Analytics?\nPerformance. It used to be true that C++ was considerably slower than C. But on most major platforms, the difference in performance today is small. The computer benchmarks hosted on Alioth, for example, show that C++ (running on 32-bit Linux) runs the series of tests 27% slower than C. Other surveys show this difference as slightly larger or slightly smaller. But in almost all cases, C++ is the next fastest language after C. It is generally much faster than JVM and .NET hosted languages. So, while C retains an advantage in benchmarks, in most apps that would accept Java performance (so, any enterprise apps or client-facing software), the difference is not substantial.\nUbiquity. In the embedded programming world, where C is still happily ensconced as the primary language, it is preferred due to the fact that every hardware vendor offers a C compiler. It used to be true that C++ did not figure strongly in embedded development. However, today most component vendors who offer programming tools offer a C++ compiler. (The consistent exception is in PIC microcontrollers.) This is a dwindling benefit.\nPortability. C++ used to be a dog to port. (Actually, C was, too, before the C89 standard.) However, compilers nowadays have implemented the core of the C++ language sufficiently that most software can be recompiled with few, if any, tweaks, provided the code is written, as Brian Kernighan once put it, \"down the middle of the language.\" Library portability presents a more troublesome factor, but the same problem exists with C libraries. In both C and C++, standards compliance of compilers varies tremendously, so using features that are not fully supported (C99 and C11, C++11) is an equally inherent risk. That being said, C89 is probably the most portable code in the world. (And for this reason, it's chosen where portability is an overriding concern. For example, the Lua team chose C for this reason as well as its performance.)\nIt is fair to say that for performance, ubiquity, and portability, C still has advantages over C++, but that those advantages are steadily diminishing. In this regard, the C++ community has done well by its users to address what were once substantial obstacles to adoption. The question is: Do those shrinking advantages offset the benefits of C++? These include object orientation, exception handling, better type management, templates, larger standard libraries, and so on. Without those benefits, every project in C can feel like trying to mow the lawn with a pair of scissors.\nThose features certainly help getting the code written, but they have a cost complexity which is where C most readily distinguishes itself from C++. C is one of the few general programming languages that is small and simple enough that you can get your arms entirely around it. It is indeed possible to know the ins and outs of the language completely, as well as knowing the standard library well enough to use it without having to look up an API call. I don't believe this is possible in any other major language, certainly not C++.\nThis smallness is one of the language's attractions. You can learn it quickly and be productive fast. This simplicity is enhanced by another rarely discussed characteristic: the supreme legibility of the language. I mean this semantically in addition to syntactically. Semantically, there are a very limited number of ways to do things in C. Consequently, when you read the code anyone's code you know exactly what they're doing. C++, by contrast, has many different ways to do the same thing a flexibility that its developers enjoy. Because of C's clarity in this respect, it is an excellent language for writing complex infrastructure. For this reason, the original writers of the JRockit JVM (now, Oracle's primary JVM) chose C. In conversations a few years ago, they articulated their view that by choosing C, and not C++, they could onboard developers more quickly; and when doing deep dives into the code, they could understand what they were looking at much more easily than in C++.\nFor this alone, C remains an excellent choice for systems-level code: It's fast, it's portable, it's easy to read and understand. For applications, though, where the emphasis is more on development productivity, it's clear that C++ will continue to dominate native languages and likely expand its footprint.", "label": 1}
{"text": "The cloud is an abstract notion of a loosely connected group of computers working together to perform some task or service that appears as if it is being fulfilled by a single entity. The architecture behind the scenes is also abstract: each cloud provider is free to design its offering as it sees fit. Software as a Service (SaaS) is a related concept, in that the cloud offers some service to users. The cloud model potentially lowers users' costs because they don't need to buy software and the hardware to run it — the provider of the service has done that already.\nTake, for example, Amazon's S3 offering. As its name implies, it is a publicly available service that lets Web developers store digital assets (such as images, video, music, and documents) for use in their applications. When you use S3, it looks like a machine sitting on the Internet that has a hard drive containing your digital assets. In reality, a number of machines (spread across a geographical area) contain the digital assets (or pieces of them, perhaps). Amazon also handles all the complexity of fulfilling a service request to store your data and to retrieve it. You pay a small fee (around 15 cents per gigabyte per month) to store assets on Amazon's servers and one to transfer data to and from Amazon's servers.\nRather than reinvent the wheel, Amazon's S3 service exposes a RESTful API, which enables you to access S3 in any language that supports communicating over HTTP. The JetS3t project is an open source Java library that abstracts away the details of working with S3's RESTful API, exposing the API as normal Java methods and classes. It's always best to write less code, right? And it makes a lot of sense to borrow someone else's hard work too. As you'll see in this article, JetS3t makes working with S3 and the Java language a lot easier and ultimately a lot more efficient.\nLogically, S3 is a global storage area network (SAN), which appears as a super-big hard drive where you can store and retrieve digital assets. Technically though, Amazon's architecture is a bit different. Assets you choose to store and retrieve via S3 are called objects. Objects are stored in buckets. You can map this in your mind using the hard-drive analogy: objects are to files as buckets are to folders (or directories). And just like a hard drive, objects and buckets can be located via a Uniform Resource Identifier (URI).\nFor example, on my hard drive, I have a file named whitepaper.pdf, which is in the folder named documents in my home directory. Accordingly, the URI of the .pdf file is /home/aglover/documents/whitepaper.pdf. In S3's case, the URI is slightly different. First, buckets are top-level only — you can't nest them as you would folders (or directories) on a hard drive. Second, buckets must follow Internet naming rules; they can't include dashes next to periods, names shouldn't contain underscores, and so on. Lastly, because bucket names become part of a public URI within Amazon's domain (s3.amazonaws.com), bucket names must be unique across all of S3. (The good news is that you can only have 100 buckets per account, so it's doubtful there are squatters taking hundreds of good names.)\nBuckets serve as the root of a URI in S3. That is, a bucket's name becomes part of the URI leading to an object within S3. for example, if I have a bucket named agdocs and an object named whitepaper.pdf, the URI would be http://agdocs.s3.amazonaws.com/whitepaper.pdf.\nS3 also offers the ability to specify owners and permissions for buckets and objects, as you can do for files and folders on a hard drive. When you define an object or a bucket in S3, you can specify an access-control policy that states who can access your S3 assets and how (for example, read and write permissions). Accordingly, you can then provide access to your objects in a number of ways; using a RESTful API is just one of them.\nTo begin using S3, you need an account. S3 isn't free, so when you create your account you must provide Amazon with a means of payment (such as a credit card number). Don't worry — there are no setup fees; you only pay for usage. The nominal fees for the examples in this article will cost less than $1.\nAs part of the account-creation process, you also need to create some credentials: an access key and a secret key (think username and password). (You can also obtain x.509 certificates; however, they are only needed if you use Amazon's SOAP API.) As with any access information, it is imperative that you keep your secret key ... secret. Should anyone else get hold of your credentials and use them to access S3, you'll be billed. Consequently, the default behavior any time you create a bucket or an object is to make everything private; you must explicitly grant access to the outside world.\nWith an access key and a secret key in hand, you can download JetS3t and use it with abandon to interact with S3 via its RESTful API via.\nProgrammatically signing into S3 via JetS3t is a two-step process. First, you must\nAWSCredentials object and then pass it into a\nS3Service object. The\nAWSCredentials object is fairly straightforward. It takes your access and secret keys as\nS3Service object is actually an interface type. Because S3 offers both a RESTful API and a SOAP API, the JetS3t library offers two implementation types:\nSoapS3Service. For the purposes of this article (and indeed, most, if not all of your S3 pursuits), the RESTful API's simplicity makes it a good choice.\nCreating a connected\nRestS3Service instance is simple, as shown in Listing 1:\nListing 1. Creating an instance of JetS3t's\ndef awsAccessKey = \"blahblah\" def awsSecretKey = \"blah-blah\" def awsCredentials = new AWSCredentials(awsAccessKey, awsSecretKey) def s3Service = new RestS3Service(awsCredentials)\nNow you are set to do something interesting: create a bucket, say, add a movie to it, and then obtain a special limited-time-available URL. In fact, that sounds like a business process, right? It's a business process associated with releasing a limited asset, such as a movie.\nFor my imaginary movie business, I'm going to create a bucket dubbed bc50i. With\nJetS3t, the process is simple. Via the\nS3Service type, you have a few options. I prefer to use the\ngetOrCreateBucket call, shown in Listing 2. As the name implies, calling this method either returns an instance of the bucket (represented by an instance of the\nS3Bucket type) or creates the bucket in S3.\nListing 2. Creating a bucket on a S3 server\ndef bucket = s3Service.getOrCreateBucket(\"bc50i\")\nDon't let my simple code examples fool you. The JetS3t library is fairly extensive. For\ninstance, you can quickly ascertain how many buckets you have by simply asking an instance of an\nS3Service via the\nlistAllBuckets call. This method returns an array of\nS3Bucket instances. With any instance of a bucket, you can ask for its name and creation date. More important, you can control permissions associated with it via JetS3t's\nAccessControlList type. For instance, I can grab an instance of my bc50i bucket and make it publicly available for anyone to read and write to, as shown in Listing 3:\nListing 3. Altering the access-control list for a bucket\ndef bucket.acl = AccessControlList.REST_CANNED_PUBLIC_READ_WRITE\nOf course, via the API, you are free to remove buckets too. Amazon even allows you to specify in which geographical areas you'd like your bucket created. Amazon handles the complexity of where the actual data is stored, but you can nudge Amazon to put your bucket (and then all objects within it) in either the United States or Europe (the currently available options).\nCreating S3 objects with JetS3t's API is just as easy as bucket manipulation. The library is also smart enough to take care of some of the intricacies of dealing with content types associated with files within an S3 bucket. For instance, imagine that the movie I'd like to upload to S3 for customers to view for a limited time is nerfwars2.mp4. Creating an S3 object is as easy as creating a normal\njava.io.File type and associating the\nS3Object type with a bucket, as I've done in Listing 4:\nListing 4. Creating an S3 object\ndef s3obj = new S3Object(bucket, new File(\"/path/to/nerfwars2.mp4\"))\nOnce you've got a\nS3Object initialized with a file and a bucket, all you need to do is upload it via the\nputObject method, as shown in Listing 5:\nListing 5. Uploading the movie is a piece of cake\nWith the code in Listing 5, you're done. The movie is now on Amazon's servers, and the key for the movie is its name. You could, of course, override that name should you feel the need to call the object something else. In truth, the JetS3t API (and by relation the Amazon S3 RESTful API) exposes a bit more information for you when you create objects. As you know, you can also provide access-control lists. Any object within S3 is capable of holding additional metadata, which the API allows you to create. You can later query any object via the S3 API (and by derivation, JetS3t) for that metadata.\nAt this point, my S3 instance has a bucket with a movie sitting in it. In fact, my movie can be found at this URI: http://bc50i.s3.amazonaws.com/nerfwars2.mp4. Yet, no one other than me can get to it. (And in this case, I can only access it programmatically, because the default access controls associated with everything are set to deny any noncredentialed access to it.) My goal is to provide select customers a way to view the new movie (for a limited time) until I'm ready to start charging for access (which S3 can facilitate as well).\nFigure 1 shows the default access control in action. The XML document returned (and accordingly displayed in my browser) is informing me that access is denied to the asset I was trying to reach (http://bc50i.s3.amazonaws.com/nerfwars2.mp4).\nFigure 1. Amazon's security in action\nCreating a public URL is a handy feature exposed by S3; in fact, with S3, you can create a public URL that is only valid for a period of time (for instance, 24 hours). For the movie I've just stored on the S3 servers, I'm going to create a URL that is valid for 48 hours. Then I'll then provide this URL to select customers so they can download the movie and watch it at will (provided they download it within two days).\nTo create a time-sensitive URL for an S3 object, you can use JetS3t's\ncreateSignedGetUrl method, which is a static method of the\nS3Service type. It takes a bucket name, a object's key (the movie's\nname in this case, remember?), some credentials (in the form of JetS3t's\nAWSCredentials object), and an expiration date. If you know the desired bucket name and the object's key, you can quickly obtain a URL as shown in the Groovy code in Listing 6:\nListing 6. Creating a time-sensitive URL\ndef now = new Date() def url = S3Service.createSignedGetUrl( bucket.getName(), s3obj.key, awsCredentials, now + 2)\nWith Groovy, I can specify a date 48 hours in the future quite easily via the\n+ 2 syntax. The resulting URL looks something like this (on a single line):\nNow, with this resultant URL, browser requests will honored, as shown in Figure 2:\nFigure 2. The URL facilitates downloading\nWasn't this process a piece of cake? With a few lines of code, I've created a secure asset in the cloud that can only be downloaded with a special URL.\nS3 makes a lot of sense if your bandwidth and storage needs aren't constant. For example, imagine the business model I'm demonstrating — one in which movies are released at specific times throughout the year. In the traditional storage model, you'd need to buy a bunch of space on a rack somewhere (or provide your own hardware and pipe leading to it) and most likely see spikes of downloads followed by lulls of relatively low activity. You'd be paying, however, regardless of demand. With S3, the model is satisfied based on demand — the business pays for storage and bandwidth only when it's required. What's more, S3's security features let you further specify when people can download videos and even specify who can download them.\nAchieving these requirements with S3 turns out to be quite easy. At a high level, creating a limited publicly available download for a movie requires four steps:\n- Sign into S3.\n- Create a bucket.\n- Add a desired video (or object) to that bucket.\n- Create a time-sensitive URL for the video.\nS3's pay-as-you-go model has some obvious advantages over the traditional storage model. For instance, to store my music collection on my own hard drive, I must buy one — say a 500GB unit for $130 — up front. I don't have nearly 500GB of data to store, so in essence I'm paying roughly 25 cents per gigabyte for unneeded (albeit fairly inexpensive) capacity. I also must maintain my device and pay to power it. If I go the Amazon route, I don't need to fork out $130 up front for a deprecating asset. I'll pay about 10 cents less per gigabyte and needn't pay to manage and maintain the storage hardware. Now imagine the same benefits on an enterprise scale. Twitter, for example, stores the images for its more than 1 million user accounts on S3. By paying on a per-usage basis, Twitter is spared the high expense of acquiring a hardware infrastructure to store and serve up those images, as well as ongoing labor and parts costs to configure and maintain it.\nThe cloud's benefits don't end there. You also gain low latency and high availability. The presumption is that the assets stored on Amazon's cloud are physically located around the globe, so content is served up faster to varying locations. What's more, because your assets are distributed to various machines, your data remains highly available should some machine (or portion of the network) go down.\nIn summary, the benefits of Amazon's S3 are simple: low cost, high availability, and security. Unless you're a SAN guru and enjoy maintaining hardware assets for storing digital items, Amazon probably does a better job than you. So why spend the up-front money on hardware (which loses value over time, don't forget) when you can borrow someone else's?\nAmazon S3: Visit home base for the Amazon Simple Storage Service.\nJetS3t: Learn more about the JetS3t toolkit and application suite.\nCloud Computing: Visit IBM Cloud Computing Central for a wealth of cloud resources.\ntechnology bookstore for books on these and other technical topics.\ndeveloperWorks Java technology zone: Find hundreds of articles about every aspect of Java programming.\nGet products and technologies\nJetS3t: Download JetS3t.\ndeveloperWorks Cloud Computing Resource Center: Access IBM software products in the Amazon Elastic Compute Cloud (EC2) virtual environment.\nAndrew Glover is a developer, author, speaker, and entrepreneur. He is the founder of the easyb Behavior-Driven Development (BDD) framework and is the co-author of three books: Continuous Integration, Groovy in Action, and Java Testing Patterns. He teaches a wide variety of Groovy-, Grails-, and testing-related classes at ThirstyHead.com. You can keep up with Andy at thediscoblog.com, where he routinely blogs about software development.", "label": 1}
{"text": "Defeating online con-men: Resisting social engineering and phishing attacks\nIn today's high-tech world, security threats abound. As online criminals like con-artists, identity thieves and sexual stalkers have come into the limelight, people have become increasingly more cautious. But many computer users are often completely unaware of one of the biggest threats in the electronic world - social engineering.\nIn fact, some experts say that social engineering will become the greatest threat to any security system, which includes personal computers, financial systems and even cell phones or PDAs.\nSo what is social engineering anyway? In simple terms, social engineering is a form of deception carried out by an attacker - an online con-artist, of sorts - that attempts to convince the victim to do something that would compromise their safety. This can include computer, financial or physical safety.\nThe strength and weakness of social engineering attacks is that they absolutely require human intervention. If the potential victim sees through the attack and realizes that the attacker(s) aren't who they claim to be, then the attack attempt has no teeth and no permanent damage is done. Education is key.\nMany such attacks attempt to convince the potential victim to do something unwise like providing user names and passwords to their computer, providing financial account numbers or giving credit card numbers to an attacker who is often masquerading as someone or something else. Phishing attempts aren't restricted to computers and can occur via phone or other communication mediums.\nUnfortunately, many users trustfully provide the information, not knowing that the attacker isn't legitimate or that the information may be used to harm them or others.\nOne early form of social engineering involved a circulating email message that claimed to be from an anti-virus and computer security institution, instructing users to check for a specific file on their computers. If the file was there, the message claimed, it meant that the computer was infected with a virus. The message instructed users to promptly delete the file to remove the virus. The problem was, the file was entirely legitimate and was required for normal computer operation. Many computer users blindly followed the instructions and soon thereafter had to find help to fix the problem.\nNaturally, most recipients trust such messages from friends or family unequivocally, and to their own demise, often follow the directions in the email. Others forward the messages along to friends or family, thinking they are doing them a service. This is why social engineering attacks are often so successful.\nTo further the problem, many victims feel foolish for falling into the attacker's trap in the first place. Out of embarrassment, many victims will lie outright to a computer technician and deny they have done anything to their computer. But withholding such information makes it harder for the technician to diagnose and repair the problem, which only puts more anguish on the victim. A good computer repair technician understands that these attacks happen to the best of us and will be understanding and helpful in fixing the problem. Like with many other situations, a person's best policy in this situation is honesty.\nAnother common social engineering attack is sent in the form of an email message that parades as the potential victim's financial institution, and asks them to go to the site provided in the message and provide user names, passwords and financial account numbers to \"verify\" the person's account information.\nAnd yet another common social engineering attack claims to be from a legal representative of a so-called long-lost relative that has died and willed their massive fortunes to the potential victim. All they need, they claim, is the user's financial information, and the riches will be transferred into the victim's financial account.\nSadly, many are intrigued by the prospect of being rich and follow the directions in the email. What these people find out is that these con-artists do the entire opposite - transfer every penny out of the victim's financial account, often swindling them out of hundreds or even thousands of dollars.\nLike the saying goes, \"if it's too good to be true, it probably isn't true.\" In the online world, this sentiment will save potential victims time and time again.\nBut many social engineering attacks aren't so easy to detect. Phishing, for example, is a form of social engineering that lures the victim into revealing information based on the false premise that an established brand name must be naturally trustworthy.\nPhishing attacks often come in the form of website forgeries. An unsuspecting victim will visit the site thinking it is something else. When the user provides their user name and password, the attacker records it on the system and then uses it to access the person's financial account via the real website.\nFor example, suppose a person utilizes financial services through a fictitious bank called Example Bank. Example Bank has a website where customers can access their bank account online via the Internet. Suppose an attacker creates a site of their own that looks identical to the Example Bank's official site and sends a forged email to a handful of people, claiming to be from Example Bank.\nSuppose one of the recipients decides to visit the attacker's site, not realizing it isn't legitimate. They attempt to login but receive an error page saying the service is temporarily unavailable and to check back in a few days.\nAt this point, the attacker now has the recipient's user name and password, which they use to access their financial account and swindle them out of money. By the time the recipient realizes what has happened, the attacker has already robbed them.\nFortunately, legitimate financial institutions are aware of most phishing techniques and the potential for problems that they bring. And as a result, most of them have already instituted policies and protections to help prevent such attacks from being successful. But it isn't a substitute for good education and sound judgment.\nBrowser makers have also come forward with help. Many modern browsers now include phishing features that try to detect website forgeries and immediately notify the user. Microsoft Internet Explorer 7 and Mozilla Firefox 2.0 are just a few of the several browsers that do.\nBut by far the best weapon people have against social engineering attacks is knowledge. With a heightened awareness and information about how attacks happen, people can protect themselves from being exploited in the first place.\nNever delete system files or make system configuration changes without personal instructions (preferably verified by a phone call or personal visit) from a technical expert they know and trust.\nLearn to protect and value their personal information. This means understanding when providing personal information is necessary and appropriate.\nNever provide financial account information, user names or passwords via email or instant messaging (IM).\nNever trust email messages that appear to be from their financial institution unless they have explicitly asked for them and know they are genuine.\nReport any website forgeries of their financial institution's website to the institution itself.\nEnsure anti-virus software and virus definitions are up to date.\nEnsure their computer is up to date with the latest bug patches and security updates.\nRefrain from installing untrusted or questionable software on your computer. Everyone should heavily scrutinize software downloaded from public networks like LimeWire or Gnutella.\nCheck with their local financial institution to gain additional information about policies and procedures the institution employs to protect customers from phishing and other forms of social engineering.\nHave comments about this article or suggestions for a future Tech Tips article? Send an e-mail to firstname.lastname@example.org.", "label": 1}
{"text": "Leave it to the computer scientists to turn baby pictures into a slick animation that traces faces through the years.\nThe technique is already being put to use on Google's Picasa photo-sharing website as a feature called \"Face Movie.\"\n\"I have 10,000 photos of my 5-year-old son, taken over every possible expression,\" Steve Seitz, a computer science and engineering professor at the University of Washington and an engineer at Google's Seattle office, said today in a news release about the research project. \"I would like to visualize how he changes over time, be able to see all the expressions he makes, be able to see him in 3-D or animate him from the photos.\"\nSeitz and his colleagues have already started down that road, thanks to the university's \"Photobios\" project. UW researcher Ira Kemelmacher-Shlizerman is due to present their research next week in Vancouver, B.C., at a meeting of the ACM Special Interest Group on Computer Graphics and Interactive Techniques, or SIGGRAPH.\nRapid advances in image recognition\nPhotobios take advantage of rapid advances in automated image recognition and tagging. In the past, such advances led to the development of Microsoft's Photosynth technology for re-creating clickable 3-D scenes from a \"cloud\" of images taken from many different angles. (Microsoft and NBC Universal are partners in the msnbc.com joint venture.)\nPicasa's Face Movie feature takes that one step further by building in face recognition and name-tagging.\n\"This work provides a motivation for tagging,\" Seitz said. \"The bigger goal is to figure out how to browse and organize your photo collection. I think this is just one step toward that bigger goal.\"\nTo build a Photobio, you'd start with a collection of photos showing the same person, whether they show your daughter or George W. Bush. You can arrange the photos chronologically, or specify the beginning and end points. The software automatically identifies the face and major features, lines up the eyes and morphs smoothly from one image to the next. Automated morphing is one of the key reasons why the results are so easy to produce and easy on the eyes.\n\"There's been a lot of interest in the computer vision community in modeling faces, but almost all of the projects focus on specially acquired photos, taken under carefully controlled conditions,\" Seitz said. \"This is one of the first papers to focus on unstructured photo collections, taken under different conditions, of the type that you would find in iPhoto or Facebook.\"\nBetter 3-D avatars\nKemelmacher-Shlizerman and Seitz are already working on the next step: taking a collection of photos and turning them into a movable 3-D model of a face. They'll be presenting research on that topic this fall at the International Conference on Computer Vision in Barcelona, Spain.\nThe researchers say such models could be used to create more realistic animated avatars for use in video conferencing or game play. More accurate face modeling also could well lead to improved face-recognition programs, for personal use (that is, sorting through the pictures on your hard drive or Facebook friend list) as well as for security applications (that is, matching up a photo taken at a security checkpoint with a database of images taken from different perspectives).\nDoes that sound cool, or scary? Feel free to weigh in with your thoughts on face-tracing and other image-recognition applications you'd like to see.\nIn addition to Seitz and Kemelmacher-Shlizerman, the authors of the SIGGRAPH presentation, \"Exploring Photobios,\" include Eli Shechtman and Rahul Garg. The research was funded by Google, Microsoft, Adobe Systems and the National Science Foundation.\nConnect with the Cosmic Log community by \"liking\" the log's Facebook page or following @b0yle on Twitter. You can also check out \"The Case for Pluto,\" my book about the controversial dwarf planet and the search for new worlds.", "label": 1}
{"text": "For K-12 educators, facility directors and planners, school security for K-12 has become a critical issue as schools across the Country work to ensure they are prepared for any eventuality. Certainly all the appropriate actions and responses have not been formulated, but we can and we must be prepared as professionals to recommit to review and consider measures that can make a difference while permitting schools to retain the look of creative learning environments and not fortresses. At many contemporary K-12 facilities, security protocol for visitor access is in place at the school utilizing typical visual “vetting” and subsequent manual release of an electromagnetic lock at the entrance door. However, schools need to be aware of the risk of an unauthorized person to be able to gain access directly into the internal corridor network of the occupied school and the classrooms. This type of incursion can overwhelm all the measures in place designed to detect and deter unauthorized access at defined perimeters. Currently in most schools, the primary premise of contemporary security systems concentrates on the surveillance, detection and reasonable deterrence of unauthorized entry. Reasonable deterrence most typically translates to a locked door, and often to assist in the visual vetting process glass is present in both the door and the surrounding wall system. This glass may typically be either tempered or heat strengthened for safety reasons upon breakage, but it possesses very little resistance capability.\nThe search for solutions and new measures to safeguard the K-12 environment from unauthorized incursions and their negative impacts is reaching full speed. It has been an important educational premise to treat schools with special care to nurture creativity and the learning process; it would almost be unthinkable to take steps backward and move towards more correctional-like environments. To understand where improvements may be necessary it is important to consider the state of contemporary K-12 security. Currently measures may include any number of layered active and passive measures that focus on being able to identify a potential event and communicate and react to it as quickly as possible. Generally, security measures should afford school administrators more time to assess the situation, communicate with interfacing agencies, and notify occupants of the facility. Minutes, indeed seconds, can be critical in these assessments and interventions.. Disrupting the timing or progression of a potential event before it escalates is an inclusive part of an effective tiered strategy. Passive security measures can be simple things such as direct visual access from administration areas to the front door, access drive and parking lot and beyond and redundant communication features to quickly relay the event to authorities and school occupants. Active security measures include numerous types of physical safeguards such as restricted access doorways, metal detectors , secure areas or vestibules and even the use of supplemental armed security.\nAlthough certainly not foolproof, one of the most direct but least invasive methodologies incorporated into contemporary security protocols for school access is the use of a security vestibule. This convention upgrades the ability to more fully evaluate every visitor of the school prior to granting direct access into the internal corridor network of the school. The security vestibule can augment the closed circuit interface process where direct visual access to the front door is not available. With this architectural configuration, all core hour visitors must use this designated location and are tentatively cleared and first routed directly into a secure or unsecured portion of the administration office of the school where they are credentialed and granted or denied access to the interior of the school. This strategy may now need to be revisited.\nThe configuration of this inner secure area as open to the interior administration area will undoubtedly be under greater scrutiny by administrators and designers. “Hardening” of this inner secure area by the use of concrete masonry walls and bullet resistant glass to detain the visitor from further entering or exiting the building if the need arises may need to be considered. This potentially new secure inner area effectively removes the face to face vetting of a visitor by school administration and both protects them and access to the interior of the school by destructive intrusion. The use of bullet resistance glazing for this hardened interior vestibule can be accomplished without unreasonable cost and it can be visually compatible with other glazing. Locations for this new hardened secure area could include adjacent main entries to buildings similar to current configurations or at a separate “visitor” location where they have the ability to be more remote from the administration area or “front door” of the facility. Other layered protocols can still be added to the sequence such as drivers license data base checks and/or metal detectors. Precautions against destructive intrusion should additionally be reviewed at primary entrances for potential hardening, but notably main entry doors to the facility should be evaluated for inclusion particularly where they are associated with any new hardened secure area. This process will undoubtedly take much thought and discussion, but the best overall security strategies remain the ones that incorporate multiple layered and redundant protocols. The inclusion of hardening select building elements should be considered as an augmentation to those comprehensive strategies. Any protocol that provides additional minutes or seconds of time to has the potential to save lives.", "label": 1}
{"text": "More than 400 mobile viruses have been documented to date, resulting in tens of thousands of infections worldwide. These numbers may pale in comparison with Win32, but Patrik Runald, Chief Security Advisor at F-Secure, believes they are a wake-up call. \"At some point, the criminals now developing PC malware will start focusing on mobile devices,\" Runald said. \"It's not a question of if, but when and how. I'm keeping a close eye on the iPhone -- it may be the tipping point that sets the mobile malware field afire.\"\nThat was then\nSkeptics have long scoffed at the prospect of mobile malware. Why? The mobile market was too small to represent a worthwhile target. Mobile devices were too diverse and too limited to facilitate large-scale attacks. And mobile devices lacked the connectivity and infection vectors required to propagate malware rapidly, without depending on user interaction. To appreciate these impediments -- and how they're changing -- it's helpful to consider the history of mobile malware.\nPalm Liberty was arguably the first, debuting back in August 2000. This trojan posed as a patch to register Nintendo Gameboy emulator shareware but actually deleted all applications from the infected Palm PDA. Liberty failed to spread in the wild because it targeted a very small number of naïve users and immediately rendered any victims inoperable. In fact, Liberty was so unsuccessful that most antivirus companies begin their mobile malware signature lists with Cabir.\nSymbian Cabir (the predecessor of 15 variants) was released in June 2004. This worm infects Symbian Series 60 smartphones by sending itself over Bluetooth connections. It requires the victim to open a messaging Inbox file and click Yes when prompted by the installer. Cabir then tries to spread by searching for nearby Bluetooth devices in discoverable mode. Although Cabir infections have been reported in more than 20 countries, most antivirus companies consider it low risk. Why? Cabir targeted a very popular device but propagated far too slowly, infecting just one phone per reboot. For most victims, Cabir's only adverse impact was battery drain.\nSibling Mabir had somewhat better reach, propagating over MMS instead of Bluetooth. Mabir listens for incoming MMS or SMS messages sent to the victim's phone, sending a copy of itself in an MMS response. Mabir overcame Cabir's geographic limitations (i.e., Bluetooth's short range), but still depended on social engineering and explicit user acceptance for activation.\nIn early 2005, Commwarrior (the predecessor of seven variants) improved on these techniques by searching both for nearby Bluetooth devices and sending itself via MMS to phone numbers in the victim's local address book. Commwarrior also sends randomly named files to avoid immediate user recognition and tries to covers its tracks afterwards. As a result, even though it still required user acceptance to install, Commwarrior was far more successful in propagating. More importantly, it caused financial damage by racking up MMS transmission fees. One operator reported that malware was responsible for 5% of its MMS traffic.\nA pair of Pocket PC malware programs emerged around the same time as Cabir. Duts is a small, innocuous virus that runs on an ARM-based WinCE PDA. The user must invoke Duts and accept a threatening prompt (\"Dear user, am I allowed to spread?\") before the virus can attempt to append itself to all .EXE files in the current directory. Brador is an ARM-based WinCE trojan that copies itself to the Pocket PC's Startup folder, emails the victim's IP address to the author, then listens for incoming remote control commands. However, neither proof-of-concept propagated itself to other mobiles, nor were they installed without active user participation. Mobile virus writers quickly returned their attentions to the OS with the biggest market share: Symbian.\nThis is now\nAccording to F-Secure's Runald, approximately 98% of mobile malware programs identified to date are designed to run on Symbian. \"Series 60 second edition is the primary target,\" Runald said. \"The third edition pretty much kills off malware because of code signing.\"\nCode signing makes it possible for software publishers to digitally sign their work, using credentials issued by a formal certification program like Symbian Signed, Microsoft's Mobile2Market, or RIM's Controlled APIs for BlackBerry. Mobile operating systems have also been upgraded to incorporate access controls that can prevent OS file tampering and sensitive function invocation by unauthorized applications.\nCode signing is not a panacea, however. To prevent unsigned application installation, something still needs to check that signature. Often, this task still falls to end users, many of whom willingly accept unsigned software, downloaded from unfamiliar websites. As mobile trojans and worms grew beyond proof of concept, new malware stopped blatantly announcing itself as Cabir and Duts did. Instead, mobile malware has grown increasingly malicious and financially motivated:\n- Symbian Skulls is a major family of trojans with 31 variants. Skulls overwrites all of the device's applications with non-functional versions -- except for those required to communicate. Skulls propagates by installing new, improved versions of Cabir. Later variants added Flexispy -- a spyware program called \"phones\" that locks itself to resist removal and records voice calls and SMS text, relaying that private information to an Internet server.\n- Symbian Pbstealer is a trojan that builds upon Cabir's Bluetooth propagation mechanism. To trick users into installing it, Pbstealer poses as a shareware address book compaction utility. Instead, Pbstealer sends a copy of the victim's local address book to the first nearby Bluetooth device that it can find.\n- In February 2006, the first J2ME trojan emerged as Redbrowser, a Java applet that masqueraded as a shareware WAP browser that could retrieve Web pages for free. Instead, Redbrowser sent SMS messages to premium numbers in Russia at a cost of $5 apiece.\n- In December 2007, the Symbian Beselo worm started to spread itself via Bluetooth and MMS. Beselo is similar to Commwarrior, except that installation files are not identified by the usual .SIS extension. Instead, Beselo files are named with .MP3, .JPG, or .RM extensions, fooling users into opening these phony multimedia files, thereby installing Beselo.\n- In February 2008, a new WinCE InfoJack trojan appeared, packed inside legitimate application installer packages like Google Maps, posing as an optional add-on. InfoJack disables Windows Mobile's installation security so that other unsigned applications can be installed without warning. It then sends the victim's serial number, operating system, and other information to a website in China.\n- In March 2008, Symbian Series 60 second edition devices were targeted by MultipleDropper, a malicious program that arrives via Bluetooth or MMS, then installs Commwarrior, Beselo, and a new trojan, Kiazha. After sending an SMS to the malware's author, Kiazha attempts to extort $7 (RMB 50) as ransom, to be sent by the user through the Chinese IM network QQ.\nBack to the future\nThese examples demonstrate both roadblocks that have impeded mobile malware to date and several ingredients necessary for mobile malware to flourish in the future.\nSymbian in general, and the Symbian Series 60 second edition in particular, remain favorite targets because the target population is large and those older devices harbor exploitable vulnerabilities. Newer Symbian devices, including Series 60 third edition, cannot actually run many of these trojan and worm installers thanks to Symbian OS 9 Platform Security features like Capability Management and Data Caging.\nAs smartphones grow more sophisticated, however, they are likely to harbor new vulnerabilities that could be exploited by malware. Runald expects the iPhone to draw mobile malware because of its growing popularity and its relatively feature-rich operating system.\n\"Symbian was a mobile OS from the start,\" Runald explained. \"The iPhone runs a cut-down computer OS. As mobile manufacturers bring out more of these sophisticated devices, they may have vulnerabilities that would let malware be installed without requiring user interaction.\" The latter is an important distinction, since mobile malware has so far relied on social engineering and user installation.\nRunald also noted that there will be an element of prestige involved in hacking the iPhone. To illustrate, consider last summer's rush to \"jailbreak\" the iPhone -- that is, enabling third-party applications on otherwise operator-locked devices. While \"jailbreaking\" is NOT malware, unlocked devices will let users install shareware of unknown origin. This creates more opportunities (and thus a far more lucrative market) for malware writers. A similar \"jailbreak hack\" was recently developed for Symbian Series 60 third edition, which could open the door for a new generation of Symbian trojans.\nSymbian has also been a favored target because it is an open platform, with published APIs and readily available SDKs. Clearly, it is important for operating system vendors to harden these open platforms against attack -- and it should be noted that all major mobile OS vendors are moving in that direction. Experience shows, however, that new interfaces are not always fully debugged on first release. Runald believes that early SDK security holes could play a role in future mobile malware -- not just for Symbian but for Windows Mobile, iPhone and (eventually) Android.\nFinally, 3G, Wi-Fi, and mobile Web coverage are creating friendlier vectors for malware propagation. Bluetooth is inherently limited because worms need crowds to spread -- for example, the Cabir outbreak reported at a large athletic event in Helsinki in August 2005. Mobile messaging has wider reach, but per-message fees play a role in curbing massive outbreaks over MMS or SMS. On the other hand, Wi-Fi and 3G services can deliver near-continuous and \"unlimited\" high-speed Internet connectivity. Furthermore, handhelds like the iPhone with GUIs that encourage mobile Web surfing present more opportunities for Web-borne malware to be delivered as Java applets, and so on.\nThese factors, along with overall growth in smartphone business usage, suggest that mobile malware will eventually morph from background nuisance to noteworthy threat. When will that happen? Only time will tell. Is this your most pressing mobile threat today? No. But given the cost of malware cleanup and mobile workforce dependency on mobile devices, you may want to start thinking about how to protect yourself. In next month's tip, we take a look at past and present mobile malware defenses.\nAbout the author:\nLisa Phifer is vice president of Core Competence Inc., a consulting firm specializing in network security and management technology. Phifer has been involved in the design, implementation, and evaluation of data communications, internetworking, security, and network management products for nearly 20 years. She teaches about wireless LANs and virtual private networking at industry conferences and has written extensively about network infrastructure and security technologies for numerous publications. She is also a site expert to SearchMobileComputing.com and SearchNetworking.com.\nThis was first published in July 2008", "label": 1}
{"text": "Software Piracy, AKA copyright breach, is one of one or two prohibited actions that could be taken by the consumer of a selected programme. Just about all software programmes today carry an end user licensing deal, or EULA. On installing the software, the final user must accept the EULA, or click-through-license, before the software will install.\nThe EULA lays out conditions in which the software may and may not be used in accordance with copyright protections. Software robbery involves breaking the EULA agreement on one or two conditions. Some typical examples of software robbery are : Making fake copies for sale : While software robbery laws vary from country to country, this infringement isn’t legal in most states. Obscure exceptions might exist for atypical circumstances in certain nations ,eg alteration of a programme for advantage of the disabled, but generally, copying software for selling it’s the classic definition of software robbery. Making fake copies to give away : Though the U.\nS. recognizes “fair use” protection, which can permit protected work to be shared in a constrained demeanour as an acceptable breach, software robbery goes past “fair use.” A less interpretive opposite number to fair use is “fair dealing,” recognised by countries like Australia, New Zealand, Singapore, Canada and the Great Britain. These laws attempt to give protection to the rights of the consumer and the good of society, counterbalanced by the rights of the copyright holder. A protected work that’s shared with a neighbour might be considered fair use in some jurisdictions, but lines can be somewhat imprecise and sundry as to precisely where protections end and software robbery starts. Most commonly, anything that extends beyond private use is often banned by the EULA and can bring legal questions into play. Hard-disk loading : Another sort of software robbery is selling a PC system with illegal software already installed. Typically , the purchaser doesn’t receive manuals, license agreements, or maybe the CDs or diskettes containing the original programme. Net sharing : Software that’s neither freeware nor shareware can’t be legally distibuted on the web. But many software programmes are freely available over P2P ( P-2-P ) networks, through binary newsgroups or in chat-rooms. This kind of software robbery is called warez and has often been cracked to make it serviceable by anybody without suppressive copyright instruments in effect. Leasing software : While libraries and academic establishments can buy special licenses to hire some sorts of software, leasing software generally is illegal and a kind of software robbery. Unlimited customer access : Installing software on a server without a network license and allowing clients to access that software is considered software robbery.\nUsing private software for commerce purposes : Many applications are free for private use, but need a license for commercial use. Using shareware outside the test period without stumping up for it : According to most shareware EULAs, a user must either pay for shareware or de-install it after the test period to avoid software robbery.\nInterfering with the copyright of any software, including freeware : Even freeware might be the topic of software robbery, when the copyright is unlawfully modified or the programme is unlawfully altered then redistributed.\nThe redistributed product doesn’t need an original price ticket to qualify as bootleg software. Possibly, the most debatable sort of software robbery is related to what many individuals consider easy ‘personal use ‘ — buying an application, then installing it on more than one private machine.\nSome software licenses prohibit this, a limitation that many purchasers see as company greediness, particularly where ‘non-optional ‘ programs like operating systems are concerned. In several cases this has aligned otherwise law-abiding voters with hackers and crackers when they seek tactics round the categorical copyright security provisions that they see as unfairly constrictive. To avoid software robbery, read the contract of each program fastidiously. Public domain software is the sole sort of software that may be altered, modified, redistributed or used without limitations.", "label": 1}
{"text": "Code of Best Practices in Fair Use for OpenCourseWare\nBY A COMMITTEE OF PRACTITIONERS OF OPENCOURSEWARE IN THE UNITED STATES, INCLUDING:\nTerri Bays, formerly director of Notre Dame OpenCourseWare\nDaniel Carchidi, publication director, MIT OpenCourseWare\nSheree Carter-Galvan, associate general counsel, Office of General Counsel, Yale University\nPamela Chambers, attorney, Office of General Counsel, Yale University\nGarin Fons, open education specialist, University of Michigan Open.Michigan\nIra Gooding, project coordinator, Johns Hopkins Bloomberg School of Public Health OpenCourseWare\nJoseph Hardin, clinical assistant professor of information, School of Information, University of Michigan\nPieter Kleymeer, open education specialist, University of Michigan Open.Michigan\nRobbin Smith, OCW editor/curricular content specialist, Tufts OpenCourseWare\nLindsey Weeramuni, Intellectual Property Supervisor, MIT OpenCourseWare\nIN CONSULTATION WITH\nLila Bailey, counsel for ccLearn\nWHAT THIS IS\nThis document is a code of best practices (download as PDF here) designed to help those preparing OpenCourseWare (OCW) to interpret and apply fair use under United States copyright law. The OCW movement, which is part of the larger Open Educational Resources (OER) movement, was pioneered in 2002, when the Massachusetts Institute of Technology launched its OpenCourseWare initiative, making course materials available in digital form on a free and open basis to all. In 2005, MIT helped to organize with the support of the William and Flora Hewlett Foundation a group of not-for-profit organizations interested in following the OpenCourseWare model and standardizing the delivery of OCW material. This group of institutions, known as the OCW Consortium (OCWC), has grown into a concern of more than 200 universities worldwide promoting universal access to knowledge on a nonprofit basis. The mission of OCWC is “to advance formal and informal learning through the worldwide sharing and use of free, open, high-quality educational materials organized as courses.”\nProviders of OCW are an essential part of the larger Open Educational Resources (OER) movement, dedicated to providing high-quality digitized educational materials, tools, and implementation resources offered freely and openly for anyone with access to the Internet. (For more information, consult http://www.hewlett.org/oer.) This movement and the dissemination of OCW material often depend upon Creative Commons licenses (creativecommons.org) in order to make materials as widely available as possible to public- access users.\nOCW materials often, where possible, integrate third-party materials. Incorporating such material frequently presents significant challenges. Under certain circumstances, those producing OCW will be required to secure permission from copyright owners and “clear the rights” in order to proceed with the intended use. The process of securing permissions or licenses from copyright owners is rarely an easy, inexpensive, certain, or straightforward enterprise. Fortunately, there are instances under U.S. copyright law where rights clearance is not necessary. Fair use is one such instance. Fair use is the right to use copyrighted material without permission or payment under some circumstances—especially when the cultural or social benefits of the use are predominant. It is a general right that may apply even in situations where the law provides no specific authorization for the use in question. This is a guide to current best practices for the use of copyright material in OCW, drawing on the actual activities of educators and educational staff who prepare courses for distribution.\nWHAT THIS ISN’T\nThis code of best practices does not tell you the limits of the fair use rights of OCW makers. Instead, it describes how those rights apply in certain recurrent situations.\nIt is not a guide to using material pursuant to licensing agreements because such works are subject to contractual limitations that have been agreed to, so they can be used the way the owners say they can. Whether a specific license authorizes the use of material in an OCW setting (as distinct from a closed academic one) will thus depend on the terms of that agreement. Where a license does not explicitly authorize the inclusion of content in OCW, fair use may be an option. However, many licensing agreements place limits on fair use. A lively debate is under way among copyright academics about whether such terms are binding and enforceable, but court decisions to date give scant indication that the fair use principle will prevail. Notably, however, Creative Commons licenses make clear that when an OCW provider is relying on fair use, license conditions do not apply because the use is authorized by law. Thus, a Creative Commons license does not interfere with a user’s ability to rely on fair use.\nThis is also not a guide to material that is already free to use without considering copyright. For instance, all federal government works are in the public domain, as are many older works. For more information on such “free use,” consult the document “Yes, You Can!” (centerforsocialmedia.org/files/pdf/free_use.pdf and http://www.copyright.cornell.edu/resources/publicdomain.cfm).\nIt is not a guide that addresses directly the use of material that someone wants to license but cannot trace back to an owner—the so-called “orphan works” problem. However, fair use does apply to orphan works on the same terms as works with known copyright owners. Thus, in those situations the principles stated in this document will be relevant.\nFinally, this guide is legal information and not legal advice. Readers who want to know how its principles apply to their own circumstances, or how the law has evolved since this document was created, may wish to consult an attorney.\nHOW THIS DOCUMENT WAS CREATED\nThis code of best practices was drafted with input from representatives of seven OCW producers—Johns Hopkins School of Public Health, Massachusetts Institute of Technology, Notre Dame University, Tufts University, University of California at Berkeley, University of Michigan, and ccLearn, the education division of Creative Commons—as well as by representatives from Yale University. It was grounded in interviews with 23 OCW makers at 18 U.S. institutions.\nThe drafting process was initiated by Sheree Carter-Galvan at Yale University (associate general counsel) and led by Lindsey Weeramuni of MIT (intellectual property supervisor: MIT OpenCourseWare ) and coordinated by Profs. Peter Jaszi (Program on Information Justice and Intellectual Property, Washington College of Law, American University) and Patricia Aufderheide (Center for Social Media, School of Communication, American University). The code of best practices was reviewed by a committee of legal scholars and lawyers expert in copyright and fair use. (Consult end of document for complete list.)\nOCW AND THIRD-PARTY RIGHTS\nAs the OER movement has grown, the problem of using copyrighted material has proliferated. References to and especially quotations from others’ copyrighted materials inhere in most scholarly materials, including teaching materials. They occur throughout the curriculum, from the arts and humanities to the sciences, technology, engineering, and mathematics. In order to incorporate this material, OCW makers must decide whether to rely on a license (whether open or restricted) or to employ fair use if relevant licensing terms do not prevent it. If these options are not available, they may decide to replace, delete, or obscure the material.\nUntil now, it has been difficult for OCW makers and their institutions to be confident in employing fair use, because there is no direct legal precedent clarifying the applicability of fair use to the practice. This has resulted in expending time and resources licensing material that does not need to be licensed, or alternatively, in weakening the educational quality of OCW by the precautionary removal of third-party copyrighted material.\nThe idea of “openness” that animates the preparation of open courseware begins with a commitment to making educational materials available to the members of the public, not just to students formally enrolled in specific institutions. The Copyright Act is particularly solicitous of unlicensed educational uses in the classroom (as reflected in 17 U.S.C. Sec. 110), and there were even attempts (however inadequate) to update these provisions for distance education in the so-called TEACH Act of 2002. But where online educational activities like OCW are concerned, providers must look for support to the fair use doctrine—which singles out “teaching” as one example of the activities it exists to support.\nFair use is the right to use copyrighted material without permission or payment, when the benefit to society is larger than the damage to the copyright holder. It is an essential part of copyright policy in the United States, where the purpose of copyright is to promote the progress through the creation of culture—“science and the useful arts.” Given that goal, our law values all methods that help create culture, including those that enable people to make new culture by using existing culture in new ways. Among these, of course, educational activities figure prominently.\nFair use also is rooted in the First Amendment. As is true of the exercise of expressive freedom in other speech settings, taking advantage of fair use in education depends on the application of general principles to specific situations. “Bright line” tests and “rules of thumb” are not appropriate to fair use analysis, which requires case-by-case determinations made through reasoning about how and why a new use recontextualizes existing material. The Congress provided some general guidance in the four factor test in Sec 107 of the 1976 Copyright Act.1 Since then, two common questions have emerged from the case law as core guiding principles for fair use reasoning in situations like those most commonly presented by OCW, where material originally created with other goals in mind is being quoted in an educational setting:\n- Is the re-use “transformative”— that is, does it add value to and repurpose preexisting material for a new audience?\n- Is the amount of material taken appropriate to the re-use?\nMany OCW products that appropriately incorporate preexisting content are poised to fare well when these questions are applied to them. In addition, it is worth noting that even nontransformative uses can be fair—especially nonprofit educational ones that don’t cut into the earnings of copyright owners. In this context, it may be important (although not determinative) whether the source of the repurposed material can be ascertained and whether the material is being actively exploited by its owner. If the answer to either of these subsidiary questions is “no,” fair use is more likely to apply than otherwise.\nFair use is not platform specific. In other words, a fair educational use of preexisting material will remain so, if fair use values are maintained, when material that originally appeared online is downloaded for use in hard copy or on digital media.\nFair use sometimes is referred to as an “equitable rule of reason.” Since fair use was first recognized in 1841, courts have deferred to custom and practice within use communities where there was clear evidence of it. Various information industries (trade publishing and broadcasting, for example) have noted this fact and created their own internal “standards and practices” for fair use.\nLarge corporate copyright owners have denigrated fair use as part of their struggle against “piracy”—occurring just when the doctrine is enjoying the broadest judicial recognition since its inception. Ironically, some public interest copyright advocates also have inadvertently contributed to the undermining of confidence in fair use. As a consequence, many people who regularly need third-party material in their work are confused and anxious about their ability to rely on fair use and unnecessarily suspicious about its ultimate utility.\nIn response, creative communities have assembled to develop norms interpreting fair use. There is nothing new in this approach; for example, broadcast news producers, have long depended upon such interpretive documents as standards and practices guides for TV networks to support their ubiquitous employment of fair use. Recently, codes of best practices in fair use have been developed by documentary filmmakers, dance archivists, film scholars, and media literacy teachers. Such codes can have a dramatic effect, creating new opportunities for both creation and circulation of new content. For instance, after some 15 years of refusing to accept fair use claims for coverage, with the introduction of the Documentary Filmmakers’ Statement of Best Practices in Fair Use, all errors and omissions insurers now routinely accept documentary filmmakers’ fair use claims. Even more to the point, films are being made today, in reliance on fair use, which would have been literally impossible to produce five years ago.\nThe code set forth below was crafted with the goal of open education in mind and in recognition that the scope of fair use in the classroom or behind a university’s firewall is likely broader than it is when materials are placed on the publicly accessible Internet because the risks to the copyright owner’s interests differ. On the other hand, the code also reflects OCW providers’ strongly shared convictions that they serve a universe of users who would not otherwise have access to educational materials and that the limited and integrated uses they make of copyrighted content in preparing those materials are fundamentally and inherently transformative.\nCOMMON COPYRIGHT CONFUSIONS IN OCW\nOCW makers commonly confront copyright problems in their daily work. Interviews that were conducted in connection with creating this code reflect a high level of sophistication. At the same time, they also revealed some common misunderstandings:\nConfusion of copyright and trademark\n- Some OCW makers expressed concern about showing corporate brand names and symbols in OCW. The reality: In general, re-use of commercial identifiers is not regulated by copyright law. Instead, trademark law applies—and it teaches that educational uses of trademarks and trade names simply are not actionable where such uses do not mislead or confuse consumers about the source of a good or service, and do not constitute libel or product disparagement. So there is no need to “blur” out brand names in images or substitute generic designations (ibuprofen for Motrin) in text.\nOverly conservative analysis\n- OCW makers are often hesitant to include public domain works that have been digitized by others, for fear that the process may create new copyrights. The reality: The few judicial interpretations of U.S. copyright law that bear on the question of whether preparing such digitized versions (scans of pages in old manuscripts, for example) would be considered sufficiently “original” to merit protection indicate the contrary (as does as the preponderance of academic commentary). There is little indication anywhere in the world that simple scans would be protected under national laws (any more than would photocopies).\nOverstatement of copyright’s implications for the liability of OCW providers\n- Some OCW makers were concerned that they might be legally responsible for public-access uses made of materials they provide. The reality: OCW generally can be distributed safely despite such concerns about so-called “secondary liability.” United States law requires something more than providing copyrighted materials to another before declaring the activity to be unlawful. Cautious providers may wish to package OCW with an admonition that it is intended only for lawful, noncommercial educational uses. But they will not be legally responsible for public-access uses unless they encourage unlawful uses, have advance knowledge that materials will be misused, or receive a direct financial benefit from such misuse.\nUnderstatement of copyright’s reach\n- A few OCW makers evidently believed that they could safely substitute materials found on the Web for content that raised copyright issues. The reality: Much online material is copyright protected. Thus, for example, the presence of music snippets on Amazon.com indicates only that they have been made available for a specific use; they are no less (or more) subject to copyright protection than equivalent passages gleaned from commercial recordings in other formats.\nLack of awareness about the how the intensity of copyright protection varies\n- Many users believe that all copyrights are of equivalent strength and scope. The reality: So-called “fact-intensive” works (a category including tables and charts that display scientific or historical data, technical photographs, etc.) receive “thinner” protection than do “creative” ones (films, poetry, etc.). This disparity in treatment reflects the different levels of “original authorship” that various kinds of works reflect. One can often avoid “thin” copyrights altogether by extracting the unprotected factual information or making changes to the presentation format. In addition, this distinction significantly affects “fair use,” which applies even more broadly to works of the former group than to those of the latter. Thus, excerpts from fact-intensive works can be used fairly in a wider variety of contexts than more creative ones.\nMis-estimating the scope of fair use\n- A common misunderstanding is that fair use applies differently depending on whether text or music is involved, or whether the material is in analog or digital format. Another is that fair use applies automatically to all core nonprofit educational activities, but not to commercial ones. The reality: Fair use applies across the board to materials of different genres in different formats. Commercial uses can be fair ones, but (by the same token) not all educational uses will qualify. In each case, the user needs to analyze the proposed use according to the considerations outlined below.\nFAIR USE VALUES INTERNATIONALLY: “LIMITATIONS AND EXCEPTIONS”\nThe preference for educational uses in copyright policy is not a U.S. specialty by any means. In fact, fair use is part of an international family of “limitations and exceptions” on copyright provided under national laws, all of which make provision (though in somewhat different terms) for unlicensed educational uses. Almost all foreign copyright laws provide private use exceptions that benefit individual students, and many also include specific educational use exceptions that shelter providers of learning materials from liability. Thus, for example, Article 5(3) of the 2001 European Union Directive on “The harmonisation of certain aspects of copyright and related rights in the information society” specifically permits exceptions covering use for “the sole purpose of illustration for teaching or scientific research” and “quotations for purposes such as criticism or reviews,” so long as the extent of the use is appropriate to the purpose to be achieved and as long as the source, including the author’s name, is indicated, unless this proves impossible. In addition to specific educational and quotation exemptions, many countries have specific copyright exceptions for incidental use (topics addressed in the United States only through the general fair use doctrine).\nCopyrights are protected across national boundaries by international agreements. But OCW makers need to be concerned with the law of the country in which they produce their work, rather than that of the country where copyrighted material originates. In other words, U.S.-based makers can rely on fair use in considering how to employ material from a French work, even though France doesn’t recognize our fair use doctrine. This code is concerned with fair use in the United States, and international OCW makers should consult the limitations and exceptions that apply in other countries.\nUTILITY OF LABELING FAIRLY USED MATERIAL\nBefore considering when quotations from copyrighted works in OCW are fair, a word is in order about what such a determination might imply. Most obviously, of course, a U.S. provider of OCW would be free to use the material in question in the selected context. The drafters of this code believe, however, that a provider’s right to use others’ copyrighted content implies certain responsibilities, including duties to (1) attribute third-party material whenever reasoably possible and (2) use labeling conventions to notify public-access users when the OCW provider is relying on fair use. Such labeling would permit follow-on users to make informed judgments about what elements of an OCW offering they have a reasonable basis for reproducing or adapting. In the United States the fair use rationale for the initial use generally will apply to subsequent noncommercial educational uses of the material as well. Elsewhere, however, users will need to determine how the educational exemptions in their own national laws would apply.\nCode of Best Practices in Fair Use for OpenCourseWare\nThis section describes a number of common, recurrent situations in which OCW providers may be concerned about whether or not to incorporate preexisting content into learning materials. It reflects the shared views of OCW professionals about when and how fair use should apply to their activities.\nNote that certain uses may fall into more than one of the categories listed below. In each instance, it is assumed that, in fact, the content in question actually does enjoy copyright protection.\nIt also is assumed that the material in question was not obtained under a license that limits fair use, whether in specific terms or by way of language that restricts the licensee to specific kinds of uses recited in the licensing agreements. Unfortunately, such terms are relatively common in institutional subscriptions to data bases and other electronic information resources, and OCW makers should be aware of them.\nCOPYRIGHTED MATERIAL APPEARING INCIDENTALLY\nSITUATION: The copyrighted material is inextricably linked to or juxtaposed with content included in an OCW offering, or simply appears in the background. For instance, a professor may comment on social implications of celebrity fashion as portrayed in a music video which also includes other copyrighted content, or a classroom where a lecture is videoed may have copyrighted material on posters in the background.\nPRINCIPLE: In an environment where copyright extends to so many kinds of information, some incidental copying is unavoidable. Copyrighted material that is incorporated in this manner is being used for purposes very different from those intended by its creators. Where incidental use cannot be avoided with reasonable effort, or without detracting from the educational experience, it should be considered fair.\nLIMITATIONS: In considering incidental fair use in educational settings, the interests of private rights holders must be balanced against the needs of teachers and learners.\n- Video recordings of lectures for OCW should avoid focusing on extraneous copyrighted material whenever possible.\n- Reasonable consideration should be given to removing incidentally captured copyrighted material from OCW material where such avoidance or removal will not detract from the educational experience.\n- Reasonable measures also should be employed to minimize the amount or duration of incidental copying where it has not been eliminated; and where incidentally captured copyrighted material can be identified and attributed with reasonable effort, it should be so attributed.\nCRITIQUE AND ANALYSIS\nSITUATION: Copyrighted texts, images, or sounds are being scrutinized. These materials, in other words, are literally the subject of the course, rather than useful or incidental adjuncts to it or even examples or illustrations of the subject matter. The principle stated below applies to all kinds of courses in the humanities and sciences. Film studies, music literature, sociology and other courses that reference popular culture are particularly likely places for copyrighted material to be critiqued and analyzed.\nPRINCIPLE: The investigation of preexisting works of authorship is an essential part of education, freedom of inquiry, and freedom of expression. Thus, this is a core example of fair use. Whatever the original informative or entertainment purpose that underlay the creation of the copyrighted material, it is being repurposed here as an object of commentary or other related discourse. This use of preexisting information or entertainment materials is a classic mode of advancing learning in the conventional face-to-face classroom, and it should be equally available in any OCW.\nLIMITATIONS: Because the fair use status of third-party material used for critique, analysis, or both depends in part on the critical value added by the creator of the OCW materials, certain considerations should be borne in mind.\n- Although commentary can be negative or positive, and express or implied, the purposes for which the copyrighted material has been incorporated should be reasonably clear, and to the extent possible, the commentary should be integrated with the copyrighted material.\n- Wherever possible, incorporated material should be drawn from primary sources.\n- The extent of the use should be no more than is reasonably needed for the critical purpose.\n- Copyrighted material used pursuant to fair use should be attributed where reasonably possible.\nCOPYRIGHTED MATERIAL USED FOR ILLUSTRATION\nSITUATION: Third-party content serving to expand upon or reinforce a point that an instructor has made by other means. Examples include digital “slides” in an art history course, botanical drawings in a science lecture, excerpts from recordings in a course on folk music styles, short film clips shown in a film studies class to illustrate a point or argument, and photographs or drawings used to depict events and personalities in a history course.\nPRINCIPLE: Illustrative uses are essential for effectively portraying and explaining information to learners. Practices vary around the licensing of illustrative examples in learning materials (such as textbooks) created for sale. In nonprofit education settings, however, the instructor’s right to use relevant examples under fair use has never been successfully challenged in a court of law. The drafters of this code believe that OCW makers should enjoy the same use rights as other educators. This principle applies to any copyrighted material, from historical letters to YouTube videos.\nLIMITATIONS: Relevance is the key concept distinguishing fair uses from questionable ones in this category. OCW providers should look for the relationship between incorporated illustrative material and course objectives.\n- The incorporated material should clearly advance an instructor’s teaching goals.\n- Copyrighted material that serves primarily to add entertainment value to the course should be avoided, as should merely duplicative illustrations that do not add materially to students’ understanding.\n- The extent of the use should be no more than is reasonably needed for the illustrative purpose.\n- Where possible with reasonable effort, the source of the illustration should be attributed.\nCOPYRIGHTED MATERIAL USED FOR DEMONSTRATION OR EXPLANATION\nSITUATION: The copyrighted material does not simply reinforce, dramatize, decorate, or illustrate a point or argument, but actually furthers understanding by demonstrating or illustrating a process, procedure, or arrangement. Examples include the use of a chart that summarizes experimental or observational findings, an animation that demonstrates the operation of a machine or body part, and a passage of text that sums up a complex historical development or cultural phenomenon. In some cases, materials quoted in this use category are created specifically for educational purposes (graphics from textbooks, for example), and in others they are items created for other purposes and repurposed by the instructor.\nPRINCIPLE: Uses for demonstration and explanation can be fair when the instructor is not merely trying to save effort in constructing a lesson. The strongest argument for fair use arises when the copyrighted content was prepared by the copyright owner for purposes other than education and is not being actively licensed in the educational market.\nLIMITATIONS: In incorporating demonstrations and explanations from copyrighted sources, OCW providers must walk a line between allowing legitimate transformative use and avoiding unfair and exploitive use.\n- The demonstration or example should be integral to the lesson.\n- It should not be merely cumulative with other lesson materials serving the same function.\n- No ready substitute (including one that the instructor himself or herself could create with reasonable effort) should be available.\n- The extent of the use should be appropriate to the purpose.\n- Where reasonably possible, the source of the demonstrative or illustrative material should be fully attributed.\nASSIGNED AND SUPPLEMENTARY MATERIALS\nSITUATION: A course draws systematically upon copyrighted materials to help explain the concepts or lesson it imparts, or assigns such materials for independent review. A provider of OCW may wish to make available electronic versions of these materials (e.g., some segments of OCW users are located in areas without continuous Internet connectivity.)\nPRINCIPLE: Although fair use applies to some aspects of “e-reserves” and course management systems in conventional educational settings, these do not translate readily to the OCW context. As a general matter, it is preferable to provide links or citations to materials of this kind, rather than to include them (whether in their entirety or in substantial part).\nLIMITATIONS: Fair use should be employed cautiously where this category of uses is concerned. It will be particularly inappropriate when the material in question originally was prepared for educational or scholarly purposes, or is being actively licensed for use in educational settings. In such cases, it is difficult to conclude that OCW use is meaningfully transformative or socially beneficial.\n- Where the material in question is not routinely licensed or available for sale for the intended amount of use, it may be more reasonable to rely on fair use.\n- The same is true where the copyright ownership of the material cannot be ascertained by a reasonable effort employing the best search tools available.\n- In situations of this kind where fair use is relied upon, OCW providers should be prepared to remove the material in question or license it when and if the copyright owner comes forward.\n- Where reliance on fair use is crucial, providers should limit the amount of reading material made available in connection with OCW courses to only those passages that are most directly germane to a specific lesson.\n- Attribution of the material should be provided.\nThis document will be used by OCW makers in the United States to achieve the highest goals of their educational mission. It will also be useful to makers outside the United States, who may be able to match up their own country’s educational exemptions with the standards described here. Again, this document is not intended to set outer limits for fair use in OCW, nor is it intended to be a comprehensive blueprint for every OCW project. The categories identified are simply those that surfaced most commonly in our interviews, and other practices of OCW creators also may qualify—now or in the future. Finally, OER creators can usefully extrapolate from this beyond the confines of OpenCourseWare.\n1 § 107. Limitations on exclusive rights: Fair use\n- the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;\n- the nature of the copyrighted work;\n- the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and\n- the effect of the use upon the potential market for or value of the copyrighted work.\n- Weeramuni is the intellectual property supervisor of MIT OpenCourseWare, a free and open publication of MIT course materials that reflects almost all the undergraduate and graduate subjects taught at MIT, all available with no registration required (http://ocw.mit.edu/). Weeramuni developed the IP strategy for MIT OpenCourseWare and oversees its implementation in the ongoing publication. She also consults with members of the OpenCourseWare Consortium, a worldwide collaboration of more than 200 higher education institutions and associated organizations creating open educational content using a shared model.\n- Jaszi is one of the founders of the WCL’s Program on Information Justice and Intellectual Property (PIJIP), which promotes social justice in law governing information dissemination and intellectual property through research, scholarship, public events, advocacy, and provision of legal and consulting services. Jaszi initiated the best practices in fair use model, developed since 2004 in conjunction with the Center for Social Media.\n- Aufderheide founded and directs the center, which showcases and analyzes media for social justice, civil society, and democracy, and the public environment that nurtures them. The best practices in fair use project, led by Aufderheide with Jaszi and PIJIP, has resulted in several other codes of best practices in fair use, which have changed norms of practice for creative and user communities.\nNotwithstanding the provisions of sections 106 and 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include —\nThe fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors.\nLindsey Weeramuni, intellectual property supervisor, MIT OpenCourseWare\nPeter Jaszi, professor, Washington College of Law, American University\nPatricia Aufderheide, professor and director, Center for Social Media, School of Communication, American University\nLEGAL ADVISORY BOARD\n(Institutional affiliations for identification only)\nJamie Bischoff, Ballard Spahr Andrews and Ingersoll, LL.P., Philadelphia, Pennsylvania\nMichael W. Carroll, American University, Washington College of Law, Washington, D.C.\nGeorgia K. Harper, Scholarly Communications Advisor, University of Texas at Austin Libraries, Austin, Texas\nMichael J. Madison, University of Pittsburgh School of Law, Pittsburgh, Pennsylvania\nJennifer M. Urban, Boalt Hall School of Law, University of California–Berkeley, Berkeley, California\nThis code is licensed using a Creative Commons Attribution 3.0 Unported license. Please attribute to Code of Best Practices for Fair Use in OpenCourseWare 2009 by A Committee of Practitioners of OpenCourseWare in the United States.\nCode of Best Practices in Fair Use for OpenCourseWare by A Committee of Practitioners of OpenCourseWare in the U.S. is licensed under a Creative Commons Attribution 3.0 Unported License.\nBased on a work at Centerforsocialmedia.org/ocw.\nPermissions beyond the scope of this license may be available at Centerforsocialmedia.org/ocw", "label": 1}
{"text": "Group Uses Cold Air to Hack Security Software\nA group led by a Princeton University computer security researcher has developed a simple method to steal encrypted information stored on computer hard disks.\nThe technique, which could undermine security software protecting critical data on computers, is as easy as chilling a computer memory chip with a blast of frigid air from a can of dust remover.\nEncryption software is widely used by companies and government agencies, notably in portable computers that are especially susceptible to theft.\nThe development, which was described on the group’s Web site Thursday, could also have implications for the protection of encrypted personal data from prosecutors.\nThe move, which cannot be carried out remotely, exploits a little-known vulnerability of the dynamic random access, or DRAM, chip. Those chips temporarily hold data, including the keys to modern data-scrambling algorithms. When the computer’s electrical power is shut off, the data, including the keys, is supposed to disappear.\nIn a technical paper that was published Thursday on the Web site of Princeton’s Center for Information Technology Policy, the group demonstrated that standard memory chips actually retain their data for seconds or even minutes after power is cut off.\nWhen the chips were chilled using an inexpensive can of air, the data was frozen in place, permitting the researchers to easily read the keys — long strings of ones and zeros — out of the chip’s memory.\n“Cool the chips in liquid nitrogen (-196 °C) and they hold their state for hours at least, without any power,” Edward W. Felten, a Princeton computer scientist, wrote in a Web posting. “Just put the chips back into a machine and you can read out their contents.”\nThe researchers used special pattern-recognition software of their own to identify security keys among the millions or even billions of pieces of data on the memory chip.\n“We think this is pretty serious to the extent people are relying on file protection,” Mr. Felten said.\nThe team, which included five graduate students led by Mr. Felten and three independent technical experts, said they did not know if such an attack capability would compromise government computer information because details of how classified computer data is protected are not publicly available.\nOfficials at the Department of Homeland Security, which paid for a portion of the research, did not return repeated calls for comment.\nThe researchers also said they had not explored disk encryption protection systems as now built into some commercial disk drives.\nBut they said they had proved that so-called Trusted Computing hardware, an industry standard approach that has been heralded as significantly increasing the security of modern personal computers, does not appear to stop the potential attacks.\nA number of computer security experts said the research results were an indication that assertions of robust computer security should be regarded with caution.\n“This is just another example of how things aren’t quite what they seem when people tell you things are secure,” said Peter Neumann, a security researcher at SRI International in Menlo Park, Calif.\nThe Princeton researchers wrote that they were able to compromise encrypted information stored using special utilities in the Windows, Macintosh and Linux operating systems.\nApple has had a FileVault disk encryption feature as an option in its OS X operating system since 2003. Microsoft added file encryption last year with BitLocker features in its Windows Vista operating system. The programs both use the federal government’s certified Advanced Encryption System algorithm to scramble data as it is read from and written to a computer hard disk. But both programs leave the keys in computer memory in an unencrypted form.\n“The software world tends not to think about these issues,” said Matt Blaze, an associate professor of computer and information science at the University of Pennsylvania. “We tend to make assumptions about the hardware. When we find out that those assumptions are wrong, we’re in trouble.”\nBoth of the software publishers said they ship their operating systems with the file encryption turned off. It is then up to the customer to turn on the feature.\nExecutives of Microsoft said BitLocker has a range of protection options that they referred to as “good, better and best.”\nAustin Wilson, director of Windows product management security at Microsoft, said the company recommended that BitLocker be used in some cases with additional hardware security. That might include either a special U.S.B. hardware key, or a secure identification card that generates an additional key string.\nThe Princeton researchers acknowledged that in these advanced modes, BitLocker encrypted data could not be accessed using the vulnerability they discovered.\nAn Apple spokeswoman said that the security of the FileVault system could also be enhanced by using a secure card to add to the strength of the key.\nThe researchers said they began exploring the utilities for vulnerabilities last fall after seeing a reference to the persistence of data in memory in a technical paper written by computer scientists at Stanford in 2005.\nThe Princeton group included Seth D. Schoen of the Electronic Frontier Foundation, William Paul of Wind River Systems and Jacob Appelbaum, an independent computer security researcher.\nThe issue of protecting information with disk encryption technology became prominent recently in a criminal case involving a Canadian citizen who late in 2006 was stopped by United States customs agents who said they had found child pornography on his computer.\nWhen the agents tried to examine the machine later, they discovered that the data was protected by encryption. The suspect has refused to divulge his password. A federal agent testified in court that the only way to determine the password otherwise would be with a password guessing program, which could take years.\nA federal magistrate ruled recently that forcing the suspect to disclose the password would be unconstitutional.", "label": 1}
{"text": "Are Pa55.W0rd5 Dead?\nHow long and complex should a password be? At what point does it become effectively uncrackable?\nTime out: Look at that opening paragraph. It's 87 characters long, but it could be your password to your Microsoft Windows system. Yes, even with the spaces in it. Technically, this has become known as a \"passphrase.\"\nRobert Hensing, a member of Microsoft's Security Incident Response Team, has written in his blog ( http://blogs.msdn.com/robert_hensing/archive/2004/07/28/199610.aspx ) that you shouldn't use passwords any more for Windows systems; you should use passphrases.\nThe blog entry has generated a lot of interest on security lists. Many agree with Hensing, and there's a lot I like about the idea. The discussions also raised my awareness that there are cracking tools for Windows passwords which do things you might not believe possible.\nThat first paragraph might not make a good passphrase because it's not very memorable. But let's say you're a Deadhead: \"It's just a box of rain, I don't know who put it there\" is very strong and it's pretty easy to remember. It also has upper- and lowercase letters, punctuation, and 58 characters. The downside relative to a more conventional password is that it has upper- and lower-case letters, punctuation, and 58 characters. It takes a while to type, and you're more likely to make mistakes.\nAs Hensing points out, Windows has supported passphrases of up to 127 characters since Windows 2000. But boilerplate password advice from people like me has always focused on bizarre words that we kid ourselves are easy to remember, like \"Ih8m0d3rnART!\" (\"I hate modern art\"). Take a phrase you can remember and distort it into a password. Hensing asks, why not just use the phrase?\nIn fact, the \"Ih8m0d3rnART!\" example is instructive in another way. It looks long and complex and is relatively impervious to certain types of attacks, but it's only 13 characters long, and is therefore vulnerable to a weakness in Windows 2000 password hash methodology. I'll get into it more in a future column, but if you have local-administrator access to the system, it's possible to reverse-engineer Windows passwords up to a particular length. As I understand it, this problem has been eliminated in Windows 2003 domains, but it remains in Windows 2000 for reasons of backward compatibility with third-party programs.\nHensing also notes that a large number of malware programs carry embedded dictionaries of common passwords to try on systems they attack. Many have hundreds of passwords, most of them real sucker material like \"password\" and \"asdf.\" But over time, these dictionaries should get better, and brute-force cracking programs will be able to try more possibilities.\nAlso, not everything is as security-conscious as Windows (yes, my tongue is in my cheek). For example, Barnes and Noble's password policies ( www.barnesandnoble.com/help/password ) require you to have a 6- to 12-character password composed of \"letters, numbers, or Shift/numeric characters only; spaces cannot be used.\" But the message is getting around; I just set my Amazon.com password to a 129-character passphrase with punctuation and mixed cases.\nWhether long and effective passphrases would be more acceptable to users is a matter for research. But if longer, more complex passwords are better, surely passphrases are better than passwords, right? I saw two basic arguments against this in the discussions below Hensing's blog and another on the Full-Disclosure list ( http://seclists.org/lists/fulldisclosure/2004/Oct/0578.html ).\nThe first counterargument says that if brute-force password crackers work by trying combinations of characters, a passphrase cracker would work by trying combinations of words. I have a hard time believing this would be a practical way of cracking, especially if you consider the possibilities for mixed case and punctuation.\nThe second argument is related to the first but raises the issue of \"entropy,\" which refers to the randomness of the bits in the password. I don't fully follow this argument (especially the incoherent ramble I just linked to). I'm more persuaded by Hensing's position that the greatly increased length of a good passphrase trumps any weaknesses in the randomness of its bits.\nI'm on board with this, and I've already begun to move my own passwords over to passphrases, but it's going to be a tough sell to nonprofessionals. Will the only people willing to use passphrases be the ones who were willing to use complex passwords?\nLarry Seltzer, a frequent contributor to PC Magazine, writes the Security Watch newsletter for pcmag.com.\nblog comments powered by Disqus", "label": 1}
{"text": "On October 2nd NIST announced\nthat they picked the Keccak\nalgorithm as the winner of the SHA-3 competition. Thus, the cryptographic hash function is prepared for future use in a wide range of applications. Keccak was created by Guido Bertoni, Joan Daemen, and Gilles Van Assche of STMicroelectronics and Michaël Peeters of NXP Semiconductors.\nA cryptographic hash function\nis an algorithm that takes a message (usually a string of text or a binary file) and calculates a fixed size digest, which is usually represented as a hexadecimal string. Hash functions are designed in a way that the same input will generate the same output, but starting with just the output, it is not possible to calculate the input other than doing a brute force check which involves trying all possible inputs until you come up with a suitable candidate. Any hash function that violates this property, i.e. it is possible to come up with the input belonging to the hash faster than with a brute force attack is considered broken by cryptographic researchers. There are also other desired properties which are explained in the linked Wikipedia article.\nHash functions are commonly used for password verification, file identification, and integrity verification. Without going too much into technical details, suffice it to say that the security properties of hash functions are a major building block of certificate based security infrastructure and digital signatures verifying the authenticity of digital documents.\nFrom time to time advances in cryptographic research lead to previous hash functions being broken. A famous example of a broken hash function would be MD5, which is still widely used for less critical applications. In general, use of known broken hash functions should be avoided when more secure alternatives are available.\nIn the last decade some critical advances in cryptographic research raised fears that soon the currently employed SHA-2 family of hash functions would be broken. In order to come up with a new cryptographic hash function as an alternative, the NIST started a competition back in 2007. The winning algorithm of the competition would be designated as a new hash primitive to be standardized for widespread use.\nThe competition initially had 64 entries, 51 of which made it to the first round (meaning they fulfilled the basic application guidelines by NIST) and 14 algorithms made it to the second round (the rest either got broken or had other design flaws). Of these, 5 finalists were selected based on a number of criteria. Finally, Keccak was selected as the winner.\nIt should be noted that the other entrants did not show clear disadvantages compared to the winner, but exhibited some theoretical similarities with previous hash functions while Keccak employed quite a few novel design elements. The rationale behind this is that in the event of SHA-2 being broken, it should be unlikely that the same approach would break SHA-3 as well.\n“Keccak has the added advantage of not being vulnerable in the same ways SHA-2 might be,” says NIST computer security expert Tim Polk. “An attack that could work on SHA-2 most likely would not work on Keccak because the two algorithms are designed so differently.”\nSecurity researcher Bruce Schneier applauds\nthe selection in his blog. Schneier also participated in the competition with the Skein algorithm\nhe developed with a team of experienced cryptographers and made it to the final round. Last week he explained that even if the competition ended without a winner, the world would not be in danger, as there currently is no need for a new hash function. The currently standardized SHA-2 family is considered secure.\nNIST continues to suggest using SHA-2 as it is considered secure at the time of writing. However, the availability of SHA-3 gives implementers an additional choice and serves as insurance in the event of SHA-2 being broken. The underlying algorithm of SHA-3 should lend itself to be easy to implement in embedded systems, which might be another advantage.\n© 2009 - 2013 Bright Side Of News*, All rights reserved.", "label": 1}
{"text": "An EU agency is asking for new ways to calculate botnet threats because it believes estimates of botnet sizes are generally exaggerated because of a lack of reliable data and because the larger estimates will bring more financial support for security measures.\nSize doesn't mean everything\nwhen trying to determine how dangerous a botnet is, and new metrics are needed\nto provide more accurate estimates, according to a European security agency.\nSecurity researchers often\nestimate the size and scope of a botnet to describe the army of zombie machines\nready to launch malicious attacks at the will of their masters. However, these\nfigures are inaccurate because there is a lot of incentive to exaggerate,\naccording to a research report released March 9 by the\nENISA (European Network and Information Security Agency)\nThe study examined the\nreliability of botnet size estimates and noted that some of the best-known\nbotnets were estimated to have several million compromised machines. Most\ncommonly reported estimates for Conficker ranged from 7 million to 9 million,\nover 13 million for Mariposa, and 30 million in Bredolab, the report said.\n\"As big numbers imply big\nthreats, therefore high attention, there is a significant incentive for\noverestimation,\" the report said.\nENISA conducted two parallel\nstudies to collectively evaluate the botnet threat and to assess the\neffectiveness of existing countermeasures. The studies were published at a\nsecurity conference in Cologne, Germany. The report's main findings were\ndistilled into a Question-and-Answer format to address the \"10 Tough Questions\"\nGiles Hogben, the report's\neditor, said the number\nof infected machines\ninside a botnet is usually extrapolated from samples\ncollected, but there is often no explanation of the steps taken to reach a\ngiven estimate of botnet sizes. Methodologies that count IP addresses with\ninfected traffic are not an accurate representation, Hogben said in his report.\nIn the analysis of the Torpig botnet by University of California, Santa Barbara,\nresearchers found 1.2 million hosts based on unique IP addresses, compared with\nthe much smaller 180,000, based on unique bot identifiers.\nThe report also said the\nchances of receiving financial support strongly correlated with the level of\nthreat implied by the large size of the botnet. As a result, organizations have\nan incentive to publicize the inflated number, Hogben said.\nEven small botnets can cause\nsevere damage, if the malware was sophisticated enough, Hogben said in the\nEstimates of the total\nannual global economic loss as a result of malicious botnet activities exceed\n$10 billion, the report found.\n\"A shift in the\nmotivation for the creation of malicious software has led to a financially oriented\nunderground economy of criminals acting in cyber-space,\" the report said.\nThe ENISA report points out\nthat relying too much on botnet size may lead to organizations misallocating\nsecurity resources, by investing in defenses they don't need or by not\ninvesting in technologies they do need.\nThe other half of the report\nfocused on recommendations on tactics that can be used to mitigate the botnet\nthreat. They included financial incentives for Internet service providers for\ndetection efforts, and to support customers with their malware defenses.\nAnother recommendation in the report suggested a \"Good Samaritan Law\" to\nencourage individuals to take actions against botnets. However, the law would\nhave to be written in a way to discourage cyber-vigilantism, the report said.", "label": 1}
{"text": "February 20, 2012\nSTART researchers fight cybercrime with old school criminology\nCriminologists, psychologists and computer security experts collaborate to improve the security of computer systems\nBY SAMANTHA GOLDMAN\nAs the world’s dependency on the Internet grows, so too does the collection of cybersecurity threats our nation faces—but a landmark study conducted by researchers from the National Consortium for the Study of Terrorism and Responses to Terrorism (START) and the University of Maryland aims to develop strategies to reduce and prevent cyberattacks.\nThe project, “Protecting the Bazaar: The Ecology of Cybersecurity in Weakly Fortified Networks,” marks the first active collaboration between computer security experts and social and behavioral scientists on the study of cybercrime.\nUnder the direction of principal investigator David Maimon, START researcher and assistant professor of criminology and criminal justice, the team will evaluate criminological theories within cyberspace using survey data and experimental design, in addition to detailed network and target computer data.\n“Essentially, we are testing how real world crime prevention strategies can be implemented in the context of cyberspace,” Maimon said. “For instance, we know that increasing the effort or risk of criminal behavior reduces the probability that a motivated offender will act – it’s like putting a lock on a door. Similarly, reducing the anticipated reward from a criminal act also decreases the likelihood that a motivated offender will act. But we want to know whether these real-world strategies can be used online to reduce and prevent attacks against our systems and network users.\nThe project, which builds on a series of earlier studies conducted by Maimon and senior researcher Michel Cukier, will also examine the characteristics of user-victims, offender-hackers and the bazaar computing environment—a weakly fortified system where a wide variety of users engage in a range of activities with minimal security in largely unregulated settings. Information on hackers and attacks will be collected using a large set of target computers called “honeypots” built for the sole purpose of being attacked.\n“By identifying specific system configurations that deter computer hackers from malicious activities, as well as particular behaviors that cyber-attack victims exhibit, we believe that we can increase the security of computer systems,” Cukier said.\nWith support from Maryland’s Office of Information Technology (OIT), the team will conduct its research within the context of the university’s bazaar computing system, which includes more than 130,000 IP addresses and 45,000 computers.\nThe project’s ecological approach fills a critical gap in cybersecurity research, Maimon explained. Although cyberattacks have been occurring for more than a decade, prior studies have ignored the human element of the hacker as it relates to the attacks themselves.", "label": 1}
{"text": "An Internet-attached server that acts as a decoy, luring in potential hackers in order to study their activities and monitor how they are able to break into a system. Honeypots are designed to mimic systems that an intruder would like to break into but limit the intruder from having access to an entire network. If a honeypot is successful, the intruder will have no idea that s/he is being tricked and monitored. Most honeypots are installed inside firewalls so that they can better be controlled, though it is possible to install them outside of firewalls. A firewall in a honeypot works in the opposite way that a normal firewall works: instead of restricting what comes into a system from the Internet, the honeypot firewall allows all traffic to come in from the Internet and restricts what the system sends back out.\nBy luring a hacker into a system, a honeypot serves several purposes:\n- The administrator can watch the hacker exploit the vulnerabilities of the system, thereby learning where the system has weaknesses that need to be redesigned.\n- The hacker can be caught and stopped while trying to obtain root access to the system.\n- By studying the activities of hackers, designers can better create more secure systems that are potentially invulnerable to future hackers.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "Identity theft, while not as common as generally perceived, is still a serious matter that deserves your attention. Learn to spot the signs, and if you suspect you’ve been victimized, you’ll be prepared to take immediate action.\nOn this page\nWhat is identity theft?\nUsing everyday items such as your driver’s license or Social Security number, a thief can assume your identity to open new bank accounts, establish new credit card accounts, write bad checks, obtain personal or car loans, or get cash advances – all in your name. They may even set up cell phone or utility services and run up bills, in addition to making charges on your existing account, obtaining employment or renting an apartment using your identity. Just one instance of identity theft can negatively impact your credit score and may create problems if you need to obtain credit in the future.\nHow does identity theft work?\nThieves use a variety of tactics to access your personal information. They may pose as someone with a legitimate need to gain access to financial data. Or the criminal could be a roommate, a worker in your home, or a friend who can easily get his or her hands on your documents. Identity thieves may even resort to rummaging through trash for pieces of non-shredded personal information, a tactic known as “Dumpster diving.” Data breaches are another way your information may become exposed.\nHow can Visa help?\nProtecting your card information is our top priority. If you are a victim of identity theft, you can get help through Visa’s partnership with the consumer network Call For Action by calling (866) ID-HOTLINE or by visiting the Call For Action website to learn more. Read here about more ways to Get Help Now from Visa.\nHow can I reduce my risk of identity theft?\nThere are a few basic practices you should follow to increase your card safety.\n- Monitor your credit card and account statements online on a weekly basis.\n- Report lost or stolen cards immediately and cancel all inactive accounts. When using your card at checkout, do not volunteer any personal information.\n- If you’ve applied for a new card and don’t receive it in a timely manner, or if a replacement card is not received prior to your card’s expiration date, contact your financial institution immediately. Be sure to sign new cards upon receipt, too.\n- Shred sensitive documents before disposing of them, install anti-virus and anti-spyware software on all computers, and change your passwords regularly.\n- Get more tips on protecting your financial information here and from the Better Business Bureau.\nWhere can I learn more about Visa’s security measures?\nFind out more about Visa’s Zero Liability1 policy, check out our Identity Theft Assistance page for steps to take in the event of identity theft, or access our Tips for Protecting Yourself to learn how to stay safe when shopping online or at retail stores, at home or while traveling.", "label": 1}
{"text": "Computer Viruses Are Still A Big Threat [AUDIO]\nDespite years of security advancements, attacks over the Internet are still very common. In fact, recent reports show a sharp increase in viruses and other cyber attacks over the past few years. Close to 100 million strands of malware are ready to pounce on unprotected and unsuspecting users.\nNot only are the incidents increasing; their purpose has become more demonic. During the first wave of the world wide web, “trojans” and “worms” were mainly the work of high school kids or graduate students who were just looking for fun and fascinated by the ability to infiltrate another person’s system. Since then, keeping the malware genre alive, hackers and high-profile criminals have learned the cash value of cyber attacks.\n“This is big business now,” said David Loudon, Science and Technology Adviser for Townsquare Media.\nIn the most serious cases, hackers are after information from users that they would want to keep a secret – social security number, account usernames and passwords, and more.\n“Their objective is to be able to get into people’s bank accounts,” Loudon said of the most malicious attackers.\nMalware growth has also spiked because of the increased opportunities for attack. With the proliferation of mobile computing, many people now depend on transacting important business via smart phones, tablets and lap tops. If hackers can get into those devices, just like computers, they can siphon information to use to their own advantage.\nMobile devices are more difficult to access because of the uniqueness of each model, but malware is still a real threat, according to Loudon.\nEarlier this year, hundreds of thousands of infections were discovered on Apple computers, products known for their immunity to such attacks.\nA “malware of choice” recently has been drive-by attacks, in which hackers can taint specific web sites and infect any users that visit those sites. They have even been reported on major, legitimate sites, and on mobile devices.\nRansomware has also become a pressing threat. Attackers can take over a device remotely, and then demand payment from the victim.\n- FILE a web attack complaint\nLoudon said it’s better to have your device protected beforehand, rather than look for a solution after your information or machine has been hijacked.\n“You should have a good anti-malware program on your computer,” Loudon advised. There are several programs that work great at no cost, as well as low-cost programs that provide excellent protection.\nHe strongly suggests a hardware firewall as well, typically found in broadband routers.\nLoudon added, “Don’t open e-mails from people you don’t know. Make sure you’ve got your e-mail client set up so it doesn’t automatically download content until you’ve had a chance to open the message and see what it’s about.”\nWhen responding to web attacks, mobile devices have a slight edge. In most cases, a phone can be swiped clean of its data and booted to its original condition. For computers, unless done professionally and for a hefty price, removing some strands of malware can be near impossible.", "label": 1}
{"text": "To assist new Freedom of Information and Protection of Privacy Co-ordinators, we have compiled a basic web-based tool kit to help get you started. Freedom of Information refers to public access to records relating to activities of government, ranging from administrative and operations to legislation and policy. The underlying objective is open government. Protection of Privacy refers to the safeguarding of personal information held by government organizations, as well as the right of individuals to see their own personal information and have it corrected if necessary.\nWhile your work with the IPC will mostly involve responding to appeals and privacy complaints, we have also included reference to materials on the role of the Co-ordinator as well as on the request stage of the freedom of information process.\nRole of the Co-ordinator:\nThe Legislation and Interpretive Tools:\nProtection of Privacy:\nTHERE'S MORE…ONCE YOU'VE GOT YOUR FEET WET!\nYou may want to check out the rest of our site - it offers a wealth of resources for Co-ordinators - everything from news releases to publications, presentations and other resources; in particular, the How Things Work section of our site provides a lot more detail about appeals and privacy complaints. And don't forget the Ministry of Government Services (MGS) site at http://www.mgs.gov.on.ca/, which offers, among other things, a comprehensive freedom of information manual.", "label": 1}
{"text": "There are certainly benefits and advantages to being able to carry massive amounts of files and data in your pocket. However, the small size and gargantuan storage capacities also make portable media very easy to lose or misplace, and a prime target for criminals.\nWhether it is a USB thumb drive, an external hard drive, a smartphone, a tablet, or some other device, it is not uncommon for people to have 32GB, 64GB, or even a terabyte of data on them. The data could be a music library or albums of personal photos, or it could be an entire patient or student database–complete with Social Security numbers, driver’s license numbers, home addresses, and other valuable information.\nAccording to the Privacy Rights Clearinghouse, a non-profit organization dedicated to protecting consumer privacy and raising awareness of privacy concerns, there were 142 reported data breach incidents in 2010 involving portable storage devices. Those incidents led to the compromise or exposure of nearly 7 million records. That amounts to 7 million possible cases of identity theft or credit fraud, or 7 million violations of security and privacy mandates such as HIPAA or PCI DSS.\nIt is important that organizations limit the types of data that are allowed to be stored or transported on portable media, and that data that is stored on portable devices is properly protected so that–even if the device is lost or stolen–the data it contains will be safe.", "label": 1}
{"text": "A secretive group of independent, influential scientists who advise the United States government on science and technology recently released The $100 Genome: Implications for the DoD. Perhaps unsurprisingly, it pays little attention to the larger social and ethical questions raised by such technology.\nThe group, known as the Jasons, was asked to consider the impact of personal genomics over the next decade and to assess the opportunities and challenges of the field for the Department of Defense (DoD). The report concluded with the following recommendations:\n- Establish procedures for the collection and archiving from all military personnel DNA samples that are compatible with subsequent genotype determination.\n- Plan for the eventual collection of complete human genome sequence data from all military personnel.\n- Arrange for the secure, long-term storage of DNA sequence data.\n- Prepare for the collection of epigenome and microbiome data when appropriate.\n- Determine which phenotypes are of greatest relevance to the DoD.\n- Cooperate with health care professionals to collect and store these data.\n- Use bioinformatics tools to correlate genetic information with phenotypes to discover linkages between the two datasets that will ultimately allow genotype information to be used productively.\nSome critics have begun to raise important concerns about the recommendations. Secrecy News and The Huffington Post both ran articles (1,2,3) raising a number of concerns regarding privacy, exploitation, discrimination, and eugenics.\nSteven Aftergood of Secrecy News writes:\nWhat could possibly go wrong? Quite a few things, actually. Besides the risk of failing to maintain the privacy and security of genetic data, the data could be used in unethical ways or their significance could be misinterpreted. ... Acting on genotype information that is not convincingly linked to specific phenotypes could lead to erroneous and detrimental decision making.\nAftergood, quoted in The Huffington Post, also discussed privacy concerns and exploitation:\nQuestions about control and exploitation quickly become front and center … I think all of us should be concerned about the advancing state of genetic research and its susceptibility to improper or thoughtless use.\nIt lends itself to corporate control and for-profit exploitation of genetic data, which is the most intimately private information there could possibly be. Your genetic code is more private and more unique to you than anything else in the universe.\nUnfortunately, soldiers are particularly susceptible to harms relating to release of their DNA because they are excluded from the Genetic Information Nondiscrimination Act (GINA).\nWhile the report does acknowledge the need for “resolution of ethical and social issues that arise from these activities,” it fails to do much more beyond this in thinking about potential implications of gathering DNA from soldiers. A spokesperson from the Pentagon says that it is seeking input from others on the issue. But Ann Finkbeiner, author of a book on the Jasons, suggests that they are highly influential: “My feel for the track record is that they are taken very seriously … and I think a lot of their ideas sort of end up in programs.”\nPreviously on Biopolitical Times:\nPosted in Civil Society, DNA Forensics, Eugenics, Jillian Theil's Blog Posts, Personal genomics\nComments are now closed for this item.\nComment by ReGenesis Films, Mar 22nd, 2011 9:14am\nThe published, peer reviewed reports (in mainstream science and medical journals) of Dr. Gerald Pollack, Dr. Mae Wan Ho, Dr. Marcel Vogel, Dr. Glen Rein, Dr. Dan Nelson, and Dr. Jean Benveniste (and many more) repeatedly demonstrate the relationship between DNA and structured water (which has interfaced with certain light and sound frequencies). They have each concluded that the DNA each human is born with is not fixed and responds to biophotonic light (infra red) and sound (phonons) in repeated experiments performed over the past 20 years. These studies are freely available all over the Internet. Of particular interest to this article is the 2010 published work of Nobel Prize winner Luc Montagnier PhD (discovered HIV) \"DNA Waves and Water\" is very important to the analysis of other more efficacious options than Eugenics, regardless of the hyperboles used to rationalize it. I would highly recommend to readers Googling the published works of these scientists in the field of structured water and its effect on human DNA morphological changes.\nComment by Jillian, Jan 27th, 2011 10:49am\nWe would love to know what you mean by your comment. Could you please clarify?\nComment by jasmine singleton, Jan 24th, 2011 8:52am\nin my opinion this is just getting blown way out of proportion", "label": 1}
{"text": "Create secure passwords to keep your identity safe\nChoosing more secure passwords will help keep your identity safe on the internet. This article and the companion video will show you how to create secure, easy-to-remember passwords.\nTable of Contents\nStep 1: Choose a phrase\nYou can create a more secure password by starting with a simple phrase. For example, let's use a quote from Ogden Nash: \"Happiness is having a scratch for every itch.\"\nIf we use the first letter of each word, and substitute 4 for \"for\", we get:\nStep 2: Add special characters\nThis is a reasonably strong password but we can improve it a bit by adding some special characters:\nStep 3: Associate it with a website\nWe can use our new password on several different websites by adding a prefix or suffix with a mnemonic link to a particular site. Let's use the first letter and the next two consonants in the site name.\nJust to add a bit more randomness we'll alternate upper-case and lower case, and if the first character in the site name is a vowel we'll start with upper-case. To mix things up a bit more we'll use the same rule to decide whether to add the site mnemonic to the left side or the right side.\n#Hihas4ei:AmZ for Amazon\nfCb#Hihas4ei: for Facebook\n#Hihas4ei:YtB for YouTube\ndRm#Hihas4ei: for Drumbeat\nThis is just one possible rule for picking the prefix or suffix that you use to customize your password for each web site. Reversing the order of the letters in the suffix, using only vowels, only consonants, or adding some other characters that come to mind when you think about the web site are all possible approaches that will improve security.\nWhile this technique lets us reuse the phrase-generated part of the password on a number of different websites, it would still be a bad idea to use it on a site like a bank account which contains high-value information. Sites like that deserve their own password selection phrase.\nTry It Yourself!\nTake a moment to think of a phrase that's meaningful to you. Use that phrase to create a secure password that you can customize for each website you visit.\nFor more information on choosing secure passwords, check out the blog post on Shiny Pebbles.\nShare this article: http://mzl.la/O36XLr", "label": 1}
{"text": "By Shawn Lafferty and Tauseef Ghazi – A smart grid can help utilities conserve energy, reduce costs, increase reliability and transparency, and make processes more efficient. The increasing use of IT-based electric power systems, however, increases cyber security vulnerabilities, which increases cyber security’s importance. Utilities must consider smart grid security, including vulnerable areas, strategic issues, the layered security approach, data management and privacy concerns, and scenario planning and threat profiling.\nAdvanced metering infrastructure (AMI) and a meter data management system (MDMS) are basic smart grid components. AMI collects and transmits smart meter data between devices and MDMS facilitates data collection, storage and management. The smart grid system applies AMI sensing, measurement and control devices with two-way communications to the power grid’s production, transmission, distribution and consumption segments to enable real-time pricing, monitoring and conservation. These technologies communicate information about grid conditions to system users, operators and automated devices, making it possible to respond dynamically to grid condition changes. more> http://tinyurl.com/3f278tz", "label": 1}
{"text": "(ARA) – In today’s technically advanced world, radical groups and rogue states don’t just use guns and bombs to attack our country and allies; they use technology and information too. The need to defend against these cyber attacks has spurred an evolution in the field of Information Warfare – and generated exciting, meaningful career opportunities for a new generation of men and women who want to serve their country.\nFrom the Civil War period, when specially trained U.S. Naval personnel intercepted and deciphered enemy signals and employed cryptology to secure domestic and international communications, protecting our nation’s communication infrastructure has been a priority. Sailors and Marines assumed cryptologic duties as early as 1889, when the first radio transmission was sent from a U.S. Navy ship. During World War II, nearly 10,000 Naval cryptologic personnel worked worldwide to support every major campaign in the war.\nSince that time, cryptologists have played a direct role in every United States conflict and have evolved to meet the dynamic challenges of modern cyberwarfare. Today’s Information Warfare community consists of more than 11,000 members. Their efforts have played a critical role in missions ranging from the Osama bin Laden raid in Pakistan to the capture of the Maersk Alabama, a cargo ship held hostage by pirates off the coast of Somalia. As cyber security grows in importance to national security, the demand for people who can help keep our country protected has never been greater.\nIn an era of Information Warfare, enemy groups are able to plan their attacks more effectively. Therefore, people with the skills to protect our country’s communication and technological systems are critical to capitalize on vulnerabilities in our enemies’ information environments. The responsibility of the Information Warfare community involves attacking, defending and exploiting rival communications networks at sea, in the air or on land. The field of Information Warfare offers opportunities for those who excel at computing, foreign languages or other technical fields. The Navy can provide jobs and training opportunities for high school and college graduates as well as those with professional experience. Assignments place Sailors in a variety of locations, from aircraft carriers to amphibious command ships to Naval air stations, at home and abroad.\nHere are a few of the chief Information Warfare career opportunities that are most in demand now and will be in the future:\nAn array of cyber threats, vulnerabilities and the growing military dependence on cyberspace mean the military needs Cryptologic Linguists for every mission during peace and war. A Navy Cryptologic Technician Interpretive (CTI) is an expert who uses knowledge of a region’s language, culture, history and current political landscape to advise decision makers on real world situations. CTIs work daily with aural and written foreign language material. These professionals support security missions both domestically and internationally.\nThe United States depends on an information advantage to keep its people safe from harm. Navy Intelligence operatives filter and analyze raw data, turning it into knowledge that helps inform international policy and military strategy. The Intelligence community is one of the largest and most important networks in the world, supplying real-time information for every mission the Navy conducts. Tasks may include coding classified information, using state-of-the-art computer equipment aboard aircraft carriers or amphibious command ships. Specialty training is provided for all Intelligence candidates regardless of experience.\nMaintaining communication channels takes on a whole new level of importance when the security of a nation is at risk. Information Technology (IT) is a growing career field in both the civilian and military worlds. Experienced IT professionals, such as computer programmers, data analysts and technicians, help protect the Navy’s networks from threats. Navy IT Specialists are in charge of the needs of ships, aircraft and personnel. In this field, Sailors work with a variety of virtual channels and may operate mainframe computer systems that handle classified material, set up video surveillance to help U.S. forces keep watch and provide technical support to deployed units.\nCyber Warfare Engineering\nProtecting against electronic warfare is a never-ending task, since thieves are relentless in developing new ways to attack. Cyber Warfare Engineers develop computer network operations capabilities in order to protect our country from cyber threats, which could potentially destroy entire infrastructures, such as railroad systems, gas pipelines and even financial markets. The best and brightest Computer Scientists and Computer Engineers lead teams that protect against espionage, ensuring the United States never loses the information advantage. Because of their intelligence, leadership and specialized skills, Cyber Warfare Engineers are in high demand while in the Navy and also upon returning to civilian life.\nBecause of the way our world has had to evolve to protect our communications infrastructures from existing, developing and future threats, Information Warfare careers will continue to be in high demand in the years ahead. The specific responsibilities of America’s Navy are carried out by the hundreds of thousands of Sailors who work tirelessly to achieve the highest standards of excellence in hundreds of diverse career fields. Visit www.navy.com to learn more about the career opportunities and the background that is required to answer this call to serve.", "label": 1}
{"text": "Protect your identity\nTo avoid identity theft, be cautious about the identifying information you share -- and not just online. You also need to be careful about what you share over the telephone.\nTake precautions to deter identity theft, bank account fraud, credit card fraud and other criminal uses of your personal information.\nWhat is pretexting?\nYou may have heard about phishing scams -- emails and online messages that try to fool people into giving up their Social Security number, passwords and financial information -- but do you know about pretexting? Pretexting is when criminals aim to get your personal information over the phone using false pretenses.\nPretexters gather information and sell it to other individuals and criminal companies that may use it to steal your money, get credit in your name, sue you or otherwise use your identity. Those pretexters use a number of different tactics to try to secure your personal information -- the most common way is through a phone call. Usually the pretexter claims he's from a familiar company or a research firm. He asks your name, address, birth date and Social Security number. After obtaining the information, the pretexter can call your financial institution and use this information to gain access to your account, start applying for credit cards under your name or use your information in a variety of other fraudulent ways.\nYour Social Security number\nThe primary piece of information you should never share over the phone is your Social Security number. Armed with your Social Security number, a thief or dishonest person can use it to apply for credit or try to contact your financial institutions and gain access to your accounts. By giving out your Social Security number over the phone, you put yourself at risk for identity theft, as well as credit card and bank account fraud. Avoid losing money and your credit rating by never revealing your Social Security number over the phone.\nYour debit or credit card number\nWhen a sales person or other individual has initiated the phone call, you should never give out your debit or credit card number. It's a common scam for criminals to pretend to represent a legitimate company to gain access to your personal information. If you want to place an order or purchase something over the phone, you should be the one making the call. And be wary of the number you are calling as well. Don't call the phone number you received by email or one that was left on your voicemail. Instead, look up the customer service or sales department phone number on the company's official website.\nBe cautious when giving out your full name, birthdate and address over the phone too. Again, you should only do this when you are the one who initiated the call. You should never give out this information if you answer a call or dial back a number that was left by email or voicemail. The goal is to put the least amount of details out there that thieves can steal.\nYou may not find out that someone is using your credit or your identity until you begin to get collection calls or get turned down for credit. It's important to check your bank and credit card statements diligently every month, and also regularly check your credit rating or reports several times each year. Also, consider using an identity theft service offered by LifeLock that can help you protect your identity from identity thieves.\nAvoid oversharing on the phone, in person and online. You don't want strangers to know when you are going to be away from home or other details about your whereabouts. Revealing too much can put you at risk for identity theft and numerous other crimes.\nMore about money and identity theft", "label": 1}
{"text": "Flame, Stuxnet viruses show 'cooperation'\nMOSCOW, June 11 (UPI) -- Teams creating the Stuxnet and Flame viruses worked together and both programs may have been the work of the U.S. government, Russian security researchers say.\nExperts at Kaspersky Lab, a Russian company that first identified the Flame virus, said source code was shared between the teams making the malware attacks.\nBoth Flame, discovered last month, and Stuxnet, revealed in 2010, attacked targets in Iran.\n\"What we have found is very strong evidence that Stuxnet/Duqu and Flame cyber-weapons are connected,\" said Alexander Gostev, chief security expert at Kaspersky. \"The new findings that reveal how the teams shared source code of at least one module in the early stages of development prove that the groups co-operated at least once.\"\nAn investigation by The New York Times has pointed to the United States as being responsible for Stuxnet, developed in cooperation with Israel to cause disruption in Iranian nuclear facilities.\nNo definitive evidence has been presented that the United States was behind Flame, The Hill reported.\nNo country has as yet publicly taken responsibility for either malware attack.\nRecord-breaking solar flare described\nGREENBELT, Md., June 11 (UPI) -- A NASA space telescope detected the highest-energy light ever measured in an eruption on the sun during a powerful solar blast, the space agency has reported.\nThe powerful solar flare, observed March 7 by the Fermi Gamma-ray Space Telescope, produced such an outpouring of gamma rays -- a form of light with even greater energy than X-rays -- that the sun briefly became the brightest object in the gamma-ray sky, NASA said Monday.\n\"For most of Fermi's four years in orbit, its LAT saw the sun as a faint, steady gamma-ray source thanks to the impacts of high-speed particles called cosmic rays,\" Nicola Omodei, an astrophysicist at Stanford University, said. \"Now we're beginning to see what the sun itself can do.\"\nThe March flare produced high-energy gamma rays for about 20 hours, two and a half times longer than any event on record, researchers said.\nSolar eruptions are increasing as the sun moves toward the peak of its roughly 11-year-long activity cycle, expected in mid-2013, they said.\nLow-lactose calf genetically bred in China\nHOHHOT, China, June 11 (UPI) -- Chinese scientists say they've bred the world's first genetically-modified calf that will produce low-lactose milk when it matures in two years.\nNamed \"Lakes,\" the calf was born April 24 at Inner Mongolia Agricultural University, China's state-run Xinhua News Agency reported Monday.\nResearcher Zhang Li and a research team extracted fetal fibroblasts from a Holstein cow that was 45 days pregnant and genetically engineered the fetus by transplanting a lactose dissolution enzyme into the cell.\nThe engineered fetus was then transplanted into the womb of a cow in July 2011.\n\"The enzyme can dissolve lactose -- the main sugar found in dairy products -- into galactose or glucose to ease digestive disorders among the lactose-intolerant people,\" Zhang said.\nLakes should produce safer milk for such people, who account for nearly 60 percent of the Chinese population, researchers said.\nSymptoms of the lactose intolerance include rashes, diarrhea and digestive disorders.\n\"Lakes, the calf, is a blessing for these people,\" Zhang said. \"She will produce low-lactose milk after she is 25 months old and has delivered calves.\"\nApple shows new iOS 6 feature set\nSAN FRANCISCO, June 11 (UPI) -- Apple has announced the latest version of its iOS mobile operating system, with version 6 of the software having 200 new features for the iPhone and iPad.\nPersonalization options -- such as allowing users to turn on a do-not-disturb mode, respond to phone calls with a set message and set VIP status for individuals whose e-mails would come through as alerts -- were among the features revealed at Apple's Worldwide Developers Conference in San Francisco, CNET.com reported Monday.\nAlso included is an updated version of the Siri voice assistant program.\nIn the new operating system a user's Apple ID and phone number will be consolidated, allowing calls and messages to be accessed on either the iPhone or iPad, Apple said.\nAn app called Passbook will be able to store boarding passes, store gift cards and movie tickets, the company said.\nExpected to be available to consumers in the fall, iOS 6 will work with iPhones back to 3GS models and with second and third generation iPads.\n|Additional Technology Stories|\nSANFORD, Fla., May 24 (UPI) --Pictures and texts from Trayvon Martin's cellphone show a different side of the teenager a Florida man is accused of killing unprovoked, defense attorneys say.\nLOS ANGELES, May 24 (UPI) --Joe Francis says he is sorry he told The Hollywood Reporter the jury that convicted him of false imprisonment is retarded and should be euthanized.\nCOLOGNE, Germany, May 24 (UPI) --An auctioneer in Germany said he has set the starting bid for an Apple-1 computer at a stunning, but not record-setting, $116,000.", "label": 1}
{"text": "Next-gen UAVs grow in form and popularity\nFighter-jet sized drones require high degree of autonomy\n- By Henry Kenyon\n- Aug 22, 2011\nUnmanned aircraft have been used in combat for years, but they have either been large reconnaissance platforms or smaller surveillance/attack types. The next generation of robotic aircraft is taking shape and it consists of fighter-jet sized aircraft designed to operate in heavily contested airspace to attack high-value targets.\nAn update on the progress of two of the most mature of these programs was provided Aug. 16 by top aerospace industry officials at the Association of Unmanned Vehicle Systems International Conference in Washington D.C.\nDOD stuck in IT 'Stone Age,' top Pentagon official says\nThe two platforms are Boeing’s Phantom Ray and Northrop Grumman’s X-47B unmanned combat aerial system (UCAS). The Phantom Ray is a company-sponsored technology demonstrator, and the X-47B is part of a Navy program. Both aircraft made their initial flights this year.\nDeveloped with company funds, the Phantom Ray is a one-off UCAS platform built to demonstrate the firm’s expertise in the field and to showcase its rapid prototyping and development techniques, said Craig Brown, Boeing’s Phantom Ray program manager. An evolution of the platform originally created for the cancelled Defense Advanced Research Projects Agency’s Joint Unmanned Combat Aerial Systems (J-UCAS) program, the Phantom Ray went from concept to flying prototype in about three years. There are still very few fighter-sized unmanned aerial systems, he said.\nThe aircraft is designed for a variety of missions such as intelligence gathering, surveillance and reconnaissance, suppression of enemy air defenses, electronic attack, and hunter-killer missions. It is a stealthy flying-wing shaped aircraft that is 36-feet long and has a 50-foot wingspan capable of cruising at 614 miles per hour at an operational altitude of 40,000 feet. Key to its intended role, the Phantom Ray can carry up to 4,500 pounds of ordinance, extra fuel and/or sensors in its payload bays. The bays are large enough to accommodate two 2,000 pound Joint Direct Attack Munition satellite guided bombs.\nBesides being a stealthy attack demonstrator, the Phantom Ray is also designed to be autonomous. The aircraft’s pilot station consists of “a keyboard and a mouse,” Brown said. The aircraft is designed to manage most of its flight capabilities, such as takeoff, landing and course alterations while leaving human operators in the loop for important decisions such as deciding to attack a target.\nAnother offshoot from DARPA’s J-UCAS program, Northrop Grumman’s X-47B is undergoing evaluations as part of a Navy program to develop a carrier-based UCAS system. Like the Phantom Ray, the X-47B is highly autonomous, which is vital for its intended role taking off and landing on aircraft carriers. “An unmanned autonomous carrier capable aircraft is different from a manned [remotely piloted] vehicle,” said Carl Johnson, deputy program manager for Northrop Grumman’s Unmanned Combat Aerial System Demonstration program.\nIn development since 2000, the X-47B is designed to operate in a harsh naval environment. The aircraft is reinforced to withstand the shock of carrier landings, and its dimensions are suited to transiting cramped carrier hangar spaces and elevators. The aircraft also has a 2,400 mile range and a 4,500 pound payload capacity for strike operations.\nLike the Phantom Ray, the X-47B is designed to be highly autonomous. This is important in the crowded, moving environment of an aircraft carrier’s deck, where the aircraft must maneuver around and respond to human personnel—something that cannot be done remotely by a pilot, Johnson said.\nAutonomy also extends to operations in defended airspace, where the aircraft must be able to identify and maneuver around threats in real time. Human operators must remain in the loop, but the aircraft’s autonomy can be scaled to the operation. Because of these needs, the X-47B has a robust data processing capability. “You’re not accessing the computer on your desk [to control the aircraft], you’re accessing the server on the airplane,” he said.", "label": 1}
{"text": "How can I help protect my computer from viruses?\nThis information applies to Windows Internet Explorer 7 and Windows Internet Explorer 8.\nProtecting your computer from viruses and other threats isn't difficult, but you have to be diligent.\nInstall an antivirus program. Installing an antivirus program and keeping it up to date can help defend your computer against viruses. Antivirus programs scan for viruses trying to get into your e‑mail, operating system, or files. New viruses appear daily, so check the antivirus manufacturer's website frequently for updates. Most antivirus programs are sold with annual subscriptions, which can be renewed as needed. To find an antivirus scanner, visit the Windows Vista Security Software Providers\nDo not open e‑mail attachments. Many viruses are attached to e‑mail messages and will spread as soon as you open the e‑mail attachment. It's best not to open any attachment unless it is something you are expecting. Microsoft Outlook and Windows Mail help block potentially dangerous attachments.\nKeep Windows updated. Periodically, Microsoft releases special security updates that can help protect your computer. These updates can help prevent viruses and other computer attacks by closing possible security holes. Make sure that Windows receives these updates by turning on Windows automatic updating. To learn how, see Turn automatic updating on or off.\nUse a firewall. Windows Firewall or any other firewall can help alert you to suspicious activity if a virus or worm attempts to connect to your computer. It can also block viruses, worms, and hackers from attempting to download potentially harmful programs to your computer.", "label": 1}
{"text": "A spoofed email message is often the cornerstone of any well-executed phishing scam. From the earliest days of phishing, fraudulent email messages have been used to catch Internet users unawares. Phishing attacks picked up steam during the heyday of AOL. Instant messages and email messages were used to carry out those attacks. Although many things have changed, many others have remained the same. To this very day, major online entities like PayPal and eBay have to grapple with the problem of email phishing. Several online banks have been targeted as well. Learn more about how email phishing works, what it looks like and how avoid falling victim to it below.\nWhat is Email Phishing?\nEmail phishing refers to the act of creating and sending fraudulent or spoofed emails with the goal of obtaining sensitive financial and personal information. Under such schemes, emails are designed to look exactly like the ones that are sent by legitimate companies. Sophisticated phishing attacks use the email addresses of people who are registered to use certain services. When those people receive emails that are supposed to be from those companies, they are more likely to trust them. Spoofed emails often contain links that lead to spoofed websites, where various methods are used to request and collect a person’s financial and personal information. Forms are occasionally contained within the emails themselves too.\nWhy Email Phishing Works\nConsidering how long email phishing has been used, it may seem odd that it continues to work. It isn’t because people are foolish; it is because these emails are very well done. Phishers know precisely how to design spoofed emails to look like their legitimate counterparts. By throwing in some urgent language, phishers dramatically increase their odds of success. Busy people scan such emails, trust them and click on their links because they look almost exactly like the real thing. One wrong click can lead to a world of hurt.\nSigns of Email Phishing\nThere are many signs of a phishing email. The first thing that you should look at is the greeting. Does it use your actual name, or does it have a generic greeting? Look closely at the email’s header. What is the sender’s email address? These addresses are usually carefully designed to look authentic. By taking a very close look at them, though, you can usually see inconsistencies and things that don’t make sense. If possible, compare the sender’s email address to that of previous messages from the same company. If it’s a phishing email, you will notice things that don’t add up.\nExamples of Successful Email Phishing\nMany successful email phishing attacks have been carried out in the past, which is why they continue to be used to this day. Prominent examples include eBay phishing scams and PayPal phishing scams. Both companies were prime targets of email phishing campaigns in the past. eBay and PayPal users receive messages that look legitimate. The messages typically urge them to verify their account information or to update their credit card numbers. People often fall for these ruses because they are afraid of losing access to these important services. Both companies now offer extensive information on ways to avoid such phishing scams on their websites.\nThere is no simple way to completely avoid email phishing attacks. Sooner or later, someone is bound to send you a spoofed email. The easiest way to avoid these scams is by never clicking on links that are included in email messages. Make it a policy to always type in the URL of the site that you need to access manually. Upon arriving on the site, you will be able to confirm whether or not the message that you received was legitimate. If it’s a spoofed email, find out where to send it – most companies like to know about the scams that are going on out there.\nRelated Phishing.org articles:", "label": 1}
{"text": "By Tiffany Williams, IACP Technology Center Outreach Coordinator\nhe mission of the U.S. Customs and Border Protection (CBP) (U.S. Border Patrol) is to “…secure America’s borders; to protect the American public against terrorism and the instruments of terror; and to enforce the laws of the United States while fostering its economic security through lawful international trade and travel.”1 As a component of the U.S. Department of Homeland Security, U.S. Border Patrol comprises approximately 20,000 agents that work at and around U.S. borders in an effort to keep Americans safe. The U.S. Border Patrol patrols the United States’ southern border from Texas to California, all of the Floridian border continuing along the Louisiana (the gulf coast) border and the Caribbean Ramey sector of Puerto Rico. To the north, U.S. Border Patrol patrols the U.S. border from Washington to Maine.\nThe U.S. Border Patrol is responsible for securing America’s borders beyond the specified ports of entry. This encompasses different terrains and remote locations varying from the desolate deserts to water borders. To better secure the borders, there are three main components employed: technology, infrastructure, and personnel. The Enforcement and Information Technology (EIT) division of the U.S. Border Patrol Headquarters in Washington, D.C., focuses on the technology aspect. Due to the breadth of the issues surrounding border protection, it is not surprising that the U.S. Border Patrol’s responsibility for patrolling thousands of miles of the border requires its technology “tool belt” to include emerging technologies that not only promote mobility, but also create the best possible level of surveillance and protection.\nRemote Surveillance Systems\nPatrolling remote areas of the border is an arduous task as these areas are ideal locations for persons intending to illegally cross the border. The U.S. Border Patrol is able to better patrol these areas due in part to its deployment of the Remote Video Surveillance System (RVSS). The RVSS is strategically placed along the northern and southern borders and consists of two sets of camera systems affixed to a platform atop an 80-foot pole. One is a thermal nighttime camera; the other, a color daytime camera. Their pan-tilt ability allows them to move in different directions to ensure a comprehensive level of surveillance, for example, while one set of cameras looks east, the other looks west, overlapping each other to cover all areas.\nTo date, there are about 290 RVSS sites across both the northern and southern borders. Some of these sites are situated in such remote locations that they operate by solar energy and generators. The remote location of these RVSS sites allows the U.S. Border Patrol to focus on potentially prime crossing points for illegal traffickers. EIT division chief Steve Evans emphasizes that the system is “not a catchall.” But it is one of many helpful tools used to fight illegal border crossings and ultimately allows the U.S. Border Patrol to strategically place its manpower.\nMobile Surveillance Systems\nIn conjunction with the RVSS, the Mobile Surveillance System (MSS) that is used by the U.S. Border Patrol allows the same type of security and surveillance as the RVSS, but it has the mobile component that is necessary to cover a larger area. The MSS is a camera mounted on a high pole affixed to a large flatbed truck, thus allowing it to be mobile. In addition to the camera bundles, the MSS has a radar unit that is particularly helpful in the desert environment. Moreover, the U.S. Border Patrol uses Mobile Remote Video Surveillance Systems (MRVSS), or “scope trucks,” that are smaller than the MSS trucks and permit access to more remote locations.\nUnattended Ground Sensors\nThe U.S. Border Patrol has been using sensors to detect motion for years; however, it has adapted to evolving technologies that are more precise and intelligent. These modern sensors are strategically placed upon the recommendation of the field agents in problem locations. The Unattended Ground Sensors (UGS) come in three main forms: seismic, magnetic, and infrared. The seismic sensors detect ground movement; the magnetic ones recognize metal in passing vehicles; and the infrared sensors respond to the breakage of spatial planes. The U.S. Border Patrol is mindful of the environmental limitations of sensors, for example, the seismic sensors are not appropriate for northern borders because of frozen ground affecting their functionality. The U.S. Border Patrol analyzes different terrains to decipher which areas would benefit from what particular types of sensor in order to ensure their effectiveness.\nThe E3/IDENT is a technology that was created to assist in evaluating arrests and in collecting the biometrics and photographs of apprehended persons. This technology allows agents to secure this information and forward it to the Federal Bureau of Investigation (FBI). Within 8 to 10 minutes, agents will receive historic federal criminal information on individuals. Moreover, it will display whether or not an individual currently is wanted for a criminal offense. Another component is its capability to access the INS/IDENT database in order to search for possible immigration violations.\nResults and Moving Forward\nAssistant Chief of the U.S. Border Patrol, Robert Nelson, claims that EIT “fills the immediate technology gap.” Both Chiefs Nelson and Evans stress the importance of using technology to better secure U.S. borders. Chief Evans is constantly searching for and learning about emerging technologies that will better assist his team in their mission. It is imperative to note that all three components—technology, infrastructure, and personnel—play important and interconnected roles in securing U.S. borders. Overall, the combined use of all three contributed to 723,825 apprehensions in fiscal year 2008 and ultimately assisted in keeping U.S. citizens safe.\nSpecial thank you to Division Chief Steve Evans and Assistant Chief Robert Nelson of the U.S. Border Patrol, Customs and Border Protection, for providing the information that contributed to this article. &9632;\n1Customs and Border Protection, “CBP Mission Statement and Core Values,” http://www.cbp.gov/xp/cgov/about/mission/guardians.xml (accessed August 10, 2009).", "label": 1}
{"text": "Protect Yourself From Cyber Crime\nProtect your digital life\nCyber crime is on the rise and your smartphone makes you an easier target - protect yourself with these tips\nIt’s important to know that not all hackers are out to sow mayhem and destroy credit ratings. Some are just trying to make things better by making changes to existing systems that benefit the public – those hackers are the whitehatters. Blackhatters are the type that are on a search and destroy mission.\nHackers have the ability to get your valuable information like email addresses and address books. These can be sold as marketing ponds, or to genuine marketers, who will send you spam in the hope of landing your personal data. Whether hacker’s are working to benefit you, or to get their hands on your valuable information, it’s important to know how to protect your data from others.\nThere are various types of hacks: system hacks, device hacks and social engineering hacks. Here’s how to protect yourself from all three.\nSocial engineering hacks\nThese is the most prevalent type of hack, called phishing. (You should have got a couple of emails from your bank about this.) A person will give up their data voluntarily thinking that they are interacting with a legitimate site – like the spam from the Chinese chemical company or Ghaddafi’s son. Due to the overwhelming numbers involved it usually runs as an automatic script rather than one person interacting with the user. To avoid getting caught, position your mouse cursor over the \"link\" in the mail. If the web address that appears in the bottom of the email or browser window doesn't match the link description in the email then you are almost certainly headed into a trap.\nThese come from insecurities in the software you've loaded or the access you’ve mistakenly given. Either you haven’t blocked a device from external connections, or a bluetooth channel is permanently left open. Device hacks can be the fault of the software loaded on the system or the fault of the user who is downloading viruses and trojans through their browsing or other risky online behaviour.\nAt some point you’ll entrust your details to a company and if they haven’t adequately secured their website, premises, system, data or building they can be hacked. It happened to big online corporates like Linkedin and Apple, but it can happen to any company, bank or government.\nWatch your websites\nEven a “strong password” that includes numbers, letters, capitals and symbols can be hacked. It doesn't matter what you type in if there's someone on the other end of the website that is reading the field where it’s stored. If a website gives you an option to send you your \"lost password\" (via email or SMS) beware. This means they have stored the mechanism to decipher whatever hashing they've done. Websites that send you a link to reset your lost password are slightly better.\nSome security projects use salted passwords that are hashed and stored in their transformed format. They take your password and then use a unique key that transforms your password into something unintelligible. If you use a different key for every single person in your database it can be a little bit more challenging to find out the actual password. But it can still be deciphered. Linkedin used a very simple hash for its password system and it got hacked. Once someone has the ability to see the salted password and they know the value that was entered to arrive at that password they have a basis for interrogating the algorithm for everyone on that system.\nVary your passwords\nYou use the same password for every website, email account and bank account right? Not smart. A hacker only needs to find one site or system that is not secure and the rest of your accounts are theirs for the taking. If you can’t remember a million different combinations of your dog’s name, download Safewallet (download at sbsh.net or you smartphone applications store). It’ll give you random passwords – that can be as complex as you want – and store them for you. (But a hacker only needs to crack your Safewallet password to get access to everything… so it’s a bit of double edged sword.)\nAvoid QR codes\nYou have absolutely no clue what you’re doing when you scan those little black and white QR code blocks. Unlike a normal domain name link where you can usually tell that it’s not the official website, QR codes will take you to the site before you even know it may be a trap. There are QR code readers that can give you a clue about where you are going to be surfing to, but nobody but the very paranoid will actually ever stop to read the code before surfing straight to it. And even if you know where you were going, there's no guarantee that it’s safe.\nDo business face-to-face\nAll a hacker needs is an existing credit card number and a name to attach to it in order to hide under the anonymity of an online profile. Because of FICA regulations setting up a credit card under a fake name is difficult, messy and opens you up to being caught. So keep your credit card details safe. (Hackers prefer to use details of someone who has died, that way when someone doesn't recognise a bank charge or gets called to collect a bad debt then there is no one to physically find or contact.) Be careful of keeping large amounts of data on th web, like Cloud storage – this is no different from uploading your data to a website or your email on a hosted server. Its still your data that’s on a server somewhere, there's just more of it and it’s password protected. Its up to you what you are exposing and you have no guarantee of its security. Ever.\nKeep it simple\nYou can take small precautions but there are never any guarantees. Be vigilant. Check on your credit profile every now and again. Use a software program to give you different passwords. Change them for every site from time to time. Get a reputable anti-virus programme – free or paid for. But remember that even an anti-virus programme isn’t full proof. New viruses are created all the time and software bugs are a natural occurrence in systems, (and no virus program will ever stop you from being exploited through a social engineering hack).\nKaspersky One is your protection solution for all your devices. Worldwide, 50 million people are now members of the Kaspersky Security Network, sending data to the company’s Moscow headquarters every time they download an application to their desktop. When it comes to keeping computers free from infection, Kaspersky Lab is on its way to becoming an industry leader. phoenixsoftware.co.za\nLast updated: Tue, 2013-02-05 08:57", "label": 1}
{"text": "Here are some tips for PC and Mac users alike — and smartphone users, too. Though there are “few” Mac viruses in the wild, there are plenty of unscrupulous programmers and con-men spreading free fraudulent software and malware.\nTake the following steps to help prevent infection on your computer:\n- Enable a firewall on your computer.\n- Get the latest computer updates for all your installed software.\n- Use up-to-date antivirus software.\n- Limit user privileges on the computer.\n- Use caution when opening attachments and accepting file transfers.\n- Use caution when clicking on links to webpages.\n- Avoid downloading pirated software.\n- Protect yourself against social engineering attacks.\n- Use strong passwords.\nLet me elaborate on a few points:\nGet the latest computer updates\nUpdates help protect your computer from viruses, worms, and other threats as they are discovered. It is important to install updates for all the software that is installed in your computer. These are usually available from the providing company’s website. The following are programs I recommend updating straight from the source:\n- Adobe (www.adobe.com):\n- Acrobat Reader\n- Java (www.java.com): Check this one monthly.\nUse up-to-date antivirus software\nMost antivirus software can detect and prevent infection by known malicious software. To help protect you from infection, you should always run antivirus software. If you have a “subscription” for update service, make sure you renew annually. Antivirus, contrary to popular belief, is not free-for-life.\nUse caution when opening attachments and accepting file transfers\nExercise caution with email and attachments received from unknown sources, or received unexpectedly from known sources. Use extreme caution when accepting file transfers from known or unknown sources. When in doubt, reply to the sender, assuming it is someone you know, and confirm that they meant to send you the attachment. It’s possible their computer is infected and sent you the file without their knowledge. I’ve seen this happen several timers in the course of a year.\nUse caution when clicking on links to webpages\nAs above: Exercise caution with links to webpages that you receive from unknown sources, especially if the links are to a webpage that you are not familiar with, unsure of the destination of, or suspicious of. Malicious software may be installed in your computer simply by visiting a webpage with harmful content.\nAvoid downloading pirated software\nThreats may also be bundled with software and files that are available for download on various torrent sites. Downloading “cracked” or “pirated” software from these sites carries not only the risk of being infected with malware, but is also illegal. For more information, see ‘The risks of obtaining and using pirated software‘.\nProtect yourself from social engineering attacks\nWhile attackers may attempt to exploit vulnerabilities in hardware or software to compromise a computer, they also attempt to exploit vulnerabilities in human behavior to do the same. When an attacker attempts to take advantage of human behavior to persuade the affected user to perform an action of the attacker’s choice, it is known as ‘social engineering’. Essentially, social engineering is an attack against the human interface of the targeted computer. For more information, see ‘What is social engineering?‘.\nUse strong passwords\nAttackers may try to gain access to your Windows account by guessing your password. It is therefore important that you use a strong password – one that cannot be easily guessed by an attacker. A strong password is one that has at least eight characters, and combines letters, numbers, and symbols. For more information, see http://www.microsoft.com/protect/yourself/password/create.mspx.", "label": 1}
{"text": "Advances in information technology have changed our daily lives. Most faculty and staff members use computers to manage, share and store a wide range of information. Because you have access to information that is often personal and confidential, it is important for you to know how to protect that information. Security is the responsibility of all members of the University community.\nWhat is the purpose of security awareness?\nThe purpose of awareness is to focus attention on security, creating sensitivity to the threats and vulnerabilities of computer systems and recognition of the need to protect data, information and systems.\nWhat are some of the threats to information security?\n- Password guessing\n- Accidental disclosure of confidential information\n- Misuse of systems or networks\n- Abuse of system privileges\n- Social engineering\n- Malicious viruses, worms and Trojan horses from e-mails and downloaded files\n- Theft of mobile devices (laptops, PDAs) that contain confidential information\nWhy is security awareness training needed?\nIt is important for students, faculty and staff to understand the importance of IT security and to ensure that each individual understands his or her responsibilities. In order to do our jobs, we must have information available when we need it. It must be accurate, and we must know the steps needed to safeguard its confidentiality when necessary. To be truly effective, everyone must do his or her part to secure the information environment.\nThe Risk, Security and Compliance office is committed to a strong approach to education, outreach and awareness training. We provide training for students, faculty and staff and are eager to work with any department or office on campus to ensure good security practices are in place.\nFeel free to contact us to find out more.", "label": 1}
{"text": "Counterfeit medicines: the silent epidemic\nWHO convenes stakeholders to find global solutions to a growing health threat\n15 February 2006 | Rome/Geneva - The World Health Organization (WHO) calls for immediate concrete action against the growing epidemic of counterfeit medicines. In a bid to accelerate the war on fake drugs, the agency will push for stronger global cooperation, political commitment and creative solutions at a meeting in Rome from 16 to 18 February.\nWHO aims to create a global task force involving all major interested parties. The task force will focus on legislation and law enforcement, trade, risk communications and innovative technology solutions, including public-private initiatives for applying new technologies to the detection of counterfeits and technology transfer to developing countries.\nThe counterfeiting of medicines is present in all countries and is thought to represent 10% of the global medicines trade. Particularly insidious, counterfeit medicines dupe sick people into believing they are taking something which will make them well, when it may instead make them sicker or even kill them.\n\"People don’t die from carrying a fake handbag or wearing a fake t-shirt. They can die from taking a counterfeit medicine,” says Howard Zucker, Assistant Director General for Health Technology and Pharmaceuticals at WHO. “International police action against the factories and distribution networks should be as uncompromising as that applied to the pursuit of narcotic smuggling.”\nCounterfeit medicines are part of the broader phenomenon of substandard pharmaceuticals. The difference is that they are deliberately and fraudulently mislabelled with respect to identity and/or source. These products mostly have no therapeutic benefit; they can cause drug resistance and death.\nTrade in counterfeits is extremely lucrative, thus making it more attractive to criminal networks. A report released by the Centre for Medicines in the Public Interest, in the United States, projects counterfeit drug sales to reach US$ 75 billion in 2010, a 92 % increase from 2005.\nThe presence of fake drugs is more prevalent in countries with weak drug regulation control and enforcement. However, no single country is immune to the problem. Reports from the pharmaceutical industry and governments clearly indicate that the methods and channels used by counterfeiters are becoming more sophisticated, making detection more difficult. Measures for combating counterfeit medicines so far have included support to under-resourced drug regulatory authorities; simple, easily interpretable and cheap markers of authenticity such as barcoding; transnational surveillance for fake and substandard drugs; and education of patients, healthcare workers, and pharmacists.\n“These measures need to be intensified,” adds Dr Zucker. “Countries should think about ways to make the necessary technological, legislative and financial adjustments as quickly as possible to guarantee the availability of quality assured essential drugs.”\nWHO would also like to see more developments in the areas of innovative high and low tech solutions for prevention at the manufacturing stage and for detection in the distribution chain.\nSimple, inexpensive methods to identify fakes can be effective. For example, simple colorimetric assays developed for artemisinins have been used successfully to identify fake artesunate antimalarials.\nWHO set up the world's first web-based system for tracking the activities of drug cheats in the Western Pacific Region in 2005. The Rapid Alert System (RAS) communications network transmits reports on the distribution of counterfeit medicines to the relevant authorities for them to take rapid countermeasures. That system should be expanded to include all regions.\nRadio frequency identification (RFID) and more sophisticated technologies for product tracking within supply chain management systems are being experimented in some countries. Means must be sought to make these more sophisticated tools available and workable in developing countries.\nInformation on fake drug identity and distribution needs to be shared nationally and internationally between government drug regulatory authorities, customs and police organizations, pharmaceutical companies, non-governmental organizations, and consumer groups. Risk communications, involving the media, should be practised to raise public awareness.\nThe Rome conference is hosted by the Italian Pharmaceutical Agency (AIFA) and Italian Cooperation, and organized with the support of the International Federation of Pharmaceutical Manufacturers & Associations (IFPMA) and the German Government. Participants in the conference include experts from national governments and regulatory authorities, industry, intergovernmental organizations, and consumer and patient groups.\nNotes for the press\nWHO will hold a press conference at Palazzo Brancaccio, via del Monte Oppio 7, Rome, on Thursday 16, 13.00.pm. Journalists wishing to attend the press conference and/or conference presentations throughout Thursday, should register with Ms Arianna Gasparini by sending an e-mail to ufficiostampaAIFA@sanita.it\nFor more information on the conference, the programme and participants, please see: www.who.int/medicines/counterfeit_conference/en/index.html\nJournalists wishing to attend the first day of the conference, should register via email@example.com\nFor more information contact:\nTelephone: + 41 22 791 45 44\nMobile phone: + 41 794 75 5490", "label": 1}
{"text": "OnGuardOnline.gov, co-managed by the Federal Trade Commission, is the federal government’s website to help you be safe, secure and responsible online.OnGuardOnline.gov is a partner in the Stop Think Connect campaign, led by the Department of Homeland Security, and part of the National Initiative for Cybersecurity Education, led by the National Institute of Standards and Technology.\nI, for one, am a big fan of the Department of Homeland Security, so I wanted to provide some DHS perspectives on wireless, its vulnerabilities and encryption–such as that obtainable through Hotspot Shield VPN—straight from the government’s mouth: “Wi-Fi hotspots in coffee shops, libraries, airports, hotels, universities and other public places are convenient, but they’re often not secure. When using a hotspot, it’s best to send information only to websites that are fully encrypted.\n“You can be confident a hotspot is secure only if it asks you to provide a WPA password. If you’re not sure, treat the network as if it were unsecured.”\nYou’ve heard it from this blogger before, but this is what Homeland Security has to say about encrypting your web communications:\n“Encryption is the key to keeping your personal information secure online. Encryption scrambles the information you send over the internet into a code so that it’s not accessible to others. When using wireless networks, it’s best to send personal information only if it’s encrypted—either by an encrypted website or a secure WiFinetwork. An encrypted website protects only the information you send to and from that site. A secure wireless network encrypts all the information you send using that network.” Homeland Security further states: “Don’t assume a Wi-Fi hotspot is secure. Most Wi-Fi hotspots don’t encrypt the information you send over the internet and are not secure.”\nHence, get yourself a wireless VPN! And use it. Advice straight from the DHS’s mouth.\nRobert Siciliano is an Identity Theft Expert to Hotspot Shield VPN. He is the author of 99 Things You Wish You Knew Before Your Identity Was StolenSee him discussing internet and wireless security on Good Morning America. Disclosures.", "label": 1}
{"text": "NoSQL databases have been the subject of considerable debate as developers and systems architects disagree on where they're most useful. Some technologists are skeptical that NoSQL will even fill a long-term need: They believe NoSQL databases will be limited to niche applications and that SQL databases will continue to be the dominant model. Such concerns ignore fundamental changes to how and why applications are developed. NoSQL is definitely here to stay, for a variety of reasons.\nScalability and Big Data\nThe days of gigabytes of data are gone; even modestly sized applications now must cope with terabytes or petabytes of data, much of it constantly changing and growing. As the data load continues to grow, IT organizations need a way to scale up quickly and flexibly without investing hundreds of thousands of dollars in building single-server solutions that become increasingly expensive with scale.\nNoSQL databases make it easy to meet expanding needs because they're built to scale out, instead of scale up. By automatically functioning across pools of inexpensive commodity servers or cloud computing instances, NoSQL databases enable sites to increase (or decrease) capacity cost-effectively you can have a high-performance system even if you don't necessarily have the largest budget.\nAnd because they have fewer limits on scalability, NoSQL databases are much better equipped to handle the volume of data that modern applications need. The amount of data we use is not going to shrink, so the need for database management systems that can handle the growth is permanent.\nChanging System Architectures\nWith the advent of cloud computing, the way that systems are set up has changed drastically, and will continue to change as new server types and technologies become available. A database instance might easily be spread across thousands of nodes, located around the world, and serving millions of widely dispersed customers simultaneously.\nNoSQL databases natively work with modern system architectures, which means they're set up to scale across an unlimited number of servers and continue functioning normally even as nodes are added and removed. This design dramatically reduces scaling costs as well as server administration and setup time. Many NoSQL databases are also location-aware, making it easy to accelerate data delivery to users based on geography.\nEase of Use\nBecause they don't have fixed schemas, NoSQL databases are known for being easy to work with. You can code applications quickly, without worrying about time spent migrating data to new schemas as your application evolves. In addition, document-oriented databases make it unnecessary to have object-oriented code transform requests into SQL queries, and then change the SQL results back into objects that fit in with the application logic. So will NoSQL databases displace RDBMS technology across the spectrum of applications? No. Not anytime soon, anyway. But for the vast majority of applications, NoSQL databases and particularly document databases offer the scale, flexibility, and ease-of-use that applications require.", "label": 1}
{"text": "In This Issue: Two Places at Once? NIST Shows It's Only for Atoms Presidential Initiative Seeks Funds to Squash Hackers On Balance, MEASUREnet.gov May Be Best New Thing on the Internet For California Confectionery, Life Is Sweet Once More If It's Warm Outside, It's Not Midweek New Registry Helps Developers Check IDs at the Door Tech Trivia\nWhen you see the camera icon, click to see available picture !\n[NIST Tech Beat Search] [Credits] [NIST Tech Beat Archives] [Media Contacts] [Subscription Information]\nTwo Places at Once? NIST Shows It's Only for Atoms\nSuperpositioning. Being in two places at the same time. We'd all like to have the power with our busy schedules.\nScientists at the National Institute of Standards and Technology's Boulder, Colo., laboratories proved in 1996 that superpositioning can occur at the atomic level. Four years later, the same team has shown that-unfortunately for humans-it only works in that tiny world.\nIn both experiments, the researchers isolated a single beryllium ion (an atom with one of its two outer electrons stripped away) in an electromagnetic trap, cooled it nearly to absolute zero with lasers and left it resting almost without motion. The ion's single remaining outer electron, which can have two internal quantum states, is considered in superposition if the two states both exist and are stacked upon one another. Until disturbed by an outside force, there is an equal probability that the electron is in either state, and thus it is considered to be in both states.\nIn the latest experiment, the NIST team separated the two states over a range of distances from almost overlapping to around 10 atomic widths apart. As they increased the distance between the two states, the environmental effects on the superposition increased exponentially, causing the separated ion to quickly collapse back into a single entity.\nFred McGehan (Boulder) , (303) 497-3246\nPresidential Initiative Seeks Funds to Squash Hackers\nMonday morning, Feb. 7, 2000. Web surfers hoping to use the Yahoo browser to search for information, check the latest news or shop for the upcoming Valentine's Day holiday, got a rude surprise. One of the world's best-protected web sites had been shut down by hackers-and would stay offline for three hours.\nOver the following three days, seven of the Internet's top sites fell prey to \"denial of service\" attacks where the target is flooded with an overwhelming number of messages. The large scale-Yahoo claimed it was at times trying to process a gigabyte per second-made the attacks almost unstoppable. Worse yet, the use of multiple computers and falsified Internet return addresses hid the attackers well.\nIronically, the cyberterrorist activities began the day that President Clinton submitted his proposed fiscal year 2001 federal budget to Congress. Within that budget is a $60 million initiative for the National Institute of Standards and Technology to protect the nation's critical information infrastructure by: (1) establishing an institute to provide grants for research and technology development to protect critical infrastructures from attack or other failures ($50 million); (2) developing new measurements, standards, test methods and guidelines to better protect IT elements ($5 million); and (3) creating and fielding a team of computer security experts to help federal agencies identify and fix existing vulnerabilities in information systems and prepare for future IT security threats ($5 million).\nMichael E. Newman , (301) 975-3025\nOn Balance, MEASUREnet.gov May Be Best New Thing on the Internet\nNext time you place your apples on a grocery scale, stop and thank your state's weights and measures laboratory and the National Institute of Standards and Technology. You can be sure those scales, as well as the scales used to package foods and manufacture pharmaceuticals, are correct due to the efforts of the NIST Office of Weights and Measures and the National Conference on Weights and Measures, which represents the state weights and measures labs.\nA new effort at NIST could further improve accuracy in our nation's system of weights and measures by leveraging the capabilities of the Internet. MEASUREnet. gov will link NIST to local government weights and measures laboratories in 10 states and Puerto Rico. It eventually could be expanded to all U.S. states and territories.\nMEASUREnet.gov is an interactive Internet-video conferencing system intended to support training and collaborative work between NIST and state weights and measures laboratories. MEASUREnet.gov will enable NIST to provide technical assistance and training more frequently and efficiently and to develop standards in partnership with states. U.S. industry relies on the state weights and measures laboratories to calibrate standards for a variety of processes from manufacturing pharmaceuticals to filling cereal boxes. State laboratories provide more than 340,000 NIST-traceable calibrations to more than 19,400 customers each year. Ninety percent of those calibrations are for mass measurements.\nLinda Joy , (301) 975-4403\nFor California Confectionery, Life Is Sweet Once More\nLike the \"I Love Lucy\" episode where candy came down the conveyor belt faster than Lucy could package it, Marich Confectionery of Hollister, Calif., was having trouble keeping up with demand. Each year, the 37-employee company produces and ships nearly 4 million pounds of gourmet candies worldwide. But shipping on time was a major problem. The candy maker's efficiency also suffered from low employee morale, maintaining a sufficient supply of raw materials and losing control of finished products.\nMarich contacted Manex, the northern California center affiliated with the NIST Manufacturing Extension Partnership, for help. Working with company executives and employees, Manex experts recommended a process improvement plan and a new manufacturing layout. Manex also showed the company how to use flow charts for scheduling, material planning and purchasing, and controlling inventory. As a result, shipments are made on time and in full, and employee morale and productivity has improved.\nSmall manufacturers in all 50 states, the District of Columbia and Puerto Rico can reach their local NIST MEP affiliate by calling (800) MEP-4MFG (637-4634), or through the World Wide Web at www.mep.nist.gov.\nJan Kosko , (301) 975-2767\nIf It's Warm Outside, It's Not Midweek\nWhile researching techniques for extracting information from noisy electromagnetic signals, Kevin Coakley, a statistician at the Boulder, Colo., laboratories of the National Institute of Standards and Technology, noticed a surprising phenomenon relevant to meteorology as well as metrology.\nTo illustrate his statistical methods, Coakley analyzed the daily maximum temperature data collected at the San Francisco International Airport from 1949 to 1994. For each of the 52 weeks in each year, he recorded the day on which the weekly maximum temperature occurred. He found that the weekly maximum temperature occurs more frequently on the first (or last) day of the week compared to a day in the middle of the week. Even if the week is redefined to begin on Wednesday and end on Tuesday, the conclusion is the same.\nCoakley argues that the phenomenon happens because temperature readings follow random upward or downward trends over short intervals of time. For instance, if it's warmer than average today, it probably will be warmer than average tomorrow. More generally, this apparent paradox can occur in any measurement process for which the random noise in the results is positively correlated (more alike than unalike) from one measurement to the next.\nThis work appears in the February 2000 issue of the Bulletin of the American Meteorological Society.\nFred McGehan (Boulder), (303) 497-3246\nNew Registry Helps Developers Check IDs at the Door\nImagine your name is John Smith and you're at a party where everyone attending has that name. No one could get anyone's attention, conversations would be difficult and there would be no obvious winner for the door prize drawing. In other words, total confusion.\nFor years, software and web site developers have faced a John Smith dilemma of their own. Choosing identifiers-things that distinguish variables, filename extensions (such as .wpd for \"Word Perfect document\"), system call names, port numbers and the like in programming languages-wasn't as simple as it might seem. Developers could not easily determine if their identifier was a duplication of or in conflict with one already in use. The uncertainty meant a dangerous potential for software or web sites to run ineffectively or crash.\nTo solve the problem, the National Institute of Standards and Technology has established the NIST Identifier Collaboration Service, a free, online registry for identifiers. Users can browse the database for identifiers, determine that theirs is original and then add it to the repository. An added benefit of the NICS is that other developers can review the new identifier and comment on possible conflicts.\nIf the NICS becomes widely used, its creators feel that it will reduce software and web page development time significantly, lower development costs and increase reliability. Interested parties can get more information on the World Wide Web at http://pitch.nist.gov/nics.\nMichael E. Newman, (301) 975-3025\nIn 1950, NIST performed some 250,000 tests and calibrations for industry and other federal agencies. The items evaluated included 9 million barrels of cement; 4 million light bulbs; 15,318 thermometers; 2,000 radium therapy preparations; 615 automotive spark plugs; and 266 beer meters (the devices that measure the total volume of beer produced by a brewery).\nIn 1949, Congress approved funds for \"the construction and equipment of a radio laboratory building for the National Bureau of Standards.\" The Boulder, Colo., Chamber of Commerce raised $90,000 during the following year, purchased a 217-acre site within the city and sold it to the government for $1. The complex is now known as the NIST Boulder Laboratories.\nIn the mid-1960s, NIST used a sled-and-track device at Holloman Air Force Base, N.M., to test the effectiveness of automobile belt and shoulder harnesses on anthropomorphic dummies and human volunteers. Results from the tests, conducted for the Department of Transportation, were cited as justification for mandating shoulder restraints in U.S. motor vehicles.", "label": 1}
{"text": "What is Identity Theft?\nIdentity theft is a serious crime. It can\ndisrupt your finances, credit history, and reputation, and\ntake time, money, and patience to resolve. Identity theft\nhappens when someone steals your personal information and\nuses it without your permission.\nIdentity thieves might:\n- go through trash cans and dumpsters, stealing\nbills and documents that have sensitive information.\n- work for businesses, medical offices, or\ngovernment agencies, and steal personal information on the\n- misuse the name of a legitimate business,\nand call or send emails that trick you into revealing personal\n- pretend to offer a job, a loan, or an apartment,\nand ask you to send personal information to “qualify.”\n- steal your wallet, purse, backpack, or\nmail, and remove your credit cards, driver’s license,\npassport, health insurance card, and other items that show\nHow Can I Protect My Information?\nDo you utilize online banking and\nbill pay options?\nhere for tips on how to make online transactions safe and\nyou a business owner?\nhere for tips on how to make online banking for your business\nsafe and more secure.\nRed Flags of Fraud & Identiy\n- mistakes on your bank, credit card, or\nother account statements\n- mistakes on the explanation of medical\nbenefits from your health plan\n- your regular bills and account statements\ndon’t arrive on time\n- bills or collection notices for products\nor services you never received\n- calls from debt collectors about debts\nthat don’t belong to you\n- a notice from the IRS that someone used\nyour Social Security number\n- mail, email, or calls about accounts or\njobs in your minor child’s name\n- unwarranted collection notices on your\n- businesses turn down your checks\n- you are turned down unexpectedly for a\nloan or job\nIf Your Identity is Stolen...\nFlag Your Credit Reports\nCall one of the nationwide credit reporting companies, and\nask for a fraud alert on your credit report. The company you\ncall must contact the other two so they can put fraud alerts\non your files. An initial fraud alert is good for 90 days.\nEquifax 1 800 525 6285\nExperian 1 888 397 3742\nTransUnion 1 800 680 7289\nOrder Your Credit Reports\nEach company’s credit report about you is slightly different,\nso order a report from each company. When you order, you must\nanswer some questions to prove your identity. Read your reports\ncarefully to see if the information is correct. If you see\nmistakes or signs of fraud, contact the credit reporting company.\nCreate an Identity Theft Report\nAn Identity Theft Report can help you get fraudulent information\nremoved from your credit report, stop a company from collecting\ndebts caused by identity theft, and get information about\naccounts a thief opened in your name. To create an Identity\n- file a complaint with the FTC at ftc.gov/complaint\nor 1-877-438-4338; TTY: 1-866-653-4261. Your completed complaint\nis called an FTC Affidavit.\n- take your FTC Affidavit to your local\npolice, or to the police where the theft occurred, and file\na police report. Get a copy of the police report.\nThe two documents comprise an Identity Theft\nFor more information on Fraud & Identity\nTheft, please visit the following websites:", "label": 1}
{"text": "Digital Intelligence & Forensics\nMeasurement & Analysis\nPerformance & Dependability\nProcess & Performance Improvement\nSecurity & Survivability\nThe software architecture of a program or computing system is a depiction of the system that aids in the understanding of how the system will behave.\nSoftware architecture serves as the blueprint for both the system and the project developing it, defining the work assignments that must be carried out by design and implementation teams. The architecture is the primary carrier of system qualities such as performance, modifiability, and security, none of which can be achieved without a unifying architectural vision. Architecture is an artifact for early analysis to make sure that a design approach will yield an acceptable system. By building effective architecture, you can identify design risks and mitigate them early in the development process.\nFor almost two decades, the SEI has been instrumental in the creation and development of the field of software engineering known as software architecture. Operated by Carnegie Mellon University—a global research university recognized worldwide for its innovative work—and funded by the federal government, the SEI solves real-world problems by conducting research, developing tools and methods, providing consulting services, and publishing case studies.\nMay 21, 2013\nThe SEI has a rich body of influential and widely cited reports, presentations, and books in the field of software architecture. These publications present research results, case studies, and practitioner experience with architecture-centric practices, tools, and methods.\nSEI publications in software architecture provide information about practices and techniques for predictably and efficiently designing, constructing, and guiding the evolution of software-reliant systems with the qualities needed to meet business and mission goals.\nThe SEI publishes and makes available free downloads of reports that offer new technical information about software engineering topics, whether theoretical or applied. The SEI also publishes books on software engineering for industry, government, and military applications and practices.\nThe SEI offers software architecture courses and certification programs. People from more than 900 organizations have attended SEI courses, and more than 1,800 of them have earned certificates conferred by the SEI for taking a series of architecture-related SEI courses. These courses are informed by the experiences of SEI staff members working directly with organizations over the past two decades and helping them to achieve significant cost reductions, quicker time to market, and higher product quality by applying architecture-centric practices to the development of their systems.\nSoftware professionals can complete one or more of three software architecture certificate programs. These programs are based on completion of specific sequences in the software architecture curriculum, as depicted below. For more information on these software architecture certificates, please visit the SEI Professional Certificates in Architecture website.\nSince its creation, the SEI has defined and advocated methods for building high-quality software. Training from the SEI enables individuals to benefit from SEI research and practice. The same technical experts who conduct the research and apply these practices in real settings are actively engaged in developing and delivering the SEI's training courses.\nPlease tell us what you\nthink with this short\n(< 5 minute) survey.", "label": 1}
{"text": "Connections 20038. Top Secret\nWhat are secrets and why do we need to keep them hidden? Once we have secrets, how do we keep other people, companies, organizations and countries from uncovering them?\nYour computer log-in password and your credit card number are two secrets you want to keep hidden from strangers. Microsoft’s source code is a secret, and the formula that produces Coca-Cola is coded, locked in a vault, and kept under tight security. Al Qaeda has secrets that the U.S. government wants to know. The U.S. government has military secrets, diplomatic secrets and policy secrets it doesn’t want anyone, even allies, to know.\nThis two-course connection enables students to relate the “hows” of encoding secret information in the math course to the “whats” and the “whys” of doing so in the domains of government and business in the political science and economics courses. Students will learn what information policy makers and planners believe is necessary to keep secret and how to construct unbreakable codes to keep these secrets secure.", "label": 1}
{"text": "Email phishing attempts, try to fool you into providing private information such as your Internet password, banking information, or other information that might lead to identity theft. Recently a new UMD student reported having responded to an email offering a job opportunity. Because it came in her UMD email, she thought it was an email from UMD, and she responded by providing some information and indicating an interest in this job. Unfortunately, the email was not from UMD, and it is hard to tell whether or not it was a legitimate business. Luckily, she did not provide any private financial information, so we hope all will be well. If you are wondering how to tell whether an email is legitimate or not, How To Tell If an Email Is a Phishing is a good article that might help.\nITSS scans email before it is delivered and then tags suspicious email in the subject line with [phish?]. There is no need to call or email us when you see a message like this. Unless you have a good reason to believe it is legitimate, you should simply delete the message. Please know that we can't detect every phish message, so you should still remain vigilant. In gmail, you can also choose to tag the message as spam, using the icon that looks like a stop sign with an exclamation point inside.\nPlease know that no reputable business, including the University of Minnesota, will ask you to provide personal information via email. In particular, guard your passwords, bank numbers, social security numbers, and similar data, and do not provide it via email. You should also avoid clicking on a web link in a suspicious message. For further information consult Phishing Scams.", "label": 1}
{"text": "Receiving spam is never fun. Not only does it clog email inboxes, but it's also an easy way for cybercriminals to plant malware on your computer or trick you into handing over some of your private data.\nA recent report released by Internet security firm Sophos reveals the top spam-relaying nations. Combined, computers in these countries were responsible for sending out nearly 60 percent of spamming around the world from January through March of 2012.\nSophos' Graham Cluley points out that a computer owner might not know when his or her device is relaying spam. \"The vast majority of spam comes from home computers that have been compromised by hackers, and commandeered into a botnet,\" Cluley wrote in a blog post explaining the study.\nWhile basic email marketing spam has decreased since last year, according to the report, Cluley noted that, \"the number of messages that spread malware or that represent more targeted attempts to phish usernames, passwords and personal information is increasing.\" In addition, it seems both basic spammers and cybercriminals are using social networks like Facebook, Twitter and Pinterst to spread their messages or malware. For example, AGBeat reported in March, many Pinterest users fell for a scam offering free Starbucks gift cards; however, clicking the pin led users to a scammy survey site, rather than the official Starbucks site.\nNews 1 year ago", "label": 1}
{"text": "June 11, 2012: Jianyu Huang, a Chinese scientist working in the United States, has been arrested and charged with passing stolen technology back to China. Huang was fired from his nanotechnology research job in April and has been charged with stealing and lying to security officials about these activities. Huang was born in China but moved to the U.S. and became an American citizen.\nAmerican intelligence and counter-intelligence agencies have increasingly been paying close attention to Chinese born American scientists, seeking out the minority that use their access to American technology secrets to either give or sell this valuable material to government or commercial organizations in China. This is all part of extensive Chinese intelligence efforts to steal American technology.\nChina sees this kind of broad-spectrum intelligence gathering as a major operation and one they intend to keep going as long as possible. Thus, during the last four years China has established eight National Intelligence Colleges in major universities. In effect, each school now has an \"Espionage Department.\" With this, about 300 carefully selected applicants are accepted each year, to be trained as spies and intelligence operatives and future commanders of these operations. The college trained operatives expect to make a career out of stealing Western technology. China has found that espionage is an enormously profitable way to steal military and commercial secrets. While Chinese Cyber War operations in this area get a lot of publicity, the more conventional spying brings in a lot of stuff that is not reachable on the Internet.\nOne indicator of this effort is the fact that American counter-intelligence efforts are snagging more Chinese spies. But this is largely due to increased spying efforts by China, rather than more success by the FBI and CIA. This use of industrial espionage has played a large part in turning China into the mightiest industrial and military power on the planet.\nFor over two decades China has been attempting to do what the Soviet Union never accomplished: steal Western technology and then use it to move ahead of the West. The Soviets lacked the many essential supporting industries found in the West (founded and run by entrepreneurs) and was never able to get all the many pieces needed to match Western technical accomplishments. Soviet copies of American computers, for example, were crude, less reliable, and less powerful. It was the same with their jet fighters, tanks, and warships.\nChina gets around this by making it profitable for Western firms to set up factories in China, where Chinese managers and workers can be taught how to make things right. At the same time China allows thousands of their best students to go to the United States to study. While most of these students will stay in America, where there are better jobs and more opportunities, some will come back to China and bring American business and technical skills with them. Finally, China energetically uses the \"thousand grains of sand\" approach to espionage. This involves China trying to get all Chinese going overseas, and those of Chinese ancestry living outside the motherland, to spy for China, if only a tiny bit.\nThis approach to espionage is nothing new. Other nations have used similar systems for centuries. What is unusual is the scale of the Chinese effort. Backing it all up is a Chinese intelligence bureaucracy back home that is huge, with nearly 100,000 people working just to keep track of the many Chinese overseas and what they could, or should, be trying to grab for the motherland. This is where many of the graduates of the National Intelligence College program will work.\nIt begins when Chinese intelligence officials examine who is going overseas and for what purpose. Chinese citizens cannot leave the country legally without the state security organizations being notified. The intel people are not being asked to give permission. They are being alerted in case they want to have a talk with students, tourists, or business people before they leave the country. Interviews are often held when these people come back as well.\nThose who might be coming in contact with useful information are asked to remember what they saw or bring back souvenirs. Over 100,000 Chinese students go off to foreign universities each year. Even more go abroad as tourists or on business. Most of these people were not asked to actually act as spies but simply to share, with Chinese government officials (who are not always identified as intelligence personnel), whatever information they obtained. The more energetic among these amateur spies sometimes get caught and prosecuted. But the majority are quite casual and, individually, bring back relatively little but are almost impossible to catch.\nLike the Russians, the Chinese are also employing the traditional methods, using people with diplomatic immunity to recruit spies, and offering cash, or whatever, to get people to sell them information. This is still effective and when combined with the \"thousand grains of sand\" methods, brings in lots of secrets. The final ingredient is a shadowy venture capital operation, sometimes called Project 863, which offers money for Chinese entrepreneurs who will turn the stolen technology into something real. No questions asked. If you can get back to China with the secrets you are home free and potentially very rich.\nBut there are some legal problems. When the Chinese steal some technology, and produce something that the Western victims can prove was stolen (via patents and prior use of the technology), legal action can make it impossible, or very difficult, to sell anything using the stolen tech outside of China. For that reason the Chinese like to steal military technology. This kind of stuff rarely leaves China. And in some cases, like manufacturing technology, there's an advantage to not selling it outside of China. Because China is still a communist dictatorship the courts do as they are told and they are rarely told to honor foreign patent claims. That, however, is beginning to change, as more Chinese firms patent new ideas and are demanding protection inside China and overseas. This, more than anything else, will reduce Chinese technology theft.", "label": 1}
{"text": "The CAN-SPAM Act in the US was created over eight years ago in response to the increasing amount of email spam that people were receiving in their inboxes. However, in spite of the efforts of the government and lawmakers to make it easily understood for everyone, there still is confusion over what exactly does the CAN-SPAM Act does or doesn’t do.\nThe US CAN-SPAM Act was created to stem the flow of unsolicited bulk email or spam as a form of commercial advertising, thereby trying to prevent the abuse of email addresses by shady online marketers. Congress passed the law in 2003 after much debate, becoming effective on January 1, 2004.\nIn creating the law, Congress has set out basic guidelines for email marketers to follow:\n1. Email marketers should not mislead recipients as to the source or content an email\n2. People should be allowed to decline or unsubscribe from any email message from any source.\nHowever, the CAN-SPAM Act does not restrict any business from sending an unsolicited email to another company for business purposes. However, it does mention that if a person wants to opt-out of receiving emails from a particular company, the business must comply. Other guidelines are:\n· Any unsolicited messages must not have misleading subject headings.\n· All emails must have an unsubscribe or opt-out link that is valid for 30 days after the email is sent. If the receiver wants to opt-out, you have 10 days to comply with that demand.\n· All ads must be identified as commercial advertisements in the email.\n· Every advertising email that you send out, must have a physical mailing address clearly marked in the email.\n· You cannot sell or share email addresses of people who have unsubscribed from your list.\nIn Canada, the Personal Information Protection and Electronic Documents Act (PIPEDA) governs email marketing practices in the country. Enacted in 2004, the PIPEDA is different from the CAN-SPAM act in that it governs how personal information is distributed and managed online. In brief, it states that:\n· Emails marketers must obtain permission from the recipient when collecting their personal information and must be kept secure once collected.\n· Any data collected cannot be shared or sold to another party without express permission of the recipient.\n· A double-opt in signup method is required for Canadian residents.\n· You are liable for any data collected and stored. If there is a data breach, you will be at risk for any damages occurred.\n· Like the CAN-SPAM act, you must have an unsubscribe link in your email clearly indicated.\nFor the typical B2B marketer, these regulations were not meant to be present a challenge. The purpose of both the CAN-SPAM and PIPEDA was to protect the consumer from any scams or phishing attacks that are commonly found in B2C campaigns. As long as marketers observe the regulations set out by both countries, there should be no problem in sending out emails.", "label": 1}
{"text": "At ICANN’s meeting in Egypt last week, I had the opportunity to try and explain to various non-technical audiences why the Domain Name System (DNS) is vulnerable to attack, and why that is important, without needing a computer science degree to understand it. Here is the summary.\nHow does the DNS work?\nThe DNS can be considered to be a question-and-answer system. When you type in an address like “icann.org” into a web browser, your computer needs to turn that into a numeric address of the computer hosting that website. To do this, it sends a question over the Internet to a DNS server “Where is icann.org?” The DNS server sends back an answer, “The address is 192.0.2.0”.\nHow do you attack the DNS?\nLet’s say I want to execute an attack on this question and answer exchange, in order to convince the computer to go to the wrong address. When the computer I wish to attack asks a question, my goal is to provide a fake response back to that computer quicker than the real server comes back with the response. By getting my forged answer back faster, the computer will proceed using my answer, rather than the official one.\nSo, if I send back a fake address to a computer, I can get that computer to go to a different address than the one intended. For example, on that address I might have set up a fake website intended to take someone’s sensitive data, like a replica of a bank’s website.\nIf I manage to attack one computer why is that a big deal?\nA successful attack on one computer in isolation can be problematic for the user of that computer, but it is not that interesting to an attacker to succeed against only one person. Unlucky for us, just one successful attack can very easily have wider consequences. Let me explain.\nThe DNS is made much more efficient by the use of “caching” name servers. These name servers sit at ISPs, or on corporate networks, and perform DNS lookups on behalf of customers. It then stores the answers it receives in a cache, so for future lookups for the same domain it does not repeat the lookup – it just remembers the previous answer.\nThis means that if you execute an attack and it gets stored in a cache, it can actually impact many people over and over again, because that answer will be redistributed to everyone that uses that same caching server.\nThis is why this type of attack is usually called a “cache poisoning” attack, because by poisoning the cache with the wrong data, it creates a much more serious problem.\nSo I just send back an answer quicker, and that’s it?\nIt is not quite as simple as just sending a quicker answer back to a computer, you also have to guess certain attributes correctly on the answer that match the question. For example, your answer needs to go back to the same computer the question originated. You also need match the question that was being asked in your answer.\nIt is simple, however, to guess most of the attributes. As you know which computer you are trying to attack, you don’t need to guess that. As you know which domain you are trying to impersonate, that is also a given. Conventionally, there are only two variables. One variable is you need to guess which server the answer is coming from. The average domain on the Internet has around two or three name servers, only one of which will respond to any given query. Therefore you have about a one in three chance of guessing that correctly. The second variable is a unique reference number (formally, a “transaction ID”), that has about 65000 possibilities. Therefore you have about a 1 in 65000 chance of guessing that correctly.\nEarlier this year, security researcher Dan Kaminsky found that it is devastatingly simple to exhaust all those possibilities in a very short amount of time by performing an attack in a certain way. How short? Well, British DNS researcher John Dickinson did some tests and found that on average he could successfully attack a server in just 1.3 seconds.\nHow do you fix the problem?\nThe sad news is there is no real solution as far as the regular DNS is concerned. It is not like a security hole in a piece of software that can be repaired with an update. This is an architectural flaw in the DNS protocol itself. There are patches for DNS software, but these only attempt to make executing an attack more difficult, they don’t solve the problem.\nSome of the short term approaches to make attacks more difficult are as follows:\n- Randomise the “source port”. One of the attributes in the packet that an attacker needs to guess is called the port number. For architectural reasons, this needs to be port 53 on the way to the server — this is how the server realises it is a DNS query as opposed to a different type of query. However, the port number that a response is sent back to doesn’t need to be port 53. By randomising this, you make it harder for an attacker to guess. Much of the software updates to this problem in mid-2008 related to adding source port randomisation.\n- Block open recursive name service. If you provide access to a caching name server to the whole Internet, then it is very easy for the whole Internet to execute an attack against your server. If you limit access to just those who need it (i.e. your local network), then you reduce that risk.\n- Experimentation with capitalisation of domains. Domains in practice are not case sensitive – if you type ICANN.ORG or icann.org, it means the same thing. However, inside the DNS protocol itself, the encoded transmission between computers actually is case sensitive. This property can be used to add some more randomness to transmissions. If my computer sends off a question asking about “iCaNn.OrG” and gets back an answer for “icann.org”, it can throw it away as untrustworthy. This approach is still experimental and being discussed.\nThe net effect of these attempts to reduce the risk of attacks primarily involve adding more randomness for the attacker to guess. These approaches approximately double the number of “bits” of randomness. To be clear though, they only make an attack harder, but an attack is still viable. Furthermore, we know that both network speeds and computer speeds get faster and faster each year. These are the two things that slow down an attacker. Therefore, we know that successful attacks will just be easier and easier into the future.\nIf there is no short term solution, what is the long term solution?\nWhile the DNS itself can’t be properly fixed for the security problem, a new protocol that overlays the DNS called DNSSEC does. DNSSEC uses a system of certification to show that a DNS answer has not been modified. If someone tries to execute an attack, the certificate won’t validate, and the incorrect answer will be thrown away.\nDNSSEC is difficult to deploy. It requires upgrades in DNS servers, it changes the way domain name holders manage their name servers, and it adds extra complexity. However, with the knowledge that DNS attacks are so simple to execute without it, there is growing consensus that the pain it will take to deploy is less than the pain of a DNS that you can no longer trust.\nYou can view the presentation slides used in Cairo.", "label": 1}
{"text": "What was the motive behind the secret directive on cybersecurity?\nInformation recently was leaked to the press and quickly became public about a classified presidential policy directive, PPD-20, that was signed by President Obama just weeks before the presidential election. This is the latest leak of sensitive or classified information, and it has many people wondering if we have lost our ability to keep a secret.\nWhile details are scarce, the general consensus of experts and of the reporting community is that this executive order established the rules of engagement when it comes to cyberattacks on the United States. The directive is said to set forth a set of standards that are to be used as a guide for the response and operations of federal agencies to confronting cyber threats. Sources report that offensive and defensive cyber actions are defined in detail for the first time. Integral to these standards is a set of definitions and thresholds or lines for cyber conflict, which if crossed would constitute an act of war against the country.\nThis action came on the heels of several federal executives warning of the implications of a successful cyberattack on the nation’s critical infrastructure. When you look at these recent comments and warnings, together with the signing of PPD-20, it raises some interesting questions. For example, why in what was thought to be a very tight election would the president take this action and risk increased criticism that the White House is closed and acts on its own? Is the clock ticking? Are all the comments and warnings accidental, or are they part of a coordinated effort due to threat intelligence about a pending cyberattack? The answers to these questions are not known. Only time will provide those answers.\nPosted by Kevin Coleman on Nov 29, 2012 at 12:55 PM", "label": 1}
{"text": "Today's most talked about and perhaps the least understood buzzword, \"Cloud Computing\" is a metaphor for the delivery of computer power as a service via the Internet to anyone, anywhere who has access to a web browser on any kind of device. Clouds may be public, private or hybrid. The National Institute of Standards and Technology (NIST) defines a Cloud as \"a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources… that can be rapidly provisioned and released with minimal management effort or service provider interaction.\"***\nbodHOST is part of a worldwide group of companies in North America, Europe and Asia that is providing Cloud Computing to large corporations, government organizations and the SMB sector. We provide a secure Cloud environment for hosting your SAP and other ERP applications. Certification by SAP is underway and will be concluded shortly.\nA – All computer resources – such as, CPUs, memory, servers, hard disk storage, networking equipment, databases, firewall, anti-virus software, etc., and even applications software – are now available as a service and consumed like a utility (such as electricity). You use any or all of these only as and when required.\nB – The computational power is highly scalable (up or down) – hence elastic.\nC – There is nothing ever to buy. No CAPEX (Capital Expenditure). No hardware specs and prices to agonize over. All equipment is owned and operated by the Cloud Hosting provider.\nD – Bye-bye obsolescence. Since you own nothing, you have to replace nothing and incur cost for nothing.\nE – Cloud services are priced on the utility model. When your lights are off, your electricity meter comes to a halt. You may only for the wattage you consume. The same is true for Clouds. You will be billed per minute, and you pay only for services you consume.\nF – All software hosted in the Cloud is accessible anytime, anywhere – as long as there is Internet connection. (Well, broadband Internet connection, actually – which is almost like saying \"at least a 1000-cc car\".)\nG – Since access to the Cloud is via the Internet, any device that can access the Internet can access the Cloud. So in one fell swoop, your software becomes available on every desktop, laptop, net book and tablet in the world. Edit Excel Sheet on an Android tablet without any \"Office look-alike\" app. How cool is that!\nH – In a Public Cloud, costs are optimized by hosting multiple tenants on the same cloud so that spare resources can be made available to whosoever needs it – thereby achieving economies of scale. Security is never compromised, and – in fact – in one sense enhanced, because resources are dynamically assigned to tenants, thereby making it virtually impossible for a human agent to deliberately walk up to your server and compromise it. Multi-tenancy reduces cost and does not compromise exclusive use of resources or security.\nI – The leading concern of those surveyed about outsourcing some IT to a cloud service provider is generally security (by a wide margin of 66 percent). In a Cloud, security can actually improve due to centralization of data, and increased security-focused resources, etc., and we are especially vigilant about retaining control over certain sensitive data, the water tight security for stored kernels. Additionally, we are guard against attacks targeting server, platform, and data center infrastructure assets; hackers seeking to gain control of software assets; attacks targeting end points (notebooks, devices); attacks targeting networks (denial of services, distributed denial of service); and, root-kit attacks at the hypervisor or below on servers(BIOS and firmware)\nJ – The service is hosted somewhere on the Internet, with built-in redundancy for security, backup and recovery.\nK – The resources are virtualized (i.e., not pegged to any particular hardware at any point in time), and the technology allows servers and storage devices to be shared and utilization be increased. As a result, applications can be easily migrated from one physical server to another.\nL – The Cloud Hosting company owns all equipment. Only the application software is generally yours.\n*** Mell and Grance, \"The NIST Definition of Cloud Computing,\" National Institute of Standards and Technology, Information Technology Laboratory.", "label": 1}
{"text": "Experts: Drones basis for new global arms race\nThe success of U.S. drones in Iraq and Afghanistan has triggered a global arms race, raising concerns the remotely piloted aircraft could fall into unfriendly hands, military experts say.\nThe number of countries that have acquired or developed drones expanded to more than 75, up from about 40 in 2005, according to the Government Accountability Office, the investigative arm of Congress. Iran and China are among the countries that have fielded their own systems.\n\"People have seen the successes we've had,\" said Lt. Gen. Larry James, the Air Force's deputy chief of staff for intelligence, surveillance and reconnaissance.\nThe U.S. military has used drones extensively in Afghanistan, primarily to watch over enemy targets. Armed drones have been used to target terrorist leaders with missiles that are fired from miles away.\nThe United States is years ahead of the world in the technology of drones. Israel is also a leader in developing the unmanned aircraft.\nAmerican drones are equipped with sophisticated sensors and linked to a global network that allows their video feeds to be monitored from anywhere. Armed drones fire the latest in precision guided missiles.\nBuilding an unmanned aircraft is only part of what is needed for a successful drone program.\n\"Just because you can build a remotely piloted aircraft doesn't mean you can put all this together and do something with it,\" James said.\nAnalysts warn that even a less-sophisticated drone can be dangerous. Such drones can be equipped with chemical or biological weapons or be used to provide intelligence about the location of American forces.\nThe GAO reports it is likely that foreign countries have used drones to spy on U.S. military activities overseas. The report did not provide specifics. \"Even the less sophisticated technologies can provide useful tactical battlefield intelligence,\" said Thomas Melito, a GAO official.\nIsraeli aircraft recently shot down an Iranian-made drone launched by Hezbollah that had penetrated Israeli airspace. Hezbollah is a U.S.-designated terror group supported by Iran that has fought wars with Israel and carried out attacks on U.S. personnel.\nPakistan is attempting to acquire an armed-drone system, apparently with help from China, according to IHS Jane's, a security research firm.\nCountries may be able to narrow the technology gap over the course of years. \"We are dramatically ahead today, but people will look and learn,\" James said. \"Over time, they will build capacity.\"\nThe U.S. State Department and Defense Department control exports of U.S. drone technology and equipment, and the United States has rejected requests from a growing number of countries seeking drone technology. Israel has sold drone equipment to India, Russia and Georgia, according to the GAO.\nSome analysts contend that nations seek the drones as much for the clout they bring as any military utility they provide, since few countries have the sophisticated sensors or precision weapons that the United States employs.\n\"It's a prestige thing,\" said Micah Zenko, an analyst at the Council on Foreign Relations. \"It doesn't provide you with much additional combat capability.\"", "label": 1}
{"text": "Hardware hackers defeat quantum crypto\nTripping the light fantastic\nSecurity researchers using hardware hacking techniques have unearthed generic flaws in supposedly ultra-secure quantum cryptography systems.\nThe security of quantum cryptography hinges on using the fundamental properties of quantum physics for quantum key exchange. Any attempts to monitor this exchange would inevitably be detected as increased noise on the line and an abandoned data exchange. That principle remains solid and the attack, like others before it, relies on exploiting implementation flaws.\nThis particular crypto-busting technique, which uses off-the-shelf but expensive hardware, relies on remotely manipulating a photon detector at the receiver's end of a supposedly secure link. Commercial systems from MagiQ Technology's QPN 5505 and ID Quantique Clavis2 systems were demonstrated as potentially vulnerable by a team of computer scientists from Norway and Germany.\nResearchers from Norwegian University of Science and Technology (NTNU), the University of Erlangen-Nürnberg and the Max Planck Institute for the Science of Light in Erlangen are working with manufacturers to develop countermeasures. The loophole - which relies on specially tailored bright illumination - is likely to be common in most QKD systems using avalanche photodiodes to detect single photons, the researchers warn.\n“Unlike previously published attempts, this attack is implementable with current off-the-shelf components,” explained Dr Vadim Makarov, a researcher in the Quantum Hacking group at NTNU. “Our eavesdropping method worked both against MagiQ Technology's QPN 5505 and ID Quantique Clavis2 systems.”\nThe hack pulled off by the team is complex and might involve an initial outlay of $50,000 or more, potentially within the reach of industrial spies and certainly in the scope of intelligence agencies.\nQuantum key distribution systems became commercially available around five or six years ago and are used for the secure exchange of highly sensitive material by banks and governments, so a major up-front investment in equipment and expertise is certainly possible.\nThe researchers have published their preliminary findings in a letter to the August 29 edition of academic journal Nature Photonics.\nAn overview of the research, together with pictures of the hacking rig, can be found here. ®\nuh... lab only?\nWhat do you mean lab only? Had you head of quantum encryption in banking before today? Several of the world's major banks employ quantum crypto for sensitive transactions *right now*. There's good money in being able to supply entangled pairs for the crypto required, and showing that the security offered through them is only worth $50,000 means these institutions now have a problem they need to deal with immediately.\nCongratulations, no boffins.\nNo such thing as secure\nJust stuff that hasn't been cracked yet.", "label": 1}
{"text": "Everybody has secrets. In the computer world, secrets range from a simple password to an entire hard drive full of confidential information.\nOf course, there are many ways to protect your secrets in cyberspace. You can use password managers, secure connections, hidden partitions and many other methods to protect them from prying eyes.\nThe problem with most of these methods is that they use encryption to safeguard your data. Encryption like AES is very difficult to crack, but not impossible.\nA better approach to protect your secrets is to hide them. If you make your secrets invisible to anyone but yourself, you don’t even need encryption.\nUnbelievably, you don’t need expensive software or complex technical knowledge to make passwords or any kind of text invisible.\nIn fact, if you use Windows, you already have the means inside your computer. All you need to hide any text inside regular files is to download a free application and use the NTFS file system.\nWindows uses alternative data streams to store thumbnails and other meta-data. Data streams exist only in the NTFS file system and were originally conceived to allow compatibility with Apple computers.\nBy using a free application called Streams Viewer, you can detect and even create your own hidden streams in any file.\nStreams Viewer allows you to attach a secret text message to the end of the stream. This works with any type of file, regardless of extension, and it does not change the file in any way.\nThe information in the stream cannot be detected by any other Windows applications such as Windows Explorer or even through the command line interface. This allows you to open an inconspicuous file, create your own streams and send it through email or post it on the internet without fear that someone will see your secret message.\nAlternative data streams also pose a dangerous security risk. Hackers frequently use hidden streams, as it allows them to get an anonymous foothold in a network. Streams Viewer allows you to detect and delete hidden streams already present on your computer.\nHere are the steps necessary to view and create your own hidden data streams.\nFirst, open your browser and visit http://www.pdfforge.org/other-projects\nThen, scroll to the bottom of the page, locate the Streams Viewer section and click on the StreamsViewer-4_0_2.exe (2 MB) link.\nSave the .exe file to your desktop or any other folder on your hard drive and double-click to open it.\nIf you get an Open File – Security Warning, click on Run to give Windows permission to start the installation.\nThis opens up the installer program. Click on Next to continue.\nIn the License Agreement window, select the I accept the agreement option and click on Next to continue.\nIn the next window, click Browse to install Stream Viewer in a different location on your hard drive or click on Next to continue.\nAgain, in the next two steps, click on Next to continue.\nThen, click on Install to start the installation process.\nLater, when the install process is complete, click on Finish to open the program automatically. If it does not open, double-click the Streams Viewer desktop shortcut to open it.\nTo start a search for hidden streams, click on the Search button located on the top left corner of the program.\nThen, in the Search alternative streams window, click the … (browse) button.\nNext, select the partition to search (ex: C and click on OK.\nCheck the Recursive box and click on Start to begin searching.\nAfter the search is over you will see all the data streams on that hard drive partition in the results table. Repeat the steps above for each hard drive partition you have.\nYou can double-click each item in the results table to open it or click the Save button to save the list as a .csv file (you can open it with Microsoft Excel).\nIf you want to remove the hidden data stream without deleting the file, double-click the file in the results table, go to the Alternative streams section of the program and click on the Remove button.\nNow, to create your own hidden data stream, go to the Folder and files section (on the left) and select a file to use. It can be any kind of file, although for best results you should use common files like wav, mp3, jpg, doc or txt.\nWarning! Do not use an important file for this operation as modifying the data stream may corrupt the file or cause it to behave unexpectedly.\nWith the file selected, click on the Add button, located in the Alternative streams section. Browse your computer for the same file, select it and click on Open.\nYou should now see garbled text in the Text/Hex section of the program.\nUse the scroll bar on the right of the text box and scroll down to the end of the box. Click at the end of the last line of garbled text and press Enter from the keyboard.\nNow you can type in your secret message or password. It can be as long as you want, but you cannot use copy/paste from another file, you have to type it in by hand.\nBe careful not to delete or modify any of the garbled text. If you do, the file might be corrupted.\nThen, click the Update stream button, located below the text box. This will update the data stream to include your latest modification.\nLastly, click on the Save in file button, located in the Alternative streams section.\nAgain, browse through your computer for the same file, select it and click on Save. It will ask you to replace your original file with the file containing your secret message. Click on Yes to save your modified file.\nYou can then exit the application and look at the file you modified in Windows Explorer. As you can see, the file still has the same size and is fully functional. If you notice the file has no thumbnail, open it and it will revert to normal.\nTo view the secret message inside the file, use the search process detailed a few steps back, double-click the file from the list and scroll down to the end of the text box.", "label": 1}
{"text": "What is Encryption?\nEncryption is a process by which we use software to scramble sensitive information while it is in transit to Dell.\nPlease take a moment to read about the steps that we have taken to help protect your information and make your online transmissions safer. We also invite you to review the steps you can take to help protect yourself further.\nHow Does Encryption Work?\nEncryption is based on a key that has two different parts. The public part and the private part. The public part of the key is distributed to those you want to communicate with. The private part is for the recipient's use only.\nWhen you send personal information to dell.com, you use Dell's public key to encrypt your personal information. That means, if at any point during the transmission your information is intercepted, it is scrambled and very difficult to decrypt. Once Dell receives your encrypted personal information, we use the private part of our key to decode it.\nWhat Kind of Encryption Software Does Dell Use?\nDell currently uses the industry-standard SSL (Secure Sockets Layer) encryption. But we continue to keep up with the current technologies in an effort to protect the security of your information.\nWhat Information Does Dell Encrypt?\nDell encrypts all personal information you give us when you place an order online. Remember, if you feel uncomfortable providing any of this information online, please feel free to call one of our representatives at 1-800-WWW-DELL.\nHow Safe is Encryption Really?\nProviding encrypted information online is as safe as doing it over the phone.", "label": 1}
{"text": "Many states are using the technology to scan driver’s licenses to prevent identity fraud. It led to the arrest of a suspected arsonist in New York. And while facial recognition technology\ncould not identify the Boston Marathon bombing suspects, police used the software in their search. These recent headlines illustrate the benefits this technology provides for law enforcement agencies in an investigation. Not surprisingly, many businesses also see an advantage in using facial recognition, not for crime-fighting, but to reach customers. However, Brian Mennecke, an associate professor of information systems at Iowa State University, questions whether customers are ready for it.\nPITTSBURGH-Researchers previously have shown that a depth camera system, such as Kinect, can be combined with a projector to turn almost any surface into a touchscreen. But now researchers at Carnegie Mellon University have demonstrated how these touch-based interfaces can be created almost at will\n, with the wave of a hand.\nA transparent computer that allows users to 'reach inside' and 'touch' digital content\nhas been unveiled at the TED conference in LA. Jinha Lee has been working on the SpaceTop 3D desktop in collaboration with Microsoft.\nA 3D printing technique that produces clusters of stem cells\ncould speed up progress towards creating artificial organs, Edinburgh scientists have claimed.\nCheap sensors that help cars avoid collisions could emerge from research into a lens-less imaging system\n. US scientists have used metamaterials to build the imaging system, which samples infra-red and microwave light.\nRugby Football Union is going to trial a 'ref-cam' during the televised chapionship game between Newcastle Falcons and London Scottish this Sunday. It will offer a new perspective for viewers, who can already hear the ref via a microphone, and will provide an additional tool which can be utilised within the development of referees.", "label": 1}
{"text": "What are the different wireless network security methods?\nIf you plan to have a wireless network, you should set it up so that only people you choose can access it. Here are a few options for wireless network security.\nWi‑Fi Protected Access encrypts information and makes sure that the network security key has not been modified. Wi‑Fi Protected Access also authenticates users to help ensure that only authorized people can access the network.\nThere are two types of WPA authentication: WPA and WPA2. WPA is designed to work with all wireless network adapters, but it might not work with older routers or access points. WPA2 is more secure than WPA, but it will not work with some older network adapters. WPA is designed to be used with an 802.1X authentication server, which distributes different keys to each user. This is referred to as WPA-Enterprise or WPA2-Enterprise. It can also be used in a pre-shared key (PSK) mode, where every user is given the same passphrase. This is referred to as WPA-Personal or WPA2-Personal.\nWEP is an older network security method that's still available to support older devices, but it's no longer recommended. When you enable WEP, you set up a network security key. This key encrypts the information that one computer sends to another computer across your network. However, WEP security is relatively easy to crack.\nWe recommend using WPA2, if possible. We don't recommend using WEP. WPA or WPA2 are more secure. If you try WPA or WPA2 and they don't work, we recommend that you upgrade your network adapter to one that works with WPA or WPA2.\n802.1X authentication can help enhance security for 802.11 wireless networks and wired Ethernet networks. 802.1X uses an authentication server to validate users and provide network access. On wireless networks, 802.1X can work with WPA, WPA2, or WEP keys. This type of authentication is typically used when connecting to a workplace network.", "label": 1}
{"text": "Following the outbreak of chikungunya in the Indian Ocean, the Ministry of Health directed the necessary development of an early outbreak detection system. A disease surveillance team including the Institut Pasteur in Madagascar (IPM) was organized to establish a sentinel syndromic-based surveillance system. The system, which was set up in March 2007, transmits patient data on a daily basis from the various voluntary general practitioners throughout the six provinces of the country to the IPM. We describe the challenges and steps involved in developing a sentinel surveillance system and the well-timed information it provides for improving public health decision-making.\nSurveillance was based on data collected from sentinel general practitioners (SGP). The SGPs report the sex, age, visit date and time, and symptoms of each new patient weekly, using forms addressed to the management team. However, the system is original in that SGPs also report data at least once a day, from Monday to Friday (number of fever cases, rapid test confirmed malaria, influenza, arboviral syndromes or diarrhoeal disease), by cellular telephone (encrypted message SMS). Information can also be validated by the management team, by mobile phone. This data transmission costs 120 ariary per day, less than US$1 per month.\nIn 2008, the sentinel surveillance system included 13 health centers, and identified 5 outbreaks. Of the 218,849 visits to SGPs, 12.2% were related to fever syndromes. Of these 26,669 fever cases, 12.3% were related to Dengue-like fever, 11.1% to Influenza-like illness and 9.7% to malaria cases confirmed by a specific rapid diagnostic test.\nThe sentinel surveillance system represents the first nationwide real-time-like surveillance system ever established in Madagascar. Our findings should encourage other African countries to develop their own syndromic surveillance systems.\nPrompt detection of an outbreak of infectious disease may lead to control measures that limit its impact and help prevent future outbreaks.\nWith the increase in international travel, infectious disease control is gaining a greater importance across regional borders . Adequate surveillance systems are crucial for preventing the global spread of infectious disease . Real-time syndrome-based surveillance provides the quickest way of identifying several diseases; thus, it is the best way of focusing the appropriate response measures to any outbreak scenario and to help identify specific etiologies .\nUntil March 2007, Malagasy surveillance system was only based on passive approach. Each primary health center reported monthly activities and diseases on a simple paper form. In the absence of diagnostic laboratories in most regions, the ability to confirm diagnosis remains low. Likewise, outbreaks must be notified using a forward stepwise approach involving each health system level, but that approach tends to be too slow for an adequate and efficient response. In fact, healthcare information systems have been driven mainly by the need to report aggregate statistics to Ministry of Health (MoH).\nIn March 2007, following the Indian Ocean chikungunya outbreak [4,5], which highlighted the absence of an efficient surveillance system in Madagascar and drew attention to the necessary improvement of systems for the early detection of outbreaks, the Malagasy MoH, with the support of the Institut Pasteur in Madagascar (IPM), set up a sentinel surveillance system based on daily data collection. The aim was to allow the rapid detection of an epidemic and to identify circulating arboviruses.\nIn general, viral surveillance does not allow normal viral circulation to be distinguished from a potential epidemic situation. Actually, the essential elements needed to plan for the prevention and control of epidemics cannot be obtained from a system based on virus surveillance alone, but requires a system based on both viral and clinical surveillance.\nPrompt recognition of disease outbreaks and rapid diagnosis may permit prophylactic measures being introduced to decrease morbidity and mortality. However, the window of opportunity is short. This highlights the need for a rapid surveillance system that does not depend on confirmed diagnoses, but rather the detection of aberrant patterns. In focusing the appropriate outbreak response measures and helping to identify specific etiologies, syndrome-based real-time surveillance provides the quickest way of recognizing and responding to several disease outbreak scenarios [6-8].\nThe sentinel surveillance system in Madagascar was initiated to provide information using health service-based indicators and to alert health officials to changes in fever frequency during fever-associated diagnoses and changes in diarrheal frequency.\nWe aimed to describe the essential components of the Madagascar sentinel surveillance information system, and its results after one year.\nThe surveillance uses health service-based indicators, and mostly focuses on fever syndromes. Since January 1, 2008, diarrhea has also been included as an indicator. Four sentinel primary health centers located in coastal cities with high population densities were also implemented with arbovirus surveillance.\nThe first step in creating the sentinel fever network was to identify the appropriate stakeholders. The development team within the MoH and the IPM consisted of epidemiologists, virologists and managers of SSUREPI (epidemiological surveillance service, MoH) and SLMER (the service against emerging and re-emerging diseases, MoH). Next, immediate external stakeholders, including the regional health department and district managers, were brought into the discussion to identify potential sentinel centers.\nSentinel primary health care centers\nAs Madagascar is a large island and have different climate patterns, implementation of the sentinel centers were carried to give geographical representativity and to provide best information about the trends in each of these climate areas. A sentinel center was selected based on several criteria, including the number of general practitioners (at last two by center), care level (activities, number of people that visit the center, equipments), communication facilities (mobile phone network availability) and motivation (voluntary participation) for the surveillance activity. The sentinel general practitioners, recruited on a voluntary and unpaid basis, are the backbone of this system. The centers numbered 13 on December 2008 and may increase to 20 over the next few months (figure 1).\nFigure 1. Surrounding Climate and Location of the Health Centers that participated in the Sentinel Surveillance System in Madagascar.\nSurveillance was based on data collected from sentinel general practitioners (SGP). Each participating SGP reported the number of cases that met the criteria, including the total number of patient visits on each reporting day. SGPs were expected to communicate encrypted data via cellular telephone (encrypted SMS) at least once a day, from Monday to Friday, despite occasional clinic closures resulting from routine weekday-weekend schedules. If data from a sentinel center was not received by 08:00 a.m., the IPM staff member contacted the sentinel center to obtain the missing data.\nThe cost of data transmission was 120 ariary per day, less than 1 $ per month. Considering the lack of effective communication systems and money in Madagascar, the management team had to devise an efficient and cheap means of reporting data on a daily basis.\nThe sentinel surveillance system in Madagascar was based on clinical pre-diagnostic data. Fever (criteria for inclusion were an axillary temperature of more than 37.5°Celsius) was the first symptom targeted. Three illnesses in relation with fever were selected for surveillance: malaria confirmed cases (criteria for inclusion were fever with a positive result in the rapid diagnostic test); influenza-like illness (defined as fever with cough and sore throat); arbovirus (criteria for inclusion were fever without respiratory symptom and at least two other symptoms: headache, arthralgia, myalgia-like backache, skin rash, retro-orbital pain, haemorrhagic manifestations). Diarrheal disease was defined as 3 or more abnormally loose stools during the previous 48 hours. For each fever syndrome, a malaria rapid diagnostic test have to be performed using the CareStart™ Malaria kit provided by the malaria national program.\nFurthermore, SGPs reported the sex, age, date and time of visit, and listed the chief complaint or symptoms for each new case via a paper form addressed to the IPM on a weekly basis. IPM staff were able to validate any information via mobile phone. However the notification was anonymous. The exchange between SGPs and IPM staff used only forms identification number. Data collection on a daily basis began in March 2007 and collection is ongoing. In terms of real-time surveillance, we are increasing the data entry and data transfer speed, with the aim of receiving most of the data within a 24-hour period. The data obtained daily from the SMS were entered into the Access® database.\nData were available for analysis shortly after the patient's initial visit. Data from all 13 primary health centers were evaluated for variation on a daily basis. A medical epidemiologist reviewed the output on a daily basis, and noted any changes to community-wide incidences of fever. Separate analyses were carried out for each syndrome category of interest, to look for temporal distribution increases at each sentinel center.\nWe estimated the proportion of all fever cases corresponding to each febrile syndrome at each sentinel center; we also estimated the proportion of all fever or diarrhea cases that were primary case encounters.\nSo, various health service-based indicators were monitored daily; these included the percentage of fever cases, confirmed malaria cases, influenza-like illness cases, arbovirus suspected cases, and the number of cases with diarrhea and diarrhea with fever.\nSurveillance data analysis was descriptive and straightforward using standard epidemiological techniques. Data were presented in the form of tables and graphs, and included the number of cases relating to each event (figure 2). Data were organized using statistical programs, which analyzed the daily and weekly graph values of various indicators, thus obtaining a baseline pattern for each syndrome in Madagascar.\nFigure 2. Daily visit counts in the sentinel surveillance system in Madagascar and the moving average (over 5 days) for daily visit counts, April 10, 2007 - December 31, 2008.\nToday, fluctuations in values in a sentinel center can be monitored on a daily basis, and increases can be detected through data analysis. Increases are reported immediately by telephone to SLMER and SSUREPI, to monitor events and to decide on whether to initiate an outbreak investigation.\nAbility to detect outbreaks\nThe sentinel surveillance system was able to detect peaks in the plots relating to febrile syndromes, including which disease among arbovirosis, influenza and malaria was the most probable cause. Without baseline levels, fluctuations were monitored daily, but the identification of aberrations was empirical and based on peak detection alone. Each increase was reported immediately by phone to regional health officials, and public health officials at the Ministry of Health. These district managers assisted with the interpretation and follow-up of aberrations in their perspective regions.\nFurther investigations were carried out if a change was detected. The first step in any outbreak investigation is to verify the signals, as the use of text message strings, to identify affected patients, may result in inclusion of patients whose main medical complaints are unrelated.\nThe study was approved by the Ministry of Health and the National Ethics Committee of Madagascar.\nImplementation of the sentinel surveillance network\nThe surveillance network consisted of 13 centers in December 2008, which will increase to 20 by the end of 2009 (figure 1). During the planning phase, the advantages of sentinel surveillance were explained not only to public health officials but also to medical staff at participating health centers. Public health officials tended to prefer a weekly surveillance system, but daily transmission was easier for SGPs. More than three health centers in each sentinel town were contacted before the best center was chosen.\nOverview of the data - characteristics of the data on sentinel visits in Madagascar\nData, collected on a daily basis between April 1, 2007 and December 31, 2008 from the 13 sentinel centers and stored in the database, corresponded to 218,849 visits. Data was transmitted within 24 h in 89% of cases. The age distribution according to the overall number of visits and febrile syndromes are listed (Table 1).\nTable 1. Distribution of overall visits and fever-related illnesses according to the age group.\nA total of 26,669 cases (12.2%) presented a fever syndrome; a specific sheet was completed for 24,862 of these patients (93.2%). The sex ratio (male/female) for those with fever syndrome was 0.87. The age was available for 21,189 patients (85.2%), and the mean age was 14 years (CI95%: [13.8-14.2]).\nConfirmed Malaria accounted for 9.7% of the overall number of fever-related illnesses, Flu-like syndromes accounted for 11.1% and Dengue-like syndromes accounted for 12.3%.\nUnderstanding the characteristics and patterns of the number of visits over a period of time using this surveillance system in Madagascar was necessary before the appropriate threshold levels for various syndrome groups could be implemented for outbreak detection.\nPatterns of the Syndrome Groups\nTo understand the epidemiological characteristics of groups with fever-related syndromes or those with rapid diagnostic test (RDT)-confirmed cases of malaria under the sentinel surveillance system, data of their daily counts were plotted on a graph (Figure 2 and 3, respectively). Daily and weekly counts as a function of the regional pattern were also plotted and analyzed for each sentinel center. Analysis of the weekly trends showed that the number of people visiting was greater on Monday (p < 0.001) than on any other day, probably related to the weekend closure effect. Figure 2 showed 2 peaks for daily visits count on January and November 2008 in relation with an increasing of fever syndrome on January (Figure 3).\nFigure 3. Daily Sentinel surveillance time series plots (%) of total visits of fever and of total fever of the 3 syndrome groups and the moving average Apr. 10, 2007 - Dec. 31, 2008.\nThe plots for global visits and fever-related visits were quite similar with a high correlation (R = 0.88). However, diarrheal syndrome was not highly correlated with global visits (R = 0.54).\nCorrelation between febrile syndrome and ILI syndrome (R = 0.73), febrile syndrome and dengue-like syndrome (R = 0.68) or febrile syndrome and confirmed cases of malaria (R = 0.72) was moderate.\nThe distribution of febrile and other syndromes in 2008 (figure 4) showed that arbovirosis was the dominant cause on the east coast, malaria was the dominant cause on the west coast and ILI was the dominant cause in a central strip between Morondava (West coast) and Farafangana (East coast).\nFigure 4. Fever syndromes and proportions of fever-related syndromes under sentinel surveillance based on data collected from sentinel centers in 2008.\nTen cases of fever clusters occurred between March 2007 and December 2008, which led to an investigation after contact with the district managers. They were not detected by traditional surveillance system. Laboratory investigation confirmed the clinical signals and identified the etiological agents. The sentinel surveillance system confirmed five outbreaks: two via an increase in the dengue-like syndrome ratio without an increase in the fever-related ratio, in one of the four virological sentinel centers that have reported chikungunya virus circulation; two with an increase in fever and ILI indicators (Influenza A H1N1 seasonal); and one with an increase in RDT-confirmed cases of malaria.\nSurveillance is fundamental to public health decision-making and subsequent action. Sustained and integrated global epidemiological surveillance has been weak in Madagascar, similar to that in other developing countries . Sentinel surveillance systems offer advantages over passive surveillance, which is known to have limitations due to incomplete reporting . The major objective of sentinel surveillance was to identify illness clusters early, before diagnoses are confirmed and reported to public health agencies, and to mobilize a rapid response, thereby reducing morbidity and mortality. To ensure efficiency and accuracy, sentinel systems require strong communication systems.\nGPs participated in sentinel surveillance on a voluntary basis; therefore, the system is not representative of the whole country. To ensure better representation, the number of participating GPs should be increased. On the all 1500 health care centers directed by an physician, only 13 were included in the network. However, it was also important to ensure that sentinel GPs are easily accessible to surveillance staff. All sentinel centers were located in urban areas where population density was higher and where outbreak impact should be very dramatic. They also had been chosen to give an estimate picture of the different climate trend of Madagascar. The estimated population covered by all sentinel sites is 500.000 inhabitant representing as of 2008 3% of the Malagasy population.\nSupervision of the surveillance system was carried out by MOH as planned. Stakeholders were made aware of the advantages and limitations of sentinel surveillance systems. Sentinel surveillance systems may enhance collaboration among health ministry services and health-care practitioners. However, they do not replace traditional public health surveillance, nor are they substitutes for direct medical analysis, in which the physician reports unusual or suspect cases of public health importance.\nEstablishing sentinel surveillance was a difficult process, even if it was less costly and used fewer resources than passive surveillance. The problem, among others, in establishing such a system involves connecting GPs to the sentinel system and coordinating their work. We selected mobile phone communication for daily reporting and paper forms for weekly reporting, increasing the human resources required to carry out this type of surveillance. In the future, with the increase in mobile communication in Madagascar, in particular that involving 3G internet, sentinel surveillance could be based on electronic records delivered directly from the practitioners.\nAlthough the cost of data transmission on a daily basis is minimal, at less than 1US$ per month per sentinel center, the costs and maintenance of the system require better quantification, both in terms of resources spent (time of the SGPs,...) and person-hours involved in responding to system alerts. Furthermore, the importance of malaria in Madagascar and other sub-Saharan countries requires that a rapid malarial test be linked to fever syndrome surveillance.\nThe mobile phone with its low cost and universal availability has been recognized as an important piece of communication technology in health care . However, published studies on using mobile phones are still limited  to countries where limited resources and remote locations are the main reasons for using mobile phone.\nSentinel surveillance systems seek to use existing health data in real time (daily) to provide immediate analysis and feedback to those charged with the investigation and follow-up of potential outbreaks. However, data relating to these various syndromes are nonspecific by nature. For illnesses that are self-limiting and of a short duration, resolving the causes of the syndrome is not usually of direct benefit to the patient, is not a priority for the clinician, and is not always feasible with current technology. The advantage of using syndromic data for outbreak detection is speed of response . Experiences to date indicate that this advantage may only be theoretical. The time required to conduct investigations and retrieve diagnostic and epidemiological information might negate the advantage of quick data acquisition. The absence of sustained syndromic signals usually provides greater reassurance that an outbreak does not exist than the information obtained by immediate investigation.\nThe rapidity of the system, although excellent compared with traditional surveillance systems, needs to be improved. This Malagasy sentinel surveillance system did detected fever outbreaks in areas where traditional surveillance system didn't. It also highlighted the difficulty in building epidemiological baselines without historical references.\nSystematic methods for determining the expected number of visits on a particular day require historical data to create baselines in trimmed-mean seasonal and autoregressive integrated moving average (ARIMA) models. Time series methods are an important tool to provide alarm thresholds. These forecasting models could produce results with good accuracy in their predictions of the data .\nA sentinel real-time-like surveillance system may be the key to the detection of and prompt reaction to any infectious disease outbreak. Although preliminary, the results showed the feasibility of implementing syndrome surveillance in a developing country at low cost, with good cooperation by SGPs (daily data transfer rate estimated to 89%) and a minimum of effort by staff. This is the first description of a sentinel surveillance system based on daily SMS reporting. We believe that this very simple system may provide an example to several other developing -- and even developed -- countries. Although the cost of data transmission was minimal, the cost and maintenance requirements of the system need to be better quantified, both in terms of resources spent and person-hours used to respond to system alerts. The time required to conduct investigations and retrieve diagnostic and epidemiological information might negate the advantage of timely data acquisition, especially in developing countries where the money for investigation can be difficult to find. For this reason, the Madagascar Ministry of Health has dedicated funds to outbreak investigation, in addition to those invested in the surveillance system.\nThe sentinel surveillance system is a key step in closing the gap that exists in the surveillance of disease in Madagascar. However efficient, this system cannot replace traditional surveillance, nor can it substitute for the direct reporting of unusual or suspect cases of public health importance by physicians. Epidemiological baselines for each center need to be determined, to help develop better statistical methods and sensible alarm thresholds, which can then be extended to more sentinel centers.\nOur findings should encourage other African countries to develop functional, patient-based sentinel surveillance systems, while discovering their inherent advantages and limitations.\nThe authors declare that they have no competing interests.\nRL was in charge of epidemiological data analysis, improvement of the Sentinel Surveillance System and manuscript writing. RY initiated the project for detecting outbreaks and participated in the task force. RL participated in the task force. ASF and HJM were in charge of biological surveillance. RM was in charge of epidemiological data analysis. RR and RSA participated in the task force. RV led the study and coordinated the data analysis manuscript writing, and participated in the task force.\nAll authors read and approved the final manuscript\nWe thank the GPs and staff of participating district. We thank also World Bank, Institut Pasteur de Madagascar, USAID for their financial support.\nLancet inf dis 2004, 4:171-177. Publisher Full Text\nPLoS Med 2006, 3:e263.\nEpub 2006 May 23PubMed Abstract | Publisher Full Text | PubMed Central Full Text\nThe pre-publication history for this paper can be accessed here:", "label": 1}
{"text": "Can Advanced Technologies Really Help Curb Highway Congestion?\nAccording to the Department of Transportation (DOT), congestion costs America an estimated $200 billion a year in lost travel time and fuel, and drivers in metropolitan areas spend more than one-quarter of their total annual travel time in congested conditions.\nIn a report out this week by congressional watchdogs at the Government Accountability Office noted that state and local governments have used technologies it calls Intelligent Transportation Systems (ITS) that consist of a range of communications, electronics and computer program to help manage congestion. But, while there's even more technology in the pipeline, state and local governments face many challenges in planning and funding ITS use, ensuring that staff and leaders have adequate knowledge of the technology, and coordinating ITS approaches to make the most effective use of such technologies.\nThe GAO spotlighted these emerging technologies which include:\n1.Traffic management applications: State and local governments within some metropolitan areas, such as Washington, D.C., are employing new traffic management applications that make use of data integrated from various, previously siloed databases. The objective of these approaches is to collect, manage, integrate, and apply real-time transportation data. Agencies integrate a variety of real-time information -- including incident information, travel time, and weather advisories -- obtained from various sources to manage the transportation system and provide relevant information to travelers. The expansion of real-time data collection technologies and coverage in recent years has allowed for greater use of these data in daily traffic operations. As one expert noted, data are the foundation of managing congestion, and the more and better quality the data, the better the tools that can be brought to bear on managing traffic. In addition to supporting a more active role in managing traffic, such data allow management agencies to provide real-time traffic advisories and support performance measurement, the GAO stated.\nCollection and integration of data -- such as traffic and emergency services data -- across jurisdictions can enhance incident management by allowing quick detection and response to incidents. For example, the I-95 Corridor Coalition makes vehicle probe data available to 19 agencies, which use the data to monitor traffic patterns across state boundaries and to respond to incidents and congestion. In 2009, the New York State Police used these vehicle probe data along with data from the New York 511 website to assist in managing holiday traffic congestion. This proactive approach to traffic management led to a 50% reduction in traffic queues over previous years.\nThe Regional Integrated Transportation Information System (RITIS) program in the Washington, D.C., area is an example of data integration that allows for improved traffic operations, incident management, and traveler information. RITIS is a system that compiles data across modes of transportation from agencies throughout the metropolitan area, including data on incidents, weather, managed lane status, signal status, and data from public safety computer-aided dispatch systems. RITIS then standardizes these data, and makes them available to participating agencies. Previously, many of the area transportation agencies had implemented stand-alone systems and relied on ad hoc communications that were driven by personal relationships between staff for coordination.\n2. Active traffic management: The proactive management of roadway capacity and transportation demand is the next step in congestion relief. In Seattle, the Washington State DOT has instituted active traffic management systems. These systems, which are among the few such systems in the country, use overhead signs that display changing speed limits and real-time traffic information for drivers over each lane. These signs automatically reduce speed limits to alert drivers to slow their vehicles when they approach congestion, collisions, or backups at off-ramps. The signs also alert drivers to upcoming lane closures because of traffic incidents or road work and direct them to open lanes. The system also includes message signs that alert drivers of downstream backups and signs that display estimated travel times, the GAO stated.\nAlthough a formal evaluation of the systems in Seattle is forthcoming, the government has reported that similar systems in Europe, depending on the location and the combination of strategies deployed, have resulted in increases in overall capacity ranging from 3 to 22 percent, increases in travel time reliability, and reductions in primary incidents ranging from 3 to 30 percent.\nTechnical advances now make it possible to move from relatively passive monitoring to proactive control of traffic through mechanisms like variable speed limits, congestion pricing, and ramp metering. Active transportation and demand management is a proactive approach for dynamic management and control of existing transportation infrastructure based on current traffic conditions using real-time data and information. This approach considers the real-time management of both supply and demand to prevent, delay, or minimize facility breakdown when travel demand exceeds system capacity.\nActive transportation management can also include managed lanes, in which officials control traffic lane use by granting access to only certain types of vehicles, such as high occupancy vehicles; controlling access, such as designing express lanes where access is restricted to a few points; or congestion pricing, where vehicles pay a toll to use the lane.\n3. Road pricing: Some say one strategy to reduce congestion is road pricing or congestion pricing -- assessing tolls that vary with the level of congestion and the time of day. This demand management strategy aims to improve the flow of traffic by motivating drivers to travel by other modes, such as carpools or transit, or by traveling at less congested times. For example, in Los Angeles, the California Department of Transportation and the Los Angeles County Metropolitan Transportation Authority are converting over 50 miles of freeway from High Occupancy Vehicle, or carpool, lanes, to High Occupancy Toll lanes. This is to allow use of excess capacity in the lanes by single occupancy vehicles for a price. Agencies have used electronic fare collection and traveler information ITS technologies to accomplish this conversion. Officials can also proactively manage traffic conditions through ramp metering, which can maintain smooth freeway flow by regulating vehicle entry at entrance ramps. DOT's 2010 deployment survey found that freeway agencies believe ramp control has high benefit, despite the fact that the technology is lightly deployed.\n4. Work zone technology: Work zone management is another emerging use of ITS applications to proactively manage traffic. Transportation agencies can use work zone management to reduce the congestion normally associated with construction activities such as lane closures. Agencies use ITS to mitigate the effects of lane closures, detours, and other factors. Examples of ITS technologies used in work zones include using electronic signs to control merging for lane closures and variable speed limit signs. Agencies also use traveler information ITS technologies to notify the public of road closures and work zone-related delays.\n5. Wireless everywhere: Connected vehicle technology, still under development, could significantly change traffic management, both in terms of the amount of traffic data transportation agencies will collect and in how agencies proactively manage traffic. DOT's current ITS research agenda focuses on the department's vision to provide the nation with a national, multimodal transportation system that features wireless communications among vehicles, infrastructure, and portable devices. The importance of data management and integration will continue given that connected vehicle technology has the potential to significantly increase the amount of transportation data available to state and local governments, the GAO stated.\nFollow Michael Cooney on Twitter: @nwwlayer8 and on Facebook.\nRead more about data center in Network World's Data Center section.", "label": 1}
{"text": "Protect your systems from these threats\nComputer viruses can infiltrate your system and send your data to criminals. It’s vital you employ the following measures:\n- Use anti-virus software - developed by a reputable supplier.\n- Update regularly - anti-virus software is only effective if it’s up-to-date.\n- Scan regularly - check all your computers and media for viruses. This includes all data storage devices coming from outside your business.\n- Use virus repair software with caution - you should only do this if you understand the virus characteristics and know that the correct repair is certain.\n- Ban unauthorized software - make sure staff only run approved code.\n- Keep checking - regularly review the software and data which supports your critical business processes.\n- Be suspicious - investigate the presence of unknown files or unauthorized amendments.\n- Virus check all e-mail attachments - they are a common source of infection Virus check downloaded software – viruses can be inserted into files on the internet and other external networks.\n- Know how to react - set up procedures and responsibilities for reporting and recovering from virus attacks. You should also set up business continuity plans, including data and software back-up and recovery.\n- Patch your software - make sure you do this regularly, to make sure your system benefits from the latest protection.\n- Test everything - make sure your security systems and procedures actually work, especially your backups.\n- Install and maintain a network firewall - if the system can access the internet.\n- Use encryption - for data sent across networks.", "label": 1}
{"text": "If you’re an IT professional like me who likes to stay in touch with and expand your network, you’re probably familiar with LinkedIn (LNKD), operator of the world’s largest Internet-based professional network with 161 million members spanning over 200 countries and territories. In early June, the company learned that the encrypted passwords of over 6.4 million subscribers had been compromised and posted online.\nIn response to this incident, LinkedIn Director, Vicente Silveira, in a blog, said, “To the best of our knowledge, no email logins associated with the passwords have been published, nor have we received any verified reports of unauthorized access to any member’s account as a result of this event.” The company disabled passwords of those members believed to be at risk and sent them a message explaining how to reset their passwords. LinkedIn also stated that since the incident, it had enhanced its security measures (beyond SHA-1) by applying an additional layer of data protection know as “salting” to better secure members’ information.\nHere’s how salting works. Before generating the hash (note: hash function is the transformation of a string of characters into a usually shorter fixed-length value or key that represents the original string) for each user password, you would create a random string of characters of a predetermined length and prepend this string to each plain text password. As long as the string (aka. a \"salt\") is of sufficient length and sufficiently random, the resulting hash will almost certainly be different each time the hash function is executed. By randomizing the hashes, lookup tables, reverse lookup tables, and rainbow tables become ineffective. Because an attacker won't know in advance what the salt will be, he or she can’t pre-compute a lookup table or rainbow table to crack passwords. If each user's password is hashed with a different salt, the reverse lookup table attack won't work either. Furthermore, in case an attacker tries to use brute force cracking in order to obtain passwords, Mykonos Web Security may be used to help prevent that.\nOn the other hand, if a legitimate user is logging into the Web site, because the user’s password associated salt is stored in the user database along with the hashed password, the authentication server will take the user supplied password and apply the user’s salt to obtain the hashed password. If there is a match, the user will successfully be authenticated.\nDiscussing a wide range of topics impacting enterprises and data center security.", "label": 1}
{"text": "in-dash gps navigation?\nWhat are Firmware Updates?\nAnd why do I need them?\nFirmware plays an important role in many of our electronics these days. But what exactly is it, and why is it so important?\nWhat is firmware?\n\"Firmware,\" generally speaking, refers to the programs that help a device do what it's supposed to do; it's the background programming that runs the machine. That's in contrast with the \"software\" that we use to do stuff on the machine: games and programs on a computer, music files on an MP3 player, and the discs we watch on our Blu-ray players. This is a simplified definition and comparison, but it's reasonable enough for the purposes of this article.\n|The Xbox 360 gained lots of new features after a firmware update|\nWhy does firmware need to be updated?\nMost of the gear we use today is as much a computer as it is an audio or video device. As such, sometimes the manufacturer makes improvements to those programs that run the device (firmware). These improvements are released as firmware updates. We can expect to see firmware updates for everything from our Blu-ray players and video game consoles to our car stereos.\nHere are a couple of examples to illustrate the importance of firmware updates:\n- Xbox 360™ added a new user interface, Netflix streaming, Last FM, and other new features via a big firmware update in 2009.\n- Some early models of Blu-ray players added new surround sound decoding functionality via firmware update, giving owners new ways to experience the audio details in their movies.\nThe same thing goes for software updates, and we're all probably more familiar with those. Our computers constantly check for updates for the programs we run: new versions of video players or iTunes®, for example.\nTo simplify the issue, whether an update is for a device's firmware or software, doesn't really matter. They both work the same way. The point is that sometimes updates are released and we need to apply them to our gear.\nWhere do the updates come from?\nThese updates tend to come from one of two places:\n- Manufacturers — Firmware updates usually come from the manufacturer of the item.\n- Software providers — Sometimes other companies might release updates for the software that an item is using, such as when Adobe® releases an update for its Flash player, which most of us use for watching Internet videos on our computers.\nNavigation receivers from Kenwood, like this DNX6190, use software from Garmin.\nKenwood's navigation receivers present a good example for how updates could come from multiple sources. These receivers use navigation software supplied by Garmin. Potential updates could take any of these forms:\n- Firmware updates for the functionality of the stereo come from Kenwood.\n- Garmin could release updates for navigation functionality, adding features or improving performance (firmware).\n- Garmin also releases occasional map updates to keep the directions as accurate as possible (software).\nHow do I apply the update?\nUpdating the gear is easy when you can connect it to your computer, like MP3 players and cameras. If your television, Blu-ray player, or game console are connected to the Internet, then updating them can be this easy too. It'll depend on the specific equipment, of course.\nFor other gear, you will typically download the update to your computer and then transfer it to your device via disc, thumb drive, or SD card. Simply load the update via disc drive or USB or SD card input, and it should take care of itself from there. Read the manufacturer's website for the specifics of your equipment.\nA caution about applying updates\nBefore applying an update, especially in the case of firmware, you need to make sure that the update is for your exact model of device. Applying an update intended for a similar-but-different model could result in your gear becoming non-operational. The old firmware gets overwritten (replaced) by new operating instructions that aren't compatible with your model, which means your device won't work anymore. That's referred to as \"bricking\" your gear.\nSo always double check those model numbers before applying a firmware update.\nHow do I find out about updates?\nThere are three things you can do to stay abreast of firmware updates.\n- The best way to make sure you're alerted to important updates for your device is to register your purchase with the manufacturer. Fill out the registration card that comes with it or register it online at the manufacturer's website. That way, the manufacturer knows you own one of their devices and can alert you if a really important update comes along.\n- The other way to keep on top of updates is to occasionally visit the manufacturer's website and look up your equipment model or a list of released firmware updates. This might be the only way to learn about updates for minor issues.\n- If you really like your gear, join a message board or Twitter™ feed dedicated to that brand or device. Hanging out with other users is sure to keep you informed about any changes.\nBack to my Kenwood example, upon going to Kenwood's website, I easily made my way to the support section and discovered messages about firmware updates for iPod® and Bluetooth® compatibility.\nWhen in doubt...\nWhether your favorite gadget is your iPod, your Blu-ray player, your car stereo, or your laptop, firmware updates are important for keeping it running smoothly. Just take care and don't apply any updates not meant for your specific model. Whenever in doubt, turn to the manufacturer for confirmation. And if you purchased the item from Crutchfield, our tech support crew can help you out too.", "label": 1}
{"text": "A Guide to Credit Card Safety\nIt’s common practice to pay with a credit card\nwhen eating at a restaurant. Oftentimes, the signed receipt gets left at the empty table until it’s bussed for the next party. That’s enticing for a dishonest person to get your name from the receipt and begin the process of digging for gold.\nSome unscrupulous servers and store clerks will carry a small device called a credit card skimmer\n. With a quick additional swipe of your credit card, the thief puts credit card numbers in storage and will create fake cards with which to make purchases, or sell the card numbers to other thieves. Until the monthly statement becomes available, a cardholder has no idea that fraudulent purchases were made, on the phone, over the internet, or even in person, with his or her credit card number.\nThese are examples of identity theft,\nand reasons for diligence in keeping credit cards and account numbers\nout of the hands of the wrong people. Identity theft happens when a person obtains someone else's personal information\nwithout their knowledge, and fraudulently uses that information to make purchases or withdrawals from bank accounts, etc.\nA Federal Trade Commission (FTC) survey\nin 2006 showed that more than 8 million US consumers were victimized by identity theft\nin the previous year. That’s nearly 4 percent of America’s adult population. In 2008\n, that figure rose to more than 9 million and was up to more than 11 million in 2010. Victims of fraudulent credit card purchases are usually not held responsible for more than $50 per card, so it’s the banking institutions and credit issuers that suffer the financial losses of unrecovered fraudulent debt. But that 2006 survey also revealed that victims of credit card fraud spent more than 200 million hours trying to clear their names and credit status\n. It’s a good idea to request a credit report\n, especially after experiencing identity theft. This provides theft victims the opportunity to dispute information that is fraud-related, let alone simply erroneous.\nOver the internet, be wary of unsolicited email messages that request personal information for the purpose of updating a company’s member or billing information. The victim is made to believe the company is genuine when, in approaches like this, called phishing or spoofing\n, the company is often bogus. This is yet another way individuals scheme to obtain information for fraudulent usage.\nBe sure to check monthly credit card statements. Otherwise, cardholders don’t discover their private information\nhas been stolen until they do something like apply for a loan or a home mortgage, and are denied. It is vital to know some of the methods\nthieves use for obtaining peoples’ personal information. You’ll be better armed for keeping private information private\n. It won’t guarantee you’ll never fall victim to credit card or identity theft, but it can help to minimize risk.\nA good practice\nis to carry only credit cards that are necessary, especially while travelling\n; and carry them not in a wallet or purse– a prime target for thieves – but in a front pocket. Keep other credit cards at home, in a household safe. While you’re away, arrange for your mail to be held for you at the Post Office\nuntil you pick it up. Have your newspaper delivery placed on hiatus until you return. Interior lights should be placed on timers. These small actions can minimize the appearance of an unoccupied home, and thus deter the possibility of break-in and theft of personal information while you are away.\nAre there credit cards for open-but-unused accounts in your wallet? When several accounts are attached to your name and a breach of one of your accounts is discovered, there’s a very good chance that your other accounts can be violated as well. Cancel any unused credit cards and maintain only those that are used regularly.\nDid you know that your trash\ncan be a field day for thieves? They’ll look for items like cut-up debit and credit cards that are expired, credit card statements, and unused credit card checks, envelopes with return addresses which divulge your banking institutions, credit card offers, and all sorts of other items that most honest people wouldn’t know are very telling for a thief. Even something that only reveals your name gives a thief enough information to be dangerous. Rather than tearing up such documents, use a shredder. Many office product chain stores offer shredding for a small fee, based on the weight of the material to be shredded. Home shredders are relatively inexpensive and might be worth their cost several times over if you tend to receive a lot of junk mail.\nIf a retail clerk asks for I.D.\nwhen I use my credit card, should I be offended? Absolutely NOT! The business is attempting to curtail possible fraudulent credit card usage, and the extra measures on its part are indirectly assisting the cardholder. Ensuring the name and signature on the credit card matches that of the driver’s license, for instance, allows the business to prevent liability for merchandise that has been dishonestly obtained – STOLEN! In turn, if your credit card has come into the wrong hands, proper authorities can be alerted.\nShould the internet be trusted for making purchases? It is crucial that online buyers check into the legitimacy of any company they are buying or ordering from. If it has an email address\n, send a message to see whether the address is valid and active. The site must be secure for credit card transactions. Check the site to see what kind of encryption software it is using. Don’t give out credit card numbers without knowing who is receiving the information.\nBy taking each of these steps, you are helping to ensure the protection of your identity. Being the victim of identity fraud\nor credit card fraud can be a very trying experience. It is best to take the initiative and avoid becoming a victim at all. And, although these steps do not fully guarantee that a person will be fully protected\n, they do help to reduce the risk of one's personal information falling into the wrong hands.", "label": 1}
{"text": "The spread of malicious software, also known as malware or computer viruses, is a growing problem that can lead to crashed computer systems, stolen personal information, and billions of dollars in lost productivity every year. One of the most insidious types of malware is a “rootkit,” which can effectively hide the presence of other spyware or viruses from the user — allowing third parties to steal information from your computer without your knowledge. But now researchers from North Carolina State University have devised a new way to block rootkits and prevent them from taking over your computer.\nTo give some idea of the scale of the computer malware problem, a recent Internet security threat report showed a 1,000 percent increase in the number of new malware signatures extracted from the in-the-wild malware programs found from 2006 to 2008. Of these malware programs, “rootkits are one of the stealthiest,” Continue reading at ScienceDaily.", "label": 1}
{"text": "The Cyber Intelligence Sharing and Protection Act (“CISPA”) is a pending legislative proposal aimed at protecting against cyber-threats and cyber-attacks. CISPA follows the much publicized and now effectively defunct legislative proposals Stop Online Piracy Act (“SOPA”) and the Protect IP Act (“PIPA”) as a means to combat online misconduct. On January 18, 2012, Internet megasites Wikipedia, Craigslist, Reddit, Mozilla, Linux and others voluntarily shut down their websites to protest the passage of SOPA and PIPA. Following these protests, SOPA and PIPA were indefinitely postponed. Although some critics see CISPA as a new SOPA/PIPA, CISPA has a somewhat different aim and has received much less protest from the online community.\nWhile not required to do so, CISPA permits certain technology and manufacturing companies to share users’ personal information with the U.S. government, including information presently protected by privacy laws such as HIPAA (Health Insurance Portability and Accountability Act), VPPA (Video Privacy Protection Act) or FERPA (Family Education Rights and Privacy Act), without disclosing to the users that their information has been shared. Consequently, otherwise private information, including video rental records, book rentals, newspaper subscriptions, online reading or data protected by state consumer protection laws (like utility usage records) may freely be shared under CISPA despite existing privacy rules and sharing safeguards.\nCISPA supporters state that the availability of this information will help the government identify cyber-threats and prevent cyber-attacks. Critics state that this is an unnecessary violation of privacy rights, accomplishing no more for the private sector than the currently enacted Wiretap Act and Electronic Communications Privacy Act and allowing the U.S. government unfettered access to private information for which it would otherwise require a warrant.\nCISPA was passed by the U.S. House of Representatives by a vote of 248 to 168 on April 26, 2012. While by no means a foregone conclusion, pundits presently speculate that CISPA will not make it onto the Senate’s agenda. Two alternative bills generally aimed at the same measures, the Cybersecurity Act of 2012 (“CSA”) and the Strengthening and Enhancing Cybersecurity by Using Research, Education, Information, and Technology (“SECURE IT”), are likely to be taken up instead.\nWe will keep you informed of these and other developments as they progress.", "label": 1}
{"text": "Do you have kids who are heading off to college? This can be an intense and exciting time for them. It's a taste of independence, freedom ... and all too often, financial difficulties.\nIt's not just getting into debt that\"s the problem: Academic and psychological risks are part of the issue here, with some students even dropping out of classes because of a high debt load.\nInstead, help your kids start their careers and their adult lives off in the right direction, by sharing these money-management tips.\n1. Open sesame.\nA checking account is essential. However, before you decide on an account, assess how many transactions you'll make each month, and how you'll make them (i.e., paying bills in person or over the Internet, cash withdrawals from ATM). Then look at the accounts your financial institution offers, to see which one covers those transactions for the lowest service charges or monthly fees (look for a college student plan -- they may provide lower fees). When you withdrawal cash from ATMs, use the ones offered by your bank. Other ATMs can charge hefty service fees.\n2. Debit wisely.\nUsing debit cards (which take money directly out of your account) can be a wiser move for keeping budgets on track than credit cards (which can rack up big debts in a short amount of time). But they do come with security risks. Scammers who observe your card number and your password can create their own cards to access your accounts. Always be aware of who\"s around you when you\"re using the card. Shield your password with your hand when you\"re entering it, and report lost cards immediately.\n3. Keep it balanced.\nOnline banking makes checkbook balancing quick and easy. Simply opt for one of the free or low-cost money managing software programs, and enter in all of your transactions. At the end of the month, click on \"reconcile\" or \"balance\" and the program picks up the information from your financial institution's online banking program and makes the calculations for you. Keeping those accounts balanced means that you'll never mistakenly overdraw your account -- and you'll also know if scammers have attacked your account.\n4. Breaking the budget.\nBudgets are all about avoiding nasty financial surprises. Add up all your expenses, from rent to food to transportation to entertainment. (College welcome packages and online resources will often include examples.) Then look at the money coming in. The difference between income and expenses should be positive (as in, money left over) -- if it's not, figure out how to make your budget at least break even (boosting income, for example, or reducing expenses). Check your budget regularly -- if your projections weren't accurate, change them. Make your budget work for you.\n5. The right kind of credit.\nA study found that almost two thirds of college students held at least one credit card -- and one in five of those had four or more cards. College students often use credit cards because they've run out of cash.with Consequently, they don't have the money to repay the debt, which then increases every month as interest charges mount up. The best way to use credit cards is to keep track of all the expenses that you\"re putting on them, and to make sure that you can pay them off in full every month, to avoid interest charges. Always check your credit card statements -- verify that all the purchases listed are valid ones, and let your credit card issuer know immediately if there's a problem.\nAbout the author\nStanley J. Kershman is The Debt Doctor. A leading authority on solving financial disasters, he has been helping people get out of debt for more than 25 years. He's also the author of Put Your Debt on a Diet: A Step-by-Step Guide to Financial Fitness (Pepper Pike Press), a practical handbook that walks you through the process of improving your money management skills. For free copies of Stanley's handy budgeting worksheets, visit www.debtonadiet.com.", "label": 1}
{"text": "Apr. 7, 2011 Faster, more secure logins for multimedia sites might be possible thanks to a new approach to website and database security. Boolean logins would allow thousands if not millions of users to more quickly access the content to which they are entitled, such as music, video and images. The same approach might also reduce the risk of hackers accessing the materials illicitly.\nClassic user identification requires the remote user sending a username and a password to the system to which they want to be authenticated. The system looks up the username in its locally stored database and if the password submitted matches the stored password, then access is granted. This method for identification works under the assumption that there exist no malicious users and that their local terminals cannot be infected by viruses.\nIncreasingly, however, these assumptions are too naïve. Not all users can be assumed to have good intentions. Technology continuously facilitates the capture of transactions in wireless channels. Usernames and passwords can therefore be easily obtained by malicious third parties (other users or viruses) and be used for illegal accesses to systems.\nNow, Nikolaos Bardis of the University of Military Education, in Vari, Greece and colleagues there and at the Polytechnic Institute of Kiev, in Ukraine, have developed an innovative approach to logins, which implements the advanced concept of zero knowledge identification. The system is based on a set of relatively simple mathematical functions, known as one-way Boolean operators, to verify a login rather than the standard encryption-decryption calculations used today. The team explains that preliminary testing shows that their approach to a login algorithm could be hundreds or thousands of times faster than conventional logins. Importantly, the system will reduce the overall computing requirements on the provider side of the system as well as making logins much more secure.\n\"The efficiency of information security algorithms is defined based on two factors: the level of security and the amount of computational resources required for the implementation of the security functions,\" Bardis and colleagues explain in the latest issue of the International Journal of Multimedia Intelligence and Security.\nUnderpinning any information security algorithm is an analytically insoluble mathematical problem that can be defined as a function applied to \"x\" to give \"y\"; Y = F(X). The function is made to be so complex that reversing it is impossible, like trying to unmix different coloured paints in a pot. Asymmetric cryptographic algorithms (public key encryption algorithms) use this approach and are common in web browser logins and access systems for many different types of database. This type of login requires a lot of computational power and is inherently slow. The team points out that a Boolean function can be just as sophisticated but requires a fraction of the computational power and so could be much, much faster.\nZero order user authentication schemes supply the user with a special function that produces an extremely large number of different results for all its possible inputs. A set of inputs that produce a common result is selected. These inputs are the user's passwords. A new user registers by submitting to the system their function and the common result. The user authenticates for a normal session using each password only once. The user provides the password at the beginning of each session. The system calculates the value produced when this password is used as input to the function. If this is equal to the common result, then authentication is successful and access is granted. Someone that is trying to gain access without the necessary knowledge (an illicit user) will practically have to try all possible password combinations, before reaching the correct one.\nNormally, the functions used involve raising large numbers to large powers and dividing large numbers to find their remainder. These are operations make processors of ordinary computer systems run very slow and impose a significant burden even on larger information systems with large numbers of users. The proposed scheme uses systems of non-linear Boolean equations to construct the unique function. Boolean equations process binary data, using simple binary operations between bits. Such an operation is the eXclusive OR operation (XOR). Calculations are hence much simpler for the simple reason that it is much easier to calculate a logic expression than to raise a 100 digit number to a 10 digit power and then divide the result by another large number. The series of exchanges for registration and authentication is the same as before. However the inputs and the common results are binary vectors.\n\"Zero knowledge user identification solves the security issues by using passwords that change for every session and are not known to the system beforehand. The system can only check their validity,\" team member Nikolaos Doukas explains. \"The proposed scheme has potential use in any system where malicious users have incentives to gain illegal access and perform actions they are not entitled to. The number of such systems increases rapidly as information gains value,\" he concludes.\nOther social bookmarking and sharing tools:\n- Nikolaos Bardis, Nikolaos Doukas, Oleksandr P. Markovskyi. Fast subscriber identification based on the zero knowledge principle for multimedia content distribution. International Journal of Multimedia Intelligence and Security, 2010; 1 (4): 363 DOI: 10.1504/IJMIS.2010.039237\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "“What does not move could be a Threat”\nThe goal of Airport Security is to prevent attacks at\ncommercial aviation. The strategy is to prevent the threats from\ngaining access to the commercial airplanes. Airports are divided into\ntwo sectors for security. There is an open sector and a secured sector\non each side of the security screening portals.\nPotential threats before the screening stations are largely ignored.\nSecurity from the curb or parking structures to the screeners is left to\na handful of professionals using conventional crowd control security measures.\nThis means, the threat must reveal themselves in some way to trigger a response.\nErratic behavior is a common form of spotting a potential threat. A\nsignificant problem to Airport Security is “unattended luggage” in the open\nareas of the Airport. There is a concern that terrorist may detonate\nexplosive device in the heavy populated open areas of Airports.\nThis threat often takes the form of an unattended package. The Airport\nloudspeaker system constantly repeats over and over again, “beware of unattended\nluggage, don’t leave your bag unattended, and if you see an unattended bag\nreport it to an Airport employee”. This form of security uses the general\npublic as the first line of defense. How successful is this approach?\nHard to measure, but it is certainly cost effective.\nIt is difficult to assess the effectiveness of the present public awareness\nsystem. The fact that few attacks of this nature have been launched,\nsuccessfully or unsuccessfully, leads to a false sense of security.\nBasic information like how often is a package or suitcase left unattended\nis missing? How long is the time before an unattended suitcase is detected\nand reported? How disruptive in response to these unattended packages\nare these events? This last question we do have sources of good\nAirports shut down all the time for weather reasons. Thunderstorms\nfor short periods, major storms or fog situations for longer periods provide\nreliable information on the impact of these disruptions. The shutting\ndown of a terminal, evacuating all passengers, screening of evacuees, canceling\nor rescheduling flights, produces major disruptions that propagate far beyond\nthe immediate airport. Plane schedules or delays and cancellations\noften take days to recover. A relatively benign shut down of less than\none hour is manageable. When the threat has a bomb or incendiary potential\nthe shut down can push to several hours or more, even when the threat is\nfalse. These kinds of delays are not a containable event. Costs\nand operational impacts mushroom with time. The cost of false alarms is significant;\nanything that expedites the process by cutting down the event time has a\nhuge cost benefit. Although each Airport case is unique, shut downs costs\nfrom $100,000 to over a $1,000,000 for each event are reasonable estimates.\nWe believe ISSM is a game changer because it is automatically resolves most\nthreats to a resolution of true or false threats and facilitates the Airport\nresponse. How is this achieved?\nTo understand the benefit of ISSM we need to understand the capability of\nISSM as a surveillance system. Infrared Security System & Method\n(ISSM, US patent 7,738,008, June 15, 2010) is a real time three-dimensional\nscreening system that can accurately detect moving and stationary objects.\nObjects are defined by their physical size and precise location. With\nthis precise size capability measuring capability a small package is easily\ndetected when left alone. ISSM screens all stationary and moving objects\nand classifying them into different size categories fitting the application\n(e.g. luggage, people, animals, small and large vehicles). How does\nISSM apply its capability to the Airport problem?\n- ISSM detects, classifies, and categorizes all isolated objects in its\nsurveillance field of view. The computations are performed at video frame\n- ISSM processor ignores moving objects (in this case), and identifies only stationary objects as a potential threat.\n- The stationary object must be in a certain size range, must be non-moving,\nand cannot have a “person size object” within a defined range to the object.\nIf a person sets their luggage down we do not want to trigger an unattended\nobject event unless the person moves away from the object. Detected objects\nmeeting these criteria are classified as a “potential target”.\n- This “potential target” is observed for 30-60 seconds. If the potential\nthreat remains stationary and unattended, its classification is increased\nto “target”. People passing by the “target” may temporarily obscure the\ntarget, the 30-60 second range compensates for any line-of-sight interruptions.\n- Once the “target” is identified, the target scene video that has been\nrecorded is “back tracked” to identify and determine the circumstances of\nthe “birth” of the target. (A detected target must be created by some event\nthat caused the target to become an isolated object).\n- Once the source producing the birth has been detected; we can refine the threat. Let’s examine potential sources.\na. The “target” occurred as a result of a person setting the object\ndown and walking away. This is the most common situation and the focus of\nb. The “target” occurred without a clear connection to an identifiable\nperson. In this case a security analyst must be engaged to interpret the\n- The ISSM alerts Airport Security that an event is ongoing.\n- ISSM before a back track search of the video to determine the circumstances\nin the birth of the target. ISSM has the ability to uniquely identify the\nperson that set down the object. ISSM has computed a “signature” (size and\nthermal contrast) that uniquely identifies the culprit and allows the tracking\nof the individual in a crowded environment.\n- ISSM forward tracks the culprit to record his behavior and to accurately\ndetermine where the culprit has moved since leaving his luggage.\na. In most cases the owner of the unattended package is in the area involved\nin some form of distraction, (e.g. talking on his cell-phone or ordering\nfrom a food service stand). Dispatching a security official armed with a\nreal time cell-phone video of the scene will contain and resolve this breach.\nb. In other cases the culprit has departed the area, suggesting a clear\nintent to leave the package behind. Real time information is used to vector Airport security personnel to apprehend the culprit as he tries to\nescape. The tracking of the culprit continues as long as the culprit remains\nin the surveillance field of view. The size and thermal signature is information\nthat can be used to extend the coverage by handing off to other ISSM surveillance\ncameras in other parts of the Airport facility.\nc. The security analyst will “back track” the culprit with the package\nlooking for prior interactions that would suggest additional people are involved.\nd. ISSM continues to provide real time information of the event. Airport\nsecurity uses the information to direct a controlled, limited, and focused\nthe response. Information is key element to an effective limited response.\nThis minimizes the overall disruption, enhances security, and provides a\ncost-effective resolution to the event.\nISSM possess a level of detection and discrimination not previously\navailable by convention physical security systems. By exploiting the\nenhanced capabilities a multi-level search, detect, and classify is performed\nwithout human operator involvement. Once the threat level has been\nperformed, airport security needs to take over. The benefit of ISSM\nin the above scenario is obvious. The threat can be categorized into\na routine problem or a potential serious event. Recognition and verification\nof non-threatening events allows a simple security response that will not\ncause an impact on airport operations. The terminal does not need to\nbe shut down.\nISSM identified true target threats within 60 seconds of first detection.\nISSM identified the culprit (source of the target) within 2 minutes, and\nhas initiated tracking of the culprit. If the target information and\nthreat level is transmitted to the response personnel apprehension could\nbe within minutes. The early apprehension of the culprit allows a rapid\nresolve the actual situation. Since a very high percentage of “unattended\nbaggage” events are actually false alarms, ISSM allows an early detection\nthus avoiding both major and minor disruptions in Airport operations.\nThreats are detected in real time. This allows a rapid response to the “target”,\nearly evacuations, and early capture of the people involved in the event.\nAll of which features serves to minimize the duration of the shut down thus\nminimizing the impact.\nInfrared Applications Inc. is the owner of the ISSM patent.\nGary Ball, President of IAI, is in the process of formulating future plans\nfor ISSM for a multitude of applications. Interested parties may contact\nMr. Ball at BaG370@aol.com for more information.", "label": 1}
{"text": "E P I C A l e r t\nCongress passed the \"Protect America Act of 2007,\" making significant changes to the Foreign Intelligence Surveillance Act (FISA). FISA was enacted in 1978 to regulate intelligence gathering following revelations of abusive uses of covert intelligence powers. The 1978 law created a secret FISA court to oversee this intelligence gathering. The new law removes some surveillance from the limited FISA court review, allows the government to create more surveillance programs with limited review, and immunizes from lawsuits telecommunications companies who participate in these programs. These powers are temporary, as the new law expires in 6 months.\nThe law does not focus on \"terrorists,\" but on communications when one of the parties is outside of the United States. The law amends the legal definition of \"electronic surveillance,\" as monitored by the FISA court, \"Electronic surveillance\" no longer encompasses surveillance of people reasonably believed to be outside of the United States.\nThe law allows the Director of National Intelligence and the Attorney General to approve surveillance on a program-wide, rather than individual basis. These officials must certify that, among other conditions, these programs have as \"a significant purpose\" the obtaining of foreign intelligence information. Instead of individually reviewing each application for surveillance, the FISA court may only review the proposed program to determine whether Executive branch officials are \"clearly erroneous\" in how they design and certify a given program.\nLastly, the law forces information holders, such as telecommunications companies and Internet service providers, to turn information over to the government, or face the criminal penalty of contempt of court.\nProtect America Act of 2007:\nEPIC's FISA page:\nEPIC Resources on Domestic Surveillance:\nLast week, the President signed the Implementing Recommendations of the 9/11 Commission Act of 2007. The law is a compromise between a Senate bill (S. 4) passed in March and a House bill (H.R. 1) passed in January. Both houses of Congress passed the harmonized version in July.\nThe law implements certain recommendations of the 9/11 Commission, including improving privacy and civil liberties protections in agencies that perform law enforcement or anti-terrorism functions. The bill also provides for establishing regional law enforcement \"fusion centers\" for information sharing.\nThe law strengthens the Privacy and Civil Liberties Oversight Board. Previously, members of the Board served at \"the pleasure of the President.\" The House bill, H.R. 1, originally proposed to make the Oversight Board into an independent agency, but the new Act allows the Oversight Board to remain in the Executive Office of the President. The new Act also implements fixed 6-year terms, and limits the number of members from the same political party as the President to three. Although the members of the Board are still appointed by the President, the new law mandates that all members be subject to Senate approval. The new Board may request attorney general-issued subpoenas in the course of their investigations. The attorney general is required to submit a written explanation of any denials of or modifications to the subpoena request to the Board as well as the House and Senate Judiciary Committees.\nThe Act also strengthens privacy oversight in individual agencies. The new Act directs several specific agencies to appoint privacy and civil liberties officers. The law also contains some whistleblower protections, preventing reprisals against employees who disclose possible privacy and civil liberties violations to privacy officers or the Board. Furthermore, the Privacy Officer of the Department of Homeland Security is given the power to access records of DHS components and may, with the permission of the Secretary, issue subpoenas for DHS records.\nFinal Text of Implementing Recommendations of the 9/11 Commission Act of 2007:\nEPIC's Report on Privacy Oversight (September 2006):\nEPIC Spotlight on Fusion Centers:\nEPIC's Privacy Oversight page:\nEPIC's 9/11 Commission page:\nIn a complaint to the Canadian Commissioner of Competition, the Canadian Internet Policy and Public Interest Clinic (CIPPIC) at the University of Ottawa last week requested an investigation into the proposed $3.1 billion merger between Google and Internet advertising company DoubleClick. CIPPIC said the merger should be reviewed \"on the grounds that it is likely to prevent or lessen competition substantially in the targeted online advertising industry.\"\n\"Through the merger, Google-DoubleClick will gain unprecedented market power, with which they can manipulate online advertising prices. Advertisers and web publishers will have no real choice but to choose Google's advertisement platforms in order to remain visible in the e-commerce market,\" said CIPPIC Director Philippa Lawson. CIPPIC cited the US Federal Trade Commission complaint and supplement filed by EPIC, the Center for Digial Democracy and the US Public Interest Research Group, as well as the ongoing European investigations into the merger. The Federal Trade Commission has made a \"second request\" to Google concerning the merger, which means the FTC is closely scrutinizing the proposed deal under antirust and privacy issues.\nIn July, the European Commission Directorate on Competition announced that it would review the merger. The decision was made shortly after European consumer group BEUC sent a letter urging the Commission to investigate the merger, noting that the European Commission has considered consumer choice as an element in its review of past mergers. BEUC also reminded the Commission that it has publicly defined its role as preventing mergers that would deprive consumers of \"high quality products, a wide selection of goods and services, and innovation.\"\nThe Article 29 Data Protection Working Party also recently expanded an investigation of Google's data retention policies after receiving Google's response to their initial inquiry. The initial review focused on Google's storage periods of server logs, whereas the Working Party has indicated that its new investigation will evaluate the previous analysis in addition to the data protection issues at stake with other search engines.\nCanadian Internet Policy and Public Interest Clinic, Section 9 Application for an Inquiry into the Proposed Merger of Google, Inc. and DoubleClick Inc. (Aug. 2, 2007) (pdf):\nThe European Commission Directorate on Competition:\nBEUC's letter on Proposed Acquisition of DoubleClick by Google (pdf):\nArticle 29 Data Protection Working Party Press Release (pdf):\nEPIC's page on Proposed Google/DoubleClick Merger:\nFederal Trade Commission, Press Release: FTC to Host Town Hall to Examine Privacy Issues and Online Behavioral Advertising (Aug. 6, 2007):\nThe Department of Homeland Security announced revisions to two passenger profiling programs this week: the Automated Targeting System and Secure Flight. However, privacy and security threats remain in both programs. DHS also announced a final rule on the Advance Passenger Information System.\nThe Advance Passenger Information System final rule \"enables DHS to collect manifest information for international flights departing from or arriving in the United States prior to boarding,\" DHS said. The rule requires air carriers to transmit manifests 30 minutes before departure or \"provide manifest information on passengers as each passenger checks in for the flight, up to the time when aircraft doors are secured.\" For vessels departing from foreign ports to the United States, the rule does not change current requirements to transmit passenger and crew arrival manifest data between 24 to 96 hours prior to arrival, \"but requires vessel carriers to transmit [Advance Passenger Information System] data 60 minutes prior to departure from the United States.\"\nIn response to a November rulemaking, DHS announced changes to the Automated Targeting System, a federal database that created secret, terrorist ratings on tens of millions of American citizens. The system was originally established to assess cargo that might pose a threat to the United States. Since 1999, ATS was used to assign a \"risk assessment,\" which is essentially a terrorist risk rating, to all people \"seeking to enter or exit the United States,\" \"engag[ing] in any form of trade or other commercial transaction related to the importation or exportation of merchandise,\" \"employed in any capacity related to the transit of merchandise intended to cross the United States border,\" and \"serv[ing] as operators, crew, or passengers on any vessel, vehicle, aircraft, or train who enters or exits the United States.\"\nSome positive changes to ATS include a significant reduction in the data retention period (from 40 years to 15 years) and the elimination of a routine use that was unnecessary and far too broad (it allowed data to be used for hiring decisions). However, there remain many of the security and privacy risks outlined in comments previously filed by EPIC, 29 organizations and 16 privacy and technology experts that urged the agency to suspend the program and to fully enforce Privacy Act obligations. Most importantly, the Automated Targeting System still creates terrorist risk profiles that are secret and unreviewable.\nDHS released a Response to Public Comments to the November 2006 ATS Rulemaking, new Notice of Proposed Rulemaking, System of Records Notice and Privacy Impact Assessment concerning the revised Automated Targeting System. Comments on this new rulemaking are due on September 5.\nMore than a year after Secure Flight was suspended for a comprehensive review, the Department of Homeland Security has announced major revisions to the program. Previously, DHS sought to use Secure Flight to assess possibilities for criminal behavior from travelers. The new program will \"determine if passenger data matches the information on government watch lists, and transmit matching results to aircraft operators,\" according to DHS. Currently, the airlines run passenger names against the watch lists.\nSecure Flight was grounded in February 2006 after government investigations found numerous security and privacy vulnerabilities. One report said the program had inconclusive risk assessments and 144 known security vulnerabilities. In February 2007, the head of the Transportation Security Administration said full implementation of Secure Flight would be delayed until 2010, at least five years behind schedule.\nThere are ongoing concerns about the secrecy and accuracy of watch lists and adequacy of redress procedures. In February comments to the Department of Homeland Security, EPIC urged the agency to fully apply Privacy Act requirements of notice, access, and correction to the new traveler redress program and its underlying system of watch lists. EPIC noted that the federal watch lists are full of errors. In December 2005, the director of TSA's redress office revealed that more than 30,000 people who are not terrorists have asked TSA to remove their names from the lists since September 11, 2001. Earlier this year, the head of the Transportation Security Administration said that the watchlists were being reviewed, and he expected to cut the list of names in half.\nThe Secure Flight Notice of Proposed Rulemaking has not yet been published in the Federal Register; comments will be due 60 days after publication. DHS has posted a copy of the notice on its site.\nDepartment of Homeland Security, Press Release: Statement by Homeland Security Chief Privacy Officer Hugo Teufel III on the Privacy Act System of Records Notice for the Automated Targeting System (Aug. 3, 2007) (including links to the Response to Public Comments to the November 2006 ATS Rulemaking, Current Notice of Proposed Rulemaking, System of Records Notice and Privacy Impact Assessment):\nDepartment of Homeland Security, Press Release: DHS Announces Predeparture Screening of International Passengers and First Step Toward Secure Flight (Aug. 9, 2007) (including link to the Notice of Proposed Rulemaking):\nComments on ATS of EPIC, 29 organizations and 16 privacy and technology experts (Dec. 4, 2006) (pdf):\nEPIC's Comments to the Department of Homeland Security about TRIP (Feb. 20, 2007) (pdf):\nEPIC's page on the Automated Targeting System:\nEPIC's page on Secure Flight:\nThe Senate has passed a freedom of information bill introduced by Senators Leahy and Cornyn. The Openness Promotes Effectiveness in our National Government Act (OPEN Government Act), S.849, ensures that anyone who gathers information to inform the public, including freelance journalists and bloggers, may seek a fee waiver when they request information under FOIA. The bill also clarifies that the definition of news media, for purposes of FOIA fee waivers, includes free newspapers and individuals performing a media function who do not necessarily have a prior history of publication.\nFurther, the bill imposes a 20-day time frame for responding to requests, and allows FOIA requesters to obtain attorneys' fees when they file a lawsuit to obtain records from the government and the government releases those records before the court orders them to do so. The bill also creates an Office of Government Information Services in the National Archives, an ombudsman to mediate agency-level FOIA disputes, and a Chief FOIA Officer in every federal agency. The bill also creates a hotline service for all federal agencies, so that requesters can track their requests.\nFinally, the bill also clarifies that FOIA applies to agency records that are held by outside private contractors, no matter where these records are located. The OPEN Government Act, the first major FOIA reform in over a decade, “will help to reverse the troubling trends of excessive delays and lax FOIA compliance in our government and help to restore the public's trust in their government. This bill will also improve transparency in the Federal Government's FOIA process,” according to Senator Leahy.\nOpenness Promotes Effectiveness in our National Government Act (the “OPEN Government Act”), S.849:\nSenator Leahy Statement, \"Bipartisan Leahy-Cornyn Bill Passes Senate, On Course To Increase Government Transparency\" (Aug. 6, 2007)\nEPIC's FOIA page:\nEPIC Warns Federal Agencies About RFID in US Travel Cards\nIn comments to the departments of State and Homeland Security, EPIC recommended against the use of \"long-range\" RFID technology (which transmits personal data to remote tracking devices) in the proposed \"PASS card\" for travel between the United States, Canada, Mexico, and the Caribbean. EPIC explained that the tracking technology would jeopardize the privacy and security of US travelers, and urged the agencies to delay the implementation of the passport card requirement until solutions can be found for the extraordinary delays, problems, costs and privacy risks. Earlier this year, Homeland Security abandoned a similar proposal for US-VISIT travel documents, following criticisms from EPIC and the Government Accountability Office. EPIC also noted that, although the PASS card notice was released on June 26, 2007 and comments are due on or before August 27, the Privacy Impact Assessment for the proposed long-range tracking program was not released until August 10. In the last two fiscal years, DHS has only published 45 of the 189 required Privacy Impact Assessments.\nEPIC's Comments on the Western Hemisphere Travel Initiative (August 1, 2007) (pdf):\nEPIC's page on RFID:\nBorder Security Computer System Plagued With Problems\nThe computer system for border control program US-VISIT is riddled with security vulnerabilities, according to a new report from the Government Accountability Office, which outlined security risks in the system last year. \"Weaknesses existed in all control areas and computing device types reviewed,\" the GAO said. Security flaws in the network used at 400 entry points nationwide increase the risk of theft or manipulation of tens of millions of identity records, which include passport, visa, Social Security and biometric data. In 2005, a computer virus crashed the US-VISIT system. According to documents released to Wired News under the Freedom of Information Act, DHS knew of the software vulnerability, but deliberately chose to leave more than 1,300 sensitive US-VISIT workstations vulnerable to attack. EPIC has repeatedly criticized many security and privacy flaws in the US-VISIT system.\nGovernment Accountability Office, \"Information Security: Homeland Security Needs to Immediately Address Significant Weaknesses in Systems Supporting the US-VISIT Program GAO-07-870\" (July 2007) (pdf):\nEPIC's page on US-VISIT:\nFTC Seeks Public Comments on SSN Uses\nThe Federal Trade Commission (FTC) is requesting public comments on private sector Social Security Number uses. This follows the President's Identity Theft Task Force's April recommendation that agencies develop a record on the extent and necessity of privacy sector SSN use. The FTC is requesting that industry, academics, consumer advocates and law enforcement submit comments on private sector Social Security Number uses; the necessity of these uses; what alternatives are available and how to transition to alternative identifiers; and how Social Security Numbers are gathered by identity thieves.\nFTC Request for Comments on Social Security Numbers:\nPresident's Identity Theft Task Force:\nEPIC Comments to Identity Theft Task Force (pdf):\nOECD Communications Outlook 2007 Now Available\nThe biannual OECD Communications Outlook is now available. The 2007 edition provides an extensive range of indicators on the development of different communications networks and compares performance indicators such as revenue, investment, employment and prices for services throughout the OECD area. These indicators are essential for industry participants and for regulators who use benchmarking to evaluate policy performance. This book is based on the data from the OECD Telecommunications Database 2007, which provides time series of telecommunications and economic indicators, such as network dimension, revenues, investment and employment, for OECD countries from 1980 to 2005.\nOECD Communications Outlook 2007:\nEPIC Files Comments on E911, Proposes Greater Location Privacy\nEPIC filed comments to the Federal Communications Commission on proposed rules for Enhanced 911 location information. Wireless telephone providers are required to meet certain standards for location accuracy. The FCC requested comments on location accuracy standards as well as extending the rules to VOIP services. EPIC reminded the FCC that current privacy rules do not adequately protect location information. EPIC proposed that location privacy rules should improve with location accuracy, and that there should be consistent privacy rules for VOIP and other services.\nEPIC's Comments on E911 (pdf):\nEPIC's CPNI page:\nCable Industry Opposes Consumer Privacy Safeguards\nThe National Cable and Telecommunications Association has filed a complaint with a federal appeals court challenging the FCC's rule that would protect the protect of consumers telephone record information. EPIC petitioned the FCC to establish these safeguards after mounting evidence of \"pretexting\" and identity theft, based on the misuse of telephone records. The industry groups claim a First Amendment right to disclose customer information. Courts have typically rejected that argument.\nFCC, \"Telecommunications Carriers’ Use of Customer Proprietary Network Information and Other Customer Information\" (Apr. 2, 2007):\nEPIC's CPNI Page:\nComplete Guide to Security and Privacy Metrics by Debra S. Herrman (Auerbach Publications, 2007)\nMeasuring compliance with privacy and security standards has never been an easy task. Many privacy principles are vague (\"collection limitation\") and many well defined security requirements are largely unrelated to significant privacy concerns. The law has also thrown up its hands when it comes to measuring privacy harms. Privacy statues typically designate a fixed amount for a privacy violation. Not surprisingly, privacy and security do not fair well under a cost benefit analysis. As a consequence, security breeches are widespread and identity theft is, according to the Federal Trade Commission, the number one concern of American consumers.\nEnter this remarkably comprehensive, clearly written, and well organized manual. Debra Herman has broad experience in IT development and system evaluation in the federal government, and a deep regard for privacy protection. Though the book is primarily directed toward IT managers, it is well informed by privacy law and policy. The guide offers plenty of checklists to evaluate key security factors. It also touches upon several of the hot button privacy concerns, including problems with RFID tags and the battles over the use of encryption.\nFor agency officials who are preparing a privacy impact assessment or privacy experts who want to learn more about the hard work of system security, the Complete Guide to Security and Privacy Metrics is an unbeatable resource.\n-- Marc Rotenberg\n\"Information Privacy Law: Cases and Materials, Second Edition\" Daniel J.\nSolove, Marc Rotenberg, and Paul Schwartz. (Aspen 2005).\nThis clear, comprehensive introduction to the field of information privacy law allows instructors to enliven their teaching of fundamental concepts by addressing both enduring and emerging controversies. The Second Edition addresses numerous rapidly developing areas of privacy law, including: identity theft, government data mining and electronic surveillance law, the Foreign Intelligence Surveillance Act, intelligence sharing, RFID tags, GPS, spyware, web bugs, and more. Information Privacy Law, Second Edition, builds a cohesive foundation for an exciting course in this rapidly evolving area of law.\n\"Privacy & Human Rights 2005: An International Survey of Privacy Laws\nand Developments\" (EPIC 2006). Price: $60.\nThis annual report by EPIC and Privacy International provides an overview of key privacy topics and reviews the state of privacy in over 70 countries around the world. The report outlines legal protections, new challenges, and important issues and events relating to privacy. Privacy & Human Rights 2005 is the most comprehensive report on privacy and data protection ever published.\n\"FOIA 2004: Litigation Under the Federal Open Government Laws,\" Harry\nHammitt, David Sobel and Tiffany Stedman, editors (EPIC 2004).\nThis is the standard reference work covering all aspects of the Freedom of Information Act, the Privacy Act, the Government in the Sunshine Act, and the Federal Advisory Committee Act. The 22nd edition fully updates the manual that lawyers, journalists and researchers have relied on for more than 25 years. For those who litigate open government cases (or need to learn how to litigate them), this is an essential reference manual.\n\"The Public Voice WSIS Sourcebook: Perspectives on the World Summit on\nthe Information Society\" (EPIC 2004). Price: $40.\nThis resource promotes a dialogue on the issues, the outcomes, and the process of the World Summit on the Information Society (WSIS). This reference guide provides the official UN documents, regional and issue-oriented perspectives, and recommendations and proposals for future action, as well as a useful list of resources and contacts for individuals and organizations that wish to become more involved in the WSIS process.\n\"The Privacy Law Sourcebook 2004: United States Law, International Law,\nand Recent Developments,\" Marc Rotenberg, editor (EPIC 2005).\nThe Privacy Law Sourcebook, which has been called the \"Physician's Desk Reference\" of the privacy world, is the leading resource for students, attorneys, researchers, and journalists interested in pursuing privacy law in the United States and around the world. It includes the full texts of major privacy laws and directives such as the Fair Credit Reporting Act, the Privacy Act, and the OECD Privacy Guidelines, as well as an up-to-date section on recent developments. New materials include the APEC Privacy Framework, the Video Voyeurism Prevention Act, and the CAN-SPAM Act.\n\"Filters and Freedom 2.0: Free Speech Perspectives on Internet Content\nControls\" (EPIC 2001). Price: $20.\nA collection of essays, studies, and critiques of Internet content filtering. These papers are instrumental in explaining why filtering threatens free expression.\nEPIC publications and other books on privacy, open government, free expression, crypto and governance can be ordered at:\nEPIC Bookstore http://www.epic.org/bookstore\n\"EPIC Bookshelf\" at Powell's Books\nEPIC also publishes EPIC FOIA Notes, which provides brief summaries of interesting documents obtained from government agencies under the Freedom of Information Act.\nSubscribe to EPIC FOIA Notes at:\n7th Annual Future of Music Policy Summit. September 17-18, 2007.\nWashington, DC. For more information\nPIPA Conference: Private Sector Privacy in a Changing World. September\n20-21, 2007. Vancouver, Canada. For more information:\nCivil Society Privacy Conference: Privacy Rights in a World Under\nSurveillance. September 25, 2007. Montreal, Canada. For more\n29th International Conference of Data Protection and Privacy\nCommissioners. September 25-28, 2007. Montreal, Canada. For more\nInternet Bill of Rights meeting. September 27, 2007. Rome, Italy. For more information: http://www.internet-bill-of-rights.org/en/\nOECD and Industry Canada: Shaping Policies for Creativity, Confidence\nand Convergence in the Digital World. October 3, 2007. Ottawa,\nFor more information:\nUniversity of Ottawa Faculty of Law: The Revealed \"I\". October 25-27,\n2007. Ottawa, Canada. For more information:\nComputer Professionals for Social Responsibility: Technology in Wartime Conference. AJanuary 26, 2008. Stanford University. For more information: http://cpsr.org/news/compiler/2007/Compiler200707#twc\nFuture of the Internet Economy - OECD Ministerial Meeting. June 14-18,\n2008. Seoul, Korea. For more information:\nSubscribe/unsubscribe via web interface:\nBack issues are available at:\nThe EPIC Alert displays best in a fixed-width font, such as Courier.\nThe EPIC Alert mailing list is used only to mail the EPIC Alert and to send notices about EPIC activities. We do not sell, rent or share our mailing list. We also intend to challenge any subpoena or other legal process seeking access to our mailing list. We do not enhance (link to other databases) our mailing list or require your actual name.\nIn the event you wish to subscribe or unsubscribe your e-mail address from this list, please follow the above instructions under \"subscription information.\"\nThe Electronic Privacy Information Center is a public interest research center in Washington, DC. It was established in 1994 to focus public attention on emerging privacy issues such as the Clipper Chip, the Digital Telephony proposal, national ID cards, medical record privacy, and the collection and sale of personal information. EPIC publishes the EPIC Alert, pursues Freedom of Information Act litigation, and conducts policy research. For more information, see http://www.epic.org or write EPIC, 1718 Connecticut Ave., NW, Suite 200, Washington, DC 20009. +1 202 483 1140 (tel), +1 202 483 1248 (fax).\nIf you'd like to support the work of the Electronic Privacy Information Center, contributions are welcome and fully tax-deductible. Checks should be made out to \"EPIC\" and sent to 1718 Connecticut Ave., NW, Suite 200, Washington, DC 20009. Or you can contribute online at:\nYour contributions will help support Freedom of Information Act and First Amendment litigation, strong and effective advocacy for the right of privacy and efforts to oppose government regulation of encryption and expanding wiretapping powers.\nThank you for your support.", "label": 1}
{"text": "Computers and other devices have done nothing but get faster, giving businesses the ability to move traditional functions onto the computer. This move saved companies untold amounts of money and made employees more productive. The new trend is to move these now “physical” elements into a more virtual environment, a trend called virtualization.\nIn technical circles, the process of virtualization is the creation of a virtual copy of something actual like a server, network or storage device. Virtualization allows one device to run as more than one device. Running Windows on your Mac, or partitioning a physical hard drive into smaller sections that each act as a separate hard drive are examples of virtualization. In general, there are four types of virtualization:\n- Operating System virtualization. Running more than one operating system on the same device.\n- Server virtualization. Running more than one server on the same physical server.\n- Storage virtualization. Linking together multiple storage devices into what’s perceived as one device. Cloud storage is a common form of storage virtualization.\n- Network virtualization. Network virtualization is the combining of network connections like Internet and other Data into one seemingly visible network and then dividing the connection into separate connections. E.g., Taking a 5mb connection and assigning 2mb to your server and 3mb to employee’s computers.\n- Decreased physical hardware. When you virtualize systems, you need less hardware. Imagine an office that has both Mac and Windows computers, you can run either OS on the same machine which means no need to duplicate computers. If you have more than one server, you can bring them together onto one server, possibly being able to get rid of unnecessary equipment.\n- Reduced overhead. With virtualization you will be able to get rid of hardware, which means all associated operating costs - e.g., electricity bills - and capital expenditures - e.g., maintenance - related to the hardware are decreased, or eliminated. You save money in the long run.\n- Increased efficiency. As virtualization solidifies different systems into one, you’ll be able to more efficiently use the hardware components e.g., there’s no need to have separate Internet connections for email, servers and computers.\n- Easy Disaster Recovery. With virtualization, you don’t need to invest heavily in backing up your company’s data, you can take the money saved from virtualization and invest it in a small number of servers that house backups offsite. When a disaster strikes, you can be up and running again quickly.\n- Extended device lifecycle. It seems that current hardware is out of date almost as soon as you buy it, and within a couple of years it’s struggling to meet demands of more modern programs. With virtualization your programs are stored on servers, so the need for modern equipment is lessened. This means you can use your current equipment for longer.", "label": 1}
{"text": "Welcome to the official Cryptography site for Duke CompSci 182 Group 5 Section 1.\nA Typical Conversation on Cryptography\nMe: Hey, you like feeling secure with your computer, right?\nFriend:...riiiiiiiiiight? (having no idea where I'm going with this)\nMe: Would you feel like switching over to a new mail client and chat client that would promote the confidentiality of your online communications?\nFriend: I guess. Would it be easy?\nMe: Oh, probably. How would you also feel about needing to find a public key in order to send an e-mail to some-one new and posting a public key so people can talk to you?\nFriend: I would need to use this public key thing to talk to you?\nFriend: I'm not sure if I like talking to you enough to put up with that.\nCourtesy of XKCD\nWhat Is Cryptography.\nCryptography is the practice and study of techniques for secure communication in the presence of third parties. More generally, it is about constructing and analyzing protocols that overcome the influence of adversaries and which are related to various aspects in information security such as data confidentiality, data integrity, and authentication. Modern cryptography intersects the disciplines of mathematics, computer science, and electrical engineering. Applications of cryptography include ATM cards, computer passwords, and electronic commerce.\nEveryday Uses of Cryptography.\nWhether you realize it or not, there are a lot of ways that you deal with some form of encryption every day. The simplest example is the password you use to log on to a network. Orginally passwords were sent to the server in plaintext. Not the brightest idea. So the passwords are now encrypted!\nIf you have ever purchased something online you have likely encountered another form of encryption. Both SSL and S-HTTP are technologies that have been developed to protect such web activity. S-HTTP was designed to allow files and messages to be encrypted and then sent over the Internet. SSL on the other hand was developed to allow a secure connection between a browser and web server. In the case of SSL, all data that is sent can be encrytped rather than only messages S-HTTP. There are two levels of encryption 40-bit and 128-bit. The bit is the size of the key and the longer the key the more security.\nOther familiar uses of encryption involve ATMs. The magnetic strip on the back of an ATM card contains among many things an encrypted copy of your account number. With the given PIN number (key) this encryption is able to be verified and your account accessed. Without the PIN, the card is useless.Additionally, cryptographic technics are employed to protect the copyrighted material found on DVDs and CDs. And finally, all cell phone data that uses GSM technology, has its transmissions encrypted.\nCurrent Issues: Quantum Computing\nQuantum computers are computers that utilize the power of quantum mechanics\nto perform computational operations on data. They are fundamentally different from the\nclassical model of a computer. Whereas data for classical computers are encoded in bits,\nquantum computers employ quantum bits to represent data and to perform computation.\nThese ‘qubits’ can exist not only in the classical 0 and 1 states but also in a quantum\nsuperposition of both these states. When these ‘qubits’ are in this superposition of states,\nit can effectively perform an operation on both values simultaneously. Moreover, a pair\nof qubits can be in any quantum superposition of 4 states; therefore, it can perform on 4\nvalues at the same time. Similarly, a three-qubit system can perform on 8 values.\nGenerally, an n qubit system can perform an operation on 2n values simultaneously. This\nmethod by which quantum computers can perform simultaneous computations is called\nQuantum computers function by manipulating these qubits with a quantum algorithm. With large-scale quantum computers, these algorithms can solve certain problems in a fraction of the time taken by a classical computer. For instance, Shor’s algorithm can quickly factor large numbers. Factoring a 1000 digit number on a quantum computer with Shor’s algorithm would take twenty whereas on a classical computer it would take longer than age of the universe. As we can see, an implementation of Shor’s algorithm would have a severe effect on the field of cryptography because it would utterly undermine security provided by public key encryption. Cryptographers have thought that more digits added to the key can combat the increased performance of computers. However, with the power of quantum parallelism, the number of digits in the key has such a small effect on a quantum computer running Shor’s algorithm. The algorithm can crack RSA 140 in a matter of seconds.", "label": 1}
{"text": "An Introduction to Unix Permissions -- Part Two\nPages: 1, 2\nRemember from last week that what a user can do with a file depends on both the file's permissions and the directory's permissions. Let's make a test directory in our home directory to store some test files:\ncd mkdir testdir cd testdir touch testfile ls -latotal 2 drwxr-xr-x 2 genisis wheel 512 Aug 20 10:24 . drwxr-xr-x 14 genisis wheel 1024 Aug 20 10:23 .. -rw-r--r-- 1 genisis wheel 0 Aug 20 10:24 testfile\nNote the interesting behaviour with the times. The parent directory was last modified when\ntestdir was created, as its name had to be added to the parent directory's list. (Remember from last week that a directory is simply a file containing a list of the directory's contents). Similarly, the\ntestdir directory was modified the same time that the\ntestfile was created, as it also had to be added to its directory list.\nNow, I want you to\nlogin as a different user (other than root). Looking at the permissions for the testdir directory, will that user be able to\ncd into that directory, use the\nls command, read a file, change a file, create a file, or remove a file? As you try this exercise, remind yourself which permission is allowing or preventing that user from doing something in the\ntestdir directory. I'll\nlogin as the user\nexit login: bikoPassword:\nNote the shortcut to return to\ngenisis' home directory. Looks like the execute permission for everyone on\ncd into it.\nls -latotal 2 drwxr-xr-x 2 genisis wheel 512 Aug 20 10:24 . drwxr-xr-x 14 genisis wheel 1024 Aug 20 10:23 .. -rw-r--r-- 1 genisis wheel 0 Aug 20 10:24 testfile\nLooks like the read permission for everyone on the\ntestdir directory allowed\nbiko to list its contents.\nLooks like the read for everyone on the\ntestfile allowed its contents to be read. Even though the file was empty,\nbiko did not receive an error message.\ntouch myfiletouch: myfile: Permission denied\nbiko doesn't have write permission to this directory, so he won't be creating any files in it.\nrm testfileoverride rw-r--r-- genisis/wheel for testfile?\nyrm: testfile: Permission denied\nAgain, lack of write permission will prevent\nbiko from removing files from this directory.\nmv testfile ~mv: rename testfile to /home/biko/testfile: Permission denied\nThis is a move operation;\nbiko would need write permission on the\ntestdir directory for this to work.\ncp testfile ~\nThis copy operation was successful as\nbiko does have write permission on his home directory.\nls -la >> testfiletestfile: Permission denied.\nHere I was trying to append the results of\nls -la to the end of the testfile. If\nbiko had write permission, he would be able to do this.\nNow, how would we give\nbiko permission to create files in this directory but not delete any files which were created by\ngenisis? See if you can come up with a solution in both absolute and symbolic mode before testing your theory. Note, you have a choice of giving permission to the primary group, to everyone else, or to both. You'll have to log in as the original user who made the testdir directory in order to change its\npermissions. And don't forget to change your directory's sticky bit.\nNow is a good time to mention groups, as group membership is an important consideration when setting permissions. To see what groups you belong to, simply type:\nTo see what groups anyone else belongs to, add their login name to the end of the groups command like so:\nHere I have two users who don't live in the same group. If I wanted them\nto share a directory, I could set permissions on everyone, but this would\nalso give permissions to everyone else. Alternately, I could make them\nmembers of the same group and set permissions for the group. With this\nmethod, I may also have to change the primary group of the file using the\nchown command. Let's create a group called\nprojects and add these two users to it. Become root, as only root can make new users or groups. We'll use the\npw command to create the group; first, we'll type\npw to get the syntax:\nusage:pw [user|group|lock|unlock] [add|del|mod|show|next] [help|switches/values]\nThen we'll add a group with the fairly straightforward syntax:\npw group add projects\nThen we'll verify that it worked like so:\ngrep projects /etc/groupprojects:*:1006:\nOur new group is showing up in the\n/etc/group database with a group ID of\n1006. Now, I'll want to add the users\nbiko to the group like so:\npw groupmod projects -M genisis,biko grep projects /etc/groupprojects:*:1006:genisis,biko\nEverything looks good; one last test to verify:\ngroups genisiswheel projects\ngroups bikobiko projects\nNote that you can belong to more than one group at a time in FreeBSD. Now\nall we have to do is change the primary group of the\ntestdir directory so we can give permissions to just\nbiko. The user\ngenisis can do this, as she owns the directory, so we'll exit out of the root account and log back in as\ncd chown :projects testdir\nNote that the\nchown command requires a full colon (\n:) to indicate you want to change the primary group, not the owner of the file or directory.\nNow, let's see if the change was successful:\nls -la testdirtotal 2 drwxr-xr-x 2 genisis projects 512 Aug 20 10:24 . drwxr-xr-x 14 genisis wheel 1024 Aug 20 11:45 .. -rw-r--r-- 1 genisis wheel 0 Aug 20 10:24 testfile\nWe can now set permissions for the projects group, and it will only affect\nI'd like to end this article with some common permissions to set on directories that you create.\nIf you create a directory that will contain private data that you only\nwant yourself to access, set its permissions to\n700. Users will be able to see the directory, but they won't be able to\ncd into it, list its contents, or modify any of the files in it. Keep in mind that root is not subject to permissions, so nothing is really hidden from the root account.\nIf you wish to have a directory inaccessible to a group of users, set its\n705. This works, as FreeBSD stops reading permissions when it finds a match. This means that FreeBSD first checks to see if you are the owner of the file; if you are, you are subject to the owner's permissions. If you are not the owner, it then checks to see if you belong to the primary group of the file; if you do, you are subject to that\ngroup's permissions. If you don't, you are subject to the permissions of\nIf you want a group to be able to write files, but only delete their own\nfiles, set the directory's permissions to\nPractice reading directory listings to determine what you can and can't do\nwith a file. When you see a listing, think which\nchmod command would have set that permission. Before you know it, you'll be able to look at a\nlisting and know how to change its permissions so your users can do what\nyou want them to do.\nNext week, we'll do some customizing of the user environment by learning how to change our shell prompt.\nDru Lavigne is a network and systems administrator, IT instructor, author and international speaker. She has over a decade of experience administering and teaching Netware, Microsoft, Cisco, Checkpoint, SCO, Solaris, Linux, and BSD systems. A prolific author, she pens the popular FreeBSD Basics column for O'Reilly and is author of BSD Hacks and The Best of FreeBSD Basics.\nRead more FreeBSD Basics columns.\nDiscuss this article in the Operating Systems Forum.\nReturn to the BSD DevCenter.", "label": 1}
{"text": "RSA Encryption 'Crack' Rattles Infosec Industry\nA team of researchers say they've found a method for subverting RSA encryption. \"This could be a big deal because there may be applications out there vulnerable to this attack,\" said John Hopkins' Matthew Green. RSA, however, contends the danger attributed to the research is being exaggerated.\nClaims by a team of international cyrptographic researchers that they've \"cracked\" the RSA encryption used on a number of smartcards and secure tokens has set off a tempest in security circles.\nThe scientists from France, Italy, Norway and the United States have found a method for compromising the code in as little as 13 minutes. They plan to divulge more details in a paper they will present at the Crypto 2010 conference in August\n\"This could be a big deal because there may be applications out there vulnerable to this attack,\" Matthew Green, a professor specializing in cryptography in the computer science department Johns Hopkins University, told TechNewsWorld.\n\"I think it could be a serious problem, but I don't know of a concrete situation where it has allowed someone to attack a system,\" he added.\nRSA, though, contends the danger attributed to the research is being exaggerated. \"Our product isn't 'cracked,'\" RSA chief technology officer for identity and data protection Sam Curry told TechNewsWorld.\n\"You can get some things off a device, but you can't get the private key,\" he said. \"It doesn't let you clone it.\"\nIn public key cryptology, information is encrypted using a public key that's freely available to anyone. Information encrypted with a public key can only be decrypted with a private key that's paired to it. If someone could obtain a private key and make copies of it, or clone it, they could raise havoc with an organization's digital security.\nWebsites Getting Less Vulnerable\nDespite the daily tattoo of reports about infected websites spreading malicious software, a study released last week by White Hat Security found that website security has been improving in recent years.\nThe study of some 7,000 websites found that the average number of serious vulnerabilities per site last year to be 79. That's a 65 percent drop over 2010, when the average was 230, and part of what has been a steady downward trend since 2007, when the average was a staggering 1,111 per site.\n\"Websites are notoriously riddled with vulnerabilities,\" White Hat founder and chief technology officer Jeremiah Grossman told TechNewsWorld. \"Eight of 10 websites have something seriously wrong with them.\"\n\"Over time, though, the number of vulnerabilities we're finding in these websites is decreasing,\" he said. \"That's a good thing.\"\nOne reason cited by Grossman for the decline in vulnerabilities is greater security awareness among developers. \"Developers are getting better at writing more secure code and are seeing the importance in that,\" he observed.\nTurning False Positives Into Sales\nEvents that attract global audiences, like the recently completed Euro 2012 soccer tournament or the upcoming Summer Olympics, can be both good and bad news for online retailers. The good news is the events can give their sales a boost. The bad news is the venues are magnets for cybercriminals.\nTo fend off digital desperadoes, many retailers put rules and policies in place to block suspicious orders. Those rules, though, are often too broadly crafted. That results is lost sales of legitimate orders, according to David Britton, vice president of industry solutions for 41st Parameter.\nThe attack rate from online miscreants on a retailer during one of these global events is less than one percent of retail traffic, he explained. Yet, he told TechNewsWorld, \"We see as much as 7 percent of traffic being cancelled automatically and another 20 to 25 percent of traffic being held for suspicion of fraud.\"\n\"That amounts to an impact to your business of as much as 32 percent of either denied sales or delayed sales to solve a 1 percent fraud problem,\" he noted.\n- June 25: Employees of U.S. Commodity Futures Trading Commission, the country's top regulator of derivatives, were informed by management that the agency's systems were compromised in May and personal information, including Social Security numbers, of employees may be at risk. No trading or market data was affected by the breach, the agency said.\n- June 25: Two LulzSec hackers, Ryan Cleary (Kayla) and Jake Davis (Topiary) plead guilty to a spring hacking spree that included attacks on Sony, Nintendo, News International, the Arizona State Police, PBS and HBGary Federal.\n- June 26: The Alaska Department of Health and Social Services agreed to pay U.S. Department of Health and Human Services US$1.7 million for alleged violations of the Health Insurance Portability and Accountability Act of 1996 (HIPAA). The Alaskan Agency allegedly stored electronic health information on unencrypted USB devices.\n- June 26: The U.S. Federal Trade Commission filed a lawsuit against Wyndham Worldwide, the franchiser of Days Inn hotels and Super 8 motels for security breaches that led to more than half a million credit card numbers being compromised and fraud losses of more than $10.6 million.\n- June 26: U.S. prosecutors asked a federal court in California to order alleged \"Hollywood Hacker\" Chris Chaney to pay $150,000 in restitution and serve five years behind bars for compromising accounts of Scarlett Johansson and other celebrities during a hacking spree last year.\n- June 27: The FBI lowered the hammer in a sting operation resulting in arrest of two dozen suspected hackers in eight countries. The agency estimates the operation saved legitimate credit card users more than $200 million and protected 400,000 potential victims from fraud.\n- June 28: The University of Texas MD Anderon Cancer Center reported that a computer containing patient information was robbed from a physician's office in April. The university is still trying to determine what information was on the computer's unencrypted hard drive.\n- July 13: BSidesCleveland. Embassy Suites, Cleveland. Free.\n- July 19: Five Steps for Compliance, encryption, DLP and Email Security. 9 a.m. - 10:30 a.m., Sheraton Commander Hotel, 16 Garden Street, Cambridge, Mass. Complimentary continental breakfast. Sponsored by WatchGuard.\n- July 19: Securing the Cloud for Your Devices and Applications. 12 noon - 2 p.m., Sheraton Commander Hotel, 16 Garden Street, Cambridge, Mass. Complimentary lunch. Sponsored by WatchGuard.\n- July 21-26: Black Hat Conference/USA. Las Vegas, Nev. Registration: $2,195. Onsite: $2,595.\n- July 26-29: Def Con 20. Las Vegas, Nev. Registration: $200.\n- August 20-23: Gartner Catalyst Conference. San Diego, Calif. Early bird price (before June 23): US$1,995. Standard price: $2,295.\n- October 9-11: Crypto Commons. Hilton London Metropole, UK Early bird price (by August 10): pounds 800, plus VAT. Discount registration (by September 12): pounds 900. Standard registration: pounds 1,025.", "label": 1}
{"text": "It appears that before the \"bubble-burst\" in the late 1990s, little thought was given to the long-term effects that technology could have on business. IT budgets were large, and CIOs were buying into the idea that newer was better -- over and over again.\nOne legacy of that particular time was the distinct separation among the individual \"tech\" components within an organization. Within the IT departments, networking and server groups were formed along with application developers and \"voice guys.\" This practice continues in today's environment -- with one key difference: Newer technology is beginning to force these individual groups to unite and work together. Voice over IP (VoIP) brings the \"voice guys\" and \"networking guys\" together while such technologies as\nContent Delivery Networking (CDN) is a concept which essentially has that \"bridging\" effect within an organization. This week's tip gives an overview of CDN technology -- which employs several computers, or nodes, networked across the Internet to deliver large media content to end users -- and its components.\nA technology overlay\nA complete network architecture consists of several individual components, or infrastructures, whose purpose is to provide a service to the user community. An example of an infrastructure component could be consolidated file servers, which act as repositories for user files and application data. These servers sit atop another component of the architecture: the routing and switching infrastructure. The foundation for network architecture lies in the routing and switching infrastructure, which provides transport for all other infrastructure components and their various forms of data.\nCDNs are considered \"overlays\" to the routing and switching architecture as well, but they are unique to other infrastructures in that they have the ability to share characteristics of each of them. A CDN can bring together the functionality of file-access, caching, multimedia delivery and application processing -- while using the advanced policies of the routing and switching infrastructure to ensure survivability and guaranteed delivery. A CDN may have the ability to deliver this functionality, but the individual CDN components are key to making it possible.\nElements of a CDN\nTo deliver features such as file access and caching, a CDN must contain the following elements:\nThe \"request\" element of a CDN deals with the ability of users and systems to ask for specific content, whether it be a file or a video. Because a request occurs at the user end, protocols (such as WCCP) have been developed to intercept and redirect these requests to the hardware components or content engines closest to the user. Once a request has been made, the content engine can decide whether it can answer the request or proxy it on the user's behalf.\nThe \"distribution\" element of the CDN determines which decision (answer or proxy) is appropriate. Content has to come from somewhere within the architecture (origin servers), and based on patterns of use and requests, CDN administrators can distribute it appropriately. The choice of distribution, in turn, directly affects the details of a request.\nFinally, the \"delivery\" element is responsible for getting the content to the correct locations within the architecture. This element relies heavily on the routing and switching infrastructure for reliable and efficient delivery.\nHopefully, you now have an idea about CDN technology and the elements that make it an attractive choice for businesses. Next week, I'll break down some of the individual hardware components and introduce Cisco's integrated CDN products.\nAbout the author:\nDoug Downer (CCIE #9848 and JNCIS #881) is a senior consultant with Callisma Inc., a wholly owned subsidiary of SBC Communications. Doug has more than seven years of experience in the industry and currently provides high-level business and technology consulting for various federal clients in the Washington, D.C. area.\nThis was first published in May 2006", "label": 1}
{"text": "A ‘English Tutorials’ kategória archívuma\nIn this Article I am endeavor to do a demonstration in HTML5 to be introduced data storage modul (Web Storage) of a client side. Naturally it will not change the World as it seems – since the “cloud” we know that it will -, but nevertheless it assures a great option which we could solve only with different tricks so far (e.g.: Cookie). But the Cookie had many disadvantage (limited size 4KB, traffic through the forwarding per request etc.). Well on the other hands the HTML5 Web Storage by the current definition can store 5MB data per source. Plenty of data can be stored here. It is important aswell that no unnecessary traffic will spring up because it is not sending data only if we ask. (by the way it is not done to make 5MB storages)\nThe Web Storage itself stores the data in a key/value pair form and we can search back with this in a later time when we need it. The type of the key is text while the type of the value can be anything. Let’s see the types of the storage:\n1. Session Storage\nThe data will be stored here until the end of the browsing Session. After that they will be deleted (this can redeem the cookies). As long as the data will not be important to us in a later time, or for users, it is worthwhile to use this solution due to saving of the resources.\n2. Local Storage\nIt is a different case like the previous. The data will be stored here and remains until we will not delete the key/value pairs or the user will not do this with his/her browser. Now You could ask why is this so good? Because e.g.: if a user opens a new window he/she can get the data or if he/she quits from his/her browser and re-enter, the data will be available. Tovább olvasom »\nGot an idea from You that would be good to deal with the text marking a little bit. So I thought we should see some examples for the innovations and for the text marking aswell.\nLet’s see the things we should know about according to the texts. Starting with the basics our texts should take into paragraph with the <p> element. Long ago there was an attribute called “align” but it was disused in HTML4 too neither HTML5 support this. Its use is very simple:\n<p>It is a new paragraph</p>\nThe next is the <q> element which serves to insert short cites in. Some of the browsers show this between apostrophe. It has only one attribute. With its help we can mark the source where we cite from.\nFor this purpose we can use the <blockquote> element too. We can show longer cites with this but i recommend the use of the <q> element because in the case of the latter the browers running new paragraphs pell-mell. Its use the same as the element of <q>:\n<q cite=\"http://www.magyarorszag.hu/\">http://html5.ugyesen.com/ - HTML5 webportal</q>\nMore of You have indicated, that the lists and the changes of the lists have been out of the articles so far. Now I would like to dissolve this gap. In my opinion there are less changes that happened according to HTML4.\nYou can make lists (ordered: (<ol> … <li>) or unordered (<ul>…<li>) or mixed lists (ordered and unordered) in a similar manner. So far we had opportunity to create lists in html aswell so let’s see an example for this:\nThe build-up of an unordered list:\n<ul> <li>Budapest</li> <li>Pécs</li> </ul>\nThe build-up of an ordered list:\n<ol> <li>Budapest</li> <li>Pécs</li> </ol>\nWhat realy Geolocation is? The Geolocation modul of HTML5 returns the geographical position of device (computer, tablet, mobil etc.) that displays the webpage. We can send this to Google Maps. The only flaw is that it is not defined what helps to determine this location. (built-in GPS, based by cell informations or by IP Address etc.) If the Technical Specification in the final version is going to determine this a little bit specifically then we are going to get a very useful and fast spread tool in our hands.\nUntil that it is worthwhile to deal with this as curiosity. Unfortunately if there is no GPS modul in the device it can be locate our position approximately with 35-50km accuracy based by my experience. But I have got 200km deviation too. Let’s start then.\nChecking the browser.\nFirst of all we are going to check that whether our browser supports the new device or not. The code below only queries that our browser capable to use geolocation or not. If not then it returns an error signal. If it is capable then returns a blank screen. Tovább olvasom »\nThe working source can be available here. What is My IP? I put this up here because many of you seek.\nBefore we start the geolocation let me make a little retrospection. In this article we are going to see how we queried the data of browsers and users in the past. Our best assistance was the “user agent”.\nThe user agent acts as a client in a network protocol used in communications within a client–server distributed computing system.\nMost frequently people use this in case of World Wide Web access applications (web browsers, web crawler etc.). The browers forwarding the “user agent” to the web server which describes the client hardware platform, the operating system, the browsers type and version and its language settings.\nBrowser information Tovább olvasom »", "label": 1}
{"text": "|Posted by Jipol27Juper on February 1, 2011 at 8:23 AM|\nA brand new Pc, free of defective components, will operate perfectly smooth. Even as many years go by, as much more programs are installed in your program, your computer running slow may not be noticeable. If all of a sudden your pc keeps on freezing up or you notice a sudden slowdown, it may be attacked corrupt content material.\nDespite the reality that this really is extremely typical issue amongst users, not many of us actually know what might be affecting the machine. The factors are numerous and diverse such as not enough space in the tough disk or not sufficient ram. Nevertheless, before obtaining a brand new tough disk or much more ram, you need to consider that occasionally registry mistakes could be those to blame.\nThere are lots of slow pc solutions, but when the issue has not but been recognized it could be hard to fix. A virus, or a minimum of a malignant one, gives away particular signs and symptoms including your computer freezing, programs not opening properly, actions becoming blocked towards other knowingly safe applications, random shutdowns, and sudden pc slowness. A broken computer, or one that seems to become damaged, can frequently be fixed if a virus will be the trigger. Occasionally, although, a virus has already carried out as well a lot harm to become repair or recovered.\nA technical term of a computer malware is really a piece of software program that will duplicate itself and infect a pc. Although numerous other malicious applications like malware and worms are often confused with becoming viruses, they are, in fact, not, though for the objective of this article, it's irrelevant. All of them need to power to place a computer in a worse condition. Viruses come in numerous various types, and there are just as many names connected to these viruses. A Trojan horse virus will get its name from the well-known poem made famous by Homer. The Trojan horse virus pretends to become a plan, or pretends to become capable of doing a certain desirable action, and (possibly additionally to performing what it's supposed to) steals files or harms the program.\nInside the PCs working system there is a registry that's essential for that great functioning of the machine. The cause is because the software package works by scanning keys and information bits that are essential in the procedure of loading information and making hardware function around the machine. Remember the essential stage to think about is the registry.\nWhen the registry shows reviews of errors and corrupt entries is when your Pc begins to work much more gradually. Be cautious simply because in the event the registry is reporting too numerous mistakes, you may find problems running applications. This kind of registry problems arises whenever you ameliorate applications as well as whenever you set up a new program as well. If your antivirus software has detected spyware and it has to remove it from your machine you may also expertise registry errors.\nThe best form of protection against viruses is prevention. Newer variations of Windows come having a plan called Windows Defender that protects against spyware but does not safeguard against viruses. There are plenty of web sites having a free antivirus trial so you can test out which antivirus software program you wish to buy. Some individuals also wish to purchase or try anti-spyware software online. This really is also perfectly acceptable. Download from highly rated web sites, and also you cannot go wrong. A crucial stage to keep in mind, although, is that two antivirus applications running in the exact same time isn't recommended. Two antivirus programs doesn't equivalent twice the protection. In fact, two antivirus applications will wind up fighting each other for priority, and then they'll each wind up not working properly.\nYou are able to get a registry cleaner plan on the internet. In fact you can access a scan and the possibility to repair little mistakes with out needing to buy the product. When you get it, you'll not be questioning \"why is my computer running slow ?\" actually again. I personally managed to clear up my pc by downloading higher high quality registry cleaner software program.", "label": 1}
{"text": "(NaturalNews) It's a concept that is anathema to most of today's military pilots: Fighter planes without a human being at the helm.\nYet, that's the next generation of strike fighters that are going to be produced by the United States, according to a number of analysts. In fact, the Navy already has its own version making test flights.\nThe X-47B, manufactured by Northrup Grumman, was unveiled by Navy officials this month as a pilotless, remote-controlled weapons platform that will ultimately be flying missions from the decks of American carriers. Officially known as the Unmanned Combat Air System, the drone-like strike fighter is currently undergoing flight tests at the Patuxent River Naval Air Station in Maryland. Eventually, officials say, the platform will carry weapons, though none are being placed on board the current test model.\nAccording to the manufacturer, the X-47B will make its first carrier landings.\n\"Under a contract awarded in 2007, the company designed, produced and is currently flight testing two X-47B aircraft. In 2013, these aircraft will be used to demonstrate the first carrier-based launches and recoveries by an autonomous, low-observable-relevant unmanned aircraft,\" Northrup Grumman said, adding that the aircraft will undergo aerial refueling testing the following year, in 2014.More testing on the horizon\nThe aircraft program has steadily matured. The X-47B's first successful test flight occurred Feb. 4, 2011, which consisted of a short flight of just 29 minutes, to a ceiling of 5,000 feet. Since then, follow-up testing has improved on the craft's capabilities and has demonstrated its potential.\nIn some of the latest flight tests that took place earlier this year, the aircraft\nclimbed to 15,000 feet and undertook \"multiple maneuvers that are essential for using an aircraft carrier as its base of operations including extending and retracting a tail hook needed to catch the carrier's arresting wires upon landing and 'touch-and-go\" landings,\" Forbes\nOfficials said part of the carrier tests would include so-called \"bolter\" runs, in which the tail hook fails to catch on the carrier deck and it must immediately take off again. The craft will also undergo wave-offs, in which the operator will have to abort a landing.\nsaid the goal of the X-47B program is to provide the military with an \"unmanned air system capable of providing persistent, penetrating surveillance, and penetrating strike capability in high threat areas.\" The aerial refueling element means the aircraft could stay aloft for extended periods, perhaps even taking on several pre-programmed missions, so long as conditions remained favorable and its weapons lasted.\nAlso, it's tailless design and special composite body makes the X-47B harder for radar to detect, adding a stealth element that will prove vital in covert operations especially.More than just military applications?\nWhat's more, the capability could expand into other aircraft markets.\n\"Even more exciting than the X-47B is the technology to fly aircraft with a laptop and a click of the mouse instead of a joystick and human pilot,\" said a report in Discovery News\nSuch technology exists even for cargo and commercial aircraft, experts say, but right now, the risk is too great.\n\"You could build one. The question is: Would you be allowed to operate it?\" John Hansford, director of the Center for International Air Transportation\nand a professor of aerospace engineering at the Massachusetts Institute of Technology\n, told the Web site.\n\"We already have the technology to take an existing commercial-scale airplane -- say an Airbus 320 or Boeing 777 -- and convert it to unmanned operations,\" he said. \"However, it's not clear yet that you could guarantee the safety of that to a level that would be acceptable for general public transport. If it has a problem, then it becomes a hazard to people on the ground.\"Sources:http://news.discovery.com/tech/navy-fighter-drone-120802.htmlhttp://www.forbes.comhttp://www.as.northropgrumman.com/products/nucasx47b/index.html\nHave comments on this article? Post them here:\npeople have commented on this article.", "label": 1}
{"text": "How to protect your PC\nBeing an Internet user you should know how necessary is to protect your PC from different malware, viruses and worms. Be sure to prevent is better than to cure.\nThe traditional method to provide you computer with additional protection\nUsually people try to use multiple signature scanners that include anti-viruses, anti-trojans, anti-spywares and anti-rootkits. Very often these tools cost too much and afford too little additional protection.\nAn up to date antivirus will find a lot of spyware while an anti-spyware program will also detect several Trojans, viruses and worms as well.\nYou should know that adding the “layer” of protection you will get not only a better protection but also several false positives. One of them is that you will suffer from long time load on your computer. It means that having good firewall together with an antivirus and antispyware tool will diminish returns.\nSometimes a specific malware that has penetrated your PC can disable all the layers of protection considering them useless.\nWell, how to prevent infection?\n- Keep your OS and MS Office completely updated. Check if your update settings are automatic.\n- If you use Firefox, Adobe products, Flash plug-ins and other useful software you should update them as well.\n- Choose the alternative software. Sometimes popular programs are worse than others because of high weight and its “popularity” among malware writers.\n- Be cautious while surfing. Avoid visiting web pages that offer serial numbers, keygens, AVG LinkScanner, etc. These free offers very often have hidden plug-ins that attend site security ratings.\n- While checking email never open the attachments from suspicious sources. Also don’t click on the links in email from unknown senders.\n- Download software from the websites you can trust. Install the program just when you are confident it doesn’t include infection.\n- Be sure that your firewall is turned on. You can use your Windows’ firewall or a firewall with outbound protection.\n- Disable AutoRun function.\nBasically even the above tips won’t guarantee 100% protection. Even a trusted source can be infected with malware. So you need more protection than a basic security service.\nProvide with a better protection\nTake care of your normal Windows environment. This is what you are using now, your default setup in Windows.\nThere are few ways to keep all malware away from your normal Windows account.\n- For your daily work use limited user account\n- High risk programs need to be run with limited rights\n- While testing high risk programs you should have a sandbox\n- Use policy restrictions while running high risk programs\nEach point has its advantages and disadvantages. That’s why you need to find all necessary information about it and to analyze them individually.\nAlso you can try on-demand scanning. It can be represented by antivirus scanner, key logger scanner or a rootkit detector. An on-demand scan is a scan when you initiate it manually.\nThis type of scanning helps you to use only computer power. Try anti-spyware scanner like Super Antispyware or Panda Antirootkit. These are free and very effective. Run them weekly or monthly. It will give additional protection to your antivirus program.\nFinally you should understand that day by day there appear new malware programs. Absolutely none of antimalware programs can provide you with 100% protection.\nChoose your security method and remember that an ounce of prevention is worth a pound of cure.\nHow to protect your PC\nTypes of Viruses\nMalware: A General Overview\nA Quick Analysis of a PC Virus\nProtecting Your PC from Spyware\nPreventing Macro Viruses\nWrite a comment\n- Required fields are marked with *.\nFree Antivirus Software\n- Free Antivirus Software\n- Free Online Virus Scan\n- Free Trojan Removers\n- Free Adware/Spyware Removers\n- Free Antivirus for Android\n- Free Antivirus for Mobile\n- Free Firewall\n- Free Rootkit Removers\n- Free Spam Filters\n- Free Advanced Spam Filters\n- Free HIPS (Host Intrusion Protection Software)\n- Free Antivirus for MAC\n- Free Antivirus for Linux", "label": 1}
{"text": "2010 Report: Public Health Preparedness\nSection 1: A National Snapshot of Public Health Preparedness Activities\nSurveillance and Epidemiology: Monitoring and Investigating Health Threats\nSurveillance and epidemiology are core public health functions that detect community health threats, investigate their sources and patterns of distribution, and monitor their impacts. These data are used to help in making decisions on actions meant to control or prevent disease or injury.\nSurveillance: Data for Monitoring Health Threats\nPublic health surveillance is the ongoing, systematic collection, analysis, and interpretation of health data, and the dissemination of this information to those who need to know. Surveillance data may describe health problem trends, detect epidemics, provide details about disease patterns, monitor changes in disease agents like viruses (through working with laboratorians), help determine the most effective mitigation strategies, and evaluate the effects of control and prevention measures.\nPublic health officials use different types of surveillance data as a basis for decision making to protect the public’s health. One of the first examples of a public health action stemming from the use of surveillance data likely occurred during the bubonic plague in the 14th century, when authorities boarded ships to prevent passengers with plague symptoms from coming ashore. Many early surveillance systems were based on identifying and reporting cases of disease.\nIn the United States, surveillance systems are a collaborative effort between CDC and its many partners in state, local and territorial health departments; public health and clinical laboratories; vital statistics offices; healthcare providers; clinics; and emergency departments. These surveillance systems resources helped support decision making by public health officials during the 2009 H1N1 influenza pandemic response (see boxes below and on next page).\nCurrent surveillance systems at the local, state, national, and international levels need to improve to meet the nation’s growing challenge to manage and integrate data from a variety of different sources, ensure that decision makers have access to the data, and exchange data with other federal agencies and with public health partners. In 2007, Homeland Security Presidential Directive 21 called for the development of a nationwide approach to enhance the United States’ ability to detect and respond to health-related threats. The National Biosurveillance Strategy for Human Health, an effort coordinated by CDC for the U.S. Department of Health and Human Services, provides a plan for building a nationwide, next-generation capability designed to generate timely, comprehensive, and accessible information for public health and clinical decision making.36 The Strategy established six priority areas: electronic health information exchange, electronic laboratory information exchange, unstructured data, integrated biosurveillance information, global disease detection and collaboration, and biosurveillance workforce.\nEpidemiology: Investigating Health Threats\nEpidemiologists – known as “disease detectives” – work closely with laboratorians to identify health threats, determine their patterns in a community, and estimate their effects. They might identify contaminated food causing illness, assess the number and locations of people injured and types of injuries resulting from a disaster, or determine causes of a sudden onset of fever in a community. Epidemiologists also work to minimize the negative effects of community health threats.\nDetection depends on accurate and complete surveillance data. Problems can arise if data are not available, especially for state and local health agencies. In particular, health problems may not be identified early and public health interventions (e.g., the provision of treatments or vaccines) may be delayed.\nEpidemiologists conduct targeted investigations and surveys that complement surveillance to validate and identify the causes and effects of a health event. Analyses of these data can produce criteria (e.g., specific symptoms) for determining whether a person should be counted as affected by the particular event, the characteristics of those affected (e.g., age, medication use, socioeconomic status), and the geographic extent of the event. Further studies help identify populations at increased risk for the disease or other health event.\n|Number of epidemiologists working in state health departments||2,498||2,193||12%|\n|Number of state health departments reporting substantial-to-full capacity in bioterrorism/emergency response||41||237||10%|\nSource: Council of State and Territorial Epidemiologists\nCDC epidemiological support to states and localities for FY 2008 included 26 Career Epidemiology Field Officers (CEFOs) located in states and localities supported through state Public Health Emergency Preparedness (PHEP) funding. CDC also deployed 71 field officers from its Epidemic Intelligence Service (EIS) to conduct 319 investigations in the same year. EIS is a two-year epidemiology training program modeled on a traditional medical fellowship. Officers in this program support states during responses to routine public health incidents and large-scale national emergencies. CEFOs are experienced, fulltime epidemiologists located in state and local public health departments to enhance and build epidemiologic capacity for public health preparedness and response.\nState epidemiological capacity continues to decline. A 2009 assessment37 by the Council of State and Territorial Epidemiologists reports that national epidemiological capacity has been eroding since 2004 (see Table 1). This trend contrasts with the significant increase in the number of epidemiologists that took place during 2001–2004, when emergency response and preparedness funds fueled rapid growth in the number of new and replacement epidemiologists in the public health workforce. The 2009 assessment also suggests that nearly 20% of current public health epidemiologists anticipate retiring or changing careers in the next 5 years and recommends that federal, state, and local agencies develop a strategy to address these projected downward trends and major gaps.\nAssessing Capabilities for Surveillance and Epidemiology\nCDC is developing performance measures related to surveillance and epidemiological capabilities. PHEP-funded states, localities, and U.S. insular areas will be required to report on measures that address the following:\n- Timely recognition of a potential health emergency through disease reports submitted to public health agencies\n- Ability to investigate an outbreak or exposure, summarize findings, and make improvements to the investigative process\n- Timeliness of initiating interventions to limit the spread of disease\nThe intent of these new measures is to demonstrate an ability to turn data into actionable information that supports decision making in a public health emergency. For more information on new performance measures, see the Moving Forward section.\n- Page last updated September 21, 2010\n- Page last reviewed September 21, 2010\n- Content source: Office of Public Health Preparedness and Response (OPHPR, formerly the Coordinating Office for Terrorism Preparedness and Emergency Response [COTPER])\nGet email updates\nTo receive email updates about this page, enter your email address:\n- Centers for Disease Control and Prevention\n1600 Clifton Rd\nAtlanta, GA 30333\nTTY: (888) 232-6348\n- Contact CDC-INFO", "label": 1}
{"text": "Sidebar Site Navigation\nWhat is it?\nIdentity theft happens when someone else uses your personal information to open credit accounts in your name. Since the accounts are in your name, you can be liable for any charges made to them.\nHow does it happen?\nIdentity thieves take personal information from you out of your mailbox, your garbage, off of canceled checks, etc. Accounts can be opened with your name and address or your social security number.\nHow do I know if I've been a victim?\nChecking your credit report regularly will keep you apprised of what accounts are being credited to you. While not every inaccuracy in your credit report is an indicator of identity theft*, keeping track of what is yours and what you don't recognize on your report will let you know if someone else is using your credit.\n*Sometimes inaccuracies can just be due to poor record keeping on the part of the credit bureau. Yes, it does happen. The author of this article had her credit merged with a random man by the credit bureau.\nWhat do I do if someone steals my identity?\nUnder the Fair and Accurate Credit Transactions Act (FACTA), credit bureaus are required to place a fraud alert in the file of a consumer who believes he or she has been a victim of identity theft. That person must request it. The fraud alert can last from 90 days to 7 years, depending on what you request. Once an alert has been placed on your file, no new accounts can be opened with your information while the fraud alert is active. That means no one can open a new account, not even you. Further, anytime anyone requests information about your credit, the bureau may block information and must inform the requester of the fraud alert.\nWhen you discover or become suspicious that you are or may be a victim of identity theft, contact the credit bureaus and let them know as soon as possible. Do this to avoid being liable for charges made on accounts opened in your name by a thief.\nYour credit is your reputation. Take good care of it. Guard it. While there are ways to fix problems with your credit report, monitoring it is a good way to prevent your credit from becoming a mess.\nFor more information concerning identity theft, how to prevent it, and how to handle it if it's happened to you, see:\nHow Safe Are You?\nWells Fargo Bank has a quiz on its website to test how safe you are from identity theft as it relates to your bank and credit card accounts. It can be found here:https://www.wellsfargo.com/privacy_security/fraud/protect/quiz/\nSome basics on keeping your identity safe:\n- DO NOT carry your social security card in your wallet. It should be stored at home, in a safe deposit box, anywhere else that is safe and less likely to be lost or stolen.\n- DO NOT give out your social security number. Don't use it as a password, a customer number, a PIN number, or any other way that would make it less secure and more open to prying eyes and ears.\n- DO NOT volunteer personal information over the phone to people whose identity you cannot verify.\n- DO NOT respond to e-mails from senders claiming to be your financial institution, asking you to click on a link and change your information.\n- DO shred bank statements, credit card receipts and statements, and anything else with your address and account numbers on it, rather than simply tossing them. Identity thieves are dumpster divers. They don't mind a little muck if it means a new life for them yours.\n- DO be aware of your financial institution's way of handling possible identity theft.\n- DO be aware of online payment systems' policies for handling customer accounts (i.e., PayPal never sends out e-mails that simply say, \"Dear Customer.\" They ALWAYS use your name. NEVER click on links in e-mails that don't address you by name from PayPal. Just one of many)\n- DO keep your credit card numbers and credit card companies' phone numbers in a file so you can call and report lost or stolen cards", "label": 1}
{"text": "What is Malware?Malicious software (malware) is the wide range of software applications developed with a malicious intent. The methods used for malware installation is unlike any other software installation you are accustomed to because malware is installed through devious means. People often use the terms virus and malware interchangeably. However, a virus is a type of malware. Other major malware types include:\nA virus contains malicious code that attaches itself to an application. When the infected application is executed, the virus is launched and will attempt to spread to other computers. A virus typically will not cause immediate damage as it needs time to replicate in order to infect other computers. Eventually, the virus will deliver its payload. The payload can cause significant damage such as deletion of critical system files, random reboots of your computer, and can corrupt hard drives and make them unbootable. Viruses are delivered to systems in a variety of ways. Email is the most common method for spreading viruses. For example, spammers will email viruses as attachments and will entice users to download and open the attachment, which in turn will execute the virus. Users can also transmit viruses by using infected USB flash drives. Most operating systems have Autorun enabled, which enable infected USB flash drives to execute the virus as soon as the device is plugged into the machine.\nTrojan horses trick users by posing as legitimate applications. For example, a Trojan horse may appear to be a game or a screensaver. A deceived user will download the application and the Trojan horse is released once the user executes the program.\nUnlike viruses and Trojan horses, worms do not need to be executed. Worms reside within memory and can travel throughout a network without depending on an infected computer application or interaction. Worms replicate themselves exponentially and can literally crash networks by consuming its bandwidth.\nSpyware is installed on a machine without the user’s awareness or consent. Spyware attempts to gather specific user information and send it to a third party. You can determine if your computer is infected with spyware if your Internet home page has suddenly changed, if your web browser redirects web searches, or if additional software has been installed on your machine. Another form of spyware is adware. Adware launches pop-up windows to display unwanted advertisements.\nA logic bomb is malicious code embedded within an application that executes based on certain events. The logic bomb lies dormant until that event occurs. The event may be when a specific date is reached or if an employee’s record is removed from an organization’s payroll information system.\nA rootkit is the combination of programs designed to infect your computer without being detected. Your antivirus application communicates with your operating system to identify threats. However, rootkits breaks down this communication process. Consequently, your antivirus software will think that everything is fine and will not report that your computer is infected.\nYou can find security tools that will protect your computer from the above threats. In most cases, one tool is not enough. You may need to use a combination of utilities to fully project your system. Understanding the major types of malware can help you make informed decisions about acquiring tools to project your computer.", "label": 1}
{"text": "I deal with a lot of customers who area worried about Windows password attacks. These days, the biggest fear is of pass-the-hash attacks, a topic I've written about many times in the past couple of years.\nOften, when customers voice concern about pass-the-hash attacks, they ask me about cached log-ons in Windows. They've heard about the vulnerability and have read one or more whitepapers about it. Even Microsoft recommends disabling cached log-ons.\n[ Brace yourself for IT's 9 biggest security threats. | Find out how to block the viruses, worms, and other malware that threaten your business. | Learn how to protect your systems with InfoWorld's Security Central newsletter. ]\nIn fact, cached Windows log-ons aren't a big risk at all. I'll tell you why in a minute, but first, let's review the basics.\nHow cached passwords work\nWhen a user successfully logs on to a Windows computer for the first time, Windows creates a local user profile folder to store desktop and other user-related settings. For domain users, Windows will store a cached log-on as well. With future log-ons, if the domain user attempts to log on to the same domain but the Windows user cannot successfully contact a domain controller, Windows will log on the user locally if the user submits the same password (or other authentication credentials) entered in the last successful domain log-on.\nA common use for cached log-ons is to serve traveling laptop users. When the laptop user is connected to the home domain network, log-ons are verified by the domain controller. But when the laptop is away from its home domain, the user can still log on and use Windows because of the cached information. The password (or authentication credential) used during travel must be identical to the one previously cached while on the home network. When away, the submitted password is verified against something called the cached log-on password verifier, which is a one-way function of the user's previously submitted password.\nA case of mistaken identity\nIn thinking about cached log-on verifiers, users often make the error of equating them to normal password hashes (such as LANManager or NT hashes) that computer hackers are always stealing, replaying, and cracking. Fortunately, they aren't the same. The mistaken assumption is reinforced by Microsoft's recommendation, as documented in the Microsoft Security Compliance Manager tool, that cached log-ons be disabled.\nThe default cached log-on setting (located in group policy objects at Computer Configuration/Windows Settings/Security Settings/Local Policies/Security Options/Interactive Logon: Number of Previous Logons to Cache) is usually around 10 cached log-ons. This default setting goes back to Windows NT 4.0, if not longer. Now, Microsoft recommends that cached log-ons be set to 0, which disables it.\nThe bad thing about disabling cached log-ons is that many computers could be difficult to log on to, or even to troubleshoot or repair, if the computer cannot reach a domain controller. Many computers, even ones that never leave the home network, suffer quick, transient network problems, which cached log-ons help overcome.\nThe confusion over the security risk of the cached log-on seems to ensnare lots of Windows security experts. I've read more than a few security papers that have characterized removing cached log-ons as a highly critical recommendation. I have seen respected computer security firms find cached log-on verifiers on their customer's networks and point them out as hacking vectors that need to be addressed immediately.", "label": 1}
{"text": "Trusted name resolution with DNSSEC\nChain of Trust\nSome Internet exploits target name resolution servers. DNSSEC uses cryptography to protect the name resolution service.\nSystem administrators and security consultants have devised elaborate strategies for protecting computer networks, but one very basic part of the Internet infrastructure is still surprisingly vulnerable: the name resolution system. Intruders have developed sophisticated techniques for spoofing DNS responses. Of course, the white hats have fought back with their own defensive maneuvers, but experts agree that a fundamentally different approach is necessary. The DNS Security Extensions (DNSSEC) system  offers a comprehensive solution for authentication and data integrity for DNS.\nDNSSEC adds cryptographic signatures to the legacy name resolution service. But a signature can't solve the problem alone (because an attacker can create a signature, too). DNSSEC also needs a method for authenticating the public key used in the asymmetric encryption, which means the system must provide its own form of Public Key Infrastructure (PKI).\nTo help DNSSEC succeed, two groups must make a contribution: Users can only benefit from the system if network managers provide servers that use DNSSEC responses to validate their users. Name server managers must sign their zones and integrate them with the chain of trust in the superordinate zones . The free ISC BIND name server, which many regard as being a DNS reference implementation, provides solutions for both these objectives .\nDNSSEC name server extends its zone file. Besides administrative information in the SOA record, it mainly contains RRs that support mapping of DNS names to IP addresses or vice versa. DNSSEC uses signatures to protect the RRs. To do so, the DNSSEC introduces another series of RRs, as listed in Table 1.\nBecause the DNS system typically resolves names through a hierarchical chain of interacting name servers, DNSSEC can only guarantee authenticity if it operates at all levels of the chain. A complete solution therefore requires the adoption of DNSSEC on a massive scale. So far, the Swedish .se domain is the only top-level domain signed with DNSSEC, but many organizations have started implementing and experimenting with DNSSEC at lower levels. In this article, I will look at trusted name resolution with DNSSEC.\nPublic Keys for DNS\nThe first thing you will need is a resolver that supports DNSSEC. Because most stub resolvers can't do this – and the one in libc is no exception – administrators on enterprise networks will need to install a name server and enable its DNSSEC functionality.\nNow, thanks to DNSSEC, when clients on the network ask the server for IP addresses, the name server is guaranteed to return reliable results. Of course, the hop between the client and the first server is not safeguarded and theoretically could be manipulated. If you are responsible for security on your network, you will need to decide on an individual basis whether to take this lapse seriously.\nThe DNSSEC resolver now checks to see whether the query is for a DNSSEC-secured zone. If the requested target is on a secure island, this is always true. The top nodes in these structures are referred to as Secure Entry Points (SEPs, see Figure 1). Admins must make these entries the top priority on the DNSSEC resolver. Thus, the list of SEPs is the functional equivalent of providing CA certificates to a web browser.\nDNSSEC uses the same access mechanisms as legacy DNS. Because the resolver only requests Resource Records (RRs) from a server, the system is downwardly compatible. Additional security is provided by a DNSSEC-enabled resolver validating the signatures in the RRs. If a response is not correctly signed, it is discarded.\nBecause the user is never tempted to use a potentially compromised response, this is a very secure approach. However, users must get used to the server responding with NXDOMAIN, which means \"this domain does not exist.\"\nIn contrast to this, PKI will pop up a window with web certificates in the same situation. The user can decide how to react to the invalid certificate; unfortunately, many users just ignore the warning.\nIf the response does not come from a secure island, the resolver will resort to legacy methods to resolve it and then return the response to the requesting client. Security admins should be aware that, if they use DNSSEC, the user will not be able to tell whether or not a response is authenticated by DNSSEC.\nIn the long term, the DNSSEC lobby seeks to have just a single SEP that points to the DNS root zone. A chain of trust links the signing key with all the zones below it in the hierarchy. This lets DNSSEC resolvers validate signatures. On the Internet today, this is not the case, in that it is still just interspersed with independent secure islands. Until the islands grow together, resolver administrators still need to manage multiple trusted keys as SEPs.\nRichard Stallman calls for the W3C to remain independent of vendor interests.\nThe new release supports nine architectures, 73 human languages, and zero non-Free components.\nFedora developers release the first alpha version of Fedora 19, known as Schrödinger’s Cat, for general testing. The final release is expected in July 2013.\nack is a grep-like, command-line tool that has been optimized for programmers to search large trees of source code.\nNew features in SUSE Studio 1.3 include enhanced cloud integration, VM platform support, and lifecycle management.\nThe Linux Foundation recently announced that the Xen Project is becoming a Linux Foundation Collaborative Project.\nOpen source version of LiveCode is now available for developing apps, games, and utilities for all major platforms.\nOpenDaylight is an open source software-defined networking project committed to furthering adoption of SDN and accelerating innovation in a vendor-neutral and open environment.\nThe new Gnome release includes privacy and sharing settings, allowing more user control over access to personal information.\nMozilla is collaborating with Samsung on a new web browser engine called Servo.", "label": 1}
{"text": "This article can also be found in the Premium Editorial Download \"Virtual Data Center: What is cloud computing, and what can it really do?.\"\nDownload it now to read this article plus other related content.\nCloud computing got a big boost in credibility recently when major vendors jumped on board. But\nlost in the swarm of announcements are questions about what cloud computing is and what it can\nMany data center managers envision cloud computing as the ability to pool resources, charge customers based on actual usage and tap into extra external capacity when needed. This view of cloud computing is becoming possible through a blend of technologies like virtualization, Software as a Service, and Web-based applications.\nBut to achieve this computing nirvana, there are several questions about how clouds will work—and how companies’ technology architectures will work with cloud architectures. How can data center managers tap into cloud computing? And should they? How will cloud computing affect data centers with more than 1,000 servers? Which architectural and technological decisions affect a company’s ability to use and exploit cloud computing?\nThese critical questions will likely arise repeatedly as data center managers begin to navigate vendor hype to uncover the realities of cloud computing as well as its possible benefits for their organizations.\nNuts and bolts of the cloud\nTo start, it’s important to know that there are external clouds—such as pooled resources provided by third parties like Amazon and Google—and internal clouds—such as pooled resources internal to a company. The interaction between external clouds and internal\nSome related considerations include the following:\n- How well does a cloud-computing scenario work for many of today’s noWeb-based applications, or does truly harnessing the cloud paradigm require that organizations “re-architect” several internal applications?\n- How does an organization manage network connectivity between its private internal cloud and external cloud resources?\n- How can organizations provision, configure and customize external cloud resources appropriately?\n- How do external cloud resources gain access to the internal data they require in order to operate?\n- For applications running in the external cloud, how much bandwidth is required so these applications can access the internal data they require?\n- How does an organization provide access control?\nExisting technologies—such as virtual private networks and data replication— can address some of\nthese issues. VPNs, for example, can provide connectivity between external clouds and private\nclouds. And many VPN solutions also provide access control lists, or ACLs, for traffic running\ninside the tunnel, giving organizations fine-grain control over the traffic that moves from a\nprivate cloud to an external cloud. This approach helps to ensure that only authorized external\ncloud resources are allowed to communicate with appropriate resources in the private cloud and only\nvia authorized ports and protocols.\nData replication technologies may be able to address the need for external cloud resources to access certain data sets in order to function correctly. Vendor-independent replication technologies—those that are not tied to a particular storage vendor’s hardware, for example—will be particularly useful in this case, offering organizations and service providers alike greater flexibility and compatibility.\nAt the same time, however, VPN technologies and data replication topologies must be coordinated between an organization and its service provider and, therefore, can create some degree of vendor lock-in. Successfully using these technologies to solve practical challenges of cloud computing will require IT organizations and their service providers to work together much more closely than ever before.\nAs a result, the tight coordination of such technologies doesn’t extend to the rest of a cloud-computing solution. These close ties between an organization and a service provider make it more difficult and more costly for organizations to switch cloud-computing providers, effectively reducing portability.\nAlso, as the ecosystem of virtualization hypervisors becomes increasingly competitive—with Citrix Systems Inc.’s XenServer and Microsoft’s Hyper-V poised to compete with the market leader VMware Inc.—there are other factors undermining portability. Given that virtualization typically plays a significant role in cloud-computing environments, particularly in private clouds, the interoperability of hypervisors from different platforms and guest virtual machines (VMs) is a key factor in portability and, by extension, the widespread adoption of cloud computing.\nThese factors introduce even more issues. For example, will organizations be able to make a VMware ESX-powered internal cloud work properly with a XenServer-powered external cloud, and vice versa? Will an organization that currently uses a VMware ESX-powered external cloud be able to switch to a XenServer-powered external cloud? Will service providers be able to mask that complexity for users?\nVirtualization vendors now tout interoperability, hoping to answer these questions, but users have yet to see significant progress on this front.\nThree major areas of interoperability that have yet to be addressed are VM definitions, virtual\nhard disks and para virtualized device drivers. Until efforts to address these areas bear results,\ndata center managers need to be wary of the claims of seamless scaling and fluidity that cloud\ncomputing supposedly offers. Leveraging cloud computing today may reap benefits for some\norganizations and some applications, as long as data center managers are fully aware of—and plan\nStumbling over cloud-computing compatibility\nWork is already being done to address the key compatibility issues: VM definitions, virtual hard disks and para virtualized device drivers. Some of these efforts, though, are still early in development. For example, on the VM definition or configuration front, the Open Virtualization Format (OVF)—also referred to as Open Virtual Machine Format—has been approved as a standard, yet broad support for the format is still lacking.\nVMware has the most complete implementation, while Citrix, Microsoft, Novell Inc. and others lag\nbehind. Organizations that want to leverage cloud computing should not count on using OVF to help\nprovide greater compatibility until all of the major vendors have shipped OVF support in their\nproducts. Note that some vendors have announced support for OVF, but that support has yet to be\ndelivered to users in the form of actual products. Furthermore, adoption of the standard doesn’t\nnecessarily resolve other key cross hypervisor compatibility issues.\nVirtual hard disk formats, in the form of VMware’s Virtual Machine Disk format and Microsoft’s VHD formats, pose another compatibility issue. The OVF specification supports both formats, and each vendor offers the ability to read or convert another provider’s format, but what about native read/write functionality?\nMicrosoft and Citrix each have a slight upper hand here, in that both natively support the VHD format, but VMware’s Virtual Machine Disk format is the market leader. Both camps have taken steps to make their virtual hard disk formats the default by opening up specifications to third-party developers, but neither format has emerged as the clear, de facto standard.\nThe use of hypervisor-specific para virtualized device drivers is another key compatibility\nissue that the virtualization industry has yet to address. All major virtualization providers use\npara virtualized device drivers to optimize performance of VMs running on their virtualization\nplatforms. VMware Tools, Microsoft’s enlightenments and Citrix’s Xen Tools are examples of para\nvirtualized device drivers. Again, by virtue of their interoperability and cross-licensing\nagreement, Microsoft and Citrix each have a slight advantage here, making it more likely that\nXenServer and Hyper-V VMs will be compatible in this realm.\nBut VMware still controls the lion’s share of the market. This dominance leaves customers without a clear standard on para virtualized device drivers in cross-virtual platform environments.\nSo how have the major vendors tried to address these key issues? It’s worth noting that the big three players in this area—VMware, Microsoft and Citrix— have taken different approaches to address the challenges for widespread adoption of cloud computing. Here is how each positions itself:\nVmware: Hoping to leverage its market leadership in the cloud-computing space, VMware’s\napproach lies in its vCloud initiative, which is based on its close partnership with service\nproviders, the use of virtual appliances and vApps, and the ubiquitous presence of the ESX\nhypervisor and supporting applications, in particular vCenter, formerly known as VirtualCenter.\nVMware intends to partner with several service providers that will use its software to build\nexternal clouds powered by the ESX or ESXi hypervisor and that are managed—or manageable —by\nTogether with virtual appliances and vApps, the OVF standard enables portability between these external and internal clouds. The vApps technology can be considered an extension of the OVF standard and can incorporate information about that application’s service-level agreement, disaster recovery requirements, security needs and other policy information. With vApps and the OVF, organizations could move applications from one “VMware-ready vCloud” to another relatively easily.\nAnd, because service providers offer ESX- or ESXi-based virtualization, it means that applications—in the form of vApps, virtual appliances or VMs with an OS and application installed—can be easily shared and transferred between internal and external cloud infrastructures. VMware has said that it plans to expose vCloud application programming interfaces (APIs) that enable even greater integration between internal cloud infrastructures and external cloud providers.\nIn that particular scenario, organizations would use VMware vCloud when they use VMware virtualization internally by “federating” a private cloud with an external VMware-ready vCloud service provider. Although the precise mechanics are yet unknown, the idea is that organizations could then move workloads from an internal cloud to an external one or spin up additional VMs at the external provider to handle additional load.\nCitrix: In some respects, Citrix’s answer to the cloud—Citrix Cloud Center (C3) —is similar to VMware’s. Naturally, Citrix XenServer is a key component of C3. Citrix will deliver a special version of XenServer—XenServer Cloud Edition— that incorporates all the functionality of traditional XenServer plus consumption based pricing so that service providers can charge based on metered resource usage.\nC3 joins XenServer Cloud Edition with NetScaler to provide policy-based application performance management. NetScaler integration will enable organizations to dynamically scale the number of VMs based on user demand to balance workloads across cloud environments or, in the event of failures or outages, to redirect traffic transparently. NetScaler also offloads some protocol and transaction processing from servers, providing greater scalability.\nWANScaler is another part of the package that provides acceleration and optimization of traffic between external and internal clouds. Citrix Workflow Studio aims to unify these different components. Like VMware vCloud, Citrix will offer this functionality to service providers. Citrix has focused less on the dynamic movement of workloads between internal and external clouds and more on application delivery via NetScaler and WANScaler, which gives C3 some advantages over vCloud.\nSimilar to how VMware-using organizations would take advantage of Vmware vCloud, organizations using XenServer —or potentially the open source Xen hypervisor—internally would partner with service providers using C3 to provide the ability to shift workload processing based on demand. C3’s integration with NetScaler enables the latter to become the vehicle by which workloads are shifted internally or externally or are load-balanced between the two based on business-driven policies. If demand dictates, NetScaler can also activate additional VMs. WANScaler optimizes traffic between internal and external clouds as workloads shift.\nMicrosoft: Windows Azure, Microsoft’s cloud-computing initiative, is quite different than the rest. Rather than relying on virtualization as a key building block, Microsoft has exploited its massive developer base and the leadership of .NET as a development platform to build a new cloud-computing environment. Microsoft touts Windows Azure as a “cloud services operating system” that is designed to provide “on-demand compute and storage to host, scale and manage Web applications on the Internet through Microsoft data centers.”\nAnd although VMware and Citrix tryto help service providers build their own clouds through the use of their virtualization software, Microsoft instead seeks to be its own service provider. External service providers won’t be able to buy Windows Azure, or the Azure Services Platform. These integrated components will be managed and maintained directly by Microsoft.\nThe other major differentiator of Windows Azure and the Azure Services Platform is that organizations seeking to host their applications in an Azure-powered cloud must port their applications over to Azure because unmodified applications won’t run on Azure. Although Microsoft said it will support third-party languages like Ruby, PHP and Python, the requirement that applications be ported to run on Azure suggests that applications won’t run elsewhere, even in a private cloud infrastructure. Naturally, Microsoft is not talking about merging internal and external clouds or about shifting workloads between clouds because none of that seems to be possible with its approach.\nUnlike organizations seeking to take advantage of VMware vCloud or C3, those that want to leverage Windows Azure will need to port their Web-based applications over to the Azure Services Platform, where it will run in data centers that are owned and managed by Microsoft. Within these data centers, Microsoft’s Azure Services Platform will be able to distribute workload processing across many different physical servers and add or remove processing capacity as needed.\nThere would be no shifting of workloads between clouds. Instead, the processing and hosting would occur within Microsoft’s cloud. In this sense, Microsoft is more of a competitor with other cloud-computing service providers than a provider of cloud-computing infrastructure.\nAs the dust settles in the cloud-computing market, the initiatives from the major vendors—VMware’s vCloud, Citrix’s Cloud Center (C3) and Windows’ Azure—are grand strategic visions that present different notions of a cloud architecture. What’s conspicuously absent, however, are key definitions, standards, compatibility, interoperability, security and privacy.\nVendors that have jumped into this market have yet to provide concrete, substantive answers on how these questions will be addressed. Until they do, the strategic vision of pervasive cloud computing will not likely see the explosive growth that many experts and industry pundits have predicted.\nSo what should data center managers do until then? How should they prepare? Data center managers need to recognize that cloud computing may benefit only a portion of their overall set of applications. Until the challenges around portability, compatibility and security are resolved, cloud computing involving external providers may need to be constrained to specific applications and/or specific user populations. As standards evolve and vendors increase their support for these standards, then data center managers can begin to look to cloud computing as a broader solution and can trust more of their applications to this new computing paradigm.\nAbout the Author\nScott Lowe is a senior engineer at ePlus Technology Inc., a provider of technology solutions based in Herndon, Va. Lowe’s experience in enterprise technologies includes storage area networks, server virtualization, directory services and interoperability. He has worked as the president and chief technology officer at Mercurion Systems and as the CTO of iO Systems.\nThis was first published in February 2009", "label": 1}
{"text": "Kids, you've heard of phone calls, right? Did you know that there's an app on your smartphone that lets you talk out loud to family and friends? Ask your grandparents about it.\nWe're being facetious, but it's true that the stereotype of a chatty teen or young adult spending hours talking on the phone is fading. Those interactions are being replaced by the image of a kid hunched over a handset, tapping out texts, emails, or Facebook messages.\nTwo new pieces of research highlight just how common that image has become.\nA British study conducted by independent media regulator Ofcom found that among 16- to 24-year-olds, phone calls are being superseded by texts or other e-messages. Per the research, 96 percent use some form of text-based communication -- either though social networks (73 percent) or through traditional texting (90 percent) -- on a daily basis. By comparison, only 67 percent of that age group talks on the phone daily. Overall, total time spent on the phone declined 5 percent for Britons of all ages, the first such drop since the 1990s, according to The Guardian.\nAnd new research from Pew finds similar trends among teens stateside. As NBC News explains, 63 percent of teens text every day, compared to only 39 percent making or taking cell phone calls daily. And it seems social networking (29 percent daily use) and instant messaging (22 percent) are increasingly taking up U.S. teens' time, too.\nTaken together, these studies appear to foreshadow a time in the not-so-distant future when text-based messages are the norm and phone calls are thought of as a quaint, nonessential way to get in touch.\nIn fact, that day may come sooner than you think, if the chief executive of one of the largest American phone carriers is to be believed. \"I'll be surprised if, in the next 24 months, we don't see people in the market place with data-only plans,\" AT&T CEO Randall Stephenson said at a conference in June. \"I just think that's inevitable.\"\nConsider it the beginning of the end of the phone call as we know it, with teens leading the trend.\nContact Your Phone\n<a href=\"http://www.pcmag.com/article2/0,2817,2363526,00.asp\"target=\"_blank\">PCMag</a> recommends using another phone to text your lost phone with a message offering a reward for the device, and you can always try calling it as well. If you don't have a phone handy, you can use a service like Skype, Google Voice or <a href=\"http://www.fonefindr.com/\"target=\"_blank\">fonefindr.com</a> to ping your phone. It can't hurt -- someone may have found your phone or maybe you'll find hear it ringing between the couch cushions.\nCall Your Carrier\nAfter you've called or texted your phone, retraced your steps, and shed a few tears in frustration over losing your precious device, you'll want to call your cellphone carrier immediately and tell them your phone has been lost or stolen. Ask them to suspend service (i.e. disable messaging and calls) on the device, because thieves could rack up thousands of dollars in international calls or app purchases. AT&T will even let you do this from your <a href=\"http://www.wireless.att.com/answer-center/main.jsp?t=solutionTab&solutionId=KB63935\"target=\"_blank\">account on the Web</a>.\nPassword Protect Your Phone\nWith all the messages, years of email, contacts, social networking accounts and other personal data stored on today's smartphones, we can't recommend password protecting your phone enough. Yes, it's a momentary frustration that requires you tap a few numbers every time you check your phone, but the extra security and peace of mind is worth the effort. While a thief could still wipe a password-protected device and there's always the possibility you just lost the phone for good, the alternative (going password-free) leaves not only your cellphone account but your bank, social networking, and e-mail accounts completely open. If your phone <em>was</em> stolen and you haven't locked it down, immediately change the passwords to your online accounts and alert any banks or services that you enabled on the phone.\nUse Remote Protection Apps\nMany remote security apps are now available for modern smartphones, and they offer everything from near real-time location tracking (often showing your phone's location on a map via a Web interface) and the ability to remote wipe your phone in case of theft to remote photo and data backup. There are many free options, and they take just a few minutes to install and set up. Your corporate BlackBerry can probably be wiped and tracked by your company's IT admins, and consumers can grab the free BlackBerry Protect from <a href=\"http://us.blackberry.com/apps-software/protect/\"target=\"_blank\">BlackBerry App World</a> for remote tracking and wiping. iPhone users should download the free '<a href=\"http://itunes.apple.com/us/app/find-my-iphone/id376101648?mt=8\"target=\"_blank\">Find My iPhone</a>' app Android users can grab the free <a href=\"http://preyproject.com/\"target=\"_blank\">Prey</a> app. Similarly, other third party solutions like <a href=\"http://www.mobiledefense.com/\"target=\"_blank\">Mobile Defense</a>, <a href=\"https://www.mylookout.com/\"target=\"_blank\">Lookout</a> can help secure your device.\nSave Your Phone's Unique ID\nTake a note of your phone's ESN, IMEI or MEID number (often found behind the battery or on the back of the iPhone near the FCC ID). This number will come in handy when reporting a lost or stolen phone to the police or to your cellphone provider.\nSchedule Regular Backups\nIt sounds obvious, but regularly back up your device to your computer to ensure that you don't lose essentials documents, purchases, apps and photos that are stored only on your phone. Even if you're forced to wipe your cellphone or if it's lost for good, you can often restore a factory fresh replacement to the last backup you've got, complete with apps, settings and documents. Depending on how much you use your phone, we recommend backing up between once a month and once a week.", "label": 1}
{"text": "Computer Forensics Schools and Education\n- Find a Computer Forensics School\n- Find Computer Forensics Education Requirements and Information\n- Find Computer Forensics Career Salary Information\nComputer crime is one of the fastest-growing types of crime in the world. With the Internet expanding, and email, social networks, ecommerce and texting so common, personal and corporate computers, cell phones and tablets, and other hand-held devices have become extremely vulnerable to attack. This has created an increased need for computer forensics analysts and investigators.\nWhat Do Computer Forensics Investigators Do?\nComputer forensics investigators are taught to combat crimes ranging from crimes against children to file system recovery on hacked or damaged computers. Computer forensics investigators—also known as a computer forensics specialists—recover data from digital media that may be used in criminal proceedings. Digital media refers to all methods of electronic data storage and transfer devices including computers, laptops, cell phones, PDAs and the documents, images, spreadsheets and other types of files stored on these devices. Once a computer forensics investigator retrieves the necessary information, they'll prepare detailed written reports on the collected data that may later be presented in court. Part of a computer forensics investigator's job is to testify in court regarding the information they recover and the methods they used to get that information.\nComputer forensics consulting firms and freelance computer forensic investigators are also hired by large corporations to test the security of their information systems. Computer forensic specialists may mimic how a malicious hacker might attempt to gain access to a corporation's computer network. But the best place to get the education you need is in computer forensics school.\nRequirements to Become a Computer Forensics Investigator\nComputer forensics is a relatively new field, so there have not been consistent requirements to become an analyst. Many individuals get their computer forensics skills by working in law enforcement or the military. Now that more colleges are offering computer forensics degrees and related information systems (security degrees/cyber crime degrees), education has become an important requirement to stay competitive in the industry. This includes continuing education once you've found a job to stay current in this rapidly changing field.\nComputer Forensics Education\nWe put together a collection of the skills you should look for in your computer forensics program to prepare you for a career in computer forensics. We consulted with leaders in the field of computer forensics and compiled their thoughts. Here's what they had to say:\nIndividuals should take courses in incident handling, investigation, management, protection, detection and reaction. They should study Internet crimes against people and children, learn about presenting digital evidence at trial, network security intrusion and detection, personal digital device forensics and advanced-file system recovery. Law and business are also critical to success in a computer forensics career.\nOne individual emphasized that a comprehensive knowledge of UNIX and NT is essential to retrieving deleted files and evidence of breaches in system security. We were also told that advanced knowledge of networking and routing has become increasingly important with the growth of the Internet and email.\nAll of the people we spoke with agreed that individuals with a desire to become computer forensics investigators should begin by earning a degree in computer forensics or a related degree such as information systems security or cyber crime.\nInformation systems security and computer forensics degrees are offered at the associate's, bachelor's and master's degree levels. An associate's degree along with a law enforcement internship is sometimes enough to be hired by a police department as a computer forensics investigator. Associate's also transition well into bachelor's degrees. Graduate degrees are usually 2-year programs and may advance your career and increase your salary in computer forensics. Some computer forensics careers require certifications such as, CISSP, CISM, CISA or CCSP.\nComputer Forensics Investigator Salary\nAccording to the U.S. Bureau of Labor Statistics' 2012-13 Occupational Outlook Handbook, the median national annual salary for information security analysts is $75,660. Actual salaries may vary greatly based on specialization within the field, location, years of experience and a variety of other factors. Freelancers and those working in consulting firms can earn even more and the BLS estimates that 17 percent of those analysts working are self-employed.\nRequest information from the accredited online schools below. The degree programs offered here may provide you with the skills to succeed as a computer forensics investigator.\nOnline Criminal Justice Schools\n- Doctor of Business Administration (DBA) - Computer and Information Security (Online)\n- PhD in Business Administration - Computer and Information Security (Online)\n- Master of Business Administration (MBA) - Computer and Information Security (Online)\n- Master of Science (M.S.) in Information Technology (Online)\n- BSIT/Information Systems Track - Information Security and Forensics (Online)\n- Associate's - Network Security\n- Bachelor's - Network Security\n- Bachelor of Information Technology - Digital Investigation (Online)\n- Bachelor of Information Technology - Information Assurance and Security (Online)\n- Master of Information Technology - Information Assurance and Security (Online)\n- Bachelor of Science in Information Technology - Security (Online)\n- Doctor of Computer Science in Digital Systems Security - Executive Format (Online)\n- Doctor of Computer Science in Information Assurance - Executive Format (Online)\n- Master of Science in Computer Science - Computer Systems Security (Online)\n- Master of Science in Information Technology - Security Management (Online)\n- Master of Science in Information Security - Technical Track (Online)", "label": 1}
{"text": "In the last article, you learned that a cryptosystem is used to protect the privacy, integrity, and authenticity of data as it traverses a network. In today's article, we'll see how the SSH cryptosystem provides these features.\nIf you're using at least FreeBSD version 4.0, your FreeBSD system uses OpensSSH and it is installed and ready to go. As the name implies, this is an open source implementation of the SSH cryptosystem. You can read more about it at the OpenSSH website.\nIn a previous article (see IP Packets Revealed), I demonstrated that the telnet utility can be used to login to a remote computer from another system. Once logged in, a user can do anything on that remote system as if he were physically sitting in front of it. That is, every keystroke is sent to the remote system and interpreted as if it had come from the keyboard attached to that remote system (even though that keyboard input first had to travel over a network). We also saw in that article that every single keystroke and response was sent in clear text, meaning that a sniffer could watch the entire session.\nAny SSH cryptosystem will allow a user to login to a remote system and work just as if he were physically there. However, before the user is given a login prompt, a key will be generated to encrypt and decrypt all of the data that will be passed between the two computers. That is, more is happening behind the scenes.\nSince SSH is used to access another computer, a user account must exist on the computer to be accessed. Additionally, the computer being accessed is known as the SSH server and must be running the SSH daemon; by default, this daemon listens on TCP port 22. The machine you are sitting at is known as the SSH client; it will contact the daemon on the other machine.\nYour FreeBSD system has default configurations that allow you to use SSH as is. I'll demonstrate the default configuration first, then move on to some changes you may wish to make to increase the security of SSH.\nI'll be using two computers. 10.0.0.1 will be the SSH daemon, the computer\nI wish to access, and 10.0.0.2 will be the SSH client, the computer I'm sitting\nat. On both systems, I have created a user account called \"genisis\". You'll\nnote that the cryptosystem is called OpenSSH. It uses a protocol usually\nwritten as uppercase SSH, and the commands you type,\nsshd, are written in lowercase. Also, you can use the\nssh command to access either an IP address or a hostname. In\nthis week's article, I'll purposefully use IP addresses. In the next\narticle I'll take a closer look at name resolution issues when using SSH.\nFirst, I need to check if the host keys have been created on the system that will be the server. At 10.0.0.1, I'll run this command:\nIf I get this output:\nmoduli ssh_host_dsa_key.pub ssh_host_rsa_key ssh_config ssh_host_key ssh_host_rsa_key.pub ssh_host_dsa_key ssh_host_key.pub sshd_config\nI have the necessary keys. However, if I instead get this output:\nmoduli ssh_config sshd_config\nthere aren't any host keys and I will need to generate them before I can start the SSH daemon. If I'm impatient and try to start the SSH daemon before creating the keys, it will refuse to start and I'll instead receive this error message:\nsshd Could not load host key: /etc/ssh/ssh_host_key Could not load host key: /etc/ssh/ssh_host_dsa_key Disabling protocol version 1. Could not load host key Disabling protocol version 2. Could not load host key sshd: no hostkeys available -- exiting.\nThere are several ways to generate those missing keys. If you are an\nadvanced user who is comfortable with reading startup scripts, search for\n/etc/rc.network to see which commands your\nFreeBSD system uses to generate the host keys. I'll instead demonstrate the\nresults of running that script. The easiest way to ensure the necessary keys\nare generated and that SSH starts whenever the system reboots is to add the\nfollowing line to\nOnce I've saved my changes, I'll type:\nWhen I get a prompt back, I'll press enter and then type the word exit. As my startup scripts are reinitialized, I see the following message:\nStarting final network daemons: creating ssh1 RSA host key Generating public/private rsa1 key pair. Your identification has been saved in /etc/ssh/ssh_host_key. Your public key has been saved in /etc/ ssh/ssh_host_key.pub. The key fingerprint is: 12:d9:3d:f3:95:92:0e:e7:6b:54:09:80:77:a0:3e:cf root@hostname creating ssh2 RSA host key Generating public/private rsa key pair. Your identification has been saved in /etc/ssh/ssh_host_rsa_key. Your public key has been saved in /etc/ssh/ssh_host_rsa_key.pub. The key fingerprint is: 4b:cf:7e:af:f1:a8:01:08:64:1b:c0:79:e3:a2:58:78 root@hostname creating ssh2 DSA host key Generating public/private dsa key pair. Your identification has been saved in /etc/ssh/ssh_host_dsa_key. Your public key has been saved in /etc/ssh/ssh_host_dsa_key.pub. The key fingerprint is: 22:69:d7:05:23:c6:db:d9:55:2a:20:a3:34:bd:f4:ef root@hostname\nLet's take a look at that output. You'll note that three separate key pairs were generated: one for rsa1, one for rsa, and one for dsa. You should recognize the RSA and DSA acronyms from the last article on cryptographic terms. But why so many key pairs? There are two versions of the SSH protocol, and OpenSSH supports them both. Not surprisingly, the rsa1 keypair is used by SSH version 1. You can see from the output that ssh2 (version 2) supports both RSA and DSA.\nPages: 1, 2", "label": 1}
{"text": "A new scheme in the UK aims to find the next wave of British computer security experts in a bid to tackle cybercrime.\nThe Cyber Security Challenge (CSC), which is based on a similar scheme already running in the US, is backed by a number of organisations including the Metropolitan Police and the Institute of Information Security Professionals.\nEntrants will be required to solve online games and challenges using eight key skills such as programming, digital forensics, network analysis and logical thinking.\nA Cyber Security Challenge is already running in the US\n\"We are increasingly dependent on networks and computer systems. The whole digital economy and society is structured around them,\" Judy Baker, director of the Cyber Security Challenge, told the BBC.\nBaker said those that show the most aptitude in the games will go through to a second stage, which is likely to include practical texts.\nThose that excel in these tests will be receive mentoring, training and scholarships to hone their skills.\n\"There's a real need for people with these skills and they can give great value back to the nation as a whole,\" Baker said highlighting that many firms have failing to recruit enough skilled member of staff to deal with computer security issues.\nCyber Security Challenge is expected to start this autumn and is open to those aged 16 and over.", "label": 1}
{"text": "1-18-2009 Virus spreads quickly\nA computer virus that may leave Microsoft Windows users vulnerable to digital hijacking is spreading through companies in the U.S., Europe and Asia, already infecting close to 9 million machines, according to a private online security firm.\nThough computer bugs have become a common affliction, Finland-based F-Secure says a virus it has been tracking for the past several weeks has surged more rapidly through corporate networks than anything they've seen in years.\nF-Secure's chief security adviser, Patrik Runald, said the virus's coding suggests a type of bug that alerts computer users to bogus infections on their machines and offers to help by selling them antivirus software.\nInstead, the virus is simply spreading to little effect, though it may still pose a threat to infected computers.\n\"The gang behind this worm haven't used it yet,\" F-Secure's chief research officer, Nikko Hypponen said by phone. \"But they could do anything they like with any of these machines at any time.\"\nMicrosoft issued a security update Tuesday to deal with the so-called \"Downadup\" or \"Conficker\" virus, which appears to be a new version of a bug that popped up in October.\nMost computers with Windows will automatically download Microsoft's security update, but Hypponen said the virus disables updates on infected machines.\nWhile the origin of the virus is a mystery, F-Secure's best guess is it came from Ukraine. Hypponen said it is coded to avoid computers there, which may indicate whoever wrote the virus was trying to avoid drawing attention from local authorities.", "label": 1}
{"text": "I'm looking for information on what NSA suggested for use in commercial systems in past times. 90's and early 2000's.\nI'm mainly interested in PKI and symmetric cyphers for SSL and file/disk encryption.\nNSA did not publicize their involvement in national standards. So, the exact role NSA played in algorithms and documents may be difficult to determine.\nIn 1987 the U.S. Congress passed the \"Computer Security Act\" which was intended to limit the role of the National Security Agency (NSA) in the development of civilian standards.. The act also authroized the U.S. government to develop standards for publicly available cryptography as most of the encryption up to this point was intended for military use.\nThe National Institute of Standards and Technology (NIST) had previously published FIPS 46 specifying The Data Encryption Standard in 1977. 1988 NIST issued FIPS 46-1 continuing to support DES. IN 1993 NIST published FIPS 46-2 which again supported DES. It wasn't until 1999 that NIST recommended using Tripple DES also known as 3DES.\nIn 1991 NIST published FIPS 186 The Digital Signature Standard (DSS). EPIC claims that the NSA actually produced the technology behind DSS. DSS became an official standard when approved by the U.S. Secretary of Commerce.\nIn 1994 NIST publishes FIPS 185 Escrowed Encryption Standard (EES) The most well know implementation of the standard was the Clipper Chip. EPIC describes Skipjack, the cryptographic algorithm used by ESS as 'developed by the National Security Agency' The Clipper Chip and ESS are failures whith little to no adoption. NIST also publishes FIPS 140-1 a standard for commercial development of cryptographic modules.\nIn 1995 NIST published FIPS 180 Secure Hash Standard (SHS) which describe the Secure Hash Algorithm (SHA-1). Wikipedia describes SHA-1 as being 'designed by the National Security Agency and published by the NIST'\nIn 1996 NIST publishes FIPS 186-1 a minor revision to FIPS 186 describing the Digital Signature Standard (DSS).\nIn 1997 NIST anounced the Advanced Encryption Standard competition. An open competition to select an algorithm to replace DES.\nIn 1999 NIST publishes FIPS 46-3 recommending Tripple DES (3DES) for new systems and the continued use of DES for legacy systems.\nIn 2001 NIST publishes FIPS 140-2 and makes revisions based on new technology and comments received from the vendor, tester, and user communities.\nIn 2002 NIST announced the winner of the AES competition and published FIPS 197 Advanced Encryption Standard (AES)\nNSA was undergoing a transformation on the subject question during the timeframe you are questioning.\nIn the previous two decades through the mid 90s NSA advocated for no strong privately controlled public encryption. This position surfaced with their clash with MIT over the work of the famed RSA crew Ron Rivest, Adi Shamir, and Leonard Adleman resulting in the rushed publishing of same in 1976. Federal funding for MIT was threatened during that dust up. That position continued through the next 15 years highlighted by the flare up with Phil Zimmermann and PGP which almost landed him in prison. By 1993 NSA was advocating the ‘Clipper Chip’ solution (using Skipjack) which created a back door key escrow for all public encryption. The pushback against the concept was great from both academia and the common computer enthusiast. That sets the stage for the period you question.\nTimes were changing as the Cold War ended, BBS-based personal computing was replaced by web browsing based on the Netscape browser with its PKI SSL solution, and with those changing times so changed NSA. By July 2000 NSA had gone so far as to partner with Network Associates, the owners of Zimmerman’s PGP at that point, to create a free open source operating system – SELinux. NSA by that point embraced publically available encryption as we know it today and provided hardening recommendations using same. You can find specifics at http://www.nsa.gov/ia/guidance/security_configuration_guides/archived_guides.shtml . Keep in mind that NSA was actually just joining the public using commercial standards of the day in the period you are questioning.", "label": 1}
{"text": "Let us guess: you have profiles on Facebook, twitter, MySpace, Foursquare, Reddit, Digg, Yelp, and the list goes on. You have separate email addresses for work, friends, spam, and some you can’t even remember. You’ve created countless accounts all across the web to track your online shopping orders, comment on blog posts, enter contests, share photos, and take quizzes.\nYou’ve reached a point where you can’t remember all of the sites on which you’re registered, let alone your password, so you’ve started using the same password (or a slight variation of it) on every site you visit. You’re hoping that you won’t fall victim to identity theft, or that spammers won’t figure out your go-to password.\nIf this sounds like you, we have good news and bad news for you.\nFirst the bad: each year, more than 15 million Americans fall prey to identity theft and fraud because of online security breaches. Maybe you’ve avoided it up until now, but odds are you won’t be so lucky in the future.\nNow the good: Abine’s PrivacySuite, a free browser-add on that runs in the background while you’re online, keeps track of all of your online accounts and passwords. It even generates random, encrypted passwords to make sure your accounts stay safe.\nPeople tend to make a few common mistakes regarding password security.\nFirst, we don’t create sufficiently safe passwords. The best passwords are easy for you to remember but hard for others to guess. Unfortunately, however, many of us worry more about remembering our passwords instead of making them secure.\nWhat makes a secure password?\nA combination of length, content, and how often you change it. In general, longer passwords with a wider variety of capitalization, letters, numbers, and symbols are the most secure, and the more often you change them, the better. The harder it is for others to guess, the safer it is. A few examples of notoriously bad passwords:\n- your first or last name\nOur second problem: we reuse our passwords everywhere.\nA 2003 survey found that 65% of us use the same password for different applications or services. We’re only human; we can’t keep hundreds of different username and password combinations in our heads at all times. But in our effort to try to keep things simple, we expose ourselves to a great deal of risk. Think about it: a spammer who discovers your password on, say, Facebook, can then access all the other sites where you use it: PayPal, your online banking site, your phone service, your email, and everywhere else.\nPrivacySuite takes care of both password security and complicated account management.\nIf you already use your browser to remember existing passwords and automatically fill in forms, PrivacySuite can import all of those passwords into one place. The next time you want to visit Facebook, for example, PrivacySuite can automatically fill your username and password and log you in, all in one click. You can also start fresh and have PrivacySuite start remembering your logins when you begin using it. With PrivacySuite, you’ll never have to memorize another username or password again.\nWhat about the passwords you’ve been constantly reusing? PrivacySuite lists all of your accounts and rates the strength of the passwords you use on them. A green circle next to your password means that it’s strong: it’s unique, difficult to crack, and you don’t use it often. Yellow means that you’ve reused it a few times, and red means that you reuse it often. With a quick glance, you’ll be able to see how all your passwords rank in terms of security.\nAnd if your passwords aren’t as strong as you’d like, you can use PrivacySuite to generate secure ones as you browse. Just right click in the password box, click “fill password,” and PrivacySuite creates an 8-character random password using mixed case and numbers and letters. Best of all, PrivacySuite then saves the password you just made so you’ll never have to keep track of it.\nPrivacySuite securely organizes your online accounts and stores your passwords in an encrypted form on your computer, keeping them safe from scammers, hackers, and advertisers. No other person or company can access your information, not even our servers.\nIf you want more control, organization, and security in your online life, try PrivacySuite today.\nA bit about us: Abine’s Privacy Suite and DeleteMe services help you stay private when you surf online, stay private when you enter your personal info into forms, and reclaim your privacy if you have info or accounts online you’d like removed. Many of these services are free or reasonably priced, and come directly from us at Abine, The Online Privacy Company.", "label": 1}
{"text": "In 1983, Americans watched as Matthew Broderick, armed with only a personal computer, brought the world to its knees. In the popular movie WarGames, Broderick played a young hacker who broke into the military’s electronic network and nearly started World War III. In recent years, as fear of terrorism continues to overwhelm rational threat assessment, the WarGames scenario looks a lot like what so-called cybersecurity experts and their federal government allies tout.\nThe problem with “cybersecurity,” says Jim Harper, director of information policy studies at the Cato Institute, is that we’re convincing ourselves that cyberspace is an endless sea of vulnerabilities that leave us weak and exposed. It’s not. Harper has emerged as the voice of reason among breathless news reports of “cyber attacks” and calls for Washington to take over security of the nation’s computing infrastructure. In his papers, congressional testimonies, and numerous media appearances, Harper emphasizes the need to better understand the nature of cyberspace, to appreciate the improvements in cybersecurity civil society is constantly generating, and to recognize the near impossibility that terrorists might inflict significant harm using computers.\n“It’s helpful to imagine ‘cyberspace’ as organized like the physical world,” Harper says. “Think of personal computers as people’s homes. Their attachments to the network analogize to driveways, which connect to roads and then highways. E-mails, financial files, and pictures are the personal possessions that could be stolen out of houses and private vehicles, leading to privacy loss.”\nCyberspace will be secured the way real space is. Computer owners, like homeowners and businesses, should be the first line of protection for their own property, Harper says. They should install the latest patches and place their systems behind firewalls. What the government wants — to come up with a national cybersecurity plan and force it upon network, data, and computer owners — is akin to cutting down crime in neighborhoods by stationing police officers in livingrooms and dictating what sorts of door locks and alarm systems must be in all new homes.\n“The analogy between cyberspace and real space shows that ‘cybersecurity’ is not a small universe of problems, but thousands of different problems that will be handled in thousands of different ways by millions of people,” Harper says. This analogy is particularly important when the topic shifts from broad “cybersecurity” to the narrower threat of “cyberterrorism.”\nThe popular view of such attacks, like WarGames, is nonsense, according to Harper. “With communications networks, computing infrastructure, and data stores under regular attack from a variety of quarters — and regularly strengthening to meet them — it is highly unlikely that terrorists can pull off a cybersecurity event disruptive enough to instill widespread fear of further disruption,” Harper says. If they could do it at all, taking down websites, interrupting financial networks, or knocking out power systems does not terrorize. In a 2009 speech about cybersecurity, President Obama spoke about “weapons of mass disruption,” a poor relation of the instruments that truly threaten violence and chaos.\nThe federal government plays a significant role in protecting Americans from genuine terrorism. And, even though the threat of cyberterrorism is dramatically overblown, the government can improve security in that area, too. But it should not do so through regulation, Harper says. Instead, it can take advantage of its position as a large purchaser of information technology and, through the market, guide technology producers to meet better security standards.\nThe politicians in Washington should realize that the easiest way to protect critical data and infrastructure is not to make it vulnerable in the first place. “Where security is truly at a premium,” Harper says, “the lion’s share of securing infrastructure against cyberattack can be achieved by the simple policy of fully decoupling it from the Internet.”\nHarper’s level-headedness is getting attention. The Obama White House cited a paper he wrote in the executive summary of its Cyberspace Policy Review. In it, Harper argued that updating tort law to allow those harmed by insecure computer products to recover damages from providers and manufacturers is a better path to true security than government regulation of the market. And he was called before the House Subcommittee on Technology and Innovation to testify about how the federal government should respond to cyberterrorist threats and how it should approach securing the nation’s informationtechnology infrastructure.\nHarper is adamantly clear that cybersecurity is important. While arguing that the federal government should not directly regulate computer security, he is careful not to downplay the need to secure our computer networks. But such security, like in the brick and- mortar world outside the Internet, is a matter of personal responsibility, business interest, and common sense.\nThat same common sense should lead us to recognize that cyberterrorism does not exist and that threat of cyberwarfare is minimal. Claims to the contrary result from technological illiteracy and the incentives of government officials and contractors that favor inflating threats. Cyberterrorism is “cyber–snake oil,” Harper says.", "label": 1}
{"text": "At all times, PostgreSQL maintains a write ahead log (WAL) in the pg_xlog/ subdirectory of the cluster's data directory. The log records every change made to the database's data files. This log exists primarily for crash-safety purposes: if the system crashes, the database can be restored to consistency by \"replaying\" the log entries made since the last checkpoint. However, the existence of the log makes it possible to use a third strategy for backing up databases: we can combine a file-system-level backup with backup of the WAL files. If recovery is needed, we restore the file system backup and then replay from the backed-up WAL files to bring the system to a current state. This approach is more complex to administer than either of the previous approaches, but it has some significant benefits:\nWe do not need a perfectly consistent file system backup as the starting point. Any internal inconsistency in the backup will be corrected by log replay (this is not significantly different from what happens during crash recovery). So we do not need a file system snapshot capability, just tar or a similar archiving tool.\nSince we can combine an indefinitely long sequence of WAL files for replay, continuous backup can be achieved simply by continuing to archive the WAL files. This is particularly valuable for large databases, where it might not be convenient to take a full backup frequently.\nIt is not necessary to replay the WAL entries all the way to the end. We could stop the replay at any point and have a consistent snapshot of the database as it was at that time. Thus, this technique supports point-in-time recovery: it is possible to restore the database to its state at any time since your base backup was taken.\nIf we continuously feed the series of WAL files to another machine that has been loaded with the same base backup file, we have a warm standby system: at any point we can bring up the second machine and it will have a nearly-current copy of the database.\nNote: pg_dump and pg_dumpall do not produce file-system-level backups and cannot be used as part of a continuous-archiving solution. Such dumps are logical and do not contain enough information to be used by WAL replay.\nAs with the plain file-system-backup technique, this method can only support restoration of an entire database cluster, not a subset. Also, it requires a lot of archival storage: the base backup might be bulky, and a busy system will generate many megabytes of WAL traffic that have to be archived. Still, it is the preferred backup technique in many situations where high reliability is needed.\nTo recover successfully using continuous archiving (also called \"online backup\" by many database vendors), you need a continuous sequence of archived WAL files that extends back at least as far as the start time of your backup. So to get started, you should set up and test your procedure for archiving WAL files before you take your first base backup. Accordingly, we first discuss the mechanics of archiving WAL files.\nIn an abstract sense, a running PostgreSQL system produces an indefinitely long sequence of WAL records. The system physically divides this sequence into WAL segment files, which are normally 16MB apiece (although the segment size can be altered when building PostgreSQL). The segment files are given numeric names that reflect their position in the abstract WAL sequence. When not using WAL archiving, the system normally creates just a few segment files and then \"recycles\" them by renaming no-longer-needed segment files to higher segment numbers. It's assumed that segment files whose contents precede the checkpoint-before-last are no longer of interest and can be recycled.\nWhen archiving WAL data, we need to capture the contents of each segment file once it is filled, and save that data somewhere before the segment file is recycled for reuse. Depending on the application and the available hardware, there could be many different ways of \"saving the data somewhere\": we could copy the segment files to an NFS-mounted directory on another machine, write them onto a tape drive (ensuring that you have a way of identifying the original name of each file), or batch them together and burn them onto CDs, or something else entirely. To provide the database administrator with flexibility, PostgreSQL tries not to make any assumptions about how the archiving will be done. Instead, PostgreSQL lets the administrator specify a shell command to be executed to copy a completed segment file to wherever it needs to go. The command could be as simple as a cp, or it could invoke a complex shell script — it's all up to you.\nTo enable WAL archiving, set the wal_level configuration parameter to archive (or hot_standby), archive_mode to on, and specify the shell command to use in the archive_command configuration parameter. In practice these settings will always be placed in the postgresql.conf file. In archive_command, %p is replaced by the path name of the file to archive, while %f is replaced by only the file name. (The path name is relative to the current working directory, i.e., the cluster's data directory.) Use %% if you need to embed an actual % character in the command. The simplest useful command is something like:\narchive_command = 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f' # Unix archive_command = 'copy \"%p\" \"C:\\\\server\\\\archivedir\\\\%f\"' # Windows\nwhich will copy archivable WAL segments to the directory /mnt/server/archivedir. (This is an example, not a recommendation, and might not work on all platforms.) After the %p and %f parameters have been replaced, the actual command executed might look like this:\ntest ! -f /mnt/server/archivedir/00000001000000A900000065 && cp pg_xlog/00000001000000A900000065 /mnt/server/archivedir/00000001000000A900000065\nA similar command will be generated for each new file to be archived.\nThe archive command will be executed under the ownership of the same user that the PostgreSQL server is running as. Since the series of WAL files being archived contains effectively everything in your database, you will want to be sure that the archived data is protected from prying eyes; for example, archive into a directory that does not have group or world read access.\nIt is important that the archive command return zero exit status if and only if it succeeds. Upon getting a zero result, PostgreSQL will assume that the file has been successfully archived, and will remove or recycle it. However, a nonzero status tells PostgreSQL that the file was not archived; it will try again periodically until it succeeds.\nThe archive command should generally be designed to refuse to overwrite any pre-existing archive file. This is an important safety feature to preserve the integrity of your archive in case of administrator error (such as sending the output of two different servers to the same archive directory).\nIt is advisable to test your proposed archive command to ensure that it indeed does not overwrite an existing file, and that it returns nonzero status in this case. The example command above for Unix ensures this by including a separate test step. On some Unix platforms, cp has switches such as -i that can be used to do the same thing less verbosely, but you should not rely on these without verifying that the right exit status is returned. (In particular, GNU cp will return status zero when -i is used and the target file already exists, which is not the desired behavior.)\nWhile designing your archiving setup, consider what will happen if the archive command fails repeatedly because some aspect requires operator intervention or the archive runs out of space. For example, this could occur if you write to tape without an autochanger; when the tape fills, nothing further can be archived until the tape is swapped. You should ensure that any error condition or request to a human operator is reported appropriately so that the situation can be resolved reasonably quickly. The pg_xlog/ directory will continue to fill with WAL segment files until the situation is resolved. (If the file system containing pg_xlog/ fills up, PostgreSQL will do a PANIC shutdown. No committed transactions will be lost, but the database will remain offline until you free some space.)\nThe speed of the archiving command is unimportant as long as it can keep up with the average rate at which your server generates WAL data. Normal operation continues even if the archiving process falls a little behind. If archiving falls significantly behind, this will increase the amount of data that would be lost in the event of a disaster. It will also mean that the pg_xlog/ directory will contain large numbers of not-yet-archived segment files, which could eventually exceed available disk space. You are advised to monitor the archiving process to ensure that it is working as you intend.\nIn writing your archive command, you should assume that the file names to be archived can be up to 64 characters long and can contain any combination of ASCII letters, digits, and dots. It is not necessary to preserve the original relative path (%p) but it is necessary to preserve the file name (%f).\nNote that although WAL archiving will allow you to restore any modifications made to the data in your PostgreSQL database, it will not restore changes made to configuration files (that is, postgresql.conf, pg_hba.conf and pg_ident.conf), since those are edited manually rather than through SQL operations. You might wish to keep the configuration files in a location that will be backed up by your regular file system backup procedures. See Section 18.2 for how to relocate the configuration files.\nThe archive command is only invoked on completed WAL segments. Hence, if your server generates only little WAL traffic (or has slack periods where it does so), there could be a long delay between the completion of a transaction and its safe recording in archive storage. To put a limit on how old unarchived data can be, you can set archive_timeout to force the server to switch to a new WAL segment file at least that often. Note that archived files that are archived early due to a forced switch are still the same length as completely full files. It is therefore unwise to set a very short archive_timeout — it will bloat your archive storage. archive_timeout settings of a minute or so are usually reasonable.\nAlso, you can force a segment switch manually with\npg_switch_xlog if you want to\nensure that a just-finished transaction is archived as soon as\npossible. Other utility functions related to WAL management are\nlisted in Table\nWhen wal_level is minimal some SQL commands are optimized to avoid WAL logging, as described in Section 14.4.7. If archiving or streaming replication were turned on during execution of one of these statements, WAL would not contain enough information for archive recovery. (Crash recovery is unaffected.) For this reason, wal_level can only be changed at server start. However, archive_command can be changed with a configuration file reload. If you wish to temporarily stop archiving, one way to do it is to set archive_command to the empty string (''). This will cause WAL files to accumulate in pg_xlog/ until a working archive_command is re-established.\nThe procedure for making a base backup is relatively simple:\nEnsure that WAL archiving is enabled and working.\nConnect to the database as a superuser and issue the command:\nwhere label is any string you\nwant to use to uniquely identify this backup operation.\n(One good practice is to use the full path where you intend\nto put the backup dump file.)\npg_start_backup creates a backup label file, called backup_label, in the cluster directory with\ninformation about your backup, including the start time and\nIt does not matter which database within the cluster you connect to to issue this command. You can ignore the result returned by the function; but if it reports an error, deal with that before proceeding.\npg_start_backup can take a long time to\nfinish. This is because it performs a checkpoint, and the\nI/O required for the checkpoint will be spread out over a\nsignificant period of time, by default half your\ninter-checkpoint interval (see the configuration parameter\nThis is usually what you want, because it minimizes the\nimpact on query processing. If you want to start the backup\nas soon as possible, use:\nSELECT pg_start_backup('label', true);\nThis forces the checkpoint to be done as quickly as possible.\nPerform the backup, using any convenient file-system-backup tool such as tar or cpio (not pg_dump or pg_dumpall). It is neither necessary nor desirable to stop normal operation of the database while you do this.\nAgain connect to the database as a superuser, and issue the command:\nThis terminates the backup mode and performs an automatic switch to the next WAL segment. The reason for the switch is to arrange for the last WAL segment file written during the backup interval to be ready to archive.\nOnce the WAL segment files active during the backup are\narchived, you are done. The file identified by\npg_stop_backup's result is the last\nsegment that is required to form a complete set of backup\nfiles. If archive_mode is enabled,\npg_stop_backup does not\nreturn until the last segment has been archived. Archiving\nof these files happens automatically since you have already\nconfigured archive_command. In\nmost cases this happens quickly, but you are advised to\nmonitor your archive system to ensure there are no delays.\nIf the archive process has fallen behind because of\nfailures of the archive command, it will keep retrying\nuntil the archive succeeds and the backup is complete. If\nyou wish to place a time limit on the execution of\npg_stop_backup, set an\nYou can also use the pg_basebackup tool to take the\nbackup, instead of manually copying the files. This tool will\ndo the equivalent of\npg_start_backup(), copy and\npg_stop_backup() steps automatically, and\ntransfers the backup over a regular PostgreSQL connection using the\nreplication protocol, instead of requiring file system level\naccess. pg_basebackup does not\ninterfere with file system level backups taken using\nSome file system backup tools emit warnings or errors if the files they are trying to copy change while the copy proceeds. When taking a base backup of an active database, this situation is normal and not an error. However, you need to ensure that you can distinguish complaints of this sort from real errors. For example, some versions of rsync return a separate exit code for \"vanished source files\", and you can write a driver script to accept this exit code as a non-error case. Also, some versions of GNU tar return an error code indistinguishable from a fatal error if a file was truncated while tar was copying it. Fortunately, GNU tar versions 1.16 and later exit with 1 if a file was changed during the backup, and 2 for other errors.\nIt is not necessary to be concerned about the amount of time\nand the start of the actual backup, nor between the end of the\npg_stop_backup; a few\nminutes' delay won't hurt anything. (However, if you normally\nrun the server with full_page_writes\ndisabled, you might notice a drop in performance between\npg_stop_backup, since full_page_writes is effectively forced on during\nbackup mode.) You must ensure that these steps are carried out\nin sequence, without any possible overlap, or you will\ninvalidate the backup.\nBe certain that your backup dump includes all of the files under the database cluster directory (e.g., /usr/local/pgsql/data). If you are using tablespaces that do not reside underneath this directory, be careful to include them as well (and be sure that your backup dump archives symbolic links as links, otherwise the restore will corrupt your tablespaces).\nYou can, however, omit from the backup dump the files within the cluster's pg_xlog/ subdirectory. This slight adjustment is worthwhile because it reduces the risk of mistakes when restoring. This is easy to arrange if pg_xlog/ is a symbolic link pointing to someplace outside the cluster directory, which is a common setup anyway for performance reasons. You might also want to exclude postmaster.pid and postmaster.opts, which record information about the running postmaster, not about the postmaster which will eventually use this backup. (These files can confuse pg_ctl.)\nTo make use of the backup, you will need to keep all the WAL\nsegment files generated during and after the file system\nbackup. To aid you in doing this, the\npg_stop_backup function creates a backup history file that is immediately stored\ninto the WAL archive area. This file is named after the first\nWAL segment file that you need for the file system backup. For\nexample, if the starting WAL file is 0000000100001234000055CD the backup history file\nwill be named something like 0000000100001234000055CD.007C9330.backup. (The\nsecond part of the file name stands for an exact position\nwithin the WAL file, and can ordinarily be ignored.) Once you\nhave safely archived the file system backup and the WAL segment\nfiles used during the backup (as specified in the backup\nhistory file), all archived WAL segments with names numerically\nless are no longer needed to recover the file system backup and\ncan be deleted. However, you should consider keeping several\nbackup sets to be absolutely certain that you can recover your\nThe backup history file is just a small text file. It\ncontains the label string you gave to\npg_start_backup, as well as the starting and\nending times and WAL segments of the backup. If you used the\nlabel to identify the associated dump file, then the archived\nhistory file is enough to tell you which dump file to\nSince you have to keep around all the archived WAL files back to your last base backup, the interval between base backups should usually be chosen based on how much storage you want to expend on archived WAL files. You should also consider how long you are prepared to spend recovering, if recovery should be necessary — the system will have to replay all those WAL segments, and that could take awhile if it has been a long time since the last base backup.\nIt's also worth noting that the\npg_start_backup function makes a file named\nbackup_label in the database cluster\ndirectory, which is removed by\npg_stop_backup. This file will of course be\narchived as a part of your backup dump file. The backup label\nfile includes the label string you gave to\npg_start_backup, as well as the time at which\npg_start_backup was run, and the\nname of the starting WAL file. In case of confusion it is\ntherefore possible to look inside a backup dump file and\ndetermine exactly which backup session the dump file came\nIt is also possible to make a backup dump while the server\nis stopped. In this case, you obviously cannot use\npg_stop_backup, and you will therefore be\nleft to your own devices to keep track of which backup dump is\nwhich and how far back the associated WAL files go. It is\ngenerally better to follow the continuous archiving procedure\nOkay, the worst has happened and you need to recover from your backup. Here is the procedure:\nStop the server, if it's running.\nIf you have the space to do so, copy the whole cluster data directory and any tablespaces to a temporary location in case you need them later. Note that this precaution will require that you have enough free space on your system to hold two copies of your existing database. If you do not have enough space, you should at least save the contents of the cluster's pg_xlog subdirectory, as it might contain logs which were not archived before the system went down.\nRemove all existing files and subdirectories under the cluster data directory and under the root directories of any tablespaces you are using.\nRestore the database files from your file system backup. Be sure that they are restored with the right ownership (the database system user, not root!) and with the right permissions. If you are using tablespaces, you should verify that the symbolic links in pg_tblspc/ were correctly restored.\nRemove any files present in pg_xlog/; these came from the file system backup and are therefore probably obsolete rather than current. If you didn't archive pg_xlog/ at all, then recreate it with proper permissions, being careful to ensure that you re-establish it as a symbolic link if you had it set up that way before.\nIf you have unarchived WAL segment files that you saved in step 2, copy them into pg_xlog/. (It is best to copy them, not move them, so you still have the unmodified files if a problem occurs and you have to start over.)\nCreate a recovery command file recovery.conf in the cluster data directory (see Chapter 26). You might also want to temporarily modify pg_hba.conf to prevent ordinary users from connecting until you are sure the recovery was successful.\nStart the server. The server will go into recovery mode and proceed to read through the archived WAL files it needs. Should the recovery be terminated because of an external error, the server can simply be restarted and it will continue recovery. Upon completion of the recovery process, the server will rename recovery.conf to recovery.done (to prevent accidentally re-entering recovery mode later) and then commence normal database operations.\nInspect the contents of the database to ensure you have recovered to the desired state. If not, return to step 1. If all is well, allow your users to connect by restoring pg_hba.conf to normal.\nThe key part of all this is to set up a recovery configuration file that describes how you want to recover and how far the recovery should run. You can use recovery.conf.sample (normally located in the installation's share/ directory) as a prototype. The one thing that you absolutely must specify in recovery.conf is the restore_command, which tells PostgreSQL how to retrieve archived WAL file segments. Like the archive_command, this is a shell command string. It can contain %f, which is replaced by the name of the desired log file, and %p, which is replaced by the path name to copy the log file to. (The path name is relative to the current working directory, i.e., the cluster's data directory.) Write %% if you need to embed an actual % character in the command. The simplest useful command is something like:\nrestore_command = 'cp /mnt/server/archivedir/%f %p'\nwhich will copy previously archived WAL segments from the directory /mnt/server/archivedir. Of course, you can use something much more complicated, perhaps even a shell script that requests the operator to mount an appropriate tape.\nIt is important that the command return nonzero exit status on failure. The command will be called requesting files that are not present in the archive; it must return nonzero when so asked. This is not an error condition. Not all of the requested files will be WAL segment files; you should also expect requests for files with a suffix of .backup or .history. Also be aware that the base name of the %p path will be different from %f; do not expect them to be interchangeable.\nWAL segments that cannot be found in the archive will be sought in pg_xlog/; this allows use of recent un-archived segments. However, segments that are available from the archive will be used in preference to files in pg_xlog/. The system will not overwrite the existing contents of pg_xlog/ when retrieving archived files.\nNormally, recovery will proceed through all available WAL segments, thereby restoring the database to the current point in time (or as close as possible given the available WAL segments). Therefore, a normal recovery will end with a \"file not found\" message, the exact text of the error message depending upon your choice of restore_command. You may also see an error message at the start of recovery for a file named something like 00000001.history. This is also normal and does not indicate a problem in simple recovery situations; see Section 24.3.4 for discussion.\nIf you want to recover to some previous point in time (say, right before the junior DBA dropped your main transaction table), just specify the required stopping point in recovery.conf. You can specify the stop point, known as the \"recovery target\", either by date/time, named restore point or by completion of a specific transaction ID. As of this writing only the date/time and named restore point options are very usable, since there are no tools to help you identify with any accuracy which transaction ID to use.\nNote: The stop point must be after the ending time of the base backup, i.e., the end time of\npg_stop_backup. You cannot use a base backup to recover to a time when that backup was in progress. (To recover to such a time, you must go back to your previous base backup and roll forward from there.)\nIf recovery finds corrupted WAL data, recovery will halt at that point and the server will not start. In such a case the recovery process could be re-run from the beginning, specifying a \"recovery target\" before the point of corruption so that recovery can complete normally. If recovery fails for an external reason, such as a system crash or if the WAL archive has become inaccessible, then the recovery can simply be restarted and it will restart almost from where it failed. Recovery restart works much like checkpointing in normal operation: the server periodically forces all its state to disk, and then updates the pg_control file to indicate that the already-processed WAL data need not be scanned again.\nThe ability to restore the database to a previous point in time creates some complexities that are akin to science-fiction stories about time travel and parallel universes. For example, in the original history of the database, suppose you dropped a critical table at 5:15PM on Tuesday evening, but didn't realize your mistake until Wednesday noon. Unfazed, you get out your backup, restore to the point-in-time 5:14PM Tuesday evening, and are up and running. In this history of the database universe, you never dropped the table. But suppose you later realize this wasn't such a great idea, and would like to return to sometime Wednesday morning in the original history. You won't be able to if, while your database was up-and-running, it overwrote some of the WAL segment files that led up to the time you now wish you could get back to. Thus, to avoid this, you need to distinguish the series of WAL records generated after you've done a point-in-time recovery from those that were generated in the original database history.\nTo deal with this problem, PostgreSQL has a notion of timelines. Whenever an archive recovery completes, a new timeline is created to identify the series of WAL records generated after that recovery. The timeline ID number is part of WAL segment file names so a new timeline does not overwrite the WAL data generated by previous timelines. It is in fact possible to archive many different timelines. While that might seem like a useless feature, it's often a lifesaver. Consider the situation where you aren't quite sure what point-in-time to recover to, and so have to do several point-in-time recoveries by trial and error until you find the best place to branch off from the old history. Without timelines this process would soon generate an unmanageable mess. With timelines, you can recover to any prior state, including states in timeline branches that you abandoned earlier.\nEvery time a new timeline is created, PostgreSQL creates a \"timeline history\" file that shows which timeline it branched off from and when. These history files are necessary to allow the system to pick the right WAL segment files when recovering from an archive that contains multiple timelines. Therefore, they are archived into the WAL archive area just like WAL segment files. The history files are just small text files, so it's cheap and appropriate to keep them around indefinitely (unlike the segment files which are large). You can, if you like, add comments to a history file to record your own notes about how and why this particular timeline was created. Such comments will be especially valuable when you have a thicket of different timelines as a result of experimentation.\nThe default behavior of recovery is to recover along the same timeline that was current when the base backup was taken. If you wish to recover into some child timeline (that is, you want to return to some state that was itself generated after a recovery attempt), you need to specify the target timeline ID in recovery.conf. You cannot recover into timelines that branched off earlier than the base backup.\nSome tips for configuring continuous archiving are given here.\nIt is possible to use PostgreSQL's backup facilities to produce standalone hot backups. These are backups that cannot be used for point-in-time recovery, yet are typically much faster to backup and restore than pg_dump dumps. (They are also much larger than pg_dump dumps, so in some cases the speed advantage might be negated.)\nTo prepare for standalone hot backups, set wal_level to archive (or hot_standby), archive_mode to on, and set up an archive_command that performs archiving only when a switch file exists. For example:\narchive_command = 'test ! -f /var/lib/pgsql/backup_in_progress || (test ! -f /var/lib/pgsql/archive/%f && cp %p /var/lib/pgsql/archive/%f)'\nThis command will perform archiving when /var/lib/pgsql/backup_in_progress exists, and otherwise silently return zero exit status (allowing PostgreSQL to recycle the unwanted WAL file).\nWith this preparation, a backup can be taken using a script like the following:\ntouch /var/lib/pgsql/backup_in_progress psql -c \"select pg_start_backup('hot_backup');\" tar -cf /var/lib/pgsql/backup.tar /var/lib/pgsql/data/ psql -c \"select pg_stop_backup();\" rm /var/lib/pgsql/backup_in_progress tar -rf /var/lib/pgsql/backup.tar /var/lib/pgsql/archive/\nThe switch file /var/lib/pgsql/backup_in_progress is created first, enabling archiving of completed WAL files to occur. After the backup the switch file is removed. Archived WAL files are then added to the backup so that both base backup and all required WAL files are part of the same tar file. Please remember to add error handling to your backup scripts.\nIf archive storage size is a concern, use pg_compresslog, http://pglesslog.projects.postgresql.org, to remove unnecessary full_page_writes and trailing space from the WAL files. You can then use gzip to further compress the output of pg_compresslog:\narchive_command = 'pg_compresslog %p - | gzip > /var/lib/pgsql/archive/%f'\nYou will then need to use gunzip and pg_decompresslog during recovery:\nrestore_command = 'gunzip < /mnt/server/archivedir/%f | pg_decompresslog - %p'\nMany people choose to use scripts to define their archive_command, so that their postgresql.conf entry looks very simple:\narchive_command = 'local_backup_script.sh \"%p\" \"%f\"'\nUsing a separate script file is advisable any time you want to use more than a single command in the archiving process. This allows all complexity to be managed within the script, which can be written in a popular scripting language such as bash or perl.\nExamples of requirements that might be solved within a script include:\nCopying data to secure off-site data storage\nBatching WAL files so that they are transferred every three hours, rather than one at a time\nInterfacing with other backup and recovery software\nInterfacing with monitoring software to report errors\nTip: When using an archive_command script, it's desirable to enable logging_collector. Any messages written to stderr from the script will then appear in the database server log, allowing complex configurations to be diagnosed easily if they fail.\nAt this writing, there are several limitations of the continuous archiving technique. These will probably be fixed in future releases:\nOperations on hash indexes are not presently WAL-logged, so replay will not update these indexes. This will mean that any new inserts will be ignored by the index, updated rows will apparently disappear and deleted rows will still retain pointers. In other words, if you modify a table with a hash index on it then you will get incorrect query results on a standby server. When recovery completes it is recommended that you manually REINDEX each such index after completing a recovery operation.\nIf a CREATE DATABASE command is executed while a base backup is being taken, and then the template database that the CREATE DATABASE copied is modified while the base backup is still in progress, it is possible that recovery will cause those modifications to be propagated into the created database as well. This is of course undesirable. To avoid this risk, it is best not to modify any template databases while taking a base backup.\nCREATE TABLESPACE commands are WAL-logged with the literal absolute path, and will therefore be replayed as tablespace creations with the same absolute path. This might be undesirable if the log is being replayed on a different machine. It can be dangerous even if the log is being replayed on the same machine, but into a new data directory: the replay will still overwrite the contents of the original tablespace. To avoid potential gotchas of this sort, the best practice is to take a new base backup after creating or dropping tablespaces.\nIt should also be noted that the default WAL format is fairly bulky since it includes many disk page snapshots. These page snapshots are designed to support crash recovery, since we might need to fix partially-written disk pages. Depending on your system hardware and software, the risk of partial writes might be small enough to ignore, in which case you can significantly reduce the total volume of archived logs by turning off page snapshots using the full_page_writes parameter. (Read the notes and warnings in Chapter 29 before you do so.) Turning off page snapshots does not prevent use of the logs for PITR operations. An area for future development is to compress archived WAL data by removing unnecessary page copies even when full_page_writes is on. In the meantime, administrators might wish to reduce the number of page snapshots included in WAL by increasing the checkpoint interval parameters as much as feasible.\nSome might find it helpful to use the following when using gzip and pg_compresslog:\nrestore_command = '[ -e /mnt/server/archivedir/%f ] && gunzip < /mnt/server/archivedir/%f | pg_decompresslog - %p'\nThis will correctly return non-zero for a missing file", "label": 1}
{"text": "An academic research paper by University of Pennsylvania researchers claims touch screen phones may be vulnerable to smudge attacks, a new form of security vulnerability based on the oily residue left on the screen. The researchers claim malicious attackers may be able to ascertain a certain amount of information, such as inferring a password used by the devices owner, left by the smudges left on a touch screen.\nThe researchers took photos of screens and used a program to analyze the photos closely. They found they could figure out the password over 90 percent of the time. The study used Android phones, which use a graphical pattern to allow users to unlock the phone. Phones included the Nexus 1.\nThe study also found that “pattern smudges,” which build up from writing the same password numerous times, are particularly recognizable.\nWhile it sounds somewhat plausible, I find it hard to believe that practical use of this vulnerability, assuming it is even an issue, will result in widespread exploits. The attackers would have to gain physical access to the device in order to make use of the exploit, and most bad guys prefer to do their dirty deeds from afar. This is not to necessarily downplay the issue but to speak towards the reality of the situation.\nIt should be worth watching to see if any true security issues ever come from this research. I applaud the University of Pennsylvania team for conducting some very exhaustive investigative work, and some very informative and interesting research, but the reality is this “vulnerability” is a non-issue right now.", "label": 1}
{"text": "Today's smartphones are much more than phones -- they are powerful, networked multimedia computers, and over the next 10 years they'll get far more advanced. As a result, mobility is transforming many day-to-day processes -- including how we sell, communicate, collaborate, train, and educate. The following are some key technological developments that will revolutionize the smartphone over the next decade.\nYour smartphone will have a 3-D display and a 3-D Web browser, and you won't need special glasses to view it. So instead of just viewing Web pages on your smartphone, you'll be able to go into environments (or stores or showrooms) and maneuver around in them, just as you do on devices like the Xbox. Alternatively, you'll be able to see things sticking out from the screen, again without the special glasses. So, the 3-D Web on your smartphone will be a game-changer for business.\nRather than have to remember numerous passwords, you will be able to access data and sites on your smartphone using multiple biometric authentications. Advanced screen resolution and sensors on the phone will make this possible.\nFor example, when you touch the screen, it will recognize you based on your fingerprint. In addition, your phone's front-facing camera will use facial recognition to identify you. Everyone's voice is unique, so voice recognition will also be part of the identification/security process.\nHow you handle the phone -- your keystrokes and touch/maneuver patterns -- are also unique. The number of biometrics used will depend on the level of security you want based on what you are doing. For example, if you're accessing your Facebook account, you may only want one biometric for authentication. However, if you're doing a high-level security activity (such as banking via your smart phone), you'll likely want to use multiple biometrics.\nYour smartphone will become your wallet. Credit cards are easy, but e-wallets are easier. Currently, Google has a mobile wallet that works with Citi MasterCard, and in the future it will work with other credit cards. It is secure and enables you to make payments with your smartphone.\nIn the near future, as every financial service firm gets into mobile payments, you will move very quickly from a leather wallet to a smartphone wallet. One example of an enabling technology is NFC -- near-field communications chips -- which are being built into smart phones as you read this article. They allow for secure and easy payment, so be ready for it.\nYour ultra intelligent agent will get smarter. The first ultra intelligent agent was Apple's Siri. As Siri-like agents advance, they will turn into personal assistants and will be able to search the Web for you and bring back focused, highly relevant information based on how long you have used your e-agent and how well it knows you.\nIn other words, your ultra intelligent agent will know your preferences, your likes, and your needs and will automatically compile, present, and share what's pertinent to you.\nAdditionally, your ultra intelligent agent will have a face when you are looking at the screen and a personality that you choose. You'll even see celebrities licensing the rights to their digital likeness and personality to be used as ultra intelligent agents.\nNo more screens\nSome of your smartphones will be screen-less. The traditional smartphone with a screen will not go away, but you will have an option for a screen-less smartphone. This will be a very popular and highly adopted smartphone because without the screen, you get rid of much of the need for a big battery. Think of the screen-less smartphone like the little piece of jewelry people wore on the old Star Trek TV show. The screen-less smartphone will be touch and voice activated. When you tap it, you'll be connected to your ultra intelligent agent, which is part of a super computer in the cloud. Whatever you need, your ultra intelligent agent will be able to verbally give you the information, such as turn-by-turn directions, reading your email to you and so on.\nYour smartphone will interface with smart surfaces. We are already seeing the beginning of using touch and voice-operated intelligent screens as tabletop computers that can access the internet. Simply by placing your smartphone on these surfaces, the two will link together. Additionally, your ultra intelligent agent will flow from your smartphone to the screen.\nThis is just a small sampling of what we'll see for future smartphone technology. All of these advancements are in their early stages today. So keep in mind that if it can be done, it will be done. The question is, who will be first?", "label": 1}
{"text": "Most Americans are aware that identity theft is a significant problem, and that it's important to take measures to protect your identity. What people might not know is their children may also be targets of identity theft before they even become old enough to own a credit card. The Federal Trade Commission has identified child identity theft as a growing problem and encourages parents to do what they can to minimize the risks to their children.\nThe most common way a criminal can steal or misuse the identity of a child is to get access to the child's Social Security number. The perpetrator then uses the Social Security number to open credit card accounts or loans, rent an apartment, sign up for utilities like cellphone service, or even apply for a job. Credit issuers often don't have a way to verify the age of the applicant, so if the criminal changes the age of the identity associated with your child, it's possible that the issuer may approve them for credit, according to the Identity Theft Resource Center.\nOnce an account has been established in your child's name, it's easier for criminals to establish subsequent accounts until this fraud is discovered. If your child's identity is stolen at an early age and the theft goes undiscovered until she reaches the age where she begins to establish her own credit, it can be very difficult to discover how the fraud first occurred.\nParents can take a number of steps to help prevent their children from becoming identity theft victims:\n- Store your children's Social Security cards in a safe place, such as a safety deposit box. Only give out your children's Social Security number when it's absolutely necessary, and provide alternate verification whenever possible.\n- Teach your children to never reveal personal information to anyone, no matter how trustworthy that person may seem. People close to the family are often found to be perpetrators in child identity theft cases.\n- If your child receives pre-approved credit card offers in the mail, you may want to check in with a credit reporting agency or Social Security. If you've been contacted by a collection agency regarding an account in your child's name, there's a possibility your child's identity was stolen.\n- Consider signing up your family members for a credit monitoring and identity protection solution.", "label": 1}
{"text": "Your user names, e-mail addresses and passwords are crucial for your internet security, so keep that in mind when you’re setting up an account on whatever site, forum or social media site you choose. The dangers out there in the online world are many: someone could try to trick you into revealing your personal data or downright steal it and use it to get into your bank account. And how about those pesky spam messages that clog up your inbox and waste your time?\nHere are a few internet security tips we’d like to share with you that will help you protect your online accounts from internet security threats such as hacking, phishing and identity theft:\n1. Use multiple addresses and make each one of them unique\nUse both numbers and letters when you create your e-mail address. This way you’ll save your address from spammers who use \"dictionary attacks\" to e-mail thousands of possible name combinations at large Internet Service Providers or e-mail services (ex: Hotmail, Yahoo), hoping to find valid addresses.\nYou should also have more than one e-mail address and use your second or “sacrifice” address to register to unknown websites, forums, and blogs or just to make online purchases.\n2. Create a user name that’s different from your e-mail address\nCreate a unique user name that is not associated with your e-mail address when you join websites like social networks or public forums. User names are accessible to anyone, so don't make it easy for internet crooks to guess your e-mail address.\n3. Mask your e-mail address when posting it online\nIf you need or want to share your address on a public website, you can mask it: just add a phrase or a character that people will know right away is not a part of your e-mail address. For example, if your address is “email@example.com”, you could mask it as “firstname.lastname@example.org”. This way spammers won’t pick up your address with their special software.\n4. Use strong passwords on all your accounts\nA strong password will never be guessed by someone else and that’s vital for your internet security, especially when you bank or shop online. Here are some hints:\n- Include letters, numbers and keyboard symbols (some of the symbols may be difficult to enter on foreign keyboards, so choose wisely)\n- Use at least 7 characters\n- Don’t use your username, your real name or your company’s name\nWhat makes a weak password? Any of the following, so think twice before resorting to them:\n- No password at all\n- A common dictionary word\n- Some piece of information about yourself that’s easy to guess from your online profile (your favorite sports team, your birthday, your spouse’s name)\n- The word “password”\n- One that you haven’t changed in the last few months\n5. Look after your passwords:\n- Never share your passwords with anyone. You never know how and where an internet security breach may appear from.\n- Don’t enter your password when others can see what you type in.\n- Have a unique password for banking sites, but don’t use the same one for different services.\n- Change your passwords every couple of months.\n- Don’t recycle your password for different accounts (for example password1, password2).\n- Don’t write passwords down, use memory tricks to remember them.\n- Never send your password by e-mail, as no serious company will ask you to do this.\n- Change your password immediately if you suspect someone else has figured it out.", "label": 1}
{"text": "Anyone can be a victim. Anybody who uses e-mail and has received a virus has been a victim of cybervandalism. Cybercrime—stalking, harassment, tampering, fraud, and theft of property or service—happens daily by way of the Internet.\nFrom left, Bill Oblitey and Mary Micco of the Computer Science Department and Dennis Giever of Criminology\nIf Dennis Giever had a credo, it might be an ounce of prevention is worth a pound of cure. A hackneyed admonition, perhaps, but one that might make the hacker drop in his tracks. He believes that it is the average citizen who will notice an act of terrorism or other crime by means of technology, and, therefore, blow the whistle. To notice it, he or she must recognize it.\nThe Criminology Department chairperson’s vision for an undergraduate minor in cybersecurity is based on prevention and public awareness; what makes it special is that it may be the first in the nation to be multidisciplinary, entailing courses in both computer science and criminology. It is meant for the average citizen, not the technology expert.\nGiever joined colleagues in the Computer Science Department, Mary Micco and William Oblitey, to write a proposal and receive a $250,000 grant from the National Science Foundation. The grant funds development of a minor program and allows IUP to offer workshops that might spur other educators to develop similar programs.\n“Our goal is to start the process of educating the masses,” said Giever. “The realization is that we have to get this information into classrooms everywhere.”\nWhile the official minor discipline is being developed by faculty members in both academic areas, two courses already are offered to IUP students. Criminology offers Cybersecurity and the Law, and Computer Science offers Cybersecurity Basics, according to Giever. Micco, Oblitey, and Giever oversaw three workshops during the summer meant to assist educators in other settings to develop their own programs; another workshop is planned. In addition, the Computer Science Department is developing an information assurance concentration, and certification and literacy programs are being considered.\n“We want to be proactive. The [experts] in the field today are reactive. If something happens, they have tons of expertise to fix and investigate a problem,” said Giever, referring to crimes such as product tampering, interruption of service, stalking, and murder. “We want to prevent these things from happening…. It becomes an issue of public awareness. We have a long way to go before the general public understands all of this,” Giever said. “A small circle of specialized IT professionals has traditionally been responsible for working with this type of activity. But, it’s time that not just they and law enforcement officials understand this. The office manager must understand. That’s why we need an interdisciplinary minor.”", "label": 1}
{"text": "Browser-hijacking malware talks to attackers using SPF email validation protocol\n- — 28 January, 2013 16:17\nA new Trojan program that displays rogue advertisements during browsing sessions uses a DNS-based email validation protocol called the Sender Policy Framework (SPF) in order to receive instructions from attackers without being detected, according to security researchers from Symantec.\nHowever, the most interesting aspect of this malware is the way in which it receives updated URLs from attackers to use in the rogue HTML script elements.\nThe malware periodically generates a domain name according to a predefined algorithm and makes an SPF lookup for it. Knowing in advance which domain will be generated, the attackers register it and configure its SPF record to contain IP (Internet Protocol) addresses or host names that will be used by the malware to construct new malicious URLs.\nSPF was designed to detect email spoofing and is implemented using the DNS (Domain Name System).\nA domain name owner can specify an SPF policy -- a number of IP addresses or host names that are allowed to send emails from that particular domain -- inside a DNS TXT or SPF record. Email servers can then perform SPF lookups via DNS in order to check that email messages appearing to have been sent from that domain actually came from an IP address authorized by the domain administrator.\nIf the sender IP address or host specified in an email's header is not listed in the SPF policy for the corresponding domain name then the email sender's address was probably spoofed.\nIn the case of Trojan.Spachanel, the SPF policy for the domain name is not used to validate emails, but to provide a new list of malicious host names to be used by the malware.\nUsing this technique, attackers can hide the malicious traffic from firewalls and other security products that might otherwise block direct connections to known malware command-and-control servers.\nThat's because in order to perform SPF lookups, the malware queries a trusted DNS server located on the local network or the Internet service provider's network. This server then queries other DNS servers up the chain until the request reaches the authoritative DNS server for the domain name, which responds with a TXT or SPF record containing the SPF policy.\n\"In some cases, specific domains are blocked by a local DNS server, but this malware generates a domain that is rarely filtered,\" Katsuki said.", "label": 1}
{"text": "NSF award for Dr. Carpenter\nNSF Award on Preventing Psychology Cyber-Attacks\nApproximately six million Americans are targets of identity theft each year. Many of the attacks on identity privacy use psychological influence strategies (\"psychological attacks\") to induce individuals to provide their private information. Although people are appropriately concerned about their privacy, they often unnecessarily disclose information that could be used to their disadvantage. Our studies have shown that people's privacy exposure behaviors may be severely affected by psychological attacks. Unfortunately, research from a psychological perspective to mitigate the attacks is scarce. This research identifies critical aspects of warnings for a sub-set of psychological cyber-attacks on privacy and provides guidelines for developing effective mitigations against other types of psychological cyber-attacks. We create computer-mediated countermeasures. We also ascertain the extent to which the warnings capture attention, are understood, are memorable, increase perceptions of risk, decrease trust, and lead to compliance under conditions of psychological attacks.\nThis research is a first investigation of whether theoretical models developed to reduce risky behaviors (e.g., health-related behaviors) can be extended to the domain of computer privacy. The research determines whether warnings can have significant impact on people?s decisions about disclosure of their private information. The effectiveness of our mitigation approach is tested on hand-held devices and web sites with the goal of increasing compliance with the warnings.\nThis research provides mitigation strategies for private information exposure and provides guidelines for software developers to use when designing privacy preserving software. Potentially, the results can be generalized to mitigate other current and future psychological privacy attacks. Research findings are disseminated in both social psychology and computer science. In addition, a website is developed to share the research results, the data sets, and the lessons learned, in order to raise the awareness of the importance of protecting identity information and mitigating psychological cyber-attacks.\n- Hits: 2225", "label": 1}
{"text": "Got this from IT at work. Use Caution with Search Engines\nNan and Sandy Sanders\nesanders at erols.com\nThu Nov 29 20:35:00 CST 2007\nUnlike the usual message of this type, this seems for real. Read the\narticles linked at the end.\nInformation Security Advisory: Use Caution with Search Engines\nA new threat has been discovered that affects the entire Internet.\nThe most widely used search engines; including Google, Yahoo, and\nMSN; contain links to malicious websites that appear near the top of\nsearch results. Seemingly legitimate searches may lead users to sites\nthat contain viruses, trojans, and other malicious code that can be\neasily transferred to the browser's computer.\nHow it Works\nAttackers have created enormous automated networks to spoof and scam\nsearch engines into placing their websites near the top of search\nresults. Unwary users assume that popular search engines only point\nto legitimate websites.\nMalicious iFrames, rootkits and fake codecs are being served up on\ntens of thousands of sites returned as results for searches for such\nthings as alternate router firmware or \"how to for Microsoft Excel,\"\n\"currency converter,\" \"americanexpress/activate,\" and \"knitted or\ncrocheted dachshund patterns.\"\nBy clicking on these sites, users may become infected by adware,\nviruses, or even rootkits and password stealers.\nThere's no absolute way to determine if a website contains malcode or\nnot. But some good practices include:\n- don't click on any link ending in \".cn\"\n- don't click on website names or descriptions that don't\n- don't accept any requests by websites to install drivers,\ncodecs, or any other application on your system\nThese links provide more technical information about the situation.\nMore information about the Tacos", "label": 1}
{"text": "How to Avoid Malware Online\nMalware (malicious software) is the collective term used for software that is designed with the intention of slowing down, appropriating or crippling a device or a network. Malware can also be tailored to covertly record information regarding your online activities and relay that information to its designers. This is illegal and usually done with the intention of offering the information as a cheap alternative to legitimate market research. It is also commonly used to steal private and banking information for the purposes of identity and currency theft.\nMalware comes in many shapes and sizes, all of which are undesirable and should be avoided wherever possible. Unfortunately this can be a tricky process, as knowing when and where Malware will strike is difficult and can be confusing to many users. Of course, Malware can always be removed after it has been installed, but as with most things of this nature prevention is better than cure.\nRegarding the prevention process there tends to be 2 prevailing but dichotomously opposed attitudes:\n- Anti-virus software is key. Grab the most powerful anti-virus program you can and you should be safe.\n- Anti-virus software is useless. It slows down your computer needlessly when all that was needed in the first place was a little common sense and caution on behalf of the user.\nOf course, as with most areas of fierce debate, the answer tends to lie somewhere between the two. Anti-virus software can indeed be helpful in protecting you from malware, but it’s important to not rely on it too heavily. Anti-virus software should be viewed as your safety net, or last-line of defence. There are many types of malware than can circumnavigate anti-virus software.\nThe argument that anti-virus software slows down a computer is also somewhat valid. While modern-day anti-virus programs are much lighter and require less of your system’s attention than older iterations, they can cause increased delays when starting up a computer or installing new software. Due to the lighter nature of today’s anti-virus software these delays are usually quite minimal in comparison to what their opponents claim, but the delays do still exist, nonetheless.\nAs such we advise merging the two ideologies. While most of the responsibility of avoiding malware can easily rest on the user, it’s still a good idea to be running some form of background protection, however minimal, in order to have a chance of catching anything that slips by.\nCommon Types of Malware\nFar and away the most well-known form of malware is the computer virus. A virus hides in pre-existing programs, applications or system files and is capable of replicating itself. A virus will usually try to spread itself to other computers once it has infected yours. This can be done over the internet, over a closed-network or by transmitting itself to a data transfer device such as a USB key.\nA worm is similar to a virus in that it can replicate itself, only it does not hide in pre-existing files but instead is a file unto itself. Worms are usually designed to destroy files, hinder networks and generally decrease computer efficiency. Some worms, such as the Blaster Worm from 2003, can actually prevent your computer from fully starting up before it shuts down again.\nTrojans are possibly the most dangerous form of malware from a social and personal-economic standpoint.\nA Trojan will find its way on to your computer using another file as a carrier. It rarely destroys files or affects computer performance. Rather, Trojans are generally intended to record user information, such as passwords or banking details, and relay this information to the developer.\nA botnet is not a piece of malware unto itself, but rather something that is created by malware. What happens here is that your computer is taken over by a botnet operator and used for their own purposes. This can be anything from increasing computer-power in order to perform brute-force hacks or to unleashing dedicated denial of service attacks on websites. Basically your computer is secretly turned in to an unwilling part of a large hive-mind of similarly enslaved computers, with one puppet-master pulling all the strings.\nThis is often not a conspicuous process and the puppet-master will go to great lengths to ensure that your computer’s new status as a zombie will not be noticed.\nSpyware, surprisingly enough, spies on you. This is generally done with the intention of gathering marketing data so that companies can more accurately advertise to you.\nAdware is similar, but actually contains the ads themselves. Adware is often installed on your computer legally, as it can be found in many user licence agreements. Agreeing to a user licence agreement can often mean you have given a company permission to install adware on your computer.\nSpyware and Adware can usually be removed with active system scans.\nModern Malware Penetration Techniques\nAs technology changes and online security systems advance so does malware and the methods that are employed to get it from its developer to your computer. Where once malware was predominantly passed around on USB drives, floppy discs or emails it’s now far more common to see more inconspicuous methods. Many victims of malware actually never realise that they’re a victim until real-world repercussions start rolling in.\nOne of the more common methods for the transferral of malware is to use a malicious or hacked website as a carrier. These websites will prompt you to download an innocent-looking package such as a video codec or browser plugin that is ‘required’ to view material on the website. Another method is to exploit browser security holes to install malware directly on to your computer without even asking.\nHowever, even prompted-downloads can be difficult to spot. This isn’t because you are somehow tricked in to clicking a download button without your knowledge, rather it is because reliable websites can be hacked and turned in to malware-dispensing tools. Even the BBC has had a couple of its websites turned in to these malware vendors in the past.\nPossibly the nastiest way that malware commonly proliferates by pretending to be ‘free’ anti-virus software. An alert will pop up in the user’s browser, warning them that a threat has been detected on their computer and that they have to download this new software now in order to eliminate it. The unwitting victim then dutifully downloads the package, allowing the real malware threat that was actually the download itself instant access to their system. Do not fall for this. Only pre-installed anti-virus programs should ever be installed.\nIf you get a pop-up from a program that is not already installed on your computer then ignore it and leave the website immediately. Don’t even click the ‘x’ box in the top right or left of the pop-up if you can avoid it, as that might be a cleverly hidden download button. You may also wish to contact the website to warn them that they have been hacked, but doing so may increase your risk and thus is up to you.\nDesktop PCs laptops running Windows are still the most vulnerable devices to malware. Apple Macs have become a larger target in recent years as well, but still get less attention from malware developers than anything running Windows. Android phones have also become a target, due to Android’s open-source nature and a user’s ability to download an app that has not been directly approved of by Google. Anything downloaded through the Google Play store (previously Android Market) should be safe. iPhones and iPads haven’t really had any problems, mostly thanks to Apple’s often strict control over the iOS ecosystem so that nothing that hasn’t passed Apple’s required tests isn’t made available on the App Store.\nThe key to staying safe from malware is to be alert. Be careful with small-time or dodgy-looking sites. Smaller websites usually have worse security methods in place and thus can be targeted more easily by malware developers. It’s also less common for maliciously-designed websites to look and act as professionally as a larger one, as malware developers often won’t have the kind of money that’s necessary to create a first-class web experience just to lure in unsuspecting prey. If a website looks bad or unprofessional then you might want to think twice about visiting there, let alone downloading any files.\nMost larger sites, especially those that support monetary transactions or store personal information, will use a more secure network. This can often be spotted easily, as the web address will begin with ‘https’ rather than the traditional ‘http’. Modern browsers and anti-virus packages will also often provide some kind of a marker, such as a green box or tick, to indicate that a website has been tested and is now a trusted source.\nAs far as anti-virus applications for Windows go there are some solid free options such as AVG, Avast, Avira and Microsoft’s Security Essentials. These programs provide a constant passive protection, as well as a more direct approach.\nIf your computer is acting sluggishly, or you believe you may have some malware, you can activate a scan that checks every file on your system. This is best to do overnight or while you’re out as it usually takes time to complete. Any threats that are detected will be quarantined until you decide what to do with them. The usual course of action is deletion. Scanning will not find every piece of malware out there, but it will detect and eliminate most of them. If you’re using a dedicated anti-adware program for this be careful, anti-adware packages are one of the more common fake ‘security services’ previously mentioned that end up being malware themselves. It’s probably best to use your pre-installed anti-virus software, if you have it.\nCurrently Mac users tend to not have to really worry about security software, as the prevailing majority of malware is still designed to target Windows machines.\nBasically we suggest that you remain alert and only use Anti-Virus software as a backup. The first and best defence against malware is to pay attention to what you’re doing and avoid online threats. Keep your eyes peeled and if you see something suspicious play it safe and just avoid it, rather than hoping your Anti-Virus package will protect you.", "label": 1}
{"text": "Cyber security software usage variations create vulnerabilities\nThere is certainly a difference between how cyber security software performs in a testing environment and how it performs in the real world. The many variables in real world usage patterns add an entirely new dimension to cyber security. Through my work at the Smart Grig Interoperability Panel (SGIP), I’ve come to believe that systems designers must consider the various means of inappropriate use or abuse capable by untrained users or nefarious individuals and provide appropriate testing for such usage at the outset.\nWhen we install conformant and interoperable products in the smart grid and achieve interconnectivity and information flow only a few experts need to know how to use the software. The software is most often a transparent service to the users. But when we are implementing a cyber secure system, we have to implement processes that ensure that the users of the system (who typically are process-oriented individuals and not technical experts) are using it in the proper manner and not opening holes that breach security. Many breaches in systems occur because the user either did not configure them so they would be appropriately secure or because they used them outside of the environment they were intended to function.\nExamples abound: Users did not select an appropriate password. Users did not use encryption on their laptop hard drive and it was stolen. That one should sound familiar, as it has occurred multiple times in organizations whose names you would immediately recognize. Users gave out their private security key or left a hardware token on their desk. Users added a device to their system which circumvented the organization’s security policy. Etc.\nTherefore, interoperability and conformance testing cannot be content to simply focus on testing of message boundary exchanges and data structure syntax or even the presence of proper cyber related algorithms in the software under testing. Going with the examples above, tests might incorporate scenarios of data-at-rest encryption or dual-factor authentication or other product specific tests. While poor user interaction can never be totally predicted and fully addressed, it must be considered in developing interoperability and conformance testing.\nSo, we must view cyber security as an integral part of the interoperability and conformance testing – performing testing for all of them in a coordinated manner. We must have input from security professionals, both on how the software should be used as well as how it may be used in the real world. Only by employing such a unified approach can we have confidence that our testing methodology is appropriately focused. For more information, see the Smart Grid Testing and Testing Certification Committee wiki page. What are your experiences with these testing and usage challenges? Let us know.\nRik Drummond, CEO Drummond Group Inc\n- An Accredited Test Lab and Certification Body by NAVLAP and ANSI\n- Chair emeritus DoE’s Grid Wise Architecture Council\n- Chair NIST Smart Grid Interoperability Panel’s Testing and Certification Committee", "label": 1}
{"text": "Protect Your Passwords from Theft\nPasswords are the keys to a person’s identity. However, it is more and more often the case that we hear of passwords and their corresponding usernames falling into malicious hands … causing financial loss, time loss, emotional distress, and worse.\nIn this day and age, you pretty much have to use the Internet and deal with passwords and security issues. You can take many steps to protect yourself from password theft and to minimize the damage caused if a password were to fall into the wrong hands.\nCommon Ways Passwords are Compromised\nIn order to protect your passwords, we need to have a good idea of what we are protecting them against. The most common ways that people’s passwords are discovered by others include:\n- Using “Insecure Connections” to web sites and Internet services. Malicious people in the same wifi hotspot or network as you can eavesdrop on your communications and easily discover your username, password, and any other information sent to or from your computer.\n- Companies that are hacked. Just like what happened recently with Sony’s Playstation Network (70 million accounts stolen including usernames, passwords, and perhaps other personal and financial information).\n- Passwords being guessed. Manual or automated attempts at guessing peoples passwords. Either people sitting down and trying to try passwords that they think you may use, or computers trying thousands or millions of common passwords until a match is found.\n- Company employee access to passwords. Many times, employees at companies (like Gmail) have full access to your passwords. They can, maliciously, save them and use them.\n- Scraps of paper. You wrote your password(s) down on a post-it note and someone saw it …\nHow to Protect Your Passwords\n1. Do not use “Insecure Connections”.\nIf you are connecting to a web site, be sure that the address in your browser’s address bar starts with “https://” and not “http:”. The “s” in “https” means “secured using SSL” and means that everything between you and that site is encrypted. However, if your browser gives you a warning that the site is “not trusted” or that there is some problem with the web sites “certificate”, you should NOT go there and login — someone may be trying to intercept your connection to glean your credentials!\nConnecting to other services, like email, chat, Facebook or Twitter, should also be made over SSL or TLS connections. If you want to use a service and they do not support secure connections, either do not use them, or use a username and password that is only for them (so if it gets discovered, it won’t impact anything else you are doing).\n2. Do not write your passwords on post it notes.\nLeaving your passwords written down and lying around is a great way to get yourself in trouble. Instead of the “post-it note” method of remembering passwords, it is best (if you can’t just remember them all in your head — but really, who can?) to store them in a secure database. I.e. keep all the usernames, passwords, and other pertinent information (like secret questions and answers) in a file or database or location that is itself encrypted — with one password, the only password your really have to remember (or maybe it is protected with a fingerprint reader … even better). With an encrypted password database, you can access all of your password data anytime, and no one else can get to them, even if they have access to your computer and all of your stuff.\nLuxSci provides one such solution in its WebAides suite — online Encrypted Password storage. Access your passwords securely from anywhere you have an online computer, and rest assured that the passwords are actually backed up and safe from disaster, misfortune, or compromise.\n3. Choose vendors that do not actually save your passwords in “plain text” anywhere.\nThe big problem with companies being hacked or having malicious employees is that databases of customer information get stolen. It is often the case, that companies have your passwords stored in “plain text” along with your username in their databases. I.e. if your password is “apple123″, and anyone looks in the database, they would see that clearly — and that is bad.\nAnother way to do things is for companies to store only “hashes” of passwords. A “hash” is a one-way mathematical function for turning “plain text” like “apple123″ into pretty unique gibberish like “$1$rjogGOYN$0p0j.DxKEBw0qKh4w1svU1″. They only store the gibberish (the hash) in their databases. In this way, they can still see if your password is correct by passing it through that math function and seeing if the result matches the gibberish. However, you can’t “go backwards” from the gibberish to the original password. If the database of a company that stores only hashes of passwords is stolen somehow, the passwords themselves are safe (well, mostly — see below).\nIf you can, you should choose to work with companies, like LuxSci, that never store plain text passwords anywhere.\n4. Choose good passwords!\nThis almost goes without saying, but if you don’t keep saying it, people won’t do it.\nIf you choose a simple (poor) password like “apple”, it is easily guessed by computer programs that try millions of common words, phrases, and commonly used passwords. How?\n- Some systems (unlike LuxSci’s) allow unlimited login attempts in a short period of time, even if they are all failing and all from the same place. This allows computer programs to quickly try all kinds of different passwords until one is found that works (the so-called “brute force” approach).\n- Also, if the gibberish (the hash) of a password is known, while you can’t “go backwards”, you can try all kinds of passwords and see if any of them “go forwards” and match the hash. If one does, it is the proper password.\nIf your password is simple, it can be quickly guessed by a computer in either of the above situations. If not, you are probably safe.\nWhat makes a good password? Doing a combinations of:\n- Using a phrase instead of a word: i.e. “let the games begin”\n- Using symbols and numbers and mixed case: i.e. “Let the 2011 Game$ begin!”\n- Keep it complex, but easily remembered.\n5. Use different passwords for different sites / accounts\nA big “no no” is to use the same password everywhere. Why? If it gets compromised in one place, then all of your accounts are vulnerable. The more places you use your password, the more vulnerable it becomes.\nOf course, the best thing to do is to use a different good password for each account you have. However, remembering all of these passwords quickly becomes cumbersome, even with a good password database. It is best if you can have different passwords for each account and create them in a way that makes them (a) strong, (b) easily remembered, and (c) you can’t easily guess one if you know another one.\nFor a good way to do this, see: Security Simplified, the Base+Suffix Method for Memorable Strong Passwords.\n6. Use Two-Factor Authentication when available and choose companies that support it!\nTwo Factor Authentication typically requires some kind of verification beyond your username and password in order to gain access to an account. I.e. if you have Two Factor Authentication enabled at LuxSci, when you login you will have a “token” (a short number) sent to either an alternate email address of your choice or to your mobile phone as a text messages. You have to access this token and enter it into the login page in order to complete the login process.\nTwo Factor Authentication protects your account against your password being stolen … as without access to the “second factor” (i.e. your phone), your account is still safe from intrusion.\nYou can also use a good OpenID to provide multi-factor authentication, if your account supports it.\n- How to Protect Yourself from Password Theft\n- Two Factor Authentication\n- DuoSecurity: Advanced Two-Factor Login for LuxSci’s Web Interface\n- How can I remember all these ##@! passwords?\n- Master Password Encryption in FireFox and Thunderbird", "label": 1}
{"text": "Peer-to-peer (P2P) File Sharing & Copyright Safety\nPeer-to-peer (P2P) file-sharing allows users to share files online through an informal network of computers running the same software. File-sharing can give you access to a wealth of information, but it also has a number of risks. You could download copyright-protected material, pornography, or viruses without meaning to. Or you could mistakenly allow other people to copy files you don't mean to share.\nIf you're considering P2P file-sharing:\n- Install file-sharing software carefully,\nso that you know what's being shared. Changes you make to the default settings of the \"save\" or \"shared\" folder might cause you to share folders and subfolders you don't want to share. Check the proper settings so that other users of the file-sharing network won't have access to your private files, folders, or sub-folders.\n- Use a security program from a vendor you know and trust;\nkeep that software and your operating system up-to-date. Some file-sharing software may install malware or adware, and some files may include unwanted content.\n- You may want to adjust the file-sharing program's controls\nso that it is not connected to the P2P network all the time. Some file-sharing programs automatically open every time you turn on your computer and continue to operate even when you \"close\" them.\n- Consider setting up separate user accounts,\nin addition to the administrator's account, if your computer has multiple users. Limiting rights on user accounts may help protect your computer from unwanted software and your data from unwelcome sharing.\n- Back up data\nyou don't want to lose in case of a computer crash, and use a password to protect any files that contain sensitive information.\nP2P File-Sharing: Evaluate the Risks\nEvery day, millions of computer users share files online. Whether it is music, games, or software, file-sharing can give people access to a wealth of information. To share files through a P2P network, you download special software that connects your computer to other computers running the same software. Millions of users could be connected to each other through this software at one time. The software often is free.\nSounds promising, right? Maybe, but make sure that you consider the trade-offs. OnGuard Online cautions that file-sharing can have a number of risks. For example, when you are connected to file-sharing programs, you may unknowingly allow others to copy private files — even giving access to entire folders and subfolders — you never intended to share. You may download material that is protected by copyright laws and find yourself mired in legal issues. You may download a virus or facilitate a security breach. Or you may unwittingly download pornography labeled as something else.\nTo secure the personal information stored on your computer, OnGuard Online suggests that you:\n- Install file-sharing software carefully\n- so that you know what's being shared. When you load a file-sharing application onto your computer, any changes you make to the P2P software's default settings during installation could cause serious problems. For example, if you change the defaults when you set up the \"shared\" or \"save\" folder, you may let other P2P users into any of your folders — and all its subfolders. You could inadvertently share information on your hard drive — like your tax returns, email messages, medical records, photos, or other personal documents — along with the files you want to share. And almost all P2P file-sharing applications will, by default, share the downloads in your \"save\" or \"download\" folder — unless you set it not to.\n- Use security software and keep it and your operating system up-to-date.\nSome file-sharing programs may install malware that monitors a user's computer use and then sends that data to third parties. Files you download may also hide malware, viruses, or other unwanted content. And when you install a P2P file-sharing application, you might be required to install \"adware\" that monitors your browsing habits and serves you advertising.\nMalware and adware can be difficult to detect and remove. Before you use any file-sharing program, get a security program that includes anti-virus and anti-spyware protection from a vendor you know and trust and make sure that your operating system is up to date. Set your security software and operating system to be updated regularly. Make sure your security software and firewall are running whenever your computer is connected to the Internet.\nDelete any software the security program detects that you don't want on your computer. And before you open or play any downloaded files, scan them with your security software to detect malware or viruses.\n- Close your connection\n- In some instances, closing the file-sharing program window does not actually close your connection to the network. That allows file-sharing to continue and could increase your security risk. If you have a high-speed or \"broadband\" connection to the Internet, you stay connected to the Internet unless you turn off the computer or disconnect your Internet service. These \"always on\" connections may allow others to copy your shared files at any time. To be sure your file-sharing program is closed, take the time to \"exit\" the program, rather than just clicking \"X\" or \"closing\" it. What's more, some file-sharing programs automatically open every time you turn on your computer. As a preventive measure, you may want to adjust the file-sharing program's controls to prevent the file-sharing program from automatically opening.\n- Create separate user accounts\n- If more than one person uses your computer, consider setting up separate user accounts, in addition to the administrator's account, and give those user accounts only limited rights. Since only a user with administrator rights can install software, this can help protect against software you don't want on your computer. It also can keep users from accessing other users' folders and subfolders, since users with limited rights generally don't have access to each other's information. Also use a password to protect your firewall and security software so no one else can disable them or grant themselves rights that you don't want them to have on your machine.\n- Back up sensitive documents\n- Back up files that you'd want to keep if your computer crashes. Store them on CDs, DVDs, or detachable drives that you keep in a safe place.\n- Talk with your family about file-sharing\n- If you're a parent, ask your children whether they've downloaded file-sharing software, and if they've exchanged games, videos, music, or other material. Talk to your kids about the security and other risks involved with file-sharing and how to install the software correctly, if they're going to use P2P file-sharing at all. If you're a teen or tween interested in file-sharing, talk with your parents before downloading software or exchanging files.\nFor more information about peer-to-peer file sharing and how it relates to copyright infringement, visit https://protect.iu.edu/cybersecurity/safeonline/filesharing/tutorial.\nSanctions for copyright infringement\nUnauthorized distribution of copyrighted material using Indiana University's information technology resources — including sharing copyrighted music, movies, and software through peer-to-peer applications like LimeWire, BitTorrent, etc. using Internet access provided by IU — is against the law and university policy. Unlawful file sharing may subject you to legal penalties, which can include any or all of the following:\n- Having to pay money to the copyright holder in a lawsuit — between $750 and $30,000 for each file, and up to $150,000 for each file if the infringement was willful\n- Having to pay the copyright holder's costs and attorney fees to bring the lawsuit\n- Criminal fines of up to $250,000, and up to 10 years' jail time — even if someone sharing files doesn't sell or charge for them\n- Seizure and destruction of infringing files\nAdditionally the university may impose sanctions, including loss of network access and disciplinary action. Visit https://protect.iu.edu/cybersecurity/safeonline/filesharing/procedure for further information about these sanctions or to learn how to avoid copyright infringement claims from music, movie, and software copyright holders.", "label": 1}
{"text": "by Dr. Scott Vanstone\nThe Practical Side of Public-Key Authentication\nThe authentication of the public keys used in a security protocol is one of the essential steps to ensuring the authenticity of the participants.\nYou may ask, “Why do you need to authenticate the public keys in a security protocol?” Without authentication, it may be possible for someone to insert themselves in a protocol and appear as a valid participant. This is the traditional man-in-the-middle attack. For example, assume Alice and Bob are using Diffie-Hellman (DH). If Eve inserts herself into the communications path and impersonates both Alice and Bob in the DH protocol, Alice and Bob will discover this only if they authenticate the public keys they receive from each other. This is because each will have received Eve’s public key during the exchange rather than each other’s authentic keys.\nPublic-key authentication schemes range from manual to fully automatic methods. Manual methods work well when a limited number of parties are involved; automated methods are generally more secure and cost effective for large distributed networks. Manual authentication usually involves an out-of-band verification process, such as telephonic verification, the use of pre-shared secrets, or public key signing “events” such as those held at IETF meetings.\nAs the number of users increases, it is no longer always practical to use a manual method – users may not know each other or secure communications must be established “on-the-fly”. A VPN device or a secure telephone may need to establish a secure session with a previously unknown (but authorized) party. For these applications where a manual setup process is too costly or time intensive, an automated method must be used. Automated methods will rely upon certificates; and as we’ve seen in this issue of Code and Cipher, there are many forms of certificates ranging from implicit to proprietary and X.509 explicit formats.\nWhen certificates are used, a Certificate Authority (CA) is required. However, it need not be complex or standalone. Again, depending on system criteria, the CA could be built into one device and issue certificates to the other communicating devices. For instance, a CA in a manufacturing environment may create and load a manufacturer’s certificate into each device before it is shipped. At the customer site, another device with a built-in CA will communicate with all other deployed devices, validate their manufacturer’s certificates, and then issue new customer-specific certificates to them. These certificates can be proprietary, if it’s a closed network, or X.509 for an open network. Both proprietary explicit and implicit certificates can be very lightweight. A public CA really only needs to be used when secure communications must be established between parties who have little to no other a priori knowledge of each other.\nObviously, this column is not a complete discussion of authentication methods or certificates. There are many alternatives available for performing the critical task of public key authentication. Security requirements, level of expertise and resources available all influence the final product. The use of a simple embedded CA issuing either implicit or explicit certificates can provide high security and great efficiency. Which authentication solution you select will depend on your specific application and its projected usage requirements.", "label": 1}
{"text": "A form of attack on a database-driven Web site in which the attacker executes unauthorized SQL commands by taking advantage of insecure code on a system connected to the Internet, bypassing the firewall. SQL injection attacks are used to steal information from a database from which the data would normally not be available and/or to gain access to an organization's host computers through the computer that is hosting the database. SQL injection attacks typically are easy to avoid by ensuring that a system has strong input validation.\nFeatured Partners Sponsored\n- Increase worker productivity, enhance data security, and enjoy greater energy savings. Find out how. Download the “Ultimate Desktop Simplicity Kit” now.»\n- Find out which 10 hardware additions will help you maintain excellent service and outstanding security for you and your customers. »\n- Server virtualization is growing in popularity, but the technology for securing it lags. To protect your virtual network.»\n- Before you implement a private cloud, find out what you need to know about automated delivery, virtual sprawl, and more. »", "label": 1}
{"text": "There have been so many password \"hacking\" stories lately, I thought I'd write this post so I can refer back to it. For added security, I've included the above image of Makise Kurisu, the scientist in my anime harem.\nCovering my behind\nCrypto is an exact science, so before I go any further I will make these clear.\n- When I say random, technically I mean pseudorandom. Algorithms are deterministic, and computer order and logic can't strictly speaking produce \"true\" randomness. Contemporary algorithms are an order of magnitude better than the BASIC RND() function of yore though.\n- When I say impossible and one way, I mean practically speaking. Our current algorithms would take the birth and death of several universes to brute force with current hardware, but that doesn't mean it's impossible. Just very very very very improbable!\nHow passwords are supposed to be stored\nWhen you create an account with a well designed, secure website, your chosen password is not stored anywhere. Instead, your password is put through a one way cryptographic hashing algorithm which converts it to random gibberish, along with some salt or random information only the web server knows.\nWhen you attempt to log into your site, the password you give is hashed and compared to the hash on file. If they're the same the server knows you have the right password.\nIt's a proven, tested technique and it works... provided everything is implemented properly. No doubt you've seen plenty of news stories suggesting sound security is harder than coming up with some snappy alliteration on a blog post.\nWhy go to the trouble?\nRather than storing a hash of a password, you could simply store the password and compare it when someone logs in. It's simpler, and a worryingly large number sites still do this.\nThe problem is, if the database is broken into, the malicious hacker has access to all your customer's passwords. People like conserving energy (politically correct way of saying lazy!), and are probably using those same passwords for all sorts of stuff including their banking sites, email, social networks and so on. You can see what a disaster this could be!\nIf you store them as hashes, all anyone ever sees is random gibberish... even the site owner!\nHow to tell\nShort of asking the site administrator, there are two main tells that a site is storing your passwords instead of a hash:\n- They're able to provide you with your password. This could happen when you first create your account and they send you a welcome email, or if you've said you've forgotten your password. A secure site should always direct you to a page to reset it, because they don't know your password either.\n- Hashes take any password length and adjust them to a uniform size (such as 128 bits). Not always, but often if a site puts a limit on your password length, it's because they're storing it as plaintext in their database.\nThere may have been (bad) excuses for these practices in the past, but not any more. If a site you access does either of these, it's time to question how important they are and whether they're worth risking your data and security over. Blunt, but true.\nIf you suspect a site you access is storing your password in plain text and you have no choice but to use them, complain, and make sure you pick something random and unique to that one site. If/when they get broken into, you'll be glad you did.", "label": 1}
{"text": "beware of clicking links in email or im messages\nPhishing occurs when a person attempts to steal personal information or install malicious software on your computer with the intention of stealing money from you. Cybercriminals can do this in a number of ways, all of which require some action on your part. They might email you, call you on the phone, post a link on your Facebook wall, or convince you to download something off a website. The best way to protect against phishing scams is to know the signs.\nSigns of phishing scams:\n- Incorrect Spelling and Grammar - Professional companies will not send out mass emails with spelling or grammar mistakes. If you find mistakes in an email, there is a good chance it is a scam.\n- Beware of Links - If an email seems suspicious, do not click on any links. Be especially suspicious of any truncated or shortened URL which then redirects you to the actual web site.\n- Threats - A common characteristic of spam emails are threats. For example, a typical phishing email might warn that your Hotmail account will be closed if you do not verify your personal information at a given address. The email is a scam intended on stealing your personal data.\n- Suspicious Facebook Posts - When a Facebook friend makes a post on your wall that seems uncharacteristic of that individual, be sure to avoid clicking on any links associated with the post. Often, spammers exploit contact lists and social media websites to virally spread their messages.\nKeep your computer safe. When in doubt, delete the email or message.\n- Learn more about staying safe or what to do if you’ve already given out personal information from the Anti-Phishing Work Group (APWG).\n- Learn about phishing scams at BC.\n- Test your knowledge by taking this phishing quiz.\n- Learn what to do, if you think your identity has been stolen from the FTC (Federal Trade Commission).", "label": 1}
{"text": "|Understanding VPN IPSec Tunnel Mode and IPSec Transport Mode - What's the Difference?|\n|Written by Administrator|\n|Sunday, 06 May 2012 04:14|\nIPSec’s protocol objective is to provide security services for IP packets such as encrypting sensitive data, authentication, protection against replay and data confidentiality.\nAs outlined in our IPSec protocol article, Encapsulating Security Payload (ESP) and Authentication Header (AH) are the two IPSec security protocols used to provide these security services. Analysing the ESP and AH protocols is out of this article’s scope, however you can turn to our IPSec article where you’ll find an in-depth analysis and packet diagrams to help make the concept clear.\nUnderstanding IPSec Modes –Tunnel Mode & Transport Mode\nIPSec can be configured to operate in two different modes, Tunnel and Transport mode. Use of each mode depends on the requirements and implementation of IPSec.\nIPSec Tunnel Mode\nIPSec tunnel mode is the default mode. With tunnel mode, the entire original IP packet is protected by IPSec. This means IPSec wraps the original packet, encrypts it, adds a new IP header and sends it to the other side of the VPN tunnel (IPSec peer).\nTunnel mode is most commonly used between gateways (Cisco routers or ASA firewalls), or at an end-station to a gateway, the gateway acting as a proxy for the hosts behind it.Tunnel mode is used to encrypt traffic between secure IPSec Gateways, for example two Cisco routers connected over the Internet via IPSec VPN. Configuration and setup of this topology is extensively covered in our Site-to-Site IPSec VPN article. In this example, each router acts as an IPSec Gateway for their LAN, providing secure connectivity to the remote network:\nAnother example of tunnel mode is an IPSec tunnel between a Cisco VPN Client and an IPSec Gateway (e.g ASA5510 or PIX Firewall). The client connects to the IPSec Gateway. Traffic from the client is encrypted, encapsulated inside a new IP packet and sent to the other end. Once decrypted by the firewall appliance, the client’s original IP packet is sent to the local network.\nIn tunnel mode, an IPSec header (AH or ESP header) is inserted between the IP header and the upper layer protocol. Between AH and ESP, ESP is most commonly used in IPSec VPN Tunnel configuration.\nThe packet diagram below illustrates IPSec Tunnel mode with ESP header:\nESP is identified in the New IP header with an IP protocol ID of 50.\nThe packet diagram below illustrates IPSec Tunnel mode with AH header:\nThe AH can be applied alone or together with the ESP, when IPSec is in tunnel mode. AH’s job is to protect the entire packet. The AH does not protect all of the fields in the New IP Header because some change in transit, and the sender cannot predict how they might change. The AH protects everything that does not change in transit. AH is identified in the New IP header with an IP protocol ID of 51.\nIPSec Transport Mode\nIPSec Transport mode is used for end-to-end communications, for example, for communication between a client and a server or between a workstation and a gateway (if the gateway is being treated as a host). A good example would be an encrypted Telnet or Remote Desktop session from a workstation to a server.\nTransport mode provides the protection of our data, also known as IP Payload, and consists of TCP/UDP header + Data, through an AH or ESP header. The payload is encapsulated by the IPSec headers and trailers. The original IP headers remain intact, except that the IP protocol field is changed to ESP (50) or AH (51), and the original protocol value is saved in the IPsec trailer to be restored when the packet is decrypted.\nIPSec transport mode is usually used when another tunneling protocol (like GRE) is used to first encapsulate the IP data packet, then IPSec is used to protect the GRE tunnel packets. IPSec protects the GRE tunnel traffic in transport mode.\nNotice that the original IP header at the front is the IP header from the original IP packet. Placing the sender’s IP header at the front (with minor changes to the protocol ID), proves that transport mode does not provide protection or encryption to the original IP header and ESP is identified in the New IP header with an IP protocol ID of 50.\nThe packet diagram below illustrates IPSec Transport mode with AH header:\nThe AH can be applied alone or together with the ESP when IPSec is in transport mode. AH’s job is to protect the entire packet, however, IPSec in transport mode does not create a new IP header in front of the packet but places a copy of the original with some minor changes to the protocol ID therefore not providing essential protection to the details contained in the IP header (Source IP, destination IP etc). AH is identified in the New IP header with an IP protocol ID of 51.\nIn both ESP and AH cases with IPSec Transport mode, the IP header is exposed.\n|Last Updated on Friday, 11 May 2012 11:21|", "label": 1}
{"text": "Security expert Craig Heffner from Seismic, a company specializing in security consulting, will be sharing the details of a security flaw that opens up many common household routers to a hack. The revelation will be part of the Black Hat Conference in Las Vegas at the end of the month. Black Hat is a gathering of technologists who are interested in security issues, some from the corporate world and some from the darker side of the issue. Heffner’s talk is entitled How to Hack Millions of Routers.â€\nAccording to Forbes, Heffner will release code that can be used to get into popular routers from Linksys, Dell, and Verizon FIOS or DSL. If a user visits a web site with the code, malicious hosts can gain access to information or send a browser to another site.\nThe way the hack works is extremely technical. If you want all the details check out the Forbes blog post. Simply put, it exploits the way Domain Name Systems (DNS) work. The DNS address is kind of like a web page’s phone number. When you type in Notebooks.com a request is sent to a computer connected to the Internet called a DNS server. It looks up the address Notebooks.com. The DNS server then gives the browser the right Internet Protocol address (IP address) so that it can find the actual computer containing the site’s web pages. An IP address is a series of four numbers ranging from 1 to 255. For example, where I live in NC Google’s IP address is 22.214.171.124. It changes based on your locality.\nEach web site can have more than one IP address. The trick is fool the router into giving up its address as if it were the secondary IP address for that site. Then the malicious code hidden in the site can gather access from the router like your login information as if your local network were part of that site. Forbes says this isn’t new, but has been patched repeatedly. However, Heffner has found a new way to exploit the system to gain access to most of the popular consumer routers. One of those that is vulnerable is the popular Linksys WRT54G routers.\nYou should go to the Forbes site and find out if your router has been tested. Towards the end of the post is a table listing some of the routers tested with for the vulnerability.\nTo secure your router do the following:\n- Change your password to a strong one. You do this by logging into the configuration page of your router, usually something like 192.168.1.1. Get specific instructions from your manufacturer’s website. Here is a site that will generate very strong passwords for you. The length should be set to at least 8 characters and include letters (both upper and lower case), numbers, and maybe even punctuation marks. Do not include words or names.\n- Go to your router’s support site and get the latest firmware and install it. This is different for each router. Some routers have a link in the router’s configuration page (see below).\n- Be careful which web sites you visit. Porn and pirated software pages are notorious for including this kind of code.\n“One comfort for users may be that Heffner’s method still requires the attacker to compromise the victim’s router after gaining access to his or her network. But that can be accomplished by using a vulnerability in the device’s software or by simply trying the default login password. Only a tiny fraction of users actually change their router’s login settings, says Heffner. ‘Routers are usually poorly configured and have vulnerabilities,” he says. “So the trick isn’t how to exploit the router. It’s how to get access to it.’” (Andy Greenberg, Forbes)\nSome may ask why would Heffner reveal this information? He believes it is the best way to force companies to update their software. As you notice from my router above, D-Link has not updated the firmware in a long time. Fortunately, most D-Link routers are not on the list of vulnerable routers.\nThe source for this was Dwight Silverman of the Houston Chronicle.", "label": 1}
{"text": "All Windows 2000 administrators want to allow the right people access to the right information. To do that, you must understand the most basic form of security -- permissions.\nMost network administrators are already familiar with the setting up of permissions to files/folders, so this article looks at the major concepts you should consider when applying permissions to files/folders. You need to do proper planning before you actually assign permissions.\nOne of the benefits of using Windows 2000 over Windows 98 or Me, for workstations as well as servers, is the ability to use file and folder permissions. To enable file and folder permissions, you need to use NTFS: they are not available on FAT. So when you upgrade to Windows 2000, if you are concerned about file/folder security, you must convert that FAT partition to NTFS. This is normally done during the upgrade process.\nUse caution when applying the deny permission, because the deny permission takes precedence over any allow permission. All other permission is cumulative or additive. For example, if a user has been assigned the \"Read\" permission to a file, but is also a member of a group that has been assigned the \"Write\" permission, the user's effective permission to the file is \"Write.\" If, on the other hand, a user has been assigned the \"Deny Write\" permission, then that user will not be able to write to the file or folder, even if he/she also belongs to a group that has been assigned\nTo properly assign permissions:\n- Calculate what permissions you are going to use for files/folders. Permissions for\nfiles/folders are \"least restrictive.\" For example, Paul is a user that has been assigned Read\npermission to a file. He also is a member of the shipping group that was assigned Full Control to\nthe same file. The result is that Paul's permission for the file will be Full Control, because the\n\"least restrictive\" permission will apply to users, and Full Control is less restrictive than Read.\n- Then perform separate calculations for shares using the \"least restrictive\" rule. For\nexample, the shipping folder is now shared. Paul is assigned change permission. The shipping group\n(of which Paul is a member) has been assigned Read Only permission. Based on the \"least\nrestrictive\" rule this user now has Change permission to the shared folder.\nPermission for files and shares are always additive or least restrictive.\nWhat would Paul's effective permission be? It is the combined permission for Paul when he accesses files and folders within the shared folder. This is calculated using the most restrictive rule. So because Paul is accessing the file (for which he has Full Control) through the shared folder (for which he has Change permission), then his effective permission (combined permission) would be Change since this is the most restrictive between the shared folder (Change) and the file permission (Full Control). Paul has Full Control for the file and Change permission for the share folder. Therefore Paul's effective permission is Change.\nAdesh Rampat has 10 years experience with network and IT administration. He is a member of the Association of Internet Professionals, the Institute for Network Professionals and the International Webmasters Association. He has also lectured extensively on a variety of topics.\nDid you like this tip? If so, (or if not) why not let us know. Send an email to us and sound off.\nThis was first published in September 2001", "label": 1}
{"text": "Creating and maintaining high safety standards of critical data are concerns for almost all of us, especially followers of online shopping and online banking. In this blog, we would be reading about some easy yet effective ways on how to prevent hacking attacks on PCs. Read on!\nIn today’s web-dominated world, almost every one of us makes use of PC and Internet to reduce time and efforts and staying close to comfort and convenience. Things are easy and safe till the time we come to know that critical information stored on the PC has been hacked. Things can be restored but it is always better to play it safe from the start itself. Let us read about computer hacking and find some easy ways to protect your privacy and data.\nBefore we start reading about ways to prevent hacking, let us read about computer hacking so that all of us can be on the same knowledge platform.\nComputer hacking is all about manipulating vulnerabilities of a computer by a hacker with an aim to invade privacy or steal or modify information. Most of us think that PCs at homes are safe but that is far from being true. Hacking can happen to any PC in this world and your PC is no exception.\nLet us now read about good ways to prevent hacking at the first place.\nTips to prevent Computer Hacking\n1. Install a good paid antivirus. You can install a free version to check its reliability but paid version has improved tools to prevent hacking and is therefore recommended. Moreover, update the antivirus on a daily basis and scan the PC, at least once a week\n2. Turn ON the Firewall and allow your PC to install all critical patches from Microsoft by activating Automatic Updates and Windows Firewall found under Control Panel-Security Center.\n3. Turn off sharing all your drives, especially where program files are usually stored, the C: / drive.\n4. Delete temporary internet files. Enter PREFETCH in the RUN box and delete by pressing SHIFT+DEL. Follow the same deletion process by typing %TEMP%, also type TEMP in the RUN box after clearing prefetch and %TEMP%. Go to start, type run, and type (prefetch, %temp%, and temp, one by one).\n5. Go to Control panel-Performance and Maintenance-System-Remote and UNCHECK the box “Allow remote invitations to be sent from this computer”, apply and then press OK. This will prevent hackers from gaining unauthorized access on your PC.\n6. Always scan a USB drive, floppy, attachment, and CD before opening its contents. This may take some time but it is always better to be safe\n7. Block pop-ups and do not click on misleading advertisements\n8. Never clicks on URLs that redirect you to other sites, especially those mischievously claiming to be from your bank or card issuing authority\n9. Do not disclose personal information by responding to emails suggesting that you just won a prize or lottery. If you have not participated, how come you won it? It is that simple\n10. Do not click or open emails or attachments from unknown persons\n11. Never install Kazaa, Napster, or new software from an unknown source\nFollow these simple tips and you can easily protect your PC and critical information from getting hacked.\nTags: computer hacking, Hacking, how to prevent hacking attacks, online banking, Online Shopping, prevent hacking, protect your PC, ways to prevent hacking", "label": 1}
{"text": "Number of oil spills continued to decrease in 2011\nPress release by SYKE and the Finnish Border Guard\nThe number of oil spills detected by Finnish authorities has continued to decrease. In 2011, the authorities observed 57 oil spills compared with closer to 70 in the previous two years. The authorities were informed of a total of 83 potential oil spills last year.\nA larger number of surveillance flight hours than in previous years\nAircraft operated by the Finnish Border Guard observed a total of 21 verified oil spills in the Finnish sea area. Helicopters observed eight oil spills and airplanes equipped with oil spill surveillance equipment observed 13 spills. In addition, surveillance airplanes observed three oil spills in the Swedish and two in the Estonian exclusive economic zones. The Estonian surveillance airplane verified three oil spills in the Finnish Exclusive Economic Zone, and one spill was observed by German surveillance airplane.\nOil spills detected by Finnish surveillance planes in years 1996-2011\nIn 2011, Finnish surveillance flights above sea areas exceeded the average level and amounted to 645 hours. The pollution per flight hour index, 0.03, was at a record low. This indicator offers strong support to the view that number of oil spills is decreasing in the northern Baltic Sea.\nSimilarly, the average volume of oil spills detected during surveillance flights has declined significantly in the past few years. The average volume of spills observed within the Finnish exclusive economic zone in 2011 was some 30 litres. In the three previous years the average volume of a spill has been more than 100 litres, and the average volume of spills detected e.g. in 2005 was 608 litres.\nIn addition to surveillance flights, the satellite based oil spill detection service CleanSeaNet (CSN) service of the European Maritime Safety Agency (EMSA) contributes significantly to the surveillance of marine oil spills. In 2010, Finnish authorities received 250 satellite images through the EMSA. Finnish Border Guard attempts to verify all oil spill indications.\nFinnish Border Guard investigates the oil pollution cases\nIn 2011, the Finnish Border Guard investigated nine cases to determine whether the conditions for imposing an administrative oil pollution fee were met. In six cases, an oil pollution fee was imposed. The fees varied from EUR 2,139 to EUR 17,112. Cases where no pollution fee was imposed were minor in terms of the volume and the environmental impact.\nInternational cooperation contributes to the reduction in spills in the Baltic Sea\nLast year, Finland organised SuperCEPCO Baltic 2011, a major pollution surveillance operation during which aircraft from five countries conducted surveillance over the northern Baltic Sea for a total of 68 hours. During the operation, one minor mineral oil spill was detected and two spills of other substances.\nThe results of the pollution surveillance operations together with national and international statistics show that thanks to closer international cooperation and an increased risk of getting caught, the number of oil spills has decreased. It would also seem that environmental awareness among shipping companies operating in the Baltic Sea has grown. Another contributor to the positive development is the HELCOM recommendation which states that all vessels in the Baltic Sea must dispose of any waste containing oil in collection points located in harbours.\nOil spill control\nKati Tahvonen, Research Engineer,\nFinnish Environment Institute (SYKE), tel. +358 400 148 754\nAdministrative oil pollution fees\nTom Lundell, Maritime Safety Expert,\nFinnish Border Guard, tel. +358 40 521 4685\nChief Editor for Web Services\nFinnish Environment Institute (SYKE), tel. +358 400 148 875", "label": 1}
{"text": "Using the Internet\nIn 2009 the Internet Crime Complaint Center (IC3), which acts in partnership with the National White Collar Crime Center and the FBI, received more than 336,000 complaints on its website and referred over 146,000 to law enforcement agencies for further consideration. The total loss from all of these cases was over $560 million. You may be at risk if you answer \"yes\" to any of the following questions:\n- Do you visit websites by clicking on links within an e-mail?\n- Do you reply to e-mails from persons or businesses you are not familiar with?\n- Have you received packages to hold or ship to someone you met on the Internet?\n- Have you been asked to cash checks and wire funds to someone you met on the Internet?\n- Would you cash checks or money orders received through an Internet transaction without first confirming their legitimacy?\n- Would you provide your personal banking information in response to an e-mail notification?\nThe following security tips will help you deal with dangerous matters associated with using the internet.\n- E-card Dangers\n- Illegitimate Websites\n- Safe Cyber Practices\n- Social Networking Dangers\n- Suspicious E-mails\nYou receive an e-mail saying \"A friend has sent you an e-card.\" The e-mail appears to be from a legitimate card company, but malware or a virus is downloaded into your computer when you click the link to see the card. You should delete the e-mail if you don't recognize the sender or if you are instructed to download an executable program to view the e-card. And make sure your computer has adequate anti-virus protection.\nAnd even if you recognize the sender your computer could be harmed if the incoming e-mail is phony and you click on a link to an e-card or open an attachment. This happened around Christmas time in December 2010 when employees of various government agencies received phony holiday messages that appeared to come from the White House.\nCybercriminals are now creating illegitimate websites that will receive high search-engine rankings and thus attract the attention of persons searching for information on a particular subject. Persons just visiting those sites risk having their computers infected with viruses. And if they click on any links in those sites they risk becoming a victim of identity theft and various scams, e.g., ones that claim you can make a lot of money for a small initial investment.\nTo avoid these problems users should:\n- Keep your computer's anti-virus system up to date with the latest firewalls and software.\n- Use caution clicking on links that claim to provide videos or information on hot topics in the current news, e.g., the earthquakes in Haiti and Chile. And be aware that the bad guys are now tricking Google into telling you that the link is a PDF file, which makes it look more authentic.\n- Do not click on links to other websites. Look up the address elsewhere and retype it into your browser.\n- If the link address is correct, before clicking on it check to see where you would actually go. You can do this by scrolling your mouse over the link and reading the address in the box that will pop up over the link. Do not click on the link if this address does not match the one in the link.\n- Use the tips provided above to counter phishing. Do the following to make sure a website is legitimate, especially if you are planning to make a purchase of a name brand product:\n- Check that the domain name is spelled correctly.\n- Check that the domain name ends in .com, .org, or .net. Those ending in .cn for China or .mn for Mongolia are likely to be fraudulent.\n- Call the phone number posted and talk to a live person.\nIn an e-mail scam known as \"phishing\" identity thieves fish for personal information by sending realistic-looking e-mail that asks recipients to go to a bogus website and provide personal information such as a credit card number or a Personal Identification Number (PIN). Legitimate banks and financial institutions don't send e-mails asking you to verify your account information. They already have it. The following are examples of scammers posing as the Internal Revenue Service (IRS), Federal Bureau of Investigation (FBI), Federal Deposit Insurance Corporation (FDIC), and the Centers for Disease Control and Prevention (CDC).\nEach year during tax preparation time there is a surge in the number of frauds by criminals posing as IRS officials to obtain personal information for identity theft. The IRS never sends out unsolicited e-mails or asks for detailed personal and financial information. Any such e-mail is a fraud. So are telephone calls from someone stating they are from the IRS. Go to the IRS website at www.irs.gov for information on the latest scams and instructions on how to protect yourself from suspicious e-mails or phishing schemes. The IRS also recommends forwarding the suspicious e-mail to it at firstname.lastname@example.org.\nFraudulent e-mails have also been sent out by criminals posing as FBI agents and officials. They give the appearance of legitimacy by using the FBI seal, letterhead, and pictures of the FBI Director. They may also claim to come from the FBI's domestic or overseas offices. Like the IRS, the FBI does not send out e-mails soliciting personal or financial information. For more information on this kind of fraud go to the FBI website at www.fbi.gov and click on New E-Scams and Warnings under Be Crime Smart.\nAnother agency that has become aware of fraudulent e-mails in its name is the FDIC. These ask recipients to \"visit the official FDIC website\" by clicking on a hyperlink that directs them to a fraudulent website that includes hyperlinks that open a \"personal FDIC insurance file\" to check on their deposit insurance coverage. Clicking on these links will download a file that contains malicious software to collect personal and confidential information.\nOn Dec. 2, 2009 the CDC issued a health alert warning people not to respond to an e-mail referencing a CDC-sponsored state vaccination program for the H1N1 (Swine Flu) contagion that requires registration on \"www.cdc.gov.\" People that click on this embedded link risk having a malicious code installed on their computer. Examples of this and other hoaxes and rumors can be seen at http://www.cdc.gov/hoaxes_rumors.html.\nUse the following tips to counter phishing:\n- Do not open any e-mail from an unknown sender.\n- Do not open any unexpected e-mail attachments.\n- Do not open any attachments that ask you to reset a password.\n- Do not click on website addresses in e-mails you get even if they look real. Retype them into your browser.\n- Do not click on links within e-mail messages purporting to come from your bank.\n- Do not double click on an Internet pop-up offering a link or provide personal information in response to an e-mail or Internet pop-up offer.\n- Use the latest versions of Internet browsers, e.g., Microsoft Internet Explorer 8, which is designed to prevent phishing attacks. Use Explorer in the \"protected mode,\" which restricts the installation of files without the user's consent, and set the \"Internet zone security\" to high. That disables some of Explorer's less-secure features. And set your operating system and browser software to automatically download and install security patches.\n- Make sure the website page you are entering sensitive information on is secure. You can tell it is secure when the address on the top of your screen where the Uniform Resource Locator (URL) is displayed begins with https:// rather than http://. You can also look for a closed padlock or an unbroken key on the bottom of your screen to indicate the page is secure. If the lock is open the site or the key is broken, the page is not secure. Note that on many websites only the order page will be secure.\n- Keep your computer up to date with the latest firewalls, and anti-virus and anti-spyware software. The latter counters programs that secretly record what you type and send the information to the thieves. They are often installed when you visit websites from links in e-mail. Use security software that updates automatically. Visit www.OnGuardOnline.gov for more information.\n- Do not buy \"anti-spyware\" software in response to unexpected pop-ups or e-mails, especially ones that claim to have scanned your computer and detected viruses known as malware, i.e., malicious software.\n- Do not respond in any way to a telephone or e-mail warning that your computer has a virus even if it appears to come from an anti-virus software provider like Microsoft, Norton, or McAfee. \"Helpful hackers\" use this ploy to get you to download their software to fix the virus or sell you computer monitoring or security services to give them remote access to your computer so they can steal your passwords, online accounts, and other personal information. If you already have anti-virus software on your computer you'll receive a security update or warning directly on your computer.\n- Contact your e-mail provider. Most keep track of scams. Send your provider the suspicious message header and complete text.\n- Use caution when entering personal information online.\nThere are presently two similar efforts by the U.S. Government to promote safer use of the Internet. The one by the FTC's Bureau of Consumer Protection is called Stop.Think.Click. The other, developed by a group representing industry, government, academia, and the nonprofit sector in 2009, and promoted by the Obama administration and the Department of Homeland Security, is called Stop.Think.Connect.\nStop.Think.Click defines seven practices for safer computing and provides tips on preventing identity theft, safe use of social networking sites, online shopping, Internet auctions, avoiding scams, and wireless security. It also provides a glossary of terms. The seven practices are:\n- Protecting your personal information\n- Knowing who you're dealing with\n- Using anti-virus and anti-spyware software, as well as a firewall\n- Setting up your operating system and web browser software properly, and updating them regularly\n- Protecting your passwords\n- Backing up your important files\n- Learning who to contact if something goes wrong online. Go to www.ftc.gov/bcp/edu/pubs/consumer/tech/tec15.pdf for information about these practices and tips.\nGo to www.ftc.gov/bcp/edu/pubs/consumer/tech/tec15.pdf for information about these practices and tips.\nStop.Think.Connect suggests that users do the following:\n- Stop. Before you use the Internet take time to understand the risks and learn how to spot potential problems\n- Think. Take a moment to be certain the path ahead is clear. Watch for warning signs and consider how your actions online could impact the safety of yourself and your family.\n- Connect. Enjoy the Internet with greater confidence, knowing you've taken the right steps to safeguard yourself and your computer.\nYou can learn how to become a partner in this effort by going to its website at www.stopthinkconnect.org. This site also contains the tips and advice for doing the following.\nKeeping a clean machine:\n- Have the latest security software, web browser, and operating system.\n- Use programs that automatically connect and update your security software.\n- Protect all devices that connect to the Internet from viruses and malware.\n- Use your security software to scan all USBs and other external devices before attaching them to your computer.\nProtecting your personal information:\n- Secure your accounts with protection beyond passwords that can verify your identity before you conduct business.\n- Make passwords long and strong with capital and lowercase letters, numbers, and symbols.\n- Use different passwords for every account.\n- Keep a list of your passwords stored in a safe place away from your computer.\n- Use privacy and security settings to limit who you share information with.\nConnecting with care:\n- Delete any suspicious e-mail, tweets, posts, and online advertising.\n- Limit the business you conduct from Wi-Fi hotspots and adjust your security settings to limit who can access your computer.\n- Use only secure websites when banking and shopping, i.e., ones with https:// or shttp:// in their addresses.\nBeing web wise:\n- Keep pace with new ways to stay safe online by checking trusted website for the latest information.\n- Think before you act when you are implored to act immediately, offered something that sounds too good to be true, or asked for personal information.\n- Back up your valuable information by making an electronic copy and storing it in a safe place.\nBeing a good online citizen:\n- Practice good online safety habits.\n- Post about others as you would have them post about you.\n- Report all types of cybercrime to you local law enforcement agency and other appropriate authorities.\nThis is phishing with text messages instead of e-mails. Beware of any messages that request personal information or give you a phone number to call. Before calling verify that the number matches the number of the named institution, e.g., your bank. And never give out personal information unless you have initiated the call.\nVirus creators, identity thieves, and spammers are increasingly targeting users of social networking sites in an effort to steal personal data and account passwords. One of the tactics they use to gain access to this information involves sending social networking users e-mails that appear to come from online friends. For example, some Facebook users have been receiving e-mails from their \"friends\" that claim to contain a video of them. When they click on it they download a virus that goes through their hard drives and installs malicious programs. The virus, known as Koobface, then sends itself to all the friends on the victim's Facebook profile. A new version of the virus also is affecting users of MySpace and other social networking sites. Cyber-criminals are tricking social networking users into downloading malicious software by creating fake profiles of friends, celebrities, and others. Security experts say that such attacks, which became widespread in 2008, are increasingly successful because more and more people are becoming comfortable with putting all kinds of personal information about themselves on social networking sites. They warn that users need to be very careful about what information they post because it can be used to steal their identities. Facebook users should become a fan of its security page at www.facebook.com/security, which has posts related to all sorts of security issues, tips, resources, and other information.\nTo avoid problems on social networks or anywhere in the Internet, users should:\n- Not to click on any links, videos, programs, etc. provided in messages, even if a “friend” encourages you to click on them.\n- Get program updates from the company's website, not through a provided link.\n- Customize your privacy so only your friends have access to the information you post.\n- Scan your computer regularly with an updated anti-virus program.\n- Be suspicious of anyone, even a \"friend,\" who asks for money over the Internet.\nDelete any suspicious e-mail without replying, especially the following:\n- Business opportunities to make money with little effort or cash outlay\n- Offers to sell lists of e-mail addresses or software\n- Chain letters involving money\n- Work-at-home schemes\n- Health and diet claims of scientific breakthroughs, miraculous cures, etc.\n- Get-rich-quick schemes\n- Free goods offered to fee-paying group members\n- Investments promising high rates of return with no risk\n- Kits to unscramble cable TV signals\n- Guaranteed loans or credit on easy terms\n- Credit repair schemes\n- Vacation prize promotions\n- Special offers that require a credit check and a small fee for verification expenses to be paid by a credit or debit card\n- Notices of prize or lottery winnings that require you to pay a fee to cover expenses You should also file a complaint with the IC3 at www.ic3.gov. Its website also includes tips to assist you avoiding a variety of Internet problems.\nIn another scam known as \"whaling\" fake e-mails have been sent to high-ranking executives to trick them into clicking on a link that takes them to a website that downloads software that secretly records keystrokes and sends data to a remote computer over the Internet. This lets the criminal capture passwords and other personal or corporate information, and gain control of the executive's computer. In one case fake subpoenas have been sent to executives commanding them to appear before a grand jury in a civil case. The link that offers a copy of the entire subpoena downloads the malicious software.", "label": 1}
{"text": "October is National Cyber Security Awareness Month; and in light of this, InHomelandSecurity is presenting a series of blogposts focusing on the security steps you can take to protect yourself from hacking, clickjacking, and other forms of cyberterrorism. Think about what you can do to make yourself more secure in your online world, and take a moment to read our offerings for this month of safety and security:\nMalicious URL’s in social networking are nothing new. Back in 2011, Time’s Techland blog reported in an independent study that 68% percent of Facebook users clicked on links sent to them. And why wouldn’t they? If a URL appears on your Facebook page or a friend sends you a private message on Twitter, it’s a link coming from someone you know. A friend.\nTechland’s study, though, reveals an inconvenient truth: 42% in this study admitted not knowing all their “Friends” on Facebook.\nBut that was 2011. We’ve learned a lot in a year, haven’t we?\nFast forward to September 24, 2012, where Sophos’ Naked Security blog reported new malware (software that installs itself on your computer without you knowing) is making the rounds using both Twitter and Facebook, and here’s how it works:\n- You usually get a direct message that reads “lol ur famous now” or “lol iz this u in this vid?” along with a link.\n- Regardless if you are logged into Facebook or not, you will be asked to log in to “verify” the link.\n- You will then be asked to load a “YouTube” update or third-party video application asking to access your Facebook account.\nOnce uploaded, the “update” installs a backdoor Trojan, software that replicates itself across network drives. Usually, these updates record your computer activity (websites visited, commands and passwords entered, etc.) and send data to a remote location.\nAll this happens because of a message. From a friend.\nBut there are precautions you can take with these attempts, and many of them involve common sense:\n- Do you know the sender? Do you often hear from them in this direct a fashion? If not, send a reply, asking if they did in fact send you a link.\n- Is the message poorly constructed? If it is something like “lol iz this u in this vid?” ask yourself if this is common for your friend? Do they usually spell “is” and “you” like this? A good sign it is a spam or a compromised account is the message itself is full of typos or poor sentence structure.\n- Remove and report SPAM on your Facebook wall. Make sure to remove it by moving your cursor over the “Edit/Remove” icon of the announcement, and selecting “Report/Mark as Spam” from the offered menu. (See image below)\n- Delete any Direct Message in Twitter if you suspect it is SPAM. On Twitter, if you suspect a private message as SPAM, reply to the friend and then delete the message. If it happens again, consider removing that user from your network.\n- Change your password if you believe you have been hacked. If you suspect that your Facebook or Twitter account has been compromised, change your password immediately. Do not use the same password for social networking as you use for other websites such as banking or eCommerce.\nSo what harm would it do if you just clicked on that link a “friend” sent you? Quite a bit actually. Following these preventative tips can still allow you to enjoy the benefits social networking while avoiding malware that could lead to identity theft and fraud. A mantra to follow when networking — think before you click. It’s a simple practice that can keep you safe and secure.\nAnd take a moment to consider that “friend” suddenly reaching out to you. A moment’s consideration can save you a healthy amount of headaches when trying to repair your digital footprint.", "label": 1}
{"text": "Since 2010 we’ve seen a new type of malware rapidly evolving and making the headlines in security news magazines around the world. Traditional Trojans, viruses, spyware and computer worms can be viewed as mere tools in petty theft crimes, in comparison with cyberwarfare weapons like Stuxnet.\nAlthough these malicious programs have affected the internet security of thousands of web users around the world, it seems that the Middle East is the preferred target of cyber-attackers. In late 2011 and the first half of 2012, security experts have been buzzing with news and discoveries of new malware strains used in attacks over the energy and banking sectors of countries in this region.\nNew standards for malware sophistication and scope\nMalware complexity has reached an all-time high and malware attacks can now be easily targeted at specific countries, companies or individuals. They can be used as weapons in cyber-warfare and hacktivism.\nHere’s an overview of the most sophisticated, recently discovered internet security threats:\nStuxnet. Discovered in June 2010, Stuxnet is a highly sophisticated computer worm developed to spy on and sabotage Iran’s nuclear program. Although the worm was supposed to remain secret and infect only computers in Iran’s infrastructure, an error in its code made it possible for it to go wild on the internet and replicate itself on computers and systems around the world. With a code 50 times as big as the typical computer worm, Stuxnet is the first such Windows-based malware discovered to spy on and subvert industrial systems.\nDuqu. Also a dangerous computer worm, Duqu was discovered in September 2011, spreading in the form of a Word document via e-mail. Since then, new, more targeted variants of it have been discovered in several countries around the world, including Iran. Its main capabilities are capturing keystrokes and stealing system information. Due to similarities in code, Duqu and Stuxnet are said to be related.\nFlame. Of an even bigger complexity than Stuxnet’s, the Flame malware was identified by internet security experts in May 2012. It was found on Windows computers belonging to governmental organizations, educational institutions and private individuals in Iran, Syria, Lebanon, Saudi Arabia and Egypt. Flame can spread via USB sticks or local networks, and record audio files, Skype conversations, keyboard activity, network traffic and more, but doesn’t actually damage systems. As such, it is believed to be more of a cyber-espionage tool.\nGauss. In July 2012, internet security experts found Gauss ravaging through Windows computers in the Middle East, mainly Lebanon. Showing similarities with Flame, this piece of malware is considered a cyber-espionage tool, as well. Its main capability is stealing cookies, browser history and login credentials for online banking and payment accounts, as well as for social networking and e-mail accounts.\nShamoon. In mid-August 2012, experts made public the existence of yet another possible cyber-weapon: Shamoon. However, this virus is not believed to be state-sponsored, but more of a tool used by hacktivists to protest against tyranny and oppression in the Middle East; the primary targets were state companies from the energy sector. Shamoon has computer data-wiping capabilities and can spread to computers of the same network, including those that are not connected to the internet.\nPrevention is better than cure. We can’t stop preaching about it\nWhile the heavily targeted region for these attacks was the Middle East, other countries have also been affected, including the US, India and European countries. And even if many of these attacks were aimed at sabotaging industrial activities, private individuals have also fallen victim. Which is why states, companies and individuals alike have to make sure they always have proper internet security in place. Now, surely, states and companies have experts to look after their internet security. But what can you do to look after yours?\nHere’s some internet security advice:\n- Always stay informed about new malware and online dangers. If you have at least one internet-connected device, then make sure you know all the threats you’re up against when you go online.\n- Keep your operating system and computer programs up to date, because software vulnerabilities can easily be exploited by malware and hackers. A Vulnerability Scanner, like the one in BullGuard Internet Security 2013, may come in handy to spot any outdated software and find updates for it.\n- Last, but not least, get proper antivirus protection for your computer, just like the one provided by BullGuard’s internet security software, to prevent all types of malware from infecting it. BullGuard Internet Security 2013 comes with a multi-layered protection system that virtually impenetrable and several other security features to keep you safe at all times.", "label": 1}
{"text": "Consumer Protection > Consumer News & Information > FDIC Consumer News\nFDIC Consumer News\nFraud Alert: Text Messages, Pop-Ups and Downloads to Avoid\nFDIC Consumer News has reported how criminals masquerading as legitimate businesses or government agencies have tricked consumers into divulging valuable personal information over the computer, phone or fax in order to drain bank accounts. Here are our latest tips for protecting against new schemes using electronic devices.\nThink twice before responding to “urgent” text messages. One recent scam involved a text message sent to cell phones and smartphones (a hand-held device to access the Internet and make calls) warning bank customers that their debit or credit card had been blocked for security reasons. The message urged users to call a hotline to unblock their card, but instead they reached an automated response system asking for their card number, personal identification number (PIN) and other information.\n\"Unfortunately, this was enough information for thieves to create counterfeit cards and commit fraud,\" said Michael Benardo, Chief of the FDIC's Cyber-Fraud and Financial Crimes Section.\nWhy are smartphone users now being targeted by scammers? \"Smartphone users almost always have their phone handy and tend to respond to calls and e-mails quickly, so the expectation is that many of them may not realize that a message is fake until it's too late,\" Benardo explained. \"Not only that, but fake Web sites are also harder to spot on a small screen.\"\nBe on guard against unexpected pop-up windows on Web sites, including your bank's. If after you're logged onto your bank's Web site — or on any Web site, for that matter — and you get an unexpected pop-up window asking for your name, account numbers and other personal information, that is likely a sign that a hacker has infected your PC with spyware and is trolling for enough information to commit identity theft and gain access to your bank account.\n\"It's normal for your bank to ask for your login ID and password when you first log in and to ask you to answer a 'challenge question' if you want to reset your password or start using a new computer,\" advised David M. Nelson, an FDIC fraud specialist. \"But your bank will not ask you — through a pop-up window — to type your name and information such as your date of birth, mother's maiden name, bank account and cell phone numbers. Banks only need that type of detailed personal information when the account is initially opened.\"\nBe suspicious of unsolicited offers to download games, programs and other attractive \"apps\" (applications) onto your smartphone. Those \"deals\" could contain malicious software directing you to fake Web sites or install spyware used to steal information that can lead to theft. \"You should consider using anti-virus software specifically designed for smartphones and other mobile devices,\" added Nelson.\nWhat are your best defenses against a variety of high-tech scams?\nFor additional tips on avoiding Internet fraud, visit www.onguardonline.gov.\nLast Updated 2/22/2011", "label": 1}
{"text": "These days, it’s hard to turn on the news or open a newspaper without seeing something about cybersecurity. President Obama calls for an immediate evaluation of U.S. cybersecurity initiatives. Rod Beckstrom, cybersecurity chief at the Department of Homeland Security (DHS), resigns amid turf battles with the National Security Administration (NSA). The Chinese government is accused of orchestrating cyber attacks on U.S. military networks. Congress is contemplating new legislation to expand government authority to manage Internet operations and other national cyber infrastructure. These headlines, coupled with criticism from all directions, has our leaders looking for the answer to the $64,000 question– is it truly possible for the government to a.) Share information freely enough to ensure national security, b.) Continuously defeat cyber attackers, and c.) Respect citizen privacy? All at the same time?\nA Call for Action\nBefore we throw our hands up in frustration, we ought to remember that cybersecurity needs to strike a balance between protecting citizens and enabling the collective business of government and industry – day in and day out. What we need is a solution to ease the natural – and very strong – tension between protecting sensitive data from the wrong hands and completely imprisoning mission-critical information for fear that it will be used inappropriately. The solution must also protect the network infrastructure supporting the data, while facilitating the sharing of the very information it protects.\nFederal agencies have been working to develop this solution for quite some time, and at its core is the practice of information assurance. Information assurance combines aspects of physical and cyber security protections, allowing for safe information sharing and collaboration across agencies. While restricting unauthorized information access, information assurance simultaneously enables protected access to the network that supports the flow of information.\nTo Share or Not to Share\nGiven the grave threats to our critical infrastructure, it is tempting to lock down buildings, networks and data, limiting access in efforts to mitigate risks. However, agencies must realize that information sharing is as important to our government’s security posture as both information and physical security. Intelligence must be shared to realize its value. From Social Security numbers and tax information to law enforcement data and classified national security intelligence, agencies must carefully determine which parties can access the information, and how. Through the enforcement of policies and procedures and the deployment of technology solutions – from CAC cards to secure ID tokens to iris scans and other tools – agencies have access to the power, the technology and the know-how to allow authorized individuals in and keep others out.\nPeriodically, public concern arises that agencies like the NSA have too much access to information. But there have been laws on the books with substantial penalties for the wrongful use of sensitive information long before we started saying, “cybersecurity.” When I worked with the U.S. Customs Service (later Customs and Border Protection), we frequently coordinated with Federal, state, tribal, and local public safety officials as well as numerous commercial trade organizations. Many times we were given access to very specific information that we could only use for an authorized purpose. After obtaining the information, I was civilly and criminally liable for protecting and appropriately using that information. So I made sure we used it only for its authorized intention. Information assurance policies function similarly – users are granted access to specific information for a specific mission. Once the mission is complete, access is restricted once again.\nProtecting the Network from Cyber Attack\nNetwork security is critical to information assurance. It isn’t just about keeping rogue agents out; effective network security also enables information sharing across, within, and among Federal agencies and important mission partners. Technology tools – and skilled professionals – are needed to defeat attackers that are intent on intruding to steal information or to disable the network itself. Systems analysts and software can monitor networks 24/7 for unusual patterns. In the case of a security breach, devices containing secure information can be completely locked down or, in some cases, open a trail leading directly to the cyber attacker.\nIt is possible for government agencies to realize cybersecurity as it was meant to be: a function that allows information sharing, protects data from unauthorized use, and protects citizen privacy. Leadership and commitment from the highest levels of government and industry are the answers. Only with visible and sustained focus from the top on properly funding and staffing information assurance will the cultural change and sustained investment in disciplined governance and defensive cyber technologies occur. Cybersecurity is fundamentally a people problem, not a technology problem. We know what to do; we need the will to do it. Accountability and trust are the behaviors that need to be institutionalized. We know how to do this at the micro-organizational level. We now need to commit to do it at the macro-level for the national and global cyberspace.", "label": 1}
{"text": "The Internet is widely used for research activities including data collection via electronic surveys, recruitment of research participants, and for interventional/observational activities. All uses present unique concerns for the investigator and for the IRB.\nProtection of human subjects is no less important when the research involves observation of online behavior. The IRB will make every effort to ensure individuals such as members of online cancer support-groups grant consent before having their discussions used for research purposes.\nWith the various uses the internet provides, there are challenges that may result pertaining to data quality. Issues surrounding social networking, posting images and videos of participants online, and recruitment and compensations can also be complex and therefore require the investigator to take extra precautions to ensure that privacy and confidentiality are not breached.\nRead More: Considerations and Recommendations Concerning Internet Research and Human Subjects Research Regulations (Produced by the HHS Secretary’s Advisory Committee on Human Research Protections (SACHRP)).\nOn this page:\nUsing the Internet as a Data Source\nResearch involving observation and reporting of online behavior is sometimes called data mining. The term data mining also refers to sorting through data to identify patterns and establish relationships.\nConsider the following:\n- Not all content on the internet is “public information.” Access is not a justification for collecting data without consent from the subject(s).\n- Most online groups do not require individuals to participate in discussions. After obtaining IRB approval and PRIOR to collecting ANY research data, permission must be sought from the list/group/community manager, and an announcement should be made to the list/group/community of the investigator’s intention to conduct research on the group.\n- Consent must always be obtained from subjects before attempting to collect private information. However, the investigator may request a waiver of informed consent. Concern that permissions will not be granted is not a justifiable reason for the IRB to waive consent.\n- Procedures must be in place to verify that research participants are adults.\n- Depending on the sensitivity of the research/data, clarity of disclosure, and confidentiality/anonymity of subjects, the IRB may require permission and/or informed consent to be obtained in addition to a community-wide announcement.\nUsing the Internet as a Research Tool\nThe internet can be used as a method of surveying subjects via direct email, web surveys, or other electronic instruments. The internet is a non secured medium meaning data in transit is vulnerable. The potential harm resulting from breach of privacy and/or confidentiality is accentuated if the research involves data that places subjects at risk of criminal or civil liability and/or could damage their financial standing, employability, insurability, or reputation.\nGuidance for Online Data Collection/Consent\n- A consent document for the internet should be written like a cover letter and should include all the elements of a regular signed consent, as appropriate. The signature line should read, “By completing the survey, you are agreeing to participate in the research.” Web based surveys should offer subjects the option to “Agree”/”Not Agree.” Online consent may not be appropriate for studies involving highly sensitive information.\n- For sensitive data transmission, the investigator should include a disclosure in the consent process, such as: “This research involves the transmission of data over the internet. Every reasonable effort has been taken to ensure the effective use of available technology however, confidentiality during online communication cannot be guaranteed.”\n- An alternative means for completing the survey should be offered where appropriate, such as printing the survey and mailing it in.\n- Survey instruments should be designed in such a way that allows participants to skip questions or provide a response such as “I choose not to answer.”\n- At the end of the survey, there should be one button to submit the data and another button to discard the data. The purpose of these buttons is to ensure that a subject may withdraw at any time and to help them understand that if they do withdraw, even after completing the survey, their data can be discarded prior to transmission to the researcher.\n- There are various protocols for transmitting data securely over the internet with SSL (Secure Sockets Layer) connections or Secure HTTP. Both SSL and S-HTTP can work interdependently or together. On an IRB application, the investigator must describe the technology chosen for implementation of the research and justify the plan based upon the sensitivity of the research.\nFor more information on online subject recruitment click here.\nChallenges of Internet Research: Data Quality\nSample Bias – Exclusion of Subjects\n- Internet samples make it problematic for researchers who attempt to generalize to broader groups.\n- Internet users vs. non-users vary on demographic, social, and psychological dimensions.\n- Dropout is an issue.\n- Longitudinal data collection is problematic online because email addresses and membership in online forums can quickly change.\nControl over Data-Collection Setting\n- Researchers can lose control over the environment in which the research is conducted when they conduct surveys or experiments online.\n- Behavioral monitoring and verification of subjects’ identities, age or gender present increased challenges.\n- Online subjects may simply invest less time and energy in the research task than those involved in a telephone survey or laboratory experiment.\nIssues in Social Networking Sites\n- Voluntary participation and identity disclosure is violated when researchers participate in discussion groups and bulletin boards and/or record and analyze text, but do not identify themselves as researchers (Engel & Schutt, 2010).\n- Posting patient protected health information is a violation of the Heath Insurance Portability and Accountability Act (HIPAA).\n- Posting pictures of patients (including those taken in international sites) is a potential violation of patient privacy.\n- The participants should know what information the researcher has/will collect; boundaries should be clear regarding what information will be gathered.\n- Knowing the researcher – if participants were to look at the researcher’s Facebook profile or conduct a “Google” search on her prior to the first study visit might this impact how they answer questions (Brooks & Churchill)?\nTo ensure that privacy is protected when using blogs for research:\n- Assess the blogger’s intent to be more or less private.\n- Ensure that the information used does not contain identifiable information. If a blogger uses a pseudonym used elsewhere on the internet, it may lead someone to information that can help identify the blogger.\n- To respond to higher levels of privacy, you may want to exclude certain content. Obtain consent from the blogger or mask certain details to minimize risk.\n- Work with the IRB to come up with a plan to help clarify how to calibrate privacy protections for blog material (i.e. exclude password-protected blogs).\nPosting Images or Videos of Participants Online\nPosting images or videos online can have ethical ramifications. It is good ethical practice to let the people identified in the picture know that you are photographing them and inform they of any plans to post online.\n- Online networks, such as PhotoVoice, have increased opportunities for artistic expression through participatory photography. Photo Voice employs participants to take images of their surroundings/neighborhoods as a way to advocate for social change.\n- Using images created of or by research participants can become complex as issues of consent, anonymity, and copyright come into play.\nTips for Photographing Subjects\n- Research participants may be actively involved in gathering data as they take photos to address different topics regarding social change.\n- Researchers should tell participants if they are required to report any photos revealing child or elder abuse or the likely prospect of harm that a subject may inflict on themselves or others.\n- Investigators must learn what methods of consent are acceptable to the IRB prior to photographing or otherwise recording subjects.\n- Researchers legally own the photos.\nWorking with Children Online/ Additional Security Considerations\n- Investigators communicating with children over the internet are subject to the Children’s Online Privacy Protection Act (COPPA) in addition to human subject regulations (45 Part 46 Subpart D). Investigators must not collect personal information from a minor without verifiable parental consent.\n- As appropriate, technology may be used to help screen out minors, such as programs that check for Internet Monitoring software or Adult Check systems.\n- The data file used for data analysis should be free of IP addresses or other electronic identifiers. If IP addresses are collected by the survey tool, the addresses should be deleted from the downloaded data file.\nRecruitment and Compensation on the Internet\nThe text and context of the recruitment message for any Human Subjects Research must be reviewed and approved by the IRB before the research begins. This includes posting to a blog or message board, mass e-mailings, and web pages created for recruitment of participants.\nTips for Compensating Anonymous Subjects\n- Consider using gift certificates from online retailers (and displaying the unique certificate redemption number to subjects after they complete the survey), in lieu of requiring identifiable information in order to mail out compensation.\n- Do not link compensation to contact information.\n- Use an intermediary service to manage your compensation.\n- Internet Research Ethics and IRBs (PowerPoint)\n- International Journal of Internet Research Ethics\n- Report on Conducting Research on the Internet (British Psychological Society)\n- “Internet Research, Internet Recruitment, Managing Data on the Internet” (Video)\n- VCU, Using the Internet to Conduct Research\n- IRB Challenge: Research on the Internet\n- The Board of Scientific Affairs (BSA) Advisory Group on Conducting Research on the Internet\n- Association of Internet Researchers “Ethical Decision-making and Internet Research”\n- Advisory Reports\n- Health and Human Services Secretary’s Advisory Committee on Human Research Protections (SACHRP).\n- The Board of Scientific Affairs (BSA) is the primary advisory body to the American Psychological Association. Their advisory report describes some benefits and challenges of conducting psychological research via the Internet and offers recommendations to both researchers and institutional review boards for dealing with them.\n- Ethical Decision-making and Internet Research: The Association of Internet Researchers (AoIR) ethics statement, developed by ethicists and researchers from 11 countries, articulates guiding questions for online research appropriate to the many disciplines—both within the social sciences and the humanities—that undertake such research.\nCases of Breach of Privacy\n- Harvard Researchers Accused of Breaching Students’ Privacy (July 29, 2011): some 1,700 Facebook profiles, downloaded from an entire class of students at an “anonymous” university, could reveal how friendships and interests evolve over time.\n- Large-scale Breach of Privacy Rules by New Zealand Post: A New Zealand Post survey that collected personal data to sell to marketing companies has been damned as a “systematic, large-scale breach” of privacy principles.", "label": 1}
{"text": "\"I can STEAL YOUR MONEY, your EMAIL or your IDENTITY. I can take control of your computer and use it to distribute spam, illegal pirated movies, or even CHILD PORNOGRAPHY. I could ruin your computer or your life.\"\nClick here to find out about confidence tricks, dangerous programs, how big the risk is.\n\"A good antivirus program will protect your computer without slowing it down, be easy to use, and have telephone support when you need it.\"\nClick here to find the best antivirus program for your computer.\n\"A properly protected computer is MUCH less likely to get infected by dangerous programs or viruses. Check your computer to make sure it's secure - or get an expert to do it for you.\"\nClick here to find out about computer security.\n\"You can avoid Internet risks by taking a few simple steps. Learn to recognise commong threats, warn your children, and THINK BEFORE YOU CLICK!\"\nClick here to find out how to stay one step ahead of the crooks.", "label": 1}
{"text": "What constitutes a strong password? An excellent question and something the industry seems to have difficulties figuring out at the moment. NIST, the National Institute of Standards and Technology, has a few words to say on the topic. Basically, password strength boils down to the number of bits of entropy that a password has.\nSo the next question is: How does one calculate the number of bits of entropy of a password? NIST has proposed the following rules:\n- The first byte counts as 4 bits.\n- The next 7 bytes count as 2 bits each.\n- The next 12 bytes count as 1.5 bits each.\n- Anything beyond that counts as 1 bit each.\n- Mixed case + non-alphanumeric = up to 6 extra bits.\nAfter thinking about this for a while and crunching some numbers, the NIST proposal seemed decent enough. Plus, implementing the algorithm in software is easy. Unlike a lot of programmers, I don't take algorithms like this at face value and just implement them blindly. I like to test their claims first and sometimes introduce my own ideas.\nDuring my research phase, I also ran across this xkcd web comic:\nWhile I don't generally care for xkcd comics, this one actually made me think. Is \"correcthorsebatterystaple\" actually 44 bits of entropy? I immediately said to myself \"no\" but, being a sucker for self-inflicted punishment, I went to check.\nModern security is best done by not \"handing out\" bits of entropy. Basically, you only want to say that something has \"at most 'x' bits of entropy\" if that something passes a number of tests.\nMy initial calculations of \"correcthorsebatterystaple\" against the NIST rules result in a maximum of 41 bits of entropy. So, xkcd handed out three undeserved bits. Three bits doesn't sound like a lot, but it is the difference between 550 years and 69 years. Also, this is a phrase using words from the dictionary and the letters of the phrase have a lot of repetition, so I modified the NIST algorithm to only count a multiplier of 75% of each repeat character (e.g. the first 'r' counts for 100% of the bits, the next 'r' counts only for 75% of the bits, etc). This drops the number of bits of entropy to 34.2. My own algorithm runs some more tests but the result still comes out to 34 bits. This is 10 bits fewer than the xkcd comic's claim for that strategy to selecting a password. Or, more simply put, roughly half a year at 1000 guesses/sec. Not 550 years.\nFor the \"Tr0ub4dor&3\" part of the comic, my same base algorithm gives me 22.1 bits, not 28 bits. Or roughly 1.2 hours at 1000 guesses/sec. However, the extra tests in my algorithm actually calculate it as having about 14 bits of entropy.\nOf course, the actual time it takes to guess the password is going to be somewhere between my theoretical time and xkcd's theoretical time. So, while on a surface level, xkcd seemed way off, the approach to selecting a good password with four random words isn't actually half bad and is a considerable improvement over today's passwords that users select. And we are all for anything that improves the passwords that users select...right?\nIf the computer generates dictionary-based passwords for the user, then that will eliminate the human equation. A human, following xkcd's rules, would likely select words of things that they can see, hear, and touch in their immediate vicinity - making it easier for a hacker to build a small attack dictionary. A quick glance around me and I get \"computerkeyboardvideogamenetflixmoviewikipedia\" - a great password from the algorithm's perspective except for the fact that I'm sitting at a computer with a keyboard, I love playing video games, I have a Netflix DVD movie in front of me, and I visited Wikipedia recently. So, even though I'm sure it has terrific entropy, it is a terrible password. Hence the need for a computer to generate dictionary-based passwords.\nOne thing I've noted with so-called \"password strength meters\" is that they are generally useless. The server-side doesn't enforce password strength requirements. Part of the problem is that no one seems to have come up with a solid algorithm (other than NIST) and no one has actually said, \"here is how you should use this password strength meter...\" This combination is useless to the average server-side programmer, so the only thing I've seen done is display the meter to the user and hope they make a strong password. Ha! As if that will ever happen.\nWhat should actually happen: Calculate the number of bits of entropy in a password using a good algorithm and then apply a minimum threshold. (And get rid of the silly password meter.) If the password exceeds the threshold, then the password is strong enough, otherwise the user has to try again.\nThis approach allows a web forum owner to choose a minimum threshold of 18 bits of entropy and an online bank to choose a minimum threshold of 40 bits of entropy (or more). Each industry requires different password strengths. A password strength meter, if you really need one, could then become useful for prevalidation against the threshold. After all, the user only cares to know the answer to the question, \"Will my password be strong enough so I won't have to resubmit this form?\"\nI'm still nitpicking at my algorithm, which is one of the reasons why it isn't being published (yet). So, don't get your knickers in a twist over my \"hand-waving\" claiming to have a solution and not playing nice in the kiddie pool and sharing said solution. The algorithm will be released in due time.\nAnother example: Google recently published an online safety guide on their homepage. This guide contains a YouTube video and other similar textual instructions on creating so-called strong passwords. The YouTube video shows \"Garden1ngF@n\" as a \"strong password\". For that password, my base algorithm gives 22.8 bits of entropy, but the extra tests portion of my algorithm calculate it as having around 16 bits of entropy. Yikes. Seems really broken to me.\nSo it looks like I'm onto something here. My algorithm is blasting apart even Google's recommendations for strong passwords. Woot!\nRead the next part in this three part series: Calculating Password Strength: Part II", "label": 1}
{"text": "Cyber-protest reflects cyber-warfare in its advantages over its physical counterparts; it is difficult for law enforcement to identify and prosecute the cyber-perpetrators. Cyber assaults in all forms are economical to conduct and the financial returns are overwhelming – causing potentially millions of dollars in actual and reputational damage with an attack like the one on Sony or STRATFOR (where payment information was compromised and published causing reputational damage) at a fraction of the cost.\nCyber-protest groups such as Anonymous have begun to affect the physical sphere. Anonymous were the organizers for the BART protests in San Francisco. Occupy Wall Street was the brainchild of the Adbusters protest group, with Anonymous becoming vocal promoters of OWS as the event grew close. Although the “Occupy” concept began in Spain and Greece, it has achieved global recognition under the Occupy brand. Now the Occupy Movement is seeking other forms of expression because the actual occupations have dwindled in numbers and media coverage has waned. Therefore, cyber-protest becomes more appealing.\nCyber-protest delivers all the same threats to companies that physical protest do: compromise of reputation; compromise of individual leaders and employees through doxing (the publishing of sensitive personal information on the internet); the compromise of physical infrastructure and assets (hackers can disrupt SCADA connected to the internet) or anything from the grid, from nuclear plants to electric turbines. As a result, if any of these components are attacked, the assault will have a significant effect on the financial interests of the company.\nCyber security has therefore taken on a whole new front. Not only must companies assess and manage the risks to their data centers, payment systems and finances, which tend to be better protected than the rest of the company, the penetration of the company’s e-mail systems, its records, its files and all its facilities must now be of concern. If Anonymous can hack the FBI’s e-mails and monitor telephone conversations, one must assume nothing is truly safe.\nWhat actions can companies take? Any company that has an active General Counsel will already have policies concerning what is written in e-mails, with good cause because of what occurs during legal proceedings. With the cyber threat, that is increased as an ongoing vulnerability. Making certain that physical and cyber systems are protected from being mutually compromised is also important. From the physical components of gates and guards through the IT systems to facilitate security, physical penetration is certainly viable at this stage, and there are some assaults that can only be carried out through physical penetration, including insider threats.\nCompanies MUST understand their protestor risk. Once the threat has been established, the means by which protests may materialize, be they by physical or cyber means, can then be assessed. Once a company fully understands the risk it faces from the protest community because of its own actions and counter-parties and those of its supply chain, then it can begin to understand the threats and the measures that can be put in place to manage those threats.\nAUTHOR’S UPDATE – February 15, 2012: Beginning Tuesday morning, Anonymous began attacking the websites of companies that sell less lethal weapons and technology, with the main focus apparently Combined Systems, Inc. When the press covers the use of CS gas in Bahrain, it is the logo of Combined Systems, Inc that is most often seen. This is an excellent example illustrating the point that one must understand the complete protester threat to a company as part of routine risk management, no matter how far from controversy one might believe their company to be. Once the exposure is understood, one can design one’s response to it. This requires understanding the supply chain and the political context.\nLAST 5 POST BY Sam Rosenfeld\n- Activist Groups Flocking to Environmental Issues, Direct Action Protests - February 20th, 2013\n- FBI/DHS Inaccuracy Could Lead to Police Over-Reaction - August 25th, 2012\n- Protest Groups Publish Police Home Addresses - August 21st, 2012\n- Worrying Signs From Tampa - Protest Management at the RNC - August 14th, 2012\n- Protesting is Cool This Summer - June 21st, 2012", "label": 1}
{"text": "The social web can only thrive if its participants are willing to share personal data, data about themselves, with each other. So, you have an account with some social network (Twitter, del.ico.us, LinkedIn, etc) in order to allow others to read your Tweets, peruse your presentations or, quite generally, find out who you are and what you do. With the advent of the semantic web, of systems that can make inferences on the basis of the data that are fed to them, this is all the more true. Individual users profit from the services that the web offers to them, often for free; the service providers profit, mainly from the advertisements that accompany their services. Although there are other business models, this is the prevailing one, it seems.\nSo far so good then. But what if service providers sell the data they have acquired in the course of their business to other providers; or worse even, what if these data end up in the hand of others because of clumsiness (a stolen USB stick, a lost laptop) or criminal intent (hacking servers, bribing personel)? Admittedly, you may decide to shut down your Facebook account or give up Twittering, but this freedom of choice is absent for many services. What about your loyalty card with your favourite grocery store, which not only registers your purchasing behaviour but also gives you access to sizeable discounts; or your public transportation travel pass, a system recently introduced in The Netherlands, which allows you to travel throughout the country with one card but registers routes and start and end times in its database; or a road use system installed in your car which helps prevent traffic congestions but does so by logging your car's GPS track data in its central database? In each of these examples - and many more can easily be given - data about a person are logged into a database and it is not transparent to the data providing individual what the associated privacy risks are.\nIn 1981 the states that jointly form the European Council signed a ‘Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data’. Among other things, it stipulates that no more data may be stored than needed for a particular, identified purpose, and that those data may not be kept for longer than strictly needed. The lack of transparency compels the individual to simply trust the database manager to abide by these rules. Experience teaches us that often this trust is misguided, even if we ignore cases of intentional theft and accidental loss of data. The issue of whom to trust with what data is a complex one. It touches upon the closely related questions of what data to collect and whom to allow to access them. The other day, I read a PhD thesis that sheds an interesting light on the first one of these questions (Harold J.W. van Heerde (2010) Privacy-aware data management by means of data degradation; making private data less sensitive over time. Universiteit Twente).\nIgnoring for now the possibility to grant differential access rights, someone can decide to make her particular personal data available or decide not to do so. A LinkedIn profile may contain a photo but need not. Something similar goes for the data that are collected through someone's public transport travel pass. If one uses the pass, route and time data will be collected and stored. Could a user still decide to remove or replace her photo, the storage of travel data is fully beyond her control. The point to note here is that the decisions are all-or-none decisions. Someone’s photo is there or it isn’t, travel data or logged or aren’t. There is no middle ground. Van Heerde shows that a sensible middle ground does exist. He introduces a limited retention principle, meaning that data degrade over time. So, the public transportation database may remain fully intact for a month to allow sending out bills. The data may subsequently be degraded to the level of the route and day of the week someone has travelled to allow sending out special offers. This level of detail is maintained, say, for a year. After one year only the cumulative frequency of use or routes per day of the week, decoupled from the individual, are still available. This still allows the statistical analysis of travel data, for planning purposes for instance. Data degradation allows for a more subtle marriage of the interests of the individual (new, better, cheaper services) with those of the service provider (a more efficient and effective business). Of course, there are all sorts of theoretical and practical problems to be dealt with. Van Heerde discusses many of them, he also suggests how to solve them. For me, the importance of his contribution is his description of how one may come one step closer to heeding the European Council's admonition only to store just enough data for just long enough. This is in the interest of both web service users (aren't we all) and web service providers.", "label": 1}
{"text": "[Editor's note: The Tyee is proud to co-publish with Rabble.ca a multi-part investigation of Maker Culture -- the do-it-yourself movement fast evolving in North America and beyond. This is episode four of 11, running Fridays.]\nIt's a wet Saturday afternoon at a hacker convention in an industrial section of Hamilton, Ontario. Treven Watson's Lucite badge is flashing: blue, green and red. The LED lights are controlled by a circuit in the laser-etched ID. That little bundle of electronics is about to be probed and reprogrammed by Watson and the three dozen other coders, anxious to make it do anything but alternate primary colours.\n\"There's a tradition in hacker conventions of making badges that can be expanded, can be hacked to do other things,\" said Watson.\nWatson is a member of the Hamilton hacker space think|haus. Attendees at the convention each got their own badge and spent hours seeing who could hack it best.\nHackers love figuring out systems like these badges, whether it's picking a lock, social engineering or hacking a computer.\nBeyond the thrill of the prank, what drives people to hack? \"I think it’s what drives us to be human,\" said Howard Rheingold, a writer, artist and teacher who coined the term \"virtual community.\"\n\"When we talk about technology, I think people often disconnect that from the fact that we are creatures that have hands with opposable thumbs and binocular vision and brains that have evolved because we coordinate our activities in manipulating the world.\n\"Our ancestors were rather small creatures and they were prey, how was it that we turned into the top predator in the food chain? It had to do with not only our ability to use our hands, but our ability to coordinate and communicate with each other.\"\nThe birth of digital hacking\nBy coordinating and communicating, early computer enthusiasts formed support systems. Hackers experimented with software and hardware, pushing the bounds of computers for the fun of it, and advancing computer capabilities along the way. One of the most notable of these was the Homebrew Computer Club (HCC) out of Silicon Valley in California.\nOut of the HCC came Steve Wozniak's Apple I, a hobby computer made to impress his friends. He handed out schematics and helped people set up their own at home. His college friend Steve Jobs convinced him to patent and sell the Apple I. This was Apple Inc.'s first product, and it was quickly followed by the Apple II, which was produced until the early '90s.\nThe personal computer revolution all but ended community hacking. Hackers quickly made careers as developers who couldn't share their secrets, or they would be scooped by a competitor.\nSecurity cracking, our modern idea of hacking, grew out of the '80s alongside personal computers.\nHACKING'S PHREAKY HISTORY\nMessenger boys became the first hackers when they were hired to work on telephone switchboards in the late 1860s. They quickly hacked the system. Dropped calls, intentionally crossed lines and insulted customers became too much. And in less than two years, the boys were flung off the switchboards. Docile young ladies were hired to take their places.\nAbout a century later hackers showed up again. Phreakers hacked phone systems for free long-distance calls. The switching systems to connect calls were automatic at the time, run by a series of signals and tones at different pitches.\nIn 1972, John Draper was a young Californian fascinated by technology. But when a blind friend discovered that whistles found in Cap'n Crunch cereal mimicked the signal to switch a call to an open internal line, Draper's life changed forever. He became Cap'n Crunch, the most famous of the phone phreaks. The discovery inspired Draper to create \"blue boxes,\" devices that could imitate different system signals while connected to a telephone.\nIn the mid-'70s Draper met the future co-founders of Apple Computers, Steve Jobs and Steve Wozniak. Draper showed Wozniak how to use a blue box in Wozniak's college dorm. To test it, they placed a call to the Vatican for free and asked to speak to the Pope. It was around four in the morning in Vatican City, and the Pope was sadly unavailable.\nAt the same time as the negative press on hacking, more people began using PCs. Connecting computers became a major goal, and early networks were developed -- ARPANET, Bulletin Board Systems, then web 1.0 and 2.0. People continued to appropriate technology and use it to connect to the world around them.\n\"'Appropriated' is a word that is compatible with 'hacked,'\" said Rheingold, and in the case of communications technology, \"people will take tools that are provided for other reasons and use them to communicate.\"\nBut the concept of hacking technology for the fun of it, and making things work the way you want them to, can still trump the desire to create new ways to communicate.\nFresh, homemade mobile innovation\n\"I was inspired by the movie Ferris Bueller's Day Off, where he's sick, he makes this call where he plays back puking sounds from his keyboard,\" says Tobias Weyland. \"Bueller inserts this diskette into his keyboard and pretends to be really sick, I've always wanted a thing like that.” Weyaland's a Nintendo DS homebrew game developer.\nHe finally got to fullfill his dream -- well, without the cybervomitting. The PhD computer science student at Aachen University in Germany always wanted a portable music tracker, so he programmed one. Nitro Tracker is one of the most popular homebrew applications for the Nintendo DS and allows users to create basic melodies that resemble the beeps and boops of old video games. Weyland is also part of an active community of homebrew developers and coders called Dorkbot.\nWeyland started playing the popular PC game Crayon Physics. He wanted to take it everywhere in his pocket, so he developed Pocket Physics. Drawings on the DS touch screen react to real world forces, like gravity. Crayon Physics has spawned an online community, where users can upload and share their creations. When Weyland runs into problems developing DS homebrew, he brings his applications to his local Dorkbot group, a worldwide group of makers and hackers who get together and share ideas and concepts.\nHomemade applications need help to work. Small cartridges, called flashcards, hack the DS and allows it to run unlicensed code, including pirated commercial game files. This gives the homebrew community a bad reputation, and Nintendo has shut down many flashcard retailers. Over the years, flashcards have evolved from clunky pieces of plastic to sleek devices that look like regular DS games. Micro SD cards fit inside them and allow data transfer from computer to flashcard.\nLucas Arts lead designer Jens Anderson developed the game Colors!, which allows users to create detailed art. Anderson worked around the DS hardware limitations to make his advanced image creation program. An online community sprang up, similar to Pocket Physics' following, which allows users to upload their artwork.\n\"The most surprising thing was clearly how well it was received within the professional digital concept art community,\" said Anderson.\nJeremy Smith of Vancouver, British Columbia, developed a DS version of Guitar Hero. Users tap onscreen notes and follow the tune of popular video game music. Smith collaborated with an artist to create the visual interface for his game.\n\"I'd always been interested in doing a music-slash-rhythm game,\" said Smith, who also programs user-generated iPhone applications.\nClosed platforms: why there isn't 'an app for that'\nThe iPhone revolutionized mobile communications by allowing individuals and software companies to develop apps for the platform. But Apple continues to frustrate app developers with a \"black box\" approval process that many find arbitary and slow. Now Google has opened the gates further for inexpensive application development on the open source Android mobile platform.\nAndroid, which runs on open source code, offers an app store, the Android Market, much like the iPhone's, but with one important difference -- Google's removed the approval process. Android’s open door policy has the hacker and programming communities' interest.\nMichael Both originally developed the GolfCard app for the iPhone, because it was the only touch screen handset capable of running his program. Google contacted Both when Android was released to tell him about their new operating system. \"Essentially, it was described to us as being just like the iPhone platform, minus the approval process, but with the stipulation that if the app was seen as inappropriate it would be removed from the store,\" he said.\nAart Bik is a Google software engineer who has applications available on the Android Market. \"I implemented a few board games just for fun and put them in the market in the hope that users would enjoy them. I expect that professional programs will replace them pretty soon, but I have been pleasantly surprised with the popularity of the applications so far,\" Bik said.\nMatt Liszt is a software developer at Glu, the company responsible for the mobile version of Call of Duty on Android. Glu has a long list of mobile games which were available before the iPhone. Liszt thinks that because Android is an open platform, it will help makers innovate. \"We are already seeing that most of the top apps on Google [Android] are from small developers,\" Liszt said.\nEric Burke built the State Capitals application for Android. He is outspoken about his passion for an iPhone alternative. \"Developers are annoyed by Apple's constant app store rejections. You don't have that same frustration with Android. I can publish an update to my app and it is available for download instantly. As more and more phones arrive, there will be more customers, so Android is becoming a viable market to make some money,\" Burke said. Like many hackers and makers, Burke wants the freedom to share an innovate the Android Market offers.\nA 'beat' to save the open web\nClosed mobile platforms, like the iPhone, don't just threaten application diversity. The Mozilla Foundation thinks they threaten the very foundations of a democratic Internet, as users continue to carry their digital lives in their pocket.\nFrank Hecker, director of grants and programs for the Mozilla Foundation, said the increase in mobile technology threatens the idea of an open web. Mobile devices are often closed systems with heavy applications restrictions.\n\"There's a real danger in moving to the mobile space that we're going to lose a lot of the ‘generativity'... of the Internet which has traditionally existed,\" said Hecker, referring to the revolution of web 2.0, which gave the Internet easy self-publication tools.\nThis generativity is what the grassroots movement called Drumbeat is hoping to protect.\nCreated in August 2009 by Chelsea Novak and executive director of the Mozilla Foundation, Mark Surman, Drumbeat is a community of people from knowledgeable hackers to casual web users, who feel that the Internet should be seen as a public utility. Mozilla is giving that community a space to meet, collaborate and receive support from the Foundation themselves.\n\"There are people out there who, we like to say, they make the web,\" said Novak, fundraising and communications manager for the Mozilla Foundation. \"Technology companies and software companies, they build the web, but people who make the web are people who blog and they do LOLcats... they create all this content and all this material that we use on the web.\n\"Because they're not necessarily 'building the web,' they may not realize that they have a say in the issues.\"\nThe Mozilla Foundation gives those users a say with Drumbeat.\n\"Mozilla's mission is to make sure that the Internet continues to be open and that it continues to be a place where people can innovate and create,\" said Surman. \"Drumbeat is a new effort to go beyond that and pursue that same objective, but beyond product.\"\nDrumbeat is still in its early stages, with new contributors joining the discussion as the movement grows. The first issues to tackle have yet to be identified, Novak said, but Surman sees the rise of the Internet cloud as an area to address. He said as users toss their personal data into the \"cloud,\" through hosting applications like Gmail or Facebook, they breeze by legal jargon in Terms of Service agreements without fully understanding where their information is going, who owns it and how it will be used.\n\"There really hasn't been either a conversation or really a set of products to figure out 'what [does] my kind of freedom and my control look like in those cloud apps?'\" said Surman.\nDrumbeat wants to inspire enthusiasm for the open web and get users, not the corporations, to make change. Surman said Drumbeat is about creating plug-ins and tools that enhance the openness and accessibility of the Internet, rather than asking for changes in proprietary software.\n\"We can go to Microsoft and say, 'Make IE6 [Internet Explorer] better,' but I'd rather we created a product that people want to use,\" said Surman. \"We're trying to say that anyone can pick up the tools and create the Internet. And I think we all do. So much of the Internet is shaped by us every day in terms of who makes the content. Drumbeat is very much about that.\"\nThe street finds uses for things\nBack at the hacker conference, attentions have shifted from the blinking badges to the set-up of a 3D printer from MakerBot Industries.\nJames Arlen, founder of think|haus, looks across the busy workspace to the half-built printer. \"William Gibson said this in the early- to mid-'80s. He said 'the street finds uses for things.' So whatever the original purpose was... whatever the marketer intended, might not be the way that it turned out. And that's where we are. So that was 20 years ago,\" he says. \"What's going to happen in another 20 years?\"", "label": 1}
{"text": "malwareArticle Free Pass\nmalware, in full malicious software, malicious computer program, or “malicious software,” such as viruses, trojans, spyware, and worms. Malware typically infects a personal computer (PC) through e-mail, Web sites, or attached hardware devices.\nMalware may be used to take over PCs, turning them into zombie computers that may form part of a “botnet” used to send out spam or perform denial of service attacks on Web sites. In addition, malware has been used to distribute pornography and unlicensed software. Owners of infected PCs often become aware of a problem only as their machines become progressively slower or they find unidentifiable software that cannot be removed.\nRootkits are one of the worst forms of malware. Their name comes from the fact that they infect the “root-level” of a computer’s hard drive, making them impossible to remove without completely erasing the drives. In efforts to curb copyright infringement, some computer software makers and music companies secretly install detection software on users’ machines. For example, it was revealed in 2005 that the Sony Corporation had been secretly installing rootkits as its music CDs were loaded into PCs. The rootkit was discovered because of the way that it collected information on users’ PCs and sent the data back to Sony. The revelation turned into a public relations disaster, which forced the company to abandon the practice. The practice of monitoring users’ data, with or without installing rootkits, continues in the software industry.\nThe evolution of malware reached a new milestone in 2010, when the Stuxnet worm proliferated on computers around the world. Characterized as “weaponized software” by security experts, Stuxnet exploited four separate vulnerabilities in the Windows operating system to achieve administrator-level control over specialized industrial networks created by Siemens AG. By attacking these supervisory control and data acquisition (SCADA) systems, Stuxnet was able to cause industrial processes to behave in a manner inconsistent with their original programming, thus crossing the line between cyberspace and the “real world.” While Stuxnet’s intended target remained a matter of debate, the worm demonstrated that SCADA systems, which provide the backbone for such critical infrastructure sites as nuclear power plants and electrical grid substations, could be subverted by malicious code.\nWhat made you want to look up \"malware\"? Please share what surprised you most...", "label": 1}
{"text": "The official announcement of every terrorist attack invariably concludes with a stock phrase, “Ghatna sthal ke nikat suraksha ke prabandh our kare kar diye gaye hain (security arrangements around the place of incident have been further strengthened).” However each incident is succeeded by another attack, to be followed by a similar announcement. Terror strikes at the place and time of its choosing. Yet there is a pattern and that pattern essentially lies in the behaviour of the terrorist and modus operandi of the parent organization.\nFuture attacks cannot be predicted, but past ones can be catalogued, stored and retrieved in near real-time. “Data archiving” and “data mining” are scientific tools and methologies, the former for gathering, sifting, hoarding and storehousing data, and the latter for displaying duly processed critical information to the decision-maker, whenever the need arises. Its hallmarks are virtuality and event-retrieval potential, and its purpose is to match, locate and track saboteurs, hijackers and terrorists.\nIn April 1999, Applied Systems Intelligence Inc was selected by the US Air Force to develop innovative information technology for a Global Information Base to “store global awareness information,” besides providing information services for dynamic planning and execution of operations. The software developed by the firm is called KARNAC, short for Knowledge-Aided Retrieval in Activity Context. It is highly versatile, and is anchored in a group of technologies and decision support and database management systems. It is designed to detect and identify impending terrorist operations and similar missions.\nIt is well known that Al Qaida terrorists and others of their ilk hunt for information on the Internet, often leaving valuable clues while surfing and communicating. Therefore it is logical to look for and pursue them in their haunt rather than go on hunting missions. Adam Pasik writes in “Sifting through Data to Detect New Attacks,” (infowar.com), “The problem is that intelligence and law-enforcement agencies are searching the world’s biggest haystack – untold exabytes, or quintillions of bytes of data stored on computers across the globe – to uncover a few dangerous needles.”\nAt the time of the September 11 attacks, there was a plethora of helpful scraps of information available e.g. e-mail intercepts, telephone calls, car rentals, airline reservations, financial transactions, casino winnings, Immigration records and much more. During the attack on our Parliament, the terrorists left behind pertinent information such as a laptop, which has reportedly been sent to Microsoft for analysis, and vital information about the terrorists’ hawala (money laundering) links and ISI connections garnered from cellular numbers called by the terrorists. Whereas security, intelligence and law-enforcement agencies work in tandem in the\nand other Western democracies with common databases, in\n, the right hand does not know what the left holds. Sharing information is the only way terrorists can be defeated at their own game and this sharing must occur within the security and law-enforcement agencies in the country, and also amongst all the countries fighting the global war against terrorism.\nCritical event detection, information retrieval and knowledge-based technologies, products and systems are available off-the-shelf, and are widely used in the commercial world. Banking fraud detection, promotional mailing, market research, supply chain management, tracking stolen credit cards, and antecedent check by credit companies are some of these applications. The potential market for these products is estimated to be several hundred million dollars. Indian software companies are aware of its potential and have ventured into writing some useful software applications. The software is not infallible, but that should not detract from its merits, which essentially lies in integration, automation and embedded security.\nThe technology can bring to focus artificial intelligence and virtual reality to search large data repositories, identify events of interest and compare templates. Elsewhere, much work has been done to acquire this capability. The rub lies in matching wits, in which the terrorists have an edge. Making events appear unrelated, random and seemingly innocuous is their strong point. Archived information can help in timely detection by piecing together the pattern, and sounding the alert based on past acts of terror. It could thereby preempt attack on a government or commercial facility.", "label": 1}
{"text": "The MySQL root password allows full access to the MySQL database and allows for all actions to be undertaken including creating new users, new databases, setting access rules and so on.\nLosing one can be a difficult issue to encounter. Luckily, resetting the root password is easy as long as you have sudo access to the Server.\nA common issue is confusing the Server root user with the MySQL root user.\nThe Server root user is the server's main user. The MySQL root user has complete control over MySQL only. The two 'root' users are not connected in any way.\nThe first thing to do is stop MySQL. If you are using Ubuntu or Debian the command is as follows:\nsudo /etc/init.d/mysql stop\nFor CentOS, Fedora, and RHEL the command is:\nsudo /etc/init.d/mysqld stop\nNext we need to start MySQL in safe mode - that is to say, we will start MySQL but skip the user privileges table. Again, note that you will need to have sudo access for these commands so you don't need to worry about any user being able to reset the MySQL root password:\nsudo mysqld_safe --skip-grant-tables &\nNote: The ampersand (&) at the end of the command is required.\nAll we need to do now is to log into MySQL and set the password.\nmysql -u root\nNote: No password is required at this stage as when we started MySQL we skipped the user privileges table.\nNext, instruct MySQL which database to use:\nEnter the new password for the root user as follows:\nupdate user set password=PASSWORD(\"mynewpassword\") where User='root';\nand finally, flush the privileges:\nNow the password has been reset, we need to restart MySQL by logging out:\nand simply stopping and starting MySQL.\nsudo /etc/init.d/mysql stop ... sudo /etc/init.d/mysql start\nsudo /etc/init.d/mysqld stop ... sudo /etc/init.d/mysql start\nTest the new password by logging in:\nmysql -u root -p\nYou will be prompted for your new password.\n© 2011-2013 Rackspace US, Inc.\nExcept where otherwise noted, content on this site is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License", "label": 1}
{"text": "One thing that won't change is that you can stay safe by showing basic vigilance: Keep your security software updated and run it regularly. Click only on links from trusted sources; the same goes for buying cellphone apps. Be smart about where and how you navigate in cyberspace.\nFive areas where scammers are likely to expend extra energy:\nRansomware. It begins when you open a malicious attachment, click on a link in a scammer's email or instant message, or visit scammer websites that promise such things as enticing videos or free prizes. Ransomware locks your computer, usually displaying a screen message that appears to be from a law enforcement agency. Pay us, you're told, and you'll get back control of your computer.\nOnce considered a niche scam, ransomware attacks exploded in 2012, hitting some 70,000 computers per month. About 3 percent of victims pay the ransom fee — thanks, in part, to cyber-criminals increasingly using online payment methods to collect, says cyber-security firm Symantec, which recently published a detailed report on this ruse. \"In 2013, attackers will use more professional ransom screens, up the emotional stakes to motivate their victims, and use methods that make it harder to recover once compromised,\" predicts Symantec's Kevin Haley.\nCloud-based botnets. For years, spammers have been distributing about 150 billion junk email messages per day with the covert help of the computers of everyday users — maybe even yours. To entice folks to watch videos on social networking websites, open email greeting cards and the like, spammers infect random computers with botnet malware that makes the machines secretly send out spam.\nIn 2013, predict Georgia Tech researchers, scammers will also turn their botnet schemes to what's known as \"the cloud,\" the global network of Internet-connected computers that store huge amounts of data, shuttle it around and offer data services. If you share your family photos online, for instance, you're using the cloud. As more and more companies put customer data and computing power on the cloud, there's an ever-growing collection of prized targets. \"One possible example is for attackers to use stolen credit card information to purchase cloud computing resources and create dangerous clusters of temporary virtual attack systems,\" say Georgia Tech researchers.", "label": 1}
{"text": "However, going totally wireless at home brings with it some possible problems as any new technology will do. Not the least of those concerns is security.\nGoing wireless means by definition that access to your computing resources and the internet is occurring without wires, through the air. And just as every computer in the house can access those digital signals, so can those outside the house and those who might not wish to use those signals properly.\nTherefore when planning your wireless network at home, some precautions and preventative measures should be observed so assure that your network at home is just as secure in a wireless mode as it was when you used cables and physical connections.\nThis purpose of this article is to help you understand the terminology of wireless security in the home setting as well as to develop a check list for key security oriented steps you should take when setting up and using your network.\nSome New Terminology\nThe wireless world has its own language and set of acronyms. So it’s appropriate before beginning our discussion of security to define some of the terms we need to understand to be effective at securing your home wireless network.\nSSID (Service Set Identifier) - This is the name of your network. All devices on the wireless network must use the same SSID to communicate with each other.\nWEP (Wired Equivalent Privacy) - A discipline that was integrated into the very earliest wireless standardization efforts that were put into place for the development of wireless technology. This protocol provides base level security standardization for all WI-FI vendors and systems that benefit from the OSI standardization effort. This standard, also called 802.11 is a default security level that is mandatory for all wireless products. WEP is either turned “on” or “off”. WEP was designed around the same security paradigms that were used in the wired network development time frame.\nWPA (Wi-Fi Protected Access) - A security protocol for the wireless technology industry that was developed to improve on the limitations of WEP.\nTKIP (Temporal Key Integrity Protocol) - TKIP is a more secure version of WEP which is required to utilize WPA for network security. TKIP encryption is stronger and more resilient than the WEP algorithm.\nBy subscribing to our early morning news update, you will receive a daily digest of the latest security news published on Help Net Security.\nWith over 500 issues so far, reading our newsletter every Monday morning will keep you up-to-date with security risks out there.", "label": 1}
{"text": "gets is dangerousThis tip submitted by carl johnson on 2006-07-21 13:13:35. It has been viewed 9031 times.\nRating of 8.1 with 78 votes\nIf we use this code:\nchar string[ 100 ]; printf(\"ENTER SENTENCE: \"); gets(string);\nwe can introduce a bug or security vulnerability into our code!\nThe problem is that it allows someone to enter too much text and thereby overflow the buffer. There is no way for gets to know how big the string is supposed to be, so it will just read data until the user hits enter, even if it's way more than 100 characters. You can read more about the security risk of gets here. You can use fgets instead, which takes both a size for the string, ensuring there is no buffer overflow.\nIf you're interested in learning more about secure coding practices, check out this article on writing secure code.\nHelp your fellow programmers! Add a tip!", "label": 1}
{"text": "Aug. 4, 2009 A system that allows biometric data to be used to create a secret key for data encryption has been developed by researchers in South Africa. They describe details of the new technology in the International Journal of Electronic Security and Digital Forensics this month.\nIf a user, a web customer say, wishes to send a message or other data to another user, an online shop, over an unsecured network, the message must be encrypted to avoid interception of sensitive information such as passwords and credit card information.\nEncryption relies on authentication being symmetric to work. In other words, the user's password or PIN must match the password or PIN stored by the online shop to lock and unlock the data. This is because encryption systems use the password or PIN to produce, or seed, a random number that is used as the cipher for encrypting the data. If the passwords do not match exactly then the seed will be incorrect, the random number different and the decryption will fail.\nOne way to avoid users having to remember endless, complicated passwords is to use biometrics, including fingerprints, iris pattern, face recognition. However, biometrics is not a symmetric process. The initial recording of biometric data samples only a limited amount of the information, the pigment patter in one's iris, for instance. The unlocking process then compares the iris pattern, or other biometric \"token\", being presented for access with the sample stored in the database. If the match is close enough, the user can gain entry.\nThe reason for this asymmetry is that any biometric system takes only a digital sample of data from the fingerprint or iris, for instance. Moreover, even the legitimate user will not be able to present exactly the same biometric data repeatedly. The close enough aspect of biometrics does not make biometrics insecure, provided that the closeness is very precise, but it does mean that biometric tokens cannot be used to create a secret key for an encryption algorithm.\nBobby Tait and Basie von Solms of the University of Johannesburg, Gauteng, South Africa, explain how biometrics can nevertheless be used to make a consistent secret key for encryption.\nIn conventional encryption, if Alice wishes to send a secret message to Bill, then she must encrypt the message, whether it is an email or credit card details transmitted from her computer to the online shop. In order for the encryption algorithm to provide cipher text that is random, a secret key must be provided. Alice and Bill must share exact copies of their secret key for this to work.\nAside from the asymmetry in biometrics, this approach will not work because Alice and Bill cannot provide the same biometric token to encrypt and decrypt the message. Now, Tait and von Solms have used the so-called BioVault infrastructure to provide a safe and secure way for Alice and Bill to share biometric tokens and so use their fingerprints, iris pattern, or other biometric to encrypt and decrypt their data without their biometrics being intercepted.\nThe BioVault encryption system works as follows:\n- In phase 1, Alice identifies herself to the authentication server, and indicates that she wants to send an encrypted message to Bill and requests Bill's biometric key from the server.\n- In phase 2, the server retrieves a random biometric key from Bill's stored biometric keys.\n- In phase 3, Alice uses the biometric key to encrypt her message and sends it to Bill.\n- In phase 4, Bill receives the message sent by Alice, and decrypts the message by testing the biometric keys in his database against the received cipher text.\nThe fact that each biometric key (data) is unique means that the BioVault system can irrevocably identify and authenticate users through their biometric keys (data) and detect fraudulent use of biometric keys.\nTait adds that the same approach could also be used to digitally sign electronic documents, files, or software executables using biometrics. He will be presenting the team's results on this aspect of their work in the UK at the beginning of September. \"If passwords or tokens are used for authentication, only the password or token is proven as authentic - not the user that supplied the token or password,\" he explains, \"Biometrics authenticates the user directly - this was one of the drivers behind the BioVault development.\"\nOther social bookmarking and sharing tools:\n- BioVault: biometrically based encryption. Int. J. Electronic Security and Digital Forensics, 2009, 2, 269-279\nNote: If no author is given, the source is cited instead.", "label": 1}
{"text": "You can create strong passwords that don’t make you memorize a cryptic string of letters, numbers, and punctuation symbols. Here are three techniques:\nUse a sentence. It’s easy to remember the first letters of the words in a sentence. For example, children have used this sentence to remember the names of the nine planets: My Very Excellent Mother Just Served Us Nine Pickles. You could use the first letters of those words to generate this strong 9-character password: m*Emjsu9p, where Venus (the morning or evening star) is represented by *, the letter for Earth is capitalized, and nine is a numeral. In practice, it’s best not to use such well-known sayings to generate acronyms.\nUse a pass phrase. Several words mixed with numbers and punctuation symbols is known as a pass phrase. For example: stitch9clock^handsapplausE. The longer the pass phrase, the more secure it is, though you’ll be limited by the maximum length the site allows.\nGrowing the haystack. Developed by security expert Steve Gibson, president of California-based Gibson Research, growing the haystack takes advantage of the ways hackers crack passwords. “The first thing they’ll try is the well-known dictionary of most common passwords,” Gibson says. “Then, if they know something about you, they will try to guess things from your life.”\nTo foil that part of the process, Gibson suggests starting with a phrase that’s short but not a common word. That forces the hacker to resort to the slower brute-force approach by trying every combination in existence, which is like looking for a needle in a haystack.\nOnce you’ve accomplished that, “the length of the password matters more than its absolute complexity,” Gibson says. In other words, make the haystack larger by padding the password with numerous easy-to-remember symbols. For example, the password “c - @T - - 9 - - -” is 10 characters long and is probably not in any dictionary, but it’s not very hard to remember.\nA caveat: Don’t use any of the above examples as actual passwords. Now that they have been widely published, hackers might add them to their dictionaries.\nCopyrighted 2011, Consumers Union of U.S., Inc. All Rights Reserved.\nConsumer Reports has no relationship with any advertisers on Yahoo!", "label": 1}
{"text": "This article can also be found in the Premium Editorial Download \"Information Security magazine: With SSL VPNs on the offense, will IPSec VPNs eventually be benched?.\"\nDownload it now to read this article plus other related content.\nInsecure RPCs can leave you wide open. Take steps to protect your network.\nRemote Procedure Calls (RPCs) are at the heart of client/server computing, from Windows to *nix, allowing networked devices to seamlessly call services and components from one another. They're also the source of numerous vulnerabilities and exploits.\nRPC is ubiquitous, and that's the dilemma: You can't simply turn it off. That said, you're not without security options. RPC isn't inherently insecure: Developers can write secure code using RPC, and there are alternatives. You can defend your networks against known RPC exploits.\nSince almost every system runs RPC services, it's an obvious target.\nRPC reduces the complexity of network programming by handling communication over UDP. The programmer writes client/server code with identical parameters and leaves the networking to the protocol, allowing the protocol to span multiple OSes and networks.\nMost RPC vulnerabilities are simply the result of sloppy coding. Poor error-checking leaves an app open to buffer-overflow exploits.\nThe consequences are familiar. In 2003, flaws in the RPC interface with DCOM opened Windows 2000/XP/2003 to buffer-overflow exploits and re-sulted in the LoveSan and Blaster worms.\nLinux had a similar vulnerability in its rpc.statd and glibc libraries, which led to the Ramen worm in 2000 and the Lion and Adore worms in 2001.\nFor the Defense\nFaulty code isn't likely to go away. Given this fact of life, rigorously apply these defensive strategies:\nPatch, patch, patch. Exploits continue to be created, and unpatched systems are the easiest to compromise.\nDeploy application firewalls. Traditional layer 3 and 4 firewalls are ineffective against RPC exploits because RPCs don't use a specific port. They use a port mapper--usually running on port 135 on Windows and port 111 on Unix--to tell the client program which port RPC is running. Blocking ports 135 and 111 would deny all RPC traffic, while blocking all UDP traffic would disable DNS. Firewalls that filter layer 7 traffic can detect application-based attacks, such as RPC exploits.\nDetect and prevent. Blocking suspicious traffic at the firewall isn't always possible. Craft custom IDS signatures that can trap these anomalous packets; the trick is to analyze them and look for their uniqueness. Be precise with the syntax so legitimate traffic doesn't trigger a false alarm.\nYour signatures need to be updated in a timely manner. You may have used an application for months or years without incident, but new vulnerabilities come to light all the time.\nIf Internet-facing apps are your company's lifeblood, invest in services to bulletproof your code.\nAlternatives to RPC are complex and require significant investment of time and resources:\nRPC over HTTPS forces authentication and \"hides\" RPC within a tunneling mechanism.\nObject Request Broker (ORB) is middleware that manages communication and data exchange be-tween distributed objects from different vendors. It's more secure than RPC because object communication details are hidden.\nMessage-Oriented Middleware (MOM) is a client/server infrastructure that allows applications to be distributed across heterogeneous platforms. It simplifies development by insulating the application developer from the details of the various OS and network interfaces. Application programming interfaces that extend across diverse platforms and networks are typically provided by the MOM.\nThis was first published in May 2005", "label": 1}
{"text": "Because our forum is being polluted with bad information.\nMyth #1: When you hash something, you get a unique result that no other file or string or password can have.\nWroonnnnggggg. Let's attack this one with simple logic. Let's say your hash is 32 characters long. Now let's say you hash every possible 33-character string there is. You will have strings with matching hashes, or \"collisions\". It's simple logic -- there are far more combinations of 33-character strings than there are of 32-character strings, because for every 32-character string that exists, you can tack on every possible character to the end and make a bunch of 33-character strings. So, just making up some example numbers, if there are 90,000 33-character strings and 20,000 32-character strings, some of those 33'ers MUST have the exactly the same 32-character hash. The goal of hashing algorithms is to make collisions as rare as possible, but it is impossible to write to a hashing algorithm that has no collisions.\nMyth #2: MD5 is insecure.\nWroonnnnggggg. MD5 is a less sophisticated (and therefore much faster) hashing algorithm than, say, SHA-256, but it is not insecure. An insecure hash would mean that the hash could be reversed -- or rather, that you could take a hash, and, using that and having no other information, produce a string that has the same hash. You cannot do that with MD5. In fact, the closest anyone has gotten to this is changing an existing, large file in a way that doesn't change the hash it already has. No one in the history of humankind has been able to produce a \"reverse\" MD5. This myth comes from the fact that MD5 is a common target of password-cracking attacks, which leads to our next myth...\nMyth #3: MD5 is less secure for password hashing than other algorithms like SHA.\nWroonnnnggggg. There are exactly three attacks that can be used to find out someone's password if you have the hash of that password:\n- Hash database lookup. You go to a super-large online database of short words and their hashes, plug in the hash, and see if a short word with that hash has ever been submitted before. A common prevention for this is to salt your passwords.\n- Brute force. You run through all the words of a dictionary, hashing each one, to see if the hash matches what you have on hand. If that doesn't work, you just start hashing every possible combination of 5, 6, 7, or 8-character words to find a match. This takes for effing ever and rarely produces a result, and can easily be prevented with a salt.\n- Rainbow tables. This is a method of hashing and re-hashing the data you have to find similarities in the hashes of other words, which can eventually lead to finding the password. Salts have minimal effect on these attacks.\nMyth #4: Sophisticated, super-long hashes like SHA-256 are harder to attack because they're longer.\nWroonnnnggggg. Let's face it: the biggest threat to hash cracking attacks is the rainbow tables method. It is by far the most efficient tradeoff between processing time and storage space, and often times can find a password in under a minute if you have enough chains. But rainbow tables are not magical. That's the impression most people have because it's easier to believe that than to learn how they work, but seriously, the rainbow table attack isn't hard to understand. I suggest reading up on it if you have a spare 15 minutes.\nSo if you know how rainbow tables work, you know that the biggest weakness they have is hash collisions -- which, you'll remember from above, means more than one string that produces the same hash. So password hashing security is a tradeoff: You want an algorithm that has reasonably few collisions so that no two passwords are likely to generate the same hash, but you also want one that produces enough collisions to potentially send a rainbow table into an endless loop that can't be cracked. SHA-256 is horrible for this, because it's too good a hashing algorithm. You're extremely unlikely to get any collisions at all when using SHA-256 for a password (even a salted one), so using that makes your passwords -- salted or not -- easier to crack. SHA-256 is awesome for hashing large files. Not so awesome for passwords.\nAt the same time, though, you don't want to use a measly 32 or 48-bit hash, because collisions are extremely likely with those. You want to find a happy medium, which is around 128 bits. What's a fast 128-bit hashing algorithm? MD5.\nMyth #5: SHA-1 is still better to use than MD5 because MD5 is more likely to be cracked.\nWroonnnnggggg. Again, you're being lulled into a false sense of security. Not only is SHA-1 160 bits (so you'll still get collisions, but fewer than MD5), hash databases and rainbow tables are just as easy and well-developed for SHA-1 as they are for MD5. This myth is one that is spread far and wide among developers who have never taken the time to research the facts. The fact that SHA produces a longer hash has little-to-no impact on the ability to store them in a database or produce rainbow chains with them. All it takes is a tiny bit more storage space, and that's true for any hashing algorithm in the world, whether it's 8 bits or 8 thousand bits. The length only helps for reducing collisions, which, past around 128 bits, doesn't help at all when you're hashing passwords rather than large files.\nMyth #6: Hashing with multiple algorithms is more secure!\nWroonnnnggggg. No. Just no. Come on, now you're just pulling stuff out of your ass. I've seen this before: sha1(md5(\"Password\")). That is ridiculous. You're feeding 128 bits into 160 bits, which is an easy easy crack. You can't make hashes more-hashy. You might add one more step to the process for someone cracking it, but it's going to end up with the same result. Don't guess at what's more secure, know what's more secure.\nMyth #7: Using a global salt AND a user salt is more secure than using just a user salt.\nThere was a thread recently in which folks supported the idea of using a global salt in addition to a user salt, and I dismissed it as pointless. I was met with some fierce opposition, claiming that it makes passwords more secure if a hacker should be able to steal a copy of your database but not your source code. This is true, however the amount of extra security this offers is minimal at best. Here's why:\nOut of our list of attacks on hashes that I wrote out earlier, there is only one attack that's made more difficult to crack by using a global salt, and that's the brute force attack -- the one that's already almost impossible to use successfully to begin with. Adding a global salt only makes this more-impossible-than-nearly-impossible. So I'll admit there is SOME benefit, but with the most common and most successful attack being rainbow tables, folks would be crazy to try a brute force attack anyway. They'd just rainbow table it, and the global salt won't make your password any more secure than a properly long user salt would. And hey, let's face it: If someone's able to steal a copy of your database, chances are that they can nab a copy of your source without too much trouble too.\nIf you're looking to protect against the case where someone gets a copy of your database, a far, far, far more effective solution would be to use symmetric encryption on your hashes. Choose a fast, simple symmetric encryption algorithm (RC4, Blowfish... your call), generate a key and store it somewhere in a configuration file. Use that to encrypt all your salted password hashes in the database. Then, when you pull them from the database, just decrypt them with that key when you read them. Now you have a hash that can't even be attacked with a rainbow table if someone happens to gain unauthorized access to either your database or your account on the server, and this is still effective if you distribute your software to the public. MUCH more effective than using a global salt.\nSo what are the best practices for password hashing?\nThe only two, good options for password hashing are MD5 and SHA-1, and you should let the language you're programming in dictate which one you use. For PHP (and most languages), MD5 is faster than SHA-1, so it's the better option. The key to making it secure is using a salt of the appropriate length. The sweet spot for securely storing a password that isn't susceptible to dictionary or brute force attacks AND is relatively safe from rainbow table attacks is to feed twice the number of bits of a hash into a new hash. So, for example, using MD5, you'd want to hash two MD5s. You can generate a 128-bit salt for this (which, for a lot of users, can take up some significant storage space), or you can generate a salt that's just a handful of characters long and hash that. My favorite method is this:\n$finalHash = md5(md5($salt) . md5($password))\nWhether you want to put the symmetric encryption layer on top of that is entirely up to you\nSo please, for the love of all that is holy, stop teaching these myths to other people! The world's programmers thank you :D", "label": 1}
{"text": "A perennial issue in Canadian privacy law is what to do about the USA Patriot Act. Just when we think we have things reasonably sorted out, the issues pop up again in a new context. This time it is cloud computing.\nWhat’s the USA Patriot Act?\nThe Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act (usually referred to as the “USA Patriot Act” or just the “Patriot Act”) is US legislation that was passed following the September 11, 2001 attacks on the World Trade Centre in New York City. Among other things, the Patriot Act made it easier for US law enforcement officials to intercept electronic communications and business records. One of the controversial measures was that officials were granted the power to issue a National Security Letter to electronic communication service providers requiring them to hand over information without informing the affected parties (in some cases without any judicial oversight).\nFor the purposes of this discussion of cloud computing, however, one of the most important provisions is section 215, which deals with access to business records. Section 215 repealed and re-enacted provisions of the Foreign Intelligence Surveillance Act (USA). Pursuant to section 215 of the Patriot Act, the FBI may apply to a federal judge for an order requiring the production of any tangible things (including books, records, papers, documents, and other items) for an investigation to protect against international terrorism or clandestine intelligence activities. US commentators agree that this definition covers electronic business records.\nWhat’s cloud computing?\nIn its most complete form, cloud computing involves outsourcing applications (e.g. email, customer relationship management, and accounting software), platforms (e.g. database architecture) and infrastructure (e.g. servers). All of these IT functions are offered as a service to organizations either independently or as a package. An organization’s data (e.g. its emails) may be stored in segregated servers or intermingled with the data of other organizations and segregated through the functionality of the service provider’s information technology. The organization accesses its data through Internet portals.\nWhere’s the Cloud?\nThe cloud isn’t in the sky. Data sent over the Internet in a cloud computing arrangement may be (and often will be) stored outside of Canada and may be intermingled with data from other organizations. In many cases, the cloud computing service provider may subcontract the storage of data to one or more organizations operating data centres. If these data centres are in the US, well, therein lies the rub. The data is going to be subject to the laws of the United States, including the Patriot Act. Actually, if the data is even accessible from the US or by an organization subject to the jurisdiction of the US, the data is likely to be subject to the laws of the United States.\nOkay, so the USA Patriot Act may apply, do I have a Canadian privacy problem?\nBut organizations aren’t prohibited from using US-based cloud services, if they are only operating in the private sector. Federal and provincial private sector privacy legislation does not prohibit the transfer of personal information to an organization in another jurisdiction for processing and storage, provided that:\n- The transfer does not entitle the receiving the personal information to use that information for purposes other than those for which individuals expressly or impliedly consented.\n- The transferring organization remains accountable for the protection of the personal information that has been transferred.\n- The organization receiving the personal information provides a comparable level of data security as would be required under Canadian law and the terms on which the collecting organization collected the information.\n- Disclosure is made to individuals. As a general rule, this disclosure to individuals should include notice that (1) their personal information will be transferred outside of Canada for processing and storage, (2) their personal information will be subject to the laws of the foreign jurisdiction and (3) the laws of the foreign jurisdiction may be different (and less protective) than those of Canada.\nThe transferring organizations will wish to consider obtaining meaningful contractual commitments to administrative, technological and physical security protections from the organization to which the personal information is being transferred. The transferring organizations will also wish to consider audit or other rights that would permit ongoing diligence of these security protections as well as the use being made of the personal information.\nThe Patriot Act provisions do not (on their own) mean that personal information will not be subject to a comparable level of security. An interesting survey and comparison of surveillance laws in Canada, the US, the UK and France was conducted by the Office of the Privacy Commissioner of Canada in 2009, which remains an important reference. Since 1990, Canada and the US have had Treaty on Mutual Legal Assistance in Criminal Matters in which each country has agreed to assist the other with the investigation, including seizure of records, of criminal activity. The Canadian Security and Intelligence Service Act (Canada) provides for secret warrants for the interception and seizure of, among other things, electronic data. The National Defence Act (Canada) permits the Minister of Defence (without judicial supervision) to authorize the Canadian Communications Security Establishment to intercept communications relating to foreign entities under certain circumstances. In addition, the Criminal Code (Canada) permits seizures of electronic data. The combination of this legislation has led the Office of the Privacy Commissioner of Canada to conclude in three decisions (here , here, and here) not only that Canadians are at risk of personal information being seized by Canadian governmental authorities (including without the knowledge of the target) but also that there is already a risk of that information being shared with US authorities. (This is not to say that reasonable people cannot still differ as to whether they wish to have their personal information stored outside of Canada.)\nBut if you are a public sector organization or contracting with a public sector organization in British Columbia or Nova Scotia (and probably Alberta), you need legal advice. Cloud-based services get a bit trickier when dealing with public sector organizations. British Columbia, Nova Scotia and Alberta each have legislation the prohibits or, in the case of Alberta, potentially prohibits the storage of data outside of Canada. In these cases, organizations would be prudent to obtain legal advice.", "label": 1}
{"text": "At the recent Chaos Communications Congress, Steven J. Murdoch, a researcher in the security group at the University of Cambridge, discussed how clock skew can be used to facilitate a digital attack against anonymity networks. Clock skew, the tendency for a computer’s clock to become less precise when heated, can reduce the efficacy of anonymizers, such as the Electronic Frontier Foundation’s Tor network.\nMurdoch explains, “When a crystal is manufactured, it has a clock skew, and it’s different for each crystal (throughout its) lifetime.” Tadayoshi Kohno, now an assistant professor in the Department of Computer Science and Engineering at the University of Washington, has shown that computers on the internet can be identified by their clock skews, by tracking the timestamps of each machine’s transmitted packets. Clock skew, however, yields up to only 64 separate identifiers, making it an incomplete confirmation tool.\nClock skew has long been a concern of engineers of synchronous network, as it causes the clock signal for system components to arrive at different times; however, Murdoch is the first to take advantage of this hardware fallibility. Murdoch attacked The Onion Router, Tor, an anonymizing network that allows unregistered users to access web sites without identifying themselves. Tor network encrypts web traffic, through multiple servers, creating layers of anonymizing packets, none of which may be decrypted by another node on the Tor network.\nMurdoch tested his digital attack by setting up a Tor network server and causing the server to warm up by executing intensive processes. The increase in system temperature caused minor changes in clock skew.\nTo understand how clock skew can be used to affect the security of anonymity networks, such as Tor, I think that we must first understand how Tor works. I suggest reviewing the audio recording or transcript of Steve Gibson and Leo Laporte’s Security Now! podcast. Episode 70 of this podcast explains in clear, lucid detail how the Tor network creates anonymity for web users.\nKohno’s theoretical work and Murdoch’s proof of concept attack does not bode well for network security systems, including the GPS and other national digital assets that require precise timings to function properly.\nCall for Comments\nWhat do you think? Leave your comments below.", "label": 1}
{"text": "Cell phones have come a long way in the last twenty years. Zach Morris’ brick from Saved By The Bell was a strictly utilitarian device, built for no reason other than making and answering phone calls. Today’s iPhones and Droids, by contrast, are full-fledged computers, capable of virtually anything a laptop or desktop PC can do. In many ways this is a step forward, but our phones now also share one bad similarity with our computers: exposure to security risks.\nHere are some of the most serious to watch out for:\nPhishing has been a major security threat to laptop and desktop users for at least the last decade. It typically works in the following manner: you receive an official-looking email from someone claiming to represent a major, well-known institution (such as the bank you use.) In this email, you are asked to provide your account information for a “security check” or other seemingly legitimate reason. You may even be directed to a website that looks very much like the real thing. Unfortunately, the entire process was nothing more than a cleverly crafted ruse designed to trick you into giving scammers your account details.\nThese same scams are now targeting mobile phone users as well. A 2010 article in the Wall Street Journal said that “the next generation of “phishing” scams, focused on mobile banking, has begun, and it has the potential to do much more damage than earlier versions.” Rather than tricking you into visiting a fraudulent website, scammers are now populating the web with fraudulent banking apps that carry out the same purpose.\nEvery few years, a worm virus slithers its way onto millions of computers around the world, inflicting financial damage and whipping the tech world into a panic until it finally dies out. Melissa, SoBig, ILoveYou and MSBlast were some of the bigger culprits of the last decade. Our phones have long been immune to these gigantic hassles but no longer. Inc.com tells the story of one nasty mobile worm that hit Asia and parts of the U.S as well:\n“The Sexy View worm, so dubbed because it sends a text inviting users to look at sexy pictures, targets some Nokia phones. If a hapless user tries to look at the pictures, it will take over the phone much the way a botnet takes over a computer, and then send itself to the entire contact list.”\nCloudmark CTO told Inc.com that it’s only a matter of time before mobile worms such as these become the widespread norm in the United States. “They [smartphones] can have a 1 gigahertz processor and hundreds of megabytes of RAM. So all the same types of attacks that could happen to a computer can happen to a smart phone.”\nMany of today’s smartphones have built-in GPS capabilities, allowing users to transmit their exact geographic coordinates to anyone they wish. Though this is certainly a handy feature to have, it carries the potential for misuse. Last February, ScienceDaily.com reported that because smartphones “run the same class of operating systems as desktop and laptop computers” all sorts of abuses are now possible – including GPS hijacking that lets unscrupulous people track the travels of a phone’s owner.\nToday, the web is filled with mobile apps that let you secretively “keep track of your untrustworthy boyfriend” or “always know where your wife is.” These same tools (and others) can just as easily be used by criminals or hackers.\nUnknown Privacy Settings\nThere is also a substantial security risk connected with not being aware of your phone’s privacy settings. Take Facebook’s iPhone app, for instance. Unbeknownst to many iPhone owners, this app will broadcast your exact location unless you deliberately turn that feature off. The same is true of any number of other apps, including FourSquare and AroundMe. True, this is not necessarily a risk in and of itself – but it could be. Someone determined to intercept data transmissions from your phone could very easily determine where you are if these features are left on.\nThat’s why it’s imperative for mobile phone users to be fully aware of location-based services and the risks they pose.\nIn 1999, having your cell phone stolen was an annoying inconvenience, but hardly a security risk. After all, what was the thief really getting his hands on: your contact list and (maybe) a few personal text messages? Surely nothing to be concerned about. Today, the theft of your mobile phone could be downright catastrophic. Depending on which apps you use, the thief could now have total, unrestricted access to your emails, bank accounts and investment portfolio.\nIn short, you could be in for a whole world of trouble. Luckily, most of these risks can be prevented. As Inc.com explains, the simple act of setting an access code on your phone that wipes your data after a certain number of wrong tries goes a long way.\n“SMS Of Death”\nOn December 30, 2010, CNN Tech discussed another serious mobile security risk: the “SMS of Death” Here’s how it works:\n“…many popular feature phones operating on GSM networks (the world’s most popular mobile network standard) are vulnerable to remote-controlled disabling or damage via the “SMS of Death.” This is according to a presentation by German researchers at this week’s Chaos Computer Club Congress in Berlin.”\nIn short, your entire SIM card can be corrupted just by receiving an SMS text message with a “damaging payload” in it. When this happens, your phone gets completely disconnected from the network. Worst of all, this particular security threat mostly targets lower-end phones, not the expensive smartphones. Researchers at the German conference “performed their tricks on handsets made by Nokia, LG, Samsung, Motorola, Sony Ericsson, and Micromax, a popular Indian cell-phone manufacturer” according to TechnologyReview.com.", "label": 1}
{"text": "Do not give sensitive information to anyone unless you are sure that they are indeed who they claim to be and that they should have access to the information.\nWhat is a social engineering attack?\nIn a social engineering attack, an attacker uses human interaction (social skills) to obtain or compromise information about an organization or its computer systems. An attacker may seem unassuming and respectable, possibly claiming to be a new employee, repair person, or researcher and even offering credentials to support that identity. However, by asking questions, he or she may be able to piece together enough information to infiltrate an organization's network. If an attacker is not able to gather enough information from one source, he or she may contact another source within the same organization and rely on the information from the first source to add to his or her credibility.\nWhat is a phishing attack?\nPhishing is a form of social engineering. Phishing attacks use email or malicious websites to solicit personal information by posing as a trustworthy organization. For example, an attacker may send email seemingly from a reputable credit card company or financial institution that requests account information, often suggesting that there is a problem. When users respond with the requested information, attackers can use it to gain access to the accounts.\nPhishing attacks may also appear to come from other types of organizations, such as charities. Attackers often take advantage of current events and certain times of the year, such as\n- natural disasters (e.g., Hurricane Katrina, Indonesian tsunami)\n- epidemics and health scares (e.g., H1N1)\n- economic concerns (e.g., IRS scams)\n- major political elections\nHow do you avoid being a victim?\n- Be suspicious of unsolicited phone calls, visits, or email messages from individuals asking about employees or other internal information. If an unknown individual claims to be from a legitimate organization, try to verify his or her identity directly with the company.\n- Do not provide personal information or information about your organization, including its structure or networks, unless you are certain of a person's authority to have the information.\n- Do not reveal personal or financial information in email, and do not respond to email solicitations for this information. This includes following links sent in email.\n- Don't send sensitive information over the Internet before checking a website's security (see Protecting Your Privacyfor more information).\n- Pay attention to the URL of a website. Malicious websites may look identical to a legitimate site, but the URL may use a variation in spelling or a different domain (e.g., .com vs. .net).\n- If you are unsure whether an email request is legitimate, try to verify it by contacting the company directly. Do not use contact information provided on a website connected to the request; instead, check previous statements for contact information. Information about known phishing attacks is also available online from groups such as the Anti-Phishing Working Group (http://www.antiphishing.org).\n- Install and maintain anti-virus software, firewalls, and email filters to reduce some of this traffic (see Understanding Firewalls, Understanding Anti-Virus Software, and Reducing Spam for more information).\n- Take advantage of any anti-phishing features offered by your email client and web browser.\nWhat do you do if you think you are a victim?\n- If you believe you might have revealed sensitive information about your organization, report it to the appropriate people within the organization, including network administrators. They can be alert for any suspicious or unusual activity.\n- If you believe your financial accounts may be compromised, contact your financial institution immediately and close any accounts that may have been compromised. Watch for any unexplainable charges to your account.\n- Immediately change any passwords you might have revealed. If you used the same password for multiple resources, make sure to change it for each account, and do not use that password in the future.\n- Watch for other signs of identity theft (see Preventing and Responding to Identity Theft for more information).\n- Consider reporting the attack to the police, and file a report with the Federal Trade Commission (http://www.ftc.gov/).\nAuthor: Mindi McDowell", "label": 1}
{"text": "- Use WinDbg for kernel debugging\n- Understand basic inner working of disk driver\n- Understand virtual hidden drive creation\n- Reverse engineering Max++ driver infection technique\n- Operating Systems\n- Assembly Language\n- Operating System Security\nThis tutorial continues the analysis presented in Tutorial 20. We reveal how Max++ uses a modified disk driver to handle I/O requests on the disk it created (its name is \"\\\\?\\C2CAD...\"). Recall that in section 4.2.3 we showed you Max++ creates a new IO device and hooks it to the malicious driver object, so that whenever an IO request is raised on this device the request will be forwarded to driver object 8112d550, as shown below. Pay attention to the value of MajorFunction (0xfae36bde), this is where IO requests are handled. Obtaining the module base address, we can easily calculate its offset: _+2BDE.\nkd> dt _DRIVER_OBJECT 8112d550\n+0x000 Type : 0n4\n+0x02c DriverInit : 0xfae4772b long +0\n+0x030 DriverStartIo : (null)\n+0x034 DriverUnload : (null)\n+0x038 MajorFunction :  0xfae56bde long +0\nTo replicate the experiments of this tutorial, you have to follow the instructions in Section 2 of Tutorial 20. In this tutorial, we perform analysis on the code of raspppoe.sys from _+2BDE (0x10002BDE)\n2. Lab Configuration\nIn general we will use the instructions of Section 2 of Tutorial 20. In the following we just remind you of several important steps in the configuration:\n(1) You need a separate image named \"Win_Notes\" to record and comment the code. You don't really need to run the malware on this instance, but just to record all your observations using the .udd file. To do this, you have to modify the control flow of IMM so that it does not crash on .sys files. See Section 2 of Tutorial 20 for details. Jump to 0x10002BDE to start the analysis.\n(2) The second \"Win_DEBUG\" image has to be run in the DEBUG mode and there should be a WinDbg hooked from the host system using COM part -- so here, we are doing kernel debugging.\n(3) Set a breakpoint \"bu _+2BDE\" in WinDbg to intercept the driver entry function.\n3. Background: Windows Driver Development\nOpferman provides an excellent introduction and sample code in . In the following, we summarize of the major points here.\n(1) Each driver has a driver entry function, its prototype is shown below:\nNTSTATUS DriverEntry(PDRIVER_OBJECT pDrv, PUNICODE_STRING reg)\nHere pDrv is a pointer to _DRIVER_OBJECT, and reg is a string that represents the registry entry where the driver could store information.\nAs we shown earlier in Tutorial 20, the DriverEntry function is located at _+372b.\n(2) Each driver may have a collection of 28 functions to handle different types of I/O requests (such as close handle, read, write etc.) The IRP Function code can be found at  (typical ones are IRP_MR_CREATE and IRP_MR_READ).\nYou might wonder, do we have to set breakpoints on all of the 28 functions? The answer is YES and NO. Look at the following dump (combined with the dump in section 1).\nkd> dd 8112d550\n8112d550 00a80004 81210030 00000002 fae54000\n8112d560 00008000 ffbd7d80 8112d5f8 001a001a\n8112d570 e1389208 8068fa90 00000000 fae5772b\n8112d580 00000000 00000000 fae56bde fae56bde\n8112d590 fae56bde fae56bde fae56bde fae56bde\n8112d5a0 fae56bde fae56bde fae56bde fae56bde\n8112d5b0 fae56bde fae56bde fae56bde fae56bde\n8112d5c0 fae56bde fae56bde fae56bde fae56bde\nAt offset 0x38 of the driver object (the starting of the major function array), all IRP handlers are set to one single function _+2BDE! The malware author tries to be lazy here, and it saves us a lot of job too. We can just concentrate on _+2BDE then!\nNow before we move on, we should know that each IRP handler function has the following prototype:\nNTSTATUS Handler(PDEVICE_OBJECT pDevice, PIRP pIRP)\nHere, the first parameter is a device object, and the second parameter represents the IRP request to handle.\nWhen we hit the _+2BDE handler, we could easily find out the contents of the two input parameters (device located at 8112d550 and irp located at 00070000) as below:\nkd> dd esp\nfafb73fc 81210030 8112d550 00070000 81210030\nfafb740c fafb7460 804e37f7 81210030 ffbbe7e8\nfafb741c 00000000 fb07c7a9 81210030 c000014f\nfafb742c 00000000 00000000 c3a408e0 00000000\nfafb743c 00000001 00000000 804e2490 fa047501\nfafb744c 00000000 fafb7450 fafb7450 804fb1a9\nfafb745c 00000000 fafb748c fb07ce80 81210030\nfafb746c fafb7484 ffb6fe10 81210030 ffb6fe10\nkd> dt _DEVICE_OBJECT 8112d550\n+0x000 Type : 0n4\n+0x002 Size : 0xa8\n+0x004 ReferenceCount : 0n-2128543696\n+0x008 DriverObject : 0x00000002 _DRIVER_OBJECT\n+0x00c NextDevice : 0xfae54000 _DEVICE_OBJECT\nkd> dt _IRP 00070000\n+0x000 Type : 0n193\n+0x002 Size : 0\n+0x004 MdlAddress : 0x00000100 _MDL\n4. Anatomy of Infected Disk Driver\nFigure 1 shows you the first part of the IRP handler function at _+2BDE.\n|Figure 1. Infected Disk Driver|\nAs shown in Figure 1, the control flow is a very simple decision procedure. First it takes out the PDEVICE_OBJECT pointer from EBP+8 (1st parameter) and compare it with a global variable stored at 100061B0 (see highlighted area). Clearly, the global variables stores the newly created infected device (for \\??\\C2CAD...). If it is not a request to \\??\\C2CAD, the flow jumps to 10002BFD (second highlighted area), which calls PoCallDriver to relay the request to low level (real) drivers to do the work; otherwise it calls a self-defined function handleIRPForVirtualVolume which performs the real operation to simulate the virtual disk.\nChallenge 1. Analyze the logic between 10002BFD and 10002C25 (highlighted area in Figure 1). Especially, explain the instructions at 0x10002C16 and 0x10002C19.\n5. Simulating the Virtual Disk Operations\nNow we will analyze the function handleIRPForVirtualVolume. It is located at _+292A. In this case, you need to set a breakpoint using \"bp _+292A\" in WinDbg. Figure 2 shows its major function body. Notice that you can easily infer from the context that EBX is an input parameter of the function, EBX points to the IRP request right now!\n|Figure 2. Function body of handleIRPForVirtualVolum|\nNow comes the interesting part. Look at Figure 2, at 0x1000293C EAX now has the \"MajorFunction\" of _IO_STACK_LOCATION (the value is one of the IRP_MJ_xxx types). Then there is a big switch case statement (see the highlighted area in Figure 2), which redirects the control flow to handle each of the different IRP requests such as READ, WRITE, etc.\nChallenge 2. Argue that the statement about \"0x1000293C EAX now has the \"MajorFunction\" (the value is one of the IRP_MJ_xxx types\" is true. You may need to find out the definition of IRP_MJ_xyz values.\nAs an example of how Max++ simulates the disk volume operation, we show how it handles the IRP_MJ_READ request. Figure 3 shows the handler code.\n|Figure 3. Simulate the Disk Operation on File|\nkd> dt _IO_STACK_LOCATION ff9c7fd8\n+0x000 MajorFunction : 0x3 ''\n+0x001 MinorFunction : 0 ''\n+0x002 Flags : 0x2 ''\n+0x003 Control : 0 ''\n+0x004 Parameters : __unnamed\n+0x014 DeviceObject : 0xffb746d8 _DEVICE_OBJECT\n+0x018 FileObject : (null)\n+0x01c CompletionRoutine : (null)\n+0x020 Context : (null)\nNow look at the first instruction LEA EAX, [ESI-24] in Figure 3. The purpose here is to move 0x24 bytes away (note the direction of stack) and the size of _IO_STACK_LOCATION (0x24). So EAX is now pointing to a new _IO_STACK_LOCATION instance. The next couple of instructions copy the first 9 words of the existing _IO_STACK_LOCATION to the new.\nThen at 0x10002B10 (look at the highlighted area of Figure 3), it assigns the value of ECX (from global variable at DS:[1000614C]) to offset 0x18 of the new _IO_STACK_LOCATION. Notice that 0x18 is the FileObject attribute (see above dump of _IO_STACK_LOCATION!). The following is the dump of the File Object pointed by ECX:\nkd> dt _FILE_OBJECT 811b25d0\n+0x000 Type : 0n5\n+0x002 Size : 0n112\n+0x02c Flags : 0x40040\n+0x030 FileName : _UNICODE_STRING \"\\WINDOWS\\system32\\config\\yknueenf.sav\"\n+0x038 CurrentByteOffset : _LARGE_INTEGER 0x0\nNow it's pretty clear that the READ operation on the disk volume is actually achieved by CONSTRUCTING A NEW _IO_STACK_LOCATION task on the \"*.sav\" file created by Max++ earlier!\nThe last interesting point is at 0x10002B17: Max++ hooks up a function for the CompleteRoutine (offset 0x1c of _IO_STACK_LOCATION), the intention is pretty clear: the data stored on the *.sav file is encrypted, and Max++ now decodes it when reading it out.\nWe've finished a very challenging and interesting analysis of a portion of the infected disk driver. Now it's your job to finish the rest:\nChallenge 3. What happens when FormatEx operation is performed on the virtual disk volume?\nChallenge 4. Analyze all the other IRP_MJ_ operations supported by the infected disk driver (hint: this could take considerable efforts).\n T. Opferman, \"Driver Development Introduction Part I\", available at http://codeproject.com\n MSDN, \"IRP Function Code\", available at", "label": 1}
{"text": "Tuesday, January 26, 2010 at 10:00 AM\nWebmaster Level: All\nIf you allow users to publish content on your website, from leaving comments to creating user profiles, you’ll likely see spammers attempt to take advantage of these mechanisms to generate traffic to their own sites. Having this spammy content on your site isn't fun for anyone. Users may be subjected to annoying advertisements directing them to low-quality or dangerous sites containing scams or malware. And you as a webmaster may be hosting content that violates a search engine's quality guidelines, which can harm your site's standing in search results.\nThere are ways to handle this abuse, such as moderating comments and reviewing new user accounts, but there is often so much spam created that it can become impossible to keep up with. Spam can easily get to this unmanageable level because most spam isn’t created manually by a human spammer. Instead, spammers use computer programs called “bots” to automatically fill out web forms to create spam, and these bots can generate spam much faster than a human can review it.\nTo level the playing field, you can take steps to make sure that only humans can interact with potentially spammable features of your website. One way to determine which of your visitors are human is by using a CAPTCHA , which stands for \"completely automated public Turing test to tell computers and humans apart.\" A typical CAPTCHA contains an image of distorted letters which humans can read, but are not easily understood by computers. Here's an example:\nYou can easily take advantage of this technology on your own site by using reCAPTCHA, a free service owned by Google. One unique aspect of reCAPTCHA is that data collected from the service is used to improve the process of scanning text, such as from books or newspapers. By using reCAPTCHA, you're not only protecting your site from spammers; you're helping to digitize the world's books.\nLuis Von Ahn, one reCAPTCHA's co-founders, gives more details about how the service works in the video below:", "label": 1}
{"text": "By Mark Huffman\n— The Internet has become more sophisticated over the years and so have the threats to users. Today, hackers are doing more than sending out infected spam emails -- they're exploiting the system's vulnerabilities to threaten consumers.\nExperts at Georgia Tech -- the Georgia Tech Information Security Center (GTISC) and the Georgia Tech Research Institute (GTRI) -- constantly work to stay one step ahead of the hackers. They say the coming year will pose some steep challenges.\nHere are some threats they say consumers should be aware of:\nThe ability to create vast, virtual computing resources will further persuade cyber criminals to look for ways to co-opt cloud-based infrastructure for their own ends. For example, attackers can use stolen credit card information to purchase cloud computing resources and create dangerous clusters of temporary virtual attack systems.\nSearch history poisoning\nCyber criminals will continue to manipulate search engine algorithms and other automated mechanisms that control what information you see when you do a search. Moving beyond typical search-engine poisoning, researchers believe that manipulating users’ search histories may be a next step in ways that attackers use legitimate resources for illegitimate gains.\nMobile browser and mobile wallet vulnerabilities\nThis, unfortunately, may be a fertile growth area for scammers. While only a very small number of U.S. mobile devices show signs of infection, the explosive proliferation of smartphones will continue to tempt attackers in exploiting user and technology-based vulnerabilities, particularly with the browser function and digital wallet apps.\nUnfortunately, your anti-virus software may prove less effective against emerging threats. The developers of malicious software will employ various methods to hinder malware detection, such as hardening their software with techniques similar to those employed in Digital Rights Management (DRM), and exploiting the wealth of new interfaces and novel features on mobile devices.\n\"Our adversaries, whether motivated by monetary gain, political/social ideology or otherwise, know no boundaries, making cyber security a global issue,” said Bo Rotoloni, director of GTRI’s Cyber Technology and Information Security Laboratory. “Our best defense on the growing cyber warfront is found in cooperative education and awareness, best-of-breed tools and robust policy developed collaboratively by industry, academia and government.”\nThe bottom line, say the Georgia Tech experts, is users must keep their guard up in the coming year.\nStory provided by ConsumerAffairs.", "label": 1}
{"text": "New answers tagged authorization\nThe 802.1x protocol is built on multiple steps. The supplicant (entity who wants to connect) identify the Access point by its SSID as it would do for any wireless network. Be noted that 802.1x also work on traditional wired networks. For what we know, this can be any hardware that provides this SSID, it can be changed, maybe spoofed. When you are connected ...\nTop 50 recent answers are included", "label": 1}
{"text": "Unencrypted WAP means all traffic over the wireless link can be read by anyone.\nWith an encrypted WAP, all traffic is encrypted on the radio link, but anyone with access to the WAP's WAN port can read the traffic even without the encryption key. With the WAP's key, for WiFi, you can read all the traffic on the radio link.\nThe secure way to use a shared wireless AP is by using end-to-end encryption; your traffic is encrypted before it is sent over the radio link and is not decrypted until it arrives at the destination. So, even with the WAP key or access to the WAP's WAN port, end-to-end encrypted traffic is safe.\nA common way to gain end-to-end encryption is to use an encrypted VPN. The traffic using the VPN between your machine and the VPN endpoint is encrypted, and so safe.\nOne complication. A VPN can use a technique called split-tunneling, which means that traffic not destined for the network at the VPN's other side doesn't use the VPN. And traffic that doesn't use the VPN isn't encrypted by the VPN, so if you use split tunneling, traffic not addressed to the other end of the VPN is not protected by the VPN.", "label": 1}
{"text": "Installing an SSL / TLS certificate on Windows Server 2008\nIn order to secure web traffic, SSL (Secure Socket Layer) is generally used as a first line encryption defense (you know, it makes the little padlock icon on your browser). SSL is also known as TLS (Transport Layer Security) which is kind of its newer name. Normally you access a site by navigating your browser to some place like: http://www.devtoolshed.com\nThis kind of communication between your browser and the web server sends information \"in the clear\" meaning that an attacker can read this traffic and if there is anything private like a credit card number, this can also be seen by an attacker. The \"http\" in the browser URL informs you that it is NOT secured by SSL.\nTherefore when sensitive information needs to be passed between your browser and a web server, many times SSL is used to encrypt (basic make the traffic into gibberish characters) that only the server and the browser have the ability to decrypt (decryption turns the gibberish back into readable information). When running under SSL, instead of using the \"http\" in front of your browser address, you will use \"https\" (the \"s\" stands for \"secure\"). For example, the URL above would change to: https://www.devtoolshed.com\nHow SSL Works\nThe way SSL works is somewhat complicated but at a high level (admittedly, this has been GREATLY simplified to make it easy for non-technical readers to understand so don’t hold it against me if there are things here that are not exact), you can understand it this way. Most popular browsers including Internet Explorer and Firefox ship with a list of \"trusted root certificates\". These certificates are publicly available \"passwords\" that are digitally signed by a CA (Certificate Authority). These CA’s are companies that have been generally agreed upon to be trusted by the Internet community in general. They sell SSL certificates. Some of the names of popular CA’s you may have heard of include VeriSign, Thawte, Entrust, and GoDaddy.\nThe process to obtain a certificate generally follows these steps. You generate a long \"password\" on your server called a CSR (Certificate Signing Request). You send this CSR to the CA to digitally sign it for you. The CA sends back your CSR digitally signed by their trusted root certificate. This becomes your SSL certificate. You then install this SSL certificate into your server. The following is a step by step guide to installing the certificate in Internet Information Services (IIS) 7 and Windows Server 2008.\nInstalling an SSL Certificate on Windows Server 2008\nClick on the Start menu, go to Administrative Tools, and click on Internet Information Services (IIS) Manager.\nClick on the name of the server in the Connections column on the left. Double-click on Server Certificates.\nOn the right side, choose Create Certificate Request to start the process of generating your CSR for your certificate.\nIn the Request Certificate dialog, fill in all of the fields and click Next.\nWhat do all of these fields mean?\nCommon name: This is the full domain name that your certificate will be securing. Certificates are bound to a specific domain so when creating your request, you must specify which domain this certificate will be securing. NOTE: domains and sub-domains are different so if you had mydomain1.devtoolshed.com and mydomain2.devtoolshed.com, you would need to purchase a certificate for both. Just because they are both using the domain devtoolshed.com, each sub-domain is treated separately.\nOrganization: The exact name of your company or organization as filed with the Government. When the CA background checks your organization to issue the certificate, they will check that this name exactly matches your organization’s name. That means if you have \"inc\" or \"LLC\" on the end of your name, make sure to put that in as well.\nOrganizational Unit: This is the division or group for which this certificate is being requested by. Most CA’s do not check this field so it mostly informational.\nCity / Locality: The city where your company or organization is located.\nState / Province: the state, province, or region where your company or organization is located. If possible, use the full name of the place instead of its abbreviation.\nCountry / Region: The country where your company or organization is located. This can be abbreviated with the two-letter ISO country code.\nChoose the Cryptographic Service Provider (you can leave this as the default in most cases). Then choose a Bit Length of 2048 or higher. Then click Next.\nEnter a name of a .txt file that you want to generate the CSR to. The file will be created so it does not need to exist yet. Then click Finish.\nNow that you have this CSR, you can open the .txt file that you just generated to find your signing request code that you must send to your CA to get it digitally signed. Depending on your CA you will need to provide this as well as other information and once the request is complete and you’ve paid for your certificate, you will usually receive it via email or web link to download. Download your certificate and you are now ready to install it back to your server.\nIn IIS, make sure you are back on the Server Certificates icon (double-clicked like you did in the previous steps). On the right side will be a new link Complete Certificate Request. Click this link to start the process of installing your certificate.\nUse the … button to browse to the certificate you received from the CA. This certificate file may have a \".cer\" extension in some cases. If so, make sure to click the drop down on the file picker dialog and choose \"all files *\" so that it shows up in your file view. Choose this file and then enter a friendly name (this is just a name you want to show up in the IIS list so you can tell what this certificate is for). You can put whatever you want to help you remember this certificate in the Friendly Name. Then click OK.\nYou will now see your certificate listed as a new certificate available to use. You can configure your site now to use this certificate for SSL traffic. There is more information here about configuring certificates and other details for IIS 7:\n- ASP.NET Charting Control 3.5 fix for \"Error executing child request for ChartImg.axd\"\n- Explanation of Cross Domain and Client Access Policy files for Silverlight\n- C# Free Component to Generate PDF - Convert HTML to PDF\n- Using Stored Procedures in the Entity Framework with Scalar Return Values\n- C# Download File with Progress Bar\n- Launch URL in Default Browser using C#\n- thank you for sharing\n1 day 4 hours ago\n- Great explanation and more questions\n2 days 7 hours ago\n- Insertion of illegal Element:\n4 weeks 4 days ago\n- Insertion of illegal Element: 32\n4 weeks 5 days ago\n- re \"But, this will NOT work.\"\n5 weeks 5 days ago\n- Unable to cast COM object of t\n5 weeks 5 days ago\n- Saved my life\n5 weeks 6 days ago\n8 weeks 5 days ago\n- good article\n9 weeks 6 days ago\n- windows 2008 server backups\n11 weeks 5 days ago", "label": 1}
{"text": "Network Caching Technologies\nAlthough the volume of Web traffic on the Internet is staggering, a large percentage of that traffic is redundant-multiple users at any given site request much of the same content. This means that a significant percentage of the WAN infrastructure carries the identical content (and identical requests for it) day after day. Eliminating a significant amount of recurring telecommunications charges offers an enormous savings opportunity for enterprise and service provider customers.\nWeb caching performs the local storage of Web content to serve these redundant user requests more quickly, without sending the requests and the resulting content over the WAN.\nNetwork caching is the technique of keeping frequently accessed information in a location close to the requester. A Web cache stores Web pages and content on a storage device that is physically or logically closer to the user-closer and faster than a Web lookup. By reducing the amount of traffic on WAN links and on overburdened Web servers, caching provides significant benefits to ISPs, enterprise networks, and end users. There are two key benefits:\n- Cost savings due to WAN bandwidth reduction - ISPs can place cache engines at strategic points on their networks to improve response times and lower the bandwidth demand on their backbones. ISPs can station cache engines at strategic WAN access points to serve Web requests from a local disk rather than from distant or overrun Web servers.\n- In enterprise networks, the dramatic reduction in bandwidth usage due to Web caching allows a lower-bandwidth (lower-cost) WAN link to serve the same user base. Alternatively, the organization can add users or add more services that use the freed bandwidth on the existing WAN link.\n- Improved productivity for end users - The response of a local Web cache is often three times faster than the download time for the same content over the WAN. End users see dramatic improvements in response times, and the implementation is completely transparent to them.\nOther benefits include:\n- Secure access control and monitoring - The cache engine provides network administrators with a simple, secure method to enforce a site-wide access policy through URL filtering.\n- Operational logging - Network administrators can learn which URLs receive hits, how many requests per second the cache is serving, what percentage of URLs are served from the cache, and other related operational statistics.\nHow Web Caching Works\nWeb caching works as follows:\n- A user accesses a Web page.\n- The network analyzes the request, and based on certain parameters, transparently redirects it to a local network cache.\n- If the cache does not have the Web page, it will make its own Web request to the original Web server.\n- The original Web server delivers the content to the cache, which delivers the content to the client while saving the content in its local storage. That content is now cached.\n- Later, another user requests the same Web page, and the network analyzes this request, and based on certain parameters, transparently redirects it to the local network cache.\nInstead of sending the request over the Internet and Intranet, the network cache locally fulfills the request. This process accelerates the delivery of content.\nThe important task of ensuring that data is up-to-date is addressed in a variety of ways, depending on the design of the system.\nThe Benefits of Localizing Traffic Patterns\nImplementing caching technology localizes traffic patterns and addresses network traffic overload problems in the following ways:\n- Content is delivered to users at accelerated rates.\n- WAN bandwidth usage is optimized.\n- Administrators can more easily monitor traffic.\nThe first step in creating a network-integrated cache engine is to ensure that the network supports traffic localization, which can be achieved by enabling content routing technology at the system-level, and setting specific parameters to optimize network traffic. Cisco IOS ® Web Cache Communication Protocol (WCCP) is one example of content routing technology that can be set to support traffic localization. Once the right network foundation is in place, network caches are added into strategic points within the existing network. By pairing software and hardware, Cisco creates a network-integrated cache engine. Network-integrated caches have at least the following three properties:\n- Managed like networking equipment, resulting in minimized operational costs\n- Designed like high-density networking hardware, resulting in better physical integration into the network infrastructure as network extensions and minimizing costs associated with leasing rack space\n- Transparently inserted into the network, resulting in minimized deployment and operational costs and greater content availability\nExisting Caching Solutions\nThe three most common types of caches on the market today are proxy servers, standalone caches, and browser-based caches.\nProxy servers are software applications that run on general-purpose hardware and operating systems. A proxy server is placed on hardware that is physically between a client application, such as a Web browser, and a Web server. The proxy acts as a gatekeeper that receives all packets destined for the Web server and examines each packet to determine if it can fulfill the requests itself; if not, it makes its own request to the Web server. Proxy servers can also be used to filter requests, for example, to prevent its employees from accessing a specific set of Web sites.\nUnfortunately, proxy servers are not optimized for caching, and do not scale under heavy network loads. In addition, because the proxy is in the path of all user traffic, two problems arise: all traffic is slowed to allow the proxy to examine each packet, and failure of the proxy software or hardware causes all users to lose network access. Expensive hardware is required to compensate for the low software performance and the lack of scalability of proxy servers.\nProxies also require configuration of each user's browser-a costly and unscalable management task for service providers and large enterprises. In addition, proxy servers that are arranged in a hierarchical fashion form an additional overlay network, contradicting any plans to strategically converge disparate networks into a single, unified network.\nIn response to the shortcomings of proxy servers, some vendors have created standalone caches. These caching-focused software applications and appliances are designed to improve performance by enhancing the caching software and eliminating other slow aspects of proxy server implementations. While this is a step in the right direction, these standalone caches are not network integrated, resulting in higher costs of ownership and making them less desirable for wide-scale deployment.\nBrowser-Based Client Caching\nInternet browser applications allow an individual user to cache Web pages (that is, images and HTML text) on his or her local hard disk. A user can configure the amount of disk space devoted to caching.\nFigure: Cache configuration window to configure the amount of disk space devoted to caching in Netscape Navigator shows the cache configuration window for Netscape Navigator.\nThis setup is useful in cases where a user accesses a site more than once. The first time the user views a Web site, that content is saved as files in a subdirectory on that computer's hard disk. The next time the user points to this Web site, the browser gets the content from the cache without accessing the network. The user notices that the elements of the page--especially larger Web graphics such as buttons, icons, and images appear much more quickly than they did the first time the page was opened.\nThis method serves this user well, but does not benefit other users on the same network who might access the same Web sites. In Figure: Benefits gained by a single node using browser caching, the fact that User A has cached a popular page has no effect on the download time of this page for Users B and C.\nFigure: Benefits gained by a single node using browser caching\nWCCP Network Caching\n- In 1997, Cisco developed WCCP, a router-cache protocol that localizes network traffic and provides \"network-intelligent\" load distribution across multiple network caches for maximized download performance and content availability.\n- The cache component of the Cisco caching solution comprises network-integrated caching solutions-the Cisco Cache Engine 500 Series. They are network-integrated because they:\n- Provide network management capabilities already available on traditional Cisco networking gear (such as Cisco IOS CLI and RADIUS support), resulting in minimized management and operational costs.\n- Are inherently designed and implemented as caching-specific networking hardware, rather than being standalone server platforms adapted as caches. Thus, the high-density Cisco Cache Engines physically integrate better into the network infrastructure as network extensions transparently insert into existing network infrastructures and adapt to unusual network conditions, resulting in minimized deployment and operational costs and greater content availability.\nThe cache engine was designed from the ground up as a loosely coupled, multinode network system optimized to provide robust shared network caching. The cache engine solution comprises the Web Cache Control Protocol (a standard feature of Cisco IOS software) and one or more Cisco cache engines that store the data in the local network.\nThe Web Cache Control Protocol defines the communication between the cache engine and the router. Using the Web Cache Control Protocol, the router directs only Web requests to the cache engine (rather than to the intended server). The router also determines cache engine availability, and redirects requests to new cache engines as they are added to an installation.\nThe Cisco cache engine is a single-purpose network appliance that stores and retrieves content using highly optimized caching and retrieval algorithms. (See the Figure: Cisco cache engine connected to a Cisco IOS router)\nFigure: Cisco cache engine connected to a Cisco IOS router\nTransparent Network Caching\nA cache engine transparently caches as follows:\n- A user requests a Web page from a browser.\n- The WCCP-enabled router analyzes the request, and based on TCP port number, determines if it should transparently redirect it to a cache engine.\n- If a cache engine does not have the requested content, it sets up a separate TCP connection to the end server to retrieve the content. The content returns to, and is stored on, the cache engine.\n- The cache engine sends the content to the client. Upon subsequent requests for the same content, the cache engine transparently fulfills the requests from its local storage.\nA cache engine transparently caches as shown in Figure: Transparent Network Caching:\nFigure: Transparent Network Caching\nBecause the WCCP router redirects packets destined for Web servers to a cache engine, the cache engine operates transparently to clients. Clients do not need to configure their browsers to point to a specific proxy server. This is a compelling feature for ISPs and large enterprises, for whom uniform browser configuration is expensive and difficult to manage. In addition, the cache engine operation is transparent to the network-the router operates entirely in its normal role for nonredirected traffic.\nBecause a Cisco Cache Engine is transparent to the client and to network operation, customers can easily place cache engines in several network locations in a hierarchical fashion. For example, if an ISP deploys a Cache Engine 590 at its main point of access to the Internet, all of its points of presence (POPs) benefit (Figure: Hierarchical Implementation of Cache Engines (ISP)). Client requests hit the Cisco Cache Engine 590 and are fulfilled from its storage. To further improve service to clients, ISPs can deploy the Cache Engine 590 or 570 at each POP. Then, when a client accesses the Internet, the request is first redirected to the POP cache. If the POP cache is unable to fulfill the request from local storage, it makes a normal Web request to the end server. Upstream, this request is redirected to the Cisco Cache Engine 590 at the main Internet access point. If the request is fulfilled by the Cisco Cache Engine 590, traffic on the main Internet access link is avoided, the origin Web servers experience lower demand, and the client experiences better network response times.\nFigure: Hierarchical Implementation of Cache Engines (ISP)\nEnterprise networks can apply this hierarchical-transparent architecture to benefit in the same way as shown in Figure: Hierarchical Implementation of Cache Engines (Enterprise):\nFigure: Hierarchical Implementation of Cache Engines (Enterprise)\nThe Cisco caching solution was designed to enable network administrators to easily cluster cache engines to scale high traffic loads. This design approach allows customers to linearly scale performance and cache storage as cache engines are added. For example, a single Cisco Cache Engine 590 can support a 45-Mbps WAN link and 144 GB of cache storage; adding a second Cisco Cache Engine 590 provides support for a 90-Mbps WAN link and 288 GB of cache storage. Up to 32 cache engines can be clustered together.\nThis linear scalability is achieved because of the manner in which WCCP-enabled routers redirect traffic to cache engines. WCCP-enabled routers perform a hashing function on the incoming request's destination IP address, mapping the request into one of 256 discrete buckets. Statistically, this hashing function distributes incoming requests evenly across all buckets. In addition, these buckets are evenly allocated among all cache engines in a cluster. WCCP-enabled routers ensure that a certain cache engine deterministically fulfills requests for a certain destination IP address on the Internet. Empirically, this distribution algorithm has consistently demonstrated even load distribution across a cache engine cluster. Most of the popular Web sites have multiple IP addresses, thus preventing uneven load distribution.\nWhen the customer adds a new cache engine to the cluster, the WCCP-enabled router detects the presence of the new cache engine and reallocates the 256 buckets to accommodate the additional cache engine. For example, the simplest installation using one router and one cache engine assigns all 256 buckets to the single cache engine. If a customer adds another cache engine, the WCCP-enabled router redirects packets to the two cache engines evenly-128 buckets are allocated to each cache engine. If the customer adds a third cache engine, the WCCP-enabled router assigns 85 or 86 buckets to each of the three cache engines.\nCustomers can hot-insert cache engines into a fully operating cache cluster. In this situation, the WCCP-enabled router automatically reallocates the buckets evenly among all cache cluster members, including the new cache engine. Because a new cache engine will not have any content, it will incur frequent cache misses until enough content has been populated in its local storage. To alleviate this cold startup problem, the new cache engine, for an initial period, sends a message to the other cache cluster members to see if they have the requested content. If they have the content, they will send it to the new cache engine. Once the new cache engine determines it has retrieved enough content from its peers (based on configurable numbers), it will handle cache misses by directly requesting the content from the end server rather than from its peers.\nFault Tolerance and Fail Safety\nIf any cache engine in a cache cluster fails, the cluster automatically heals itself. The WCCP-enabled router redistributes the failed cache engine's load evenly among the remaining cache engines. The cache cluster continues operation using one less cache engine, but operation is otherwise unaffected.\nThe Cisco network caching solution enables an WCCP-enabled, Multigroup Hot-Standby Router Protocol (MHSRP) router pair to share a cache engine cluster, creating a fully redundant caching system. This is referred to as WCCP multihoming. If the WCCP-enabled router fails, existing Cisco IOS fault tolerance and fail-safe mechanisms are applied. For example, a hot-standby router could dynamically take over operations, redirecting Web requests to the cache cluster.\nIf an entire cache cluster fails, the WCCP-enabled router automatically stops redirecting traffic to the cache cluster, sending clients' Web requests to the actual destination Web site in the traditional fashion. This loss of the entire cache cluster can appear to users as an increase in download time for Web content, but has no other significant effect. This designed-in, failsafe response is made possible because the cache cluster is not directly in line with clients' other network traffic.\nWCCP Multihome Router Support\nAs previously mentioned, the Cisco network caching solution enables a cache engine cluster to home to multiple WCCP-enabled routers for added redundancy. Thus, Web traffic from all of the WCCP home routers will be redirected to the cache cluster. For example, a cache engine cluster that is homing to both routers in a MHSRP router pair creates a fully redundant caching system, eliminating any single points of failure (Figure: Fully Redundant Cache Engine Cluster Configuration).\nFigure: Fully Redundant Cache Engine Cluster Configuration\nWith a sudden Web traffic surge, a cache engine cluster could become overloaded. To gracefully handle this overload situation, each cache engine detects when it is overloaded, refuses additional requests, and forwards them to the origin Web servers. The origin Web servers respond directly to the clients because the bypassed requests were not handled by a cache engine (Figure: Overload Bypass).\nFigure: Overload Bypass\nThe overloaded cache engine will resume accepting requests when it determines that it has the resources to do so without retriggering overload bypass in the near future. The overload bypass on/off triggers are automatically determined by CPU and file system load. In the extreme situation that the cache engine becomes so overloaded that it is unable to respond to the basic WCCP status check messages from its home router, the WCCP home router will remove the cache engine from the cluster and reallocate its buckets.\nThus, overload bypass ensures that a cache engine cluster does not introduce abnormal latencies and maintains network availability even under unusually high traffic conditions.\nDynamic Client Bypass\nSome Web sites require clients to be authenticated using the client's IP address. However, when a network cache is inserted between a client and a Web server, the Web server only sees the cache's IP address and not the client's IP address.\nTo overcome this issue and similar situations, the Cisco Cache Engine has a dynamic client bypass feature that effectively allows clients, under certain conditions, to bypass cache engines and directly connect to origin Web servers. The result is that a Cisco Cache Engine can preserve existing source IP authentication models and pass through server error messages to clients. Because the cache engine dynamically adapts to these situations, less management is required to ensure cache transparency.\nDynamic Client Bypass Function\nIn Figure: Dynamic Client Bypass, a client issues a Web request, which is redirected to a cache engine. If the cache engine does not have the content, it will try to fetch the content from the origin Web server.\nFigure: Dynamic Client Bypass\nIn Figure: Dynamic Client Bypass, if the server responds to the cache engine with certain HTTP error return codes (such as 401-Unauthorized request, 403-Forbidden, or 503-Service Unavailable), the cache engine will invoke the dynamic client bypass feature. The cache engine will dynamically store a client IP-destination IP address bypass pair, so that future packets with this IP address pair will bypass the cache engine. The cache engine sends an automatic HTTP retry message to the client's browser.\nFigure: Dynamic Client Bypass\nIn Figure: Dynamic Client Bypass, when the client's browser automatically issues a reload, the request will be redirected to the cache engine. However, when the bypass table is checked and the request matches one of the table entries, the cache engine will refuse the request and send it directly to the origin Web server. Thus, the origin Web server will see the client's IP address, authenticate the client, and respond directly to the client.\nFigure: Dynamic Client Bypass\nReverse Proxy Caching\nCache engines are frequently deployed nearby clients to ensure faster network response time and minimal WAN bandwidth usage. Thus, the caches are caching the clients' most frequently accessed content. In addition, cache engines can also be deployed in front of Web server farms to increase the server farm capacity and improve Web site performance. This configuration is called reverse proxy caching because the cache engines are only caching content from the servers for whom they are acting as a front-end.\nThis feature is particularly important when cache engines are acting as a front-end for server farms in which certain content is dramatically more popular than other content on the servers. Using reverse-proxy caching allows administrators to prevent a small number high-demand URLs from impacting overall server performance. Better yet, this means the high-demand URLs do not have to be identified, manually replicated, or independently managed from the bulk of the URLs on the servers.\nReverse Proxy Caching Function\nIn Figure: Reverse Proxy Caching, each cache engine homes to WCCP-enabled routers/switches that are supporting server farms. When an incoming Web request reaches an WCCP-enabled router, the router performs a hashing function on the incoming request's source IP address and port number, mapping the request into one of 256 discrete buckets. Statistically, this hashing function distributes incoming requests evenly across all buckets. In addition, these buckets are evenly allocated among all cache engines in a cluster.\nBecause the hashing function is based on source IP address and port number instead of destination IP address, a given Web object could be stored in multiple cache engines in a cluster. By spreading popular content across a cache cluster, reverse proxy caching allows multiple cache engines to service requests for very popular content. Thus, additional cache engines can be added to a cluster to incrementally scale the performance of a popular site and decrease content download latency.\nNote that hashing on a destination IP address could also do the reverse-proxy caching. But in this case, all requests would have the same destination IP address and would be redirected to one cache engine. If you do not need to scale beyond one cache engine act as a front-end to a server farm, then this method is sufficient.\nFigure: Reverse Proxy Caching\nEnsuring Fresh Content\nA requirement for any caching system is the ability to ensure that users see the same content from a network cache as they would from the Web. Every Web page comprises several Web objects and each Web object has its own caching parameters, determined by content authors and HTTP standards (see the \"HTTP Caching Standards\" section). Thus, even a Web page with real-time objects typically has many other objects that are cacheable. Rotating ad banners and Common Gateway Interface (CGI)-generated responses are examples of objects that are typically noncacheable. Toolbars, navigation bars, GIFs, and JPEGs are examples of objects that are typically cacheable. Thus, for a given Web page, only a few dynamic objects need to be retrieved from the end server, while static objects can be fulfilled locally.\nCisco Cache Engine products deliver fresh content by obeying the HTTP caching standards and by enabling cache administrators to have control over when content should be refreshed from origin Web servers.\nHTTP Caching Standards\nHTTP 1.0 and 1.1 are caching standards, which specify caching parameters for each object on a Web page.\nHTTP 1.0 allows content authors to enable a \"Pragma: no cache\" header field for any object that should not be cached and allows authors to enable content to be cached indefinitely.\nHTTP 1.1 allows content authors to specify how long content is to be cached. For each object on a Web page, content authors can choose among the following caching attributes:\n- OK to cache (the default setting)\n- Explicit expiration date\nHTTP 1.1 has a freshness revalidation mechanism called If-Modified-Since (IMS) to ensure that cached data is up to date. A cache engine will send a lightweight IMS request to the end Web server when the cache engine receives requests for cached content that has expired or IMS requests from clients where the cached content is more than a configured percentage of its maximum age. If the object has not been modified on the end server since the object was cached, the end server will return a lightweight message indicating that the cache engine can deliver its cached copy to clients. If the object has been modified on the end server since the object was cached, the end server will return this information to the cache engine. If the case of the client issuing an IMS request, and the content is less than a configured percentage of its maximum age, the cache will serve the content without checking if it is fresh.\nCache Engine Content Freshness Controls\nAdministrators can control the freshness of Web objects in a cache engine by configuring a parameter called the freshness factor, which determines how fast or slow content expires. When an object is stored in the cache, its time-to-live (TTL) value is calculated using the following formula: TTL value = (Current date - last modified date) * Configurable freshness factor\nWhen an object expires, based on its TTL value, the cache engine will issue an IMS request the next time the object is requested (see \"HTTP Caching Standards\" section for a description of the IMS process).\nIf an administrator wants to adopt a conservative freshness policy, he or she can set the freshness factor to a small value (such as 0.05), so that objects expire more quickly. But the disadvantage to this approach is that IMS requests will be issued more frequently, consuming extra bandwidth. If an administrator wants to adopt a liberal freshness policy, the fresh factor can be set to a larger value, so that objects will expire more slowly and the IMS bandwidth overhead will be smaller.\nBrowser Freshness Controls\nFinally, clients can always explicitly refresh content at any time by using the browser's reload/refresh button.\nThe reload/refresh command is a browser-triggered command to request a data refresh. A reload/refresh will issue a series of IMS requests asking for only data that has changed.\nThe shift+reload/shift+refresh command is an extension of the reload/refresh command. In correctly implemented browsers, this command always triggers a \"pragma: no cache\" rather than an IMS request. As a result, cache engines are bypassed and the end server directly fulfills all content.\nMuch of the traffic on the Web is redundant, meaning that users in the same location often access the same content over and over. Eliminating a significant portion of recurring telecommunications offers huge savings to enterprise and service providers.\nCaching is the technique of keeping frequently accessed information in a location close to the requester. The two key benefits are:\n- Improved usability\nImplementing caching technology in a network accelerates content delivery, optimizes WAN bandwidth, and enables content monitoring.\nCisco has created a network-integrated cache engine by pairing system-level software and hardware.\nQ - On what concept is network caching based?\nA - Based on the assumption that users access the same content over and over.\nQ - What are two secondary benefits of implementing caching technology?\nA - 1. Secure access and control.\n2. Operational logging-administrators can log how many hits sites receive.\nQ - Provide a brief description of network-integrated caching technology.\nA - Network-integrated caching technology combines system-level software and hardware. Network-integrated caches must be managed like network equipment, designed like high-density hardware, and transparently inserted into the network.\nQ - How do Cisco cache engines ensure that web pages are kept up to date?\nA - By obeying HTTP caching standards that dictate which elements on a page can be cached and which cannot. Those that are not are retrieved from the source every time they are accessed.\nQ - Name an object that can be saved in cache memory, and one that cannot.\nA - Saved in cache: rotating banners, GIFs and JPEGs, toolbars, navigation bars. Noncacheable: CGI-generated responses.", "label": 1}
{"text": "- Confidentiality: Making sure people cannot acquire information they should not (keeping secrets)\n- Integrity: Making sure people cannot change information they should not (protecting data)\n- Availability: Making sure people cannot stop the computer from doing its job.\nComputer security involves telling computers what they are not to do. This makes computer security unique because most programming makes computers do things. Security takes much of a computers power.\nBasic computer security methods (in approximate order of strength) can be:\n- Limit access to computers to \"safe\" users.\n- Peripherals which block any \"unsafe\" activity.\n- Firewall and antivirus software.\nOther pages [change]", "label": 1}
{"text": "Anders Persson MCS-2007:18, pp. 31. TEK/avd. för interaktion och systemdesign, 2007.\nOnline banking and e-commerce applications have good protection against attacks directed direct towards their computer systems. This, the attacker has considered and instead use “social engineering” attacks, such as phishing to gain access to the information inside   . Phishing is a growing problem that many different companies are trying to develop a working protection against. The number of new phishing-sites per month increased by 1363 % between January 2005 and October 2006, from 2560 to 37 444 attacks  . Today there are several different antiphishing applications as well as implemented methods to prevent attacks, but it’s not certain they giving enough protection. In this paper we plan to investigate the concept of phishing to better understand the threat it provides. We will analyse 252 different phishing attacks and examine a number of existing antiphishing applications to see if there are possibilities to improve the different protection methods to improve the accuracy of such tools.", "label": 1}
{"text": "(ARA) – Have you ever casually surfed the Web, answered a friendly chat or responded to a curious email only to have it lead to major computer trouble? With virus, spam and phishing technology more sophisticated than ever, computer threats can be hidden in devious places. Are you making common computing mistakes without even knowing it?\nAccording to a 2012 Pew Internet & American Life Project survey, 58 percent of American adults have a desktop computer and 61 percent have a laptop. With all that computer power out there, it’s important to understand how to protect your at-home PC.\nHere are common mistakes that can affect computer speed and safety, from the experts at USTechSupport whose family of products include MYCLEANPC and MAXMYSPEED:\nMistake: Enjoying “free” software and movies from your buddy.\nDownloading pirated software is not only illegal; it can cause significant damage to your computer. The “free” software and media your buddy gave you can do more harm than good to your computer because it may be riddled with malicious viruses and malware, making your PC susceptible to attack. Remember, it’s better to buy than borrow when it comes to software and media.\nMistake: Clicking on enticing pop-ups.\nPop-ups caught your attention? Think before you click. Pop-ups that offer free goods, deals on products and even conversation with beautiful people can be alluring. But, do you know where that click will take you? Clicking on suspicious pop-ups can lead you down a rabbit-hole of even more unwanted pop-ups and spam. Take the time to research the subject yourself, rather than clicking on the first questionable advertisement.\nMistake: Leaving multiple files open.\nYou’re an expert at multitasking, meaning you need to constantly access many files. But leaving multiple files open in different applications can put a significant strain in your system. Try to keep only necessary resources active and see how much faster your machine responds.\nMistake: Not being proactive with computer maintenance.\nComputer issues arise frequently, even for the most savvy computer user. That’s why taking a proactive approach is best so your computer remains secure and fast. You can get a free diagnosis of issues that may be affecting your PC’s performance by visiting www.mycleanpc.com. You can easily fix common issues before they become costly (and timely) problems.\nMistake: Responding to an email with an “incredible opportunity.”\nEveryone has received them – that email investment opportunity that seems too good to ignore. The reality is, many scammers prey on trusting individuals or those who are enticed by get-rich-quick schemes. These scammers may even complete an initial transaction, only to later wipe out all your accounts. Never provide personal information, including banking information or your Social Security number, to anyone over email.\nMistake: Visiting adult websites.\n“Triple X” can also mean triple the issues. Some sites harbor more than just adult material, they can create a domino-effect of pop-ups, forcing your PC to a grinding halt as it deals with the incoming viruses that drain the system’s resources. Avoiding suspicious sites is part of keeping your computer running at its best.\nIf you’ve made some of these mistakes in the past, don’t worry. Many people are tricked each day. By learning from these useful tips and suggestions, you’ll keep your PC running fast and issue-free.", "label": 1}
{"text": "System Smart Security Description\nSystem Smart Security is a rogue security program that borrows the interface and attack techniques of similar rogue security programs. Rogue security programs in the System Smart Security family are known to create fake infection warnings and system errors, hijack web browsers and block applications and executable files. System Smart Security may look like a normal security program but is incapable of finding or removing threats from your computer. You should remove System Smart Security by using an anti-malware program, as soon as you can.\nThe Litany of System Smart Security’s Fake Alerts\nSystem Smart Security and similar threats are distributed by Trojans that attack computers through browser security exploits. Other rogue security programs that are closely related to System Smart Security include Security Essentials, Internet Security, Internet Security 2011, Security Essentials 2011 and Internet Security 2010. These rogue security programs use a similar interface, and attack your PC in the same ways, although security software that can detect a System Smart Security clone may still be unable to detect System Smart Security.\nAfter System Smart Security is installed, you’ll notice that System Smart Security runs whenever Windows starts. System Smart Security may even remain active as a memory process even if you try to shut System Smart Security down. This lets System Smart Security create pop-up errors like the following, whenever System Smart Security wants:\nContinue working in unprotected mode is very dangerous. Viruses can damage your confidential data and work on your computer. Click here to protect your computer.\nSecurity Essentials Ultimate Pack software detects programs that may compromise your privacy and harm your systems. It is highly recommended you scan your PC right now. Click here to start.\nYour computer is being attacked from a remote machine !\nBlock Internet access to your computer to prevent system infection.\nCritical System Warning! Your system is probably infected with a version of Trojan-Spy.HTML.Visafraud.a.\nThese fake alerts don’t detect real threats on your PC, since System Smart Security can only create false positives. Following their instructions may redirect you to malicious websites like System Smart Security’s homepage that attempt to steal your credit card information, or attack your PC with other threats.\nOther System Smart Security Perils to Keep Your Eyes Peeled For\nSystem Smart Security may also engage in other attacks in an attempt to fool you into believing that your PC is much more dysfunctional than it really is. The two primary and more serious System Smart Security attacks are:\n- Browser hijacks that change your homepage, redirect you to harmful websites or block you from visiting helpful websites. Hijacks by System Smart Security may also create fake errors that make it look like a website is unsafe or use links that redirect you to malicious sites.\n- System Smart Security may also block applications, most notably programs related to security or system maintenance. Windows Task Manager, MSConfig and similar default programs may be blocked, as well as well-known anti-virus scanners.\nRemoving System Smart Security will solve all of these issues, but improperly deleting System Smart Security can harm your Internet connectivity and other aspects of your PC. To remove System Smart Security with no side effects, consider using a good anti-malware program to scan your entire system once System Smart Security has been shut down.\nSystem Smart Security Automatic Detection Tool (Recommended)\nIs your PC infected with System Smart Security? To safely & quickly detect System Smart Security, we highly recommend you run the malware scanner listed below.\nDownload SpyHunter's* Malware Scanner to detect System Smart Security What happens if System Smart Security does not let you open SpyHunter or blocks the Internet?\nFile System Modifications\n- The following files were created in the system:\n# File Name 1 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\ 2 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].dll 3 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].exe 4 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].mof 5 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS].ocx 6 %Documents and Settings%\\All Users\\Application Data\\[RANDOM CHARACTERS]\\[RANDOM CHARACTERS]\\ 7 %UserProfile%\\Application Data\\System Smart Security\\ 8 %UserProfile%\\Application Data\\System Smart Security\\cookies.sqlite 9 %UserProfile%\\Application Data\\System Smart Security\\Instructions.ini\nPosted: June 7, 2011 | By SpywareRemove\nThreat Level: 10/10\nRate this article:", "label": 1}
{"text": "Information compiled by the GradSchools.com team - last updated October 2010\nStudying In the field\nIn addition to an undergraduate degree in a field such as accounting or business, some forensic accountants have backgrounds in law enforcement or criminal justice. A few schools offer accounting degrees with an emphasis in forensic accounting. For people already in the accounting field, the Association of Certified Fraud Examiners (ACFE) offers a certification exam. Entry-level forensic accountants typically earn between $30,000 and $60,000. Forensic accountants who have worked in the field for several years can make six figures.\nJob opportunities In the field\nThe field of forensic accounting is a specialty area of accounting that has to do with lawsuits or legal disputes. Webster’s dictionary defines the word “forensic” as “belonging to, used in, or suitable to courts of judicature or to public discussion and debate.” A forensic accountant might investigate white-collar crimes such as fraud or analyze financial information in a personal injury case. Sometimes forensic accountants, also called forensic auditors or investigative auditors, need to be expert witnesses at trials.\nAll of the Big Four accounting firms have forensic accounting departments. In addition, some smaller firms, such as Boston-based Feeley & Driscoll, offer forensic accounting services. International forensic accounting firm MD&D has 32 offices in the United States, the UK, Canada, Australia and Singapore. Police departments, government agencies, insurance companies and other businesses also hire forensic accountants.\nThe Bureau of Labor Statistics (BLS) expects the demand for all accountants, including forensic accountants, to increase. The BLS explains, “Increased focus on and numbers of financial crimes such as embezzlement, bribery, and securities fraud will increase the demand for forensic accountants to detect illegal financial activity by individuals, companies, and organized crime rings. Computer technology has made these crimes easier to commit, and they are on the rise. At the same time, the development of new computer software and electronic surveillance technology has made tracking down financial criminals easier, thus increasing the ease, and likelihood of, discovery. As success rates of investigations grow, demand for forensic accountants will increase.”\nCheck out: Accounting Graduate Programs\nPhoto by alancleaver_2000", "label": 1}
{"text": "Pádraic Brady: PHP Security: Default Vulnerabilities, Security Omissions & Framing Programmer\nOdd though it may seem, this principle explains some of PHP's greatest security weaknesses. PHP does not explicitly use Secure By Design as a guiding principle when executing features. I'm sure its in the back of developers' minds just as I'm sure it has influenced many if their design decisions, however there are issues when you consider how PHP has influenced the security practices of PHP programmers. The result of not following Secure By Design is that all applications and libraries written in PHP can inherit a number of security vulnerabilities, hereafter referred to as \"By-Default Vulnerabilities\".\nHe focuses on what he sees as a responsibility of those creating the language to either default to a more secure architecture or provide information as to why their choices could cause problems. In the extended version of the post, he talks about some specific issues that the language has including SSL/TLS misconfiguration, openings for XML entity injection attacks and limited native filtering for cross-site scripting.", "label": 1}
{"text": "Friday, June 17, 2011\nThe shield uses two antennas, one to transmit the jamming signal and the other to relay authenticated programming commands to the implant. (Source: MIT)\nMedical implants today receive wirelessly transmitted instructions from physicians regarding how to dispense their therapy, opening them to cyber-attacks that could potentially be fatal. However, a novel shield technology could secure access to the implants by virtue of an add-on medallion worn by the patient.\"\nEven though there have yet to be any reported cases of cyber-attacks on people with medical implants, such as pacemakers, researchers are intent on heading off the possibility with a shielding technology that works even with existing implants.\nSomeday soon Hollywood will be basing a major film on the premise that a hacker gains control of an important person's medical implant, either manipulating them by adjusting, say, their blood sugar with an insulin implant, or even assassinate them by stopping their heart with their own pacemaker. That is precisely the real-world scenario that Massachusetts Institute of Technology (MIT) professor Dina Katabi and University of Massachusetts-Amherst (UMass) professor Kevin Fu want to \"head off at the pass,\" to use the Hollywood colloquialism from old Westerns (where the bad guy alway wore a black hat).\nThe stakes are enormous. Millions of citizens worldwide already have approved medical implants and more than 300,000 more receive pacemakers, defibrillators, drug pumps, brain \"stimulators\" and the like every year. Many of these implants have wireless connections that allow doctors to monitors their performance and fine-tune their therapeutic benefits. Communication with them is carefully encoded so that stray radio signals do not unintentionally modify their programming; however, hackers today already possess the skills to circumvent these safety measures, prompting Katabi and Fu to collaborate on a solution before the problem materializes.\nThe smarter solution, according to the team, is what it calls a \"shield\" which is worn like a medallion. The shield constantly emits a jamming signal on the precise frequency at which the implant receives its wireless instructions from an external programmer, usually at the doctor's office. However, this is no dumb jamming signal that just blankets the patient in white noise, which could actually endanger the patient if it randomly changed the implant's programming. Instead, it emits a carefully encrypted signal that still allows authenticated programming to get through but which foils any hacker who does not possess the encryption key.\nPosted by R. Colin Johnson at 7:00 PM", "label": 1}
{"text": "IN DEPTH: BEGINNER'S GUIDE TO COMPUTER SECURITY\nHow safe is your computer?\nCBC News Online | Feb. 18, 2005\nSAFE PRACTICES | »TOP TIPS\nSafe practices checklist\nThe five top tips are tools to help protect your computer. They won't be much help if you reply to spam e-mail or use weak passwords. Even with a fully updated anti-virus program and firewall, an intruder with your passwords can gain access to your system.\nHere are some safe practices to layer your defence against online threats.\n\"Computers have passwords, and passwords are the keys to the kingdom. With this access they (intruders) could do anything you could and if motivated, even more.\"\nRyan Purita, security consultant.\n- Use unique passwords that you can remember. Use at least eight characters and include numbers and symbols. Make it difficult for programs that are specially written to crack your password.\nDon't use words you can find in the dictionary, or obvious things like the name of your child, your pet's name or your month of birth. Use a password that is easy to remember, so you don't have to write it down\nA 2003 Symantec survey of 700 Canadians found one out of every four respondents use family or pet's name as a password. Sixty-nine per cent memorized their passwords, but 24 per cent wrote their passwords down.\n- Be cautious with e-mail. Don't open e-mails and attachments from an unknown source. Make sure your e-mail program isn't set to automatically download attachments. Report spam to your internet service provider.\nWatch those virus warnings passed on by well-intentioned friends and family. It might be a hoax perpetuated by chain-letters. Verify the information with trusted sources. Rosaleen Citron, CEO of security firm White Hat Inc., recommends Sans.org and Anti-Phishing.org.\n- Scan downloaded files. Even if you've made sure that the file is from a trusted source, always scan for viruses before opening it.\n|AOL Canada March 2004 study\nOf 2000 Canadians surveyed:|\n· 89 per cent reported they were\nusing anti-virus protection.\n· 56 per cent were using firewall protection.\n·42 per cent had spam filtering.\n· 35 applied anti-pop-up software.\n· 6 per cent indicated they were not using any of the above.\n- Watch for unsecured shares: Turn off software features you don't use such as printer sharing and file sharing. These are available for easy access between computers on a network. This ability to share files can be used to infect your computer with a virus or allow an intruder to look at the files on your computer.\nIf you do have file sharing turned on, know what programs are using it. If you need to share files between computers, Ryan Purita, a security consultant, suggests that users set passwords to accounts and give only those accounts access: \"Never share your entire drive; rather, share folders which contain the files you want to share. Do not expose shares to the internet. Always use a firewall -- it will prevent anyone from accessing your computer via shares.\"\n- Secure your browser. Turn off features that allow automatic downloads, and turn on your browser's built-in security features. Get a blocker to stop those pop-up banners, and don't click on links in those pop-ups. Tod Maffin, CBC's technology columnist, points out most people don't read what's in the pop-ups before accepting them.\nHackers often target popular browsers such as Microsoft's Internet Explorer so\nyou might want to consider using alternative web browsers such as Firefox or\nOpera, suggests Maffin. There's no guarantee your computer will be safe, but you can avoid those\nthreats designed especially for Internet Explorer.\nIf you do use Internet Explorer, change the internet options default setting so that\nIE has to ask your permission before downloading files or running ActiveX\nControls, which are mini-programs often exploited by hackers.\n- Make backups of important files onto separate disks. If your computer does become infected, you'll have a clean copy of your files.\n- Turn your computer off or disconnect from the network between uses. Disconnecting your computer from the internet when you're not online, or shutting down the computer, lessens the chance that an intruder will be able to access your system.\nFollowing the top tips and safe practices should minimize your computer's exposure to online risks. But what if you think your computer's already been infected? What steps should you take?|\nRead some of our experts' advice.\nNEXT: PROTECT YOUR PERSONAL INFORMATION", "label": 1}
{"text": "When you're born, you're given a name which not only has meaning for you and your family, it also establishes your identity. Unfortunately, your name and identity are equally important to criminals who seek to take advantage of your name and steal your identity.\nIdentity theft is when someone wrongfully obtains and uses another person’s information in a fraudulent or deceptive manner. The personal information is typically used for financial gain. In fact, identity theft is the nation's fastest growing crime, according to the Identity Theft Resource Center. A recent study by the center showed seven million Americans become victims every year.\nWays thieves can steal your name and personal information:\nEven if the thief is caught, victims often spend a lot of time and money clearing their name. If your identity is stolen, you can expect to spend an average of 600 hours over the next few years clearing your name, and an average of $1,400 in out-of-pocket expenses.\nIdentity theft can affect your financial security for years to come\nThe residual financial effects of identity theft can be long-lasting. Identity theft can have a significant impact on your plans to save and invest in your family’s financial security. Money you have earned for saving or investments, such as your retirement or your child’s education fund, may end up paying for these collateral costs:\nIn addition to the financial strain, identity theft can also leave emotional scars. Victims have often reported the same mental conditions which afflict victims of physical assault. Common feelings include shame and embarrassment.\nSteps you can take to avoid becoming a victim:\nProtect your financial future\nWe offer two types of protection:\nGuidance from a trained professional\nYour name is one of your most valuable assets. Contact me to protect you and your family’s financial security from the threat of identity theft.\nFor product and service information, read our full disclaimer.", "label": 1}
{"text": "Systems exposed to the internet are heavily challenged to keep the bad\nguys out, and keeping up with the latest security patches is not always\neasy. So, the wise admin will attempt to institute systemic steps\nto limit the damage should a compromise occur, and one excellent\nmethod is the use of a chroot() jail.\nA chroot jail presents a dramatically restricted view of the filesystem to an\napplication, and usually far fewer system privileges, and this all intends\nto limit the damage should the application go awry or be subverted by the\nThis document touches on how chroot works and discusses some best\npractices that developers and administrators can use to make their\ninstallations more secure.\nBackground on chroot\nThe chroot system call changes the root directory\nof the current and all child processes to the given path, and this is\nnearly always some restricted subdirectory below the real root of the\nfilesystem. This new path is seen entirely as \"/\" by the process,\nand we refer to this restricted environment as the \"jail\". It's not\npossible to escape this jail except in very limited circumstances.\nThe chroot system call is found in all versions of UNIX that\nwe know of, and it serves to create a temporary root directory for\na running process, and it's a way of taking a limited hierarchy\nof a filesystem (say, /chroot/named) and making this the\ntop of the directory tree as seen by the application.\nHow to break out of jail\nThere are well-known techniques used to escape from jail, but the most\ncommon one requires root privileges inside the jail. The idea is for the\nprogram to do a chroot to a subdirectory, leaving the current\ndirectory outside the jail.\nWe'll add more notes on ways to break out of a jail - which is meant\nmore to show what must be protected against than it is as a how-to\nfor jailbreakers -- but we've found a good article on chroot in general\n- Use mknod to create a raw disk device, thereby doing\npretty much anything you like to the system.\n- Use mknod to create /dev/mem and modify kernel memory\n- Find a carelessly-left hard link that leads outside the\njail (though symbolic links don't escape jail, hard\n- Use ptrace to trace a process living outside the jail.\nWe may be able to modify this program to do our bad stuff on our behalf.\nAlmost all jail breaking requires root privileges.\nGeneral chroot principles\nWe have presented these in no particular order, and no one site will\nuse them all. In particular, some tips apply to developers at the source\ncode level, while others apply to administrators trying to jail an\nMany of these points may end up being overly petty in practice, in\nthat there are only so many layers of defense that a workable system\ncan use, but we'll present all we can think of and let you pick and\nchoose. An overriding principle is \"What if the bad guy somehow does\nX? How can we limit our exposure\".\nOur general concern is mostly about remote buffer overflows, and\nthis can give the bad guy complete control over our CPU: all our\nsteps are designed to limit the damage should this unfortunate\n- Run in the jail as a non-root user\nA chroot jail is not\nimpervious to escape, but it not easy and requires root permission in\nthe jail itself, so we must take steps to limit this possibility. By\nrunning the jail as a non-root user, it's as secure as we know how to\nmake it. It may be necessary for the daemon to launch as root in order\nto do a few tasks that require these permissions (say, binding to a\nlow-numbered port), but the program must \"give up\" its root permissions\nafter doing so.\nWe believe that this single factor is the most important one\nin setting up a jail properly.\n- \"Give up\" permissions correctly\nWe've seen situations where\non some operating systems, a program can jump back and forth between\na non-root user and root by use of a \"saved\" uid, and this has been\nexploited by the bad guy who get root.\nThe details of how to do this correctly are much more tricky when\nOS differences are taken into account: the variants are setresuid()\nseteuid(), setreuid(), and setuid() — it's likely\nthat this does not exhaust the options. The right one depends on the OS\nThe best resource by far we've found on this is the outstanding\nUsenix 2002 paper Setuid Demystified,\nby Hao Chen, David Wagner, and Drew Dean: it is precisely on point, and we'll\ndirect the reader to section 5.2 \"Comparison among Uid-setting System Calls\".\n- Explicitly chdir into the jail\n- The chroot call itself does not change the working directory, so if\nthe new root is below the current directory, the application can\nstill have access outside resources.\nThe application should explicitly change to a directory within the\njail before running chroot:\nsetXXuid(nonroot); // give up root permissions correctly.\nThis closes a trivial escape route from the jail (but we'll note that you\nmust use the proper setuid-esqe calls as noted in the previous item).\n- Keep as little in the jail as possible\n- This limits what\ncan be compromised should a vulnerability be discovered. Often this\nrequires development support to do some \"preloading\" of non-jailed\nfiles before the chroot operation itself is performed (we'll touch\non this a bit more later). But we're quite ruthless in removing things\nfrom the jail when possible.\n- Limit non-jail running of jailed binaries\n- For systems that\ndo not have a command-line option for running chroot, the only alternative\nis to create a wrapper program. This wrapper will perform the key chroot\noperation, give up root permission, and then execute the jailed binary.\nThe wrapper must be run as root (only chroot can perform this\noperation), but the wrapper itself must not be found in the jail.\nOtherwise an intruder could quietly compromise the wrapper, and\nthe next time the system is launched, the intruder's program would\nbe run as root in a non-jailed environment. This is complete\n- Have root own as many jailed files as possible\n- This limits the\nability of the intruder to make changes should a compromise occur.\nOur feeling is that the most likely cause of penetration will be\nthe buffer overflow exploit in which the intruder executes arbitrary\ncode in environment, and for files that the jailed system need not\never write to, making them readonly and owned by root means that\nthe penetration can't chmod the file before writing to it. This\nrule applies to directories as well.\n- Drastically limit all permissions of files and directories\nfeeling is that if a permission bit is not required, it should not\nbe set. For instance, the jailed \"/dev/\" directory should be of\nmode d--x--x--x with owner = root. Even though the only thing\nin the directory is /dev/null, forbidding searching of a directory\nstrikes us as prudent practice across the board when it's known to work.\n- Create a permissions-setting script\n- When first setting\nup the jail, many of the permission-related knobs are tweaked by hand\nas we gradually tighten things up, looking for things to break (at\nwhich point the knob is eased back a bit). This research is intricate,\nand the knowledge gained really ought to be represented in source code\nWe typically create a small shell script — living outside the jail\n— that sets the owner, group, and permissions mode on every file in the\njailed environment. It always starts with a few recursive change-everything\noptions to hardcode everything to very tight permissions, then relaxes\nthe settings on the files that can tolerate this. It's important to include\ndocumentation in the script on why particular permissions are relaxed,\nas well as describing why certain files are found in the jail in the first\nOnce this script is created, we typically make all of our\npermissions-related changed here and then re-run the script to\nmake them take effect. This is the only way that we can be sure\nthat our script matches the running environment.\nA great side benefit of the permission script is that it serves as\ndocumentation to the next person setting up a similar environment.\nA sample permission script that we use for one of our projects\n(running BIND in a chroot jail). The specific details aren't\nreally important, but this gives an idea\n# by default, root owns /everything/ and only root can write\n# but directories have to be executable too.\nchown -R root.named .\nfind . -print | xargs chmod u=rw,og=r # *all* files\nfind . -type d -print | xargs chmod u=rwx,og=rx # directories\n# the \"secondaries\" directory is where we park files from\n# master nameservers, and named needs to be able to update\n# these files and create new ones.\nfind conf/secondaries -type f -print | xargs chown named.named\nfind conf/secondaries -type f -print | xargs chmod ug=r,o=\nchown root.named conf/secondaries\nchmod ug=rwx,o= conf/secondaries\n# the var/run business is for the PID file\nchown root.root var\nchmod u=rwx,og=x var\nchown root.named var/run\nchmod ug=rwx,o=rx var/run\n- Try to do the chroot operation inside the daemon itself\n- ... rather than rely on the explicit chroot command (this requires\nsource code modifications). A daemon that has its own internal chroot\ncan often park the executable located outside the jail: this is a big\nwin because an intruder is not able to ever infect the binary directly.\nBut the more immediate benefit is that shared libraries and other startup\nfiles can be automatically loaded from the full system and need not be\nlocated inside the jail. This not only makes the system safer — less\nexposure to the outside — but also makes it easier to set up.\nIn many cases, even configuration files can be loaded from outside the\njail, though this won't usually work if the daemon includes any kind of\n\"reread config files\" option.\n- Preload dynamically loaded objects\nFor developers adding chroot\nsupport to programs, consider operations that require access to full-system\nresources and perform them before closing the jail door. These steps are\noften not entirely obvious at first and require some trial and error,\nbut we've found several that qualify.\nMany systems load nameservice resolver clients dynamically at runtime,\nand they are not included in the shared objects bound to the executables.\nWe have found that simply calling gethostbyname one time before the\njail door is closed will load all the appropriate libraries required, so\nthat later nameservice requests are handled properly:\nWe believe that syslogging operations fall in this category too, as many\nsystems uses UNIX domain sockets for this and require access to the socket\nthat syslogd is listening on. We've not done the modifications required\nfor syslog support and cannot offer any specific suggestions. We believe\nthat Solaris -- with its use of \"doors\" -- is an added complication.\nFor daemons that permit cmdline parameters to select the runtime users\nand group (after giving up root), the mapping of name to UID and GID must\nbe done before the chroot operation so that the system-wide /etc/passwd\nand related files are used, not the one inside the jail. See the\nnext section for the rationale.\nThis bit of C code shows the idea of how the user lookup should be performed\nseparately from the user ID changing:\nif ( geteuid() == 0 )\nstruct passwd *userent = 0;\nif ( (run_as_user != 0) && (userent = getpwnam(run_as_user)) == 0 )\n/* ERROR */\nchroot( working_dir );\nif ( userent )\nsetXXuid(userent); // use the proper call!\n- Avoid using the jailed /etc/passwd file\n- ...particularly for\nname to UID mapping used to determine the runtime user ID of the daemon.\nThe mapping involves scanning the passwd file for the given name\n(say, named) and finding the user ID associated with it. If the\nbad guy somehow manages to compromise the jailed passwd file, it's\npossible that the UID for the runtime user could be changed to zero,\nwhich is root. This will take effect the next time the daemon restarts.\nThe bad guy shouldn't be able to compromise this file in the first place,\nbecause it should not be writable by the running user, but it's not out\nof the question that the daemon could somehow retain a writable file\ndescriptor that the buffer overflow could use to modify the file: we\nbelieve we have seen this happen before. As is so common, a bug in one\narea of the system can have surprising impacts on security.\n- Close file descriptors aggressively before chrooting\n- We don't\nwish to leave handles open to non-jailed resources because these can all\nbe exploited by those living inside the jail. Some file descriptors are\nrequired (day, to the syslog daemon), but developers should make a point\nto close anything that is not strictly required.\n- Link config files from the outside\nSome systems (such as BIND)\nshare the configuration file between the jailed daemon and other utilities\nthat are run from user mode. In this case, the config file simply must\nlive inside the jail so that the daemon can access it, but the other utils\nfrom user mode still need to access this file. Rather than rebuild these\nutilities to use the special path (say, /chroot/named/etc/named.conf),\ninstead go to the \"regular\" place for this file and create a symbolic\nlink from the outside to the inside of the jail:\n# ln -s /chroot/named/etc/named.conf /etc/named.conf\nThis allows most of the tools to operate \"normally\", though one has\nto be a little more careful that users editing /etc/named.conf\nrealize that they're affecting a jailed system.\nThis doesn't go the \"other\" direction, though it's not always obvious\nat first. Symbolic links from inside the jail to the outside will\nwork for the administrator but will not work for the system running\ninside the jail.", "label": 1}
{"text": "What is Big Data?\nBig Data describes the process of extracting actionable intelligence from disparate, and often times non-traditional, data sources. These data sources may include structured data such as databases, sensor, click stream and location data, as well as unstructured data like email, HTML, social data and images. The actionable data may be represented visually (e.g. in a graph), but it is often distilled down to a structured format, which is then stored in a database for further manipulation.\nThe sheer size of data being collected is more than traditional compute infrastructures can handle; exceeding the capacities of databases, storage, networks and everything in between. Extracting actionable intelligence from BigData requires handling large amounts of disparate data and processing it very quickly. Finally, the data inputs and the actionable intelligence must be correct; the data must be consistent and clean. As the saying goes, garbage in, garbage out. All of these demands are overwhelming traditional computing infrastructure. IBM describes these new demands across four dimensions: Volume, Velocity, Variety and Veracity. I would add Richly Linked Data to this list—processing Big Data uncovers rich relationships between that data—except I cannot think of a “V” word that says richly linked. To deal with the onslaught of Big Data, companies are turning to new tools and new business processes.\nBig Data Tools\nAs Big Data overwhelms traditional databases, storage and more, companies are looking to exploit new tools like Hadoop, SSD, database virtualization, storage virtualization, network virtualization, and more. The reality is that you want to avoid single device bottlenecks, since they inhibit scaling. Hadoop uses map-reduce to spread analytical processing across armies of commodity servers. SSD, while expensive per GB of data capacity, provides the performance necessary to keep up with the velocity of Big Data. Virtualization of the database, storage and networking provides the elasticity and agility needed to scale to address Big Data demands, while delivering a consistent quality of service. These are just some of the tools being brought to bear on the Big Data challenge.\nBig Data Business Processes\nThe benefits of Big Data are quite tantalizing. Big Data can be used to improve efficiency and the predictive capabilities in everything from health care to oil drilling. Once businesses get a taste of Big Data, their appetite becomes insatiable. This has spawned new business processes to meet the rising demand. Moving to the cloud is one such business process enabling Big Data. Cloud enables you to process your Big Data using say 1,000 machines for just an hour, paying only for the time you use them. This makes Big Data processing cost-effective in terms of both operational expenses (OpEx) and capital expenses (CapEx). Another interesting business process that is becoming popular is cloud-bursting. Cloud-bursting means running the core process on your own machines, but allowing overflow compute demands to run on a public cloud, typically for a short period of time. Creative companies will use these and other innovative business processes to deal with the growing demands of Big Data.\nWhat Role do Databases Play in Big Data?\nBig Data begets Bigger Data. The more a company recognizes the transformative role of Big Data, the more data they seek to capture and utilize. As a result, more companies are capturing more data. This includes everything from web analytics and click stream data to expanding their database schema to capture more transactional information. The more you utilize Big Data, the more data you seek to collect.\nDatabases are broken into two classes: analytical and transactional. Transactional databases capture structured information and maintain the relationships between that information. Transactional data is one feedstock for Big Data. Analytical databases then sift through the structured and unstructured data to extract actionable intelligence. Often times, this actionable intelligence is then stored back in a transactional database.\nHow are Transactional Databases Handling Big Data?\nBig Data requires decentralization. Because of the volume and velocity of data being processed, centralization is anathema to Big Data. The networking, storage and compute must be decentralized or they will not scale. However, centralization is a core tenant of SQL databases. Traditional databases tightly link computation, caching and storage in a single machine in order to deliver optimal performance. There are two approaches to scaling SQL databases in order to handle Big Data—namely sharding and shared-data clustering.\nOne approach to decentralizing transactional databases is sharding. If you have an existing schema, sharding removes the relations between tables and then stores those various tables in separate databases. This forces the application layer to maintain, and in some cases reconstruct, those relationships. One common approach to sharding is to split customers across multiple databases. For example, you might have customers 1-10,000 in one database, then 10,001-20,000 in another database and so on.\nSharding is one way to scale your data handling needs, but it is very inflexible, it doesn’t adhere to the Big Data principle of agility. A sharded database cannot add new data sources, and new ways of processing that data, on the fly. Sharding creates a rigid structure that necessitates a painful re-sharding each time you modify or expand the data or relationships between the data.\nShared-data database clusters, as provided by ScaleDB and Oracle RAC®, deliver the agility required to handle Big Data. Unlike sharded databases, shared-data clusters support elastic scaling. If your database requires more compute, you can add compute nodes. If your database is I/O bound, you can add storage nodes.\nIn keeping with the Big Data principle of distributing the workload, shared-data clusters parallelize some processing across smart storage nodes, further eliminating bottlenecks, and allowing you to scale to address your Big Data needs.\nUnlike sharded databases, shared-data clusters maintain the flexibility to add new tables and relationships on the fly. This flexibility is imperative, in order to keep up with the ever changing data sources and data relationships driven by Big Data.\nHow Can You Prepare for Big Data?\nThe most important first step in preparing for Big Data is to consider scale, parallelization, and agility. These issues must be considered when choosing your computing tools and your business processes. Maintain agility or flexibility, because your data and your processing needs will change and that change may be rapid and disruptive. Scale and parallelization go hand-in-hand. The only way you can scale to handle Big Data, is by leveraging parallelization. This means you must distribute processing, data and networking so as to avoid bottlenecks.\nThese same principles aplpy to your business processes. This may involve exploiting elastic cloud computing either directly or through cloud bursting. Consider that, as you plan your infrastructure and your schemas today, things will change relatively quickly. Big Data begets Bigger Data, so prepare for future scale and agility today.\nFor more information about Big Data and how databases are adapting to the demands of Big Data, see our Big Data White Paper.", "label": 1}
{"text": "What are secure connections?\nSecure connections are designed to protect data sent between two computers via the Internet. Secure connections should:\n- Mask confidential data from third parties\n- Verify the identification of the party with whom information is being exchanged\n- Protect information from being viewed or modified by a third party\nFig. 1. Access to an MS Exchange Server mailbox via a secure connection\nThere are several ways to secure data transmission, and they all involve the use of data encryption and special keys used to read the information. The keys (also known as certificates) are usually stored in a dedicated database – a certificate archive – and are accessible to authorized users.\n- Data encryption. This method involves masking information (emails, for example) from third parties and sender verification. This method, however, does not verify the authenticity of the two computers involved in the exchange of information. In order to create an encrypted message and have two recipients read it, the recipients must have the appropriate program installed (such as PGP, GPG or S/MIME). Most encrypted data is transferred via email.\nFig. 2. Encrypting data using PGP\n- Encrypting a transfer channel. This method involves concealing the entire contents of the network connection and verifying the authenticity of all computers participating in the network connection. However in most cases, the data itself, as opposed to the first method, is not verified. For example, sender verification of an email received via an encrypted channel is not possible. These encryption protocols are called SSL and TLS.\nFig. 3. Secure connection settings in Outlook Express\nSupport for an encrypted transfer channel is currently provided by the vast majority of Internet applications: email servers and client programs, web servers and browsers, as well as a number of proprietary network applications, such as banking systems used to manage accounts and make payments online. The simplicity of this method is obvious to developers: a standard data transfer protocol can be implemented within an established secure network connection, making any necessary modifications to network ready applications minor. This is how well-known protocols function:\n- HTTPS (normally HTTP – the main Internet protocol which is encrypted using SSL/TLS)\n- POPS (normally POP3 –the main protocol for receiving email, and encrypted using SSL/TLS)\n- SMPTPS (normally SMTP – the main protocol for sending email, and encrypted using SSL/TLS)\n- MAPS (normally IMAP4 – a common protocol for receiving email, and encrypted using SSL/TLS)\n- NNTPS (normally NNTP – a common protocol for reading news and encrypted using SSL/TLS)\nSome network services are offered exclusively via an encrypted connection, such as the popular Gmail.\nThis article examines encrypted transfer channels, or so-called secure connections.\nDifferent types of protection against network threats\nNetwork connections are used to transmit both useful information but also malicious data, which can pose a threat to computers. Typical examples of malicious data include most contemporary threats: hacker attacks, Trojans, email worms and exploits which target web application vulnerabilities.\nThe following types of programs and application packages can be used to protect against network traffic threats:\n- Checks every network connection on the local computer in accordance with designated rules: the connection will either be permitted or denied.\n- Can detect (but not delete) Trojans when they attempt to transmit harvested confidential data to a third party.\n- Cannot detect viruses, regardless of the type of connection.\nFig. 4. Firewall rules for an application\n- Protection against network attacks (IDS: Intrusion detection system):\n- Scans for, and is capable of blocking attacks for which there is a signature with in an established network connection regardless of protocol;\n- Can detect viruses, but not delete them from common HDLC protocols such as HTTP and POP3. When a virus is detected in an email received via POP3, the only possible action is to terminate the network connection. This does not guarantee, among other things, protection against the virus detected in the email. When the user attempts to get other emails from the server, the infected email will cause the victim machine to disconnect from the mail server;\n- Cannot detect viruses within an encrypted connection.\nFig. 5. Blocking a network attack\n- Antivirus solutions (email and web):\n- Can detect and neutralize viruses included in the database during sending and receiving data via a known HDLC protocol.\n- Cannot detect viruses within an encrypted connection.\nFig. 6. Detecting a virus in a downloaded file\nThe danger of secure connections\nAs stated above, both useful and malicious information can be transmitted via network connections. Standard solutions protect computers against threats present in standard network connections, but aren’t able to counter threats present in secure connections. Verifying the contents of a secure connection is impossible by virtue of its secure nature, as demonstrated by the different types of protection listed above. As a result, malicious data within secure channels can cause a significant amount of damage, and sometimes more than if it were to be transmitted via a standard, non-secure connection.\nThe fact that it’s easy to encrypt a network channel and the fact that in most cases there will be no verification of who created the file results in a contradictory situation: a “secure connection” to a server provides the user with a feeling of security, but does not guarantee that the connection will be free from malicious data.\nThe dangers inherent in “secure connections” are particularly apparent now as such threats are becoming more and more widespread. After developers ensured SSL/TLS support for all popular web applications, a number of servers on the Internet began to offer their services via SSL/ TLS: together with major banking sites, all the big-name email services and partner sites opened access exclusively via secure connection. The qualifications of administrators of such servers is often barely enough for them to configure a secure server connection correctly.\nThe situation is exacerbated by the fact that an attack on a computer can be carried out remotely – for example, by simply placing a malicious file on a server which can be reached only via a secure connection.\nA few examples can be found below.\nGmail and viruses\nThe popular email service Gmail offers access to its services exclusively via secure connection. It is known that Gmail servers use an antivirus program. Now let’s consider some hypothetical situations:\n- A virus writer sends his virus to a Gmail subscriber.\n- Gmail’s antivirus doesn’t detect the virus, because the antivirus database update has been delayed.\n- After a certain time the user downloads the infected email from a local computer, because the Gmail antivirus has been optimized, resulting in emails being scanned only once they reach the inbox, and not when they are transmitted to the user.\n- The antivirus program on the local computer, which has already updated its database to include the relevant signature, does not detect the virus since the network connection was encrypted in line with Gmail requirements, and the email antivirus was not able to scan the email.\n- The file antivirus detects the virus in the email database and indicates that the entire email database should be deleted, since it is often impossible to disinfect an email database.\n- Result: the user will lose all his correspondence.\nWeb servers and viruses\nAn equally interesting example: a malicious user can upload a malicious file to a web server and then attract Internet users to visit that server. If the virus is placed on a regular HTTP server, a computer with antivirus software will not be in any danger. However if the virus is placed on an HTTPS server the situation is a little more complicated:\n- A virus writer can use a vulnerability to access files stored on a server (e.g. the case of the Valuehost servers, run by a Russian provider) and can replace files with the virus.\n- A user opens a familiar website with a standard browser using HTTPS. The web antivirus cannot read the data in the encrypted connection and cannot prevent infected files from being downloaded.\n- Instead of a normal web page, the browser loads a virus which exploits a browser vulnerability. The virus will instantly execute its code within the browser. The file antivirus cannot block the execution of the malicious code, because the infected file is processed by the file antivirus only after it has been saved to disk i.e. in this case after the malicious code has been executed.\n- Result: the computer is infected.\nIn order to check data transferred via a secure connection, most antivirus developers offer plug-ins for web applications. This approach has its pluses and its minuses:\n- The data stream between client and server is not affected\n- The data stream cannot be accessed by third parties\n- It’s impossible to create a plug-in for certain applications. One key example: Outlook Express, the most common email program.\n- There are limitations on using plug-ins, for example MS Outlook.\nFig. 7. An antivirus plug-in for Microsoft Office Outlook\nAn alternative to using plug-ins is checking traffic using a man-in-the-middle method, which overcomes the negative aspects of plug-in architecture. Although it does have its drawbacks, antivirus vendors have been forced to implement this approach in order to protect their users.\nThis method is an attack on the essence of SSL/TLS, since it intercepts the secure connection, substitutes the original certificate and establishes two secure connections: between the application and the proxy antivirus, and again between the proxy antivirus and the remote computer.\nFig. 8. A standard secure connection\nFig. 9. A secure connection being scanned\n- Connections can be scanned for any client application.\n- Connection can be scanned for viruses under any known protocol.\n- In addition to antivirus scanning, the proxy can conduct all other data operations, scanning for phishing, spam, etc.\n- The data stream cannot be viewed by a third party unless s/he conducts a man-in-the-middle attack.\n- The data stream between client and server is modified. As a result:\n- Web applications cannot verify the authenticity of a server;\n- A server cannot verify the authenticity of a client;\n- If the proxy does not carry out its own verification, a second man-in-the-middle attack (between proxy and server) could be conducted. This could be done by a malicious user in order to read and modify data.\nIn practice, traffic scanning does not present any real danger to the user. Scanning is conducted on the local machine; the user can be asked to make choices, and all remote certificates can be verified by antivirus software and certificate archives, just as is done by web applications.\nThe drawbacks of the man-in-the-middle method are more than compensated for. The computer will be totally protection against threats on all types of network connections.\nKaspersky Internet Security\nKaspersky Internet Security includes solutions that verify both types of secured connections:\n- Plug-ins for web applications:\n- MS Outlook,\n- IE ScriptChecker\n- Verification of secured connections in traffic using man-in-the-middle method:\n- Kaspersky Internet Security informs the user of all actions:\n- Notifies the user about server certificate substitutions\n- Verifies certificates received from a server in the Windows certificate archives in exactly the same way as web applications\n- The final stage of the man-in-the-middle method is not included. Registering a substitute certificate in the archives of trusted certificates has to be conducted by the user\n- Kaspersky Internet Security provides the option to disable the checking of certain connections (configuration options: applications / servers / ports.) This solves any questions which could arise about the correct functioning of services which check the authenticity of the client.\n- Kaspersky Internet Security checks all possible parameters within secure connections:\n- The web antivirus component detects viruses in browser traffic\n- The email antivirus component detects viruses in email traffic\n- The anti-phishing component detects fake websites and links to these sites\n- The antibanner component blocks pop-ups\n- The antispam component blocks unwanted correspondence\nFig. 10. Detection of the eicar test file within a secure browser connection\nSecure connections are designed to protect data against modification and theft. However, today, secure connections do not provide real protection against network attacks, and are therefore not as secure as they may seem.\nInterestingly, the term secure connection may mislead users by creating a false sense of security. The situation is further exacerbated by the fact that standard security solutions cannot perform within secure channels.\nSpecial methods have to be used in order to provide total protection against network threats. The simplest and most obvious solution is to use a plug-in for web browsers. Unfortunately, plug-ins are not universal, and many applications do not support them or impose too many restrictions on their functionality. Another solution found by antivirus manufacturers involves traffic verification.\nThe dangers of secure connections should not be underestimated. When you make important decisions about your computer’s security, make sure that your antivirus solution provides real protection against all network threats.", "label": 1}
{"text": "MalwareBy Gina on November 18, 2010 | Malware\nNovember is the month of hackers that designed bunch of rogue anti-spyware programs for different Operating Systems. They are spread all over the web and confuse computer users because the main goal of theirs is to trick users into believing that computer is severely compromised. Fake AV is designed to pilfer money from unwary users. They download and install itself automatically without user’s knowledge and consent. Read more.By Gina on October 19, 2010 | Malware\nA mistrust seed in Kaspersky is sowed. Few comments in Kaspersky Lab forum state that the site of this major computer security company is compromised by cybercriminals. It seems like hackers try to spread fake security software.Fake AV malware are designed to fool users into thinking that they are legitimate antivirus applications. As such, they usually pretend to scan systems prevent certain applications from executing, display warning messages, and connect to adult sites. Read more.By Gina on September 29, 2010 | Malware\nStuxnet worm is one of the most dangerous worms ever. It is able to infiltrate itself in a computer even after it has been already cleaned from the machine. Worm usually targets computers that are used in nuclear plants and other industrial facilities.Stuxnet has proven it is a piece of headache for the security researchers and analysts because it could affect four flaws that were undiscovered and unpatched. Read more.By Gina on August 30, 2010 | Malware\nAccording to Panda’s report, 25% of worm based malware spreads through the USB drives. Even more, most of viruses are designed to spread via USB drives. Security Company confirms that cybercriminals are very persistent and put a lot of efforts to make user’s life impossible. 25% of latest created malware are configured to enter the system through portable storage devices, usually USB drives. Read more.By Luciana on August 11, 2010 | Malware\nIf there's the Android OS on your phone and your bills started to skyrocket, you may have the first Android trojan. The incredibly popular OS made by Google couldn't be left out by cyber criminals. What's the hype about and how can you avoid the mess?The first trojan for Android Smartphones is called Trojan-SMS.AndroidOS.FakePlayer-A. It poses as a video player and it has to be installed manually. Read more.", "label": 1}
{"text": "Keep Passwords Strong, Secret, and Safe\nIn early 2009 more than 30 high-profile accounts on social-messaging site Twitter were compromised, including those of President Barack Obama and Britney Spears. A weak password on a Twitter employee's computer caused the security breach—a hacker used dictionary attack software, which systematically tries all words in the program's \"dictionary,\" beginning with commonly used ones such as names and places, until it discovers a computer's password or exhausts its list.\nThis hacker's program discovered the Twitter employee's password and used administrative tools on the computer to reset passwords on the high-profile accounts. Then, in an online forum, the hacker offered anyone access to the accounts upon request.\nHow could the Twitter employee have foiled the dictionary attack? By creating a robust password and guarding it from unauthorized access. Dictionary attacks are only one way unscrupulous people steal passwords and commit malicious acts on unsuspecting consumers, and the consequences can be far more serious than having people open your Twitter account. (Although sending fake messages as President Obama could be quite serious, fortunately the scam was discovered before that happened.)\nThe point is, it's vital that you keep your computer's content secure by creating strong passwords, keeping them secret, and keeping track of them. A compromised password could lead to identity theft or other dire consequences. A criminal could use your information to apply for credit cards or mortgages, or to make online purchases or other transactions.\nCreate strong passwords\nThe first rule of thumb is to use a different password for each of your accounts. It may be easier to keep track of just one password, but if a crook discovers that one password, he or she can access all of your accounts. This tip has been well publicized, but the Accenture consultancy's survey of 800 U.S. and U.K. consumers revealed that 88% use just one, universal password.\nThe second key to a robust password is to make it lengthy. According to a Microsoft spokesperson, each character you add to your password increases the protection it affords many times over. At a minimum, your passwords should be eight digits long, and 14 digits or more is ideal.\nA compromised password could lead to identity theft or other dire consequences.\nUsing the greatest variety of characters possible in your passwords—letters, numbers, symbols—makes them harder to guess or uncover with malicious software. Microsoft's spokesperson says the fewer types of characters you use, the longer your password needs to be—if you use only letters and numbers make it 15 characters long.\nConsider using words and phrases you can remember, but that others wouldn't guess. You can use the first letter of each word in a sentence, plus some numbers, mix upper- and lowercase, and include some misspellings and symbols. Here's one example: \"I went to Hawaii in August 2009 with Bob,\" becomes \"iWThI082009wB.\" Include a few symbols and it's \"!WT*h;I082009w%B:.\" (The exclamation point substitutes for \"I\" and the randomly selected symbols bracket \"Hawaii\" and \"Bob.\") Who would ever guess that one? You can also substitute numbers for letters: \"hate\" becomes \"h8.\"\nAfter creating your password, you can test its strength with one of the \"password checkers\" available online such as Microsoft's Password checker and The Password Meter. If your password tests as weak, make it more complex.\nSome password don'ts include:\nKeep passwords secret\nOf course, the strongest password is useless if you share it with others, so guard yours closely. Don't reveal your passwords to family or friends. Children, particularly, may unwittingly pass them on to others, Microsoft's spokesperson reminds.\nYou shouldn't type passwords into public computers, such as those at libraries or in hotel lobbies. Even if you instruct the computer not to save the password, there could be malicious software on the computer that records your keystrokes for a criminal's use.\nAlso, you shouldn't send passwords via e-mail—it isn't a secure delivery channel—and you shouldn't enter a password if requested to do so via an e-mail.\nIf you see suspicious activity, notify the authorities and contact your credit union for help.\nDon't store a list of your passwords on your computer—that would be a goldmine to a crook. Microsoft's spokesperson says it's safer to record your passwords on paper, and then hide the paper where others won't find it. Make sure it's a location you'll remember, though. What about between the pages of a book on your shelf? Another idea is to store the word file on a thumb drive and hide the thumb drive, says Ian Forkash, an information technology manager for the Credit Union National Association in Madison, Wis.\nIf you add encryption software to your computer, which codes information for privacy, you can store passwords there. Some versions of the software are available at no charge, such as a limited version of RoboForm for Windows. There's a fee for more comprehensive programs, such as Symantec's Endpoint Security.\nKeep track of passwords\nSo, how do you remember your many passwords? Your secret list is one way, of course. And using a familiar phrase when creating the passwords, as described above, is another.\nConsumer Reports suggests developing a couple of basic passwords you can memorize, and then adding different prefixes or suffixes to them for different accounts or Web sites, or scattering different symbols throughout.\nThen, on your password list, you can write down just the add-ons and where they appear in the password. For example, if you add an asterisk as the second character in the password for one account, on your list you can just write: 2*.\nDon't store a list of your passwords on your computer—that would be a goldmine to a crook.\nVince, who lives in Louisiana, uses a consistent approach to make his passwords memorable. \"I use a combination of the Web site's name, along with recognizable information,\" he says. \"For Yahoo, my password could be the first three letters of Yahoo, the first three letters of my pet's name, and the number of my birth month. So, my password for Yahoo might be: yahspo04. This way my password is always different, but still is easy enough to remember.\" Vince was one of several Home & Family Finance Resource Center's What's Your Story respondents.\nStephanie, from West Virginia, has another approach. \"I have a good memory for numbers and things such as passwords, so I can typically remember many of them. But when I first change my password, I enter it in my rolodex as a code,\" she recounts. \"Say my user name is 'username,' I would put down 'un.' If my password is 'password1,' I would put down 'pw1.' If I enter a year behind a password like 'password2009,' I would write down 'pw yr full.' Full means I've used a four-digit number instead of two.\" (Of course, Stephanie would want to use a combination of various characters rather than words that appear in dictionaries.)\nWhen it comes to password storage, Catherine, from California, has a creative method. She uses a set of small index cards, hole-punched at the corner and attached to a metal ring made for organizing papers. \"Every time I sign up on a new Web site I write its name on a card, along with the user name and password and other relevant information,\" she says.\nShe stores the cards in a safe place that she can remember. \"The cards are small enough to drop in my bag, and easy enough to hide from prying eyes,\" she says. \"It works very well for me.\"\nPaul, from New Mexico, stores his online. \"I use the Secure Login add-on available for the Firefox Web browser,\" he explains. \"It uses one master password to give you automatic access to an encrypted database containing all your individual passwords.\"\nTake action if someone gets your password\nIf, despite your best efforts, your password is compromised—possibly through a security breach at a business—don't panic. Monitor all the information you protect with that password, such as online shopping accounts or investment accounts, and request free copies of your credit reports from the national credit bureaus.\nUsing a variety of characters in passwords—letters, numbers, symbols—makes them harder to guess or uncover with software.\nIf you see suspicious activity in any of these places, notify the authorities and contact your credit union for help. If you're a victim of identity theft, the Federal Trade Commission's Web site includes information about what steps to take. But remember, the stronger your passwords, the less likely this is to happen.\nHome & Family Finance® Resource Center", "label": 1}
{"text": "Data protection and identity theft\nThe Data Protection Act controls how your personal information is used by corporations or the government. Its rules require everyone who collects data to follow strict rules, and to keep your information safe. This page explains how it works.\nProtecting your information\nThe Data Protection Act's rulesare quite complex, but at the heart of it are eight common sense rules known as the 'data protection principles'.\nThese principles require any organisation, corporation or governmental body that collectspersonal information to handle it safely. Anyone collecting personal information must:\n- fairly and lawfully process it\n- process it onlyfor limited, specifically statedpurposes\n- use the information in a way that is adequate, relevant and not excessive\n- use the information accurately\n- keep the information on file no longer than absolutely necessary\n- process the information in accordance with your legal rights\n- keep the informationsecure\n- never transferthe information outside the UK without adequate protection\nAll organisations collecting and using personal information are legally required to comply with these principles.\nThe law provides stronger protection for more sensitive information - such as your ethnic background, political opinions, religious beliefs, health, sexual life or any criminal history. It is enforced by an independent information commissioner, who can take action against any company or governmental body that fails to protect your information, or that abuses its right to collect and hold that information.\nFinding out who knows what about you\nThe Data Protection Act gives you the right to find out what information about you the government and other organisations store. This is known as the 'right of subject access'. If you submit your request in writing, they are legally required to provide you with a copy of all the information they hold about you.\nSome agencies or corporations may charge a fee for providing the information, but they are only allowed to charge up to 10 for digital information, or 50 for printed (i.e. non-electronic) medical records. Finding out what information about you credit reference agencies hold costs 2.\nStopping direct marketing\nSome people resent the way companies and government agencies contact them directly by phone, post or even fax. You have the right to stop these direct marketing campaigns from using your personal information to contact you.\nAll you have to do is register your details with one of the 'preference services', which allow you to opt out of direct marketing altogether.\nThe links below offer more information about how you can opt out\nThis content is subject to Crown Copyright", "label": 1}
{"text": "Protecting Our Ports\nData devices that plug into computers make many jobs easier, but they can expose networks to attacks.\nAll it takes is one thumb drive or other external data device plugged into a computer to jeopardize the security of information on federal networks. Army officials learned that lesson the hard way in November 2008, when a removable storage device plugged into a computer's Universal Serial Bus port introduced a worm that spewed malicious code across the network. The Defense Department has remained mum on the specifics of the attack, but hackers have used similar types of malware to take control of computers remotely and steal files.\nNow other agencies are trying to find ways to protect their data without sacrificing productivity. External storage devices that plug into a USB port have become ubiquitous in federal government. Employees use thumb drives and handheld computers to transfer files that are too large to e-mail or send over a network, or store documents while working remotely without network access. Military members in the field use flash drives when scarce bandwidth makes it difficult to access critical information on the network.\nThese devices enable employees to do their jobs, but also jeopardize network security.\n\"It's a threat-that's been proven,\" says Pat Howard, chief information security officer at the Nuclear Regulatory Commission. \"It's tough to make the system smart enough to identify what is or is not safe. But you can't say, 'No, you can't do this,' without offering some alternative for meeting business requirements.\" NRC inspectors, for example, often use flash drives when conducting field work.\nTypically, when one talks about the security of removable computer devices, it's in the context of a data breach: An employee downloads from the network sensitive files that are then exposed to unauthorized users, lost or stolen. But that isn't the only risk. Worms and viruses can spread through removable components as easily as through the Internet, and federal cybersecurity requirements don't properly address that risk.\nIn the Army's case, the virus was an AutoRun worm, which installs a file on a thumb drive or other device that is plugged into an infected computer and triggers the Microsoft operating system to execute the worm when the thumb drive is plugged into another computer. Viruses are slightly different, because they require a user to click on an executable file to infect a system. The program then infiltrates the network, as was the case at Army, says Jim Russell, vice president for the public sector at security software company Symantec.\n\"Failure to properly configure [security software] hurts the ability to cleanse the data coming into the network,\" he says. \"With the explosion of these types of devices, the endpoint has become far tougher to manage.\" A 2007 Office of Management and Budget directive provides some guidance for locking down networks by requiring agencies to use a standard set of security settings for the Microsoft Windows operating system.\nBut every infrastructure is different, whether it is for collecting tax information from citizens or sharing intelligence on terrorist suspects, and security policies must address all risks.\nAs of mid-February, the Defense Department still had a temporary ban on removable storage devices. But the USB port is essential for many employees, especially those who spend time in the field.\nThe best strategy for minimizing risk is a combination of tight security policy and multiple layers of protection for the computer network and the removable device.\nFew agencies cover all those bases.\n\"Everyone has a flash drive hanging from around their necks, and there's the capacity for a lot of data to disappear or malware to find its way onto computers-even when the flash drive has been authorized,\" Howard says.\n\"Nothing is certain. Additional controls have to be put in place.\"\nNRC requires all agency files downloaded to a flash drive to be encrypted, and forbids employees from downloading sensitive files to personal storage devices. Long-term plans include technologies that will prevent the download of such files, but for now, Howard has to rely on people to comply and accept the risk that comes with what he calls the \"human element.\"\nTechnology managers must ensure that antivirus and anti-malware software is installed, current and properly configured on all computers.\n\"If you keep patches and antivirus up to date, that's one step to making sure the machines you're working with are a first line of defense,\" says Lou Magnotti, chief information officer at the U.S. House of Representatives.\nAs an alternative to flash drives, House members can use a \"secure vault,\" Magnotti says, that encrypts and stores sensitive documents, such as draft bills and minutes from closed committee meetings, on a network drive that can be accessed remotely. He also is considering purchasing encrypted thumb drives.\nThe interagency Data-at-Rest Tiger Team, which was formed to lead data encryption policy and acquisition efforts, is weighing whether to incorporate anti-malware protection into blanket purchase agreements, says Dave Hollis, director of the tiger team and cyberspace programs for Defense's Information Assurance program. Anti-malware would enable technologists to prevent malicious programs from launching.\n\"Locking all doors and hardening the targets is critically important,\" says Christopher Painter, deputy assistant director of the FBI's cyber division. \"But everyone recognizes that no matter how well you do that, there will be persistent attackers that will get into systems. . . . It's easier to play offense, because you can focus on one hole to get through. In defense, you need to protect everything.\"", "label": 1}
{"text": "Simple Smartphone Safety Tips for Kids\nmobilesecurity.com [London, UK] It’s back to school time again, and despite a natural reluctance to return to the classroom, pupils are keen to catch up with friends and share their news from the summer break. Marian Merritt, Norton Internet Safety Advocate, offers some essential tips for parents who might be sweetening the deal by getting their kids new cell phones or even a first cell phone as part of the school preparations.\n1. Set a password on the phone to lock the keypad and screen when not in use.\n2. Set up parental and emergency contacts on the phone, and show your child how to access them.\n3. Review school cell phone policy with your child.\n4. Discuss not clicking links or replying to unknown callers or text messages.\n5. Set rules for selecting, purchasing new apps and games.\nA smartphone can be a lifeline to safety, a gaming device and an educational tool, and we all have a responsibility to make sure children understand the right way to use these devices. Read all ten tips on Marian’s full article on the Ask Marian page at Norton.com, and find time to sit down and discuss the topic with your children. Let’s all help youngsters understand that smartphones can be great fun when they pay attention to a few simple rules.", "label": 1}
{"text": "Us Online v2 is activity-based learning (K-10) about the safe, ethical and responsible use of digital technologies … interactive learning plus teacher resources about cyber-bullying, privacy and identity fraud, networking and gaming, using the web for research, making and posting content, tagging photos, copyright and sharing, security and passwords, viruses and malware, file-sharing and more.\nNo Bullying Here consists of two modules, each with activity-based learning about bullying, rights, and respect – one for Lower Primary (K-3) and one for Upper Primary (4-6) … with interactive learning and fully resourced Teacher Centres that explore the issues of cyber-bullying, verbal, physical and social bullying.\n- Multiple Intelligence Theory\n- Roar recommendations to Cyber-Safety Inquiry\n- The internet is one giant job resume\n- Tackling the seedy cyber-underbelly\n- Should there be limits on students’ screen time?\n- Did You Know 4.0 [VIDEO]\n- Millenials will make ‘sharing’ a lifelong habit, says Pew study\n- Roar Showcase [VIDEO]\n- Next Generation Learning [VIDEO]", "label": 1}
{"text": "In order to prevent the exposure of confidential data, consider the following measures: securing your computer, monitoring the major identity information sources, preventing unauthorized exposure of your personal information. It is also important to receive frequently updated detailed information on the latest risks, scams, and prevention measures.\nPlatform Windows 95/98/ME\nOperating Systems Windows 95/98/ME,Windows NT/2000,WindowsCE,Windows XP,Windows NT/2000/2003/SBS2003,Windows Vista\nSystem Requirements MS Excel\nDate added 27 Aug 2007\nLast Updated 24 Jan 2011\nTags identity theft risks metrics,identity theft risks scorecard,identity theft risks balanced scorecard,identity theft risks kpi,identity theft risks performance,identity theft risks measure,identity thef", "label": 1}
{"text": "Part 1 – PC Security and Common Sense\nThis article is part one of a two part series on computer security. Part two will feature network security, online security, and encryption.\nIn the good ‘ol days of the Internet, programmers who wrote viruses used to do it for the mischievous sense of accomplishment and respect of their hacker-culture peers. These days, however, viruses and malware are big business for organized crime. What this means for you is that viruses are no longer a nuisance, they are meant to steal valuable information without you ever knowing it. What to do to stop the attacks? Security for your home or office computer network is one of those topics that can go from the very basic to the infinitely complex. For 99% of us, though, a few simple strategies will secure your computer and its data against 99% of the threats you’ll run across.\nYour PC is the destination for all the viruses, malware, keyloggers, trojans, rootkits and any number of other malicious software. The best defense against these threats is AntiVirus software from a reputable vendor. There are several great vendors that offer free versions of their Anti-Virus software. These free versions are only for home use (not office) and may lack some functionality such as scheduled scans or advanced settings, but they use the exact same scanning system as their paid-for counterparts.\nAt MAR’s office we use a product called Vipre from Sunbelt Software. This software is a comprehensive and inexpensive alternative to many of the more well-known vendors out there: http://www.sunbeltsoftware.com/home-home-office/vipre/\nSimilarly, keeping your Windows, Mac or Linux operating system up to date is critical because these updates often block security holes that viruses use to infect your computer. Macs are not necessarily safer than PCs when it comes to viruses, they are just less of a target because they represent less of the market for stolen data. As Mac’s presence grows, so will the number of people making malicious programs to infect the Mac OS. By keeping updated on the latest updates you can protect many of the hidden entrances to your computer.\nAll the security software in the world won’t help you if you leave the front door open. Similarly, an ounce of skepticism when online will do more for your computer security than any antivirus software on the market. A few tips:\nNever open email attachments from unknown senders. A big danger comes around holidays when people start sending emails to “view the attached holiday card”. Criminals know this too, and send viruses as email attachments inviting you to watch the latest Valentines e-card. Similarly, if you receive an email inviting you to view an online birthday card, and it’s not your birthday, be very suspicious.\nBeware of phishing. Phishing is a scam where an email pretends to be from a legitimate source (like your bank, ebay, Paypal, etc) but is actually from a scam website made to look like the legitimate destination. These phishing sites will ask you to “login to verify” some type of information. What they are really doing is recording the username and password to your REAL bank website. Keep in mind that all banks are aware of this scam and will never ask you to “login to verify” or “login to update” anything using links in an email. If you suspect an email is legitimate the safest way to approach it is to open a new browser (Internet Explorer, Firefox, etc) and type in the address of the site you want to visit. Never use a link in an email message to any sensitive website because it’s very difficult to see where you’re actually going to end up. By typing in the address for BankOfAmerica.com you can rest assured you will end up at the actual BoA website.\nBeware of “Fake” Antivirus and other free software. A scourge of the Internet is pop-up ads that warn you of a virus on your computer, and then invite you to download a free utility to clean out the infection. Quite often these programs actually install viruses on your PC instead of clean them. One of the most notable examples of this is the “Antivirus 2009” virus which sports graphics and layout very similar to Windows. It runs fake scans on your computer, shows you fake infections, and then downloads real viruses to your PC. The best way to avoid these maladies is to never use a pop-up ad to visit a website or purchase a product because you can’t be sure of the source of the pop-up.\nA real-life equivalent might be walking down the street when a complete stranger asks you if you want a free gold watch. All you have to do is walk with this stranger into a dark alley to receive your prize. Would you do it?\nOther free software such as games, screensavers, and search toolbars often contain adware, which is a less-malicious form of software meant to show you pop-ups even when you aren’t browsing the Internet. This software can sometimes be a doorway to other more unsavory programs, so be very cautious about the source of your next screensaver of puppy pictures.\nLike I said at the beginning, computer security is one of those topics you can follow to an extreme degree. Many specialists devote their lives to securing large company networks against those who devote their lives to breaking in. You have advantages on your side, though. As an end user you are not likely to be the target of a serious hacker; your relative anonymity will protect you to a certain degree. What you should worry about are the automated programs designed to trick you into letting them inside. Luckily these programs are not yet as savvy as live criminals at the digital con game. Using just a few of the techniques I’ve outlined can go a long way toward keeping you, and your most personal data, safe.\nThis article is part one of a two part series on computer security. The state of Massachusetts is currently reviewing regulations that would enforce strict new requirements on data security and the privacy of client data at many businesses across the state. The final requirements of the law, however, are still in flux. The MAR is watching the proposed regulations closely and will provide tools and resources to help you and your business comply. In the meantime, good security practices should be a part of everything you do online whether at home or in the office.", "label": 1}
{"text": "What is a limited user account?\nA limited user account in Windows gives specified users the ability to only utilize certain programs and functions on their computers. People with limited user accounts are also unable to download or delete certain applications on their computer or while online.\nThere are a number of reasons and benefits for setting up limited user accounts, including:\nIncreased security. Even with firewall and anti-virus protection, harmful malware can still find its way onto a computer. This is especially true if users are downloading programs such as active x or visiting sites that install spyware while surfing the net. With the limited access limited user accounts provide, the likelihood of malware on the computer is much lower.\nAdded protection. Because users with a limited user account are unable to delete or add applications and programs, computer owners can have the confidence of knowing the computer will remain undefiled.\nWhat can you do with a limited user account?\nLimited user accounts still allow users to do pretty much everything needed to run their computer and complete day-to-day tasks. Some of the things users can still do, even with a limited user account, include:\nUse programs like Microsoft Word, Excel, and Power Point.\nUse programs that allow users to listen to music or edit photographs\nSurf the Internet and send and receive emails\nChange the passwords and pictures on the account\nWhat can you not do with a limited user account?\nThere are a number of things, as the name suggests, that users who are on a limited user account can’t do. Some of these things include:\nInstall software or hardware. New software and hardware programs must be installed by an administrator on a limited user’s account.\nChange the name or account type. Users with a limited user account on Windows are unable to change their name. In addition, they can’t change the account type (such as removing the limited user account status).\nDownload certain applications from the Internet. Limited user account users are unable to download specific Internet applications and programs. This helps protect the computer and system from malware.\nSetting up a limited user account\nYou can set up as many limited user accounts as you need to for your employees or family members. To set up a limited user account, follow these steps. Note: You must be an administrator or have administrator rights in order to set up limited user accounts.\n1. In Windows, click Start, and then select the Control Panel option.\n2. Click on User Accounts. A number of selections will come up. Select Pick a Task, then Create a new account.\n3. The Action menu will come up. Select New User.\n4. Type in the user’s name, then click Next.\n5. Under Pick an account type, select Limited User, and then click Create account.\n6. Your user will be able to select his or her own password and pictures.\nLimited user accounts are helpful for employers and are a good way to protect your computer, information, and system from the threat of being hacked or from malware being installed on your computers. If you have problems or questions setting up you limited user accounts, the Windows website is very helpful.", "label": 1}
{"text": "By David Keaton,\nThe CERT Secure Coding Program\nBuffer overflows—an all too common problem that occurs when a program tries to store more data in a buffer, or temporary storage area, than it was intended to hold—can cause security vulnerabilities. In fact, buffer overflows led to the creation of the CERT program, starting with the infamous 1988 “Morris Worm” incident in which a buffer overflow allowed a worm entry into a large number of UNIX systems. For the past several years, the CERT Secure Coding team has contributed to a major revision of the International Organization for Standardization (ISO) and International Electrotechnical Commission (IEC) standard for the C programming language. Our efforts have focused on introducing much-needed enhancements to C and its standard library to address security issues, such as buffer overflows. These security enhancements include (conditional) support for bounds-checking interfaces, (conditional) support for analyzability, static assertions, “no-return” functions, support for opening files for exclusive access, and the removal of the insecure gets() function. This blog posting explores two of the changes—bounds-checking interfaces and analyzability—from the December 2011 revision of the C programming language standard, which is known informally as C11 (each revision of the standard cancels and replaces the previous one, so there is only one C standard at a time).\nI work on the CERT Secure Coding team, where I’ve made technical contributions to the definition of the new C features for addressing security. I’ve also chaired Task Group PL22.11 (programming language C) of the International Committee for Information Technology Standards (INCITS), representing the United States. Working with SEI colleagues Robert C. Seacord and David Svoboda, I helped develop, refine, and introduce many of the security enhancements to this major ISO standard revision.\nBounds Checking Interfaces\nUntil the latest update of the C standard, its security features had been limited to the snprintf() function, which was introduced in 1999 and whose implementations have some quirks. Previous iterations of the C library contained functions that did not perform automatic bounds checking. Instead, C library implementations assume programmers provide output character arrays that are large enough to hold the result and return a notification of failure if they were not large enough.\nThe C standard now includes a library that provides extensions that can help mitigate security vulnerabilities, including bounds-checking interfaces. For example, the strcpy() copy function in previous versions of the standard C library did not check the bounds of the array into which it was copied. A buffer overflow will occur, therefore, if a programmer uses strcpy() to copy a larger string into a small array and does not explicitly check the bounds of the array prior to making the call to strcpy().\nOne remedy to the strcpy() problem is to use the strncpy() function, which provides bounds, but won’t terminate the string with a null character (whose value is 0) if there’s insufficient space. Situations like this create a vulnerability because data can be written past the end of the array, overwriting other data and program structures. This buffer overflow vulnerability can be (and has been) misused to run arbitrary code with the permissions of the defective program. If the programmer writes runtime checks to verify lengths before calling library functions, then those runtime checks frequently duplicate work done inside the library functions, which discover string lengths as a side effect of doing their job. The new bounds-checking interface provides strcpy_s(), a more secure string copy function that not only checks the bounds of the array that it is copying into, but also ensures that the string is terminated by a null character.\nAnother aspect of the C programming language we focused on in C11 is analyzability, which deals with so-called “undefined” behavior. Undefined behavior arises when a programmer uses a nonportable or erroneous program construct or erroneous data for which the C standard does not impose a requirement. The C standard includes several areas of the C language with undefined behavior because behavior of those areas depends on compiler implementation details. An example is signed integer overflow. Different hardware behaves differently on signed integer overflow, so trying to make the language mandate one method of dealing with it would negatively affect performance on some systems because the standard behavior would not match what the hardware does.\nThere are many areas in which the standard makes accommodations for various kinds of hardware, and they are all lumped together into the undefined behavior category. Since the C standard doesn’t constrain how a compiler implements undefined behavior, it could conceivably do anything, such as cause the machine to halt and catch fire, though compiler writers who do this might not find many professional programming customers!\nWe examined this issue and realized that in practice, there are two categories of undefined behavior:\n- behavior for which we really cannot say what will happen, such as storing data outside the bounds of an object, and\n- behavior where the implementation really should do something reasonable, such as signed integer overflow\nWe created the Analyzability Annex in C11, in which we labeled the former behavior \"critical undefined behavior,\" indicating that the consequences could be serious. The latter category we called \"bounded undefined behavior,\" because we can say with certainty that nothing unpredictable should be allowed to happen as a result.\nThe category of critical undefined behavior is a small subset of undefined behavior, which means that most undefined behavior becomes bounded. We didn't have to change the spirit of the C language to do this, because all we did was specify that bounded undefined behavior is not allowed to store data outside the bounds of an object. In the example of signed integer overflow, this means the compiler runtime implementation could choose to return some reasonable result, cause a trap that terminates the program, or simply print a message and move on. As long as it does not perform an out-of-bounds store, anything is permissible.\nThe bounding of undefined behavior allows analysis tools to know that a C program will not have unpredictable behavior except in a very small set of circumstances, which is why we called it the Analyzability Annex.\nOther Areas of Research\nWhile our work to date has focused on the ISO C standard and helping programmers prevent critical undefined behaviors, the CERT secure coding team has also been working on the CERT C Secure Coding Standard, which contains a set of rules and guidelines to help programmers code securely. Those guidelines, which will be the subject of an upcoming blog post, leverage our work on the ISO standard to help programmers avoid undefined behavior, as well as behavior that programmers might not have expected when writing their code.\nThe CERT C Secure Coding Standard also serves as a foundation for the Source Code Analysis Lab (SCALe), which is our software auditing service that can be used to find vulnerabilities and weaknesses in any codebase. SCALe uses a suite of static analysis and dynamic analysis tools to find vulnerabilities in a codebase, based on the patterns and guidelines defined in the CERT C Secure Coding Standard.\nFor more information about the new ISO standard for the C programming language, please visit\nThe C standard is available for purchase in the ANSI Web Store.\nFor more information about the work of the CERT Secure Coding Team, please visit\nFor more information on the CERT Source Code Analysis Lab (SCALe), please visit", "label": 1}
{"text": "Lifehacker's tech-savvy readers are the first people on speed-dial when it's time to heal an infected PC, but how much do you really know about viruses, spyware, scareware, trojans, and worms? Here's a helpful guide to understanding all the different types of malware.\nThe point of today's lesson, of course, is to help you teach your friends and family more about the different types of malware, and debunk a few of the common myths about viruses. Who knows, maybe you'll learn a thing or two as well.\nWhat is Malware?\nThe word Malware is short for malicious software, and is a general term used to describe all of the viruses, worms, spyware, and pretty much anything that is specifically designed to cause harm to your PC or steal your information.\nViruses Wreak Havoc On Your Files\nThe term computer virus is often used interchangeably with malware, though the two don't actually have the same meaning. In the strictest sense, a virus is a program that copies itself and infects a PC, spreading from one file to another, and then from one PC to another when the files are copied or shared. Image by Joffley\nMost viruses attach themselves to executable files, but some can target a master boot record, autorun scripts, MS Office macros, or even in some cases, arbitrary files. Many of these viruses, like CIH, are designed to render your PC completely inoperable, while others simply delete or corrupt your files—the general point is that a virus is designed to cause havoc and break stuff.\nYou can protect yourself from viruses by making certain your antivirus application is always updated with the latest definitions and avoiding suspicious looking files coming through email or otherwise. Pay special attention to the filename—if the file is supposed to be an mp3, and the name ends in .mp3.exe, you're dealing with a virus.\nSpyware Steals Your Information\nSpyware is any software installed on your PC that collects your information without your knowledge, and sends that information back to the creator so they can use your personal information in some nefarious way. This could include keylogging to learn your passwords, watching your searching habits, changing out your browser home and search pages, adding obnoxious browser toolbars, or just stealing your passwords and credit card numbers.\nSince spyware is primarily meant to make money at your expense, it doesn't usually kill your PC—in fact, many people have spyware running without even realizing it, but generally those that have one spyware application installed also have a dozen more. Once you've got that many pieces of software spying on you, your PC is going to become slow.\nWhat many people don't realize about spyware is that not every antivirus software is designed to catch spyware. You should check with the vendor to make sure the application you are using to protect you from malware is actually checking for spyware as well. If you come across a PC that is already heavily infected, run a combination of MalwareBytes and SuperAntiSpyware to clean it thoroughly.\nScareware Holds Your PC for Ransom\nScareware is a relatively new type of attack, where a user is tricked into downloading what appears to be an antivirus application, which then proceeds to tell you that your PC is infected with hundreds of viruses, and can only be cleaned if you pay for a full license. Of course, these scareware applications are nothing more than malware that hold your PC hostage until you pay the ransom—in most cases, you can't uninstall them or even use the PC.\nIf you manage to come across a PC infected with one of these, your best bet is to Google the name of the virus and find specific instructions on how to remove it, but the steps are usually the same—run a combination of MalwareBytes, SuperAntiSpyware, and maybe ComboFix if you need to.\nFor more on scareware, including a full walk-through of how a PC actually gets infected in the first place, check out the guide I wrote on removing Internet Security 2010 and other fake antivirus malware.\nTrojan Horses Install a Backdoor\nTrojan horses are applications that look like they are doing something innocuous, but secretly have malicious code that does something else. In many cases, trojans will create a backdoor that allows your PC to be remotely controlled, either directly or as part of a botnet—a network of computers also infected with a trojan or other malicious software. The major difference between a virus and a trojan is that trojans don't replicate themselves—they must be installed by an unwitting user. Image by otzberg\nOnce your PC has been infected with the trojan, it can be used for any number of nefarious purposes, like a denial of service (DoS) attack against a web site, a proxy server for concealing attacks, or even worse—for sending out buckets of spam. Protection against trojans works the same way as viruses—make sure that your antivirus application is up to date, don't open suspicious attachments, and think long and hard before you try and use a downloaded crack for Photoshop—that's one of malware authors' favorite spots to hide a trojan.\nWorms Infect Through the Network\nComputer worms use the network to send copies of themselves to other PCs, usually utilizing a security hole to travel from one host to the next, often automatically without user intervention. Because they can spread so rapidly across a network, infecting every PC in their path, they tend to be the most well-known type of malware, although many users still mistakenly refer to them as viruses. Image by me and the sysop\nSome of the most famous worms include the ILOVEYOU worm, transmitted as an email attachment, which cost businesses upwards of 5.5 billion dollars in damage. The Code Red worm defaced 359,000 web sites, SQL Slammer slowed down the entire internet for a brief period of time, and the Blaster worm would force your PC to reboot repeatedly.\nBecause worms often exploit a network vulnerability, they are the one type of malware that can be partially prevented by making sure your firewall is enabled and locked down—you'll still need an updated antivirus software, of course.", "label": 1}
{"text": "An Australian-led research team said Thursday they had made a technological breakthrough in the race for a quantum supercomputer that could revolutionise data encryption and medicine.\nEngineers make quantum devices at the Australian National Fabrication Facility at the University of New South Wales in Sydney in this undated photo. The Australian-led research team said they had made a technological breakthrough in the race for a quantum supercomputer that could revolutionise data encryption and medicine.\nEngineers from Sydney's University of New South Wales said they had created the first working quantum bit or qubit -- the fundamental unit of a quantum supercomputer -- with the findings published in the latest edition of Nature.\nLead researcher Andrew Dzurak said the team used a microwave field to gain unprecedented control over en electron bound to a single phosphorous atom that was implanted in a silicon transistor device.\nThey were able to both write and read information using the electron's spin, or magnetic orientation, which Dzurak said was a \"key advance towards realising a silicon quantum computer based on single atoms\".\n\"This is a remarkable scientific achievement, governing nature at its most fundamental level, and has profound implications for quantum computing,\" Dzurak said.\nQuantum computing, the next generation in information technology, harnesses the power of atoms and molecules to perform calculations and store data, with the potential to be millions of times more powerful than the most advanced modern computers.\nDzurak's research partner Andrea Morello said quantum computers, which could run one million parallel computations at once compared with a desktop PC's single-computation capacity, could do things that were currently impossible.\n\"These include data-intensive problems, such as cracking modern encryption codes, searching databases, and modelling biological molecules and drugs,\" he said.\nMorello said the study was significant because it was the first time silicon had been used -- a well understood and easily accessed material.\n\"Our technology is fundamentally the same as is already being used in countless everyday electronic devices, and that's a trillion-dollar industry,\" he said.\nThe next step is to combine qubit pairs into a \"logic gate\", which would be the basic processing unit of a quantum computer, a fully functioning model of which is likely still to be five to 10 years off.\nThe research is being funded by the Australian government, the US Army, the New South Wales state government, the University of New South Wales and the University of Melbourne.\nLatest stories in this category:\n- 'Kill Mittal' game capitalises on French workers' struggle\n- Facebook joins Web freedom group\n- Solar plane aims for new world distance record\n- Sony board examines hedge fund spin-off plan\n- Risky behaviour starts young on social media: survey\n- Teens share more online, see privacy issues: study\n- China arrests 13 over protest 'rumours'\n- Sprint lifts bid for Clearwire in broadband battle", "label": 1}
{"text": "What is a service-oriented architecture?\nFor completeness we include two different definitions, one from W3C: “A set of components which can be invoked, and whose interface descriptions can be published and discovered.”\nAnd a second from LooselyCoupled: “A system for linking resources on demand. In an SOA, resources are made available to other participants in the network as independent services that are accessed in a standardized way. This provides for more flexible loose coupling of resources than in traditional systems architectures.”\nWhat are Web Services?\nFor completeness we include two different definitions, one from W3C: “A Web service is a software system designed to support interoperable machine-to-machine interaction over a network. It has an interface described in a machine-processable format (specifically WSDL). Other systems interact with the Web service in a manner prescribed by its description using SOAP, typically conveyed using HTTP with an XML serialization in conjunction with other Web-related standards.”\nAnd a second from LooselyCoupled: “Automated resources accessed via the Internet. Web services are software-powered resources or functional components whose capabilities can be accessed at an internet URI. Standards-based web services use XML to interact with each other, which allows them to link up on demand using loose coupling.”\nWhat is Web Services Management?\nWeb Services Management is a title used by the Gartner group to describe a market for solutions that facilitate the deployment of Web services. The term has become very broad and encompasses a wide range of different capabilities, implemented to varying degrees by a number of vendors.\nAt a minimum, Web Services Management solutions provide service performance and availability monitoring, often extending to provide service level agreement (SLA) monitoring.\nSome solutions build on monitoring to provide management and enforcement of service level agreements. While others focus on Web Services Security management and enforcement.\nSOA Software offers comprehensive monitoring and management (including very advanced identity-based SLA contracts, the strongest Web Services Security solution on the market, and extends the concept of Web Services Management with a powerful SOA Enablement solution.\nThe OASIS standard WS-Security is defined by LooselyCoupled as a Standards framework for secure web services, based on SOAP. WS-Security defines additional headers that can be added to a SOAP message to implement integrity and confidentiality in web services applications. It provides a foundation for further security specifications that are under development, including WS-Policy, WS-Trust and WS-Federation. Originally put forward by IBM, Microsoft and Verisign, WS-Security became the responsibility of the OASIS e-business standards body in July 2002.\nAs a market, Web Services Security refers the set of technology solutions that enhance security, including authentication, authorization, privacy, non-repudiation and auditing, for Web services. These solutions are available in many forms ranging from XML Firewall appliances through enterprise software solutions from many different vendors.\nSOA Software offers a best-of-breed enterprise software solution for Web Services Security. SOA Software ’s advanced software delivers performance that exceeds that of many of the XML firewall appliance solutions. It also delivers much richer security from network edge to core.\nService oriented architecture enablement, or as Zapthink discusses, the SOA Implementation Framework, is an emerging technology concept that goes beyond Web Services Management to unlock the value of Web services. The promise of Web services is to enable the agile enterprise through service reuse within a service oriented architecture.\nWithout an SOA enablement solution, much of this promise falls by the wayside as developers are unable to comply with changing security and management policy and cannot keep track of changing service interfaces and locations.\nSOA Software’s industry-leading Service Manager delivers a comprehensive SOA enablement solution that offers all the capabilities of traditional Web Services Management solutions and adds:\n- Dynamic discovery and real-time implementation of service requirements for security:\n- Message auditing\n- Dynamic discovery of, and binding to, service location\n- Powerful load-balancing and high-availability\n- Real-time monitoring and enforcement of identity-based service level agreement contracts\n- An adaptive, self-healing network of services\nIn short, the Service Manager fully abstracts service and application developers from any required knowledge of central management and security policy.\nWhat is the difference between ESB, XML Firewall and Web Services Management providers?\nAt a high level there is very little difference. SOA Software believes that the distinction between these terms, and the terms themselves are transitory. To clarify, the terms exist as a result of different market sectors approaching the common problem of Web Services Management, or SOA Enablement; the EAI companies created ESB to highlight their value as a messaging system while the hardware vendors invented the XML Firewall due to the market’s familiarity with the traditional firewall. As we move forward, SOA Enablement will exist as a ubiquitous fabric that exists to abstract multiple transports, platforms and deployment scenarios.\nFrom www.searchwebservices.com: “Firewalls have long been a mainstay of corporate security - but when it comes to Web services, they may well provide no security at all, because they can only filter at the packet level, and can't examine the contents of messages. Considering that Web services traffic may account for 25 percent of all enterprise traffic by 2006 according to the ZapThink Web services consulting group, that is a serious problem for any business looking to use Web services.\nXML firewalls promise to protect corporations against the unique dangers and intrusions posed by Web services. These firewalls can examine SOAP headers and XML tags, and based on what they find, distinguish legitimate from unauthorized content.”\nMost XML Firewalls are implemented as hardware/software appliances that package Web services intermediary software with a rack mountable server.\nAn intermediary is a server (software or hardware – see XML Firewall) that sits between a web service consumer and provider endpoint. In the case of Web Services Management intermediaries, the intermediary provides varying degrees of security and monitoring functions.\n“A SOAP intermediary is both a SOAP receiver and a SOAP sender and is targetable from within a SOAP message. It processes the SOAP header blocks targeted at it and acts to forward a SOAP message towards an ultimate SOAP receiver.”\nSOA Software’s Management Point is a powerful, extremely high performance software appliance providing rich Web Services Management, Web Services Security and SOA enablement functionality.\nA Service Level Agreement (SLA) provides advanced monitoring capabilities for services and operations to ensure that they meet pre-defined operational requirements.\nSOA Software’s Service Manager implements very rich and powerful SLA monitoring with unique enterprise-class features. The distributed data collection combined with centralized analysis employed by the Service Manager ensures comprehensive, accurate performance monitoring. The Service Manager defines SLA policies that can then be applied by reference or copy to an operation or service. This provides the flexibility to be able to define central performance and availability monitoring policies that, when changed, will affect all services or operations to which they the policies have been applied.\nSLA policies can be defined for many criteria including, throughput, response time, availability, number of errors, etc.\nA contract is an agreement of a set of terms between various parties. The Service Manager uses contracts for various high-value functions. It implements both access contracts and SLA contracts.\nAn access contract is used to define highly granular rule about how a particular user, group or role and can access a service or operation. It can be used to control how many times, how frequently and at what times a user may access a particular operation. For example, the system could only allow a user to use a particular service 10 times per minute during business hours, but unlimited outside those hours. Or a user may only be allowed to use a service 100 times before being denied access.\nAn SLA contract closely models a real-world SLA by monitoring the performance of a service or operation as seen by a particular user, group or role. This allows the creation and monitoring of agreements for different user groups for the same services. For example one group of users may need a contractual commitment that a particular operation will always respond in less than 50ms to its messages, while another may want to guarantee that it will always be able to get more than 400 messages per second through a particular service.\nThese identity-based contracts are a unique feature of the Service Manager, made possible by its tight integration with identity management solutions.\nWhat is the difference between monitoring and management?\nMonitoring is the process of collecting and reporting on data. In the case of Web Services Management, monitoring typically refers to the collection and charting of performance and availability data, and in some cases security (access) data.\nManagement adds enforcement to monitoring. In Web Services Management, enforcement normally refers to security or network enforcement. Security enforcement is the process of authenticating users and making authorization decisions about the users' right to access a resource. Network enforcement is less common and should involve combining content-based routing and message throughput throttling with SLA monitoring.\nThe Service Manager is the only Web Services Management and SOA enablement solution that implements an adaptive infrastructure leveraging this concept of network enforcement.\nWhy do I need Web services management?\nThe promise of Web services is to enable the agile enterprise through service reuse within a service oriented architecture. Without an SOA enablement, or Web Services Management solution, much of this promise fails as developers are unable to comply with changing security and management policy and cannot keep track of changing service interfaces and locations.\nSpecifically, you need SOA Enablement and Web Services Management to:\n- Ensure that application developers are abstracted from service endpoint and infrastructure policy requirements\n- Provide comprehensive end-to-end security\n- Guarantee that services perform to contractually agreed, or policy defined availability and performance metrics.\nWhen should I think about using a Web Services Management system?\nThis is a “how long is a piece of string question”. Depending on the criticality and value of deployed Web services some organization should implement SOA Enablement and Web Services Management before conceiving their first Web services. Other organizations may be comfortable with insecure, unmanaged services for a long period. There is no clear rule of thumb, other than the obvious statement that without Web Services Management and SOA Enablement Web services will not be secure and will likely not live up to application developers performance and availability requirements.\nHow does Web Services Management fit into my existing infrastructure?\nThe Service Manager is completely non-intrusive. It operates using standalone and agent based intermediaries to ensure that messages are authenticated, routed and authorized appropriately. It uses powerful SLA and contract management technologies to dynamically adjust the network to ensure performance and availability without ever requiring a developer to be aware of the fabric.\nHow does Web Services Management Security fit in with my existing security and policy systems?\nThe Service Manager can implement its own user and policy store (commonly used to manage application identities), and/or it can tightly integrate with existing 3rd party identity and policy management systems extend their reach into Web services.\nHow does Web Services Management integrate with existing applications?\nThe Web Services Management solution should integrate transparently with existing client and server applications in order to abstract much of the complexity of security and message delivery and simplify the development task. The Web Services Management solution can be deployed as a proxy that intercepts the Web service calls without any changes to the application code. On Java and .NET applications, the agent can also be deployed with no changes to the application code by making a few simple declarative changes to the environment.\nHow does Web Services Management integrate with new applications?\nThe Web Services Management solution offers a great deal to developers of new applications by providing a fabric that abstracts much of the complexity of security and message delivery and simplifies the development task. Making use of the Web Services Management solution can be done during development or added later as described above.\nHow does Web Services Management & Web Services Security fit into my Netegrity environment?\nWeb Services Security solution will inevitably need to authenticate users and roles and make authorization decisions about granting access to services and operations. It is essential that the Web Services Management and Security solution is able to integrate with an existing identity-management infrastructure for authentication and most authorization decisions.\nThe Service Manager offers the closest integration with Netegrity in the industry. It can either integrate at an intermediary level, or via it’s powerful built-in Policy Manager. When integrating at the Policy Manager it can leverage identity for security and management tasks. See contracts.\nHow do I manage B2B communication?\nB2B communication brings a number of interesting challenges to the SOA, including the requirement to manage Service Level Agreement and provisioning contracts. In addition to this, you need to manage the routing of external requests through your DMZ to your internal applications. A good WSM solution will provide both the means to effectively and transparently route transactions as well as the means to manage the business agreements (SLAs and provisioning contracts) that you have set up with your partners.\nHow do I secure B2B communication?\nB2B communication raises two important security concerns. Firstly the transactions may be occurring over the Internet, resulting in an increased security risk. Secondly, the partner identities and their access rights need to be closely managed. Your WSM solution should therefore provide all the features of an XML firewall, such as:\n- High performance\n- Schema validation\n- Attack prevention\n- Authentication and authorization\n- Centralized policy management\nAdditionally, the WSM solution should be capable of associating partner identities with their provisioning contracts and Service Level Agreements\nDoes Web Services Management provide orchestration?\nBefore answering this question it is important to first describe the concept of orchestration.\nFrom a Hewlett Packard White Paper “Web Services Orchestration - A Review of Emerging Technologies, Tools, and Standards”:\n“The industry has used a number of terms to describe how components can be connected together to build complex business processes. Workflow and document management systems have existed as a means to handle the routing of work between various resources in an IT organization. These resources might include people, systems, or applications, and typically involve some human intervention. Business process management systems (BPMS) have also been used to enable a business to build a tops-down process design model, consisting of various integration activities (e.g., integration to a legacy system). BPMS systems would typically cover the full lifecycle of a business process, including the modeling, executing, monitoring, management, and optimization tasks. With the introduction of web services, terms such as “web services composition” and “web services flow” were used to describe the composition of web services in a process flow. More recently, the terms orchestration and choreography have been used to describe this. Orchestration describes how web services can interact with each other at the message level, including the business logic and execution order of the interactions. These interactions may span applications and/or organizations, and result in a longlived, transactional, multi-step process model. Choreography tracks the sequence of messages that may involve multiple parties and multiple sources, including customers, suppliers, and partners.\nChoreography is typically associated with the public message exchanges that occur between multiple web services, rather than a specific business process that is executed by a single party. There is an important distinction between web services orchestration and choreography. Orchestration refers to an executable business process that may interact with both internal and external web services. For orchestration, the process is always controlled from the perspective of one of the business parties. Choreography is more collaborative in nature, in which each party involved in the process describes the part they play in the interaction. Many of the standards that will be discussed in this paper initially focused on either orchestration or choreography. However, recent enhancements and standards convergence has somewhat blurred this distinction. In this paper, the term web services orchestration will be used to describe the creation of business processes, either executable or collaborative, that utilize web services.”\nWhile some Web Services Management solutions may provide Orchestration and Choreography functions, these would more typically be provided by a Business Process Management solution.\nIs Web Services Management only important if I have a Heterogeneous environment?\nNo, SOA Enablement and Web Service Management adds considerable value to any environment. The concept of abstracting developers from security and management policy requirements in the network and at the service endpoints is independent of development platform. Just because consumer and endpoint applications are both implemented using .NET, or BEA doesn’t mean that they automatically understand each other, and can automatically adapt to changes.\nSOA Software’s Web Services Management solution ensures the performance and availability of services using powerful failover and load balancing technologies combined with industry-leading service level agreement management and monitoring. Essentially, the Web Services Management fabric will detect impending failures or performance problems and will make appropriate routing and throttling decisions to ensure that service levels are maintained for high value or importance transactions.\nWhat is needed to deploy Web Services Management?\nDepending on the Web Services Management vendor, deployment will usually involve some central policy server(s) and software and distributed intermediaries. The intermediaries may be hardware/software appliances, standalone servers running specialized software, or a “agent” deployed with the Web service itself.\nAgain, depending on the vendor, the Web Services Management solution should not be intrusive.\nWhat is the fabric?\nThe fabric is a representation of the Web Services Management and SOA enablement infrastructure. It provides a visual concept that facilitates understanding of what Web Services Management is and does.\nDo I need to change my applications to use Web Services Management?\nDepending on the Web Services Management vendor, the solution should be completely non-intrusive.\nThe Services Manager delivers a fully non-intrusive comprehensive Web Services Management and SOA enablement fabric.\nWhat are the performance implications of Web Services Management?\nThis completely depends on the Web Services Management vendor and the architecture of the complete solution. The functions of Web Services Management; security, monitoring, enforcement, enablement, all need to be done somewhere in an SOA. A well-architected solution will externalize these functions from the applications to ensure consistent application of policy.\nThe Service Manager is an extremely high performance solution. In monitor mode, the Management Point operates at zero-latency (any added latency is not measurable). In intermediary mode where is it enforcing management and security policy it has been tested under heavy load and demonstrated sub millisecond latencies. To put this into perspective, most Web services themselves will operate with 100-200 millisecond response times, some taking several seconds to respond. In this environment, the Web Services Management fabric is increasing latency by less than 1/10th of a percent.\nFurthermore, a well-architected Web Services Management solution will constantly monitor performance and will increase the perceived performance of the Web services network through intelligent routing.\nDynamic binding is the process whereby a Web service consumer discovers the location (and in some cases the policy requirements) of a Web services immediately prior to invocation and connects to it based on this up-to-date information.\nDynamic binding is essential for the functioning of an agile enterprise. Without dynamic binding service consumers will use hard-coded endpoint information and will fail in the event of any change being made to the service endpoint.\nHow can I make my Web services secure?\nThere are many approaches to securing Web services. The Service Manager implements one of the most secure and flexible approaches by deploying agent-based intermediaries with each Web service, and forcing all messages to pass through the intermediary for authentication and authorization.\nHow can I make my Web services reliable?\nThe Service Manager’s approach to Web Services Management delivers powerful failover and load-balancing technologies to ensure service availability. As the solution begins to detect performance or availability problems it will automatically adjust traffic to ensure that high-priority messages are delivered and alert administrators to impending problems.\nHow can I make my Web services transparent?\nThe Service Manager implements powerful dynamic discovery capabilities to fully abstract consumer applications from any knowledge of service endpoint location, or fabric policy.\nHow do I expose services on Mainframe and AS/400 systems?\nExposing services on Mainframe and AS/400 systems is not the problem, there are many technologies and companies that do just that. The challenge is to do it in a way that ensures security and protects the mainframe and AS/400 systems from denial-of-service attacks.\nThe SOA Software Mainframe and AS/400 solution package delivers a powerful combination of professional services expertise and product to create secure managed Web services from mission critical Mainframe and AS/400 systems. It integrates enterprise identity-management systems such as Netegrity SiteMinder or IBM Tivoli Access Manager with Mainframe security solutions like ACF/2 and RAC/F. It delivers powerful service level agreement and contract management capabilities combined with comprehensive message throughput and routing controls to prevent denial-of-service attacks.\nWhy is policy-based management important?\nThe number of service relationships in an organization will quickly grow beyond its ability to manage and secure the services individually. To handle this, the practices and standards of the organization should be defined and stored centrally as policies. These policies can then be easily managed and applied to the distributed groups of services.\nPolicy-based management is critical if your enterprise intends to define central policies for security, performance and availability and then implement and enforce these policies at a service and application level.\nThe concept of policy-based management allows central definition of security, availability and performance requirements in a single location (the Policy Definition Point – PDP), with these definition being automatically implemented and enforced at distribute Policy Enforcement Points – PEPs. This dramatically reduces the cost of securing and managing a large scale Web services deployment.\nThe Service Manager is the industry’s first comprehensive, central policy-based management and security solution.\nManagement and Security Policy can be defined at many levels. At a high level, it is the rules defined by the enterprise for managing and securing applications and transactions. At a more granular level it is the meta-data used to describe these business policies and their enforcement.\nWhat is the difference between definition, enforcement and enablement?\nDefinition is the process of defining policies for security and management.\nEnforcement is the process of enforcing these policies as described above.\nEnablement goes beyond both of these to provide a mechanism for automatically allowing applications to comply with Policy.\nSOA Software is the only SOA enablement vendor with products that dynamically adapt to the changing infrastructure to fully abstract application developers from management and security policy. The Gateway and Management Point products provide the core of this enablement capability.\nWhy is it important to externalize policy?\nThe number of service relationships in an organization will quickly grow beyond its ability to manage and secure the services individually. To handle this, the practices and standards of the organization should be defined and stored centrally as policies. These policies can then be easily managed and applied to the distributed groups of services.\nExternalized Policy-based management is critical if your enterprise intends to define central policies for security, performance and availability and then implement and enforce these policies at a service and application level.\nWhat is the importance of the Web services standards?\nWeb services standards ratified by organization such as OASIS and the IETF are critical for the long term adoption of Web services. The basic building blocks of Web services, XML, SOAP, WSDL and UDDI allow applications to be built from loosely coupled services. Without further standards describing security, reliability, transaction support and other advanced capabilities, Web services will fail to deliver the real promise of a service oriented architecture.\nTo this end, standards like: WS-Security, WS-Federation, WS-Trust, WS-Reliability, WS-Transactions, WS-Correlation, WS-DistributedManagement and many others are fundamental to the success of Web services.\nWeb services security standards include, but are not limited to:\nWS-Security, Security Assertion Markup Language (SAML), XML-Encryption, XML-Signature, WS-Trust, WS-Federation, and WS-Policy (this is broader than security, but has strong security implications).\nWhat are the management standards?\nWeb services management standards include, but are not limited to:\nWS-Distributed Management, WS-Reliable Messaging, WS-Correlation, WS-Orchestration, WS-Meta-Data, and WS-Policy.\nWhat is WS-I?\nWS-I is the Web Services Interoperability organization. SOA Software is a member of WS-I.\nFrom the WS-I web site:\n“WS-I is an open, industry organization chartered to promote Web services interoperability across platforms, operating systems, and programming languages. The organization works across the industry and standards organizations to respond to customer needs by providing guidance, best practices, and resources for developing Web services solutions.\nWS-I was formed specifically for the creation, promotion, or support of Generic Protocols for Interoperable exchange of messages between services. Generic Protocols are protocols that are independent of any specific action indicated by the message beyond actions necessary for the secure, reliable, or efficient delivery of messages; \"Interoperable\" means suitable for and capable of being implemented in a neutral manner on multiple operating systems and in multiple programming languages.”\nOASIS (www.oasis-open.org) is the primary standards body focused on developing and ratifying Web services standards. SOA Software is a member of OASIS, tracking Web Services Management, Web Services Security and SOA Enablement standards.\nFrom the OASIS Web site:\n“OASIS is a not-for-profit, international consortium that drives the development, convergence and adoption of e-business standards. Members themselves set the OASIS technical agenda, using a lightweight, open process expressly designed to promote industry consensus and unite disparate efforts. OASIS produces worldwide standards for security, Web services, conformance, business transactions, supply chain, public sector, and interoperability within and between marketplaces.\nOASIS has more than 3,000 participants representing over 600 organizations and individual members in 100 countries around the world. The Consortium hosts two of the most widely respected information portals on XML and Web services standards, xml.CoverPages.org and XML.org. OASIS Member Sections include UDDI, CGM Open, LegalXML and PKI.”\nUDDI is one of the three foundations of Web services. It provides a registry of services that can be used both to allow application developers to find appropriate services, and as a meta-data store that can allow the fabric to abstract developers from service and fabric location and policy requirements.\nFrom www.developer.com: “(Universal Description, Discovery, and Integration)—An XML-based lookup service for locating Web Services in an Internet scenario.”\nSOAP is one of the three foundations of Web services. Arguably, for an application to be called a Web service, it must expose its interfaces as SOAP APIs.\nFrom www.developer.com: “(Simple Object Access Protocol)—A lightweight, XML-based messaging protocol that contains an envelope, header, and body, designed to exchange information in a decentralized, distributed environment.”\nWSDL is one of the three foundations of Web services. It provides a standard way of defining the interfaces and APIs implemented by a service.\nFrom www.developer.com: “(Web Services Definition Language)—An XML-based language used to give a description about the Web Services available in a UDDI.”\nThe www.developer.com definition is somewhat misleading, because it is not necessary for a service to be published in a UDDI registry for it to have a WSDL document.\nWhat is SAML?\nSAML (Security Assertions Markup Language) provides a basic framework for federated authentication and authorization. Essentially SAML allows a user (person or application) to authenticate once against a server that validates the identity. Once authenticated the server will issue an authentication assertion to the user (the server can also generate an authorization assertion that grants privileges to the user), the user can pass this (these) assertion(s) on to other application that can then verify that the user is who they say they are, without having any prior knowledge of the user. This would be most useful in partnership environments, where an enterprise can rely on its partners to authenticate their own users. Unfortunately there are some outstanding challenges that SAML must address before it can be widely used in this type of environment:\n- Chained trust – A SAML assertion is signed by its issuing authority, but there is no model for attaching a trust chain, i.e. signature of an authority that can vouch for the issuing authority\n- Token interoperability – SAML is often used as a simple container for passing proprietary credentials. A good example is Netegrity TransactionMinder that generates a SAML assertion containing just a Siteminder ID. This renders different SAML implementations non-interoperable\n- Standards battles – Liberty Alliance and a group led by Microsoft and IBM are battling over specific federation models. Without an effective federation standard SAML is rendered impotent.\nWhy is SOA Software’s SAML implementation unique and valuable? The following text is the formal description of SAML taken directly from the OASIS published standard.\nThe Security Assertion Markup Language (SAML) is an XML-based framework for exchanging security information. This security information is expressed in the form of assertions about subjects, where a subject is an entity (either human or computer) that has an identity in some security domain. A typical example of a subject is a person, identified by his or her email address in a particular Internet DNS domain.\nAssertions can convey information about authentication acts that were previously performed by subjects, attributes of subjects, and authorization decisions about whether subjects are allowed to access certain resources. A single assertion might contain several different internal statements about authentication, authorization, and attributes.\nAssertions are issued by SAML authorities, namely, authentication authorities, attribute authorities, and policy decision points. SAML defines a protocol by which clients can request assertions from SAML authorities and get a response from them. This protocol, consisting of XML-based request and response message formats, can be bound to many different underlying communications and transport protocols; SAML currently defines one binding, to SOAP over HTTP. SAML authorities can use various sources of information, such as external policy stores and assertions that were received as input in requests, in creating their responses. Thus, while clients always consume assertions, SAML authorities can be both producers and consumers of assertions.\nOne major design goal for SAML is Single Sign-On (SSO), the ability of a user to authenticate in one domain and use resources in other domains without re-authenticating. However, SAML can be used in various configurations to support additional scenarios as well. Several profiles of SAML have been defined that support different styles of SSO, as well as the securing of SOAP payloads.\nWS-Distributed Management (WSDM) is an OASIS technical committee (TC) tasked with creating a standard for the management of distributed Web services.\nFrom www.oasis-open.org: “The purpose of this TC is to define web services management, including using web services architecture and technology to manage distributed resources. This TC will also develop the model of a web service as a manageable resource.”", "label": 1}
{"text": "A Sophos researcher stirred up the Mac masses this week when he reported that 20 percent of Mac computers carry Windows malware. The good news is that even though Macs are capable of harboring Windows-targeting viruses and Trojans, those machines can't be harmed by the malware in all but exceptional cases. The bad news, though, is that Mac users can still spread that malware to Windows machines in a number of ways.\nSophos senior technology consultant Graham Cluley reported earlier this week on a Sophos study that found that one in five Macs carries one or more instances of Windows malware and that one in 36 Macs are infected with Mac malware.\nSome critics of Cluley's article have taken issue with his view that \"although most of the malware we're currently seeing on Macs is designed to infect Windows, you should still be a responsible member of society and ensure that you're keeping your Mac squeaky clean.\"\nAgain, Windows malware won't hurt a Mac, but a Mac user can inadvertently pass along that malware to a colleague's or friend's Windows machine in a number of ways. Cluely provided InfoWorld with the following examples:\n- Forwarding malware-infected emails to Windows-using friends and colleagues\n- Sharing files with Windows colleagues and friends (using USB sticks, Dropbox, or the like)\n- If Web development is done on a Mac, infected files (be they executable or HTML/JS infections) can end up being transferred to a Web server and shared with the world\nWhat's more, Mac machines aren't entirely immune to Windows malware if they're, say, running Parallels. \"When you run Parallels, or any virtual machine software that runs a full copy of Windows, it's just like you're running Windows when you're in that VM, and all the same rules apply,\" InfoWorld security expert Roger Grimes said via email.\nUnless you run Windows on your Mac, the notion of loading resource-intensive antivirus software simply for the sake of protecting a peer or friend's Windows machine may not sit well. Bill Cole, a system admin, thoughtfully weighed in on the subject in his blog:\nAs both Cole and Cluley noted, the emergence of Mac malware like Flashback points to the fact that Macs are becoming increasingly targeted by malware as the Mac platform continues to gain popularity. \"Clearly, the Windows malware on Macs isn't as big a problem as Mac malware actually running on Macs, but the fact that some of the Windows malware we found on Macs was five years old underlines that many Mac users simply aren't taking security seriously at all,\" Cluely told InfoWorld.\nIn other words, it would behoove Mac users to start taking necessary precaution to better protect their machines, just as it would suit vendors (hey, how about Apple?) to develop the sort of security software that Mac users will want to use. Mac malware will only increase, and down the road, we might start seeing instances of malware capable of infecting both Macs and Windows.\n\"There are very, very few examples of malware that have payloads that work on both Mac and Windows. The ones that do exist aren't common in the wild,\" said Grimes. \"As our Web standards become more standard (with Web services, HTML5, and so on), we can expect payloads to become cross-platform, because the bad guy can at least infect and exploit within the hosting browser environment. I expect a future headline within a year or two to announce the arrival of popular cross-platform malware.\"\nThis story, \"Why Mac users should care about Windows malware,\" was originally published at InfoWorld.com. Get the first word on what the important tech news really means with the InfoWorld Tech Watch blog. For the latest developments in business technology news, follow InfoWorld.com on Twitter.", "label": 1}
{"text": "Oracle just launched Oracle Global Secure Desktop 4.7. It is a\ndesktop virtualization product based upon Oracle's Oracle VM, access\nvirtualization and application virtualization technology. It is designed\nto offer Oracle's customers Web-based access to their Windows, Linux,\nUNIX, and both IBM System i and System z applications. This approach\nallows applications and data to be safely tucked away in the customer's\ndatacenter, reduces the cost and complexity of desktop system\nmanagement, and, Oracle hope's, will beat out similar product offerings\nfrom Citrix, Microsoft and VMware.\nWhat is desktop virtualization?\nAlthough I've run though this examination before, Oracle's Global Secure Desktop launch suggests that it would be good time to consider desktop virtualization once again. Desktop virtualization, as a catch phrase, means different things to different suppliers. For the most part, desktop virtualization is the use of one or more of four different virtualization technologies to create an artificial desktop computing environment. If we examine offerings coming from Citrix, Microsoft and VMware, all of the following technologies are included.\nThe four virtualization technologies in use include:\n- Access Virtualization — hardware and software technology that allows nearly any device to access any application without either having to know too much about the other. The application sees a device it’s used to working with. The device sees an application it knows how to display. In some cases, special purpose hardware is used on each side of the network connection to increase performance, allow many users to share a single client system or allow a single individual to see multiple displays.\n- Application Virtualization — software technology allowing applications to run on many different operating systems and hardware platforms. This usually means that the application has been written to use an application framework. It also means that applications running on the same system that do not use this framework do not get the benefits of application virtualization. More advanced forms of this technology offer the ability to restart an application in case of a failure, start another instance of an application if the application is not meeting service level objectives, or provide workload balancing among multiple instances of an application to archive high levels of scalability. Some really sophisticated approaches to application virtualization can do this magical feat without requiring that the application be re-architected or rewritten using some special application framework.\n- Processing Virtualization — hardware and software technology that hides physical hardware configuration from system services, operating systems or applications. This type of Virtualization technology can make one system appear to be many or many systems appear to be a single computing resource to achieve goals ranging from raw performance, high levels of scalability, reliability/availability, agility or consolidation of multiple environments onto a single system.\n- Management of virtualized environments — In the case of desktop virtualization, this means the management of a combination of some of the following: virtual machine software, operating system, application frameworks, applications, database manager, user personalization and/or user data to create a secure, reliabile, movable artificial client system or environment.\nHow does Oracle describe Oracle Global Desktop 4.7?\nOracle Secure Global Desktop 4.7 delivers a richer application experience by providing:\n- Multi-monitor support: Can increase productivity in organizations such as contact centers by allowing users to run multiple applications on different physical monitors at the same time.\n- Bi-directional audio: Expanding on the existing support for audio output for Windows applications, Oracle Secure Global Desktop now supports microphones and other audio input devices. This enables the use of dictation, conferencing, training, and other applications requiring audio interaction.\n- Enhanced Linux and UNIX graphics display: Oracle Secure Global Desktop now supports improved performance for 3-D applications utilizing OpenGL 1.3 graphics extensions. This provides a richer user experience for customers in Federal Government, Healthcare, Education and other industries where the regular use of graphically intense applications is becoming more common.\n- Oracle Secure Global Desktop 4.7 provides optimal out-of-the-box security through pre-configured security settings, eliminating the need for additional effort by administrators. This helps ensure consistency for large enterprise deployments.\n- Oracle Secure Global Desktop 4.7 adds support for the latest Internet browsers and server OS platforms including Internet Explorer 9, Chrome and the latest Firefox ESR browsers, and the Oracle Linux 6 and Oracle Solaris 11 operating systems.\nIf you are an Oracle customer, this form of desktop virtualization will be attractive. It is tightly integrated into the Oracle virtualization strategy and, in all likelihood, will be easier to manage and install. Is this offering better than similar technology being offered by Citrix, Microsoft and VMware. That is subject to debate.\nWhat is clear is that Oracle has developed a template for its Oracle VM product that should make installation and initial use a pretty painless process.\nIf you are not an Oracle customer, the requirement for having one of the following platforms in your IT infrastructure could be a show stopper:\n- Oracle Linux 5.7, 5.8, 6.2 or 6.3\n- Oracle Solaris 11 and Oracle Solaris 11 Trusted Extensions (x86 and SPARC)\n- Oracle Solaris 10 and Oracle Solaris 10 Trusted Extensions (x86 and SPARC)\nIf your organization' IT infrastructure doesn't include one of these operating systems, other offerings would be a better choice.", "label": 1}
{"text": "Android Paternity Test App Developed by UC Irvine Computer Scientists\nUniversity of California, Irvine, computer scientists have developed a genomic app that conducts on-the-spot paternity tests and holds potential for personalized medicine.\nThe software platform, or personal genomic toolkit, is called GenoDroid, and the actual Android app is named Pater Noster, which means \"our father\" in Latin.\nGenoDroid uses advanced encryption techniques to preserve the privacy of people's DNA.\n\"It doesn't do magic,\" Gene Tsudik, UC Irvine professor of computer science told eWEEK. \"It just shows that today it's practical to run privacy-preserving genomic applications [and] operations, on modern smartphones—these ubiquitous personal devices.\"\nTsudik leads a group of faculty and students and visitors in applied cryptography, computer/network security and privacy as part of Security and Privacy Research Outfit (SPROUT) at UC Irvine.\nHe designed the smartphone app along with Emiliano De Cristofaro of Xerox's Palo Alto Research Center and a UC Irvine doctoral program graduate; UC Irvine Ph.D. candidate Sky Faber and Paolo Gasti, assistant professor at the New York Institute of Technology and a former UC Irvine postdoctoral researcher.\nDNA extracted from skin, hair or body fluids holds clues to genetic dispositions such as diseases, personality, eye color, hair color and height, Tsudik noted.\nMost of the genomic data would be storage on a PC or a laptop, said Tsudik.\nThe scientists tested the the app with publicly available genomic data. It can determine in less than a second whether one person is the father of another.\n\"What we do is we extract certain information from the DNA that is necessary to run a paternity test, so you don't actually need the entire genome to run a paternity test,\" he explained.\n\"The paternity test app compares the lengths of specific DNA segments from two individuals to determine how many of them match in the two samples,\" said Tsudik.\nWith the growing options for genomic sequencing, maintaining privacy of the data is essential, and promoting and protecting the privacy of a person's DNA is the main goal of the application, he said.\nCryptographic and encryption techniques protect the data during the paternity test on the app, according to Tsudik. A test algorithm decrypts and compares the DNA.\nThe app's \"double-blind\" technique only indicates a match or no match and doesn't reveal any other details about the DNA.\n\"Privacy of genomic information is really, really important,\" he said. \"It is possible to get privacy and still do these kinds of genomic operations.\"\nIf DNA falls into the wrong hands and various parties, such as an employer or car insurance company, find out about a person's temper, for example, it could be detrimental, Tsudik suggested.\nCurrently the app is limited to a quick paternity test, but its functionality will be expanded when DNA digitalization become commonplace.\n\"We are working on extending it to privacy-preserving maternity and more general ancestry tests,\" said Tsudik. Eventually, it could determine the likelihood of being born with an illness such as Down syndrome and be able to help biologists customize cancer-fighting drugs, he said.", "label": 1}
